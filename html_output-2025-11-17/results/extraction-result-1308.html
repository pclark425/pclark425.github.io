<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1308 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1308</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1308</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-272600498</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.08097v1.pdf" target="_blank">Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach</a></p>
                <p><strong>Paper Abstract:</strong> Testing controllers in safety-critical systems is vital for ensuring their safety and preventing failures. In this paper, we address the falsification problem within learning-based closed-loop control systems through simulation. This problem involves the identification of counterexamples that violate system safety requirements and can be formulated as an optimization task based on these requirements. Using full-fidelity simulator data in this optimization problem can be computationally expensive. To improve efficiency, we propose a multi-fidelity Bayesian optimization falsification framework that harnesses simulators with varying levels of accuracy. Our proposed framework can transition between different simulators and establish meaningful relationships between them. Through multi-fidelity Bayesian optimization, we determine both the optimal system input likely to be a counterexample and the appropriate fidelity level for assessment. We evaluated our approach across various Gym environments, each featuring different levels of fidelity. Our experiments demonstrate that multi-fidelity Bayesian optimization is more computationally efficient than full-fidelity Bayesian optimization and other baseline methods in detecting counterexamples. A Python implementation of the algorithm is available at https://github.com/SAILRIT/MFBO_Falsification.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1308.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1308.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cart-Pole (Gym variants)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Custom multi-fidelity Cart-Pole simulators based on OpenAI Gym CartPole</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Three fidelity variants (low, middle, high) of the classic Cart-Pole Gym environment were created by changing integrator, force magnitude, sensor noise/precision, and episode length; a PPO controller was trained on the highest-fidelity simulator and evaluated across fidelities for falsification experiments using multi-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>OpenAI Gym CartPole (custom low/mid/high variants)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Gym Cart-Pole environment modified into three fidelity levels by changing the numerical integrator (Euler vs semi-implicit Euler), applied force magnitudes, sensor noise/precision, and episode lengths to create increasing realism and computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / control (classical control)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Three levels: low-fidelity (Euler integrator, lower episode length and coarse sensors), middle-fidelity (intermediate settings), high-fidelity (semi-implicit Euler integrator, highest force magnitude and longest episode length).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Low: Euler integrator, force magnitude 10, position sensor noise N(0,0.25), sensors precision 2 digits, episode length 150; Middle: Euler integrator, force magnitude 15, sensors precision 6 digits, episode length 300; High: semi-implicit Euler integrator, force magnitude 20, sensors precision 8 digits, episode length 450. (Values from Table I in paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>PPO (Proximal Policy Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reinforcement learning agent trained with PPO on the high-fidelity Cart-Pole simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Controller safety validation / falsification (find environment parameter e that causes spec violation for the trained controller).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Validation / falsification on lower- and higher-fidelity simulators (counterexamples proposed on low/mid fidelities validated on high-fidelity simulator).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO produced counterexamples whose validated reliability was about 26% higher (on average) than BO conducted solely on low- and middle-fidelity simulators; cost-per-counterexample reduced up to 49.5% (three-fidelity) and 32.4% (two-fidelity) compared to BO on high-fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>The paper compares two- and three-fidelity BO against single-fidelity BO. Three-fidelity BO reduced reliance on the low-fidelity simulator (27% reduction in use) and improved reliability vs two-fidelity in Cart-Pole; overall multi-fidelity BO found more reliable counterexamples for the same cost than single-fidelity high-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit single 'minimum' fidelity is prescribed; authors note that middle-fidelity can be beneficial when it provides information distinct from low-fidelity, but if middle is similar to low it adds little value.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Noted that if lower fidelities are too dissimilar or too noisy, they may mislead optimization; assumption of linear correlation between fidelities can be insufficient for complex models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1308.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1308.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lunar Lander (Gym variants)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Custom multi-fidelity Lunar Lander simulators based on OpenAI Gym LunarLander</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Low, middle, and high-fidelity variants of the Lunar Lander Gym environment were created by adding/removing wind disturbances, changing sensor precision, and episode lengths; a DDPG controller was trained on the high-fidelity simulator and falsified with multi-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>OpenAI Gym LunarLander (custom low/mid/high variants)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Gym LunarLander environment adjusted to three fidelity levels by varying wind disturbances (none/one/ two sources), turbulence magnitude, sensor precision, and episode length to alter realism and computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>aerospace control / mechanics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Three levels: low-fidelity (no wind disturbances, lower sensor precision), middle-fidelity (one disturbance), high-fidelity (two disturbances and higher turbulence magnitude).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Low: no wind, lower turbulence, sensors ~2 decimal points; Middle: one wind disturbance, intermediate precision and episode length; High: two wind disturbances, higher turbulence power (e.g., turbulence power up to ~1.99 in table), longest episode length. Simulation frequency and exact sensor precisions also vary per Table I.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DDPG (Deep Deterministic Policy Gradient)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Continuous-action RL agent trained with DDPG on the high-fidelity Lunar Lander simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Controller falsification / safety testing (identify initial perturbations and disturbances that violate landing safety specifications).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Validation of counterexamples from low/mid fidelities on the high-fidelity simulator (i.e., transfer of falsifying scenarios to the trained high-fidelity controller).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO yielded about a 30% improvement in reliability of discovered counterexamples compared to BO on low/mid fidelities; cost reductions vs high-fidelity BO were reported as ~69% (three-fidelity) and ~65% (two-fidelity).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Three- and two-fidelity BO outperform single-fidelity high-fidelity BO in average cost per validated counterexample; however, when middle-fidelity is very similar to low-fidelity, adding the middle level did not improve reliability (middle provided little new information).</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors conclude that a middle-fidelity level close to low-fidelity may be redundant; minimal useful fidelity depends on whether lower fidelities provide informative, non-redundant signals for the high-fidelity objective.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When the middle-fidelity is similar to low-fidelity (small gap), three-fidelity BO did not improve reliability; inaccurate cost estimates or poor fidelity gaps can degrade multi-fidelity performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1308.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1308.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Highway Driving (custom)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Custom multi-fidelity Highway driving simulators (autonomous driving scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>High-, middle-, and low-fidelity highway driving simulators were implemented by varying simulation frequency, number of vehicles, sensor noise, and other traffic-model parameters; a DQN ego-agent was trained on the high-fidelity simulator and falsified with multi-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Custom autonomous driving highway simulators (Gym-based)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Multi-agent traffic simulation implementing an ego vehicle (kinematic bicycle model) and surrounding vehicles using IDM and MOBIL models; fidelity varied via simulation frequency (11/13/15 Hz), number of cars (fewer in low-fidelity), and increased sensor noise at lower fidelities.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>autonomous driving / vehicle dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Low: lower sim frequency (11), fewer cars, larger sensor noise; Middle: intermediate frequency (13) and noise; High: highest sim frequency (15), more cars on road, negligible sensor noise.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Simulation frequency differences (11,13,15); low/mid fidelity inject sensor noise into position and speed measurements (e.g., position noise N(0,0.1–0.2)); fewer vehicles present in lower fidelities. Traffic agent models (IDM, MOBIL) use different parameterizations across fidelities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DQN (Deep Q-Network) for ego vehicle; IDM and MOBIL for other vehicles</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Discrete-action RL agent (DQN) controls lane changes and speed; surrounding vehicles simulated with parametric models (IDM for longitudinal, MOBIL for lateral).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Find safety-violating traffic scenarios (maintain safe distances) — falsification of trained driving policy under uncertainty in initial spacings/velocities.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Validation of counterexamples discovered on low/mid fidelities on high-fidelity driving simulator (i.e., transfer to the trained high-fidelity controller/environment).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO improved validated counterexample reliability by ~12% (vs BO on low/mid fidelities) in highway case; cost reductions vs high-fidelity BO were ~18% (three-fidelity) and ~26% (two-fidelity).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Two- and three-fidelity BO reduce cost-per-counterexample compared to high-fidelity BO, but three-fidelity sometimes underperformed (fewer high-fidelity evaluations were run, reducing reliability); TuRBO-1 outperformed multi-fidelity BO in this higher-dimensional scenario.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors note that in higher-dimensional uncertainty spaces (e.g., highway), multi-fidelity models can become less accurate and replacing some high-fidelity evaluations with middle-fidelity ones can reduce overall reliability; no single minimum fidelity is prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Three-fidelity BO performed worse in some highway experiments because a small proportion of accurate high-fidelity runs were replaced by middle-fidelity ones, decreasing reliability; TuRBO-1 sometimes outperforms in high-dimensional settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1308.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1308.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Merge Driving (custom)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Custom multi-fidelity Merge negotiation driving simulators</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Merge scenario simulators vary IDM parameters and sensor noise to create low/mid/high fidelities (highly aggressive to conservative driving behavior); controllers trained on high-fidelity were falsified via multi-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Custom autonomous driving merge simulators (Gym-based)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>High-fidelity simulator models aggressive IDM parameters and realistic sensor characteristics; middle/low fidelities use more conservative IDM parameters and add sensor noise to reduce realism and cost.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>autonomous driving / traffic dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>High: aggressive IDM parameters, accurate sensors; Middle: intermediate IDM parameters and sensor noise; Low: conservative IDM parameters and higher sensor noise.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Fidelity adjusted via IDM parameters (max comfortable accel/decel), time-gap, max braking, and sensor noise; low/mid include sensor noise and conservative driver behavior while high-fidelity is most aggressive and realistic.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DQN (ego), IDM for longitudinal behavior of other vehicles</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RL ego agent (DQN); other vehicles modeled parametrically with IDM using different parameters per fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Falsification of merge maneuver safety (maintain minimum distance and avoid collisions while preserving speed).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Validation of counterexamples from lower fidelities on the high-fidelity merge simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Reported cost reductions vs high-fidelity BO were 2.7% (two-fidelity) and 58% (three-fidelity); multi-fidelity BO sometimes used higher fidelity more often in merge, increasing cost but improving reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Three-fidelity BO tended to use higher-fidelity simulators more frequently in this scenario (less exploration of low-fidelity), which increased cost compared to two-fidelity but could improve reliability when middle fidelity is informative.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors emphasize that usefulness of middle-fidelity depends on whether it provides new informative signals vs low-fidelity; no explicit minimal fidelity threshold is given.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>If middle-fidelity is not informative, multi-fidelity approach may default to high-fidelity and lose cost advantage; selection depends on fidelity gaps and cost ratios.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1308.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1308.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Roundabout Driving (custom)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Custom multi-fidelity Roundabout driving simulators</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Roundabout simulators vary MOBIL parameters (politeness, lane-change delay) and braking/acceleration constraints across three fidelities; a DQN agent trained on high-fidelity was falsified using multi-fidelity BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Custom autonomous driving roundabout simulators (Gym-based)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Simulators model ego and surrounding vehicles negotiating a roundabout; fidelity controlled by MOBIL parameters such as politeness factor and lane-change delays, and max braking/acceleration constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>autonomous driving / traffic dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Low: conservative MOBIL params (higher politeness, larger lane-change delays), mid: intermediate, high: aggressive/realistic MOBIL params with quicker lane-change decisions and stricter accel/brake constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Parameter changes include lane-change delay (0.84/0.82/0.8), politeness (0.1/0.05/0.0), and max braking/acceleration adjustments; number/behavior of vehicles and sensor noise may also vary.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>DQN (ego), MOBIL for lateral behavior of other vehicles</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Discrete-action RL ego agent (DQN); surrounding vehicles use MOBIL model with varying parameters per fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Falsification of roundabout navigation safety (maintain coordinate separation thresholds to avoid collisions).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Validation of counterexamples from lower fidelities on high-fidelity roundabout simulator.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Multi-fidelity BO obtained cost reductions of ~61% (three-fidelity) and ~70% (two-fidelity) compared to high-fidelity BO; multi-fidelity improved reliability of counterexamples substantially in this scenario.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Integration of a middle-fidelity level can either increase or decrease average cost-per-counterexample depending on how informative the middle level is; in roundabout experiments three- and two-fidelity BO delivered large cost savings.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimal fidelity specified; authors note that fidelity usefulness depends on how much additional useful information a level provides relative to its cost.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When middle-fidelity is uninformative or cost ratios are mis-estimated, multi-fidelity can lose advantage; incorrect cost estimates or poor fidelity gaps can reduce effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Safety validation of learning-based autonomous systems: A multi-fidelity approach <em>(Rating: 2)</em></li>
                <li>Exploring the role of simulator fidelity in the safety validation of learning-enabled autonomous systems <em>(Rating: 2)</em></li>
                <li>Predicting the output from a complex computer code when fast approximations are available <em>(Rating: 2)</em></li>
                <li>Nonlinear information fusion algorithms for dataefficient multi-fidelity modelling <em>(Rating: 2)</em></li>
                <li>Recursive co-kriging model for design of computer experiments with multiple levels of fidelity <em>(Rating: 2)</em></li>
                <li>Falsification of learning-based controllers through multi-fidelity Bayesian optimization <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1308",
    "paper_id": "paper-272600498",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "Cart-Pole (Gym variants)",
            "name_full": "Custom multi-fidelity Cart-Pole simulators based on OpenAI Gym CartPole",
            "brief_description": "Three fidelity variants (low, middle, high) of the classic Cart-Pole Gym environment were created by changing integrator, force magnitude, sensor noise/precision, and episode length; a PPO controller was trained on the highest-fidelity simulator and evaluated across fidelities for falsification experiments using multi-fidelity BO.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "OpenAI Gym CartPole (custom low/mid/high variants)",
            "simulator_description": "Gym Cart-Pole environment modified into three fidelity levels by changing the numerical integrator (Euler vs semi-implicit Euler), applied force magnitudes, sensor noise/precision, and episode lengths to create increasing realism and computational cost.",
            "scientific_domain": "mechanics / control (classical control)",
            "fidelity_level": "Three levels: low-fidelity (Euler integrator, lower episode length and coarse sensors), middle-fidelity (intermediate settings), high-fidelity (semi-implicit Euler integrator, highest force magnitude and longest episode length).",
            "fidelity_characteristics": "Low: Euler integrator, force magnitude 10, position sensor noise N(0,0.25), sensors precision 2 digits, episode length 150; Middle: Euler integrator, force magnitude 15, sensors precision 6 digits, episode length 300; High: semi-implicit Euler integrator, force magnitude 20, sensors precision 8 digits, episode length 450. (Values from Table I in paper.)",
            "model_or_agent_name": "PPO (Proximal Policy Optimization)",
            "model_description": "Reinforcement learning agent trained with PPO on the high-fidelity Cart-Pole simulator.",
            "reasoning_task": "Controller safety validation / falsification (find environment parameter e that causes spec violation for the trained controller).",
            "training_performance": null,
            "transfer_target": "Validation / falsification on lower- and higher-fidelity simulators (counterexamples proposed on low/mid fidelities validated on high-fidelity simulator).",
            "transfer_performance": "Multi-fidelity BO produced counterexamples whose validated reliability was about 26% higher (on average) than BO conducted solely on low- and middle-fidelity simulators; cost-per-counterexample reduced up to 49.5% (three-fidelity) and 32.4% (two-fidelity) compared to BO on high-fidelity.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "The paper compares two- and three-fidelity BO against single-fidelity BO. Three-fidelity BO reduced reliance on the low-fidelity simulator (27% reduction in use) and improved reliability vs two-fidelity in Cart-Pole; overall multi-fidelity BO found more reliable counterexamples for the same cost than single-fidelity high-fidelity BO.",
            "minimal_fidelity_discussion": "No explicit single 'minimum' fidelity is prescribed; authors note that middle-fidelity can be beneficial when it provides information distinct from low-fidelity, but if middle is similar to low it adds little value.",
            "failure_cases": "Noted that if lower fidelities are too dissimilar or too noisy, they may mislead optimization; assumption of linear correlation between fidelities can be insufficient for complex models.",
            "uuid": "e1308.0",
            "source_info": {
                "paper_title": "Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Lunar Lander (Gym variants)",
            "name_full": "Custom multi-fidelity Lunar Lander simulators based on OpenAI Gym LunarLander",
            "brief_description": "Low, middle, and high-fidelity variants of the Lunar Lander Gym environment were created by adding/removing wind disturbances, changing sensor precision, and episode lengths; a DDPG controller was trained on the high-fidelity simulator and falsified with multi-fidelity BO.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "OpenAI Gym LunarLander (custom low/mid/high variants)",
            "simulator_description": "Gym LunarLander environment adjusted to three fidelity levels by varying wind disturbances (none/one/ two sources), turbulence magnitude, sensor precision, and episode length to alter realism and computational cost.",
            "scientific_domain": "aerospace control / mechanics",
            "fidelity_level": "Three levels: low-fidelity (no wind disturbances, lower sensor precision), middle-fidelity (one disturbance), high-fidelity (two disturbances and higher turbulence magnitude).",
            "fidelity_characteristics": "Low: no wind, lower turbulence, sensors ~2 decimal points; Middle: one wind disturbance, intermediate precision and episode length; High: two wind disturbances, higher turbulence power (e.g., turbulence power up to ~1.99 in table), longest episode length. Simulation frequency and exact sensor precisions also vary per Table I.",
            "model_or_agent_name": "DDPG (Deep Deterministic Policy Gradient)",
            "model_description": "Continuous-action RL agent trained with DDPG on the high-fidelity Lunar Lander simulator.",
            "reasoning_task": "Controller falsification / safety testing (identify initial perturbations and disturbances that violate landing safety specifications).",
            "training_performance": null,
            "transfer_target": "Validation of counterexamples from low/mid fidelities on the high-fidelity simulator (i.e., transfer of falsifying scenarios to the trained high-fidelity controller).",
            "transfer_performance": "Multi-fidelity BO yielded about a 30% improvement in reliability of discovered counterexamples compared to BO on low/mid fidelities; cost reductions vs high-fidelity BO were reported as ~69% (three-fidelity) and ~65% (two-fidelity).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Three- and two-fidelity BO outperform single-fidelity high-fidelity BO in average cost per validated counterexample; however, when middle-fidelity is very similar to low-fidelity, adding the middle level did not improve reliability (middle provided little new information).",
            "minimal_fidelity_discussion": "Authors conclude that a middle-fidelity level close to low-fidelity may be redundant; minimal useful fidelity depends on whether lower fidelities provide informative, non-redundant signals for the high-fidelity objective.",
            "failure_cases": "When the middle-fidelity is similar to low-fidelity (small gap), three-fidelity BO did not improve reliability; inaccurate cost estimates or poor fidelity gaps can degrade multi-fidelity performance.",
            "uuid": "e1308.1",
            "source_info": {
                "paper_title": "Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Highway Driving (custom)",
            "name_full": "Custom multi-fidelity Highway driving simulators (autonomous driving scenarios)",
            "brief_description": "High-, middle-, and low-fidelity highway driving simulators were implemented by varying simulation frequency, number of vehicles, sensor noise, and other traffic-model parameters; a DQN ego-agent was trained on the high-fidelity simulator and falsified with multi-fidelity BO.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Custom autonomous driving highway simulators (Gym-based)",
            "simulator_description": "Multi-agent traffic simulation implementing an ego vehicle (kinematic bicycle model) and surrounding vehicles using IDM and MOBIL models; fidelity varied via simulation frequency (11/13/15 Hz), number of cars (fewer in low-fidelity), and increased sensor noise at lower fidelities.",
            "scientific_domain": "autonomous driving / vehicle dynamics",
            "fidelity_level": "Low: lower sim frequency (11), fewer cars, larger sensor noise; Middle: intermediate frequency (13) and noise; High: highest sim frequency (15), more cars on road, negligible sensor noise.",
            "fidelity_characteristics": "Simulation frequency differences (11,13,15); low/mid fidelity inject sensor noise into position and speed measurements (e.g., position noise N(0,0.1–0.2)); fewer vehicles present in lower fidelities. Traffic agent models (IDM, MOBIL) use different parameterizations across fidelities.",
            "model_or_agent_name": "DQN (Deep Q-Network) for ego vehicle; IDM and MOBIL for other vehicles",
            "model_description": "Discrete-action RL agent (DQN) controls lane changes and speed; surrounding vehicles simulated with parametric models (IDM for longitudinal, MOBIL for lateral).",
            "reasoning_task": "Find safety-violating traffic scenarios (maintain safe distances) — falsification of trained driving policy under uncertainty in initial spacings/velocities.",
            "training_performance": null,
            "transfer_target": "Validation of counterexamples discovered on low/mid fidelities on high-fidelity driving simulator (i.e., transfer to the trained high-fidelity controller/environment).",
            "transfer_performance": "Multi-fidelity BO improved validated counterexample reliability by ~12% (vs BO on low/mid fidelities) in highway case; cost reductions vs high-fidelity BO were ~18% (three-fidelity) and ~26% (two-fidelity).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Two- and three-fidelity BO reduce cost-per-counterexample compared to high-fidelity BO, but three-fidelity sometimes underperformed (fewer high-fidelity evaluations were run, reducing reliability); TuRBO-1 outperformed multi-fidelity BO in this higher-dimensional scenario.",
            "minimal_fidelity_discussion": "Authors note that in higher-dimensional uncertainty spaces (e.g., highway), multi-fidelity models can become less accurate and replacing some high-fidelity evaluations with middle-fidelity ones can reduce overall reliability; no single minimum fidelity is prescribed.",
            "failure_cases": "Three-fidelity BO performed worse in some highway experiments because a small proportion of accurate high-fidelity runs were replaced by middle-fidelity ones, decreasing reliability; TuRBO-1 sometimes outperforms in high-dimensional settings.",
            "uuid": "e1308.2",
            "source_info": {
                "paper_title": "Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Merge Driving (custom)",
            "name_full": "Custom multi-fidelity Merge negotiation driving simulators",
            "brief_description": "Merge scenario simulators vary IDM parameters and sensor noise to create low/mid/high fidelities (highly aggressive to conservative driving behavior); controllers trained on high-fidelity were falsified via multi-fidelity BO.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Custom autonomous driving merge simulators (Gym-based)",
            "simulator_description": "High-fidelity simulator models aggressive IDM parameters and realistic sensor characteristics; middle/low fidelities use more conservative IDM parameters and add sensor noise to reduce realism and cost.",
            "scientific_domain": "autonomous driving / traffic dynamics",
            "fidelity_level": "High: aggressive IDM parameters, accurate sensors; Middle: intermediate IDM parameters and sensor noise; Low: conservative IDM parameters and higher sensor noise.",
            "fidelity_characteristics": "Fidelity adjusted via IDM parameters (max comfortable accel/decel), time-gap, max braking, and sensor noise; low/mid include sensor noise and conservative driver behavior while high-fidelity is most aggressive and realistic.",
            "model_or_agent_name": "DQN (ego), IDM for longitudinal behavior of other vehicles",
            "model_description": "RL ego agent (DQN); other vehicles modeled parametrically with IDM using different parameters per fidelity.",
            "reasoning_task": "Falsification of merge maneuver safety (maintain minimum distance and avoid collisions while preserving speed).",
            "training_performance": null,
            "transfer_target": "Validation of counterexamples from lower fidelities on the high-fidelity merge simulator.",
            "transfer_performance": "Reported cost reductions vs high-fidelity BO were 2.7% (two-fidelity) and 58% (three-fidelity); multi-fidelity BO sometimes used higher fidelity more often in merge, increasing cost but improving reliability.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Three-fidelity BO tended to use higher-fidelity simulators more frequently in this scenario (less exploration of low-fidelity), which increased cost compared to two-fidelity but could improve reliability when middle fidelity is informative.",
            "minimal_fidelity_discussion": "Authors emphasize that usefulness of middle-fidelity depends on whether it provides new informative signals vs low-fidelity; no explicit minimal fidelity threshold is given.",
            "failure_cases": "If middle-fidelity is not informative, multi-fidelity approach may default to high-fidelity and lose cost advantage; selection depends on fidelity gaps and cost ratios.",
            "uuid": "e1308.3",
            "source_info": {
                "paper_title": "Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Roundabout Driving (custom)",
            "name_full": "Custom multi-fidelity Roundabout driving simulators",
            "brief_description": "Roundabout simulators vary MOBIL parameters (politeness, lane-change delay) and braking/acceleration constraints across three fidelities; a DQN agent trained on high-fidelity was falsified using multi-fidelity BO.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Custom autonomous driving roundabout simulators (Gym-based)",
            "simulator_description": "Simulators model ego and surrounding vehicles negotiating a roundabout; fidelity controlled by MOBIL parameters such as politeness factor and lane-change delays, and max braking/acceleration constraints.",
            "scientific_domain": "autonomous driving / traffic dynamics",
            "fidelity_level": "Low: conservative MOBIL params (higher politeness, larger lane-change delays), mid: intermediate, high: aggressive/realistic MOBIL params with quicker lane-change decisions and stricter accel/brake constraints.",
            "fidelity_characteristics": "Parameter changes include lane-change delay (0.84/0.82/0.8), politeness (0.1/0.05/0.0), and max braking/acceleration adjustments; number/behavior of vehicles and sensor noise may also vary.",
            "model_or_agent_name": "DQN (ego), MOBIL for lateral behavior of other vehicles",
            "model_description": "Discrete-action RL ego agent (DQN); surrounding vehicles use MOBIL model with varying parameters per fidelity.",
            "reasoning_task": "Falsification of roundabout navigation safety (maintain coordinate separation thresholds to avoid collisions).",
            "training_performance": null,
            "transfer_target": "Validation of counterexamples from lower fidelities on high-fidelity roundabout simulator.",
            "transfer_performance": "Multi-fidelity BO obtained cost reductions of ~61% (three-fidelity) and ~70% (two-fidelity) compared to high-fidelity BO; multi-fidelity improved reliability of counterexamples substantially in this scenario.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Integration of a middle-fidelity level can either increase or decrease average cost-per-counterexample depending on how informative the middle level is; in roundabout experiments three- and two-fidelity BO delivered large cost savings.",
            "minimal_fidelity_discussion": "No explicit minimal fidelity specified; authors note that fidelity usefulness depends on how much additional useful information a level provides relative to its cost.",
            "failure_cases": "When middle-fidelity is uninformative or cost ratios are mis-estimated, multi-fidelity can lose advantage; incorrect cost estimates or poor fidelity gaps can reduce effectiveness.",
            "uuid": "e1308.4",
            "source_info": {
                "paper_title": "Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization",
            "rating": 2,
            "sanitized_title": "virtual_vs_real_trading_off_simulations_and_physical_experiments_in_reinforcement_learning_with_bayesian_optimization"
        },
        {
            "paper_title": "Safety validation of learning-based autonomous systems: A multi-fidelity approach",
            "rating": 2,
            "sanitized_title": "safety_validation_of_learningbased_autonomous_systems_a_multifidelity_approach"
        },
        {
            "paper_title": "Exploring the role of simulator fidelity in the safety validation of learning-enabled autonomous systems",
            "rating": 2,
            "sanitized_title": "exploring_the_role_of_simulator_fidelity_in_the_safety_validation_of_learningenabled_autonomous_systems"
        },
        {
            "paper_title": "Predicting the output from a complex computer code when fast approximations are available",
            "rating": 2,
            "sanitized_title": "predicting_the_output_from_a_complex_computer_code_when_fast_approximations_are_available"
        },
        {
            "paper_title": "Nonlinear information fusion algorithms for dataefficient multi-fidelity modelling",
            "rating": 2,
            "sanitized_title": "nonlinear_information_fusion_algorithms_for_dataefficient_multifidelity_modelling"
        },
        {
            "paper_title": "Recursive co-kriging model for design of computer experiments with multiple levels of fidelity",
            "rating": 2,
            "sanitized_title": "recursive_cokriging_model_for_design_of_computer_experiments_with_multiple_levels_of_fidelity"
        },
        {
            "paper_title": "Falsification of learning-based controllers through multi-fidelity Bayesian optimization",
            "rating": 2,
            "sanitized_title": "falsification_of_learningbased_controllers_through_multifidelity_bayesian_optimization"
        }
    ],
    "cost": 0.014704499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach
12 Sep 2024</p>
<p>Zahra Shahrooei 
Mykel J Kochenderfer 
Ali Baheri 
Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach
12 Sep 202493BF67CEAC5EA6C1C92984863D6A2559arXiv:2409.08097v1[eess.SY]
Testing controllers in safety-critical systems is vital for ensuring their safety and preventing failures.In this paper, we address the falsification problem within learningbased closed-loop control systems through simulation.This problem involves the identification of counterexamples that violate system safety requirements and can be formulated as an optimization task based on these requirements.Using fullfidelity simulator data in this optimization problem can be computationally expensive.To improve efficiency, we propose a multi-fidelity Bayesian optimization falsification framework that harnesses simulators with varying levels of accuracy.Our proposed framework can transition between different simulators and establish meaningful relationships between them.Through multi-fidelity Bayesian optimization, we determine both the optimal system input likely to be a counterexample and the appropriate fidelity level for assessment.We evaluated our approach across various Gym environments, each featuring different levels of fidelity.Our experiments demonstrate that multi-fidelity Bayesian optimization is more computationally efficient than full-fidelity Bayesian optimization and other baseline methods in detecting counterexamples.A Python implementation of the algorithm is available at https:// github.com/SAILRIT/MFBO_Falsification.</p>
<p>I. INTRODUCTION AND RELATED WORKS</p>
<p>The rapid development of cyber-physical systems, including autonomous vehicles and robotics, has enhanced the need for controllers to function both safely and reliably.Ensuring the safety of these systems is crucial to prevent catastrophic failures.This involves using simulation-based tests to identify potential failures, determine the most likely failure mode, and estimate system failure likelihood.Various methods have been developed for generating test scenarios for autonomous vehicles, including knowledge-based [1], [2], data-driven [3], [4], and search-based approaches [5], [6].Knowledgebased methods use formal models to create scenarios based on traffic rules, while data-driven approaches rely on realworld driving data to identify critical situations.On the other hand, search-based techniques explore possible scenarios by systematically testing different driving conditions to ensure comprehensive coverage.</p>
<p>Falsification is a search-based testing procedure that tries to disprove safety by discovering an input (a counterexample) that leads to a safety specification violation.A safety specification is a set of requirements that must be met by the system during execution.For falsification, the specification is often expressed in signal temporal logic [7] or metric 1 Zahra Shahrooei and Ali Baheri are with the Department of Mechanical Engineering at Rochester Institute of Technology.zs9580@rit.edu and akbeme@rit.edu 2 Mykel J. Kochenderfer is with the Department of Aeronautics &amp; Astronautics at Stanford University.mykel@stanford.eduinterval temporal logic [8].Various algorithms have been developed to solve the falsification problem.Among these, optimization-based algorithms are designed to guide the falsification process by defining a suitable objective function that guides the search towards an environment trace where the specification is not satisfied.For tackling this global optimization problem, black-box methods offer a structured approach for uncovering safety failures in systems without the need for understanding their internals.Black-box testing involves searching the uncertainty space, where the parameters are system inputs and the goal is to detect failures.Sequential search algorithms include ant colony optimization [9], stochastic local search [10], and simulated annealing [11].While these algorithms excel at efficiently navigating the uncertainty space, they do not make effective use of the information gained from prior simulations.</p>
<p>In this paper, we use Bayesian optimization (BO), a black-box algorithm to globally optimize an unknown objective function by approximating its model using Gaussian processes (GPs) [12] and continuously updating posterior estimates to help determine the next point to evaluate.BO has seen successful applications ranging from robotics [13], [14] and control [15] to design optimization problems [16], [17] and hyper-parameter tuning in machine learning [18].Additionally, BO has been extensively applied in safety testing [19]- [24].These studies typically focus on safely optimizing an unknown function [25].For instance, Ghosh et al. [21] use BO to address the falsification problem in uncertain closed-loop control systems.They model the unknown specification by breaking it down into a parse tree with individual constraints represented by nodes and each constraint modeled using GPs to reduce number of the required queries for falsification.Deshmukh et al. [19] proposed the use of random embedding BO (REMBO) [26] to tackle the falsification problem in cyber-physical systems with high-dimensional input spaces.Ramezani et al. [23] applied two other extensions of BO to falsification, trust region BO (TuRBO) [27] and πBO [28].TuRBO makes use of several local GPs, each within its trust region that shrinks or expands based on the success or failure of solutions.πBO, on the other hand, focuses on injecting the expert prior knowledge of the falsifying points to the BO framework.All these studies apply BO directly on the full-fidelity simulator.A significant drawback of using BO for simulation-based falsification is the high computational cost of evaluating the objective function on full-fidelity simulators.</p>
<p>Multi-fidelity BO is a promising approach for cost reduction when leveraging rich, high-fidelity simulators.This framework has been successfully applied to engineering design problems, scientific discovery, and hyperparameter optimization [29]- [31].Multi-fidelity BO exploits information from various fidelities to achieve higher efficiency than using full-fidelity.Fidelity level in simulators refers to how closely a simulator replicates the real system.High-fidelity and lowfidelity simulators can differ widely based on various factors across different applications.For instance, model fidelity refers to the simplification of the mathematical representation of the physical system, typically by simplifying the differential equations being solved or the numerical model.Additionally, sensor fidelity is related to having more accurate sensors within the simulator while environmental fidelity is associated with considering the effect of environment factors such as weather condition or disturbances in simulator.</p>
<p>There are also works on multi-fidelity BO in control systems [32]- [35].For example, Marco et al. [34] incorporate two degrees of fidelity involving both simulations and physical experiments in order to optimize controller parameters more efficiently.They propose an acquisition function aimed at striking a balance between cost and accuracy.However, they assume that the costs of simulation and real-world experimentation are predefined constants.Hence, the proposed algorithm suffers from lack of robustness to cost variation.</p>
<p>This paper is an extension of our conference publication [36] that proposes the first multi-fidelity BO application to the computationally demanding task of falsification for closed-loop control systems using data from different levels of fidelity.The framework has been shown to successfully cut down the cost of falsification in comparison to using fullfidelity simulator.However, we used predefined costs for the simulators with varying levels of fidelity, chosen manually and without any systematic measurement or analysis even though these costs directly influence the acquisition function and, consequently, the selection of the optimal fidelity level for evaluation.This paper expands the results of [36] through the following contributions:</p>
<p>• Unlike the previous paper, which focused solely on a two-fidelity setting, we investigate both two-fidelity and three-fidelity levels.We explore the role of a third fidelity level in reducing the cost of falsification, enhancing the applicability and flexibility of our approach.Additionally, we provide a detailed analysis of the cost changes associated with transitioning from a twofidelity setting to a three-fidelity setup, highlighting the trade-offs involved.• To avoid using manually assigned costs associated with different fidelity levels which can degrade the multifidelity BO performance, we propose a method to calculate the cost proportions of various fidelity degrees by measuring specific parameters, which offers a more realistic and adaptable cost model making multi-fidelity BO framework more robust and reliable in various applications.</p>
<p>• Unlike previous work, we extend the use of multifidelity BO to falsification of complex systems, specif-ically in the context of autonomous driving to demonstrate the applicability of multi-fidelity BO approach.• We study the trade-off between cost and accuracy in the context of falsification.We demonstrate that using multi-fidelity BO can improve accuracy compared to using low-fidelity simulation alone and assess the efficacy of multi-fidelity BO in cost reduction compared to standard BO and other extensions of BO that rely exclusively on high-fidelity simulators in several case studies.This paper is organized as follows.Section II specifies the problem formulation in terms of safety requirements and outlines the BO framework.Section III explains how we use multi-fidelity BO for falsification.Section IV describes how we implement multi-fidelity BO on four case studies.Section V discusses our empirical results.Section VI concludes our work and provides potential future directions.</p>
<p>II. PROBLEM FORMULATION AND PRELIMINARIES</p>
<p>This section briefly reviews our notation, system safety specification, quantitative semantics, and BO concepts.</p>
<p>A. Problem Formulation</p>
<p>We assume that we have access to a set of simulators with varying degrees of fidelity specified by S 1 to S q for a system of interest S. All these q simulators operate in a stochastic environment E that includes various types of uncertainty.We can parameterize each simulator with a set of environment parameters e ∈ E. Hence, each simulator takes an instance of the environment e as an input and returns a finite-length trajectory ξ (e).Also, we have a controller π trained for the highest-fidelity simulator S q .We aim to test this controller performance against the system specification φ.</p>
<p>For this purpose, we use quantitative semantics to estimate the robustness value of safety specification satisfaction (dissatisfaction) ρ φ (ξ (e)).To falsify the controller, we explore search space for cases that correspond to negative robustness values (ρ φ (ξ (e)) &lt; 0).This can be considered as an optimization problem with the robustness value as the objective function argmin
e ρ φ (ξ (e))(1)
Typically, solving this optimization problem using highfidelity data is costly, but we combine the information from simulators with different levels of fidelity with limited experiments on the highest-fidelity simulator to identify the environment parameters that are likely to be counterexamples.In particular, we use BO to effectively direct the search over the environment and choose which simulator to use.</p>
<p>B. Safety Specification and Quantitative Semantics</p>
<p>A specification φ is defined with respect to system trajectories.We conceptualize φ as the set of all finitehorizon trajectories of the system that meet the systemlevel safety specification.A system trajectory ξ S (e) for an environment parameter e satisfies the specification if and only if ξ S (e) ∈ φ.In fact, φ evaluates a system trajectory to true if ξ S |= φ.The specification is composed of several individual constraints known as predicates.These predicates serve as the fundamental building blocks of the logic, which can be joined together using specific logical operations.We assume that a predicate µ is a smooth function along a system trajectory ξ S (e).We say a predicate is satisfied if µ (ξ S (e)) is greater than 0 or falsified otherwise.The logical operations ¬ (negation), ∧ (conjunction, which means "and"), and ∨ (disjunction, which means "or") are used to combine these predicates.Rather than just checking the Boolean satisfaction of a predicate, the concept of robust or quantitative semantics is defined to quantify the degree of satisfaction.This allows us to move beyond binary notions of "safe" or "unsafe" by associating each predicate with a realvalued function ρ µ (ξ S (e)) of the trajectory ξ S (e), which provides a "measure" of the margin by which µ (e) is met.This robustness value ρ µ (ξ S (e)) is defined such that The quantitative semantics of the predicates are used to establish the quantitative semantics of the safety specification φ using the following rules:
ρ µ&gt;0 := µ (ξ S (e))
(3) ρ ¬µ (ξ S (e)) := −µ (ξ S (e))</p>
<p>(4) ρ φ∧ψ (ξ S (e)) := min (ρ φ (ξ S (e)) , ρ ψ (ξ S (e))) (5) ρ φ∨ψ (ξ S (e)) := max (ρ φ (ξ S (e)) , ρ ψ (ξ S (e))) (6) By evaluating the robustness value for a specific environment parameter ρ φ (ξ S (e)), we can determine whether the system behaves safely in the corresponding e.The sign of ρ φ (ξ S (e)) serves as an indicator of whether the specification φ is satisfied (non-negative value) or not satisfied (negative value).Additionally, robust semantics enables us to establish a hierarchy among failure cases.When ρ φ (ξ S (e 1 )) &lt; ρ φ (ξ S (e 2 )), failure case e 1 is comparatively more severe than e 2 .To simplify the notation, we use ρ φ (e) instead of ρ φ (ξ S (e)) throughout the rest of paper.</p>
<p>C. Bayesian Optimization</p>
<p>There have been several applications of BO for testing learning-based control systems.For black-box systems in general, it is not known in advance how the robustness value ρ φ (e) depends on the environment parameter e.To address this, we use GPs to estimate evaluations of robustness values within the environment parameters based on prior evaluations to aid in the optimization [12].GPs are defined by a mean function m : R n → R and a positive semidefinite covariance kernel function k : R n × R n → R. In this manner, the unknown nonlinear robustness function ρ φ (e) : E → R is represented as random variables, such that any finite number of them follows a multivariate Gaussian distribution.In this paper, the prior mean of the distribution m(e) is set to 0. Search for an optimum in a GP is guided by an acquisition method, such as probability of improvement [37], expected improvement [38], upper confidence bound [39], and entropy search [40].These functions balance between exploring new areas and exploiting promising ones.In areas where the objective function is predicted to be optimal or in areas that have not yet been explored, the acquisition function assigns a higher value.</p>
<p>Entropy search, as an information-theoretic acquisition function, seeks to maximize the expected information gain from observing a subsequent query regarding the optimum, denoted as e * .We represent the nth probability distribution over e * as P n (e * ) and its associated level of uncertainty as its entropy, denoted by H(P n (e * )).Similarly, we can define H(P n (e * | ē, ρφ (ē))) as the entropy of what the (n + 1)th probability distribution over e * would be if we were to observe it at an environment instance represented by ē and obtain a corresponding value of ρφ (ē).This measure of uncertainty depends on the specific observation value ρφ (ē).</p>
<p>Algorithm 1 Multi-Fidelity BO for falsification</p>
<p>Require: simulators S i , relative costs of simulators λ i , i = 1, . . ., q uncertainty space E, policy π, safety specification φ, number of BO iterations n 1: Initialize GP over the nested training inputs from q simulators and corresponding robustness values 2: for t = 1, 2, . . ., n do Execute the scenario on S i for input e * and monitor the resulting trajectory ξ Si</p>
<p>6:</p>
<p>Derive the safety specification robustness value ρ i φ (e * ) across the trajectory 7:</p>
<p>Update GP model with new data 8:
if ρ i φ (e * ) &lt; 0 then 9:
Counterexample e * detected on fidelity i</p>
<p>We can quantify the reduction in uncertainty resulting from making such an observation using
α ES (ē) = H(P n (e * )) − E H P n e * | ρφ (ē)(10)
where E represents the expected value.Maximizing α ES (ē) translates to minimizing the uncertainty in our posterior after incorporating new observations.</p>
<p>III. METHODOLOGY</p>
<p>Full-fidelity simulators for a system of interest offer a variety of settings, the adjustment of which can significantly impact the simulator's fidelity.Starting with a highfidelity simulator, lower-fidelity versions can be developed using techniques such as model order reduction, physical simplification, or data-driven approximations.Model order reduction simplifies the system's equations while preserving key dynamics, physical simplification approximates or ignores certain phenomena to expedite simulations, and datadriven approaches employ surrogate models to replicate highfidelity outputs at reduced computational costs.In this work, we rely on domain expertise to develop low-fidelity simulators customized specifically to our application.Therefore, we consider q simulators with different levels of fidelity for a system of interest specified by S 1 , . . ., S q .Here, S 1 represents the lowest fidelity simulator (the cheapest, fastest, and least accurate one), while S q is the highest fidelity simulator (the most expensive, slowest, and most accurate one).</p>
<p>The relative query costs associated with these simulators, expressed by λ 1 , . . ., λ q , where 1 &lt; λ 1 &lt; . . .&lt; λ q are determined by conducting some specific measurements.For each simulator, we can monitor trajectories and derive robustness values ρ i φ (e) for i ∈ {1, . . ., q}.Our goal is to estimate the black-box function ρ q φ (e) given the observation information across different fidelities.Our first step is to establish a relationship between the robustness values obtained from various simulators.For this purpose, we use multioutput GPs that allow us to model a set of vector-valued outputs (the robustness values) based on a corresponding set of inputs (environment parameters) and represent the outputs as a multivariate normal distribution [41].For using multi-output GPs, we also add a dimension to the input space to represent the fidelity index i ∈ {1, . . ., q}.Doing so, the multi-output GP can be seen as a single-output GP on the extended input space.Let E i be the environment configurations of fidelity i for initializing GP model.To improve computational efficiency [42], we suppose that these initialization input data have a nested structure, i.e., the initialization input data for a simulator with a higher fidelity index is a subset of the input data for a simulator with a lower fidelity index (E q ⊆ E q−1 ⊆ . . .⊆ E 1 ).We assume that there is a linear correlation between the robustness values of different fidelity levels, as it facilitates straightforward integration of data from multiple fidelities.We use the auto-regression model [41] to express the relation between fidelities
ρ i φ (e) = η i ρ i−1 φ (e) + ρ i gap (e)(11)
Here, η i is a constant parameter that transfers knowledge linearly from the lower fidelity level to the higher one, and ρ i gap (e) is the bias term between fidelities, which is an independent GP with its own mean function m i gap and kernel function k i gap (e, e ′ ).We assume ρ i−1 φ (e) and ρ i gap (e) are independent processes linked only by the above equation.In this equation, while the linear term captures the overall trend between fidelity levels, the GP gap term is capable of capturing any residual non-linear relationships.These robustness values take the joint Gaussian distribution of the form
ρ i−1 φ ρ i φ ∼ GP 0 0 , k i−1 η i k i−1 η i k i−1 η 2 i k i−1 + k i gap (12)
The choice of kernel function is problem-dependent and encodes assumptions about smoothness and the rate of change of the robustness values.We use the radial basis function (RBF) kernel for both the error k i gap and lower fidelity simulator indicated by k i−1 .</p>
<p>It is worth noting that considering linear relations between the outputs of different fidelity levels can simplify the computational modeling process but it is often insufficient for complex models.There are versions of multi-fidelity BO that assume nonlinear relationships between fidelities, as mentioned in [43].However, these approaches also have limitations for use in certain contexts.One significant limitation is that these methods require lower-fidelity levels even during prediction to maintain a nested training set, which can be restrictive.Additionally, they often assume that the outputs are noiseless, which is challenging to meet.</p>
<p>Upon constructing the GP model, we use an acquisition function to select both the fidelity index and the environment parameter that leads to the minimum robustness value.We use a modified entropy search acquisition function:
e * , i = argmax e∈E,i∈{1,...,q} α ES i (e)/λ i(13)
Eq. 13 allows us to switch between different fidelity levels to reduce the computational costs of our experiments.Additionally, it performs two exploration and exploitation trade-offs at the same time: one at each fidelity level to search over that specific fidelity, and the other between different fidelity levels to build a more accurate GP model.Algorithm 1 outlines multi-fidelity BO for falsification.The algorithm is designed to model the robustness values using high-accuracy data from simulators with higher fidelity levels, as well as the data richness of simulators with lower fidelity levels.Once the prior GP over these q simulators is obtained, BO is performed iteratively until a stopping criterion is met.On each iteration, the algorithm seeks to find the worst counterexample by maximizing the acquisition function in Eq. 13.Depending on the gap and cost ratios between simulators, the algorithm chooses the candidate environment parameter and fidelity index to run the next experiment.Then, the GP is updated with the new environment instance and its corresponding robustness value on that specific simulator.The algorithm outputs the identified counterexamples and their corresponding fidelity indices.Fig. 1 shows multi-fidelity BO approach applied to falsification.</p>
<p>IV. EXPERIMENTS</p>
<p>In this section, we provide the implementation details and outline the methodology used to measure the cost ratios between different fidelity levels.We then discuss the baselines used for comparison.Finally, we describe our benchmarks.For each of these case studies, we identify the variables that influence the fidelity of simulator.These variables can be of various types: discrete, continuous, or categorical.Once these variables are identified, we explore different combinations of these variables to adjust and control the simulator's fidelity.We develop low-, middle-, and high-fidelity simulators and examine both two-and three-fidelity BO approaches.The source code for our experiments is online. 1</p>
<p>A. Cost Ratios Measurement</p>
<p>Selecting the next fidelity level for evaluation in Eq. 13 depends on the relative costs of simulators.Hence, we avoid allocating pre-determined constant costs to simulators and consider that the cost ratios of the high-fidelity simulator to the other two simulators can be determined by measuring Fig. 2: Fidelity levels in the highway case study.(a) Lowfidelity highway simulator at t = t 0 and t = 12t 0 .(b) High-fidelity highway simulator at t = t 0 and t &gt; 16t 0 .The simulation frequencies in the low-fidelity simulator and the high-fidelity simulator are 11 and 15; respectively.For an identical scenario, the high-fidelity simulator is slower.Additionally, the high-fidelity simulator features more cars on the road.two factors: simulation time and output similarity.Simulation time measures how long it takes for simulators to run a similar experiment, and output similarity quantifies how closely the trajectories of different simulators align.Numerous tests are available to determine the similarity between trajectories of the low-, middle-, and high-fidelity simulators subjected to identical inputs.However, we employ cosine similarity due to its straightforwardness and clarity.Eq. 14 demonstrates the cost ratios between high-, low-, and middle-fidelity simulators:
λ hf λ lf = t hf t lf × s hf lf λ hf λ mf = t hf t mf × s hf mf (14)
where t hf , t mf , and t lf are the time for executing an identical experiment on the high-fidelity, low-fidelity, and middlefidelity simulators.Further, cosine similarities between trajectories of the high-fidelity simulator and trajectories of the low-and middle-fidelity simulators are
s hf lf = ξ hf • ξ lf ∥ξ hf ∥∥ξ lf ∥ s hf mf = ξ hf • ξ mf ∥ξ hf ∥∥ξ mf ∥(15)
To provide more precise cost ratios, we compute the average similarity among ten trajectories for each of our case studies, along with the mean simulation time resulting from ten identical experiments conducted at various fidelity levels.</p>
<p>B. Baselines</p>
<p>We compare the performance of multi-fidelity BO with standard BO across high-, middle-, and low-fidelity simulators.In addition to these individual fidelity levels, we included two other baselines in our analysis: TuRBO-1 and πBO.</p>
<p>1) TuRBO-1: TuRBO-12 is a variant of the TuRBO algorithm [27] that focuses on using a single trust region for optimization.In TuRBO-1, the optimization is performed In our implementation, the trust region size is initialized to L init = 0.75, can expand to a maximum of L max = 1.5, and is reduced down to a minimum of L min = 0.5 7 when necessary.</p>
<p>2) πBO: In πBO [28], expert knowledge is represented as a probability distribution π(e) over the potential location of the optimum.This prior information is used to weight the acquisition function and guide the optimization process towards promising regions.The acquisition function α(e, D n−1 ), where D n−1 = {(e 1 , ρ φ (e 1 )), . . ., (e n−1 , ρ φ (e n−1 ))}, is modified by multiplying it with π(e) β * /n , where β * is a hyperparameter indicating the expert's confidence in the prior knowledge, and n represents the current BO iteration.This is mathematically represented as:
e * ∈ arg max e∈E α(e, D n−1 ) • π(e) β * /n(16)
As more data is collected through iterations, the exponent β * /n becomes smaller, which reduces the impact of the prior π(e) and shifts the focus to the data-driven surrogate model.</p>
<p>For πBO baseline, we consider the falsified points to be located on the edges of uncertainty space [44].Therefore, the prior knowledge of expert is a U-shaped distribution where the edges are weighted more than the inside area.In practical terms, we modeled the prior distribution at each dimension of uncertainty space as a combination of two Gaussian distributions, each centered at the edges.The value of β * is set to 0.7.</p>
<p>The rationale for selecting TuRBO-1 and πBO as baselines in our study is based on their common foundation in BO and their unique strategies for improving optimization performance.TuRBO-1 serves as a baseline to investigate whether we should concentrate on high-fidelity models to enhance optimization or incorporate information from uncertain sources to potentially improve efficiency and reduce computational costs.On the other hand, by contrasting our multi-fidelity method with πBO, we aim to highlight the benefits of using available lower-fidelity models instead of relying solely on expert knowledge, especially in situations where such knowledge may be limited or uncertain.</p>
<p>C. Case Studies</p>
<p>To evaluate our proposed approach, we implemented multi-fidelity BO using Emukit toolkit [45] and conducted experiments on five benchmarks provided by Gym [46].For each case study, we elaborate on safety specifications, system controller, and how different levels of fidelity are developed.For policy training, we used OpenAI baselines3 on the highfidelity simulator.</p>
<p>1) Classic Control-Cart-Pole: The cart-pole environment comprises a cart and a vertical pole attached to the cart using a passive pivot joint.The objective of this task is to keep the vertical pole balanced while the cart moves to the right or left along a frictionless track.The state vector of the The first four uncertainty intervals represent the possible perturbations to the position, velocity, angle, and angular velocity of the system.Following that, the last two intervals are for the mass and length of the pole, respectively.A system's trajectory is a series of states across time, i.e., ξ = (x(t), v(t), θ(t), θ(t)).Given an instance e ∈ E, the trajectory of the system is uniquely defined.</p>
<p>We consider the primary cart-pole offered by Gym as lowfidelity simulator, which has a force magnitude of 10.To create a high-fidelity simulator, we attempt to make the game more difficult and unstable by increasing the force magnitude applied to the pole.We also use a stronger strategy to solve the kinematic equations using the semi-implicit Euler method rather than Euler method for the low-fidelity simulator.The parameters chosen for multi-fidelity experiments are shown in Table I.Moreover, as per our measurements, the cost ratios amount to λ hf /λ mf = 2.71 and λ hf /λ lf = 20.81.We trained a controller for the high-fidelity simulator using proximal policy optimization (PPO) [47].</p>
<p>The controller for this case study must meet certain safety requirements.First, the cart position x should be within the range [−1, 1] (µ 1 ).Second, the absolute momentum of the cart should be less than 1 (µ 2 ).Third, the cart-pole angle should be less than 9 degrees from vertical (µ 3 ).Hence, the specification could be written as:
φ = µ 1 ∧ µ 2 ∧ µ 3 .
2) Classic Control-Lunar Lander: This environment features a lander that must safely descend onto the moon's surface under conditions of low gravity.The primary purpose is to guide the agent to the landing pad as softly and fuel-efficiently as possible.For this environment, there are eight state variables including the coordinates (x, y) of the lander, the horizontal and vertical velocities (v x , v y ), the orientation θ in space, the angular velocity v θ , and two Boolean parameters indicating whether the left or right leg has made contact with the ground.Four possible actions include activating the left orientation engine, activating the right orientation engine, activating the main engine, and taking no action.We consider four sources of uncertainty.The coordinate perturbations are such that δ x ∈ [−0.5, 0.5] and δ y ∈ [0, 3], the velocity perturbations are such that δ vx ∈ [−2, 2] and δ vy ∈ [0, 2].A trajectory of this system could be represented as ξ = (x(t), y(t), v x (t), v y (t), θ(t), θ(t)).</p>
<p>The high-fidelity simulator uses two sources of wind disturbance within the environment.In the middle-fidelity simulator, we replicate one of these disturbances, while the low-fidelity counterpart disregards both disturbances.The low-fidelity simulator includes inaccurate sensors capable of providing measurements up to two decimal points.The detailed distinctions in fidelity levels for the lunar lander case study are presented in Table I.Based on this configuration, the cost ratios are λ hf /λ mf = 2.02 and λ hf /λ lf = 4.53.</p>
<p>We employ the deep deterministic policy gradient (DDPG) algorithm [48] to train a controller for the high-fidelity sim-ulator.A trajectory is safe when it satisfies these conditions: First, the lander must keep its horizontal coordinate (x) within a certain range of the origin (µ 1 ).Second, the lander's tilt angle must not exceed π/4 (µ 2 ), and third, the lander does not spin faster than 0.2 radians per second (µ 3 ).Thus, the safety specification is φ = µ 1 ∧ µ 2 ∧ µ 3 .3) Autonomous Driving-Highway, Merge, and Roundabout Scenarios: To thoroughly evaluate the effectiveness of our approach, we concentrate on three driving scenarios: highway driving, merging, and roundabout navigation.In these scenarios, the state space includes the (x, y) longitudinal and lateral coordinates, as well as longitudinal and lateral velocities (v x , v y ) of both the ego vehicle and the four closest cars.We consider five discrete meta-actions: moving to the left lane, maintaining an idle state, shifting to the right lane, accelerating, and decelerating.The trajectories of these scenarios comprise the coordination of both the ego vehicle and the four nearest cars, represented as ξ = (x ego (t), y ego (t), x ob1 (t), y ob1 (t),</p>
<p>x ob2 (t), y ob2 (t), x ob3 (t), y ob3 (t), x ob4 (t), y ob4 (t)).</p>
<p>For these scenarios, we use deep Q-learning (DQN) [49] for the ego vehicle and both intelligent driver model (IDM) [50] and MOBIL (minimizing overall braking induced by lane change) model [51] for longitudinal and lateral behaviors of other vehicles on the road, respectively.While MOBIL is a lane-changing model that uses safety and incentive criteria-considering the braking of the new and old neighbors, as well as a politeness factor-to determine when a lane change is safe and beneficial, IDM is a parametric carfollowing model that regulates the acceleration of vehicles.In this model, the vehicle's acceleration is described by the following kinematic equation:
vα = a 1 − v α v 0 4 − s * (v α , ∆v α ) s α 2(17)
where the acceleration vα depends on the current speed v α , the gap to the leading vehicle s α , and the relative speed difference ∆v α between the ego vehicle and the vehicle ahead.The deceleration factor is influenced by the ratio of the desired minimum gap s * (v α , ∆v α ) to the actual gap s α , where s * (v α , ∆v α ) = s 0 + vT + v∆v 2 √ ab .Here, s 0 represents the minimum gap in dense traffic, vT is the gap maintained while following the leading vehicle at a constant time gap T , and a and b correspond to the maximum comfortable acceleration and deceleration, respectively.Highway: This environment involves a vehicle on a multilane highway [52].The agent controls speed and lane transitions.The aim is to achieve high speeds without colliding with adjacent vehicles while maintaining a position on the right side of the road.The motion of the ego vehicle is represented using kinematic bicycle model [53].We evaluate nine potential sources of uncertainty, arising from the initial proximity of the ego vehicle to its four nearest neighbors as well as their initial velocities.The initial spacing between the ego vehicle and the four nearest vehicles falls within the range δ x ∈ [20,30].Meanwhile, the ego vehicle's initial velocity is limited to the range v ego ∈ [20,40].Similarly, the initial velocities of other four cars are denoted as v obi ∈ [20,30] for i = 1, . . ., 4. We developed our simulators to have different levels of fidelity.The high-fidelity simulator, with a simulation frequency of 15, is more accurate than the low-and middlefidelity simulators, which operate at frequencies of 11 and 13, respectively.Our low-and middle-fidelity simulators introduce noise into the sensors, limiting the ego vehicle's ability to precisely predict the location and velocity of neighboring vehicles while also maintaining fewer cars on the road, as shown in Fig. 2. Based on these settings, we found the cost ratios to be λ hf /λ mf = 3.75 and λ hf /λ lf = 14.5.Safe trajectories are established by ensuring that an absolute distance of over 0.5 meters is maintained between the ego car and both the leading (front) and following (back) vehicles positioned in the same line.Accidents involving other vehicles on the road, not including the ego vehicle, are not considered unsafe modes.Hence, our safety specification can be written as φ = (|x ego − x obi | − 0.5) for i = 1, . . ., 4. Merge: This scenario simulates a highway merge negotiation task where the ego-vehicle approaches a merge point with vehicles incoming from an access ramp.The agent is rewarded for maintaining high speed, avoiding collisions, and making space for merging vehicles.The agent's goal is to maintain a high speed while safely accommodating other vehicles during the merge.We evaluate nine potential sources of uncertainty, focusing on the initial velocities of the ego vehicle and the four closest cars, within the range [8,12], as well as perturbations on the initial positions of these four nearby vehicles in range [10,12].To develop simulators with varying levels of fidelity for this scenario, we adjust the IDM parameters for the vehicles on the road, including maximum comfortable acceleration and deceleration, to create a more aggressive driving environment.The most aggressive scenario is designated as the high-fidelity simulator, and the controller is trained specifically for this environment.For the low-and middle-fidelity simulators, we modify the parameters to create more conservative scenarios that also include sensor noise.The specific design choices for the fidelity settings are detailed in Table I.Based on these settings, we obtained the cost ratios to be λ hf /λ mf = 1.2 and λ hf /λ lf = 2.6.A trajectory is considered safe if the ego vehicle maintains a minimum distance of 5 meters from the nearest car in the same lane throughout the trajectory.Roundabout: In this task, the ego-vehicle is navigating a roundabout with flowing traffic.While it follows a predetermined route automatically, it must manage lane changes and control its speed to pass the roundabout quickly while avoiding collisions.We evaluate five potential sources of uncertainty, arising from the vehicle length l ∈ [5,7] and perturbations in the initial positions of the four nearest neighbors δ x ∈ [−5, 5].We developed three levels of fidelity by modifying key parameters of the MOBIL model.The lowfidelity level used parameters that promote more conservative driving, such as a higher politeness factor and increased lane-change delays.In contrast, the high-fidelity level em-ployed parameters with quicker lane-change decisions and stricter acceleration and braking constraints.Based on these configurations, we determined the cost ratios to be λ hf / λ mf = 4.6 and λ hf /λ lf = 27.2.The safety requirements for this case study dictate that the differences in both the xcoordinates and y-coordinates between the ego vehicle and other vehicles should not simultaneously fall below certain thresholds.Specifically, the y-coordinate difference should not fall below 4.4 units (µ 1 ) at the same time that the xcoordinate difference drops below 2.1 units (µ 2 ).</p>
<p>V. RESULTS AND DISCUSSION In this section, we evaluate various aspects of multi-fidelity BO on the case studies we discussed previously.To examine the established trade-off between accuracy and cost by multifidelity BO framework, we begin by assessing the accuracy through the reliability of counterexamples suggested by multi-fidelity BO methods and standard BO on the lowand middle-fidelity simulators.We then discuss the costeffectiveness of multi-fidelity BO in comparison to BO on high-fidelity, TurBO-1, and πBO baselines.We run 5 experiments, each consisting of the average results from 150 tests over 200 BO iterations.We validate the counterexamples provided by lower-fidelity simulators in multi-fidelity BO methods and the counterexamples identified by conducting BO on the low-and middle-fidelity simulators.We define the reliability percent as the ratio of real counterexamples to the total number of identified counterexamples.As depicted in Fig. 3, the average reliability percentages for both two-and three-fidelity BO methods on the cart-pole case study are about 26% higher than BO on the low-and middle-fidelity simulators.This improvement for the lunar lander case study is about 30% while for the highway driving environment it is about 12%.More significant results hold in the case of the merge and roundabout scenarios.To this end, using multi-fidelity BO yields more accurate counterexamples compared to using solely lower-fidelity simulators.</p>
<p>Comparing two-fidelity and three-fidelity BO methods, the impact of the middle-fidelity simulator on accuracy becomes evident.In the cart-pole case study, transitioning from a two-fidelity setting to a three-fidelity setting resulted in a 27 reduction in the use of the low-fidelity simulator, with a corresponding increase in the use of the middle-fidelity simulator, as detailed in Table II.Since this simulator provides more reliable counterexamples in comparison to the lowfidelity simulator, three-fidelity BO demonstrates increased reliability compared to two-fidelity BO.The roundabout scenario yields similar but more remarkable results.In the lunar lander case study, despite conducting 30% of the simulations on the middle-fidelity simulator, the transition from a two-fidelity to a three-fidelity setting does not enhance reliability.This lack of improvement is due to the minimal difference between the middle-fidelity and low-fidelity simulators, as also reflected in their similar relative costs.In the highway driving case study, the three-fidelity BO method does not provide more accurate counterexamples.This can have several reasons: First, 2% of accurate simulations on high-fidelity were replaced by inaccurate ones from middlefidelity which results in decreased reliability of three-fidelity BO compared to two-fidelity BO.Second, the accuracy of the multi-fidelity model becomes questionable as the dimension of the uncertainty space increases, similar to the behavior observed in the merge scenario, which further reduces the effectiveness of the three-fidelity approach.In our previous work, we used multi-fidelity BO to solve the falsification problem across various case studies.The results indicated that multi-fidelity BO identified more counterexamples at the same cost compared to high-fidelity BO.Specifically, the results revealed that for the same cost, twofidelity BO detected counterexamples 3.31 and 1.5 times more frequently than high-fidelity BO on the cart-pole and lunar lander, respectively.Our primary criterion was ensuring the algorithm's ability to transition between fidelity levels with pre-determined costs.</p>
<p>The performance of multi-fidelity BO is heavily influenced by the difference between simulators, which affects the cost ratios.This is especially important when selecting the next fidelity level to use.Therefore, we derived these cost ratios based on precise measurements on the simulators.Based on the validated counterexamples, we illustrated the average costs of identifying a single counterexample for standard BO, TuRBO-1, and πBO on the high-fidelity simulator in addition to two-fidelity and three-fidelity BO methods through 200 BO iterations over 5 experiments for the cart-pole, lunar lander, and autonomous driving case studies in Fig. 4-8.</p>
<p>As we expected, multi-fidelity BO consistently outperforms standard BO conducted on high-fidelity in all five case studies.In the cart-pole case study, using three-and twofidelity BO could reduce the cost of falsification up to 49.5% and 32.4% in comparison to BO on the high-fidelity simulator.In the lunar lander environment, we observe 69% and 65% cost reduction, while these percentages for the highway case study are 18% and 26% by three-and twofidelity BO methods, respectively.In the merge case study, the cost reduction percentages achieved with two-and threefidelity BO are 2.7% and 58%.Additionally, three-and twofidelity BO methods in the roundabout case study offer 61% and 70% cost reduction.Hence, given the same cost, multifidelity BO can find more counterexamples compared to the high-fidelity BO.We also can see that the integration of the middle-fidelity and the shift from the two-fidelity setting to three-fidelity can increase the cost per counterexample because some evaluations on the low-fidelity simulator are replaced by more costly experiments on the middle-fidelity simulator, as shown in Table II.Our analysis showed the role of the middle-fidelity in three-fidelity BO cost reduction.</p>
<p>In the three-fidelity setting, if the middle-fidelity simulator is very similar to the low-fidelity simulator and does not provide much new information, the cost of finding a single counterexample is close to the cost of finding a single counterexample with two-fidelity BO, as evident in the lunar lander case study.However, as the middle-fidelity simulator becomes more informative and accurate, the average cost of the three-fidelity BO method approaches that of full-fidelity BO as observed in cart-pole and merge case studies.In the merge case study, the algorithm tends to use higherfidelity simulators more frequently, often disregarding the exploration of low-fidelity simulator, which leads to a greater cost difference compared to the two-fidelity setting.Additionally, in comparison to TuRBO-1 and πBO, multifidelity BO finds lower cost per counterexample in all case studies except for the highway driving case, where TuRBO-1 outperforms three-fidelity BO.This is mainly because TuRBO-1 excels in higher dimensional search spaces, such as in the highway and merge scenarios.In contrast, in the three-fidelity BO for the highway driving case study, the fewest experiments were conducted on the high-fidelity simulator (unlike the merge scenario), which hindered the performance of the three-fidelity BO.</p>
<p>We also depicted number of real detected counterexamples by different methods in Fig. 9.While in the cart-pole, highway, and merge case studies, TuRBO-1 outperforms other methods, in the lunar lander case study πBO provides more counterexamples.Moreover, in all case studies except for lunar lander, high-fidelity BO suggests more counterexamples with respect to multi-fidelity BO methods.In the lunar lander case study, because the gaps between low-and middle-fidelity simulators are not significant from the highfidelity simulator, the counterexamples suggested by multifidelity BO methods are highly reliable, as we mentioned earlier.This results in multi-fidelity methods discovering more counterexamples than standard BO on the high-fidelity simulator for the same number of BO iterations.Conversely, in the cart-pole case study, where the middle-fidelity simulator can provide more reliable counterexamples compared to the low-fidelity simulator, three-fidelity BO detects more counterexamples than the two-fidelity BO method.Moreover, in the highway driving case study, where some high-fidelity experiments were replaced by those on the middle-fidelity simulator, three-fidelity BO identifies fewer counterexamples compared to the two-fidelity BO framework.Limitations: The proposed multi-fidelity BO approach, while promising, does have several limitations.A key challenge lies in accurately estimating the relative computational costs of different simulators.While we did not use arbitrarily chosen costs, inaccuracies in these estimates can negatively impact the optimization process, potentially reducing the effectiveness of our multi-fidelity approach.Additionally, the assumption of a linear relationship between robustness values, which are not continuous functions, while simplifying the computational process, may not be sufficient to capture the complexities of models and influence the efficiency of the framework.Another challenge is the identification and utilization of appropriate lower-fidelity simulators.It can be difficult to ensure that these simulators are sufficiently accurate to guide the optimization process toward global optimum.</p>
<p>VI. CONCLUSIONS</p>
<p>We presented an extended study of multi-fidelity falsification of closed-loop control systems in a simulated environment.Our approach stands out for its ability to considerably cut down on computational cost by intelligently switching between simulators with varying levels of fidelity.To make multi-fidelity BO more robust, we used specific measurements on the simulators to determine the cost proportions of them with different fidelity levels.We demonstrated the effectiveness of our framework by applying it to controllers designed for Gym environments.</p>
<p>One promising future direction is to develop an adaptive strategy for transitioning to high-fidelity simulators to efficiently manage computational resources.This approach would involve using lower-fidelity simulators until they no longer provide significant improvements or cost-efficient insights in the optimization process, and then the algorithm would move to high-fidelity simulations.Another area for future exploration is enhancing the multi-fidelity approach to effectively manage situations where the operational environment or input variables differ across various levels of fidelity.This would use space mapping techniques to correlate the outputs of simulators operating under different conditions, which improves the robustness and applicability of the framework in real-world scenarios.Another direction for future research is the development of a cost-aware multifidelity falsification process.The algorithm can determine the optimal cost structure of the simulators throughout the optimization, offering a mechanism that is self-adjusting, especially if initial cost estimates are inaccurate.</p>
<p>Fig. 1 :
1
Fig. 1: Overview of multi-fidelity BO falsification.The algorithm begins by performing random experiments at different fidelity levels, with fewer experiments conducted at higher fidelity levels.The robustness values across trajectories are recorded, and a GP model is initialized.The algorithm then optimizes entropy search over this model to select a candidate environment parameter e, along with the fidelity index i ∈ {1, . . ., q} at which the next experiment should be performed.The GP model is then updated with the new data.</p>
<p>The kernel function k(e, e ′ ) expresses the covariance between function values ρ φ (e) and ρ φ (e ′ ) at two environment parameters e and e ′ .Suppose that we have a set of n observations: y n = [ρ φ (e 1 ), ρφ (e 2 ), . . ., ρφ (e n )] observed with independent Gaussian noise ω ∼ N(0, σ 2 ) at environment parameters E n = [e 1 , e 2 , . . ., e n ], i.e., ρφ (e) = ρ φ (e) + ω.By treating the outputs as random variables, the posterior distribution of ρ φ (e) is characterized by m n (e) = k n (e)(K n + I n σ 2 ) −1 y n (7) k n (e, e ′ ) = k(e, e ′ ) − k n (e)(K n + I n σ 2 ) −1 k T n (e ′ ) (8) σ 2 n (e) = k n (e, e ′ ) (9) noting that the vector k n (e) = [k(e, e 1 ), . . ., k(e, e n )], σ 2 n (e) is variance, I n is the identity matrix, and K n is the positive definite kernel matrix [k(e, e ′ )] e,e ′ ∈En .</p>
<p>3 :
3
Compute the acquisition function α ES (e) over GP model, as defined by Eq. 10 4: e * , i = argmax e∈E,i∈{1,...,q} α ES i (e) /λ i 5:</p>
<p>Fig. 3 :
3
Fig.3: Average reliability percentage of discovered counterexamples over 750 tests using standard BO on low-and middlefidelity simulators, two-fidelity BO and three-fidelity BO methods for cart-pole, lunar lander, highway, merge, and roundabout case studies.</p>
<p>Fig. 4 :
4
Fig. 4: Comparison between average cost of finding a counterexample through 200 BO iterations on cart-pole case study.</p>
<p>Fig. 5 :
5
Fig. 5: Comparison between average cost of finding a counterexample through 200 BO iterations on lunar lander case study.</p>
<p>Fig. 6 :
6
Fig. 6: Comparison between average cost of finding a counterexample through 200 BO iterations on highway driving environment.</p>
<p>Fig. 7 :
7
Fig. 7: Comparison between average cost of finding a counterexample through 200 BO iterations on merge case study.</p>
<p>Fig. 8 :
8
Fig. 8: Comparison between average cost of discovering a single counterexample through 200 BO iterations on roundabout scenario.</p>
<p>Fig. 9 :
9
Fig.9: Comparison between number of counterexamples discovered by two-and three-fidelity BO methods, standard BO on single fidelities, TuRBO-1, and πBO baselines.</p>
<p>TABLE I :
I
Multi-fidelity settings for case studies
Case StudySettingTypeLow-fidelity Middle-fidelityHigh-fidelityKinematic integratorCategoricalEulerEuler semi-implicit EulerForce magnitudeContinuous101520Cart-PolePosition sensor NoiseContinuousN(0, 0.25)N/AN/ASensors precisionDiscrete2 digits6 digits8 digitsEpisode lengthDiscrete150300450Wind powerContinuous0619.9Lunar LanderTurbulence powerContinuous001.99Episode lengthDiscrete200400800Simulation frequencyDiscrete111315HighwayNumber of road cars Position sensor noiseDiscrete Continuous23 N(0.1, 0.2)24 N(0.1, 0.1)25 N/ASpeed sensor noiseContinuousN(0.5, 0.5)N(0.3, 0.3)N/AMax comfort accelerationContinuous33.54MergeMax comfort decelerationContinuous55.255.5Time gapContinuous1.51.251Max imposed brakingContinuous1.834RoundaboutLane change delayContinuous0.840.820.8PolitenessContinuous0.10.050within a hyperrectangular trust region, which is centeredat the current best solution, denoted by e
* .To balance between exploration and exploitation, the side lengths of this region are adjusted based on the success of previous optimization steps.In fact, the trust region's size L is initially set to L init .It expands or contracts according to the number of consecutive successful or unsuccessful evaluations.Specifically, after τ succ successful evaluations, the region's size is doubled, L ← min(L max , 2L).Conversely, after τ fail unsuccessful evaluations, the size is reduced by half, L ← L/2.If the size L falls below a minimum threshold L min , the trust region is terminated and reinitialized.The acquisition function α(e, D), where D denotes the dataset of observations, guides the selection of new points within the trust region, and the optimization continues until convergence or a predefined budget is reached.The flexibility of TuRBO-1 to change the trust region size helps avoid getting stuck in local optima and increases optimization process efficiency.</p>
<p>TABLE II :
II
Average percentage of executions on high-fidelity, middle-fidelity, and low-fidelity simulators in two-and threefidelity BO settings over 750 tests through 200 BO iterations.</p>
<p>https://github.com/SAILRIT/MFBO Falsification X (a) X (b)
https://github.com/uber-research/TuRBO
https://github.com/openai/baselines
ACKNOWLEDGEMENTSThis research was supported in part by the National Science Foundation (NSF) under Award No. 2132060 and the Federal Aviation Administration (FAA) under Contract No. 692M15-21-T-00022.
Ontology-based scenario generation for automated driving systems verification and validation using rules of the road. A A B Da Costa, P Irvine, X Zhang, S Khastgir, P Jennings, IEEE Transactions on Intelligent Vehicles. 2024</p>
<p>Ontology-based test generation for automated and autonomous driving functions. Y Li, J Tao, F Wotawa, Information and Software Technology. 1172020</p>
<p>Scalable end-to-end autonomous vehicle testing via rare-event simulation. M O'kelly, A Sinha, H Namkoong, R Tedrake, J C Duchi, Advances in Neural Information Processing Systems. 201831</p>
<p>Analyzing real-world accidents for test scenario generation for automated vehicles. E Esenturk, S Khastgir, A Wallace, P Jennings, IEEE Intelligent Vehicles Symposium (IV). 2021</p>
<p>Testing scenario library generation for connected and automated vehicles, part i: Methodology. S Feng, Y Feng, C Yu, Y Zhang, H X Liu, IEEE Transactions on Intelligent Transportation Systems. 2232020</p>
<p>Synthesizing traffic scenarios from formal specifications for testing automated vehicles. M Klischat, M Althoff, IEEE Intelligent Vehicles Symposium (IV). 2020</p>
<p>Robust satisfaction of temporal logic over real-valued signals. A Donzé, O Maler, International Conference on Formal Modeling and Analysis of Timed Systems. 2010</p>
<p>Robustness of temporal logic specifications for continuous-time signals. G E Fainekos, G J Pappas, Theoretical Computer Science. 410422009</p>
<p>Ant colonies for temporal logic falsification of hybrid systems. Y S R Annapureddy, G E Fainekos, Annual Conference on Industrial Electronics Society. 2010</p>
<p>Stochastic local search for falsification of hybrid systems. J Deshmukh, X Jin, J Kapinski, O Maler, International Symposium on Automated Technology for Verification and Analysis. 2015</p>
<p>Temporal logic falsification of cyber-physical systems: An input-signal-space optimization approach. A Aerts, B T Minh, M R Mousavi, M A Reniers, IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW). 2018</p>
<p>Gaussian processes for machine learning. C K Williams, C E Rasmussen, 2006MIT Press</p>
<p>Safe controller optimization for quadrotors with Gaussian processes. F Berkenkamp, A P Schoellig, A Krause, IEEE International Conference on Robotics and Automation (ICRA). 2016</p>
<p>A framework for controlling multi-robot systems using bayesian optimization and linear combination of vectors. S Jacobs, R M Butts, Y Gu, A Baheri, G A Pereira, arXiv:2203.124162022arXiv preprint</p>
<p>Realtime control using Bayesian optimization: A case study in airborne wind energy systems. A Baheri, S Bin-Karim, A Bafandeh, C Vermillion, Control Engineering Practice. 692017</p>
<p>Bayesian optimization for sensor set selection. R Garnett, M A Osborne, S J Roberts, ACM/IEEE International Conference on Information Processing in Sensor Networks. 2010</p>
<p>Iterative 3d layout optimization and parametric trade study for a reconfigurable ocean current turbine array using bayesian optimization. A Baheri, P Ramaprabhu, C Vermillion, Renewable energy. 1272018</p>
<p>A tutorial on Bayesian optimization. P I Frazier, arXiv:1807.028112018arXiv preprint</p>
<p>Testing cyber-physical systems through Bayesian optimization. J Deshmukh, M Horvat, X Jin, R Majumdar, V S Prabhu, ACM Transactions on Embedded Computing Systems (TECS). 165s2017</p>
<p>Identification of test cases for automated driving systems using Bayesian optimization. B Gangopadhyay, S Khastgir, S Dey, P Dasgupta, G Montana, P Jennings, IEEE Intelligent Transportation Systems Conference (ITSC). 2019</p>
<p>Verifying controllers against adversarial examples with Bayesian optimization. S Ghosh, F Berkenkamp, G Ranade, S Qadeer, A Kapoor, IEEE International Conference on Robotics and Automation (ICRA). 2018</p>
<p>Efficient optimizationbased falsification of cyber-physical systems with multiple conjunctive requirements. L Mathesen, G Pedrielli, G Fainekos, IEEE International Conference on Automation Science and Engineering. 2021</p>
<p>Falsification of cyber-physical systems using Bayesian optimization. Z Ramezani, K Šehic, L Nardi, K Åkesson, arXiv:2209.067352022arXiv preprint</p>
<p>BEACON: A Bayesian evolutionary approach for counterexample generation of control systems. J Yancosek, A Baheri, IEEE Access. 2024</p>
<p>Safe learning and optimization techniques: Towards a survey of the state of the art. Y Kim, R Allmendinger, M López-Ibáñez, International Workshop on the Foundations of Trustworthy AI Integrating Learning, Optimization and Reasoning. 2020</p>
<p>Bayesian optimization in a billion dimensions via random embeddings. Z Wang, F Hutter, M Zoghi, D Matheson, N De Feitas, Journal of Artificial Intelligence Research. 552016</p>
<p>Scalable global optimization via local Bayesian optimization. D Eriksson, M Pearce, J Gardner, R D Turner, M Poloczek, Advances in Neural Information Processing Systems. 201932</p>
<p>C Hvarfner, D Stoll, A Souza, M Lindauer, F Hutter, L Nardi, arXiv:2204.11051BO: Augmenting acquisition functions with user beliefs for Bayesian optimization. 2022arXiv preprint</p>
<p>Multifidelity machine-learning with uncertainty quantification and bayesian optimization for materials design: Application to ternary random alloys. A Tran, J Tranchida, T Wildey, A P Thompson, The Journal of Chemical Physics. 15372020</p>
<p>Practical multi-fidelity Bayesian optimization for hyperparameter tuning. J Wu, S Toscano-Palmerin, P I Frazier, A G Wilson, Uncertainty in Artificial Intelligence. 2020PMLR</p>
<p>Multi-fidelity Bayesian optimization strategy applied to overall drone design. R Charayron, T Lefebvre, N Bartoli, J Morlier, AIAA SciTech Forum. 20232366</p>
<p>Safety verification of autonomous systems: A multi-fidelity reinforcement learning approach. J J Beard, A Baheri, arXiv:2203.034512022arXiv preprint</p>
<p>Safety validation of learning-based autonomous systems: A multi-fidelity approach. A Baheri, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337432</p>
<p>Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization. A Marco, F Berkenkamp, P Hennig, IEEE International Conference on Robotics and Automation (ICRA. 2017</p>
<p>Exploring the role of simulator fidelity in the safety validation of learning-enabled autonomous systems. A Baheri, AI Magazine. 4442023</p>
<p>Falsification of learning-based controllers through multi-fidelity Bayesian optimization. Z Shahrooei, M J Kochenderfer, A Baheri, European Control Conference (ECC). 2023</p>
<p>A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. H J Kushner, Journal of Basic Engineering. 8611964</p>
<p>On Bayesian methods for seeking the extremum. J Močkus, Optimization Techniques IFIP Technical Conference. 1975</p>
<p>Gaussian process optimization in the bandit setting: No regret and experimental design. N Srinivas, International Conference on Machine Learning. 2010</p>
<p>Entropy search for informationefficient global optimization. P Hennig, C J Schuler, Journal of Machine Learning Research. 1362012</p>
<p>Predicting the output from a complex computer code when fast approximations are available. M C Kennedy, A O'hagan, Biometrika. 8712000</p>
<p>Recursive co-kriging model for design of computer experiments with multiple levels of fidelity. L , Le Gratiet, J Garnier, International Journal for Uncertainty Quantification. 452014</p>
<p>Nonlinear information fusion algorithms for dataefficient multi-fidelity modelling. P Perdikaris, M Raissi, A Damianou, N D Lawrence, G E Karniadakis, Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences. 47321987512017</p>
<p>Testing cyber-physical systems using a line-search falsification method. Z Ramezani, K Claessen, N Smallbone, M Fabian, K Åkesson, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 4182021</p>
<p>Emukit: A Python toolkit for decision making under uncertainty. A Paleyes, M Mahsereci, N D Lawrence, Python in Science Conference. 2023</p>
<p>OpenAI Gym. G Brockman, V Cheung, L Pettersson, arXiv:1606.015402016arXiv preprint</p>
<p>J Schulman, F Wolski, P Dhariwal, A Radford, O Klimov, arXiv:1707.06347Proximal policy optimization algorithms. 2017arXiv preprint</p>
<p>Continuous control with deep reinforcement learning. T P Lillicrap, J J Hunt, A Pritzel, International Conference on Learning Representations (ICLR). 2016</p>
<p>Human-level control through deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, Nature. 51875402015</p>
<p>Congested traffic states in empirical observations and microscopic simulations. M Treiber, A Hennecke, D Helbing, Physical Review E. 62218052000</p>
<p>General lane-changing model MOBIL for car-following models. A Kesting, M Treiber, D Helbing, Transportation Research Record. 199912007</p>
<p>E Leurent, An Environment for Autonomous Driving Decision-Making. 2018</p>
<p>The kinematic bicycle model: A consistent model for planning feasible trajectories for autonomous vehicles?. P Polack, F Altché, B D'andréa-Novel, A De, La Fortelle, IEEE Intelligent Vehicles Symposium (IV. 2017</p>            </div>
        </div>

    </div>
</body>
</html>