<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3671 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3671</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3671</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-91.html">extraction-schema-91</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-261064777</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2308.11396v2.pdf" target="_blank">Towards an Understanding of Large Language Models in Software Engineering Tasks</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have drawn widespread attention and research due to their astounding performance in tasks such as text generation and reasoning. Derivative products, like ChatGPT, have been extensively deployed and highly sought after. Meanwhile, the evaluation and optimization of LLMs in software engineering tasks, such as code generation, have become a research focus. However, there is still a lack of systematic research on the application and evaluation of LLMs in the field of software engineering. Therefore, this paper is the first to comprehensively investigate and collate the research and products combining LLMs with</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3671.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3671.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CollabCoder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collabcoder: A GPT-powered workflow for collaborative qualitative analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system (paper) that proposes a GPT-powered workflow to support collaborative qualitative analysis; mentioned in this survey as an example of LLMs applied to qualitative data analysis and collaborative synthesis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Collabcoder: A gpt-powered workflow for collaborative qualitative analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>CollabCoder</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>Described in the surveyed paper only by title as a GPT-powered workflow to assist collaborative qualitative analysis; the survey does not provide implementation details, but positions it as an example of using LLMs to help synthesize and code qualitative data.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in this survey; original paper title implies qualitative datasets (e.g., interview transcripts, open-ended responses or documents) but the survey provides no corpus size, sources, or language details.</td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td>Not specified in this survey; likely driven by natural-language prompts or codebook-driven instructions to the LLM according to the title, but the surveyed article gives no concrete prompt format.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Not specified in this survey; the paper is only cited by title. The title implies use of GPT prompting/in-context learning for coding/synthesis, but no algorithmic details are given in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td>Not specified in this survey; expected outputs (from title) would be coded qualitative categories, summaries, or synthesized themes, but the survey does not list exact output formats.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td>Not specified in this survey; the survey only cites the work and does not report evaluation procedure or metrics used by CollabCoder.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Not provided in this survey; no quantitative or qualitative outcomes from CollabCoder are reported in the surveyed paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not discussed in this survey for this specific work; the survey does note general LLM limitations in other contexts (hallucination, robustness) but does not tie them specifically to CollabCoder.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td>Not provided in this survey; no comparison details are reported for CollabCoder.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards an Understanding of Large Language Models in Software Engineering Tasks', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3671.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3671.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-assisted Deductive Coding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced study that examines combining a pre-specified codebook with GPT-3 to perform deductive qualitative coding; cited in this survey as an instance of LLMs supporting qualitative synthesis and coding workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Codebook+GPT-3 deductive-coding pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>Mentioned in the survey as a work that combines an explicit codebook and GPT-3 to perform deductive coding of qualitative materials; the survey lists it among LLM-assisted qualitative-analysis works but does not give procedural details.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in this survey; implied to be qualitative textual data (e.g., interview transcripts, open responses), but the survey does not report corpus size, domains, or languages used by the original study.</td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td>Not specified in this survey; the method name implies structured guidance via a codebook plus prompts to GPT-3, but the survey does not give prompt templates or query interfaces.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Not specified in this survey; likely prompt-based instruction to GPT-3 informed by a codebook (i.e., structured prompting/deductive mapping), but the surveyed paper does not supply algorithmic or chaining details.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td>Not specified in this survey; expected outputs are coded labels/annotations and possibly higher-level summaries or thematic syntheses, but the survey does not enumerate output formats.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td>Not specified in this survey; the survey does not report how the original study validated coding quality (e.g., inter-annotator agreement, human review), only cites the work as an example.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Not provided in this survey; no performance metrics or qualitative findings from the original deductive-coding study are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Not discussed in this survey for the specific study; the survey generally highlights LLM issues (lack of robustness, hallucination) elsewhere but does not attribute them to this particular work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td>Not provided in this survey; the surveyed paper does not report whether the referenced study compared LLM-assisted coding to human coders or baseline automated methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards an Understanding of Large Language Models in Software Engineering Tasks', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Collabcoder: A gpt-powered workflow for collaborative qualitative analysis <em>(Rating: 2)</em></li>
                <li>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding <em>(Rating: 2)</em></li>
                <li>CollabCoder: A gpt-powered workflow for collaborative qualitative analysis <em>(Rating: 1)</em></li>
                <li>A bibliometric review of large language models research from 2017 to 2023 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3671",
    "paper_id": "paper-261064777",
    "extraction_schema_id": "extraction-schema-91",
    "extracted_data": [
        {
            "name_short": "CollabCoder",
            "name_full": "Collabcoder: A GPT-powered workflow for collaborative qualitative analysis",
            "brief_description": "A referenced system (paper) that proposes a GPT-powered workflow to support collaborative qualitative analysis; mentioned in this survey as an example of LLMs applied to qualitative data analysis and collaborative synthesis tasks.",
            "citation_title": "Collabcoder: A gpt-powered workflow for collaborative qualitative analysis",
            "mention_or_use": "mention",
            "system_or_method_name": "CollabCoder",
            "system_or_method_description": "Described in the surveyed paper only by title as a GPT-powered workflow to assist collaborative qualitative analysis; the survey does not provide implementation details, but positions it as an example of using LLMs to help synthesize and code qualitative data.",
            "input_corpus_description": "Not specified in this survey; original paper title implies qualitative datasets (e.g., interview transcripts, open-ended responses or documents) but the survey provides no corpus size, sources, or language details.",
            "topic_or_query_specification": "Not specified in this survey; likely driven by natural-language prompts or codebook-driven instructions to the LLM according to the title, but the surveyed article gives no concrete prompt format.",
            "distillation_method": "Not specified in this survey; the paper is only cited by title. The title implies use of GPT prompting/in-context learning for coding/synthesis, but no algorithmic details are given in the survey.",
            "output_type_and_format": "Not specified in this survey; expected outputs (from title) would be coded qualitative categories, summaries, or synthesized themes, but the survey does not list exact output formats.",
            "evaluation_or_validation_method": "Not specified in this survey; the survey only cites the work and does not report evaluation procedure or metrics used by CollabCoder.",
            "results_summary": "Not provided in this survey; no quantitative or qualitative outcomes from CollabCoder are reported in the surveyed paper.",
            "limitations_or_challenges": "Not discussed in this survey for this specific work; the survey does note general LLM limitations in other contexts (hallucination, robustness) but does not tie them specifically to CollabCoder.",
            "comparison_to_baselines_or_humans": "Not provided in this survey; no comparison details are reported for CollabCoder.",
            "uuid": "e3671.0",
            "source_info": {
                "paper_title": "Towards an Understanding of Large Language Models in Software Engineering Tasks",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LLM-assisted Deductive Coding",
            "name_full": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "brief_description": "A referenced study that examines combining a pre-specified codebook with GPT-3 to perform deductive qualitative coding; cited in this survey as an instance of LLMs supporting qualitative synthesis and coding workflows.",
            "citation_title": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "mention_or_use": "mention",
            "system_or_method_name": "Codebook+GPT-3 deductive-coding pipeline",
            "system_or_method_description": "Mentioned in the survey as a work that combines an explicit codebook and GPT-3 to perform deductive coding of qualitative materials; the survey lists it among LLM-assisted qualitative-analysis works but does not give procedural details.",
            "input_corpus_description": "Not specified in this survey; implied to be qualitative textual data (e.g., interview transcripts, open responses), but the survey does not report corpus size, domains, or languages used by the original study.",
            "topic_or_query_specification": "Not specified in this survey; the method name implies structured guidance via a codebook plus prompts to GPT-3, but the survey does not give prompt templates or query interfaces.",
            "distillation_method": "Not specified in this survey; likely prompt-based instruction to GPT-3 informed by a codebook (i.e., structured prompting/deductive mapping), but the surveyed paper does not supply algorithmic or chaining details.",
            "output_type_and_format": "Not specified in this survey; expected outputs are coded labels/annotations and possibly higher-level summaries or thematic syntheses, but the survey does not enumerate output formats.",
            "evaluation_or_validation_method": "Not specified in this survey; the survey does not report how the original study validated coding quality (e.g., inter-annotator agreement, human review), only cites the work as an example.",
            "results_summary": "Not provided in this survey; no performance metrics or qualitative findings from the original deductive-coding study are reported here.",
            "limitations_or_challenges": "Not discussed in this survey for the specific study; the survey generally highlights LLM issues (lack of robustness, hallucination) elsewhere but does not attribute them to this particular work.",
            "comparison_to_baselines_or_humans": "Not provided in this survey; the surveyed paper does not report whether the referenced study compared LLM-assisted coding to human coders or baseline automated methods.",
            "uuid": "e3671.1",
            "source_info": {
                "paper_title": "Towards an Understanding of Large Language Models in Software Engineering Tasks",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Collabcoder: A gpt-powered workflow for collaborative qualitative analysis",
            "rating": 2,
            "sanitized_title": "collabcoder_a_gptpowered_workflow_for_collaborative_qualitative_analysis"
        },
        {
            "paper_title": "Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding",
            "rating": 2,
            "sanitized_title": "supporting_qualitative_analysis_with_large_language_models_combining_codebook_with_gpt3_for_deductive_coding"
        },
        {
            "paper_title": "CollabCoder: A gpt-powered workflow for collaborative qualitative analysis",
            "rating": 1,
            "sanitized_title": "collabcoder_a_gptpowered_workflow_for_collaborative_qualitative_analysis"
        },
        {
            "paper_title": "A bibliometric review of large language models research from 2017 to 2023",
            "rating": 1,
            "sanitized_title": "a_bibliometric_review_of_large_language_models_research_from_2017_to_2023"
        }
    ],
    "cost": 0.0158405,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Towards an Understanding of Large Language Models in Software Engineering Tasks
29 Sep 2024</p>
<p>Zibin Zheng 
Kaiwen Ning ningkw@mail2.sysu.edu.cn 
Qingyuan Zhong 
Jiachi Chen 
Wenqing Chen 
Lianghong Guo 
Weicheng Wang 
Yanlin Wang </p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>Pengcheng Laboratory
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>School of Software Engineering
Sun Yat-sen University
China</p>
<p>Towards an Understanding of Large Language Models in Software Engineering Tasks
29 Sep 2024358C0B4C81917139740E71C54BB9094CarXiv:2308.11396v2[cs.SE]Received: date / Accepted: dateEmpirical StudyLiterature ReviewLarge Language ModelsSoftware Engineering
Large Language Models (LLMs) have drawn widespread attention and research due to their astounding performance in text generation and reasoning tasks.Derivative products, like ChatGPT, have been extensively deployed and highly sought after.Meanwhile, the evaluation and optimization of LLMs in software engineering tasks, such as code generation, have become</p>
<p>Introduction</p>
<p>Large language models(LLMs) refer to neural network language models trained on massive text data, with model sizes reaching hundreds of billions or more parameters (Zhao et al., 2023b).The most advanced LLMs to date, such as GPT-4 (Liu et al., 2023e;Savelka et al., 2023) and LaMDA (Thoppilan et al., 2022), have demonstrated remarkable language comprehension and generation capabilities, able to perform well on a variety of natural language processing tasks, such as text summarization (Tang et al., 2023a).The derivative products and applications of LLMs, such as ChatGPT (Gozalo-Brizuela and Garrido-Merchan, 2023) and Claude (tse Huang et al., 2023), have also gained widespread attention in both academic and industrial communities.Given the outstanding performance of LLMs, there is a growing focus on exploring their potential in software engineering tasks, seeking new opportunities to address challenges in the field of software engineering (Zan et al., 2023).</p>
<p>The primary objective of software engineering is to develop highquality and easily maintainable software products (Kotti et al., 2023).This process involves multiple stages, including requirement analysis, design, development, testing, and maintenance (Hoffmann et al., 2023).Throughout this process, engineers need to handle various software engineering tasks, such as understanding complex requirements, writing correct and reliable code, constructing comprehensive test cases, etc.In general, these software engineering tasks often rely on the expertise and experience of software engineers.This dependence not only incurs significant human resource costs, but also increases the difficulty of software development and maintenance.Additionally, with the increasing complexity of user demands and the emergence of new types of applications, engineers also face additional challenges when dealing with software engineering tasks, such as collaborative development, enhancing software quality, and shortening development cycles (Ferrario and Winter, 2023).</p>
<p>Therefore, researching how to enhance the level of automation in software engineering tasks to achieve more efficient software production and maintenance is a critical and widely discussed topic.Currently, numerous efforts are devoted to developing relevant tools and algorithms to assist engineers in completing these software engineering tasks.For instance, automated code generation (Feng et al., 2021), automatic test case generation (Wang et al., 2022a), and vulnerability detection (Liu et al., 2023g) are some of the areas of focus.However, these individual automation methods often face challenges when applied universally (Wang et al., 2023f), and some existing automated solutions may introduce new issues or errors.For example, automatically generated code may contain potential vulnerabilities (Thakur et al., 2023a), automatically generated test cases often fail to achieve comprehensive coverage (Lemieux et al., 2023), etc.</p>
<p>Fortunately, LLMs have great potential to solve the above problems due to their excellent performance on complex tasks such as text generation.LLMs usually need to be trained on a large-scale corpus containing a code base with multiple segments (Wei et al., 2022).This allows it to better learn the code syntax and semantics, and has the potential to be better equipped for tasks such as code completion and code summarization (Wang et al., 2023e).Currently, as more and more LLMs designed for software engineering tasks are deployed (Huaggingface, 2021;Nijkamp et al., 2023;Zheng et al., 2023;Wang et al., 2021;Li et al., 2022c;Chai et al., 2022;Wang et al., 2023e), many research works focused on the application of LLMs in the software engineering domain (Ahmad et al., 2023a;Zhang et al., 2023b;Li et al., 2023a;Barke et al., 2023a;Zhuo et al., 2023;Gozalo-Brizuela and Garrido-Merchan, 2023).The ability of LLMs such as generate high-quality code and high-coverage test cases has become a hot topic in the software engineering domain (Zan et al., 2023).However, in the existing literature, adequate systematic reviews and surveys have been conducted on LLMs applications in areas such as education (Leinonen et al., 2023b), but a systematic review of the application and evaluation of LLMs in the field of software engineering is still missing.</p>
<p>In this study, our goal is to conduct a comprehensive review of the intersecting theme of LLMs and software engineering.To facilitate this, we initially gathered as much relevant literature as possible from six major academic databases, namely ACM Digital Library1 , IEEE Xplore Digital Library2 , dblp3 , Elsevier Science Direct4 , Google Scholar5 , and arXiv6 .Through the method of card sorting (Reese et al., 2018), we have eliminated duplicate and irrelevant literature.We focuses on papers published after 2022 because the definition and scale of "Large" in LLMs have evolved, making earlier literature potentially outdated.According to the collected papers we define transformer based language models with a parameter count greater than or equal to 0.8 billion (0.8b) as Large Language Models (LLMs).After the screening process, we have obtained 123 relevant and valid research papers.With this study, we aim to address the following two questions: RQ1: What are the current works focusing on combining LLMs and software engineering?</p>
<p>To answer these questions, we categorized the 123 selected papers according to the software engineering tasks involved.Based on the specific content of the software engineering tasks, such as code generation and vulnerability detection, we divided them into seven categories.They are Code Generation, Code Summarization, Code translation, Vulnerability Detection, Code Evaluation, Code Management and Q&amp;A Interaction.For each category, we elaborate on their definitions and examples, which can help researchers continue to discover and solve potential issues when applying LLMs to software engineering tasks.RQ2: Can LLMs truly help better perform current software engineering tasks?</p>
<p>While LLMs have demonstrated outstanding performance in text generation tasks, their performance in software engineering tasks like code generation requires further validation.To address this issue, we conducted a selection of literature containing evaluations related to LLMs.Considering that the selected LLMs and software engineering tasks in these works may vary, we also organized and compiled this information during the screening process.Our findings indicate that currently, LLMs excel in tasks that demand an understanding of syntax, such as code summarization and code repair.However, their performance tends to be less satisfactory in tasks that require comprehension of code semantics, such as code generation and vulnerability detection.Nevertheless, we also observed that LLMs continue to make strides with each version and model iteration, indicating they still possess the potential to achieve better performance in the future.</p>
<p>The main contributions of this paper are:</p>
<p>• We systematically reviewed the state-of-the-art work in the intersection of software engineering and LLM, a highly discussed topic.We manually selected 123 relevant works from many articles in six databases and conducted detailed organization and categorization.(Open source, https : //github.com/KevinHeiwa/LLM− SE − Paper − List);</p>
<p>• We categorized these tasks manually into seven types based on different software engineering tasks.For each category, we provided application examples of LLM and delved into detailed explanations.This can assist researchers in better identifying and addressing potential challenges when applying LLM to software engineering tasks;</p>
<p>• We have comprehensively collected and compiled the performance of LLM in various software engineering tasks.We have provided an exposition and analysis of LLM's performance in these software engineering tasks, as well as the reasons for variations observed among different studies.This can assist developers in optimizing LLM more effectively.</p>
<p>The organization of this paper is as follows.In Section 2, we provide background knowledge on LLMs; In Section 4, we summarize and categorize the collected literature and propose an answer to research question 1 (RQ1); In Section 5, we address research question 2 (RQ2); In Section 6, we compiled the performance of different LLMs across various benchmarks and literature to address research question 3 (RQ3); Finally, in Section 8, we summarize the entire paper.</p>
<p>Background</p>
<p>In this section, we will introduce the background of large language models, including the transformer model, the architecture of large language models, and their emergent capabilities.</p>
<p>Transformer</p>
<p>Currently, the mainstream large language models are based on the Transformer (Vaswani et al., 2017) model, such as GPT-3 (Brown et al., 2020) and PaLM (Chowdhery et al., 2022).Compared to traditional deep learning model structures like recurrent neural networks (RNNs) and convolutional neural networks (CNNs), the Transformer model relies on a attention mechanism, allowing for parallel computation and more effective capture of long-range dependencies.This provides a foundation for effectively training large language models on large-scale text data.</p>
<p>The Transformer model first introduced by Vaswani et al (Vaswani et al., 2017) in 2017, is a sequence-to-sequence model consisting of an encoder and a decoder.Both the encoder and decoder are composed of multiple identical blocks stacked together.Each block in the encoder primarily includes a multihead self-attention module and a position-wise feed-forward network (FFN), with residual connections (He et al., 2016) and layer normalization (Ba et al., 2016) applied to enable deeper model building.(Lin et al., 2022a) In the decoder, cross-attention modules are inserted between the multi-head selfattention modules and the position-wise FFNs, allowing for the incorporation of information from the encoder.Notably, the self-attention modules in the decoder are modified to prevent attending to subsequent positions.</p>
<p>The core component of the Transformer is the attention mechanism, which allows the model to weigh the importance of different words or tokens in a sequence when generating or understanding the context.By attending to relevant parts of the input sequence, the Transformer model can effectively model the relationships between words and capture rich contextual information.Additionally, the attention mechanism does not involve sequential operations, enabling parallel computation and resulting in higher efficiency during training and inference in the Transformer model.</p>
<p>Model Architecture</p>
<p>The Transformer architecture, proposed by Vaswani et al. in 2017(Vaswani et al., 2017), has emerged as the leading choice for developing large language models (LLMs) due to its exceptional parallelizability and capacity (Zhao et al., 2023b).This scalability allows language models to be expanded to include hundreds or even thousands of billions of parameters, enabling them to capture more complex language patterns and improve performance on various tasks.In general, large language models can be categorized into three main architecture types: encoder-decoder structures, causal-decoder, and prefix decoder (Zhao et al., 2023b), each with its own characteristics and applications.</p>
<p>Encoder-decoder Architecture: The vanilla Transformer proposed in (Vaswani et al., 2017) is based on encoder-decoder architecture, which comprises separate encoder and decoder components.The encoder processes the input sequence and captures its latent representation, which is then used by the decoder to generate the output sequence autoregressively.This architecture is well-suited for tasks involving sequence-to-sequence mapping, such as machine translation, text summarization, and dialogue generation.Encoder-decoder pretrained model.Encoder-decoder pretrained models, such as BART (Lewis et al., 2019) and T5 (Raffel et al., 2020), have demonstrated excellent performance across various downstream tasks.However, with the development of LLM there are only a few large language models based on the encoder-decoder architecture, such as Flan-T5 (Chung et al., 2022) and CodeT5+ (Wang et al., 2023f).</p>
<p>Causal Decoder Architecture: The causal decoder architecture is commonly implemented as a stack of decoder layers.It utilizes a diagonal mask matrix, allowing each token to only have access to information from preceding tokens.This constraint ensures a unidirectional and autoregressive generation process.The GPT series model, initially introduced by OpenAI (Radford et al., 2018(Radford et al., , 2019;;Brown et al., 2020), represents one of the most prominent examples of the causal decoder architecture.While GPT (Radford et al., 2018) and GPT-2 (Radford et al., 2018) did not exhibit the same level of performance as GPT-3 (Brown et al., 2020), with the increase in model size and the amount of data used for pretraining, GPT-3 (Brown et al., 2020) showcased a remarkable few-shot capability that earlier models did not possess.Today, the causal decoder architecture has become the prevailing choice for large language model architectures, giving rise to a wide range of powerful LLMs such as PaLM (Chowdhery et al., 2022), LLaMA (Touvron et al., 2023), OPT (Zhang et al., 2022c), Bloom (Scao et al., 2022).The causal decoder architecture and the prefix decoder architecture, which will be discussed next, are collectively referred to as decoder-only architecture (Zhao et al., 2023b).</p>
<p>Prefix Decoder Architecture: The prefix decoder, similar to the causal decoder architecture, consists of decoder layers.However, the key distinction is in their attention mechanism.The prefix decoder utilizes bidirectional attention for the prefix tokens, incorporating information from both preceding and succeeding tokens.In contrast, unidirectional attention is applied only to the generated tokens, ensuring a unidirectional flow of information during the generation process.This combination of attention mechanisms in the prefix decoder enables flexible and controlled generation, conditioned on both the prefix and the generated tokens.Some commonly known models based on the prefix decoder architecture include U-PaLM (Tay et al., 2022) and GLM-130B (Zeng et al., 2022a).</p>
<p>Emergent Abilities</p>
<p>According to the scaling law of large language models (Kaplan et al., 2020), as the model parameters and training data increase, the model's capacity and capabilities also improve.When scaling surpasses a certain threshold, LLMs demonstrate emergent abilities that are not present in smaller models (Wei et al., 2022).These emergent abilities are considered the most notable characteristic that sets large models apart from their smaller counterparts.Such as in-context learning (Brown et al., 2020), instruction following (Sanh et al., 2021;Ouyang et al., 2022;Wei et al., 2021), and stepby-step reasoning (Shanahan, 2022).</p>
<p>Methodology</p>
<p>In this section, we introduce the detailed steps of conducting a literature review.We follow the method provided by (Kitchenham, 2007;Watson et al., 2022) for the literature review.Generally speaking, it consists of three steps: literature search, literature screening, and data analysis.As shown in Fig. 1.</p>
<p>Literature Search</p>
<p>Based on the previous literature review (Chen et al., 2021), we have selected six search engines: ACM Digital Library, IEEE Xplore Digital Library, dblp, Elsevier Science Direct, Google Scholar, and arXiv.These search engines allow us to find peer-reviewed research papers published in journals, conferences, workshops, and symposiums.Additionally, they provide access to a considerable number of preprint papers and the latest industry developments.</p>
<p>We conducted searches using the following six keywords: "SE LLM," "Software Engineering Large Language Model," "Software Engineering LLM," "SE Large Language Model," "Code LLM," and "Code Large Language Model" on the aforementioned six paper databases.The obtained results are presented in Table 1.It is worth noting that there might be a significant   number of duplicate papers and irrelevant articles resulting from different keyword searches within the same engine or the same keyword across different engines.Therefore, we need to manually screen and select these papers, which is known as literature screening or literature selection.</p>
<p>Literature Selection</p>
<p>During this stage, we need to eliminate not only duplicate papers but also irrelevant ones.For instance, some papers may primarily focus on LLM or the field of software engineering but do not mention LLM or "Large Language Model" in their abstracts.Additionally, since the definition of "Large" in LLM is subject to change, some earlier literature might have been considered LLM at the time but may not meet the criteria from perspective today (Zhao et al., 2023b;Lin et al., 2022a;Zan et al., 2023;Meade et al., 2022;Li et al., 2022a;Wang et al., 2023a).Therefore, we have excluded research conducted before 2022.We applied the following seven exclusion criteria to screen the literature: Exclusion Criteria</p>
<p>• Studies are not written in English.</p>
<p>• Master or Ph.D. theses.</p>
<p>• Keynote papers.</p>
<p>• Studies not related to LLM.</p>
<p>• Studies not related to software engineering.</p>
<p>• Duplicate literature.</p>
<p>• Studies up to 2022 (not including 2022).</p>
<p>To demonstrate the rationale behind excluding works before 2022, we collected and organized some of the important articles on language models (LMs) published in top software engineering conferences, namely ICSE, ISSTA, FSE, and ASE, between 2017 and 2022.The results are presented in Table 2, where we found a total of 19 relevant articles.</p>
<p>From Table 2, we can observe the following: Firstly, although the Transformer architecture was introduced in 2017, the application of Transformer-based pre-trained language models (PLMs) in SE tasks began around 2021.Secondly, previous articles primarily focused on "pre-trained language models" rather than LLMs.These two concepts have distinct differences.Lastly, LLMs started receiving attention and gradually being applied to software engineering tasks around 2022.</p>
<p>Furthermore, we can see that the research emphasis on PLMs and LLMs in SE tasks is quite different.For example, in Table 3, we can observe that code generation tasks are an important topic in LLM research but are rarely mentioned in studies conducted before 2022.This is due to the fact that the popular PLM architecture before 2022 was Encoder-Decoder, which significantly differs from the decoder-only architecture commonly used in current LLMs.This is the reason why we focus only on works after 2022.</p>
<p>In this study, we are specifically focused on the intersection of LLM and software engineering.Therefore, we will exclude papers that solely focus on LLM or software engineering.We are interested in the following topics:</p>
<p>Inclusion Topics</p>
<p>• LLM in Software Engineering.</p>
<p>• Application of LLM in Software Engineering (for example, code generation).</p>
<p>Table 2 Articles about pre-trained language models between 2017 and 2022 in top software engineering conferences.To improve the accuracy of the literature screening process, we will use the card sorting method to evaluate the collected data.Card sorting is a common technique used to assess data and derive categories from it.There are three types of card sorting methods: open card sorting, closed card sorting, and hybrid card sorting.Among these three types, closed card sorting involves predefined categories (Kitchenham, 2007).In our case, we applied closed card sorting to select relevant papers since we have only two categories: relevant and irrelevant.Each card will have a title (paper title) and a description (paper abstract).By using this method, we can systematically evaluated and categorized the papers based on their relevance to our research.</p>
<p>ISSTA ICSE ASE FSE</p>
<p>Six experienced researchers, including one non-coauthors, independently conducted a thorough review of the search engine results from the six databases.After individually organizing the papers, they engaged in a collaborative discussion to align their findings.Through this rigorous process, we ultimately identified 123 relevant papers that met the criteria for inclusion in our study.</p>
<p>Data Analysis</p>
<p>The definition of "large" in LLM changes over time.For this reason, we have filtered out work that does not meet the definition of LLM in (Zhao et al., 2023b) and ensured that all such work will be made public after 2022.We used open card sorting to help find the answers to these two RQs.We read the article carefully and looked closely for answers to the same two questions shown in Table 4, i.e.,(1).What are the current works focusing on combining LLMs and software engineering?(2).Can LLMs truly help to better execute current software engineering tasks?If we cannot find any answers from a paper, then that paper will be removed from our list.</p>
<p>For the answers to (1), we primarily examined whether the papers mentioned the application of LLM in software engineering tasks.We organized this information and categorized the literature based on the types of tasks.The To validate our classification, we organized the research papers from ICSE 20247 , a highly recognized conference in the field of software engineering, as shown in Table 3.We can observe that there were a total of 40 papers related to LLM in ICSE 2024, which can be categorized into the seven classes mentioned in our article.This indicates that the software engineering tasks we selected are currently the most prominent in LLM and SE research and encompass a significant portion of software engineering tasks.Furthermore, concerning benchmarking, datasets, and similar work, we do not categorize them as software engineering tasks.Instead, we classify them based on their research targets.For example, a benchmark for code generation would still fall under the code generation task.The definitions of different tasks are provided in Table 5.</p>
<p>We can see that this is a relatively large number of Code Generationoriented studies with 24 papers; conversely, Code translation-oriented is the least, with 3 papers.The number of papers in remaining 6 software engineering tasks are similar, with the least being Code Managenment-oriented work, with 6 papers.And Vulnerability Detection oriented tasks are the most with 17 papers.The specifics of these tasks are presented in 4.</p>
<p>For the answers to (2), we focused on reading whether the papers provided critical or explicit opinions on the performance of LLM in software engineering.Particularly, we examined instance studies and survey articles in this regard.</p>
<p>RQs</p>
<p>Type of Data We Collected</p>
<p>RQ1</p>
<p>What are the current works focusing on combining LLMs and software engineering?Such as code summarization, code translation, code generation, interaction with software developers, etc.</p>
<p>RQ2</p>
<p>Can LLMs truly help to better execute current software engineering tasks?Such as performance status, defects, potential, completion, deficiencies, etc.</p>
<p>LLMs in Software Engineering Tasks</p>
<p>In this section, we primarily respond to RQ1.We categorize the collected work into seven categories based on different tasks, and then provide separate explanations for each category, as shown in Table 5.</p>
<p>In this article, we consider transformer based language models with a parameter count greater than or equal to 0.8 billion (0.8b) as Large Language Models (LLMs).We arrived at this definition based on our investigation of the majority of open-source LLM papers from ICSE 2024, as shown in Table 6.We can see that, except for OpenAI's models, which are not open-source, we cannot determine their parameter counts.Among the open-source models, the one with the smallest parameter count is Flan-T5-small, with 80 million (80M) parameters.Therefore, we have defined LLM based on this model as the standard.Among the peer-reviewed articles we investigated, the smallest parameter count used for LLM was 80M ( (Ma et al., 2024a), Flan-T5-small).</p>
<p>Code Generation</p>
<p>Definition: Code generation, also known as program synthesis, is the process of automatically generating source code based on user requirements and specified constraints (Chen et al., 2023a).In most cases, it involves transforming text into code.When applying LLM for code generation, LLM will automatically generate code based on the requirements provided by the user.It should be noted that code completion, code refactoring, and code augmentation also fall under the category of code generation tasks.Traditional code generation typically involves two steps: first, parsing the user's requirements and constraints and converting them into an intermediate representation, such as an abstract syntax tree (AST) (Hu et al., 2023b) or intermediate representation (IR) (Li et al., 2022d); then, generating the target code based on this intermediate representation.The first step is requirement understanding, which involves transforming natural language into a formal, computer-understandable representation; the second step is code synthesis, which involves generating code based on this representation (Jiang et al., 2023a).</p>
<p>Code generation heavily relies on search and inference, systematically searching and reasoning to find code that satisfies the given requirements within the entire code space (Zheng et al., 2023).LLMs has demonstrated impressive capabilities in text generation tasks, attracting significant research efforts to evaluate and improve the performance of LLM in code generation tasks (Li et al., 2023b).</p>
<p>These research efforts can be roughly categorized into two main themes.The first theme mainly evaluates or discusses the capabilities of LLMs in code generation tasks or specific contexts of code generation (Houde et al., 2022;Sarsa et al., 2022;Buscemi, 2023a,b).The evaluation perspectives vary, with some focusing on the correctness of code generation in different programming languages (Bareiß et al., 2022;Thakur et al., 2023a;Kande et al., 2023), while others propose new benchmark frameworks or testing methods to better evaluate the code generated by LLMs (Liu et al., 2023b;Vaithilingam et al., 2022), providing directions for improving LLMs in this task.</p>
<p>However, it is important to note that no current technology, including LLMs, can guarantee that automatically generated code is always completely usable, as there may be obvious or subtle errors in the code.Therefore, the second theme of these research efforts is to enhance the code generation capabilities of LLMs.This includes automatically fixing bugs in code generated by LLMs (Ni et al., 2023;Jain et al., 2022b;Dinh et al., 2023), improving the quality of code generated by LLMs (Zhang et al., 2023a;Wang et al., 2023d;Barke et al., 2023a;Mouselinos et al., 2023;Lahiri et al., 2022;Dong et al., 2023;Jiang et al., 2023a), addressing security and reliability concerns (Poesia et al., 2022;Zhu and Zhang, 2023;Ke et al., 2023), enhancing the efficiency of LLM code generation (Li et al., 2023e;Wang et al., 2023b;Murali et al., 2023;Weyssow et al., 2023;Zhong and Wang, 2023;Tanaka et al., 2023), watermarking techniques for code generation (Lee et al., 2023;Wang et al., 2023c), and among others.</p>
<p>Code Summarization</p>
<p>Definition: Code summarization is an important technique for program understanding and automatic documentation generation.When using LLM for code summarization, the main goal of this task is to automatically generate clear, accurate, and useful code comments to aid developers in understanding and maintaining code.It should be noted that code summarization tasks encompass both code understanding and code summarization tasks.</p>
<p>Code summarization can be performed at different granularities, such as line-level, function-level, or module-level.Different levels of summarization require handling different contextual information.For example, function-level summarization may need to understand the inputs, outputs, functionality, and invocation relationships of functions, while module-level summarization may require understanding the functionality and interfaces with other modules.</p>
<p>Traditional code summarization methods mainly rely on rules and templates, using specific rules and templates to extract and represent key information from code.However, these methods often require a significant amount of manual effort and have poor adaptability to new programming languages and frameworks.With the advancement of machine learning, neural network-based code summarization methods have gained attention.These methods use neural networks to learn the complex mapping between code and text.Additionally, some methods employ encoder-decoder architectures, where the encoder is used to understand the source code and the decoder is used to generate natural language descriptions.</p>
<p>The use of Large Language Models (LLMs) is a recent research direction in code summarization.These models, such as OpenAI's GPT series, have also received considerable attention in the specific task of code summarization.Some works evaluate the code summarization capabilities of different LLMs, such as ChatGPT (Sun et al., 2023), Codex (Sarsa et al., 2022;Leinonen et al., 2023b), GPT-3 (MacNeil et al., 2022c), among others.Other works assess the capabilities of LLMs in code summarization from different perspectives, such as causal reasoning abilities (Liu et al., 2023d), effectiveness with minimal training (Ahmed and Devanbu, 2022), and interpretability (Leinonen et al., 2023a).Although these works provide incomplete conclusions, they generally recognize the strong potential of LLMs.</p>
<p>There are also works that utilize LLMs for code summarization to construct documentation, generate test cases, or address limitations in LLM-based code summarization (Khan and Uddin, 2023;Zhang et al., 2023b).For example, enhancing the robustness of LLM-based code summarization (Zhuo et al., 2023) or improving the interaction capabilities with developers (MacNeil et al., 2022a).</p>
<p>Code Translation</p>
<p>Definition: Code translation, also named code conversion, refers to the process of converting code between different programming languages without altering its functionality or logic.When using LLM for code transformation, LLM will take the given code and transformation requirements from the user and convert the code to the target language.</p>
<p>Traditional code translation methods often require substantial manual effort, implementing specific syntax and semantic rules through hard coding.Moreover, for new or less common programming languages, it may necessitate the redevelopment and maintenance of translation rules.Currently, the impressive natural language translation capabilities exhibited by LLMs have been recognized (Zhang et al., 2023c).However, there is limited focus on the performance of LLMs in code conversion tasks in current research.Pan et al. (Pan et al., 2023) present a large-scale empirical study to investigate the ability of LLMs, including general and code LLMs, for code translation in five languages, They are C, C++, Go, Java, and Python.</p>
<p>Pearce et al. (Pearce et al., 2022b) studied the capability of LLMs in software reverse engineering.The study explored Codex's ability to identify the purpose, functionality, and important variable names or values in code, thus evaluating the decompilation ability of LLMs.Additionally, Lin et al. (Lin et al., 2022b) proposed a Cross-language Code representation with a largescale pre-training (XCode) method and further introduced a Shared Encoder-Decoder (SED) architecture.</p>
<p>Currently, there is relatively little research on LLMs in code translation tasks, and applying LLMs to code translation tasks still faces many challenges.Firstly, code correctness and precision are crucial, as even small translation errors can render the generated code non-functional.Secondly, acquiring a large amount of high-quality source code and target code pairs is challenging, which may limit the model's learning and generalization capabilities.Thirdly, further research is needed on evaluating the performance of code translation models, as in many cases, there can be multiple different implementations of the same functionality in code.These issues require further exploration and resolution in future research.</p>
<p>Vulnerability Detection&amp; Repair</p>
<p>Definition: Code vulnerability detection and repair is an important task in the field of software engineering, crucial for improving the reliability and security of software.The main goal of this task is to identify and fix code errors that may cause program crashes, performance degradation, or security issues.When using LLM for vulnerability detection, LLM analyzes the target code for vulnerabilities, provides vulnerability reports, or fixes the detected vulnerabilities.It is worth noting that within the scope of this article's definition, tasks such as vulnerability mining and test case generation also fall under this task.</p>
<p>Due to the significance of this task, various software and hardware-based detection methods have been developed.Traditional vulnerability detection methods mainly include static analysis and dynamic analysis.Static analysis analyzes the source code before program execution to identify potential errors and vulnerabilities, while dynamic analysis analyzes program behavior during runtime to identify actual errors and vulnerabilities.These methods have their own advantages and disadvantages: static analysis can cover all code paths but may produce a large number of false positives, while dynamic analysis can precisely pinpoint actual errors but may miss errors that are not triggered in the test cases.</p>
<p>Recently, LLMs have been used in code vulnerability detection and repair tasks due to their advanced semantic understanding capabilities, which are effective in addressing logical flaws and linguistic issues in natural language.Similarly, in this task, current research can be roughly categorized into three types.The first type evaluates the capabilities of different LLMs in this task (Olausson et al., 2023;Prenner et al., 2022;Pearce et al., 2022a;Madaan et al., 2023;Noever, 2023), for example, Khoury et al. (Khoury et al., 2023) evaluated the security of ChatGPT in code generation tasks.The second type focuses on improving the correctness and performance of LLMs in vulnerability detection (Xia and Zhang, 2023a,b), such as combining LLMs with formal verification techniques (Charalambous et al., 2023), incorporating previously related edits (Gupta et al., 2023), self-debugging algorithms (Chen et al., 2023b), among others.The third type applies LLMs to vulnerability mining or other related tasks (Ahmad et al., 2023b;Chan et al., 2023;Fan et al., 2023b;Xia et al., 2022), including decompilation work (Xu et al., 2023), security analysis of hardware designs (Ahmad et al., 2023c), and black-box testing (Li et al., 2023f).</p>
<p>Code Evaluation</p>
<p>Definition: Code evaluation is a crucial task in software engineering that help ensure code quality, reliability, and expected functionality.Code evaluation aims to perform static analysis on the code to identify potential issues and improvement points.When using LLM for code assessment, LLM analyzes the nature of the given code based on the requirements, such as detecting code plagiarism or assessing code compliance with coding standards.Therefore, tasks like code cloning and code smell detection also fall under this category within the scope of this article's definition.</p>
<p>Code testing involves executing the code and checking if its behavior aligns with expectations to validate its correctness.However, code testing can be time-consuming and labour-intensive.Exploring the application of LLMs to automatically generate effective test cases based on a given code or directly evaluate the quality of a given code has attracted significant research attention.</p>
<p>In current research on applying LLMs to code testing, a significant portion of the work focuses on test case generation.For example, empirical studies have explored the unit test generation capabilities of LLMs like ChatGPT (Yuan et al., 2023;Tang et al., 2023b), or utilizing LLMs to generate test cases (Zhao et al., 2023a;Lemieux et al., 2023;Chen et al., 2022a;Tu et al., 2023;Li et al., 2023d).</p>
<p>Additionally, several works have proposed code testing frameworks utilizing LLMs based on different usage scenarios (Kang et al., 2022;Zhuo, 2023), such as combining LLMs with fuzz testing (Hu et al., 2023a) or black-box testing (Li et al., 2023f).Furthermore, a few works have developed LLM-based testing assistants or code testing models (Feldt et al., 2023;Lee et al., 2022a).</p>
<p>Code Management</p>
<p>Definition: Code management is a crucial aspect of the software engineering development and maintenance process.When using LLM for code management, LLM analyzes the given code based on the requirements, such as version control (Maruf et al., 2021), collaborative management (Potluri et al., 2022), and release management of source code during software development (Jing et al., 2021).</p>
<p>Code management is complex and challenging.Parallel development and collaboration can lead to code conflicts.Moreover, in large-scale projects, branch management and version iterations significantly increase the difficulty of code management.Traditional code management tools, such as Git (Escamilla et al., 2023), provide a powerful set of commands and rules to handle version control and branch management tasks.However, using these tools still requires developers to have expertise, especially when dealing with complex merge conflicts and branch management.</p>
<p>Due to the various challenges in code management tasks, some cutting-edge works aim to leverage the power of LLMs to alleviate the complexity of the code management process, and even achieve automated code management without manual intervention (Xiao et al., 2023;Bi et al., 2023).For example, Toufique et al. (Ahmed et al., 2023) evaluates the effectiveness of LLMs in assisting engineers in managing security incidents in cloud services, while Shrivastava et al. (Shrivastava et al., 2023a) addresses the issue of LLM models struggling to understand the context present in repositories.</p>
<p>Additionally, some works based on LLMs have developed code management tools or frameworks to assist code managers, aiding in version management (Gao et al., 2023) and personnel training (Lanciano. et al., 2023).</p>
<p>Q&amp;A Interaction</p>
<p>Definition: Interaction between humans and tools has always been a focus in the field of software engineering, as good interaction can enhance task performance (Xu et al., 2017).The wide-ranging application and research of LLM have led to the emergence of this task as a relatively independent research area.In the scope defined in this article, prompt engineering is also considered part of this task.</p>
<p>Before the widespread application of LLMs, an important way for developers to obtain information and solve problems was through Q&amp;A website, e.g., Stack Overflow8 (Zhang et al., 2022b).The emergence of LLMs changed this by being able to answer users' questions, including professional knowledge in software engineering.As a promising new tool to help developers solve code issues, LLMs also gave rise to much research on how to improve the efficiency and convenience of Q&amp;A Interaction (Gao et al., 2022).Furthermore, since the output generated by LLMs is influenced by the structure and content of user-provided prompts, research on prompts, known as prompt engineering (White et al., 2023a).</p>
<p>It is important to note that this section focuses on investigations related to Q&amp;A Interaction and prompt engineering in the context of software engineering.</p>
<p>This body of work can also be categorized into two main types.The first type focuses on the interaction between software practitioners (developers, beginners, etc.) and LLMs, and involves the development of prototype systems or interaction frameworks (Ross et al., 2023;Zamfirescu-Pereira et al., 2023;Cai et al., 2023).Among them, Zamfirescu-Pereira et al. (Zamfirescu-Pereira et al., 2023) discusses the role of non-AI practitioners in "user cue engineering" and designs BotDesigner, a cue-based chatbot design tool; Ross et al. (Ross et al., 2023) demonstrates the role and potential of developer-LLM interactions for processes such as software development, through interviews with 42 software developers; and Cai et al. (Cai et al., 2023) describes Low-code LLM, a framework for human-LLM interactions, to better support visual programming.</p>
<p>The second type consists of research-oriented work, which can be further divided into several directions.The first direction evaluates the interaction between LLMs and software developers (Barke et al., 2023b), such as whether LLMs address the same parts of natural language descriptions as developers (Kou et al., 2023), or whether they can act as a DevBot (Ahmad et al., 2023a).</p>
<p>The second direction primarily focuses on prompt engineering (White et al., 2023b,a;Shrivastava et al., 2023b), aiming to design more efficient prompt formats or automatically populate prompt content based on different subtasks and objectives.The third direction addresses security and efficiency issues in LLM interaction with developers (Sarkar et al., 2022;Sandoval et al., 2023).</p>
<p>Other Works</p>
<p>In addition to the aforementioned topics, there are other works that combine LLMs with software engineering.These works either discuss the performance of LLMs in specific subtasks (Ozkaya, 2023;Sadik et al., 2023;Xing et al., 2023), such as visualization (Maddigan and Susnjak, 2023), information extraction (Li et al., 2023a,c), and modeling (Nichols et al., 2023), propose their own solutions to existing problems, such as addressing performance issues (Jain et al., 2023), develop tools or datasets, such as code-text datasets (Manh et al., 2023;Liu et al., 2023c), or identify issues related to LLMs (Treude and Hata, 2023;Khlaaf et al., 2022).Additionally, some works focus on exploring the potential and applications of LLMs in the field of education (MacNeil et al., 2022b).</p>
<p>Performance of LLM in SE Tasks</p>
<p>In this section, we primarily discuss RQ2.First, we screened papers from our collection that evaluated the performance of LLMs on software engineering tasks.Next, we extracted the LLMs used and software engineering tasks targeted in these works.Finally, some works in Section 4 also evaluated and discussed the performance of LLMs on some specific tasks.Therefore, we will summarize these works here and emphasize their evaluation results.</p>
<p>A significant portion of the work conducted has empirically analyzed the performance of ChatGPT, one of the most popular LLM models, as a programming assistant (Tian et al., 2023;Sridhara et al., 2023;Li et al., 2023d;Liu et al., 2023a).These studies have found that ChatGPT's performance varies across different tasks.For instance, it performs well in tasks such as log summarization, referential resolution, and code summarization, but struggles in vulnerability detection and test case generation.Particularly in vulnerability detection, ChatGPT finds it challenging to identify subtle code differences when two versions have similar syntax (Li et al., 2023d).In some tasks such as Text-to-SQL (Liu et al., 2023a), answering software testing questions (Jalil et al., 2023), and test case generation (Tang et al., 2023b), although ChatGPT Table 9 The datasets and evaluation metric in papers.</p>
<p>Paper DataSet</p>
<p>Evaluation metric (Tian et al., 2023) Leetcode+Refactory Correct Rate (Sridhara et al., 2023) Multi-dataset Successful Rate (Ma et al., 2023) A new dateset Effective (Hellas et al., 2023) A new dateset Successful Rate (Li et al., 2023d) QuixBugs Correct Rate (Pearce et al., 2022b) Program Source Templates Correct Rate (gangz, 2023)</p>
<p>An example study Effective (Pearce et al., 2022a) CWE-787&amp;89+ExtractFix Effective (Bareiß et al., 2022) MeMo+ A new dataset Correct Rate (Tang et al., 2023b) Defects4J+A new dataset Correct Rate, Robustness (Sarsa et al., 2022) A new dateset Sensible, Novel, Solution (Jalil et al., 2023) A new dateset Correct Rate (Savelka et al., 2023) MCQ Correct Rate (Zhuo et al., 2023) AdvGLUE+GeoQuery+Scholar Robustness (Feiyu, 2023) An example study Correct Rate (Fan et al., 2023b) LMdefects Effective, Correct Rate, Robustness (Xia et al., 2022) Defects4J+QuixBugs+ManyBugs Correct Rate (Shirafuji et al., 2023) AOJ Solve Rate (Feng et al., 2023) A new dateset Quality (Kande et al., 2023) A new benchmark Suite Effective(Score) (Thakur et al., 2023b) A new dateset Quality (Khoury et al., 2023) A new dateset Security (Prenner et al., 2022) QuixBugs Correct Rate (Vaithilingam et al., 2022) CWE-787&amp;89+HumanEval Effective (Liu et al., 2023a) 9 dataset Effective (Rajkumar et al., 2022) GeoQuery+Scholar Correct Rate (Noever, 2023) A new dateset Effective(Score)</p>
<p>did not achieve outstanding performance, the authors still maintain a positive outlook.Some studies also highlight the limitations of ChatGPT's attention scope (Sridhara et al., 2023).Furthermore, some works analyze ChatGPT's performance in software engineering tasks from different perspectives.For instance, Ma et al. (Ma et al., 2023) investigates ChatGPT's understanding of code syntax and semantic structure, concluding that while ChatGPT excels in understanding code syntax (e.g., Abstract Syntax Trees), it faces difficulties in understanding code semantics, especially dynamic semantics.Feng et al. (Feng et al., 2023) explores ChatGPT's code generation abilities through analyzing comments on Twitter and Reddit, examining people's sentiment towards ChatGPT's code generation capabilities.</p>
<p>There are also detailed evaluations of LLMs' performance in specific tasks, such as reverse engineering (Pearce et al., 2022b), code explanation (Zhuo et al., 2023), code analysis (Feiyu, 2023), and vulnerability repair (Pearce et al., 2022a).These studies generally provide more critical conclusions, suggesting that LLMs still lag behind state-of-the-art methods in these tasks.However, two works evaluating LLMs in automated program repair (Fan et al., 2023b;Xia et al., 2022) present very positive findings.Additionally, several evaluations on specific tasks yield more positive conclusions or affirm the potential of LLMs in those tasks, such as code generation (Vaithilingam et al., 2022;Kande et al., 2023;Thakur et al., 2023b) and error fixing (Prenner et al., 2022).(gangz, 2023) evaluates the ability of large models to generate test cases on a simple game, reporting positive results.(Bareiß et al., 2022) acknowledges the performance of LLMs in code generation capabilities.</p>
<p>Moreover, a considerable portion of the research evaluates the performance of LLMs in education and programming courses (Leinonen et al., 2023a;Hellas et al., 2023;Sarsa et al., 2022;Savelka et al., 2023), with positive feedback.Additionally, compared to GPT-3, GPT-4 has made significant advancements (Savelka et al., 2023).</p>
<p>A small number of works focus on the robustness and security issues of LLMs in solving programming problems (Shirafuji et al., 2023;Khoury et al., 2023), and they have yielded important findings as well.</p>
<p>We have organized the conclusions derived from the work above, as shown in Table 7 and Table 8.We mainly screened the evaluation results from the abstract and conclusion sections of the papers.</p>
<p>Due to the inconsistency in evaluation methods and criteria for LLMs across different papers, we cannot directly standardize the assessment of a LLM's performance.We convert the results from the original papers into the "author's confidence" of LLMs' performance in completing SE tasks.We categorized the results into: High Confidence, Low Confidenceand Ambiguity.That is, if authors consider the performance of LLMs to be good, which is "High Confidence"; if authors consider the performance of LLMs to be limited, which is "Low Confidence"; If the authors cannot determine LLM's performance, then it is "Ambiguity".</p>
<p>It is worth noting that the blue shading and the grey shading respectively indicate that, although the evaluated LLM(s) in the article did not receive a High Confidence on the task, the article still provided a positive attitude towards its future potential; and that although LLMs is currently performing well, there are still limitations or even not good enough.</p>
<p>Additionally, we have presented the datasets and evaluation metrics used in the aforementioned papers, as shown in Table 9.</p>
<p>From the table and the above articles, we can reach a preliminary conclusion:</p>
<p>Findings</p>
<p>• Code generation, being a challenging task, current LLMs often do not achieve a "ready-to-use" level.The author's confidence to LLMs on this task is not enough.However, encouragingly, some articles (Kande et al., 2023;Thakur et al., 2023b), even though the evaluation conclusion did not affirm LLMs, still offered a positive attitude;</p>
<p>• On tasks like program repair, Text-to-SQL, authors usually have high confidence in the performance of LLMs.</p>
<p>• In program vulnerability detection, authors usually have low confidence in the performance of LLMs.</p>
<p>• Although there is a contradiction in the conclusions of (gangz, 2023) and (Tang et al., 2023b) about LLMs on the task of test case generation, they both expressed a relatively positive attitude, still believing that LLMs have potential in this task;</p>
<p>• In tasks like code summarization and code explanation, LLMs usually perform well, but lack robustness;</p>
<p>• According to the results of (Savelka et al., 2023), newer LLMs have made significant improvements in the task of code generation.</p>
<p>In summary, we can reach a fundamental conclusion: LLMs perform well and received high confidence from the authors on some software engineering tasks that require understanding of code syntax, such as code summarization and code repair; on some tasks that require understanding of code semantics, such as code generation and vulnerability detection, they typically do not perform well enough; LLMs continue to improve with the iteration of versions/models, and still possess great potential.</p>
<p>Therefore, at the current stage, LLMs still cannot fully achieve the level of professional human programmers in handling software engineering tasks, but they can serve as excellent assistants to software developers, as search tools, and as prompting tools.</p>
<p>6 Related work</p>
<p>Other works on reviewing LLM</p>
<p>The tremendous potential of LLM has attracted numerous investigations regarding its applications, either within the field of LLM itself or in specific domains.In this section, we will showcase these research efforts and explain their distinctions from our work.Our work focus on systematically investigate, analyze, and compile the research progress of LLM in the context of software engineering tasks.</p>
<p>Zhao et al. (Zhao et al., 2023b) is a detailed article that introduces the background, development history, technical roadmap, and latest advancements  Gozalo-Brizuela et al. (Gozalo-Brizuela and Garrido-Merchan, 2023), on the other hand, classifies generative AI models based on their input and output formats, dividing them into nine categories as shown in Table 11.The paper demonstrates the capabilities of generative AI models through these classifications.While the author believes these models possess significant creativity and potential, he also acknowledges the numerous constraints they face, particularly in terms of data acquisition.Additionally, concerns were raised over the significant computational resource consumption during their training and the time cost of model construction.Despite summarizing the capabilities of some generative AI models, the paper does not focus on LLM, nor does it discuss the performance of LLM in specific tasks, including software engineering tasks.</p>
<p>Liu et al. (Liu et al., 2023e) provides a comprehensive review of ChatGPT and GPT4, highlighting their potential applications and contributions in the field of Natural Language Processing (NLP).Meanwhile, it outlines several potential ethical issues related to the development and use of LLMs, advocating for a focus on addressing these ethical concerns, exploring new applications, and ensuring the responsible use of ChatGPT and GPT-4.Fan et al. (Fan et al., 2023a) claims that they conducted a bibliometric analysis of over 5,000 LLM research papers from 2017 to early 2023, investigating their  Wei et al. (Wei et al., 2023) provides a comprehensive overview of traditional language models (CLMs) and their successors, pre-trained language models (PLMs).CLMs are designed to predict language sequence probabilities in a causal manner, while PLMs can be fine-tuned for causal sequence modeling and downstream applications.While the article does not delve into the application of large models in the field of software engineering, it offers a brilliant overview of the current state and development progress of large models, and clearly points out future research directions for these models.</p>
<p>Additionally, some research work has reviewed and empirically analyzed the application of LLM in a specific field or particular tasks.</p>
<p>Li et al. (Li et al., 2022a) provides an overview of representative research achievements in text generation based on PLMs, reviews various evaluation metrics, open-source libraries, and common applications, with the aim to assist practitioners in assessing, selecting, and utilizing appropriate PLMs, and proposes some future research directions.Yang et al. (Yang et al., 2023b) investigates the application of Transformer-based PLMs for the Controllable Text Generation (CTG) task, summarizing typical applications, key methodologies, and evaluation systems of PLMs in CTG.Min et al. (Min et al., 2023) explores three trending paradigms of using pre-trained language models for NLP, They are Pre-train then Fine-tune, Prompt-based Learning, and NLP as Text Generation.Simultaneously, the paper mentions that their theoretical understanding of these paradigms is preliminary.</p>
<p>Wang et al. (Wang et al., 2023a) primarily summarizes the latest progress of PLMs in the biomedical field and their applications in downstream biomedical tasks, and discusses the development trends and directions.In response to the existing LLM-based recommendation systems, Wu et al. (Wu et al., 2023) proposes a classification that divides these models into two major paradigms, namely, Discriminative LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation (GLLM4Rec).The paper systematically reviews and analyzes the existing LLM-based recommendation systems in these two paradigms and discusses their methods and performance.</p>
<p>Other research mainly investigates and analyzes the shortcomings of LLMs in their applications.For instance, Meade et al. (Meade et al., 2022) survey and summarize the bias mitigation techniques in pre-trained language models.The paper empirically studies the five currently popular bias mitigation techniques and proposes three intrinsic bias benchmarks to quantify the effectiveness of each technique.Huang et al. (Huang and Chang, 2023) comprehensively describes the reasoning capabilities of LLMs, including technologies to improve and induce reasoning capabilities in these models, methods and benchmarks for assessing reasoning capabilities, and suggestions for future directions.As LLMs sometimes provide unrealistic yet seemingly plausible predictions (termed as hallucinations, see (Welleck et al., 2020)), Mialon et al. (Mialon et al., 2023) reviews two methods to enhance the abilities of LLMs, namely, by leveraging reasoning skills and invoking external tools, aiming to improve context and curb hallucinations.Xu et al. (Xu and McAuley, 2023) pays special attention to the inference stage during the construction of LLMs and reviews the current state of model compression and acceleration techniques, including benchmarks, metrics, and methods.</p>
<p>Zan et al. (Zan et al., 2023) investigates the performance of 27 large models in the field of generating code from a natural language description (or NL2Code).The main contribution of the paper is an intuitive comparison of the NL2Code capabilities of LLMs on the HumanEval benchmark.However, its research is limited to the software engineering task of code generation.It does not summarize the applications of other LLMs in code generation, nor does it investigate other software engineering tasks, such as code conversion.</p>
<p>Wong et al. (Wong et al., 2023) introduces some popular Language Modelbased Learning (LLM) approaches and their applications in downstream tasks related to AI-assisted programming.The tasks covered in the article include code generation, code completion, code translation, code refinement, code summarization, defect detection, and clone detection.However, it is worth noting that the AI-assisted methods discussed in this article are not limited to LLM but also encompass various other AI techniques.Furthermore, the focus of the article is solely on AI-assisted programming tasks.(Watson et al., 2022) provides a systematic literature review of the intersection between SE and deep learning (DL).It includes 128 references covering diverse SE domains and tasks.The article presents a detailed research roadmap, depicting the current state and application of DL techniques in SE tasks.It also analyzes and discusses future directions for the intersection of DL and SE research.The motivation and classification of SE tasks provided in the paper offer valuable insights for our article.The distinction lies in that the reviewed paper focuses on DL, while our article specifically reviews LLMs.</p>
<p>Pre-training model for Software Engineering Tasks</p>
<p>Previous works have applied pre-trained language models (PLM) to software engineering tasks, providing a solid foundation and guidance for the current application of PLMs in SE tasks.For instance, (Chen et al., 2022b) used a pretrained language model to generate variable names.(Lee et al., 2022b) utilized a PLM for bug classification.(Zhang et al., 2022d) introduced DietCode, a lightweight approach that leverages large pre-trained models for source code generation.(Li et al., 2022b) employed a PLM for automatic comment generation.Additionally, there have been works focusing on prompt learning, such as (Luo et al., 2022).</p>
<p>There are also several works that have evaluated the performance of PLMs in software engineering tasks.(Zeng et al., 2022b) studied the capabilities of pre-trained models in code comprehension and investigated the robustness of pre-trained models by examining their performance under adversarial attacks.(Zhang et al., 2022a) explored the feasibility of using pre-trained models for automatic repair of merge conflicts (both textual and semantic).(Mastropaolo et al., 2021) conducted an empirical analysis of the performance of the T5 model in code-related tasks.(Lin et al., 2021) compared and evaluated the accuracy and efficiency of three BERT architectures in linking issues and commits for bug triaging in open-source projects.(Hernández López et al., 2022) evaluated whether pre-trained language models encode the entire grammar structure of programming languages.(Karmakar and Robbes, 2021) employed probes to identify if models lack certain code properties (comprehension).(Wan et al., 2022) performed source code analysis of largescale code models to showcase the interpretability features of Code LLMs.(Tufano et al., 2022) validated the ability of the T5 model in automating code review tasks and provided positive conclusions, demonstrating its superiority over previous DL models.</p>
<p>Due to the relatively smaller parameter count of PLMs compared to LLMs, they may lack the powerful code generation capabilities, leading to potential issues in the generated code.To address this, some works have combined PLMs with program analysis techniques to enhance their performance in SE tasks.(Jain et al., 2022a) employed post-processing techniques based on program analysis to improve the reliability of LLM code generation.(Wang et al., 2022b) proposed a bridging approach between pre-trained models and coderelated tasks to enhance the capabilities of pre-trained models in tasks such as code comprehension.(Niu et al., 2022) introduced SPT-Code, a sequenceto-sequence pre-trained model specifically designed for source code.(Yang et al., 2022) attacked LLMs using adversarial input transformations to guide the models to produce incorrect outputs.(Nguyen et al., 2019) presented AutoSC for code completion tasks.(Liu et al., 2021) introduced CugLM, and (Shi et al., 2022) proposed a model compression technique to facilitate better utilization of Code LLMs by developers.</p>
<p>7 Threats to validity</p>
<p>Internal Validity</p>
<p>Sections 2 and Sections 4 rely on manual screening of papers and analysis of paper content, respectively.As a result, there may be internal subjectivity in the results of these screenings and analyses.To mitigate subjective bias and enhance the reliability of our results, we used a multi-person protocol in both sections, where multiple participants performed separate analyses and aligned the results to ensure that any disagreements were adequately resolved.Notably, the participants in these tasks (including non-co-authors) all had more than 3 years of software engineering research experience.</p>
<p>In Section 5, we focus on the performance of LLM on SE tasks.However, there may be differences in different works for LLM evaluation perspectives, such as using different datasets and oriented to different SE tasks.So there may be differences in the results in different literatures.To mitigate this effect, we organize the information about the evaluation results, evaluation datasets, and evaluation perspectives of different works to help readers understand the variability of different works.</p>
<p>External Validity</p>
<p>Currently, LLM technology is still evolving continuously at a very high rate.At the same time, LLM research work on SE is also developing rapidly.Although our findings cannot cover more future work.However, our work is still valuable in revealing the current direction of LLM on SE tasks.Meanwhile, our categorization of LLM on SE tasks remains applicable.</p>
<p>The second external threat pertains to subtle boundaries that exist between software engineering tasks, such as code cloning and code smells.These tasks may be relevant to multiple software engineering domains, which introduces potential ambiguity in their classification.To mitigate this threat, we have provided explicit definitions for each software engineering task and clarified the scope covered by the task classifications.For example, we have defined code cloning and code smell tasks within the domain of code assessment.</p>
<p>Another external threat is the inherent limitations of the literature review process itself.Due to the impracticality of verifying the accuracy of every work reviewed in the literature, there may be some bias in the results presented for RQ2.To mitigate the impact of this threat, we have provided detailed information regarding the evaluation details of each work surveyed for RQ2.This includes information such as the dataset used, the emphasis of the evaluation, the target of evaluation, and the evaluation results.We believe that if LLM consistently performs poorly in almost all evaluation studies for a specific task, it can be tentatively concluded that LLM performs poorly in that task.Conversely, if all evaluation studies provide positive assessments for a specific SE task, we can conclude that LLM performs well in that task.</p>
<p>We have provided a fair summary of the evaluation of LLM across different SE tasks.Furthermore, we address any contradictory evaluations found in the current body of evaluation studies in our conclusion.</p>
<p>Conclusion and Future Work</p>
<p>This paper comprehensively reviews the applications of Large Language Models (LLMs) in software engineering.Firstly, we collected and screened 123 works and literature related to the intersection of software engineering and LLM.Secondly, by categorizing the selected literature based on software engineering tasks, we revealed the research focus and identified existing deficiencies in the integration of LLM with various software engineering tasks.Finally, we carefully examined and summarized papers evaluating the performance of LLMs in software engineering tasks, exposing their capabilities and limitations and providing directions for future research and optimization.</p>
<p>Current works also reveal some future directions worth discussing: (1) We can see that a large part of the work in Section 4 proposes methods to improve the performance of LLMs on one or several software engineering tasks.Although most of them do not provide detailed evaluations or discussions on the performance of LLMs on these tasks, this might suggest that the current performance of LLMs on these tasks is not good enough or not stable; (2) Most current evaluations are based on general large models, such as ChatGPT, and detailed evaluations of code-centric large models like Codex are still lacking;</p>
<p>(3) Do we need to fine-tune large models for specific software engineering tasks to create large model products tailored for specific tasks?We will gradually seek the answers to these questions in the future.</p>
<p>Conflict of Interests</p>
<p>The authors declared that they have no conflict of interest exits in the submission of this manuscript, and manuscript is approved by all authors for publication.I would like to declare on behalf of my co-authors that the work described was original research that has not been published previously and is not under consideration for publication elsewhere.All the authors listed have approved the manuscript.</p>
<p>We declare that we do not have any commercial or associative interest that represents a conflict of interest in connection with the work submitted.</p>
<p>Data availability statements</p>
<p>The list of the literature surveyed in this paper is open source and is available in https://github.com/KevinHeiwa/LLM-SE-Paper-List</p>
<p>Fig. 1
1
Fig. 1 Overview of methodology design.</p>
<p>•</p>
<p>Empirical Studies of LLM on Software Engineering Tasks</p>
<p>Fig. 2
2
Fig. 2 Number of literature on different software engineering tasks.</p>
<p>Key Words Search Literature Search Literature Selection Seven Exclusion Criteria Data Analysis Literature collection and screening process: large-scale collection of literature and accurate screening of relevant literature Six Search Engines Including published literature and preprint literature Manually Context Analysis Using card classification methods to check data Paper Reading Literature classification Discussion and Unified Conclusion</p>
<p>Table 1
1
Number of keyword searches returned by each search engine.
SESoftwareSoftwareSE LargeCodeCodeLLMEngi-Engi-Lan-LLMLargeneeringneeringguageLan-LargeLLMModelguageLan-ModelguageModelACM49835590739032545322789454990DigitalLibraryIEEE024071414328XploreDigitalLibrarydblp841105762Elsevier56112735470636420649ScienceDirectGoogle10500 164004020254001140017700ScholararXiv518270174631461</p>
<p>Table 3
3
Papers related to LLM in ICSE 2024.
TasksNumbers of Paper NoteCode Generation13Includes code improvementsQ&amp;A Interaction5/Includes logsOther Works1/Total40/
number of papers included for each task is shown in Fig.2.Our selection of software engineering task classification was based on the main content of the surveyed articles.For a specific software engineering task, if there were only two articles related to that task, we categorized it separately.Otherwise, we grouped it under "Other Work."</p>
<p>Table 4
4
Data Collection for Each RQ.</p>
<p>Table 5
5
The Definition of Seven Types of Software Engineering Tasks and the Role of LLMs.
TaskDefinitionThe possible role of LLMsCode Gen-Automatically Generating source code(auxiliary)Generatecodeerationbased on user requirements andor provide developers with ideas andspecified constraints. Includes codeprogramming 'starting points',etc.completion, code enhancement, andother related tasks.CodeTo automatically generate clear,CodesummariesthatSumma-accurate, and useful code comments toassist with different granularity (suchrizationaid developers in understanding andas functions) or explain the intent ofmaintaining code. Includes tasks suchthe code,etc.as code comprehension.CodeConverting code between differentAuxiliary code conversion, Reversetransla-programminglanguageswithoutengineering,etc.tionaltering its functionality or logic.VulnerabilityToidentifyandfixCheck for potential vulnerabilities inDetectioncode errors that may cause programthe code, etc.crashes, performance degradation, orsecurity issues. Includes tasks suchas vulnerability mining, vulnerabilityremediation and code testing.CodeTo perform static analysis on theGenerate test cases or test codeEvalua-code to identify potential issues andperformance, usability, and othertionimprovement points. Includes tasksindicators, etc.such as Code Clone, Code Smell, etc.CodeManage information such as codeTeam collaborative development,Manage-versions and developers. Contains log-version control, etcmentrelated tasksQ&amp;A In-InteractionbetweensoftwareProgramassistant,Promptteractiondevelopers and LLMengineering, etcOtherSome other work, such as researchingUnknown.Workscopyright and ethical issues in LLM-generated code.</p>
<p>Table 6
6
LLM with minimum number of parameters of articles in ICSE 2024.
PaperLLM with minimum number of parameters in the article(Ma et al., 2024b)Flan-T5-small-80M(Xu et al., 2024a)text-embedding-babbage-001(Jiang et al., 2023b)GPT-3.5(Geng et al., 2023)code-davinci-002(Li et al., 2023g)codet5-base-232M(Yang et al., 2023c)CodeParrot-small-110M(Ding et al., 2023)UnixCoder(Choudhuri et al., 2023) ChatGPT(Guo et al., 2023)ChatGPT(Pan et al., 2024)GPT-4(Yang et al., 2023a)CodeGen-Multi-16B(Zhang et al., 2024)PanGu-Coder-300M(Liu et al., 2023f)ChatGPT(Feng and Chen, 2023)ChatGPT(Xu et al., 2024b)GPT-3(Ahmed et al., 2024)code-davinci-002</p>
<p>Table 7
7
Part 1 -The author's confidence of LLMs in software engineering tasks.
PaperSourceLLM(s)SubjectofAuthor's Confidenceevaluation(TianpreprintChatGPTcodegeneration,High Confidenceetal.,program2023)repair, and codesummarization(SridharapreprintChatGPT15Well done: log summary,etal.,common softwareanaphora parsing, code2023)engineering taskssummarization(method name generation)codeclonedetection, etc Not doing well: codevulnerability detection, etc(Ma et al.,preprintChatGPTsyntaxWelldone:Code2023)understanding,syntax understanding Notstaticbehaviourdoing well: Code semanticunderstanding,understandingdynamic behaviourunderstanding,capacitytocomprehendcode syntax, andcapacitytocomprehendsemanticstructures(HellaspreprintCodex, and GPT-code interpretation High Confidenceetal.,3.52023)(Li et al.,preprintChatGPTcodedefectLow Confidence2023d)detection(PearcepreprintCodexsoftwarereverseLow Confidenceetal.,engineering2022b)(gangz,preprintChatGPTtestcaseHigh Confidence2023)generation(PearcepreprintCodexcodedefectLow Confidenceetal.,detection2022a)(BareißpreprintCodexcode generationHigh Confidenceetal.,2022)(TangpreprintChatGPTtestcaseLow Confidenceetal.,generation2023b)(SarsaICERCodexcode interpretation High Confidenceetal.,2022)(JalilICSTWChatGPTsoftware testingHigh Confidenceetal.,2023)(SavelkapreprintGPT-4code generationHighConfidenceandetal.,obvious progress2023)</p>
<p>Table 8
8
Part 2 -The author's confidence of LLMs in software engineering tasks.
PaperSourceLLM(s)SubjectofAuthor's Confidenceevaluation(ZhuopreprintCodexetal.,2023)</p>
<p>Table 10
10
Model and Model structure in papers.LLM).The article primarily focuses on large-scale models (with a size greater than 10B) and does not cover early pre-trained language models such as BERT and GPT-2.The research primarily revolves around four main aspects of LLM: pre-training, fine-tuning, applications, and performance evaluation.Additionally, the author considers certain tasks in the software engineering domain as fundamental capabilities of LLM, for instance, treating Code Synthesis as part of the Language Generation capability.Consequently, the article does not delve into a comprehensive discussion and summary of LLM's application, performance, and limitations in software engineering tasks.
ModelModel structureCodexDecoder-Onlys (Causal Decoder)ChatGPT/GPT-3.5 Decoder-Onlys (Causal Decoder)GPT-4Decoder-Onlys (Causal Decoder)GPT-NeoDecoder-Onlys (Causal Decoder)GPT-JDecoder-Onlys (Causal Decoder)GPT-NeoXDecoder-Onlys (Causal Decoder)CodeT5Encoder-decoderINCODEREncoder-decoderCodeGenDecoder-Onlys (Causal Decoder)InstructGPTDecoder-Onlys (Causal Decoder)Flan-T5Encoder-decoderUnixCoderEncoder-decoderof Large Language Models (</p>
<p>Table 11 A
11
(Gozalo-Brizuela and Garrido-Merchan, 2023)models in(Gozalo-Brizuela and Garrido-Merchan, 2023)
Generative AI models categoriesExamplesText-to-image ModelsDALL•E 2, IMAGEN, MuseText-to-3D modelsDreamfusion, Magic3DImage-to-Text modelsFlamingo, VisualGPTText-to-Video modelsPhenaki, SoundifyText-to-Audio modelsAudioLM, Jukebox, WhisperText-to-Text modelsChatGPT, LaMDA, PEERText-to-Code modelsCodex, AlphacodeText-to-Science modelsGalactica, MinervaOther modelsAlphaTensor, GATO, ChatBCGapplications across various fields. The paper calls for accelerated cooperationamong stakeholders, such as government agencies, universities, companies,infrastructure service providers, etc., to responsibly develop and apply LLMs.
https://dl.acm.org/
https://ieeexplore.ieee.org/Xplore/home.jsp
https://dblp.uni-trier.de/
https://www.sciencedirect.com/
https://scholar.google.com
https://arxiv.org/
https://conf.researchr.org/track/icse-2024/icse-2024-research-track?#event-overview
 www.stackoverflow.com/ <br />
Code Translation 1 / Code Summarization 4 Includes code comprehension Code Evaluation 3 Includes code clone Vulnerability Detection 9 Included Tests Code Management 4 code interpretation Low Confidence(robustness) (Feiyu, 2023) preprint GPT-4 code analysis Low Confidence (Fan et al., 2023b) preprint Codex program repair High Confidence (Xia et al., 2022) preprint GPT-Neo-125M/1.3B/2.7B,GPT-J-6.7B,GPT-NeoX-20B, Codex-12B, CodeT5-220M and INCODER-1.3B/6.7Bprogram repair High Confidence (Shirafuji et al., 2023) preprint Codex-12B, CodeGen-16B, InstructGPT, and ChatGPT code generation Low Confidence(robustness) (Feng et al., 2023) ISAC ChatGPT code generation Ambiguity (Kande et al., 2023) preprint code-davinci-002 code generation Low Confidence (Thakur et al., 2023b) DATE CodeGen -2B/6B/16B, and Codex code generation Low Confidence (Khoury et al., 2023) preprint ChatGPT code generation High Confidence (Prenner et al., 2022)code via extended chain-of-thought.2305.16744Wang L, Yang W, Chen D, Zhou H, Lin Y, Meng F, Zhou J, Sun X (2023c) Towards codable text watermarking for large language models.2307.15992Wang X,Li S, Ji H (2023d)
Towards human-bot collaborative software architecting with chatgpt. A Ahmad, M Waseem, P Liang, M Fehmideh, M S Aktar, T Mikkonen, 2302.146002023a</p>
<p>Flag: Finding line anomalies (in code) with generative ai. B Ahmad, B Tan, R Karri, H Pearce, 2306.126432023b</p>
<p>Fixing hardware security bugs with large language models. B Ahmad, S Thakur, B Tan, R Karri, H Pearce, 2302.012152023c</p>
<p>Few-shot training llms for project-specific code-summarization. T Ahmed, P T Devanbu, 37th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022. Rochester, MI, USAACM2022. October 10-14, 2022</p>
<p>Recommending root-cause and mitigation steps for cloud incidents using large language models. T Ahmed, S Ghosh, C Bansal, T Zimmermann, X Zhang, S Rajmohan, ICSE 20232023</p>
<p>Automatic semantic augmentation of language model prompts (for code summarization). T Ahmed, K S Pai, P Devanbu, E T Barr, 2304.068152024</p>
<p>J L Ba, J R Kiros, G E Hinton, arXiv:160706450Layer normalization. 2016arXiv preprint</p>
<p>Code generation tools (almost) for free? a study of few-shot, pre-trained language models on code. P Bareiß, B Souza, M Amorim, M Pradel, 2206.013352022</p>
<p>Grounded copilot: How programmers interact with code-generating models. S Barke, M B James, N Polikarpova, 10.1145/35860302023a7</p>
<p>Grounded copilot: How programmers interact with code-generating models. S Barke, M B James, N Polikarpova, 2023b</p>
<p>Codekgc: Code language model for generative knowledge graph construction. Z Bi, J Chen, Y Jiang, F Xiong, W Guo, H Chen, N Zhang, 2304.090482023</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems. 332020</p>
<p>A comparative study of code generation using chatgpt 3.5 across 10 programming languages. A Buscemi, 2308.044772023a</p>
<p>A comparative study of code generation using chatgpt 3.5 across 10 programming languages. A Buscemi, 2308.044772023b</p>
<p>Low-code llm: Visual programming over llms. Y Cai, S Mao, W Wu, Z Wang, Y Liang, T Ge, C Wu, W You, T Song, Y Xia, J Tien, N Duan, 2304.081032023</p>
<p>Ernie-code: Beyond english-centric cross-lingual pretraining for programming languages. Y Chai, S Wang, C Pang, Y Sun, H Tian, H Wu, 10.48550/arXiv.2212.067422212.067422022</p>
<p>Transformer-based vulnerability detection in code at edittime: Zero-shot, few-shot. A Chan, A Kharkar, R Z Moghaddam, Y Mohylevskyy, A Helyar, E Kamal, M Elkamhawy, N Sundaresan, 2306.017542023</p>
<p>A new era in software security: Towards self-healing software via large language models and formal verification. Y Charalambous, N Tihanyi, R Jain, Y Sun, M A Ferrag, L C Cordeiro, 2305.147522023</p>
<p>Improving code generation by training with natural language feedback. A Chen, J Scheurer, T Korbak, J A Campos, J S Chan, S R Bowman, K Cho, E Perez, 2303.167492023a</p>
<p>Codet: Code generation with generated tests. B Chen, F Zhang, A Nguyen, D Zan, Z Lin, J G Lou, Chen W , 2207.103972022a</p>
<p>Maintenance-related concerns for post-deployed ethereum smart contract development: issues, techniques, and future challenges. J Chen, X Xia, D Lo, J Grundy, X Yang, Empirical Software Engineering. 2662021</p>
<p>Varclr: variable semantic representation pre-training via contrastive learning. Q Chen, J Lacomis, E J Schwartz, G Neubig, B Vasilescu, C L Goues, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022b</p>
<p>Teaching large language models to self-debug. X Chen, M Lin, N Schärli, D Zhou, 2304.051282023b</p>
<p>How far are we? the triumphs and trials of generative ai in learning software engineering. R Choudhuri, D Liu, I Steinmacher, M Gerosa, A Sarma, 2312.117192023</p>
<p>A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, arXiv:220402311Scaling language modeling with pathways. Palm2022arXiv preprint</p>
<p>H W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:221011416Scaling instruction-finetuned language models. 2022arXiv preprint</p>
<p>Traced: Execution-aware pre-training for source code. Y Ding, B Steenhoek, K Pei, G Kaiser, Le W Ray, B , 2306.074872023</p>
<p>Large language models of code fail at completing code with potential bugs. T Dinh, J Zhao, S Tan, R Negrinho, L Lausen, S Zha, G Karypis, 2306.034382023</p>
<p>Self-collaboration code generation via chatgpt. Y Dong, X Jiang, Jin Z Li, G , 2304.075902023</p>
<p>It's not just github: Identifying data and software sources included in publications. E Escamilla, L Salsabil, M Klein, J Wu, M C Weigle, M L Nelson, 2307.144692023</p>
<p>A bibliometric review of large language models research from. L Fan, L Li, Z Ma, S Lee, H Yu, L Hemphill, 2304.020202023a. 2017 to 2023</p>
<p>Automated repair of programs from large language models. Z Fan, X Gao, M Mirchev, A Roychoudhury, S H Tan, 2205.105832023b</p>
<p>. Feiyu, 2023</p>
<p>Towards autonomous testing agents via conversational large language models. R Feldt, S Kang, J Yoon, S Yoo, 2306.051522023</p>
<p>Prompting is all you need: Automated android bug replay with large language models. S Feng, C Chen, 2306.019872023</p>
<p>Auto-icon: An automated code generation tool for icon designs assisting in UI development. S Feng, S Ma, J Yu, C Chen, T Zhou, Y Zhen, 10.1145/3397481.3450671IUI '21: 26th International Conference on Intelligent User Interfaces. T Hammond, K Verbert, D Parra, B P Knijnenburg, O 'donovan, J Teale, P , College Station, TX, USAACM2021. April 13-17, 2021</p>
<p>Investigating code generation performance of chat-gpt with crowdsourcing social data. Y Feng, S Vanam, M Cherukupally, W Zheng, M Qiu, H Chen, Proceedings of the 47th IEEE Computer Software and Applications Conference. the 47th IEEE Computer Software and Applications Conference2023</p>
<p>Applying human values theory to software engineering practice: Lessons and implications. M A Ferrario, E Winter, 10.1109/TSE.2022.3170087IEEE Trans Software Eng. 4932023. 2023</p>
<p>Collabcoder: A gpt-powered workflow for collaborative qualitative analysis. J Gao, Y Guo, G Lim, T Zhang, Z Zhang, Tjj Li, S T Perrault, 2304.073662023</p>
<p>Technical q&amp;a site answer recommendation via question boosting. Z Gao, X Xia, D Lo, J C Grundy, 10.48550/arXiv.2210.158462022</p>
<p>Large language models are few-shot summarizers: Multi-intent comment generation via in-context learning. M Geng, S Wang, D Dong, H Wang, G Li, Jin Z Mao, X Liao, X , 2304.113842023</p>
<p>Chatgpt is not all you need. a state of the art review of large generative ai models. R Gozalo-Brizuela, E C Garrido-Merchan, 2301.046552023</p>
<p>Exploring the potential of chatgpt in automated code refinement: An empirical study. Q Guo, J Cao, X Xie, S Liu, X Li, B Chen, X Peng, 2309.082212023</p>
<p>Grace: Generation using associated code edits. P Gupta, A Khare, Y Bajpai, S Chakraborty, S Gulwani, A Kanade, A Radhakrishna, G Soares, A Tiwari, 2305.141292023</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>Exploring the responses of large language models to beginner programmers' help requests. A Hellas, J Leinonen, S Sarsa, C Koutcheme, L Kujanpää, J Sorva, 2306.057152023</p>
<p>Ast-probe: Recovering abstract syntax trees from hidden representations of pre-trained language models. Hernández López, J A Weyssow, M Cuadrado, J S Sahraoui, H , Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringAssociation for Computing Machinery202222</p>
<p>The human side of software engineering teams: An investigation of contemporary challenges. M Hoffmann, D Méndez, F Fagerholm, A Luckhardt, 10.1109/TSE.2022.3148539IEEE Trans Software Eng. 4912023</p>
<p>User and technical perspectives of controllable code generation. S Houde, NeurIPS HCAI workshop. 2022</p>
<p>Augmenting greybox fuzzing with generative ai. J Hu, Q Zhang, H Yin, 2306.067822023a</p>
<p>Fine-grained code clone detection with block-based splitting of abstract syntax tree. T Hu, Z Xu, Y Fang, Y Wu, B Yuan, D Zou, Jin H , 10.1145/3597926.3598040Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis. R Just, G Fraser, the 32nd ACM SIGSOFT International Symposium on Software Testing and AnalysisSeattle, WA, USAACM2023b. July 17-21, 2023</p>
<p>Training codeparrot from scratch. Huaggingface, 2021</p>
<p>Towards reasoning in large language models: A survey. J Huang, Kcc Chang, 2212.104032023</p>
<p>Emotionally numb or empathetic? evaluating how llms feel using emotionbench. J Tse Huang, M H Lam, E J Li, S Ren, W Wang, W Jiao, Z Tu, M R Lyu, 2308.036562023</p>
<p>Tuning models of code with compiler-generated reinforcement learning feedback. A Jain, C Adiole, S Chaudhuri, T Reps, Jermaine C , 2305.183412023</p>
<p>Jigsaw: large language models meet program synthesis. N Jain, S Vaidyanath, A Iyer, N Natarajan, S Parthasarathy, S Rajamani, R Sharma, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022a</p>
<p>Jigsaw: Large language models meet program synthesis. N Jain, S Vaidyanath, A S Iyer, N Natarajan, S Parthasarathy, S K Rajamani, R Sharma, 10.1145/3510003.351020344th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022. Pittsburgh, PA, USAACM2022b. May 25-27, 2022</p>
<p>ChatGPT and software testing education: Promises &amp; perils. S Jalil, S Rafi, T D Latoza, K Moran, W Lam, 10.1109/icstw58534.2023.000782023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW). IEEE2023</p>
<p>Selfevolve: A code evolution framework via large language models. S Jiang, Y Wang, Y Wang, 2306.029072023a</p>
<p>Xpert: Empowering incident management with query recommendations via large language models. Y Jiang, C Zhang, S He, Z Yang, M Ma, S Qin, Y Kang, Y Dang, S Rajmohan, Q Lin, D Zhang, 2312.119882023b</p>
<p>A blockchain-based code copyright management system. N Jing, Q Liu, V Sugumaran, 10.1016/j.ipm.2021.102518Inf Process Manag. 5831025182021</p>
<p>Llm-assisted generation of hardware assertions. R Kande, H Pearce, B Tan, B Dolan-Gavitt, S Thakur, R Karri, J Rajendran, 2306.140272023</p>
<p>Large language models are few-shot testers: Exploring llm-based general bug reproduction. S Kang, J Yoon, S Yoo, 2209.115152022</p>
<p>J Kaplan, S Mccandlish, T Henighan, T B Brown, B Chess, R Child, S Gray, A Radford, J Wu, D Amodei, arXiv:200108361Scaling laws for neural language models. 2020arXiv preprint</p>
<p>What do pre-trained code models know about code?. A Karmakar, R Robbes, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). 2021</p>
<p>Discriminating human-authored from chatgpt-generated code via discernable feature analysis. L Ke, H Sheng, F Cai, Z Yunhe, Ming L , 2306.143972023</p>
<p>Automatic code documentation generation using gpt-3. J Y Khan, G Uddin, 10.1145/3551349.3559548Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringNew York, NY, USA, ASEAssociation for Computing Machinery2023</p>
<p>A hazard analysis framework for code synthesis large language models. H Khlaaf, P Mishkin, J Achiam, G Krueger, M Brundage, 2207.141572022</p>
<p>How secure is code generated by chatgpt?. R Khoury, A R Avila, J Brunelle, B M Camara, 2304.096552023</p>
<p>Guidelines for performing systematic literature reviews in software engineering. ebse technical report ebse-2007-01. Ba ; Kitchenham, B Kitchenham, 10.1145/3572905IEEE Computer Society Kotti Z, Galanopoulou R, Spinellis D. 5512392007. 2023ACM Comput Surv</p>
<p>Is model attention aligned with human attention? an empirical study on large language models for code generation. B Kou, S Chen, Z Wang, L Ma, T Zhang, 2306.012202023</p>
<p>Interactive code generation via test-driven user-intent formalization. S K Lahiri, A Naik, G Sakkas, P Choudhury, Von Veh, C Musuvathi, M Inala, J P Wang, C Gao, J , 2208.059502022</p>
<p>Analyzing declarative deployment code with large language models. G Lanciano, M Stein, V Hilt, T Cucinotta, 10.5220/0011991200003488Proceedings of the 13th International Conference on Cloud Computing and Services Science -CLOSER. the 13th International Conference on Cloud Computing and Services Science -CLOSERINSTICC, SciTePress2023</p>
<p>A light bug triage framework for applying large pre-trained language model. J Lee, K Han, H Yu, 10.1145/3551349.355689837th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022. Rochester, MI, USAACM2022a. October 10-14, 2022311</p>
<p>A light bug triage framework for applying large pre-trained language model. J Lee, K Han, H Yu, Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringAssociation for Computing Machinery2022b22</p>
<p>Who wrote this code? watermarking for code generation. T Lee, S Hong, J Ahn, I Hong, H Lee, S Yun, J Shin, G Kim, 2305.150602023</p>
<p>Comparing code explanations created by students and large language models. J Leinonen, P Denny, S Macneil, S Sarsa, S Bernstein, J Kim, A Tran, A Hellas, 2304.039382023a</p>
<p>Using large language models to enhance programming error messages. J Leinonen, A Hellas, S Sarsa, B Reeves, P Denny, J Prather, B A Becker, Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1. the 54th ACM Technical Symposium on Computer Science Education V. 1New York, NY, USA, SIGCSEAssociation for Computing Machinery2023b. 2023</p>
<p>Codamosa: Escaping coverage plateaus in test generation with pre-trained large language models. C Lemieux, J P Inala, S Lahiri, S Sen, ICSE'232023</p>
<p>Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. M Lewis, Y Liu, N Goyal, M Ghazvininejad, Mohamed A Levy, O Stoyanov, V Zettlemoyer, L , arXiv:1910134612019BartarXiv preprint</p>
<p>Evaluating chatgpt's information extraction capabilities: An assessment of performance, explainability, calibration, and faithfulness. B Li, G Fang, Y Yang, Q Wang, W Ye, W Zhao, S Zhang, 2023a. 230411633</p>
<p>Pretrained language models for text generation: A survey. J Li, T Tang, W X Zhao, J Y Nie, J R Wen, 2201.052732022a</p>
<p>Enabling programming thinking in large language models toward code generation. J Li, G Li, Y Li, Jin Z , 2305.065992023b</p>
<p>Auger: automatically generating review comments with pre-training models. L Li, L Yang, H Jiang, J Yan, T Luo, Z Hua, G Liang, C Zuo, ESEC/FSE 2022Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software EngineeringAssociation for Computing Machinery2022b</p>
<p>Codeie: Large code generation models are better few-shot information extractors. P Li, T Sun, Q Tang, H Yan, Y Wu, X Huang, X Qiu, 2305.057112023c</p>
<p>Finding failure-inducing test cases with chatgpt. T O Li, W Zong, Y Wang, H Tian, Y Wang, S C Cheung, J Kramer, 2304.116862023d</p>
<p>Think outside the code: Brainstorming boosts large language models in code generation. X Y Li, J T Xue, Z Xie, M Li, 2305.106792023e</p>
<p>Competition-level code generation with alphacode. Y Li, D Choi, J Chung, N Kushman, J Schrittwieser, R Leblond, T Eccles, J Keeling, F Gimeno, A D Lago, T Hubert, P Choy, C De Masson D'autume, I Babuschkin, X Chen, P S Huang, J Welbl, S Gowal, A Cherepanov, J Molloy, D J Mankowitz, E S Robson, P Kohli, N De Freitas, K Kavukcuoglu, O Vinyals, 10.1126/science.abq1158Science. 37866242022c</p>
<p>Unleashing the power of compiler intermediate representation to enhance neural program embeddings. Z Li, P Ma, H Wang, S Wang, Q Tang, S Nie, S Wu, 10.1145/3510003.351021744th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022. Pittsburgh, PA, USAACM2022d. May 25-27, 2022</p>
<p>Cctest: Testing and repairing code completion systems. Z Li, C Wang, Z Liu, H Wang, D Chen, S Wang, C Gao, 2208.082892023f</p>
<p>On extracting specialized code abilities from large language models: A feasibility study. Z Li, C Wang, P Ma, C Liu, S Wang, D Wu, C Gao, Y Liu, 2303.030122023g</p>
<p>Traceability transformed: Generating more accurate links with pre-trained bert models. J Lin, Y Liu, Q Zeng, M Jiang, Cleland - Huang, J , 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). 2021</p>
<p>Xcode: Towards cross-language code representation with large-scale pre-training. T Lin, Y Wang, X Liu, X Qiu, Z Ai Open Lin, G Li, J Zhang, Y Deng, X Zeng, Y Zhang, Y Wan, 10.1145/3506696ACM Trans Softw Eng Methodol. 3132022a. 2022bA survey of transformers</p>
<p>A comprehensive evaluation of chatgpt's zero-shot text-to-sql capability. A Liu, X Hu, L Wen, P S Yu, 2303.135472023a</p>
<p>Multi-task learning based pre-trained language model for code completion. F Liu, G Li, Y Zhao, Jin Z , Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringAssociation for Computing Machinery202120</p>
<p>Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. J Liu, C S Xia, Y Wang, L Zhang, 2305.012102023b</p>
<p>\what it wants me to say": Bridging the abstraction gap between end-user programmers and code-generating large language models. M X Liu, A Sarkar, C Negreanu, B Zorn, J Williams, N Toronto, A D Gordon, 2023cAssociation for Computing Machinery23New York, NY, USA</p>
<p>The magic of if: Investigating causal reasoning abilities in large language models of code. X Liu, D Yin, C Zhang, Y Feng, D Zhao, 2023d. 2305. 19213</p>
<p>Summary of chatgpt/gpt-4 research and perspective towards the future of large language models. Y Liu, T Han, S Ma, J Zhang, Y Yang, J Tian, H He, A Li, M He, Z Liu, Z Wu, D Zhu, X Li, N Qiang, D Shen, T Liu, B Ge, 2304.018522023e</p>
<p>Testing the limits: Unusual text inputs generation for mobile app crash detection with large language model. Z Liu, C Chen, J Wang, M Chen, B Wu, Che X Wang, D Wang, Q , 2310.156572023f</p>
<p>Combining graph neural networks with expert knowledge for smart contract vulnerability detection. Z Liu, P Qian, X Wang, Y Zhuang, L Qiu, X Wang, 10.1109/TKDE.2021.3095196IEEE Trans Knowl Data Eng. 3522023g</p>
<p>Prcbert: Prompt learning for requirement classification using bert-based pretrained language models. X Luo, Y Xue, Z Xing, J Sun, Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringAssociation for Computing Machinery202222</p>
<p>The scope of chatgpt in software engineering: A thorough investigation. W Ma, S Liu, W Wang, Q Hu, Y Liu, C Zhang, L Nie, Y Liu, 2305.121382023</p>
<p>Llmparser: An exploratory study on using large language models for log parsing. Z Ma, A R Chen, D J Kim, Thp Chen, S Wang, 2024a</p>
<p>Llmparser: An exploratory study on using large language models for log parsing. Z Ma, A R Chen, D J Kim, Thp Chen, S Wang, 2024b</p>
<p>Experiences from using code explanations generated by large language models in a web software development e-book. S Macneil, A Tran, A Hellas, J Kim, S Sarsa, P Denny, S Bernstein, J Leinonen, 2211.022652022a</p>
<p>Automatically generating CS learning materials with large language models. S Macneil, A Tran, J Leinonen, P Denny, J Kim, A Hellas, S Bernstein, S Sarsa, 10.1145/3545947.3569630Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2, ACM. the 54th ACM Technical Symposium on Computer Science Education V. 2, ACM2022b</p>
<p>Generating diverse code explanations using the gpt-3 large language model. S Macneil, A Tran, D Mogil, S Bernstein, E Ross, Z Huang, Proceedings of the 2022 ACM Conference on International Computing Education Research. the 2022 ACM Conference on International Computing Education ResearchNew York, NY, USAAssociation for Computing Machinery2022c2</p>
<p>Learning performance-improving code edits. A Madaan, A Shypula, U Alon, M Hashemi, P Ranganathan, Y Yang, G Neubig, A Yazdanbakhsh, 2302.078672023</p>
<p>Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models. P Maddigan, T Susnjak, 2302.020942023</p>
<p>The vault: A comprehensive multilingual dataset for advancing code understanding and generation. D N Manh, N L Hai, Atv Dau, A M Nguyen, K Nghiem, J Guo, Ndq Bui, 2305.061562023</p>
<p>Using version control and issue tickets to detect code debt and economical cost. A A Maruf, N Lambaria, A S Abdelfattah, T Cerný, 10.1109/ASE51524.2021.967853236th IEEE/ACM International Conference on Automated Software Engineering, ASE 2021. Melbourne, AustraliaIEEE2021. November 15-19, 2021</p>
<p>Studying the usage of text-to-text transfer transformer to support code-related tasks. A Mastropaolo, S Scalabrino, N Cooper, Nader Palacio, D Poshyvanyk, D Oliveto, R Bavota, G , 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). 2021</p>
<p>An empirical survey of the effectiveness of debiasing techniques for pre-trained language models. N Meade, E Poole-Dayan, S Reddy, 2110.085272022</p>
<p>Augmented language models: a survey. G Mialon, R Dessì, M Lomeli, C Nalmpantis, R Pasunuru, R Raileanu, B Rozière, T Schick, J Dwivedi-Yu, A Celikyilmaz, E Grave, Y Lecun, T Scialom, 2302.078422023</p>
<p>Recent advances in natural language processing via large pre-trained language models: A survey. B Min, H Ross, E Sulem, Apb Veyseh, T H Nguyen, O Sainz, E Agirre, I Heintz, D Roth, 10.1145/3605943ACM Comput Surv. 2023</p>
<p>A simple, yet effective approach to finding biases in code generation. S Mouselinos, M Malinowski, H Michalewski, 2211.006092023</p>
<p>Codecompose: A large-scale industrial deployment of ai-assisted code authoring. V Murali, C Maddila, I Ahmad, M Bolin, D Cheng, N Ghorbani, R Fernandez, N Nagappan, 2305.120502023</p>
<p>Combining program analysis and statistical language model for code statement completion. S Nguyen, T Nguyen, Y Li, S Wang, 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). 2019. 2019</p>
<p>Lever: Learning to verify language-to-code generation with execution. A Ni, S Iyer, D Radev, V Stoyanov, W Tau Yih, S I Wang, X V Lin, 2302.084682023</p>
<p>Modeling parallel programs using large language models. D Nichols, A Marathe, H Menon, T Gamblin, A Bhatele, 2023. 230617281</p>
<p>Codegen: An open large language model for code with multi-turn program synthesis. E Nijkamp, B Pang, H Hayashi, L Tu, H Wang, Y Zhou, S Savarese, C Xiong, The Eleventh International Conference on Learning Representations, ICLR 2023. Kigali, Rwanda2023. May 1-5, 2023</p>
<p>Spt-code: sequence-to-sequence pre-training for learning source code representations. C Niu, C Li, V Ng, J Ge, L Huang, B Luo, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022</p>
<p>Can large language models find and fix vulnerable software?. D Noever, 2308.103452023</p>
<p>Demystifying gpt self-repair for code generation. T X Olausson, J P Inala, C Wang, J Gao, A Solar-Lezama, 2306.098962023</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 352022</p>
<p>Application of large language models to software engineering tasks: Opportunities, risks, and implications. I Ozkaya, 10.1109/MS.2023.3248401IEEE Software. 4032023</p>
<p>Understanding the effectiveness of large language models in code translation. R Pan, A R Ibrahimzada, R Krishna, D Sankar, L P Wassi, M Merler, B Sobolev, R Pavuluri, S Sinha, R Jabbarvand, 2308.031092023</p>
<p>Lost in translation: A study of bugs introduced by large language models while translating code. R Pan, A Ibrahimzada, R Krishna, D Sankar, L Wassi, M Merler, B Sobolev, R Pavuluri, S Sinha, R Jabbarvand, 2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE). 2024</p>
<p>Examining zero-shot vulnerability repair with large language models. H Pearce, B Tan, B Ahmad, R Karri, B Dolan-Gavitt, 2112.021252022a</p>
<p>Pop quiz! can a large language model help with reverse engineering?. H Pearce, B Tan, P Krishnamurthy, F Khorrami, R Karri, B Dolan-Gavitt, 2202.011422022b</p>
<p>Synchromesh: Reliable code generation from pre-trained language models. G Poesia, O Polozov, V Le, A Tiwari, G Soares, C Meek, S Gulwani, 2201.112272022</p>
<p>Codewalk: Facilitating shared awareness in mixed-ability collaborative software development. V Potluri, M Pandey, A Begel, M Barnett, S Reitherman, 10.1145/3517428.3544812Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility, ASSETS 2022. J Froehlich, K Shinohara, S Ludi, the 24th International ACM SIGACCESS Conference on Computers and Accessibility, ASSETS 2022Athens, GreeceACM2022. October 23-26, 20222016</p>
<p>Can openai's codex fix bugs? an evaluation on quixbugs. J A Prenner, H Babii, R Robbes, Proceedings of the Third International Workshop on Automated Program Repair. the Third International Workshop on Automated Program RepairNew York, NY, USAAssociation for Computing Machinery2022</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, T Salimans, I Sutskever, 2018</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI blog. 1892019</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, The Journal of Machine Learning Research. 2112020</p>
<p>Evaluating the text-to-sql capabilities of large language models. N Rajkumar, R Li, D Bahdanau, 2204.004982022</p>
<p>Patient information organization in the intensive care setting: expert knowledge elicitation with card sorting methods. T J Reese, N Segall, P Nesbitt, G D Fiol, R Waller, B C Macpherson, J E Tonna, M C Wright, 10.1093/jamia/ocy045J Am Medical Informatics Assoc. 2582018</p>
<p>The programmer's assistant: Conversational interaction with a large language model for software development. S I Ross, F Martinez, S Houde, M Muller, J D Weisz, Proceedings of the 28th International Conference on Intelligent User Interfaces. the 28th International Conference on Intelligent User InterfacesNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Analysis of chatgpt on source code. A R Sadik, A Ceravola, F Joublin, J Patra, 2306.005972023</p>
<p>Lost at c: A user study on the security implications of large language model code assistants. G Sandoval, H Pearce, T Nys, R Karri, S Garg, B Dolan-Gavitt, 2208.097272023</p>
<p>Multitask prompted training enables zero-shot task generalization. V Sanh, A Webson, C Raffel, S H Bach, L Sutawika, Z Alyafeai, A Chaffin, A Stiegler, T L Scao, A Raja, arXiv:2110082072021arXiv preprint</p>
<p>What is it like to program with artificial intelligence?. A Sarkar, A D Gordon, C Negreanu, C Poelitz, S S Ragavan, B Zorn, 2208.062132022</p>
<p>Thrilled by your progress! large language models (GPT-4) no longer struggle to pass assessments in higher education programming courses. S Sarsa, P Denny, A Hellas, J Leinonen, J Savelka, A Agarwal, M An, C Bogart, M Sakr, 10.48550/arXiv.2306.10073Proceedings of the 2022 ACM Conference on International Computing Education Research. the 2022 ACM Conference on International Computing Education ResearchNew York, NY, USAAssociation for Computing Machinery2022. 2023. CoRR abs/2306.100731Automatic generation of programming exercises and code explanations using large language models</p>
<p>T L Scao, Fan A Akiki, C Pavlick, E Ilić, S Hesslow, D Castagné, R Luccioni, A S Yvon, F Gallé, M , arXiv:221105100A 176b-parameter open-access multilingual language model. Bloom2022arXiv preprint</p>
<p>M Shanahan, arXiv:221203551Talking about large language models. 2022arXiv preprint</p>
<p>Compressing pre-trained models of code into 3 mb. J Shi, Z Yang, B Xu, H J Kang, D Lo, Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. the 37th IEEE/ACM International Conference on Automated Software EngineeringAssociation for Computing Machinery202222</p>
<p>Exploring the robustness of large language models for solving programming problems. A Shirafuji, Y Watanobe, T Ito, M Morishita, Y Nakamura, Y Oda, J Suzuki, 2306.145832023</p>
<p>Repofusion: Training code models to understand your repository. D Shrivastava, D Kocetkov, H De Vries, D Bahdanau, T Scholak, 2306.109982023a</p>
<p>Repository-level prompt generation for large language models of code. D Shrivastava, H Larochelle, D Tarlow, 2206.128392023b</p>
<p>Chatgpt: A study on its utility for ubiquitous software engineering tasks. G Sridhara, G Rh, S Mazumdar, 2305.168372023</p>
<p>Automatic code summarization via chatgpt: How far are we?. W Sun, C Fang, Y You, Y Miao, Y Liu, Y Li, G Deng, S Huang, Y Chen, Q Zhang, H Qian, Y Liu, Z Chen, 2305.128652023</p>
<p>Inductive-bias learning: Generating code models with large language model. T Tanaka, N Emoto, T Yumibayashi, 2308.098902023</p>
<p>The science of detecting llm-generated texts. R Tang, Y N Chuang, X Hu, 2303.072052023a</p>
<p>Chatgpt vs sbst: A comparative assessment of unit test suite generation. Y Tang, Z Liu, Z Zhou, X Luo, 2307.005882023b</p>
<p>Y Tay, J Wei, H W Chung, V Q Tran, D R So, S Shakeri, X Garcia, H S Zheng, J Rao, A Chowdhery, arXiv:221011399Transcending scaling laws with 0.1% extra compute. 2022arXiv preprint</p>
<p>Benchmarking large language models for automated verilog rtl code generation. S Thakur, B Ahmad, Fan Z Pearce, H Tan, B Karri, R Dolan-Gavitt, B Garg, S , 10.23919/DATE56975.2023.101370862023 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE). 2023a</p>
<p>Benchmarking large language models for automated verilog rtl code generation. S Thakur, B Ahmad, Fan Z Pearce, H Tan, B Karri, R Dolan-Gavitt, B Garg, S , 2023 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE). 2023b</p>
<p>Others (2022) Lamda: Language models for dialog applications. R Thoppilan, D D Freitas, J Hall, N Shazeer, A Kulshreshtha, CoRR abs/2201.08239</p>
<p>Is chatgpt the ultimate programming assistant --how far is it?. H Tian, 2304.119382023</p>
<p>H Touvron, T Lavril, G Izacard, X Martinet, M A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, arXiv:230213971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>She elicits requirements and he tests: Software engineering gender bias in large language models. C Treude, H Hata, 2303.101312023</p>
<p>Llm4cbi: Taming llms to generate effective test programs for compiler bug isolation. H Tu, Z Zhou, H Jiang, Inb Yusuf, Y Li, L Jiang, 2307.005932023</p>
<p>Using pre-trained models to boost code review automation. R Tufano, S Masiero, A Mastropaolo, L Pascarella, D Poshyvanyk, G Bavota, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022</p>
<p>Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. P Vaithilingam, T Zhang, E L Glassman, Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. New York, NY, USAAssociation for Computing Machinery2022</p>
<p>Advances in neural information processing systems 30. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Kaiser␣l, I Polosukhin, 2017Attention is all you need</p>
<p>What do they capture? a structural analysis of pre-trained language models for source code. Y Wan, W Zhao, H Zhang, Y Sui, G Xu, Jin H , ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022</p>
<p>Pre-trained language models in biomedical domain: A systematic survey. B Wang, Q Xie, J Pei, Z Chen, P Tiwari, Z Li, J Fu, 2110.050062023a</p>
<p>Automatic generation of acceptance test cases from use case specifications: An nlp-based approach. C Wang, F Pastore, A Goknil, L C Briand, 10.1109/TSE.2020.2998503IEEE Trans Software Eng. 4822022a</p>
<p>Bridging pre-trained models and downstream tasks for source code understanding. D Wang, Z Jia, S Li, Y Yu, Y Xiong, W Dong, X Liao, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022b</p>
<p>Demo2code: From summarizing demonstrations to synthesizing. H Wang, G Gonzalez-Pumariega, Y Sharma, S ; Choudhury, L Wu, Z Zheng, Z Qiu, H Wang, H Gu, T Shen, C Qin, C Zhu, H Zhu, Q Liu, H Xiong, Chen E , 2023b. 2023. 2305. 19860A survey on large language models for recommendation</p>
<p>Conversational automated program repair. C S Xia, L Zhang, 2301.132462023a</p>
<p>Keep the conversation going: Fixing 162 out of 337 bugs for $0.42 each using chatgpt. C S Xia, L Zhang, 2304.003852023b</p>
<p>Practical program repair in the era of large pre-trained language models. C S Xia, Y Wei, L Zhang, 2210.141792022</p>
<p>Supporting qualitative analysis with large language models: Combining codebook with GPT-3 for deductive coding. Z Xiao, X Yuan, Q V Liao, R Abdelghani, P Y Oudeyer, 10.1145/3581754.358413628th International Conference on Intelligent User Interfaces. ACM2023</p>
<p>Prompt sapper: Llm-empowered software engineering infrastructure for ai-native services. Z Xing, Q Huang, Y Cheng, L Zhu, Q Lu, X Xu, 2306.022302023</p>
<p>Answerbot: automated generation of answer summary to developersź technical questions. B Xu, Z Xing, X Xia, D Lo, 10.1109/ASE.2017.8115681Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. G Rosu, M D Penta, T N Nguyen, the 32nd IEEE/ACM International Conference on Automated Software EngineeringUrbana, IL, USAIEEE Computer Society2017. 2017. October 30 -November 03, 2017</p>
<p>A survey on model compression and acceleration for pretrained language models. C Xu, J Mcauley, 10.1609/aaai.v37i9.26255Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Unilog: Automatic logging via llm and in-context learning. J Xu, Z Cui, Y Zhao, X Zhang, S He, P He, L Li, Y Kang, Q Lin, Y Dang, S Rajmohan, D Zhang, 2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE). 2024a</p>
<p>Divlog: Log parsing with prompt enhanced in-context learning. J Xu, R Yang, Y Huo, C Zhang, P ; He, X Xu, Z Zhang, S Feng, Y Ye, Z Su, N Jiang, S Cheng, L Tan, X Zhang, 2306.02546Lmpa: Improving decompilation by synergy of large language model and program analysis. 2024b. 20232024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)</p>
<p>Large language models for test-free fault localization. Azh Yang, R Martins, C L Goues, V J Hellendoorn, 2310.017262023a</p>
<p>Intercode: Standardizing and benchmarking interactive coding with execution feedback. J Yang, A Prabhakar, K Narasimhan, S Yao, 2306.148982023b</p>
<p>Natural attack for pre-trained models of code. Z Yang, J Shi, J He, D Lo, ICSE '22Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringAssociation for Computing Machinery2022</p>
<p>Unveiling memorization in code models. Z Yang, Z Zhao, C Wang, J Shi, D Kim, D Han, D Lo, 2023c</p>
<p>No more manual tests? evaluating and improving chatgpt for unit test generation. Z Yuan, Y Lou, M Liu, S Ding, K Wang, Y Chen, X Peng, 2305.042072023</p>
<p>Why johnny can't prompt: How non-ai experts try (and fail) to design llm prompts. J Zamfirescu-Pereira, R Y Wong, B Hartmann, Q Yang, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. the 2023 CHI Conference on Human Factors in Computing SystemsNew York, NY, USAAssociation for Computing Machinery2023</p>
<p>Large language models meet nl2code: A survey. D Zan, B Chen, F Zhang, D Lu, B Wu, B Guan, Y Wang, J G Lou, 2212.094202023</p>
<p>A Zeng, X Liu, Z Du, Z Wang, H Lai, M Ding, Z Yang, Y Xu, W Zheng, X Xia, arXiv:221002414Glm-130b: An open bilingual pre-trained model. 2022aarXiv preprint</p>
<p>An extensive study on pre-trained models for program understanding and generation. Z Zeng, H Tan, H Zhang, J Li, Y Zhang, L Zhang, ISSTA 20222022bAssociation for Computing Machinery</p>
<p>Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper). J Zhang, T Mytkowicz, M Kaufman, R Piskac, S K Lahiri, ISSTA 20222022aAssociation for Computing Machinery</p>
<p>Self-edit: Fault-aware code editor for code generation. K Zhang, Z Li, J Li, G Li, Jin Z , 2305.040872023a</p>
<p>Algo: Synthesizing algorithmic programs with generated oracle verifiers. K Zhang, D Wang, J Xia, W Y Wang, L Li, 2305.145912023b</p>
<p>Chatbot4qr: Interactive query refinement for technical question retrieval. N Zhang, Q Huang, X Xia, Y Zou, D Lo, Z Xing, 10.1109/TSE.2020.3016006IEEE Trans Software Eng. 4842022b</p>
<p>Multilingual large language models are not (yet) code-switchers. R Zhang, S Cahyawijaya, Jcb Cruz, A F Aji, 2305.142352023c</p>
<p>Opt: Open pre-trained transformer language models. S Zhang, S Roller, N Goyal, M Artetxe, M Chen, S Chen, C Dewan, M Diab, X Li, X V Lin, arXiv:2205010682022carXiv preprint</p>
<p>Learning-based widget matching for migrating gui test cases. Y Zhang, W Zhang, D Ran, Q Zhu, C Dou, D Hao, T Xie, L Zhang, 10.1145/3597503.3623322Proceedings of the 46th IEEE/ACM International Conference on Software Engineering, ACM, ICSE '24. the 46th IEEE/ACM International Conference on Software Engineering, ACM, ICSE '242024</p>
<p>Diet code is healthy: simplifying programs for pre-trained models of code. Z Zhang, H Zhang, B Shen, X Gu, ESEC/FSE 2022Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software EngineeringAssociation for Computing Machinery2022d</p>
<p>Understanding programs by exploiting (fuzzing) test cases. J Zhao, Y Rong, Y Guo, Y He, H Chen, 2305.135922023a</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, arXiv:230318223A survey of large language models. 2023barXiv preprint</p>
<p>Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x. CoRR abs/2303. Q Zheng, X Xia, X Zou, Y Dong, S Wang, Y Xue, Z Wang, L Shen, A Wang, Y Li, T Su, Z Yang, J Tang, 10.48550/arXiv.2303.17568202317568</p>
<p>A study on robustness and reliability of large language model code generation. L Zhong, Z Wang, 2308.103352023</p>
<p>How robust is a large pre-trained language model for code generationƒ a case on attacking gpt2. R Zhu, C Zhang, 10.1109/SANER56733.2023.000762023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). 2023</p>
<p>Large language models are state-of-the-art evaluators of code generation. T Y Zhuo, 2304.143172023</p>
<p>On robustness of prompt-based semantic parsing with large pre-trained language model: An empirical study on codex. T Y Zhuo, Z Li, Y Huang, F Shiri, W Wang, G Haffari, Y F Li, Proceedings of the 17th Conference of the European Chapter. the 17th Conference of the European ChapterDubrovnik, CroatiaAssociation for Computational Linguistics2023</p>            </div>
        </div>

    </div>
</body>
</html>