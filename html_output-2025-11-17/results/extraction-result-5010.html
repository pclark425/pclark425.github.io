<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5010 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5010</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5010</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-107.html">extraction-schema-107</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-260683273</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2308.03360v1.pdf" target="_blank">Coupling Symbolic Reasoning with Language Modeling for Efficient Longitudinal Understanding of Unstructured Electronic Medical Records</a></p>
                <p><strong>Paper Abstract:</strong> The application of Artificial Intelligence (AI) in healthcare has been revolutionary, especially with the recent advancements in transformer-based Large Language Models (LLMs). However, the task of understanding unstructured electronic medical records remains a challenge given the nature of the records (e.g., disorganization, inconsistency, and redundancy) and the inability of LLMs to derive reasoning paradigms that allow for comprehensive understanding of medical variables. In this work, we examine the power of coupling symbolic reasoning with language modeling toward improved understanding of unstructured clinical texts. We show that such a combination improves the extraction of several medical variables from unstructured records. In addition, we show that the state-of-the-art commercially-free LLMs enjoy retrieval capabilities comparable to those provided by their commercial counterparts. Finally, we elaborate on the need for LLM steering through the application of symbolic reasoning as the exclusive use of LLMs results in the lowest performance.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5010.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5010.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLP_REASONING</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NLP_REASONING (Symbolic reasoning + NLP abstraction pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>In-house clinical abstraction system that combines transformer-based entity/relation extraction with a proprietary medical ontology and rule-based symbolic reasoning to produce document-level object graphs and patient-level consolidated graphs for longitudinal medical understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NLP_REASONING (symbolic reasoning system)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hybrid pipeline that uses transformer-based sequence tagging for entities and relations, an ontology-driven rule-based voter and consolidator to produce document-level object graphs and patient-level heterogeneous graphs, and confidence scoring to resolve compatibility across objects.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Longitudinal medical abstraction / consolidation of 13 cancer-related variables across multiple unstructured clinical documents</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Extract and consolidate clinically relevant facts (Neoplasm, Morphology, T/N/M stage, Stage Group, Medications, Outcome, Response, Tested Biomarkers, Surgeries, Diagnostic Procedures, Cancer Diagnosis Date) from multi-document unstructured records by applying ontology-driven logical rules and compatibility constraints transitively across documents.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Rule-based symbolic reasoning operating on tag graphs produced by transformer-based entity/relation models; joins with a proprietary hierarchical medical ontology; document-level object graph creation; patient-level consolidation using a large set of logical rules, voting mechanisms, and confidence assignments. In experiments it is applied either on full records (baseline) or on LLM-retrieved/generated chunks/answers (RET_NLP_REASONING, GEN_NLP_REASONING, RET_GEN_NLP_REASONING).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline NLP_REASONING provides strong performance on many variables (selected F1-scores from Table 2: Neoplasm 91.50% F1, Morphology 78.90%, T-Stage 77.53%, N-Stage 71.69%, M-Stage 75.26%, Stage Group 66.50%, Medications 36.73%, Outcome 47.38%, Response 37.27%, Surgeries 76.09%, Diagnostic Procedures 24.69%, Tested Biomarkers 81.40%, Cancer Diagnosis Date 59.39%). Best system performance is typically achieved by coupling this symbolic reasoning with LLM retrieval/generation (varies per variable). Applying symbolic reasoning to LLM-produced chunks reduces compute and wall time.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reasoning component can be overwhelmed by excessive or noisy information (increasing false positives). Some variables scattered across records (e.g., Tested Biomarkers) remain challenging. Purely generative LLM outputs without symbolic consolidation produce unstructured answers and substantially worse overall abstraction performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Acts as the high-quality core; coupling with LLM retrieval often improves abstraction (e.g., retrieval aids T-Stage, Stage Group, Medications, Outcome), while generative LLM answers help in subjective or scattered low-precision cases (e.g., Response, Surgeries, Cancer Diagnosis Date). Exclusive use of LLMs as end-to-end (no NLP_REASONING) yields much lower performance (see GPT3.5 standalone result).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Applying NLP_REASONING on LLM-selected chunks reduces compute and can improve F1 for many variables versus applying NLP_REASONING on full records. Specific observed effects: RET_NLP_REASONING often improves T-Stage, Stage Group, Medications, Outcome; GEN_NLP_REASONING with GPT3.5 produced large relative F1 improvements for Surgeries (+35.31%), Response (+28.97%), and Cancer Diagnosis Date (+16.33%) where NLP_REASONING alone had low precision. Standalone GPT3.5 (no NLP_REASONING) caused a relative average F1 decrease of 64.72% compared to NLP_REASONING.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5010.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial autoregressive transformer-based generative language model used here for retrieval and generation of relevant chunks/answers for clinical abstraction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive transformer-based generative LLM used for both embedding/retrieval and answer generation; employed with tuned chunk sizes and temperature settings in retrieval/generation setups.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Medical abstraction of 13 cancer-related variables (applied as retrieval/generation component feeding NLP_REASONING); not a formal logical benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Retrieve semantically relevant text chunks for targeted clinical questions and/or generate concise answers for each question to be post-processed by symbolic reasoning; tasks require cross-document consolidation and disambiguation.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Used in RET_NLP_REASONING (retrieval), GEN_NLP_REASONING (answer generation), and RET_GEN_NLP_REASONING setups; outputs (chunks and/or answers) passed to the symbolic NLP_REASONING system.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>As a retrieval model, GPT3.5 produced RET_NLP_REASONING results that improved some variables (example RET_NLP_REASONING F1s: Morphology 80.70%, T-Stage 78.42%, N-Stage 74.72%). As a generator, GEN_NLP_REASONING with GPT3.5 had mixed results: improved Response and Surgeries substantially (and Cancer Diagnosis Date), but overall generated answers were 'less efficient' across many variables. Reported macro-averaged F1 for generations (across variables) places GPT3.5 above PaLM2; the paper lists a macro F1 of approximately 55.80% for GPT3.5-generated answers (relative ordering reported in text). Standalone GPT3.5 (no symbolic reasoning) produced a large drop: average F1 decreased by 64.72% relative to NLP_REASONING.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Generative inconsistencies (contradictory answers across questions), hallucinations when targeted answers not evident in text, confusion between patient-specific vs generic information; generated answers can confuse the downstream reasoning system when combined with retrieved chunks (increasing false positives).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Outperformed PaLM2 on generation in this task; retrieval performance comparable to other retrieval models (commercial-free models matched commercial ones). GPT3.5 as generator produced better results than PaLM2, and much better than Dolly2-12b and Falcon-7b-Instruct.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>GEN_NLP_REASONING with GPT3.5 produced significant relative F1 improvements for specific variables (Surgeries +35.31%, Response +28.97%, Cancer Diagnosis Date +16.33%). Standalone GPT3.5 (no symbolic reasoning) performed poorly, demonstrating the importance of symbolic steering.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5010.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PaLM 2, a commercial transformer-based LLM (Google), evaluated here for retrieval and generation of clinical information to feed a symbolic reasoning pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language model used for retrieval and generation; applied with chunking and temperature settings for generation in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Same clinical abstraction / longitudinal consolidation task of 13 cancer-related variables.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Retrieve relevant chunks and/or generate answers to targeted clinical questions; outputs are passed to symbolic NLP_REASONING for consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Used in retrieval (RET_NLP_REASONING), generation (GEN_NLP_REASONING), and combined setups; paired with ontology-driven symbolic consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Retrieval performance comparable to other retrieval LLMs (e.g., RET_NLP_REASONING PaLM2 F1 examples: Morphology 79.50%, T-Stage 81.89%). As a generator, PaLM2 underperformed GPT3.5 in this study; reported macro-averaged generation F1 ~53.66% (text reports GPT3.5 outperforms PaLM2 with macro F1s given as GPT3.5 55.80% and PaLM2 53.66%). In GEN_NLP_REASONING PaLM2 achieved some high F1 on Cancer Diagnosis Date (92.29% recall/other metrics shown) but inconsistent overall.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Generated responses exhibited inconsistencies across questions (e.g., contradictory cancer type in successive answers). Similar hallucination and confusion issues as other generative LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Retrieval: comparable to commercial-free retrieval models. Generation: slightly worse than GPT3.5 on average; better than Dolly2-12b and Falcon-7b-Instruct in many cases but variable across endpoints.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>In RET_GEN_NLP_REASONING, PaLM2 sometimes improved particular variables (see table cell-level results); however generated answers occasionally confused downstream reasoning when combined with retrieved chunks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5010.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ada2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ada2 (embedding/retrieval model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercially-free embedding/retrieval model used to retrieve semantically relevant chunks from preprocessed clinical documents; evaluated for retrieval performance feeding symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ada2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Embedding/retrieval model used to produce vector embeddings for semantic retrieval of document chunks (used in RET_NLP_REASONING).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Chunk retrieval for downstream symbolic consolidation in the 13-variable clinical abstraction task.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Select a small number of semantically relevant chunks per question (four chunks per question in experiments) so that NLP_REASONING operates on a compact, relevant subset rather than full records.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Embedding-based retrieval (semantic search) with chunk size tuned so combined tokens fit LLM limits; retrieved chunks passed to NLP_REASONING.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Retrieval F1s comparable to other retrieval models (example RET_NLP_REASONING ada2 F1s: Neoplasm 90.40%, Morphology 78.99%, T-Stage 74.34%, N-Stage 77.27%). Paper reports maximum difference of 3.46% in macro-averaged F1 across retrieval models (excluding Falcon) indicating ada2 performs similarly to commercial retrieval models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No specific failure modes beyond general retrieval limits; retrieval performance may be limited for variables whose evidence is widely scattered across documents.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>State-of-the-art commercially-free retrieval models (ada2, Instructor-XL, SGPT) performed comparably to commercial retrieval models (GPT3.5, PaLM2) in this task.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Using retrieval LLMs to preselect chunks reduced computation and improved abstraction on several variables; retrieval-only setups often outperformed generation-only setups for many structured variables.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5010.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instructor-XL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Instructor-XL (embedding model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-finetuned embedder used for semantic retrieval (and as the embedding generator when using Dolly2-12b in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Instructor-XL</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned embedding model (from HuggingFace repository) used to produce embeddings for semantic retrieval; used standalone for retrieval and to generate embeddings for Dolly2-12b experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Semantic retrieval supporting the clinical abstraction pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Produce embeddings of document chunks and questions to retrieve top-k relevant chunks for each clinical question.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Embedding-based semantic search integrated into RET_NLP_REASONING; in Dolly2-12b experiments Instructor-XL produced embeddings for retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Retrieval performance similar to other retrieval models (included in the RET_NLP_REASONING comparisons). The paper reports that Instructor-XL (commercially-free) performed comparably to GPT3.5 and PaLM2 retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No specific additional limitations reported beyond general retrieval shortcomings (scattered evidence across records).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Comparable retrieval performance to ada2, SGPT, GPT3.5, PaLM2; used to generate embeddings for Dolly2-12b due to Dolly's embedding limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Using Instructor-XL embeddings with Dolly2-12b was an experimental configuration noted in Methods; retrieval comparability implies embedding choice did not dramatically change retrieval F1 among top retrieval models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5010.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SGPT (sentence embeddings for semantic search)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embedding-based retrieval approach (SGPT) used to perform semantic chunk retrieval for targeted clinical questions feeding symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-based sentence embedding approach for semantic search used for retrieval of relevant chunks from preprocessed medical texts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Semantic retrieval in support of patient-level consolidation for the 13-variable clinical abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Identify semantically relevant chunks per question so symbolic reasoning operates on relevant evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Embedding-based retrieval (SGPT embeddings) used in RET_NLP_REASONING setup.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Retrieval results comparable to other retrieval models (example RET_NLP_REASONING SGPT F1s: Neoplasm 91.22%, Morphology 76.49%, T-Stage 78.00%). Paper reports small spread among top retrieval models (max ~3.46% macro F1 difference excluding Falcon).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limited when evidence is scattered across many documents; retrieval itself does not resolve cross-document logical inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Comparable to ada2 and Instructor-XL and to commercial retrieval models for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>No separate ablation, but overall retrieval-first pipelines show benefits in compute and in many structured variables relative to running symbolic reasoning on full records.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5010.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dolly2-12b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dolly v2 12B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source autoregressive generative LLM with 12B parameters used as a less-restricted generator in experiments; evaluated for generation (and paired with Instructor-XL embeddings for retrieval).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dolly2-12b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source 12-billion-parameter autoregressive LLM used for answer generation in GEN_NLP_REASONING and RET_GEN_NLP_REASONING; embeddings for Dolly experiments were produced using Instructor-XL.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>12B</td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Answer generation for clinical abstraction questions that are then passed to symbolic consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate answers to targeted clinical questions (31 question set) based on retrieved chunks; outputs then fed into symbolic reasoning to extract structured variables.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Generative LLM (temperature tuned) producing per-question answers; combined with symbolic reasoning in GEN_NLP_REASONING and RET_GEN_NLP_REASONING setups.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Underperformed compared to GPT3.5 and PaLM2 on generation tasks; paper reports macro-averaged generation F1 ≈ 32.03% for Dolly2-12b (text ordering indicates Dolly and Falcon fall behind GPT3.5/PaLM2 with macro F1s 32.03% and 18.31% respectively). Per-variable GEN_NLP_REASONING F1s were generally low (examples: Neoplasm 60.40% F1, Morphology 61.65%, many variables much lower).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Poor generation quality for extraction tasks, hallucinations and inconsistencies leading to low F1; less restricted model output increased noise for downstream symbolic processing.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Worse than GPT3.5 and PaLM2 on generation; when combined in RET_GEN_NLP_REASONING sometimes retrieval compensated but overall performance lagged.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Using Instructor-XL embeddings for retrieval when pairing with Dolly2-12b was noted, but generation quality remained a bottleneck and degraded downstream symbolic reasoning performance relative to stronger generators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5010.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5010.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Falcon-7b-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Falcon-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7-billion-parameter open-source instruct-tuned transformer LLM evaluated for retrieval and generation; performed poorly on generation-based clinical abstraction in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Falcon-7b-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruct-tuned 7B-parameter transformer model used for retrieval (embeddings) and generation experiments with tuned chunk sizes and temperature.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>Generation and retrieval for the clinical abstraction pipeline of 13 cancer-related variables.</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Used to retrieve relevant chunks and/or generate answers to clinical questions; outputs integrated into symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Applied as both retrieval and generative component in RET_NLP_REASONING, GEN_NLP_REASONING, RET_GEN_NLP_REASONING setups.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Performed worst among evaluated generation models in this study: paper reports macro-averaged generation F1 ≈ 18.31% for Falcon-7b-Instruct. GEN_NLP_REASONING F1s are very low for many variables (examples: Morphology 21.76% F1, T-Stage 22.50%, N-Stage 0.00% for one reported cell). Retrieval performance was somewhat closer to others but still variable.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Poor generation quality, inconsistent and low-accuracy answers causing degraded downstream symbolic reasoning; suffered most in generation-led setups.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Substantially worse for generation than GPT3.5 and PaLM2; retrieval-only performance was closer but overall model underperformed in mixed setups.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Including Falcon-7b-Instruct in retrieval comparisons increases variance; paper excludes Falcon from some aggregated retrieval stability claims due to its lower performance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Faithful reasoning using large language models <em>(Rating: 2)</em></li>
                <li>Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change) <em>(Rating: 2)</em></li>
                <li>Faith and Fate: Limits of Transformers on Compositionality <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5010",
    "paper_id": "paper-260683273",
    "extraction_schema_id": "extraction-schema-107",
    "extracted_data": [
        {
            "name_short": "NLP_REASONING",
            "name_full": "NLP_REASONING (Symbolic reasoning + NLP abstraction pipeline)",
            "brief_description": "In-house clinical abstraction system that combines transformer-based entity/relation extraction with a proprietary medical ontology and rule-based symbolic reasoning to produce document-level object graphs and patient-level consolidated graphs for longitudinal medical understanding.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NLP_REASONING (symbolic reasoning system)",
            "model_description": "A hybrid pipeline that uses transformer-based sequence tagging for entities and relations, an ontology-driven rule-based voter and consolidator to produce document-level object graphs and patient-level heterogeneous graphs, and confidence scoring to resolve compatibility across objects.",
            "model_size": null,
            "logical_reasoning_task": "Longitudinal medical abstraction / consolidation of 13 cancer-related variables across multiple unstructured clinical documents",
            "task_description": "Extract and consolidate clinically relevant facts (Neoplasm, Morphology, T/N/M stage, Stage Group, Medications, Outcome, Response, Tested Biomarkers, Surgeries, Diagnostic Procedures, Cancer Diagnosis Date) from multi-document unstructured records by applying ontology-driven logical rules and compatibility constraints transitively across documents.",
            "method_or_approach": "Rule-based symbolic reasoning operating on tag graphs produced by transformer-based entity/relation models; joins with a proprietary hierarchical medical ontology; document-level object graph creation; patient-level consolidation using a large set of logical rules, voting mechanisms, and confidence assignments. In experiments it is applied either on full records (baseline) or on LLM-retrieved/generated chunks/answers (RET_NLP_REASONING, GEN_NLP_REASONING, RET_GEN_NLP_REASONING).",
            "performance": "Baseline NLP_REASONING provides strong performance on many variables (selected F1-scores from Table 2: Neoplasm 91.50% F1, Morphology 78.90%, T-Stage 77.53%, N-Stage 71.69%, M-Stage 75.26%, Stage Group 66.50%, Medications 36.73%, Outcome 47.38%, Response 37.27%, Surgeries 76.09%, Diagnostic Procedures 24.69%, Tested Biomarkers 81.40%, Cancer Diagnosis Date 59.39%). Best system performance is typically achieved by coupling this symbolic reasoning with LLM retrieval/generation (varies per variable). Applying symbolic reasoning to LLM-produced chunks reduces compute and wall time.",
            "limitations_or_failure_cases": "Reasoning component can be overwhelmed by excessive or noisy information (increasing false positives). Some variables scattered across records (e.g., Tested Biomarkers) remain challenging. Purely generative LLM outputs without symbolic consolidation produce unstructured answers and substantially worse overall abstraction performance.",
            "comparison": "Acts as the high-quality core; coupling with LLM retrieval often improves abstraction (e.g., retrieval aids T-Stage, Stage Group, Medications, Outcome), while generative LLM answers help in subjective or scattered low-precision cases (e.g., Response, Surgeries, Cancer Diagnosis Date). Exclusive use of LLMs as end-to-end (no NLP_REASONING) yields much lower performance (see GPT3.5 standalone result).",
            "ablation_or_analysis_results": "Applying NLP_REASONING on LLM-selected chunks reduces compute and can improve F1 for many variables versus applying NLP_REASONING on full records. Specific observed effects: RET_NLP_REASONING often improves T-Stage, Stage Group, Medications, Outcome; GEN_NLP_REASONING with GPT3.5 produced large relative F1 improvements for Surgeries (+35.31%), Response (+28.97%), and Cancer Diagnosis Date (+16.33%) where NLP_REASONING alone had low precision. Standalone GPT3.5 (no NLP_REASONING) caused a relative average F1 decrease of 64.72% compared to NLP_REASONING.",
            "uuid": "e5010.0"
        },
        {
            "name_short": "GPT3.5",
            "name_full": "GPT-3.5 (OpenAI)",
            "brief_description": "A commercial autoregressive transformer-based generative language model used here for retrieval and generation of relevant chunks/answers for clinical abstraction tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT3.5",
            "model_description": "Autoregressive transformer-based generative LLM used for both embedding/retrieval and answer generation; employed with tuned chunk sizes and temperature settings in retrieval/generation setups.",
            "model_size": null,
            "logical_reasoning_task": "Medical abstraction of 13 cancer-related variables (applied as retrieval/generation component feeding NLP_REASONING); not a formal logical benchmark.",
            "task_description": "Retrieve semantically relevant text chunks for targeted clinical questions and/or generate concise answers for each question to be post-processed by symbolic reasoning; tasks require cross-document consolidation and disambiguation.",
            "method_or_approach": "Used in RET_NLP_REASONING (retrieval), GEN_NLP_REASONING (answer generation), and RET_GEN_NLP_REASONING setups; outputs (chunks and/or answers) passed to the symbolic NLP_REASONING system.",
            "performance": "As a retrieval model, GPT3.5 produced RET_NLP_REASONING results that improved some variables (example RET_NLP_REASONING F1s: Morphology 80.70%, T-Stage 78.42%, N-Stage 74.72%). As a generator, GEN_NLP_REASONING with GPT3.5 had mixed results: improved Response and Surgeries substantially (and Cancer Diagnosis Date), but overall generated answers were 'less efficient' across many variables. Reported macro-averaged F1 for generations (across variables) places GPT3.5 above PaLM2; the paper lists a macro F1 of approximately 55.80% for GPT3.5-generated answers (relative ordering reported in text). Standalone GPT3.5 (no symbolic reasoning) produced a large drop: average F1 decreased by 64.72% relative to NLP_REASONING.",
            "limitations_or_failure_cases": "Generative inconsistencies (contradictory answers across questions), hallucinations when targeted answers not evident in text, confusion between patient-specific vs generic information; generated answers can confuse the downstream reasoning system when combined with retrieved chunks (increasing false positives).",
            "comparison": "Outperformed PaLM2 on generation in this task; retrieval performance comparable to other retrieval models (commercial-free models matched commercial ones). GPT3.5 as generator produced better results than PaLM2, and much better than Dolly2-12b and Falcon-7b-Instruct.",
            "ablation_or_analysis_results": "GEN_NLP_REASONING with GPT3.5 produced significant relative F1 improvements for specific variables (Surgeries +35.31%, Response +28.97%, Cancer Diagnosis Date +16.33%). Standalone GPT3.5 (no symbolic reasoning) performed poorly, demonstrating the importance of symbolic steering.",
            "uuid": "e5010.1"
        },
        {
            "name_short": "PaLM2",
            "name_full": "PaLM 2",
            "brief_description": "PaLM 2, a commercial transformer-based LLM (Google), evaluated here for retrieval and generation of clinical information to feed a symbolic reasoning pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "PaLM2",
            "model_description": "Transformer-based large language model used for retrieval and generation; applied with chunking and temperature settings for generation in experiments.",
            "model_size": null,
            "logical_reasoning_task": "Same clinical abstraction / longitudinal consolidation task of 13 cancer-related variables.",
            "task_description": "Retrieve relevant chunks and/or generate answers to targeted clinical questions; outputs are passed to symbolic NLP_REASONING for consolidation.",
            "method_or_approach": "Used in retrieval (RET_NLP_REASONING), generation (GEN_NLP_REASONING), and combined setups; paired with ontology-driven symbolic consolidation.",
            "performance": "Retrieval performance comparable to other retrieval LLMs (e.g., RET_NLP_REASONING PaLM2 F1 examples: Morphology 79.50%, T-Stage 81.89%). As a generator, PaLM2 underperformed GPT3.5 in this study; reported macro-averaged generation F1 ~53.66% (text reports GPT3.5 outperforms PaLM2 with macro F1s given as GPT3.5 55.80% and PaLM2 53.66%). In GEN_NLP_REASONING PaLM2 achieved some high F1 on Cancer Diagnosis Date (92.29% recall/other metrics shown) but inconsistent overall.",
            "limitations_or_failure_cases": "Generated responses exhibited inconsistencies across questions (e.g., contradictory cancer type in successive answers). Similar hallucination and confusion issues as other generative LLMs.",
            "comparison": "Retrieval: comparable to commercial-free retrieval models. Generation: slightly worse than GPT3.5 on average; better than Dolly2-12b and Falcon-7b-Instruct in many cases but variable across endpoints.",
            "ablation_or_analysis_results": "In RET_GEN_NLP_REASONING, PaLM2 sometimes improved particular variables (see table cell-level results); however generated answers occasionally confused downstream reasoning when combined with retrieved chunks.",
            "uuid": "e5010.2"
        },
        {
            "name_short": "ada2",
            "name_full": "ada2 (embedding/retrieval model)",
            "brief_description": "A commercially-free embedding/retrieval model used to retrieve semantically relevant chunks from preprocessed clinical documents; evaluated for retrieval performance feeding symbolic reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ada2",
            "model_description": "Embedding/retrieval model used to produce vector embeddings for semantic retrieval of document chunks (used in RET_NLP_REASONING).",
            "model_size": null,
            "logical_reasoning_task": "Chunk retrieval for downstream symbolic consolidation in the 13-variable clinical abstraction task.",
            "task_description": "Select a small number of semantically relevant chunks per question (four chunks per question in experiments) so that NLP_REASONING operates on a compact, relevant subset rather than full records.",
            "method_or_approach": "Embedding-based retrieval (semantic search) with chunk size tuned so combined tokens fit LLM limits; retrieved chunks passed to NLP_REASONING.",
            "performance": "Retrieval F1s comparable to other retrieval models (example RET_NLP_REASONING ada2 F1s: Neoplasm 90.40%, Morphology 78.99%, T-Stage 74.34%, N-Stage 77.27%). Paper reports maximum difference of 3.46% in macro-averaged F1 across retrieval models (excluding Falcon) indicating ada2 performs similarly to commercial retrieval models.",
            "limitations_or_failure_cases": "No specific failure modes beyond general retrieval limits; retrieval performance may be limited for variables whose evidence is widely scattered across documents.",
            "comparison": "State-of-the-art commercially-free retrieval models (ada2, Instructor-XL, SGPT) performed comparably to commercial retrieval models (GPT3.5, PaLM2) in this task.",
            "ablation_or_analysis_results": "Using retrieval LLMs to preselect chunks reduced computation and improved abstraction on several variables; retrieval-only setups often outperformed generation-only setups for many structured variables.",
            "uuid": "e5010.3"
        },
        {
            "name_short": "Instructor-XL",
            "name_full": "Instructor-XL (embedding model)",
            "brief_description": "An instruction-finetuned embedder used for semantic retrieval (and as the embedding generator when using Dolly2-12b in experiments).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Instructor-XL",
            "model_description": "Instruction-finetuned embedding model (from HuggingFace repository) used to produce embeddings for semantic retrieval; used standalone for retrieval and to generate embeddings for Dolly2-12b experiments.",
            "model_size": null,
            "logical_reasoning_task": "Semantic retrieval supporting the clinical abstraction pipeline.",
            "task_description": "Produce embeddings of document chunks and questions to retrieve top-k relevant chunks for each clinical question.",
            "method_or_approach": "Embedding-based semantic search integrated into RET_NLP_REASONING; in Dolly2-12b experiments Instructor-XL produced embeddings for retrieval.",
            "performance": "Retrieval performance similar to other retrieval models (included in the RET_NLP_REASONING comparisons). The paper reports that Instructor-XL (commercially-free) performed comparably to GPT3.5 and PaLM2 retrieval.",
            "limitations_or_failure_cases": "No specific additional limitations reported beyond general retrieval shortcomings (scattered evidence across records).",
            "comparison": "Comparable retrieval performance to ada2, SGPT, GPT3.5, PaLM2; used to generate embeddings for Dolly2-12b due to Dolly's embedding limitations.",
            "ablation_or_analysis_results": "Using Instructor-XL embeddings with Dolly2-12b was an experimental configuration noted in Methods; retrieval comparability implies embedding choice did not dramatically change retrieval F1 among top retrieval models.",
            "uuid": "e5010.4"
        },
        {
            "name_short": "SGPT",
            "name_full": "SGPT (sentence embeddings for semantic search)",
            "brief_description": "An embedding-based retrieval approach (SGPT) used to perform semantic chunk retrieval for targeted clinical questions feeding symbolic reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "SGPT",
            "model_description": "GPT-based sentence embedding approach for semantic search used for retrieval of relevant chunks from preprocessed medical texts.",
            "model_size": null,
            "logical_reasoning_task": "Semantic retrieval in support of patient-level consolidation for the 13-variable clinical abstraction.",
            "task_description": "Identify semantically relevant chunks per question so symbolic reasoning operates on relevant evidence.",
            "method_or_approach": "Embedding-based retrieval (SGPT embeddings) used in RET_NLP_REASONING setup.",
            "performance": "Retrieval results comparable to other retrieval models (example RET_NLP_REASONING SGPT F1s: Neoplasm 91.22%, Morphology 76.49%, T-Stage 78.00%). Paper reports small spread among top retrieval models (max ~3.46% macro F1 difference excluding Falcon).",
            "limitations_or_failure_cases": "Limited when evidence is scattered across many documents; retrieval itself does not resolve cross-document logical inconsistencies.",
            "comparison": "Comparable to ada2 and Instructor-XL and to commercial retrieval models for this task.",
            "ablation_or_analysis_results": "No separate ablation, but overall retrieval-first pipelines show benefits in compute and in many structured variables relative to running symbolic reasoning on full records.",
            "uuid": "e5010.5"
        },
        {
            "name_short": "Dolly2-12b",
            "name_full": "Dolly v2 12B",
            "brief_description": "An open-source autoregressive generative LLM with 12B parameters used as a less-restricted generator in experiments; evaluated for generation (and paired with Instructor-XL embeddings for retrieval).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Dolly2-12b",
            "model_description": "Open-source 12-billion-parameter autoregressive LLM used for answer generation in GEN_NLP_REASONING and RET_GEN_NLP_REASONING; embeddings for Dolly experiments were produced using Instructor-XL.",
            "model_size": "12B",
            "logical_reasoning_task": "Answer generation for clinical abstraction questions that are then passed to symbolic consolidation.",
            "task_description": "Generate answers to targeted clinical questions (31 question set) based on retrieved chunks; outputs then fed into symbolic reasoning to extract structured variables.",
            "method_or_approach": "Generative LLM (temperature tuned) producing per-question answers; combined with symbolic reasoning in GEN_NLP_REASONING and RET_GEN_NLP_REASONING setups.",
            "performance": "Underperformed compared to GPT3.5 and PaLM2 on generation tasks; paper reports macro-averaged generation F1 ≈ 32.03% for Dolly2-12b (text ordering indicates Dolly and Falcon fall behind GPT3.5/PaLM2 with macro F1s 32.03% and 18.31% respectively). Per-variable GEN_NLP_REASONING F1s were generally low (examples: Neoplasm 60.40% F1, Morphology 61.65%, many variables much lower).",
            "limitations_or_failure_cases": "Poor generation quality for extraction tasks, hallucinations and inconsistencies leading to low F1; less restricted model output increased noise for downstream symbolic processing.",
            "comparison": "Worse than GPT3.5 and PaLM2 on generation; when combined in RET_GEN_NLP_REASONING sometimes retrieval compensated but overall performance lagged.",
            "ablation_or_analysis_results": "Using Instructor-XL embeddings for retrieval when pairing with Dolly2-12b was noted, but generation quality remained a bottleneck and degraded downstream symbolic reasoning performance relative to stronger generators.",
            "uuid": "e5010.6"
        },
        {
            "name_short": "Falcon-7b-Instruct",
            "name_full": "Falcon-7B-Instruct",
            "brief_description": "A 7-billion-parameter open-source instruct-tuned transformer LLM evaluated for retrieval and generation; performed poorly on generation-based clinical abstraction in this study.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Falcon-7b-Instruct",
            "model_description": "Instruct-tuned 7B-parameter transformer model used for retrieval (embeddings) and generation experiments with tuned chunk sizes and temperature.",
            "model_size": "7B",
            "logical_reasoning_task": "Generation and retrieval for the clinical abstraction pipeline of 13 cancer-related variables.",
            "task_description": "Used to retrieve relevant chunks and/or generate answers to clinical questions; outputs integrated into symbolic reasoning.",
            "method_or_approach": "Applied as both retrieval and generative component in RET_NLP_REASONING, GEN_NLP_REASONING, RET_GEN_NLP_REASONING setups.",
            "performance": "Performed worst among evaluated generation models in this study: paper reports macro-averaged generation F1 ≈ 18.31% for Falcon-7b-Instruct. GEN_NLP_REASONING F1s are very low for many variables (examples: Morphology 21.76% F1, T-Stage 22.50%, N-Stage 0.00% for one reported cell). Retrieval performance was somewhat closer to others but still variable.",
            "limitations_or_failure_cases": "Poor generation quality, inconsistent and low-accuracy answers causing degraded downstream symbolic reasoning; suffered most in generation-led setups.",
            "comparison": "Substantially worse for generation than GPT3.5 and PaLM2; retrieval-only performance was closer but overall model underperformed in mixed setups.",
            "ablation_or_analysis_results": "Including Falcon-7b-Instruct in retrieval comparisons increases variance; paper excludes Falcon from some aggregated retrieval stability claims due to its lower performance.",
            "uuid": "e5010.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Faithful reasoning using large language models",
            "rating": 2,
            "sanitized_title": "faithful_reasoning_using_large_language_models"
        },
        {
            "paper_title": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)",
            "rating": 2,
            "sanitized_title": "large_language_models_still_cant_plan_a_benchmark_for_llms_on_planning_and_reasoning_about_change"
        },
        {
            "paper_title": "Faith and Fate: Limits of Transformers on Compositionality",
            "rating": 2,
            "sanitized_title": "faith_and_fate_limits_of_transformers_on_compositionality"
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1,
            "sanitized_title": "language_models_are_fewshot_learners"
        }
    ],
    "cost": 0.016652,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Coupling Symbolic Reasoning with Language Modeling for Efficient Longitudinal Understanding of Unstructured Electronic Medical Records</p>
<p>Shivani Shekhar shivani.s@mendel.ai 
Simran Tiwari simran.t@mendel.ai 
T C Rensink 
Ramy Eskander ramy.e@mendel.ai 
Wael Salloum </p>
<p>Mendel Health Inc. California
USA</p>
<p>Mendel Health Inc. California
USA</p>
<p>Mendel Health Inc. California
USA</p>
<p>Mendel Health Inc
New YorkUSA</p>
<p>Mendel Health Inc. California
USA</p>
<p>Coupling Symbolic Reasoning with Language Modeling for Efficient Longitudinal Understanding of Unstructured Electronic Medical Records
CCS CONCEPTSComputing methodologies ! Artificial intelligence;Applied computing ! Health informatics KEYWORDS AI in Healthcare, Symbolic Reasoning, Generative Language Mod- els, Natural Language Processing, Unstructured Electronic Medical Records
The application of Artificial Intelligence (AI) in healthcare has been revolutionary, especially with the recent advancements in transformer-based Large Language Models (LLMs). However, the task of understanding unstructured electronic medical records remains a challenge given the nature of the records (e.g., disorganization, inconsistency, and redundancy) and the inability of LLMs to derive reasoning paradigms that allow for comprehensive understanding of medical variables. In this work, we examine the power of coupling symbolic reasoning with language modeling toward improved understanding of unstructured clinical texts. We show that such a combination improves the extraction of several medical variables from unstructured records. In addition, we show that the state-of-the-art commercially-free LLMs enjoy retrieval capabilities comparable to those provided by their commercial counterparts. Finally, we elaborate on the need for LLM steering through the application of symbolic reasoning as the exclusive use of LLMs results in the lowest performance.</p>
<p>INTRODUCTION</p>
<p>Clinical language is convoluted as patient records often contain discrepancies that require human expertise to decode. For instance, Seizures can either be a symptom or a side effect, while a pathology report indicating cancer of some stage might conflict with a doctor's note indicating a different one. In addition, patient records are often unstructured and involve materials irrelevant to the patient journey; examples include routine forms and generic medical references, such as a listing of possible side effects. While Artificial Intelligence (AI) has been shaping a pivotal shift in the healthcare industry [30,32], ⇤ These two authors contributed equally to the work. the aforementioned challenges limit the capabilities of AI in clinical abstraction.</p>
<p>Transformer-based Large Language Models (LLMs), autoregressive generative models in particular, have been revolutionizing the role of AI in several industries, one of which is healthcare [4,21,31]. LLMs have proved exceptional capabilities at both retrieval and generation, where they might replace whole machine learning pipelines of complex architectures. Yet, generative LLMs surprisingly fail at solving trivial tasks. This is mainly due to the fact that those models tend to memorize sequences of operations in a shallow learning manner rather than composing proper reasoning paradigms that reflect holistic task understanding [6,10,36].</p>
<p>In this work, we examine the power of coupling symbolic reasoning (symbolic AI) with language modeling to better utilize the retrieval and generation capabilities of LLMs towards an improved understanding of unstructured electronic medical records. We achieve this by leveraging state-of-the-art LLMs within a clinical abstraction pipeline whose core understanding component utilizes both Natural Language Processing (NLP) and symbolic reasoning, denoted by NLP_REASONING. We compare NLP_REASONING to the following three setups:</p>
<p>(1) RET_LLM_NLP_REASONING: An LLM-based setup that employs NLP_REASONING on top of chunks retrieved by retrieval LLMs. In addition, we conduct an additional experiment in which a generative LLM is utilized as an end-to-end solution that replaces NLP_REASONING.</p>
<p>Our contribution in this paper is threefold:</p>
<p>(1) We assess the power of coupling symbolic reasoning with language modeling for the longitudinal understanding of unstructured electronic medical records. (2) We compare several state-of-the-art LLMs in terms of their retrieval and generation capabilities.</p>
<p>(3) We manually assess the performance of generative LLMs as a standalone system that replaces an established architecture that leverages symbolic reasoning.</p>
<p>Evaluating our abstraction pipeline on the extraction of 13 cancerrelated medical variables from unstructured medical records shows that the best solution is one that combines symbolic reasoning with language modeling, where the understanding of several medical variables benefits from the retrieval and generation capabilities of LLMs. In addition, applying symbolic reasoning on chunks and answers produced by LLMs instead of full records decreases compute cost and time. We also show that the state-of-the-art commercially-free retrieval LLMs perform as well as their commercial counterparts. At last, we highlight the necessity of symbolic reasoning as an LLM steering mechanism as solely relying on generative LLMs for medical abstraction significantly lowers the performance .</p>
<p>RELATED WORK</p>
<p>Over the past decade, Artificial Intelligence (AI) has proved successful in healthcare through an enormous number of applications [28] that save enormous clinical work and improve patient journey. Example applications include prediction of disease outbreaks, such as Malaria [35] and COVID-19 [14], prediction of diseases through genomic analyses [9,22], improvement of mental health [11,16], drug discovery [5,7,25,29], AI-based chatbots in healthcare [2,8,13,27] and disease diagnosis [20,33], especially for cancer [12,[17][18][19].</p>
<p>Applying AI for the processing of electronic medical records has been receiving increasing interest, especially in the case of unstructured records [15,23,24]. Such records, while containing valuable information, remain difficult to process, which necessitates the use of AI for the segmentation, classification and parsing of the documents prior to extracting the valuable information and ingesting them into downstream applications. In this paper, we discuss how to leverage NLP, symbolic reasoning and LLMs for the longitudinal understanding of unstructured clinical texts.</p>
<p>AI in healthcare is now attracting a bigger community given the recent revolutionary advancements in transformer-based Large Language Models (LLMs) [4,21,31], especially autoregressive generative models, such as the GPT-family models [3] and PaLM [1]. Such widespread interest is attributed to the current commoditization of such models, along with the ability to pursue customization through fine-tuning with custom data. However, LLMs come with limitations as they are unable to process complex logic and perform robust generalization, which hinders the proper understanding and processing of complex inputs [6,10,36]. Accordingly, we assess the use of LLMs in conjunction with symbolic reasoning towards better understanding of challenging clinical texts.</p>
<p>METHODS</p>
<p>The input to our clinical abstraction pipeline is a set of unstructured electronic medical records that belong to some patient and come in image and PDF formats, while our output is structured medical variables describing the patient journey.</p>
<p>Next, we describe our clinical abstraction pipeline (See Appendix A.1). This includes the preprocessing of the unstructured medical records and our core abstraction system that leverages both NLP and symbolic reasoning, denoted by NLP_REASONING. We then describe three setups that utilize LLMs for both retrieval and generation within our pipeline.</p>
<p>Preprocessing</p>
<p>3.1.1 Optical Character Recognition (OCR). We utilize an inhouse OCR system to convert the input images of medical records into texts ready to be ingested for processing.</p>
<p>3.1.2 De-identification. We employ a transformer-based sequence tagging architecture for the redaction of Protected Health Information (PHI) in the texts extracted by the OCR module to comply with HIPPA security rules 1 .</p>
<p>Medical Abstraction: NLP_REASONING</p>
<p>Document Segmentation and Segment Classification.</p>
<p>The output of the de-identification module is in the form of text files that may belong to multiple clinical documents. Accordingly, we perform document segmentation by leveraging an ensemble of embedding-based and rule-based approaches. We then classify the documents into their proper categories, e.g., Pathology, Administrative, Lab Results, SOAP Note, etc.</p>
<p>Entity and Relation Extraction.</p>
<p>We employ a transformerbased sequence tagging architecture for the tagging of predefined medical entities, e.g., Cancer and Surgery. A transformer-based context classification model then determines the relation between every possible pair of extracted entities, if any. The outputs are then stored in tag graphs in which the nodes and edges represent the entities and their relations, respectively.</p>
<p>Symbolic Reasoning.</p>
<p>We utilize an in-house proprietary medical ontology that is a comprehensive, hierarchical representation of medical terminology and knowledge. It contains an expansive set of medical concepts and the relations between them.</p>
<p>Our symbolic reasoning operates on document-level and patientlevel bases. On the document level, we join the underlying tag graphs with the ontology to extract an object graph that represents the underlying document. This is conducted with the help of rule-based approaches along with voting mechanisms to resolve disagreements. The object graph captures all the medical concepts present in the document and the relations between them. Next, the patient-level processing consolidates the documentlevel object graphs to form a heterogeneous patient-level graph. The graph is formed by combining those objects that are compatible with one another through the application of a large set of logical rules that traverse the ontology, along with confidence assignments that represent the likelihood of the objects. For instance, a Neoplasm node consolidates several Neoplasm nodes that are consistent with one another; a Neoplasm node for Cancer, for example, is consistent with another Neoplasm node for Lung Cancer since Lung Cancer is a subtype of Cancer, while Breast cancer and Lung Cancer, on the other hand, are incompatible since they do not refer to the same type of Cancer. Such compatibility rules are traced transitively across the ontology.</p>
<p>Integration of LLMs</p>
<p>We integrate LLMs into our abstraction pipeline by querying the LLMs with the output of the preprocessing steps and passing the retrieved and/or generated outputs to our core abstraction system NLP_REASONING. We describe our LLM-based setups below.</p>
<p>3.3.1 LLMs for Retrieval. In this setup, we apply retrieval (embedding) LLMs on the preprocessed documents along with a predefined set of 31 questions (See Appendix A.2) that targets a predefined set of 13 cancer-related medical variables that we need to extract (See Appendix A.3). For each question, the LLMs retrieve four semantically related chunks from the preprocessed documents. We then combine all the retrieved chunks and pass them as the sole input to NLP_REASONING (as opposed to passing all the preprocessed documents). We refer to this setup as RET_NLP_REASONING.</p>
<p>LLMs for Generation.</p>
<p>In this setup, we pass the retrieved chunks from RET_NLP_REASONING along with the corresponding questions as input to a generative LLM to obtain an answer for each question. We then combine all the answers and pass them as the sole input to NLP_REASONING. We refer to this setup as GEN_NLP_REASONING.</p>
<p>LLMs for Retrieval and Generation.</p>
<p>This setup combines RET_NLP_REASONING and GEN_NLP_REASONING by combining both the retrieved chunks and the generated answers and passing them as the sole input to NLP_REASONING. We refer to this setup as RET_GEN_NLP_REASONING.   Table 1. The retrieval chunk sizes are selected such that the combined size of the input chunks, prompts, and answers does not exceed the maximum token limit of the underlying LLM and the potential of our compute resources, while the temperatures are optimized for abstraction quality. See Appendix A.2 for the complete set of questions.</p>
<p>Language Model</p>
<p>Retrieval Generation GPT3.5 2 chunk_size=3k temperature=0.67 ada2 3 chunk_size=1,612 n/a PaLM2 [1] chunk_size=3k temperature=0.67 Instructor-XL 4 [34] chunk_size=3k n/a SGPT 5 [26] chunk_size=1,612 n/a Dolly2-12b 6 n/a temperature=1.0 7 Falcon-7b-Instruct 8 chunk_size=1,612 temperature=1.0 </p>
<p>System Performance</p>
<p>The abstraction performance of our baseline (NLP_REASONING) and the three LLM-based setups that couple symbolic reasoning with language modeling is reported in  Table 4). This suggests that the reasoning system gets overwhelmed by large amounts of information for these variables, increasing the number of false positives, while  generating synthetic responses is valuable in such cases. The generated answers, however, appear to confuse the reasoning system when combined with the relevant chunks except in the cases of Morphology, N-stage, and M-Stage.</p>
<p>Comparison of LLMs.</p>
<p>The performance of the retrieval models does not noticeably vary, only a maximum difference of 3.46% in macro-averaged F1-score across the medical variables, when excluding the least performing model Falcon-7b-Instruct. This suggests that some state-of-the-art commercially-free models (ada2, Instructor-XL, and SGPT) provide performance comparable to the commercial ones (GPT3.5 and PaLM2) at hand at the time of writing this paper. Although generated answers are less efficient for this task, GPT3.5 outperforms PaLM2, while the less restricted Dolly2-12b and Falcon-7b-Instruct fall behind in performance, with macro-averaged F1-scores of 55.80%, 53.66%, 32.03%, and 18.31%, respectively, across all the medical variables.</p>
<p>Anomalies of LLMs.</p>
<p>One noticeable behavior is that the responses generated by the LLMs exhibit inconsistencies. For instance, a patient summary provided by PaLM2 (in response to Question 1 in Appendix A.2) states that the patient has Breast Cancer, whereas it states the patient has Lung Cancer in response to the subsequent question about the cancer type. Similar issues can be observed with the use of GPT3.5, Dolly2-12b, and Falcon-7b-Instruct as well. Moreover, LLMs might confuse patient-related information with generic information, e.g., confusing the list of medications the patient had with a recommended list of medications. In addition, generative LLMs might suffer from hallucinations when the targeted answer is not obvious in the underlying text. These two factors highly impact the performance of both GEN_NLP_REASONING and RET_GEN_NLP_REASONING.</p>
<p>LLMs as Standalone Systems</p>
<p>Next, we experiment with GPT3.5 as an end-to-end abstraction system without employing NLP_Reasoning and manually compare the generated answers to our gold standard. The exclusive use of GPT3.5 results in a relative decrease of 64.72% in the average F1score achieved by NLP_Reasoning across the 13 medical variables, where GPT3.5 performs comparably to NLP_Reasoning only in the cases of objective and single-valued variables, such as the neoplasm and staging information. This is basically due to the anomalies discussed in Section 4.4. The results highlight the need to introduce symbolic reasoning to better exploit the generative capabilities of language modeling. In addition, the generated answers do not form structured outputs ready for ingestion into downstream applications, which requires additional layers of abstraction.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>In this paper, we assessed the performance of coupling symbolic reasoning with language modeling toward a better understanding of unstructured electronic medical records. We evaluated our setups on 13 cancer-related medical variables and showed that the retrieval and generation capabilities of LLMs improve the abstraction of the majority of the variables. This combination also allows for lower compute cost and time since our core abstraction system is applied on chunks and answers produced by LLMs instead of full records. We also showed that commercially-free retrieval LLMs perform comparably to their commercial counterparts. Finally, we showed that the exclusive use of generative LLMs considerably drops the overall performance, which elaborates the need to introduce symbolic reasoning as an LLM steering mechanism.</p>
<p>In the future, we plan to introduce our in-house language models that are tailored for the understating of medical records towards enhanced abstraction of medical variables. </p>
<p>A APPENDIX A.1 Abstraction Pipeline</p>
<p>A.2 Questions</p>
<p>We list below the set of questions used by the LLMs to retrieve the chunks and generate the answers for our 13 medical variables. The questions are a mix of simple and compound ones that map to one or more endpoints and are tuned to ensure reasonable outcomes.</p>
<p>(1) Summarize the patient.   Table 3 lists the 13 cancer-related medical variables that we abstract from the medical records.</p>
<p>A.3 Medical Variables</p>
<p>Medical Variable Description Neoplasm</p>
<p>The patient's current cancer diagnosis (primary topography site) Morphology</p>
<p>The description of the histological type present in a pathology specimen or recorded by a physician for a patient's cancer T-Stage</p>
<p>The size and location of the tumor, including how much the tumor has grown into nearby tissues N-Stage</p>
<p>The number of lymph nodes that have cancer</p>
<p>M-Stage</p>
<p>The distant metastatic status of the primary cancer Neoplasm Stage Group</p>
<p>An assessment based on the combined evaluation of the patient's T stage, M stage, and N stage and prognostic parameters for specific cancers Medications</p>
<p>The name of the chemotherapy, targeted therapy, endocrine therapy, or immunotherapy received by the patient for the current cancer diagnosis  </p>
<p>A.4 Precision and Recall of System Performance</p>
<p>The abstraction performance of our baseline (NLP_REASONING) and the three LLM-based setups that couple symbolic reasoning with language modeling is reported in Table 4 and Table 5 for Precision and Recall, respectively.   </p>
<p>( 2 )
2GEN_LLM_NLP_REASONING: An LLM-based setup that employs NLP_REASONING on top of answers retrieved by generative LLMs. (3) RET_GEN_LLM_NLP_REASONING: An LLM-based setup that employs NLP_REASONING on top of chunks and answers retrieved by retrieval and generative LLMs.</p>
<p>LLMs. Finally, we leverage LLMs as a standalone system in the placement of NLP_REASONING, where the answers returned by the generative model are the final outcome of the abstraction pipeline. . We conduct our experiments for the extraction of 13 cancer-related medical variables, namely Neoplasm, Morphology, T-Stage, N-Stage, M-Stage, Stage Group, Medications, Outcome, Response, Tested Biomarkers, Surgeries, Diagnostic Procedures and Cancer Diagnosis Date (See Appendix A.3 for the descriptions). We process 100 patients of three cancer types, namely Colorectal Cancer (42 patients), Breast Cancer (28 patients), and Lung Cancer (30 patients); the patients are uniformly sampled with respect to the number of corresponding records, which varies between 5 and 75, with an average of 34 records per patient.</p>
<p>Models. We conduct our experiments using a number of state-of-the-art LLMs by leveraging their retrieval and generation capabilities. The models and their settings are listed in</p>
<p>Figure 1
1depicts our pipeline before the integration of LLMs.</p>
<p>( 2 )Figure 1 :
21What cancer does the patient have?(3) What is the morphology of the cancer? (4) What are the T, N and M stages of the cancer? (5) What is the stage group of the cancer? (6) What is the date of finding the T, N and M stages of the cancer? (7) What is the date of diagnosis of the cancer?(8) What is the date of diagnosing the metastasis of the cancer? (9) Did the patient undergo radiation therapy?(10) List all the cancer-related medications that the patient took.(11) List all the medications the patient used for cancer and their start dates.(12) On what date did the patient start taking each medication? Abstraction Pipeline</p>
<p>( 13 )
13List all the cancer-related surgeries that the patient underwent.(14) What are the dates of all the cancer-related surgeries that the patient underwent?(15) List all the cancer-related surgeries that the patient underwent and their dates.(16) What is the current status of the cancer?(17) What is the current status of the cancer and the date of diagnosis of the outcome?(18) What was the response of the patient to the cancer treatment?(19) How did the patient respond to the cancer-related medications and treatments, and what are the dates of the response?(20) What is the date of diagnosing the patient's response to the cancer-related medications and treatments?(21) List all the biomarkers that the patient was tested for.(22) List all the biomarkers that the patient was tested for and their interpretations. (23) List all the interpretations of each biomarker that the patient was tested for.(24) List all the biomarkers that the patient was tested for and their categorical values. (25) List the categorical values of all the biomarkers that the patient was tested for.(26) List all the biomarkers that the patient was tested for and their methods of testing.(27) List all the methods of testing of each biomarker that the patient was tested for.(28) List all the cancer-related diagnostic procedures that the patient underwent.(29) What are the dates of all the cancer-related procedures that the patient underwent?(30) What are the dates of all the cancer-related diagnostic procedures that the patient underwent? (31) List all the cancer-related diagnostic procedures that the patient underwent and their dates.</p>
<p>Table 1 :
1Utilized LLMs and their Settings4.1.3 Performance Evaluation. We evaluate the performance of 
our setups, namely NLP_REASONING, RET_NLP_REASONING, 
GEN_NLP_REASONING and RET_GEN_NLP_REASONING, us-
ing in-house manually annotated gold standard for the aforemen-
tioned medical variables in terms of F1-score, precision and recall. </p>
<p>Table 2 .
2Abstraction of Medical Variables. There is vast variation among the medical variables in how the different setups perform and which is best. The integration of LLMs achieves the biggest improve-Response, due to their ability to understand the semantics, and in the cases of variables of multiple values, such as Medications and Surgeries, due to their ability to associate related items together. On the other hand, LLMs do not help in the abstraction of Neoplasm, due to the high baseline provided by NLP_REASONING, while they suffer at abstracting variables that are scattered across the record, such as Tested Biomarkers.4.3 Analysis </p>
<p>4.3.1 ments at the detection of Surgeries (GEN_NLP_REASONING with 
GPT3.5), Response (GEN_NLP_REASONING with GPT3.5) and 
Cancer Diagnosis Date (GEN_NLP_REASONING with PaLM2), 
with relative F1-score improvements of 35.31%, 28.97% and 16.33%, 
respectively. Overall, LLMs help in the cases of subjective variables, 
such as 4.3.2 Retrieval vs. Generation. The overall performance indi-
cates that retrieval models accurately select text chunks with relevant 
information to the asked questions, and thus improve the abstraction 
of several variables, such as T-Stage, Stage Group, Medications and 
Outcome. Generated answers, on the other hand, are less beneficial 
to the core reasoning system except in the abstraction of Response, 
Surgeries and Cancer Diagnosis Date, at which NLP_REASONING 
results in low precisions (See </p>
<p>Table 2 :
2System Performance (F1-Score)%. The best result per medical variable is in bold.</p>
<p>Outcome A physician-reported outcome attributable to local treatment, e.g., surgery and radiotherapy, or systemic treatment, e.g., chemotherapy (Values: Remission, Recurrence, etc.) Response A physician-reported assessment of the effectiveness of a therapeutic procedure (Values: Disease Progression, Stable Response, etc.) Tested Biomarkers Tests to check for specific biomarkers Surgeries A list of surgeries that the patient underwent Diagnostic Procedures Tests related to the patient's cancer diagnosis Cancer Diagnosis Date The earliest pathologic evidence of the patient's current cancer diagnosis</p>
<p>Table 3 :
3Medical Variables and their Definitions</p>
<p>Coupling Symbolic Reasoning with Language Modeling for Efficient Longitudinal Understanding of Unstructured Electronic Medical Records LLMs Neoplasm Morphology T-Stage N-Stage M-Stage Stage Group Medications Outcome ResponseTested 
Surgeries 
Diagnostic 
Cancer 
Biomarkers 
Procedures Diagnosis Date </p>
<p>NLP_REASONING </p>
<p>None 91.50 
78.90 
77.53 
71.69 
75.26 
66.50 
36.73 
47.38 
37.27 
76.09 
24.69 
81.40 
59.39 </p>
<p>RET_NLP_REASONING </p>
<p>GPT3.5 90.50 
80.70 
78.42 
74.72 
72.71 
71.97 
36.06 
43.04 
39.87 
76.64 
24.95 
79.94 
60.10 
ada2 90.40 
78.99 
74.34 
77.27 
73.04 
69.62 
37.10 
49.52 
37.57 
75.57 
26.12 
82.26 
54.69 
PaLM2 88.20 
79.50 
81.89 
74.23 
72.55 
68.73 
40.73 
43.59 
39.60 
76.73 
27.67 
81.47 
62.76 
Instructor-XL 90.50 
80.50 
81.05 
74.23 
70.18 
64.83 
39.10 
50.73 
37.20 
76.23 
25.12 
81.19 
55.82 
SGPT 91.22 
76.49 
78.00 
73.65 
68.52 
72.50 
37.63 
48.29 
39.29 
76.91 
27.15 
84.75 
59.90 
Falcon-7b 89.09 
76.73 
84.09 
69.67 
66.74 
65.40 
37.31 
40 
42.83 
78.29 
27.98 
81.81 
59.18 </p>
<p>GEN_NLP_REASONING </p>
<p>GPT3.5 87.30 
80.42 
81.19 
79.02 
69.73 
60.61 
43.19 
71.43 
47.38 
74.02 
42.18 
93.11 
52.76 
PaLM2 76.30 
75.11 
73.73 
68.89 
48.42 
41.14 
39.08 
60.77 
39.68 
68.64 
42.80 
92.29 
69.08 
Dolly2-12b 60.40 
61.65 
47.14 
52.22 
17.69 
26.53 
14.86 
20.38 
31.12 
29.28 
16.09 
59.64 
21.12 
Falcon-7b 53.33 
21.76 
22.50 
0.00 
8.18 
14.55 
14.02 
20.00 
39.78 
55.17 
22.60 
52.12 
13.20 </p>
<p>RET_GEN_NLP_REASONING </p>
<p>GPT3.5 89.50 
82.60 
77.40 
75.97 
72.71 
67.01 
35.52 
42.13 
36.32 
71.25 
25.01 
80.00 
61.02 
PaLM 82.70 
81.40 
82.03 
74.72 
70.16 
65.81 
37.65 
41.63 
38.24 
68.03 
26.23 
80.31 
57.04 
Dolly2-12b 88.80 
81.60 
78.57 
72.50 
73.44 
50.38 
28.64 
32.21 
28.66 
47.24 
16.79 
70.45 
35.82 
Falcon-7b 88.28 
76.73 
84.09 
69.67 
66.74 
61.27 
32.92 
33.33 
37.07 
76.55 
21.72 
65.48 
49.79 </p>
<p>Table 4 :
4System Performance (Precision)%. The best result per medical variable is in bold. LLMs Neoplasm Morphology T-Stage N-Stage M-Stage Stage Group Medications Outcome ResponseTested 
Surgeries 
Diagnostic 
Cancer 
Biomarkers 
Procedures Diagnosis Date </p>
<p>NLP_REASONING </p>
<p>Table 5 :
5System Performance (Recall)%. The best result per medical variable is in bold.
https://www.hipaajournal.com/considered-phi-hipaa/
https://platform.openai.com/docs/models/gpt-3-5 3 https://platform.openai.com/docs/models/embeddings 4 https://huggingface.co/hkunlp/instructor-xl 5 https://github.com/Muennighoff/sgpt 6 https://huggingface.co/databricks/dolly-v2-12b7 In the case of Dolly2-12b, we use Instructor-XL to generate the embeddings. 8 https://huggingface.co/tiiuae/falcon-7b-instruct</p>
<p>. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.10403PaLM 2 Technical Report. arXiv preprintRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. PaLM 2 Technical Report. arXiv preprint arXiv:2305.10403 (2023).</p>
<p>Health care chatbots are here to help. Mary Bates, IEEE pulse. 10Mary Bates. 2019. Health care chatbots are here to help. IEEE pulse 10, 3 (2019), 12-14.</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877-1901.</p>
<p>Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. Marco Cascella, Jonathan Montomoli, Valentina Bellini, Elena Bignami, Journal of Medical Systems. 4733Marco Cascella, Jonathan Montomoli, Valentina Bellini, and Elena Bignami. 2023. Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. Journal of Medical Systems 47, 1 (2023), 33.</p>
<p>Advancing drug discovery via artificial intelligence. Hanbin Hc Stephen Chan, Thamani Shan, Horst Dahoun, Shuguang Vogel, Yuan, Trends in pharmacological sciences. 40HC Stephen Chan, Hanbin Shan, Thamani Dahoun, Horst Vogel, and Shuguang Yuan. 2019. Advancing drug discovery via artificial intelligence. Trends in pharmacological sciences 40, 8 (2019), 592-604.</p>
<p>Antonia Creswell, Murray Shanahan, arXiv:2208.14271Faithful reasoning using large language models. arXiv preprintAntonia Creswell and Murray Shanahan. 2022. Faithful reasoning using large language models. arXiv preprint arXiv:2208.14271 (2022).</p>
<p>Molecular representations in AI-driven drug discovery: a review and practical guide. Laurianne David, Amol Thakkar, Rocío Mercado, Ola Engkvist, Journal of Cheminformatics. 12Laurianne David, Amol Thakkar, Rocío Mercado, and Ola Engkvist. 2020. Molec- ular representations in AI-driven drug discovery: a review and practical guide. Journal of Cheminformatics 12, 1 (2020), 1-22.</p>
<p>Telepsychiatry and other cutting-edge technologies in COVID-19 pandemic: Bridging the distance in mental health assistance. Francesco Di Carlo, Antonella Sociali, Elena Picutti, Mauro Pettorruso, Federica Vellante, Valeria Verrastro, Giovanni Martinotti, Massimo Di Giannantonio, International journal of clinical practice. 751Francesco Di Carlo, Antonella Sociali, Elena Picutti, Mauro Pettorruso, Federica Vellante, Valeria Verrastro, Giovanni Martinotti, and Massimo di Giannantonio. 2021. Telepsychiatry and other cutting-edge technologies in COVID-19 pandemic: Bridging the distance in mental health assistance. International journal of clinical practice 75, 1 (2021).</p>
<p>Artificial intelligence in clinical and genomic diagnostics. Raquel Dias, Ali Torkamani, Genome medicine. 11Raquel Dias and Ali Torkamani. 2019. Artificial intelligence in clinical and genomic diagnostics. Genome medicine 11, 1 (2019), 1-12.</p>
<p>Nouha Dziri, Ximing Lu, Melanie Sclar, Lorraine Xiang, Liwei Li, Bill Yuchen Jian, Peter Lin, Chandra West, Bhagavatula, Jena D Ronan Le Bras, Hwang, arXiv:2305.18654Faith and Fate: Limits of Transformers on Compositionality. arXiv preprintNouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jian, Bill Yuchen Lin, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D Hwang, et al. 2023. Faith and Fate: Limits of Transformers on Compositionality. arXiv preprint arXiv:2305.18654 (2023).</p>
<p>AI in mental health. D&apos; Simon, Alfonso, Current Opinion in Psychology. 36Simon D'Alfonso. 2020. AI in mental health. Current Opinion in Psychology 36 (2020), 112-117.</p>
<p>Artificial intelligence in cancer research, diagnosis and therapy. Olivier Elemento, Christina Leslie, Johan Lundin, Georgia Tourassi, Nature Reviews Cancer. 21Olivier Elemento, Christina Leslie, Johan Lundin, and Georgia Tourassi. 2021. Artificial intelligence in cancer research, diagnosis and therapy. Nature Reviews Cancer 21, 12 (2021), 747-752.</p>
<p>Utilization of self-diagnosis health chatbots in real-world settings: case study. Xiangmin Fan, Daren Chao, Zhan Zhang, Dakuo Wang, Xiaohua Li, Feng Tian, Journal of medical Internet research. 2319928Xiangmin Fan, Daren Chao, Zhan Zhang, Dakuo Wang, Xiaohua Li, and Feng Tian. 2021. Utilization of self-diagnosis health chatbots in real-world settings: case study. Journal of medical Internet research 23, 1 (2021), e19928.</p>
<p>Recognizing suspect and predicting the spread of contagion based on mobile phone location data (counteract): a system of identifying covid-19 infectious and hazardous sites, detecting disease outbreaks based on the internet of things, edge computing, and artificial intelligence. Hemant Ghayvat, Muhammad Awais, Prosanta Gope, Sharnil Pandya, Shubhankar Majumdar, Sustainable Cities and Society. 69102798Hemant Ghayvat, Muhammad Awais, Prosanta Gope, Sharnil Pandya, and Shub- hankar Majumdar. 2021. Recognizing suspect and predicting the spread of conta- gion based on mobile phone location data (counteract): a system of identifying covid-19 infectious and hazardous sites, detecting disease outbreaks based on the internet of things, edge computing, and artificial intelligence. Sustainable Cities and Society 69 (2021), 102798.</p>
<p>Artificial intelligence in sepsis early prediction and diagnosis using unstructured data in healthcare. Kim Huat Goh, Le Wang, Adrian Yong Kwang, Hermione Yeow, Ke Poh, Li, Nature communications. Joannas Jie Lin Yeow, and Gamaliel Yu Heng Tan. 202112711Kim Huat Goh, Le Wang, Adrian Yong Kwang Yeow, Hermione Poh, Ke Li, Joannas Jie Lin Yeow, and Gamaliel Yu Heng Tan. 2021. Artificial intelligence in sepsis early prediction and diagnosis using unstructured data in healthcare. Nature communications 12, 1 (2021), 711.</p>
<p>Artificial intelligence for mental health and mental illnesses: an overview. Sarah Graham, Colin Depp, Ellen E Lee, Camille Nebeker, Xin Tu, Ho-Cheol Kim, Dilip V Jeste, Current psychiatry reports. 21Sarah Graham, Colin Depp, Ellen E Lee, Camille Nebeker, Xin Tu, Ho-Cheol Kim, and Dilip V Jeste. 2019. Artificial intelligence for mental health and mental illnesses: an overview. Current psychiatry reports 21 (2019), 1-18.</p>
<p>Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges. Shigao Huang, Jie Yang, Simon Fong, Qi Zhao, Cancer letters. 471Shigao Huang, Jie Yang, Simon Fong, and Qi Zhao. 2020. Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges. Cancer letters 471 (2020), 61-71.</p>
<p>The role of artificial intelligence in early cancer diagnosis. Benjamin Hunter, Sumeet Hindocha, Richard W Lee, Cancers. 141524Benjamin Hunter, Sumeet Hindocha, and Richard W Lee. 2022. The role of artificial intelligence in early cancer diagnosis. Cancers 14, 6 (2022), 1524.</p>
<p>Clinical applications of artificial intelligence and machine learning in cancer diagnosis: looking into the future. Muhammad Javed Iqbal, Zeeshan Javed, Haleema Sadia, A Ijaz, Asma Qureshi, Rais Irshad, Kausar Ahmed, Shahid Malik, Asif Raza, Raffaele Abbas, Pezzani, Cancer cell international. 21Muhammad Javed Iqbal, Zeeshan Javed, Haleema Sadia, Ijaz A Qureshi, Asma Irshad, Rais Ahmed, Kausar Malik, Shahid Raza, Asif Abbas, Raffaele Pezzani, et al. 2021. Clinical applications of artificial intelligence and machine learning in cancer diagnosis: looking into the future. Cancer cell international 21, 1 (2021), 1-11.</p>
<p>Artificial intelligence in disease diagnosis: a systematic literature review, synthesizing framework and future research agenda. Yogesh Kumar, Apeksha Koul, Ruchi Singla, Muhammad Fazal Ijaz, Journal of Ambient Intelligence and Humanized Computing. Yogesh Kumar, Apeksha Koul, Ruchi Singla, and Muhammad Fazal Ijaz. 2022. Artificial intelligence in disease diagnosis: a systematic literature review, synthe- sizing framework and future research agenda. Journal of Ambient Intelligence and Humanized Computing (2022), 1-28.</p>
<p>Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. H Tiffany, Morgan Kung, Arielle Cheatham, Czarina Medenilla, Lorie De Sillos, Camille Leon, Maria Elepaño, Rimel Madriaga, Giezel Aggabao, James Diaz-Candido, Maningo, PLoS digital health. 22198Tiffany H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz- Candido, James Maningo, et al. 2023. Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. PLoS digital health 2, 2 (2023), e0000198.</p>
<p>Individualization of drug therapy: history, present state, and opportunities for the future. J Lawrence, Stephan Lesko, Schmidt, Clinical Pharmacology &amp; Therapeutics. 92Lawrence J Lesko and Stephan Schmidt. 2012. Individualization of drug therapy: history, present state, and opportunities for the future. Clinical Pharmacology &amp; Therapeutics 92, 4 (2012), 458-466.</p>
<p>. Louis Létinier, Julien Jouganous, Mehdi Benkebil, Alicia Bel-Létoile, Clément Goehrs, Allison Singier, Franck Rouby, Clémence Lacroix, Ghada Miremont, Louis Létinier, Julien Jouganous, Mehdi Benkebil, Alicia Bel-Létoile, Clément Goehrs, Allison Singier, Franck Rouby, Clémence Lacroix, Ghada Miremont,</p>
<p>Artificial intelligence for unstructured healthcare data: application to coding of patient reporting of adverse drug reactions. Joëlle Micallef, Clinical Pharmacology &amp; Therapeutics. 110Joëlle Micallef, et al. 2021. Artificial intelligence for unstructured healthcare data: application to coding of patient reporting of adverse drug reactions. Clinical Pharmacology &amp; Therapeutics 110, 2 (2021), 392-400.</p>
<p>Neural Natural Language Processing for unstructured data in electronic health records: A review. Irene Li, Jessica Pan, Jeremy Goldwasser, Neha Verma, Wai Pan Wong, Yavuz Muhammed, Benjamin Nuzumlalı, Yixin Rosand, Matthew Li, David Zhang, Chang, Computer Science Review. 46100511Irene Li, Jessica Pan, Jeremy Goldwasser, Neha Verma, Wai Pan Wong, Muhammed Yavuz Nuzumlalı, Benjamin Rosand, Yixin Li, Matthew Zhang, David Chang, et al. 2022. Neural Natural Language Processing for unstructured data in electronic health records: A review. Computer Science Review 46 (2022), 100511.</p>
<p>AI-based language models powering drug discovery and development. Zhichao Liu, A Ruth, Madhu Roberts, Xi Lal-Nag, Ruili Chen, Weida Huang, Tong, Drug Discovery Today. 26Zhichao Liu, Ruth A Roberts, Madhu Lal-Nag, Xi Chen, Ruili Huang, and Weida Tong. 2021. AI-based language models powering drug discovery and development. Drug Discovery Today 26, 11 (2021), 2593-2607.</p>
<p>SGPT: GPT sentence embeddings for semantic search. Niklas Muennighoff, arXiv:2202.08904arXiv preprintNiklas Muennighoff. 2022. SGPT: GPT sentence embeddings for semantic search. arXiv preprint arXiv:2202.08904 (2022).</p>
<p>Acceptability of artificial intelligence (AI)-led chatbot services in healthcare: A mixed-methods study. Tom Nadarzynski, Oliver Miles, Aimee Cowie, Damien Ridge, Digital health. 52055207619871808Tom Nadarzynski, Oliver Miles, Aimee Cowie, and Damien Ridge. 2019. Ac- ceptability of artificial intelligence (AI)-led chatbot services in healthcare: A mixed-methods study. Digital health 5 (2019), 2055207619871808.</p>
<p>Machine learning and AI for healthcare. Arjun Panesar, SpringerArjun Panesar. 2019. Machine learning and AI for healthcare. Springer.</p>
<p>Artificial intelligence in drug discovery and development. Debleena Paul, Gaurav Sanap, Snehal Shenoy, Dnyaneshwar Kalyane, Kiran Kalia, Rakesh K Tekade, Drug discovery today. 2680Debleena Paul, Gaurav Sanap, Snehal Shenoy, Dnyaneshwar Kalyane, Kiran Kalia, and Rakesh K Tekade. 2021. Artificial intelligence in drug discovery and development. Drug discovery today 26, 1 (2021), 80.</p>
<p>AI in health and medicine. Pranav Rajpurkar, Emma Chen, Oishi Banerjee, Eric J Topol, Nature medicine. 28Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. 2022. AI in health and medicine. Nature medicine 28, 1 (2022), 31-38.</p>
<p>The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. Malik Sallam, medRxiv. Malik Sallam. 2023. The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. medRxiv (2023), 2023-02.</p>
<p>The role of artificial intelligence in healthcare: a structured literature review. Silvana Secinaro, Davide Calandra, Aurelio Secinaro, Vivek Muthurangu, Paolo Biancone, BMC medical informatics and decision making. 21Silvana Secinaro, Davide Calandra, Aurelio Secinaro, Vivek Muthurangu, and Paolo Biancone. 2021. The role of artificial intelligence in healthcare: a structured literature review. BMC medical informatics and decision making 21 (2021), 1-23.</p>
<p>Artificial intelligence versus clinicians in disease diagnosis: systematic review. Jiayi Shen, J P Casper, Bangsheng Zhang, Jiebin Jiang, Jian Chen, Zherui Song, Zonglin Liu, He, Yi Sum, Po-Han Wong, Wai-Kit Fang, Ming, JMIR medical informatics. 710010Jiayi Shen, Casper JP Zhang, Bangsheng Jiang, Jiebin Chen, Jian Song, Zherui Liu, Zonglin He, Sum Yi Wong, Po-Han Fang, Wai-Kit Ming, et al. 2019. Artificial intelligence versus clinicians in disease diagnosis: systematic review. JMIR medical informatics 7, 3 (2019), e10010.</p>
<p>Hongjin Su, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-Tau Yih, A Noah, Luke Smith, Tao Zettlemoyer, Yu, arXiv:2212.09741Any Task: Instruction-Finetuned Text Embeddings. arXiv preprintHongjin Su, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih, Noah A Smith, Luke Zettlemoyer, Tao Yu, et al. 2022. One Embedder, Any Task: Instruction-Finetuned Text Embeddings. arXiv preprint arXiv:2212.09741 (2022).</p>
<p>Artificial neural network based prediction of malaria abundances using big data: A knowledge capturing approach. Santosh Thakur, Ramesh Dharavath, Clinical Epidemiology and Global Health. 7Santosh Thakur and Ramesh Dharavath. 2019. Artificial neural network based prediction of malaria abundances using big data: A knowledge capturing approach. Clinical Epidemiology and Global Health 7, 1 (2019), 121-126.</p>
<p>Karthik Valmeekam, Alberto Olmo, arXiv:2206.10498Sarath Sreedharan, and Subbarao Kambhampati. 2022. Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). arXiv preprintKarthik Valmeekam, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambham- pati. 2022. Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). arXiv preprint arXiv:2206.10498 (2022).</p>            </div>
        </div>

    </div>
</body>
</html>