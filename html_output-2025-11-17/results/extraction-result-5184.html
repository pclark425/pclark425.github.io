<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5184 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5184</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5184</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-247170966</p>
                <p><strong>Paper Title:</strong> A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge</p>
                <p><strong>Paper Abstract:</strong> Psychology has benefited from an enormous wealth of knowledge about processes of cognition in relation to how the brain organizes information. Within the categorization literature, this behavior is often explained through theories of memory construction called exemplar theory and prototype theory which are typically based on similarity or rule functions as explanations of how categories emerge. Although these theories work well at modeling highly controlled stimuli in laboratory settings, they often perform less well outside of these settings, such as explaining the emergence of background knowledge processes. In order to explain background knowledge, we present a non-similarity-based post-Skinnerian theory of human language called Relational Frame Theory (RFT) which is rooted in a philosophical world view called functional contextualism (FC). This theory offers a very different interpretation of how categories emerge through the functions of behavior and through contextual cues, which may be of some benefit to existing categorization theories. Specifically, RFT may be able to offer a novel explanation of how background knowledge arises, and we provide some mathematical considerations in order to identify a formal model. Finally, we discuss much of this work within the broader context of general semantic knowledge and artificial intelligence research.</p>
                <p><strong>Cost:</strong> 0.031</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5184.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5184.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A similarity-based cognitive theory positing that category membership is judged by comparison to an abstracted central tendency or average (the prototype) rather than to individual exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented functionally as prototypical summary representations (an average of experienced category members); categorization is performed by measuring similarity of the stimulus to the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype (abstraction/summary) representation; similarity-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Abstracted central tendency; graded membership/typicality; sensitive to central features; reduces memory load (cognitive economy); context-sensitive insofar as prototypes depend on sampled exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic findings in supervised/unsupervised tasks where typical items are categorized faster and more confidently; Rosch & Mervis-type typicality effects and many experiments where prototypical stimuli are preferred or learned quickly (paper cites this family of evidence).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Fails to account for cases where rule or background knowledge overrides similarity (e.g., Rips metamorphosis examples where similarity and categorization dissociate), and struggles to explain inductive effects driven by causal/background knowledge rather than perceptual similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Standard category learning and typicality tasks, unsupervised categorization, many laboratory categorization experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted in the paper with exemplar and rule-based models; stronger than simple exemplar storage for economy but weaker than theory-like or relational accounts at explaining background-knowledge-driven inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Compute similarity between stimulus and prototype; apply threshold or probabilistic decision rule to assign category membership based on distance in feature space.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How prototypes are constructed and updated given complex, relational, or causal background knowledge; inability to select relevant knowledge in complex contexts (the knowledge-selection problem).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5184.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A similarity-based model that represents categories as sets of stored individual exemplars; categorization is done by comparing a new stimulus to stored exemplars and aggregating similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as a memory of multiple specific exemplars; categorization arises from similarity-weighted matching to these exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>instance-based / exemplar memory; distributed over stored examples</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Stores specific instances; flexible to capture variability; graded similarity-based generalization; can incorporate attention weights over dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains many supervised categorization effects, including performance in tasks where category boundaries are irregular and where memory traces of exemplars predict classification (cited exemplar models such as Medin & Schaffer approaches).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Cannot by itself explain background-knowledge driven inferences or rule-like generalizations when similarity and category membership diverge; suffers from knowledge-selection problem when many possible background sources are available.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Supervised categorization, memory-based categorization, modeling of exemplar effects in lab tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared with prototype and rule-based theories; more flexible than prototype for capturing variability but less explanatory for rule-like or relational inferences that rely on background causal knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Compute summed similarity of stimulus to stored exemplars (possibly weighted), then choose category with greatest summed similarity (e.g., GCM-like mechanisms).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exemplar stores interact with abstract rules or relational background knowledge, and how learners select which stored knowledge is relevant in novel contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5184.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Similarity models / GCM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Similarity-based models (Generalized Context Model - GCM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal similarity-based models (exemplified by the GCM) that embed stimuli in multidimensional psychological space and define categorization probabilities as decreasing functions of distance to category exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Generalized Context Model (GCM) / similarity-based models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Representations are points in a multidimensional metric space; categorization is a probabilistic function of summed similarity (exponential of distance) to stored exemplars or prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>feature-space (metric, continuous) representation; similarity/kernel-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit metric geometry (city-block / Euclidean), attention weights per dimension, exponential similarity function, probabilistic choice rule (Luce choice rule), captures typicality and graded categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Good fits to many supervised and unsupervised categorization datasets; GCM widely cited and successful in controlled lab stimuli where feature magnitudes drive behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Limited in accounting for arbitrary relational/background-knowledge effects, causal inferences, and knowledge selection; cannot naturally represent arbitrarily applicable relations or transfer of stimulus function (ToF).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Laboratory categorization, modeling of exemplar effects, baseline module in the paper's proposed hybrid model for non-arbitrary similarity components.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Stronger for low-level perceptual similarity predictions than rule-based or relational accounts, but weaker for explaining relational or language-mediated background knowledge; the paper proposes combining GCM with RFT modules.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Encode stimulus coordinates, compute distance-based similarity to stored exemplars, sum similarities per category, apply probabilistic choice; update attention weights via learning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to integrate with arbitrarily applicable relational representations and how similarity-based spaces interact with hierarchical relational networks that carry functions like fear, causality, or rules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5184.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rule-based / COVIS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rule-based models (including COVIS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models positing that categorization sometimes proceeds by explicit symbolic rules (if-then) that map features to category membership; COVIS is a dual-system model positing competition between explicit verbal and implicit procedural systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Rule-based models / COVIS (Competition between Verbal and Implicit Systems)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts can be represented functionally as explicit rules or classifiers; the COVIS framework proposes two learning systems: an explicit verbal (rule) system and an implicit procedural (similarity) system that compete or cooperate depending on task context.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / rule representations (explicit) alongside procedural/implicit associative representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Compositional conditional rules (IF-THEN), explicit hypothesis testing, ability to capture deterministic logical classification; in COVIS, arbitration between systems based on task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains tasks where humans use verbalizable rules (e.g., parity judgments, simple logical categories) and data showing faster learning when explicit rules are discoverable; some neuropsychological dissociations support multiple systems.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Does not specify how rules are discovered or selected from vast prior knowledge; limited explanation of how arbitrary relational functions are built from history of reinforcement; interplay with relational language-based knowledge underspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Rule-learning tasks, explicit classification tasks, experiments contrasting explicit vs. implicit learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Complements similarity/exemplar models by capturing cases where verbal rules dominate; RFT provides an alternative functional account for generation of rule-like relations grounded in histories of reinforcement rather than symbolic hypothesis search.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Hypothesis generation and testing for rule discovery; selection/switching mechanism between systems (in COVIS) based on feedback and task structure.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How explicit rules relate to broader background knowledge networks, and how context determines when rule representations are used versus relationally derived functions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5184.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Relational Frame Theory (RFT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relational Frame Theory (RFT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional-analytic behavioral theory that represents conceptual knowledge as patterns of contextually-controlled derived relational responding (arbitrarily applicable relations) organized into relational networks that transfer behavioral functions between stimuli.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Relational Frame Theory (RFT)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented functionally as nodes in relational networks where derived relations (coordination, comparison, opposition, hierarchy, deictic relations) and the transfer/transformation of stimulus functions (ToF) instantiate conceptual meaning and govern categorization and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>relational network representation (arbitrarily applicable relational responding); functional/contextual network rather than purely feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Context-sensitivity, derivation (mutual entailment, combinatorial entailment), transfer/transformation of stimulus function (ToF), capacity for hierarchical and multi-level relational networks, compositional combining of relations, flexibility and coherence as formal dimensions (MDML/HDML).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Empirical studies cited show derived relations and ToF: transformation of stimulus functions (Dougher et al., 2007), hierarchical relational responding experiments (Gi et al., 2012; Slattery & Stewart, 2011), child relational framing (Mulhern et al., 2017), and rule-following/coherence manipulations (Bern et al., 2020; Harte et al., 2017/2018).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>RFT is a behavioral-relational account that requires formal mathematical instantiation for comparison with classic models; empirical generalization to many naturalistic semantic phenomena and integration with neural plausibility remains work in progress (authors note need for formal model and testing).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Background-knowledge driven categorization, rule-following and persistence, hierarchical classification, clinical contexts (process-based therapy), language and reasoning tasks involving derived relations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Addresses limitations of similarity and exemplar models by explicitly modeling arbitrary, language-mediated relational structures and ToF; offers a functional account that can encompass rule-like behavior without positing symbolic rules; argued to extend and complement connectionist and Bayesian approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Learning histories create generalized relational responding; three core operations produce derived knowledge: mutual entailment (ME), combinatorial entailment (CE), and transformation/transfer of stimulus functions (ToF); contextual cues select which relations/functions control behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Quantitative mathematical formalization and predictive comparison to other models is incomplete; specifying mechanisms for large-scale knowledge selection and formal learning algorithms that map onto neural computation are open challenges (motivates the paper's hybrid computational proposal).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5184.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HDML / MDML / DAARRE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hyperdimensional Multilevel (HDML) framework integrating MDML and DAARRE</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extended RFT analytic framework that characterizes arbitrarily applicable relational responding across multiple levels (entailment, rules, analogical reasoning, extended narratives) and explicitly models both relational (C_rel) and functional (C_func) properties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>MDML / DAARRE integrated as HDML (Hyperdimensional Multilevel) framework</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents conceptual knowledge as multilayer relational networks with dimensions (coherence, complexity, derivation, flexibility) and explicit modeling of relating, orienting, and evoking (ROE) processes; integrates relational structure (ME/CE/ToF) with functional properties and community-level network analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>multilevel relational-network / hyperdimensional relational representation (functional + relational attributes)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Multilevel hierarchy (from simple entailments to complex narrative networks), coherence (consistency across relational patterns), derivation strength (history of emitting derived relations), complexity (network density), flexibility (context-modifiability), explicit C_rel and C_func distinction.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited empirical work on rule persistence, coherence effects and derivation-level manipulations (Bern et al., 2020; Harte et al., 2017/2018) and demonstrations of hierarchical ToF and functions (Gi et al., 2012; Slattery & Stewart, 2014).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Relatively new framework; needs systematic empirical validation across wider tasks and formal computational instantiation; mapping to scalable machine-learning architectures remains an open engineering and empirical task (addressed partially by the paper's proposed hybrid model).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Modeling complex background knowledge, multi-network interactions (e.g., self, environment, social knowledge), process-based therapy clinical modeling, advanced categorization and reasoning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Extends RFT by explicitly adding multilevel and functional dimensions, allowing direct comparisons to rule-based, Bayesian, and connectionist approaches; claimed to better handle coherence and derivation-based phenomena than traditional models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>ROE operations: relating (forming relations), orienting (attentional/contextual cues), evoking (functional valence: appetitive/aversive/neutral); operations operate across multi-level relational graphs enabling ToF and complex inferential chains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Formal quantitative metrics for coherence/complexity/derivation/flexibility and methods for learning these networks from data remain under development; empirical boundary conditions and scalability need testing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5184.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Frame semantics / lexical semantics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Frame semantics and lexical/frame-based semantic theories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Linguistic-semantic theories that model conceptual knowledge as structured attribute-value frames or cascades of frames, where concepts are nodes in frame networks and meaning arises from attributes and relations within frames.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Frame semantics / lexical semantics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is represented as structured frames (attributeâ€“value structures) and cascades of frames; conceptual inferences and categorization arise by traversing frame structures and Bayesian updating of attribute weights.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>structured symbolic/attribute-value frames; hierarchical semantic networks</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit compositional structure (attributes and values), hierarchical cascades, capacity to weight attributes (Bayesian framing), context-dependent activation of frames.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Frame-based Bayesian models can successfully explain some structured category-learning and semantic inference phenomena and are used in computational linguistics and AI; frame-theoretic Bayesian models are discussed as improving on feature-list approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Frame trees and attribute-value structures can be brittle and insufficiently rich to capture wide-ranging contextual dynamics and arbitrarily applicable relations mediated by language; scaling to rich, noisy real-world contexts is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Natural language semantics, computational linguistics, structured category learning, Bayesian concept models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More structured and interpretable than distributed connectionist representations but less flexible than RFT for modeling arbitrarily applicable relational responding and function transfer; can be integrated with Bayesian approaches for graded inference.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Activation and traversal of frame cascades, Bayesian weighting of attribute-values given contextual evidence, propagation of activation through frame networks for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How frame semantics interfaces with learned relational function transfer (ToF) and how to represent non-arbitrary vs. arbitrary relations learned through history of reinforcement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5184.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed / connectionist representations (semantic networks & DNN)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / distributed semantic representations (semantic networks, deep neural networks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representations are distributed activation patterns across many units (hidden layers); concepts are points in a high-dimensional activation space, and relational/contextual information is embedded in network weights and activations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Connectionist distributed representations / deep semantic network</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented as distributed vectors/activation patterns in hidden layers; context dependence and relational frames are captured by separate relation-input layers and deep learning modules that form relational representations across layers.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed vector representations (high-dimensional, continuous); layered feature-to-relation representations (DNN + relation input layer)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Continuous, graded encodings; hierarchical feature abstraction across layers; capacity for non-linear pattern discovery; context-sensitive through relation-input modulation; amenable to graph extraction (co-activation graphs) for interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Success of distributed models in semantics and NLP (cited GPT-3, AlphaGo successes for deep learning), and support from semantic network literature (Rogers & McClelland) and psycholinguistic modeling; the paper outlines how DNN modules can learn contexts where ToF/ME/CE occur.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Biological plausibility of backpropagation questioned; interpretability of deep representations ('black box') requires graph-extraction methods; pure DNNs do not by themselves represent arbitrarily applicable relational frames without architectural or expert-system support.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Natural language processing, semantic representation, feature discovery, modeling complex background knowledge in categorization tasks (proposed hybrid model integrates DNN with expert modules).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More flexible and scalable than symbolic frame models for complex noisy data; less transparent than symbolic/RFT accounts but can be combined with RFT/expert modules to capture arbitrary relational functions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Layer-wise feature extraction, relation-input modulation to create context-dependent hidden representations, use of supervised/unsupervised learning (DNN, SOM), extraction of co-activation graphs to recover community/relational structure and ToF patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to implement biologically plausible learning rules (Hebbian/predictive coding vs. backprop), how to explicitly encode arbitrary relational responding (ME/CE/ToF) in distributed architectures, and how to ensure interpretability and alignment with functional-level behavioral data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5184.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baywatch / KRES / ALCOVE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baywatch (Bayesian + connectionist), KRES (Knowledge-Resonance), ALCOVE (connectionist exemplar model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Connectionist and hybrid models that incorporate attention, exemplar similarity, knowledge biases, or Bayesian inference to account for categorization and some effects of background knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Hybrid connectionist/Bayesian models (Baywatch, KRES, ALCOVE)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>These are models that use connectionist architectures (often shallow nets) augmented with mechanisms for attention (ALCOVE), Hebbian recurrent resonance with knowledge (KRES), or Bayesian output transforms to express probabilistic categorization (Baywatch) to capture some background-knowledge influences.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>connectionist distributed representations with Bayesian/probabilistic output or recurrent resonance; exemplar-weighted hidden activations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Weighted associative nodes, attention learning (ALCOVE), recurrent bidirectional resonance (KRES), logistic/Bayesian conversion of network outputs to probabilities (Baywatch), capacity to embed prior biases.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Demonstrated fits to some categorization phenomena including effects of prior biases and disjunctive vs. conjunctive learning; Baywatch showed ability to identify which sources of background knowledge are selected in tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Often limited by shallow architectures (single hidden layer), limited relational expressivity compared to RFT, and scalability to complex multi-network background knowledge; struggle to model arbitrary relational functions without extra structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Modeling categorization with prior knowledge biases, simulating disjunctive/conjunctive learning differences, analyzing exemplar-based learning dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provide bridges between pure similarity models and probabilistic reasoning; less capable than proposed deep hybrid RFT+DNN+expert architectures at capturing arbitrarily applicable relational responding and ToF.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Connectionist weight updates (backprop or Hebbian), attention-weight learning, recurrent resonance for knowledge activation, Bayesian transformation of outputs to category probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to scale to deep architectures and integrate explicit relational function transfer; backprop biological plausibility concerns and need for richer relational structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5184.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rips dissociation findings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rips' similarity vs. categorization dissociations (e.g., metamorphosis example)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical findings showing that similarity judgments and categorical assignments can dissociate: items judged more similar to one category can nonetheless be categorized as belonging to another because of background knowledge or rule-like inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Empirical dissociation between similarity and categorization (Rips)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Experimental demonstrations (e.g., metamorphosis thought experiments) that categorize participants sometimes prefer rule- or knowledge-driven category assignments despite similarity-based judgments indicating otherwise, implying representations beyond raw perceptual similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Behavioral evidence for relational/theory-like representations supplementing or overriding similarity-based feature representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Dissociation between perceived similarity and category assignment; influence of inferred essences or causal/background knowledge; highlights limits of pure similarity representations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic experiments reported by Rips (1989) and discussed in the paper (pizza vs coin, metamorphosis creature) showing the divergence of similarity judgments and categorization choices.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>These findings challenge pure prototype/exemplar similarity models and motivate rule-based, theory-theory, or relational representations (like RFT) that can capture background knowledge effects.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Philosophical and experimental tasks probing conceptual essentialism, metamorphosis thought experiments, category assignment under background knowledge manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Used in the paper to argue for limits of similarity models and to motivate relational/functional accounts (RFT), and Bayesian/theory-theory approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Suggests mechanisms where background knowledge or inferred causal properties are accessed and applied to override similarity computations during categorization decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exactly background knowledge is stored, selected, and integrated functionally with perceptual similarity computations remains an open issue (the knowledge-selection problem).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5184.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heit congruence / knowledge-selection work</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heit's work on background knowledge effects and the knowledge-selection problem</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical and modeling work showing that prior knowledge (congruence) affects categorization and induction, and articulating the 'knowledge selection' problem: how learners determine which prior knowledge is relevant in a situation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Heit's integration/congruence findings and knowledge-selection problem</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Background knowledge can facilitate or bias category learning (congruence effects), but existing models struggle to formalize how learners select among many possible knowledge sources; Heit proposed integration models and highlighted the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Empirical phenomenon pointing to multi-modal, hierarchical and relational knowledge structures rather than pure exemplar/prototype stores</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Context-dependent selection of knowledge, congruence effects speeding learning, dynamic integration of prior knowledge with exemplars, and difficulty formalizing selection processes.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Heit (1994, 1995, 1997, 1998, 2001) studies showing congruence speeds classification and that exemplar distortion does not fully explain participant responses; integration model work and follow-ups.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Heit documented that similarity-only models insufficiently capture background knowledge influences and called for richer multimodal representational schemes; but formal computational solutions remained limited.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization tasks where prior knowledge is congruent or incongruent with training, inductive reasoning tasks, and studies of concept acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Positions background-knowledge effects as orthogonal to pure similarity models; the paper uses Heit's observations to motivate RFT and hybrid approaches that incorporate functional/contextual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Highlights need for selection mechanisms sensitive to context cues and hierarchical relational structures; does not fully specify the mechanism, leaving it as an open problem addressed by the paper's proposal.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Specifying formal algorithms for knowledge selection and dynamic retrieval of relevant relational/background networks remains unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5184.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5184.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToF empirical findings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformation/Transfer of stimulus function (ToF) empirical demonstrations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical demonstrations that behavioral functions (e.g., fear) conditioned to one stimulus can transfer to other stimuli through derived relational relations even without direct reinforcement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Transformation/Transfer of stimulus function (ToF)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional property where a stimulus's eliciting/discriminative functions are transformed or transferred to relationally related stimuli via derived relational responding (e.g., if A is related to B and B is paired with aversive function, A can come to evoke aversive responding).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Functional attachment to relational-network nodes leading to propagation of functions across the relational graph (functional-relational representation)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Function transfer without direct pairing, can amplify or modulate magnitude of function via comparative relations, depends on the relational structure (ME/CE) and context cues.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Experiments cited include Dougher et al. (2007) showing ToF in laboratory settings, and hierarchical ToF demonstrations (Gi et al., 2012) where functions trained at one level appear at other levels via derived entailments.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>ToF's boundary conditions (which relational structures and learning histories allow transfer) are nontrivial and require systematic mapping; some connectionist models fail to capture ToF without specialized mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Fear/avoidance learning, categorization under background knowledge (e.g., snake â†’ woods â†’ self networks), clinical applications (process-based therapy targeting functional network relations).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Distinguishes RFT/functional accounts from pure similarity/exemplar or purely symbolic rule models because ToF is not captured by similarity alone; motivates hybrid architectures integrating expert relational modules with connectionist learners.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Transfer occurs via mutual and combinatorial entailment operations: a function attached to one node is transformed according to the relations that node participates in, under the controlling contextual cues (C_rel and C_func).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Detailed computational learning rules that predict when ToF will occur, its magnitude, and its decay require further empirical and formal work (motivates SOM/DNN approaches proposed in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Relational frame theory: A post-Skinnerian account of human language and cognition <em>(Rating: 2)</em></li>
                <li>Models of the effects of prior knowledge on category learning <em>(Rating: 2)</em></li>
                <li>Attention, similarity, and the identification-categorization relationship <em>(Rating: 2)</em></li>
                <li>Category-based induction <em>(Rating: 2)</em></li>
                <li>Transformation of the discriminative and eliciting functions of generalized relational stimuli <em>(Rating: 2)</em></li>
                <li>Investigating Relational Framing of Categorization in Young Children <em>(Rating: 2)</em></li>
                <li>A preliminary demonstration of transformation of functions through hierarchical relations <em>(Rating: 1)</em></li>
                <li>Influence of prior knowledge on concept acquisition: Experimental and computational results <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5184",
    "paper_id": "paper-247170966",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory",
            "brief_description": "A similarity-based cognitive theory positing that category membership is judged by comparison to an abstracted central tendency or average (the prototype) rather than to individual exemplars.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Concepts are represented functionally as prototypical summary representations (an average of experienced category members); categorization is performed by measuring similarity of the stimulus to the prototype.",
            "representation_format_type": "prototype (abstraction/summary) representation; similarity-based",
            "key_properties": "Abstracted central tendency; graded membership/typicality; sensitive to central features; reduces memory load (cognitive economy); context-sensitive insofar as prototypes depend on sampled exemplars.",
            "empirical_support": "Classic findings in supervised/unsupervised tasks where typical items are categorized faster and more confidently; Rosch & Mervis-type typicality effects and many experiments where prototypical stimuli are preferred or learned quickly (paper cites this family of evidence).",
            "empirical_challenges": "Fails to account for cases where rule or background knowledge overrides similarity (e.g., Rips metamorphosis examples where similarity and categorization dissociate), and struggles to explain inductive effects driven by causal/background knowledge rather than perceptual similarity.",
            "applied_domains_or_tasks": "Standard category learning and typicality tasks, unsupervised categorization, many laboratory categorization experiments.",
            "comparison_to_other_models": "Contrasted in the paper with exemplar and rule-based models; stronger than simple exemplar storage for economy but weaker than theory-like or relational accounts at explaining background-knowledge-driven inferences.",
            "functional_mechanisms": "Compute similarity between stimulus and prototype; apply threshold or probabilistic decision rule to assign category membership based on distance in feature space.",
            "limitations_or_open_questions": "How prototypes are constructed and updated given complex, relational, or causal background knowledge; inability to select relevant knowledge in complex contexts (the knowledge-selection problem).",
            "uuid": "e5184.0",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory",
            "brief_description": "A similarity-based model that represents categories as sets of stored individual exemplars; categorization is done by comparing a new stimulus to stored exemplars and aggregating similarity.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar theory",
            "theory_or_model_description": "Conceptual knowledge is functionally represented as a memory of multiple specific exemplars; categorization arises from similarity-weighted matching to these exemplars.",
            "representation_format_type": "instance-based / exemplar memory; distributed over stored examples",
            "key_properties": "Stores specific instances; flexible to capture variability; graded similarity-based generalization; can incorporate attention weights over dimensions.",
            "empirical_support": "Explains many supervised categorization effects, including performance in tasks where category boundaries are irregular and where memory traces of exemplars predict classification (cited exemplar models such as Medin & Schaffer approaches).",
            "empirical_challenges": "Cannot by itself explain background-knowledge driven inferences or rule-like generalizations when similarity and category membership diverge; suffers from knowledge-selection problem when many possible background sources are available.",
            "applied_domains_or_tasks": "Supervised categorization, memory-based categorization, modeling of exemplar effects in lab tasks.",
            "comparison_to_other_models": "Compared with prototype and rule-based theories; more flexible than prototype for capturing variability but less explanatory for rule-like or relational inferences that rely on background causal knowledge.",
            "functional_mechanisms": "Compute summed similarity of stimulus to stored exemplars (possibly weighted), then choose category with greatest summed similarity (e.g., GCM-like mechanisms).",
            "limitations_or_open_questions": "How exemplar stores interact with abstract rules or relational background knowledge, and how learners select which stored knowledge is relevant in novel contexts.",
            "uuid": "e5184.1",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Similarity models / GCM",
            "name_full": "Similarity-based models (Generalized Context Model - GCM)",
            "brief_description": "Formal similarity-based models (exemplified by the GCM) that embed stimuli in multidimensional psychological space and define categorization probabilities as decreasing functions of distance to category exemplars.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Generalized Context Model (GCM) / similarity-based models",
            "theory_or_model_description": "Representations are points in a multidimensional metric space; categorization is a probabilistic function of summed similarity (exponential of distance) to stored exemplars or prototypes.",
            "representation_format_type": "feature-space (metric, continuous) representation; similarity/kernel-based",
            "key_properties": "Explicit metric geometry (city-block / Euclidean), attention weights per dimension, exponential similarity function, probabilistic choice rule (Luce choice rule), captures typicality and graded categorization.",
            "empirical_support": "Good fits to many supervised and unsupervised categorization datasets; GCM widely cited and successful in controlled lab stimuli where feature magnitudes drive behavior.",
            "empirical_challenges": "Limited in accounting for arbitrary relational/background-knowledge effects, causal inferences, and knowledge selection; cannot naturally represent arbitrarily applicable relations or transfer of stimulus function (ToF).",
            "applied_domains_or_tasks": "Laboratory categorization, modeling of exemplar effects, baseline module in the paper's proposed hybrid model for non-arbitrary similarity components.",
            "comparison_to_other_models": "Stronger for low-level perceptual similarity predictions than rule-based or relational accounts, but weaker for explaining relational or language-mediated background knowledge; the paper proposes combining GCM with RFT modules.",
            "functional_mechanisms": "Encode stimulus coordinates, compute distance-based similarity to stored exemplars, sum similarities per category, apply probabilistic choice; update attention weights via learning.",
            "limitations_or_open_questions": "How to integrate with arbitrarily applicable relational representations and how similarity-based spaces interact with hierarchical relational networks that carry functions like fear, causality, or rules.",
            "uuid": "e5184.2",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Rule-based / COVIS",
            "name_full": "Rule-based models (including COVIS)",
            "brief_description": "Models positing that categorization sometimes proceeds by explicit symbolic rules (if-then) that map features to category membership; COVIS is a dual-system model positing competition between explicit verbal and implicit procedural systems.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Rule-based models / COVIS (Competition between Verbal and Implicit Systems)",
            "theory_or_model_description": "Concepts can be represented functionally as explicit rules or classifiers; the COVIS framework proposes two learning systems: an explicit verbal (rule) system and an implicit procedural (similarity) system that compete or cooperate depending on task context.",
            "representation_format_type": "symbolic / rule representations (explicit) alongside procedural/implicit associative representations",
            "key_properties": "Compositional conditional rules (IF-THEN), explicit hypothesis testing, ability to capture deterministic logical classification; in COVIS, arbitration between systems based on task demands.",
            "empirical_support": "Explains tasks where humans use verbalizable rules (e.g., parity judgments, simple logical categories) and data showing faster learning when explicit rules are discoverable; some neuropsychological dissociations support multiple systems.",
            "empirical_challenges": "Does not specify how rules are discovered or selected from vast prior knowledge; limited explanation of how arbitrary relational functions are built from history of reinforcement; interplay with relational language-based knowledge underspecified.",
            "applied_domains_or_tasks": "Rule-learning tasks, explicit classification tasks, experiments contrasting explicit vs. implicit learning.",
            "comparison_to_other_models": "Complements similarity/exemplar models by capturing cases where verbal rules dominate; RFT provides an alternative functional account for generation of rule-like relations grounded in histories of reinforcement rather than symbolic hypothesis search.",
            "functional_mechanisms": "Hypothesis generation and testing for rule discovery; selection/switching mechanism between systems (in COVIS) based on feedback and task structure.",
            "limitations_or_open_questions": "How explicit rules relate to broader background knowledge networks, and how context determines when rule representations are used versus relationally derived functions.",
            "uuid": "e5184.3",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Relational Frame Theory (RFT)",
            "name_full": "Relational Frame Theory (RFT)",
            "brief_description": "A functional-analytic behavioral theory that represents conceptual knowledge as patterns of contextually-controlled derived relational responding (arbitrarily applicable relations) organized into relational networks that transfer behavioral functions between stimuli.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Relational Frame Theory (RFT)",
            "theory_or_model_description": "Concepts are represented functionally as nodes in relational networks where derived relations (coordination, comparison, opposition, hierarchy, deictic relations) and the transfer/transformation of stimulus functions (ToF) instantiate conceptual meaning and govern categorization and inference.",
            "representation_format_type": "relational network representation (arbitrarily applicable relational responding); functional/contextual network rather than purely feature-based",
            "key_properties": "Context-sensitivity, derivation (mutual entailment, combinatorial entailment), transfer/transformation of stimulus function (ToF), capacity for hierarchical and multi-level relational networks, compositional combining of relations, flexibility and coherence as formal dimensions (MDML/HDML).",
            "empirical_support": "Empirical studies cited show derived relations and ToF: transformation of stimulus functions (Dougher et al., 2007), hierarchical relational responding experiments (Gi et al., 2012; Slattery & Stewart, 2011), child relational framing (Mulhern et al., 2017), and rule-following/coherence manipulations (Bern et al., 2020; Harte et al., 2017/2018).",
            "empirical_challenges": "RFT is a behavioral-relational account that requires formal mathematical instantiation for comparison with classic models; empirical generalization to many naturalistic semantic phenomena and integration with neural plausibility remains work in progress (authors note need for formal model and testing).",
            "applied_domains_or_tasks": "Background-knowledge driven categorization, rule-following and persistence, hierarchical classification, clinical contexts (process-based therapy), language and reasoning tasks involving derived relations.",
            "comparison_to_other_models": "Addresses limitations of similarity and exemplar models by explicitly modeling arbitrary, language-mediated relational structures and ToF; offers a functional account that can encompass rule-like behavior without positing symbolic rules; argued to extend and complement connectionist and Bayesian approaches.",
            "functional_mechanisms": "Learning histories create generalized relational responding; three core operations produce derived knowledge: mutual entailment (ME), combinatorial entailment (CE), and transformation/transfer of stimulus functions (ToF); contextual cues select which relations/functions control behavior.",
            "limitations_or_open_questions": "Quantitative mathematical formalization and predictive comparison to other models is incomplete; specifying mechanisms for large-scale knowledge selection and formal learning algorithms that map onto neural computation are open challenges (motivates the paper's hybrid computational proposal).",
            "uuid": "e5184.4",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "HDML / MDML / DAARRE",
            "name_full": "Hyperdimensional Multilevel (HDML) framework integrating MDML and DAARRE",
            "brief_description": "An extended RFT analytic framework that characterizes arbitrarily applicable relational responding across multiple levels (entailment, rules, analogical reasoning, extended narratives) and explicitly models both relational (C_rel) and functional (C_func) properties.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "MDML / DAARRE integrated as HDML (Hyperdimensional Multilevel) framework",
            "theory_or_model_description": "Represents conceptual knowledge as multilayer relational networks with dimensions (coherence, complexity, derivation, flexibility) and explicit modeling of relating, orienting, and evoking (ROE) processes; integrates relational structure (ME/CE/ToF) with functional properties and community-level network analyses.",
            "representation_format_type": "multilevel relational-network / hyperdimensional relational representation (functional + relational attributes)",
            "key_properties": "Multilevel hierarchy (from simple entailments to complex narrative networks), coherence (consistency across relational patterns), derivation strength (history of emitting derived relations), complexity (network density), flexibility (context-modifiability), explicit C_rel and C_func distinction.",
            "empirical_support": "Cited empirical work on rule persistence, coherence effects and derivation-level manipulations (Bern et al., 2020; Harte et al., 2017/2018) and demonstrations of hierarchical ToF and functions (Gi et al., 2012; Slattery & Stewart, 2014).",
            "empirical_challenges": "Relatively new framework; needs systematic empirical validation across wider tasks and formal computational instantiation; mapping to scalable machine-learning architectures remains an open engineering and empirical task (addressed partially by the paper's proposed hybrid model).",
            "applied_domains_or_tasks": "Modeling complex background knowledge, multi-network interactions (e.g., self, environment, social knowledge), process-based therapy clinical modeling, advanced categorization and reasoning tasks.",
            "comparison_to_other_models": "Extends RFT by explicitly adding multilevel and functional dimensions, allowing direct comparisons to rule-based, Bayesian, and connectionist approaches; claimed to better handle coherence and derivation-based phenomena than traditional models.",
            "functional_mechanisms": "ROE operations: relating (forming relations), orienting (attentional/contextual cues), evoking (functional valence: appetitive/aversive/neutral); operations operate across multi-level relational graphs enabling ToF and complex inferential chains.",
            "limitations_or_open_questions": "Formal quantitative metrics for coherence/complexity/derivation/flexibility and methods for learning these networks from data remain under development; empirical boundary conditions and scalability need testing.",
            "uuid": "e5184.5",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Frame semantics / lexical semantics",
            "name_full": "Frame semantics and lexical/frame-based semantic theories",
            "brief_description": "Linguistic-semantic theories that model conceptual knowledge as structured attribute-value frames or cascades of frames, where concepts are nodes in frame networks and meaning arises from attributes and relations within frames.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Frame semantics / lexical semantics",
            "theory_or_model_description": "Conceptual knowledge is represented as structured frames (attributeâ€“value structures) and cascades of frames; conceptual inferences and categorization arise by traversing frame structures and Bayesian updating of attribute weights.",
            "representation_format_type": "structured symbolic/attribute-value frames; hierarchical semantic networks",
            "key_properties": "Explicit compositional structure (attributes and values), hierarchical cascades, capacity to weight attributes (Bayesian framing), context-dependent activation of frames.",
            "empirical_support": "Frame-based Bayesian models can successfully explain some structured category-learning and semantic inference phenomena and are used in computational linguistics and AI; frame-theoretic Bayesian models are discussed as improving on feature-list approaches.",
            "empirical_challenges": "Frame trees and attribute-value structures can be brittle and insufficiently rich to capture wide-ranging contextual dynamics and arbitrarily applicable relations mediated by language; scaling to rich, noisy real-world contexts is challenging.",
            "applied_domains_or_tasks": "Natural language semantics, computational linguistics, structured category learning, Bayesian concept models.",
            "comparison_to_other_models": "More structured and interpretable than distributed connectionist representations but less flexible than RFT for modeling arbitrarily applicable relational responding and function transfer; can be integrated with Bayesian approaches for graded inference.",
            "functional_mechanisms": "Activation and traversal of frame cascades, Bayesian weighting of attribute-values given contextual evidence, propagation of activation through frame networks for inference.",
            "limitations_or_open_questions": "How frame semantics interfaces with learned relational function transfer (ToF) and how to represent non-arbitrary vs. arbitrary relations learned through history of reinforcement.",
            "uuid": "e5184.6",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Distributed / connectionist representations (semantic networks & DNN)",
            "name_full": "Connectionist / distributed semantic representations (semantic networks, deep neural networks)",
            "brief_description": "Representations are distributed activation patterns across many units (hidden layers); concepts are points in a high-dimensional activation space, and relational/contextual information is embedded in network weights and activations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Connectionist distributed representations / deep semantic network",
            "theory_or_model_description": "Concepts are represented as distributed vectors/activation patterns in hidden layers; context dependence and relational frames are captured by separate relation-input layers and deep learning modules that form relational representations across layers.",
            "representation_format_type": "distributed vector representations (high-dimensional, continuous); layered feature-to-relation representations (DNN + relation input layer)",
            "key_properties": "Continuous, graded encodings; hierarchical feature abstraction across layers; capacity for non-linear pattern discovery; context-sensitive through relation-input modulation; amenable to graph extraction (co-activation graphs) for interpretability.",
            "empirical_support": "Success of distributed models in semantics and NLP (cited GPT-3, AlphaGo successes for deep learning), and support from semantic network literature (Rogers & McClelland) and psycholinguistic modeling; the paper outlines how DNN modules can learn contexts where ToF/ME/CE occur.",
            "empirical_challenges": "Biological plausibility of backpropagation questioned; interpretability of deep representations ('black box') requires graph-extraction methods; pure DNNs do not by themselves represent arbitrarily applicable relational frames without architectural or expert-system support.",
            "applied_domains_or_tasks": "Natural language processing, semantic representation, feature discovery, modeling complex background knowledge in categorization tasks (proposed hybrid model integrates DNN with expert modules).",
            "comparison_to_other_models": "More flexible and scalable than symbolic frame models for complex noisy data; less transparent than symbolic/RFT accounts but can be combined with RFT/expert modules to capture arbitrary relational functions.",
            "functional_mechanisms": "Layer-wise feature extraction, relation-input modulation to create context-dependent hidden representations, use of supervised/unsupervised learning (DNN, SOM), extraction of co-activation graphs to recover community/relational structure and ToF patterns.",
            "limitations_or_open_questions": "How to implement biologically plausible learning rules (Hebbian/predictive coding vs. backprop), how to explicitly encode arbitrary relational responding (ME/CE/ToF) in distributed architectures, and how to ensure interpretability and alignment with functional-level behavioral data.",
            "uuid": "e5184.7",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Baywatch / KRES / ALCOVE",
            "name_full": "Baywatch (Bayesian + connectionist), KRES (Knowledge-Resonance), ALCOVE (connectionist exemplar model)",
            "brief_description": "Connectionist and hybrid models that incorporate attention, exemplar similarity, knowledge biases, or Bayesian inference to account for categorization and some effects of background knowledge.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Hybrid connectionist/Bayesian models (Baywatch, KRES, ALCOVE)",
            "theory_or_model_description": "These are models that use connectionist architectures (often shallow nets) augmented with mechanisms for attention (ALCOVE), Hebbian recurrent resonance with knowledge (KRES), or Bayesian output transforms to express probabilistic categorization (Baywatch) to capture some background-knowledge influences.",
            "representation_format_type": "connectionist distributed representations with Bayesian/probabilistic output or recurrent resonance; exemplar-weighted hidden activations",
            "key_properties": "Weighted associative nodes, attention learning (ALCOVE), recurrent bidirectional resonance (KRES), logistic/Bayesian conversion of network outputs to probabilities (Baywatch), capacity to embed prior biases.",
            "empirical_support": "Demonstrated fits to some categorization phenomena including effects of prior biases and disjunctive vs. conjunctive learning; Baywatch showed ability to identify which sources of background knowledge are selected in tasks.",
            "empirical_challenges": "Often limited by shallow architectures (single hidden layer), limited relational expressivity compared to RFT, and scalability to complex multi-network background knowledge; struggle to model arbitrary relational functions without extra structure.",
            "applied_domains_or_tasks": "Modeling categorization with prior knowledge biases, simulating disjunctive/conjunctive learning differences, analyzing exemplar-based learning dynamics.",
            "comparison_to_other_models": "Provide bridges between pure similarity models and probabilistic reasoning; less capable than proposed deep hybrid RFT+DNN+expert architectures at capturing arbitrarily applicable relational responding and ToF.",
            "functional_mechanisms": "Connectionist weight updates (backprop or Hebbian), attention-weight learning, recurrent resonance for knowledge activation, Bayesian transformation of outputs to category probabilities.",
            "limitations_or_open_questions": "How to scale to deep architectures and integrate explicit relational function transfer; backprop biological plausibility concerns and need for richer relational structure.",
            "uuid": "e5184.8",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Rips dissociation findings",
            "name_full": "Rips' similarity vs. categorization dissociations (e.g., metamorphosis example)",
            "brief_description": "Empirical findings showing that similarity judgments and categorical assignments can dissociate: items judged more similar to one category can nonetheless be categorized as belonging to another because of background knowledge or rule-like inferences.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Empirical dissociation between similarity and categorization (Rips)",
            "theory_or_model_description": "Experimental demonstrations (e.g., metamorphosis thought experiments) that categorize participants sometimes prefer rule- or knowledge-driven category assignments despite similarity-based judgments indicating otherwise, implying representations beyond raw perceptual similarity.",
            "representation_format_type": "Behavioral evidence for relational/theory-like representations supplementing or overriding similarity-based feature representations",
            "key_properties": "Dissociation between perceived similarity and category assignment; influence of inferred essences or causal/background knowledge; highlights limits of pure similarity representations.",
            "empirical_support": "Classic experiments reported by Rips (1989) and discussed in the paper (pizza vs coin, metamorphosis creature) showing the divergence of similarity judgments and categorization choices.",
            "empirical_challenges": "These findings challenge pure prototype/exemplar similarity models and motivate rule-based, theory-theory, or relational representations (like RFT) that can capture background knowledge effects.",
            "applied_domains_or_tasks": "Philosophical and experimental tasks probing conceptual essentialism, metamorphosis thought experiments, category assignment under background knowledge manipulation.",
            "comparison_to_other_models": "Used in the paper to argue for limits of similarity models and to motivate relational/functional accounts (RFT), and Bayesian/theory-theory approaches.",
            "functional_mechanisms": "Suggests mechanisms where background knowledge or inferred causal properties are accessed and applied to override similarity computations during categorization decisions.",
            "limitations_or_open_questions": "How exactly background knowledge is stored, selected, and integrated functionally with perceptual similarity computations remains an open issue (the knowledge-selection problem).",
            "uuid": "e5184.9",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Heit congruence / knowledge-selection work",
            "name_full": "Heit's work on background knowledge effects and the knowledge-selection problem",
            "brief_description": "Empirical and modeling work showing that prior knowledge (congruence) affects categorization and induction, and articulating the 'knowledge selection' problem: how learners determine which prior knowledge is relevant in a situation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Heit's integration/congruence findings and knowledge-selection problem",
            "theory_or_model_description": "Background knowledge can facilitate or bias category learning (congruence effects), but existing models struggle to formalize how learners select among many possible knowledge sources; Heit proposed integration models and highlighted the gap.",
            "representation_format_type": "Empirical phenomenon pointing to multi-modal, hierarchical and relational knowledge structures rather than pure exemplar/prototype stores",
            "key_properties": "Context-dependent selection of knowledge, congruence effects speeding learning, dynamic integration of prior knowledge with exemplars, and difficulty formalizing selection processes.",
            "empirical_support": "Heit (1994, 1995, 1997, 1998, 2001) studies showing congruence speeds classification and that exemplar distortion does not fully explain participant responses; integration model work and follow-ups.",
            "empirical_challenges": "Heit documented that similarity-only models insufficiently capture background knowledge influences and called for richer multimodal representational schemes; but formal computational solutions remained limited.",
            "applied_domains_or_tasks": "Categorization tasks where prior knowledge is congruent or incongruent with training, inductive reasoning tasks, and studies of concept acquisition.",
            "comparison_to_other_models": "Positions background-knowledge effects as orthogonal to pure similarity models; the paper uses Heit's observations to motivate RFT and hybrid approaches that incorporate functional/contextual representations.",
            "functional_mechanisms": "Highlights need for selection mechanisms sensitive to context cues and hierarchical relational structures; does not fully specify the mechanism, leaving it as an open problem addressed by the paper's proposal.",
            "limitations_or_open_questions": "Specifying formal algorithms for knowledge selection and dynamic retrieval of relevant relational/background networks remains unresolved.",
            "uuid": "e5184.10",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "ToF empirical findings",
            "name_full": "Transformation/Transfer of stimulus function (ToF) empirical demonstrations",
            "brief_description": "Empirical demonstrations that behavioral functions (e.g., fear) conditioned to one stimulus can transfer to other stimuli through derived relational relations even without direct reinforcement.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Transformation/Transfer of stimulus function (ToF)",
            "theory_or_model_description": "Functional property where a stimulus's eliciting/discriminative functions are transformed or transferred to relationally related stimuli via derived relational responding (e.g., if A is related to B and B is paired with aversive function, A can come to evoke aversive responding).",
            "representation_format_type": "Functional attachment to relational-network nodes leading to propagation of functions across the relational graph (functional-relational representation)",
            "key_properties": "Function transfer without direct pairing, can amplify or modulate magnitude of function via comparative relations, depends on the relational structure (ME/CE) and context cues.",
            "empirical_support": "Experiments cited include Dougher et al. (2007) showing ToF in laboratory settings, and hierarchical ToF demonstrations (Gi et al., 2012) where functions trained at one level appear at other levels via derived entailments.",
            "empirical_challenges": "ToF's boundary conditions (which relational structures and learning histories allow transfer) are nontrivial and require systematic mapping; some connectionist models fail to capture ToF without specialized mechanisms.",
            "applied_domains_or_tasks": "Fear/avoidance learning, categorization under background knowledge (e.g., snake â†’ woods â†’ self networks), clinical applications (process-based therapy targeting functional network relations).",
            "comparison_to_other_models": "Distinguishes RFT/functional accounts from pure similarity/exemplar or purely symbolic rule models because ToF is not captured by similarity alone; motivates hybrid architectures integrating expert relational modules with connectionist learners.",
            "functional_mechanisms": "Transfer occurs via mutual and combinatorial entailment operations: a function attached to one node is transformed according to the relations that node participates in, under the controlling contextual cues (C_rel and C_func).",
            "limitations_or_open_questions": "Detailed computational learning rules that predict when ToF will occur, its magnitude, and its decay require further empirical and formal work (motivates SOM/DNN approaches proposed in the paper).",
            "uuid": "e5184.11",
            "source_info": {
                "paper_title": "A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge",
                "publication_date_yy_mm": "2022-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Relational frame theory: A post-Skinnerian account of human language and cognition",
            "rating": 2,
            "sanitized_title": "relational_frame_theory_a_postskinnerian_account_of_human_language_and_cognition"
        },
        {
            "paper_title": "Models of the effects of prior knowledge on category learning",
            "rating": 2,
            "sanitized_title": "models_of_the_effects_of_prior_knowledge_on_category_learning"
        },
        {
            "paper_title": "Attention, similarity, and the identification-categorization relationship",
            "rating": 2,
            "sanitized_title": "attention_similarity_and_the_identificationcategorization_relationship"
        },
        {
            "paper_title": "Category-based induction",
            "rating": 2,
            "sanitized_title": "categorybased_induction"
        },
        {
            "paper_title": "Transformation of the discriminative and eliciting functions of generalized relational stimuli",
            "rating": 2,
            "sanitized_title": "transformation_of_the_discriminative_and_eliciting_functions_of_generalized_relational_stimuli"
        },
        {
            "paper_title": "Investigating Relational Framing of Categorization in Young Children",
            "rating": 2,
            "sanitized_title": "investigating_relational_framing_of_categorization_in_young_children"
        },
        {
            "paper_title": "A preliminary demonstration of transformation of functions through hierarchical relations",
            "rating": 1,
            "sanitized_title": "a_preliminary_demonstration_of_transformation_of_functions_through_hierarchical_relations"
        },
        {
            "paper_title": "Influence of prior knowledge on concept acquisition: Experimental and computational results",
            "rating": 1,
            "sanitized_title": "influence_of_prior_knowledge_on_concept_acquisition_experimental_and_computational_results"
        }
    ],
    "cost": 0.031245000000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge
published: 02 March 2022 Published: 02 March 2022</p>
<p>Michael B Miller 
Robert Johansson 
Darren J Edwards d.j.edwards@swansea.ac.uk 
Darren J Edwards 
Department of Public Health, Policy, and Social Sciences
Swansea University
SwanseaUnited Kingdom</p>
<p>Ciara Mcenteggart 
Department of Experimental Clinical and Health Psychology
Ghent University
GhentBelgium</p>
<p>Yvonne Barnes-Holmes 
Department of Experimental Clinical and Health Psychology
Ghent University
GhentBelgium</p>
<p>University of California
Santa BarbaraUnited States</p>
<p>Stockholm University
Sweden</p>
<p>Olivera Savic
The Ohio State University
United States</p>
<p>A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge
published: 02 March 2022 Published: 02 March 202210.3389/fpsyg.2022.745306Specialty section: This article was submitted to Cognition, a section of the journal Frontiers in Psychology Received: 23 July 2021 Accepted: 09 February 2022REVIEW Edited by: Reviewed by: *Correspondence: Citation: Edwards DJ, McEnteggart C and Barnes-Holmes Y (2022) A Functional Contextual Account of Background Knowledge in Categorization: Implications for Artificial General Intelligence and Cognitive Accounts of General Knowledge. Front. Psychol. 13:745306.functional contextualismmachine learningRelational Frame Theory (RFT)categorizationbackground knowledge
Psychology has benefited from an enormous wealth of knowledge about processes of cognition in relation to how the brain organizes information. Within the categorization literature, this behavior is often explained through theories of memory construction called exemplar theory and prototype theory which are typically based on similarity or rule functions as explanations of how categories emerge. Although these theories work well at modeling highly controlled stimuli in laboratory settings, they often perform less well outside of these settings, such as explaining the emergence of background knowledge processes. In order to explain background knowledge, we present a non-similaritybased post-Skinnerian theory of human language called Relational Frame Theory (RFT) which is rooted in a philosophical world view called functional contextualism (FC). This theory offers a very different interpretation of how categories emerge through the functions of behavior and through contextual cues, which may be of some benefit to existing categorization theories. Specifically, RFT may be able to offer a novel explanation of how background knowledge arises, and we provide some mathematical considerations in order to identify a formal model. Finally, we discuss much of this work within the broader context of general semantic knowledge and artificial intelligence research. Frontiers in Psychology | www.frontiersin.org Transfer of funcï¿½on (ToF) Cfunc [Crel {A Rx B and B Ry C { B f1 Rp and C f2 Rq B ||| A f3 }}] 1 2 3 4 Community network 3. Verbal self and relational aï¿½ributes: self esteem Community network 1. Concept snake and relaï¿½onal aï¿½ributes: Is dangerous, lives in woods Community network 2. Woods and relaï¿½onal aï¿½ributes: Contains dangerous snake FIGURE 9| A network structure shows how three community clusters (relating relational networks -of the HDML framework) in a network graph can emerge whereby each cluster has related concepts and are connected (related) to other clusters in the graph where properties such as a ToF from one cluster can influence other cluster networks. Each node represents a unique concept and are connected together in a strong or weak way (depicted by the width of the connecting lines) to other nodes within a cluster. The community clusters (blue, green, and orange) containing the connected nodes are related to one another through some properties of RFT, in this case a transfer of stimulus function. The red arrow indicates the transfer of function "fear" from green community (snake category), to the blue community (woods category), and finally to the orange community (verbal self).</p>
<p>INTRODUCTION</p>
<p>Category learning has been described as fundamental to all aspects of decision-making, and refers to the process of organizing sensory experience into groups and appears to be key to understanding the world Lakoff, 2008). The main purpose of the human cognitive system for developing concepts and categories is cognitive economy, which allows individuals to process complex information in a manageable way in spite of finite memory storage (Goldstone et al., 2018). Categorization researchers use models to describe the process of categorization in a formal (and sometimes mathematical), principled and lawful way, in an attempt to achieve prediction over behavior in particular categorization tasks (Pothos and Wills, 2011).</p>
<p>Categorization processes can be separated into four distinct areas of research, supervised categorization (Nosofsky, 1988;Minda and Smith, 2001;Hampton, 2007;Kurtz, 2007;Vanpaemel and Storms, 2008) and unsupervised categorization (Fleming and Cottrell, 1990;Ashby et al., 1999;Pothos and Chater, 2002;Pothos and Close, 2008; which can utilize a similarity or rule based function. There is also the emerging area of categorization called relational representation (Stewart et al., 2005;Edwards et al., 2012) which explores inference learning in categorization, and also an area known as background knowledge (Heit, 2001) which attempts to incorporate many of the above approaches to understand how background knowledge emerges and affects category decision making.</p>
<p>Background knowledge in categorization refers to the beliefs that individuals may have about the interrelations and causal connections among features and concepts which emerge through prior learning, and how this affects category decision making (Keil, 1989;Murphy, 1993). This differs in some ways from other approaches which attempt to model knowledge such as theories in semantics, for example semantic memory. Semantic memory can be regarded as a category of long-term memory which involves the recollection of ideas, concepts, and facts commonly regarded as general knowledge (Zesch et al., 2008;Paradis, 2012;Russo et al., 2021). However, the focus within semantics has primarily been on natural language, such as the logical relations within sentence structures which give meaning to the language being expressed (LÃ¶bner et al., 2021) (however there is modest overlap -see the section on "The limited success of semantics" for a more in depth overview). Crucially, background knowledge in categorization, does not specifically and primarily explore logical relations within linguistics (as semantics does), but instead, focuses primarily on the category structure developed because of prior learning which helps form some general knowledge about some concept, and facilitates some category decision in the present moment.</p>
<p>In an example of background knowledge, if you were to ask a lay person (non-animal specialist) to describe the categorical features of a bird and a bat, they may respond by saying; "Birds and bats fly by using their wings to do so. A bat prefers to fly at night, whilst a bird prefers to fly in the day. Birds has feathers whilst bats do not." This relies on prior knowledge learned perhaps in early school, through parents and general books the person may have read out of interest. Causal connections and interrelations then are drawn by the participant from this knowledge in order for them to describe how wings are used to allow the bird and bat to fly. Specific differences are also identified by the participant such as when birds and bats prefer to fly, but little causal connections are drawn by the lay person as they lack the essential background knowledge of why this may be the case. However, if you were to ask an animal specialist, they may add to this by saying; "A bat uses echolocation to fly at night, to identify food, and to navigate, whilst a bird requires light to fly and does not use echolocation. A bat is a mammal, and feeds on milk from its mother while growing, whilst a bird is a member of the Aves, and is not a mammal." This specialist background knowledge may have been learned during higher education and allows the specialist to draw stronger and more accurate causal interrelations and connections amongst the feature of birds and bats. The study of background knowledge, is thus to identify how these causal connections and interrelations between concepts develop, in what context they emerge, and to identify the different ways in which this knowledge can influence categorization behavioral decisions in a given categorization task (Heit, 2001).</p>
<p>In this current review and conceptual development paper, we (1) firstly broadly explain why existing categorization models fail to account for background knowledge. We also briefly highlight why the problem of background knowledge is also a problem in artificial intelligence (AI) research, for those who seek to develop artificial general intelligence (AGI), and for which development in that area may be dependent on a model for background knowledge. We, therefore, seek this literature for clues of how we may develop mathematical models to solve the problem of background knowledge which may not have been considered previously; (2) We offer a functional contextual approach to understanding background knowledge which has not yet been considered in background knowledge research; (3) Finally, as part of this exploration, we offer a formal mathematical model of this functional contextual approach for use with Background knowledge experiments, which is consistent with the approach made by many other researchers who offer mathematical accounts of their categorization models, and for which may be of interest to categorization as well as AI mathematical modelers. This takes into consideration the modeling of both similarity as well as functional contextual properties within a RFT framework. We then make suggestions for future work, which specifically test the descriptive and predictive power of this RFT approach for background knowledge in categorization.</p>
<p>THE PROBLEM OF BACKGROUND KNOWLEDGE AND WHY EXISTING MODELING EFFORTS ARE SO FAR INCOMPLETE</p>
<p>The area of background knowledge has been the most difficult for categorization researchers to formalize a specific model, and most attempts have only provided an intuitive account of this thus far (Heit, 1997;Dreyfus et al., 2000;Pothos and Wills, 2011) with most efforts in this area having now been redirected to less difficult problems such as simple induction (inference) modeling (B. K. Hayes and Heit, 2013;Hawkins et al., 2016). Indeed, approaches based on similarity (i.e., identifying similar features when categorizing) which have been used to explain behavior in unsupervised and supervised tasks have not provided an effective means of explaining the emergence of background knowledge though some promising progress has been made in relation to understanding background knowledge effects on categorization decisions. Supervised learning models are often explained by exemplar and prototype theories which involve matching through similarity (magnitudes of length, height, color, etc.), either the individual memory trace of exemplars for the to-be categorized novel stimuli, or matching a prototype (e.g., a prototypical average representation of all chairs represented in memory) to the to-be categorized novel stimuli. This typically involves modeling how stimuli correspond to points in multidimensional space (usually Euclidean), and some similarity function is defined based on some mathematical axioms about how the stimuli should be categorized on this similarity basis (Lamberts and Shapiro, 2002;Pothos and Wills, 2011).</p>
<p>Similarity approaches are one of the earliest and most successful explanations of how people categorize (Posner and Keele, 1968;Reed, 1972;Rosch and Mervis, 1975;Pothos and Wills, 2011). In this account, the more similar item X is to what is known about category A (e.g., the magnitude of size), the more likely X will be categorized as belonging to A. Consider, for example, the classification of a novel bird. According to one similarity model called the prototype account (Rosch and Mervis, 1975), the reasoner would take notice of typical features such as color, wing-span, type of beak, and where the bird lives. They would then categorize the bird on these bases as belonging to a particular bird category if this bird had similar features to the prototypical list of features identified in that category (e.g., similar shaped beak, sized wing, etc.).</p>
<p>In typical similarity tasks, such as unsupervised categorization, participants are asked to put several items into sets of categories that they feel to be most intuitive. Crucially, the participant is not informed of any category structure, thus cannot infer from pre-existing knowledge about category structure. These unsupervised tasks are thought to involve category coherence (Rosch and Mervis, 1975;Murphy and Medin, 1985), which allow researchers to hypothesize about how intuitive the structures being categorized are, and how participants process this information without any background knowledge of what the category structure should look like, in order to form distinct categories. So, in this case, unsupervised categorization may be less helpful in facilitating researchers to identify a model of background knowledge, as these tasks typically do not require the use of it.</p>
<p>In supervised (also a similarity based account) categorization tasks (Nosofsky, 1988;Hampton, 2007), participants are shown the exemplars of each category (such as 20 pictures of two novel creatures) in addition to a category label (such as Blib or Chomp), and thus learn the category structure. They are then asked to decide which category a set of new items (pictures of new creatures) belong to (either the Blib or Chomp creature category). Hence, unlike unsupervised tasks, supervised tasks involve some aspect of learning about the category structure before the categorization decisions are made, and the categorization process relies of these previous memory traces of the category structure when making category decisions. This, therefore, at a conceptual level may be more helpful in facilitating researchers to identify a model of background knowledge, as these tasks require the use of memory trace, and background knowledge presumably would need to be remembered via such a memory trace. This is because, if a categorization task asks the participants, 'is a bat and a bird in the same category?' , their answer should be dependent on some memory trace of background knowledge that a "bat is a mammal, whilst a bird is not, " therefore the participants come to the conclusion that they are not in the same category. Without such a memory trace, the participant may determine that a bat and bird are in the same category on the basis of some more general similarity function based on the shape and size similarity of the creatures (i.e., similar to an unsupervised approach which does not require a strong memory trace).</p>
<p>In both supervised and unsupervised categorization tasks, many models have been formalized mathematically, and are typically based on a similarity axiom. For example, the Generalized Context Model (GCM; Nosofsky, 1986) is a generalization of the context model by Medin and Schaffer (1978), integrated with similarity and choice of classical theories by Garner (1974). It is also one of the most heavily cited and influential models in categorization research (over 3200 citations). The GCM incorporates multidimensional scaling (MDS) to model similarity, whereby multidimensional space is used to represent the exemplars and the similarity is a decreasing function of their distance in this space. There are, of course, many other similarity-based models, and a detailed examination of these is beyond of the scope of this current article. One example of an unsupervised categorization model is the simplicity model which predicts the "optimal" categories through an information reductionism perspective (Pothos and Chater, 2002;Nikolopoulos and Pothos, 2009). This model assumes that information theory applies to cognition through a simplicity principle, which states that we tend to prefer simpler and not more complex perceptual organizations. There are also models, such as the rational model (Anderson, 1990) which use features in their description of a categories should emerge. This takes the dimensional features (e.g., has four legs, barks, and has tail) and identifies the probability of which category the item belongs to, based on how similar its features are to the features within each of the categories (where assignment is made with the greatest similarity).</p>
<p>However, criticisms of these similarity models as a basis for natural concepts came as far back as from Murphy and Medin (1985) in a seminal paper concerning knowledge effects on concept learning. Rips (1989) then extended this criticism by reporting a number of cases whereby categorization behavior was better explained by a rule based account as opposed to a similarity-based account. For example, he highlighted the pizza coin experiment, where participants were asked to imagine an item that was halfway between two categories (a pizza and a coin), where one of the categories had fixed magnitudes of properties (such as fixed size -coin) and the other had variable magnitudes of properties (such as variable size -pizza). Participants were then asked: (1) whether an item was more similar to one of the categories than the other, and (2) whether an item was more likely to be a member of one category rather than the other. Rips found that participants were more likely to categorize the imagined item as belonging to the variable category (pizza) but more similar to the fixed category (coin). Rips concluded that there was sometimes a disassociation between similarity and categorization, i.e., individuals categorization behavior were not always consistent with how similar they felt items were with category members.</p>
<p>Perhaps in an even more convincing example, Rips (1989) asked participants to imagine a creature which accidentally metamorphosized from one category (bird) to another (insect). When asked whether the creature was more similar to a bird or an insect, most participants selected insect, and yet they more readily categorized the creature as a bird. In a separate condition, some participants were asked to judge the similarity of the creature before it transformed and to assume that metamorphosis happened naturally. In this condition, the participants deemed the creature more similar to a bird, and this finding suggested that some background knowledge about essential qualities (e.g., DNA) were being inferred from the detail of metamorphosis and the extent to which this was a natural process. Again, Rips proposed that this was evidence that participants were using formal rules of inference from background knowledge to inform their categorization decisions, and not merely similarity.</p>
<p>So, in spite of the success of similarity models in predicting categorization behavior based on essential category structure in many supervised and unsupervised tasks, they appear less effective in predicting behavior in tasks which involve a rules option and involve inferences made through background knowledge. The view that in addition to perceptual similarity, rule, and background knowledge information pertaining to the stimulus context may also be relevant, represented a shift away from similarity-based explanations, and toward the inclusion of critical features (Katz, 1972;Komatsu, 1992). In this classic view of critical features, necessary or sufficient features were deemed important in categorization that involved generalizable background knowledge.</p>
<p>In an example of critical features, consider the statement "not coming from Mars" as a necessary feature of the concept "human, " which can only be derived through background knowledge context (i.e., humans do not come from Mars). However, this classical theory may also be limited as many nonhumans also do not come from mars, so the classification of "necessary" may be overly simplistic. In another example, the concept "man" is a necessary feature of "bachelor, " however, some men are not bachelors. So, again, utilizing the simple idea of a "necessary" feature is clearly limited. Indeed, one of the main problems with the naÃ¯ve theory approach, is that the formalization of background knowledge into a specific model has been shown to be very difficult. As a result of this, only an intuitive account of background knowledge has been achieved through the cognitive categorization approach (Heit, 1997;Dreyfus et al., 2000;Pothos and Wills, 2011). The difficulties of tackling the very complex problem of background knowledge as a formal model, had led categorization researchers to return to similarity models and rule-based explanations to explain some of the simpler elements of knowledge effects on the categorization process.</p>
<p>Neural (connectionist) networks have also been used to model how people categorize stimuli, which utilize learned weighted associations between features in order to make classifications. One example of this is the competitive learning feature detector neural network (Rumelhart and Zipser, 1985) for unsupervised categorization. Another example is the adaptive resonance theory (ART) model, which is based on the stability-plasticity dilemma (Carpenter and Grossberg, 1988). The dilemma refers to the problem of how a learning system can remain adaptive or plastic in response to significant events and can remain stable against irrelevant events. The mathematical model uses a selforganizing neural network which organizes arbitrary input patterns in real time.</p>
<p>Though all of these models provide some basis for exploring how background knowledge can affect a categorization task, it is acknowledged these models are incomplete, as the models do not specify a framework which can be used in order to specify the relevant information (B. K. Heit, 1997;Hayes and Heit, 2013;Hawkins et al., 2016). This incompleteness stems in what is generally referred to by Heit as the knowledge selection problem, and it specifically relates to the problem, whereby, though the models discussed can address the processes in which background knowledge and new information are combined, they cannot address the processes for how a learner dynamically determines which background knowledge is most relevant, how this knowledge is generated, which context are important, and how causal connections and interrelations amongst concepts emerge within learning. As an example of this, consider Heit (1994) example of learning about joggers. In this study, and a follow up study (Heit, 1995), Heit demonstrated that information at various times points were being inferred and integrated, whereby new knowledge was derived from simple combinations of background knowledge and observations. However, this was a simple observation about the integration of knowledge, and was without a precise formal model to specify how exactly such information was being integrated and within what specific context. Heit (1994), had made specific observations that when participants were asked to categorize whether people in a new city were joggers, background knowledge was assumed to be used about joggers in a previous city. While this assumption may be straightforward in a laboratory context, real life contains an almost infinite number of possibilities for knowledge selection, such as cultural background, occupation, hobbies, prior city experience, etc. This makes the knowledge selection problem very difficult to circumvent.</p>
<p>One possible way forward which has been proposed is to explore knowledge inference and induction more formally, as Heit (1997) suggested, which comes from the reasoning and memory literature (Anderson, 1991;Ross and Murphy, 1996), and may give us some clues of how to progress theories in background knowledge for categorization, albeit still not a complete model. When utilizing reasoning in the form of induction, for example, you may expect that if you learn that a person belongs to a category of "salespersons" you may then infer that this person will try to sell you something. This of course is missing the importance of context, as a "salesperson" is only likely to sell you something in the context of the place where they work. So, any complete model would need both induction and sensitivity to context. Induction tasks are designed to answer questions about how participants can draw inferences for the information provided and when using background knowledge. A simple example of this would be asking a participant; 'Crows are likely to contract a disease, how likely is it that robins will contract a disease?' If the participant answers that it is likely that the robin will also contract the disease, this indicates that knowledge about the similarity between robins and crows may have been inferred.</p>
<p>Variations of this type of inductive reasoning task have shown that there are two kinds of inductive information which are important for understanding how background knowledge is generated and utilized within categorization tasks (Rips, 1975;Osherson et al., 1990). The first relates to the suggestion that when the premise category (e.g., crow) and the conclusion category (e.g., robin) are more similar, the induction inferences will have a stronger effect. The second is that lower rather than higher variability in the category leads to stronger inferences (Nisbett et al., 1983). In order to model these influences of inferences in category knowledge a category-based induction (CBI) model was developed (Osherson et al., 1990) which addresses some of these effects.</p>
<p>Another effect, called the selective weighting effects, has also been suggested as evidence of inductive reasoning. Here, focusing on certain features of the categories based on background knowledge has been suggested to be important (Heit and Rubinstein, 1994). For instance, consider this argument being presented to a participant: 'Robins travel shorter distances in the extreme heat. How likely is it that bats travel shorter distances in extreme heat?' In this case participants focused on the behavioral property "to travel" when comparing categories of robins and bats. As bats and robins are similar in that they both fly, then most participants inferred that bats and robins would be similar in the distance of travel when given extreme heat conditions. However, when asked a different way: 'Robins have livers with two chambers. How likely is it that bats have livers with two chambers?' Now the feature in comparing categories of bats with robins was focused on the "anatomy." As bats are mammals and robins are birds, participants inferred that it was less likely that bats and robins would be similar in terms of anatomy (two chambers in their liver). This selective weighting implies that knowledge selection is based on context, in this case functional properties of flying and anatomy.</p>
<p>Other more applied areas to consider, in for example the social domain (social categories), relate induction within the area of social psychology and relational memory, such as the influence of social stereotypes and schema which are social categories. Stangor and Ruble (1989) demonstrated that congruent commercials (girls playing with doll) were recalled better than incongruent commercials (girls playing with trucks). This may represent some important areas for applied work in the future, where a background knowledge model could help to identify relevant functional processes within the background knowledge which need to be targeted by some social intervention in order to remediate these types of stereotypes.</p>
<p>However, although these models are very encouraging, and have demonstrated that background knowledge affects category learning, where inductive learning and memory have been identified as important in this process, these models have still been suggested to be incomplete. Heit (1997) suggested that their incompleteness relates to the need for more complex conceptions of representation outside of just exemplars, prototype, and rule based models. From this perspective, he suggests, a multimodal representational scheme which accounts for both the relations among categories and the knowledge at multiple levels of abstraction, is needed, rather than overly focusing on whether one model (e.g., exemplar) provides a slightly better fit than another (e.g., prototype).</p>
<p>More recently in the last twenty years, specific modeling efforts for background knowledge categorization tasks have progressed very little. The more recent efforts of Heit and others have been to largely focus on similar problems of induction in categorization but more generally, and tweaking these types of models under different situations. For example, in one relatively recent study (B. K. Hayes and Heit, 2013), it was demonstrated that memory recognition shared some properties of induction. These category-based inductive inference models involve using the relations between categories to predict how individuals generalize novel properties of category exemplars, and reach conclusions that are likely but not certain given the available information. Jern and Kemp (2009) also showed that induction was involved in semantic repository, generalization, discovery, and identification, in relation to specific categorization tasks. The study identified, for example, that generalization was a problem for both supervised and unsupervised tasks, but unsupervised tasks also included the problem of relation discovery. Heit and colleagues have also explored how inferences are made over time, through the development of the Dynamic model for reasoning and memory (Hawkins et al., 2016). Through this model and corresponding data, they demonstrated that sequential sampling based on exemplar similarity and combined with hierarchical Bayesian analysis provided a more informative analysis in terms of the processes involved in inductive reasoning than the examination of choice data alone could provide.</p>
<p>So, induction and context seem to be an important avenue to further develop models for background knowledge. Unfortunately, however, many of the studies have focused on easier and more solvable problems such as congruent vs. incongruent tasks, or simple inference tasks. This perhaps falls short of what Heit had previously suggested, about the need for a multi-modal representational scheme which accounts for both the relations among categories and the knowledge at multiple levels of abstraction (Heit, 1997). Although these offer a useful starting point, they appear to tell us little about how or why knowledge is selected, i.e., they fail to solve knowledge selection problem. Developing a model which helps to understand what context knowledge is selected, or how the knowledge dynamically develops at a multi-modal representation level, and connects within a network of inference to allow for multiple levels of abstraction, are all important details in answering this problem.</p>
<p>In order to achieve this goal, a more general and holistic approach may be preferred, perhaps with new and fresh perspectives outside of traditional cognitive science approaches, and with a different ontological approach altogether. This approach should also capture a multi-modal representational scheme which will allow it to model multiple levels of abstraction and context. This should allow for greater ability to model more complex scenarios outside of simple congruence and inference tasks, such as how we make complex category decisions in the real world. For this, we propose considering other perspectives (in line with Heit's suggestion) outside of the usual memory trace based exemplar, and prototype domain, and more in line with his recent work of category induction. In order to do this, we propose exploring a comprehensive functional contextual account which considers inference in the form of derived relations. In addition to this, this will include multiple modes of non-arbitrary similarity functions and arbitrary nonsimilarity learned contextual functions in order to account for categorization learning which uses background knowledge processes, and which may be able to offer some greater insights into solving the knowledge selection problem through modeling contextual learning more comprehensively.</p>
<p>As such, one approach may be to focus on functions and equivalent classes more concretely, and in a more formalized way in the form of functional contextualism. Cognitivism is based on the theorizing about mental representation, where memory trace, attention, inference between exemplar representations, etc., are specified and highlighted. In this way cognitivism in categorization can be thought of as a philosophy of science consistent with the ontology of realism which is a phenomenological paradigm, and which assumes that much of our perceptual reality exists based on the language and concepts which our cognitive system produces (Zahidi, 2014). Functional contextualism, on the other hand, is based on the ontology of pragmatism, and contextualism (Pepper, 1942;David and Mogoase, 2015) which instead of mental representation, it emphasizes the importance of what specific factors predicts and influences emotion, thoughts and behavior (decision making) which include categorization tasks. Crucially, it identifies the context in which the function of concepts, stimuli, thoughts, etc., occur, and how these exert different control on behavior and decision-making, with an emphasis on how an organism interacts with historically and situationally defined contexts in order to explain how background knowledge emerges and influences category decisions.</p>
<p>Through this functional-analytic approach some of the very specific problems with the knowledge selection problem may be overcome. This is because ontologically the cognitive mechanism approaches largely try to define the form of the environment through similarity and rule based approaches. This contrasts with a functional contextual approach which tries to define the context in which stimuli exert some functional control over the behavior and decision processes of the individual -hence enabling a more structured way to model learning in context and therefore enabling greater predictive and descriptive power over subtle contextual dependencies in which inference learning arises. These specific conceptual and ontological differences (form vs. function) may be key to resolving the knowledge selection problem, as categorization decision making which is dependent on background knowledge may be largely defined by our contextualized learning histories which are specific to each individual given their experiences.</p>
<p>Functional contextualism, therefore, may be helpful in providing such a philosophical foundation for modeling and formalizing an account of background knowledge by incorporating functions and the context of environmental stimuli at a holistic level, and more concretely than previous modeling attempts through inference (derived relation) type processes. This approach focuses on functional properties (such as functional equivalence) and contextual cues. For example, in an example of functional equivalence by Sidman (1994), given the category of cutlery, forks, and knives may be grouped together because of the background knowledge that these items share the functional property "to eat with." However, in a different context, a knife may be used to peel paint off a wall (if you did not have a proper paint stripper tool) or defend yourself if you were attacked in the most extreme setting. Thus, the function is the purpose or use of that concept within a particular contextual setting. However, this early functional equivalence approach developed from Sidman (1994) has matured into a more formal model today. This approach is now embedded within the philosophical world view of functional contextualism, which defines that functions are dependent on context and specifically constitutes a post-Skinnerian behavior-analytic account of language known as Relational Frame Theory (RFT) (Barnes-Holmes et al., 2001;Blackledge, 2003;Torneke, 2010;De Houwer, 2013).</p>
<p>This fits well within the cognitive literature, as researchers such as Oaksford (2008) suggest that stimulus equivalence can to some extent explain the origins of reasoning, memory, and language generation. An equivalence class refers to the shared functional properties of items within that class (or category) which can be assumed to be equivalent (Sidman, 1994). For example, fork and knife are within the same category (or class) of cutlery and share the function "to eat with." Goldstone et al. (2018) accept that the items within a category can be broadly considered an equivalent class. If a functional-analytic approach can be adopted with regard to simple category similarity, then we propose that this approach can also be adopted to our understanding of the emergence of background knowledge.</p>
<p>THE LIMITED SUCCESS OF LINGUISTICAL SEMANTICS AND SEMATIC LOGIC OF ARTIFICIAL INTELLIGENCE IN ACCOUNTING FOR BACKGROUND KNOWLEDGE</p>
<p>The related field of semantics refers to the study of cognitive structures in the brain from a variety of perspectives including cognitive psychology, neuroscience, linguistics, philosophy, and AI (LÃ¶bner et al., 2021). There are several branches in semantics. Formal semantics is particularly relevant to the study of background knowledge in categorization, and can offer some useful perspectives. For example, it does not focus directly on cognition, and instead it focuses on natural language, such as the logical relations within sentence structures (e.g., equivalence) which give meaning to the language being expressed (LÃ¶bner et al., 2021). As such, one very important observation made in some seminal work of the formal semantics domain (Montague, 1970;Lewis, 1976) is that meaning embedded in some linguistic content is context dependent. Influenced from this early work, most semantic theories now adopt some form of pluralism about linguistic content and its attributed meaning based on this context-dependency (Potts, 2004;Zimmermann, 2012;Ciardelli and Roelofsen, 2017). Context here can relate to the objective and subjective meaning of a given linguistic sentence, epistemic content, intentional content, etc., in order to assign truth-values to linguistic utterances (LÃ¶bner et al., 2021).</p>
<p>This context dependency work has also highlighted crosslinguistic, and cross cultural linguistic differences that can alter and shape the meaning of concepts and sentences, which indicates that linguistic meaning is more complex than the words formed in a sentence (Machery et al., 2004;Smith et al., 2018). One of the perhaps most well know theories to have emerged from this work is called the Sapir-Whorf 's linguistic relativity hypothesis which suggests that the structure of language affects the speaker's cognitive worldview (e.g., Eskimos have many more words to describe and conceptualize snow than Europeans), and that the perception people develop about some concept is relative to the context of their spoken language (Koerner, 1992;Hussein, 2012;O'Neill, 2015).</p>
<p>Another branch of semantics which is relevant to studies in categorization theory of background knowledge is lexical semantics, which emphasizes linguistic concepts in the context of frames which attribute-value structures (Fillmore, 1976;Barsalou, 1992Barsalou, , 2014. Here, a cascade is a combinations of frames in a tree, and category prototypes are structured within these knowledge trees. The frames mediate the input information and output behavior through a Bayesian inference model of category learning (Taylor and Sutton, 2021). Frame-theoretic representations in the form of recursive attribute-value structures organized around a central node is clearly an improvement compared to simple feature list models (Anderson, 1991;Sanborn et al., 2006;Goodman et al., 2008;Shafto et al., 2011). For example, a feature list would simply consist of a list of features, e.g., fur, black, and soft, however, a semantic cascade of frames can add further information to the features, such as representing how these features are related by defining each feature as a value of some attribute. For example, by specifying through a frame that fur has two attributes -color (black) and texture (soft). These types of Bayesian models can allow frames to assign more or less weight to attribute values given their importance in the category structure.</p>
<p>These semantic theories have not just influenced our understanding of cognition, but they have a long standing bidirectional relation with influencing and being influenced by work in computer science, specifically in the area of attempts to formalize approaches of logic and linguistics for general knowledge in the discipline of AI through the development of knowledge tree attribute-value matrices of computational linguistics (GÃ¤rdenfors, 2004;Gardenfors, 2014). AI was developed in the 1950, and were largely based on mathematical logic programming such as propositional logic (assigning truth and false to statements), first order logic (formulas which specify some relation to objects) and second order logic (specifying relations between relations), as well as conditional logic (IF-THEN rules) (Luger, 2005;Stuart and Peter, 2020). In line with semantics which seek truth in statements, logical statements of truth can be interpreted as formal semantics, and drew from these early AI approaches. In an example of first order logic, the statement "there is a mother to all children, " can be stated as:
(âˆ€x) child (x) â†’ âˆƒy mother y, x(1)
Whereby âˆ€, expresses "for all instances, " child is x, â†’ is a connective between the two statements (where this connective is only true if both statements are true), âˆƒ expresses "there exists, " mother is y, y, x, denotes y for instance x. This is constructed as a statement of truth, through the use of the connective symbol (i.e., by explicitly stating, when this statement is true, this statement is also true).</p>
<p>These semantic approaches developed further as cognitive semantics emerged in the late 1970s out of cognitive linguistics and mathematical logic, largely based on the initial work of Noam Chomsky's (a linguist) semantic structures, theory of generative grammars (Chomsky, 1957), and largely due to the dissatisfaction of behavioral approaches (at the time) to explain a model for natural language (Andresen, 1991;Harris, 2010Harris, , 2021. Hence, this early work in AI and cognition was heavily influenced by formal approaches of cognitive semantics (Kuznetsov, 2013;Stuart and Peter, 2020).</p>
<p>However, these approaches have been entirely unsatisfactory, and have only led to very narrow approaches to AI, and have not led to the ability of AI to develop broad and deep general knowledge about the use of language in the world (Floridi, 2020;Stuart and Peter, 2020;Toosi et al., 2021). Perhaps the biggest limitation with this approach is that, though context was highlighted early as important, these development were based on narrow and overly simplistic forms of knowledge trees, which do not capture rich contextual structure in the real world. The problem of developing AGI has been suggested (Mitchell, 2021) to depend on some more generalized accounting of (background) knowledge that goes beyond simple statistical, or similarity methods which are limited in nature.</p>
<p>Since this early work on semantics there has been many breakthrough with machine learning approaches, and mathematical models of reinforcement learning (behavioral approaches) are making a return (Silver et al., 2021), and may (with functional context) be an important part the solution for AGI. Deep learning neural networks (DNN) have recently been developed with the advent of powerful processing computers (which as not the case decades ago) which has allowed researchers in the area of semantics to exploit (Rogers and McClelland, 2011) which extends previous work of distributed memory model  and the semantic memory models (Hinton, 1986;Rumelhart, 1990;Rumelhart and Todd, 1993;Hinton and Anderson, 2014). This allows the model to capture complex structure based attributes as well as relational components, and is perhaps the most promising work within semantics (which is relevant to background knowledge) at this time. This, therefore, may represent a promising way forward for modeling background knowledge in a categorization setting, and general knowledge more widely. However, the relational attributes within this approach are still very limited (e.g., "can, " "is, " etc.), representing simple word structures, and may need to be further developed and updated from a model which specializes in deep contextual (relational) learning.</p>
<p>A FUNCTIONAL CONTEXTUAL ACCOUNT OF BACKGROUND KNOWLEDGE -A POTENTIAL SOLUTION</p>
<p>One approach which we may look to progress semantic models is Relational Frame Theory (RFT), which is a modern behavioral theory of human language and cognition, which is rooted in functional contextualism (it represents the formal organizational model of functional contextualism), and offers a formal model within a functional-analytic approach to higher cognition (Barnes-Holmes et al., 2001;De Houwer, 2013). In doing so, the theory extends Skinner's concept of verbal operants to include generativity (thus accounting for Chomsky's criticism of the behavioral theory) to capture greater complexity within cognition. From an RFT perspective, language can be thought of as learned patterns of generalized contextually controlled, derived relational responding (somewhat similar to inference), called relational frames (Barnes-Holmes et al., 2001). With its basis in functional contextualism, the theory focuses on the role of context (via contextual cues) in facilitating the emergence of specific patterns of relating and how (behavioral) functions come to be attached to these patterns.</p>
<p>Relational responding can be either arbitrarily applicable or non-arbitrary in nature. Non-arbitrary relational responding is based on physical features (such as magnitudes of size, shape, or color) of the stimuli involved (not unlike similarity theories in the categorization literature). By contrast, arbitrarily applicable relational responding is not based on formal stimulus properties but is instead largely controlled by historical contextual learning. The theory specifies several different patterns of arbitrarily applicable relational responding, including (but not exclusively): co-ordination (e.g., stimulus X is equivalent to stimulus Y); comparison (e.g., A is bigger than B); opposition (e.g., up is the opposite of down); distinction (e.g., C is not the same as D); hierarchy (e.g., an Alsatian is a type of dog); and perspective-taking (often referred to as deictic) which involves the interpersonal (I vs. YOU), spatial (HERE vs. THERE) and temporal relations (NOW vs. THEN).</p>
<p>Relational Frame Theory appears to share some features with rule-based categorization but relies specifically on a history of operant conditioning across a wide range of situations in order for the early patterns of relating to be established. Indeed, the focus of a relational frame, and its definition, require the development of three properties: (1) In mutual entailment (ME), relating to one stimulus entails relating to a second stimulus. For example, if A = B, then B = A. Similarly, if you are told that X1 is smaller than X2, you can derive (entail) that X2 must be bigger than X1. (2) In combinatorial entailment (CE), relating a first</p>
<p>Male Female</p>
<p>Married Unmarried</p>
<p>Bachelor Male</p>
<p>= distinction relation = coordination relation FIGURE 1 | An RFT interpretation of a simple relational frame of coordination between the concept bachelor and the concept male. This includes a distinction relation between male and female and a distinction relation between married and unmarried(Images from adobe stock with license and permission to use and modify given. Credit for image on right "pathdoc" and image on left "wedding photography").</p>
<p>stimulus to a second and relating the second to a third facilitates entailment between the first and the third stimuli. For example, if you are told that A is greater than B and B is greater than C, you will derive (combinatorially entail) that A is greater than C and C is less than A.</p>
<p>(3) The third core property of a relational frame is known as the transfer (or transformation) of stimulus function (ToF), through which the functions of any stimulus that participates within a relational frame may be transferred or transformed in line with the relations that stimulus shares with other stimuli also participating in that frame. For example, consider a situation whereby a shock is delivered to your arm each time stimulus A appears on a screen. If you are then told that stimulus B is greater than A, fear in the presence of B can actually be stronger than fear in the presence of A, even though shock was directly paired with A and not B. This is because fear as a behavioral function that is established to A is transferred to B in greater magnitude because of the established relation that B is greater than A. In other words, the fear function is transformed (increased) because of the comparison relation between A and B (Dougher et al., 2007). For RFT, complex social concepts or background knowledge are established as broad patterns of arbitrarily applicable relational responding (AARR) in the form of complex relational networks and adjoining behavioral functions. For example, the accepted social knowledge that "all bachelors are males" involves at least the following: a co-ordination relation between the concept bachelors and the concept male; a distinction relation between male and female; and a distinction relation between married and unmarried (see Figure 1). In other words, for RFT we acquire broad and complex knowledge through verbal operant conditioning, including how males and females differ, why a bachelor is a man, but why a man may not be a bachelor. Each, on the surface, appears to be a simple concept or a comparison of simple concepts, but for RFT the stimuli or concepts participate in much more complex patterns of related or integrated social knowledge. This, therefore, does away with any need to specify a necessary or sufficient feature, and instead prefers context dependent relational networks and associated behavioral functions, which may provide a more accurate account of how causal connections and interrelations within background knowledge about these concepts emerge within their context and influence categorization behavioral decisions about these and other related concepts. As the next section will demonstrate, this approach may help extend existing background knowledge categorization models in interesting ways to help resolve the knowledge selection problem. It will do this by offering some insights into how knowledge is selected in background knowledge categorization tasks, by specifying the context in which stimuli is presented (i.e., via contextual clues) and explain how the relevant functions of stimuli emerge as they dynamically change through inference based (derived relational) networks. Crucially, this will offer some explanation as to how category decisions based on background knowledge are made.</p>
<p>SPECIFIC EXAMPLES OF CATEGORIZATION MODELING FOR BACKGROUND KNOWLEDGE AND WHY A FUNCTIONAL CONTEXTUAL MODEL MAY IMPROVE ON THESE ACCOUNTS</p>
<p>In one attempt to use a similarity-based model to address background knowledge, Heit developed the integration model of categorization (Heit, 1994), which has been explored in a number of background knowledge studies (Heit, 1994(Heit, , 1995(Heit, , 1998. In this approach, Heit had modified the similarity based exemplar model (Medin and Schaffer, 1978) in a way which would take into consideration influences of background knowledge such as congruence in category learning (Heit, 1994(Heit, , 1997.</p>
<p>Several studies have found supporting evidence for congruence in category learning. For example, if a question is presented to participants which is congruent with their existing background knowledge, this will more likely facilitate their memory (Greve et al., 2019), learning of relational properties (Ostreicher et al., 2010) and the classification of new items as consistent with the background knowledge they have (Heit, 1994). For example, in a study presented by Heit (1994), participants were asked a congruent question such as 'how likely is it that someone with expensive trainers is a jogger?' , and this was compared with an incongruent question such as 'how likely is it that someone who attends parties is shy?' It was found that participants were more likely to judge a new person as being a jogger when asked a question which was congruent to the background knowledge of the participant rather than incongruent.</p>
<p>However, in the same study by Heit (1994) it was demonstrated that congruence with background knowledge was not always the strongest factor in influencing categorization behavior. Specifically, Heit found that integration model outperformed the distortion model in predicting whether a group of individuals were "joggers" or not, given a set of categorization behavior. During an experimental setting in this study, participants were shown a training set of joggers (including associated behavioral characteristics). The distortion model predicted that the learned exemplars about these joggers in this experimental setting would undergo a form of distortion in memory to fit better with the previous background knowledge about joggers that the participants had learned over the years (such as joggers typically have expensive trainers), in order to be more congruent with their background knowledge. However, instead of undergoing distortion, the "new joggers" selected by the participants were more similar to the "jogger" training set shown, as opposed to features which were consistent with background knowledge (features typical to joggers).</p>
<p>There are two problems with the above approach. Firstly, and most importantly, congruence in category learning only explains why knowledge is selected in very specific cases and tasks. This is an incomplete model of background knowledge. Secondly, the model fails to predict or explain in what cases some similarity function, or some distortion of memory should be preferred in order to increase congruence with background knowledge. The ability to capture and predict cases of congruence with background knowledge may be captured more accurately utilizing the functional contextual (RFT) model. The RFT approach assumes that relational framing occurs amongst the properties of background knowledge of a typical jogger and some new instance of jogger, which allows for congruence.</p>
<p>So, in this case the non-arbitrary properties would be consistent with a more similarity based situation, whilst arbitrary properties would be consistent with the background knowledge of the jogger. From there, the attributes of the concept "jogger" are related in the network according to the properties of ME, CE, and ToF, where information is derived within the network according to information which can be coordinated, opposed, or where a distinction is made (hence, for example, coordinated concepts would be more congruent that those which are opposed in the network). Hierarchical information can also be held, such as structuring joggers within the network as containers of their personal values such as "healthy living, " "fitness, " etc., through determining the function of their behavior (i.e., why do joggers jog?) which may give more clues about relevant background knowledge of a typical jogger, and the crucial knowledge which needs to be selected dependent on some experimental context. Crucially, RFT can specify how this knowledge is structured within a relational network, and how context of a categorization task (what it asks the participant to categorize exactly) can help determine which knowledge is specifically selected (i.e., the context determines this). For example, if a participant in a study were asked to categorize the personal values of a jogger, then the hierarchical component of the network may be recalled to help the participant decide that jogger's value "healthy living" and "fitness" based on the participants functional interpretation of why a joggers jog (i.e., RFT determines functions within context are crucial for understanding which knowledge is selected, and thus provides some insight into overcoming the knowledge selection problem).</p>
<p>The RFT model also goes beyond simple congruence by specifying under which conditions equivalence, opposition, mutual entailment, and combinatorial entailment occur more globally, so its ability to specify precisely how congruence can emerge is understood precisely through the models' ability to predict under what circumstances entailment is generated in the relation network given very specific modeling of historical reinforcing contingences. Some recent evidence has shown that the model was able to accurately predict relational framing of categories in three domains, which included non-arbitrary, arbitrary containment, and arbitrary hierarchical relations (Mulhern et al., 2017). In that study, language and cognition which are relevant to background knowledge were assumed to be patterns of generalized, contextually controlled relational responding. The researchers suggested that this approach offers a more global accounting of knowledge generation and is in contrast with the more localized environment-behavior interactions prediction of congruence formations as is seen in many categorization approaches used Murphy, 2002;Palmer, 2002).</p>
<p>In another example, rule-based approaches of categorization describe how "if " and "then" logical rules are used to define a category (E. E. Trabasso and Bower, 1968;Smith and Sloman, 1994;E. E. Smith et al., 1998), for example, "if " X barks "then" X is a dog. Evidence has shown that in some situations rules do apply (Rouder and Ratcliff, 2006). It has been suggested that rules can be applied to many settings, such as when recognizing that 683 is an odd number (Armstrong et al., 1983) and why raccoons' offspring look like skunks but are not skunks (Keil, 1989). However, there are some problems within the categorization literature as current categorization models do not have any means to specify specific rules, identify the context in which rules emerge from environmental stimuli, or how they can be organized into complex background knowledge.</p>
<p>There have been some useful rule based models such as the competition between verbal and implicit systems (COVIS) model (Ashby et al., 1998) which suggests that explicit verbal (rules) and procedural (implicit) systems which integrates information at the point of pre-decision, are adopted depending on the context of the situation. Some evidence has suggested that implicit procedural information is integrated when it is difficult to define the rules verbally, but when these can be defined verbally, they usually supersede the procedural system (E. E. Smith et al., 1998). However, others have acknowledged that the exact interplay between rules and procedural systems has yet to be discovered (Milton and Pothos, 2011).</p>
<p>Some more specific rule-based explanations of the effects of background knowledge on categorization have been applied in conceptual acquisition tasks. These tasks were developed in order to identify situations where the background knowledge may facilitate or hinder concept acquisition. In an example of this, Pazzani (1991) used conceptual acquisition tasks involving photos of people performing actions on objects. Each picture showed either an adult or child performing an action on an uninflated balloon (dipping it in water or stretching it) that varied in size and color (it was either large or small, and either yellow or purple).</p>
<p>Pazzani compared two types of categories -a disjunctive category, and under what conditions would each of these emerge. In one experiment the participants were instructed to either learn about a category of balloons that inflate or learn something about an arbitrary category simply labeled Alpha. The assumption made by Pazzani was that participants in the inflate category would be influenced by their background knowledge about what would be needed to inflate the balloons, whereas no such influence from background knowledge would take place.</p>
<p>In their pre-test study, Pazzani found that the action of stretching a balloon would facilitate participants expectation that a balloon would inflate, and that adults would be more successful at inflating the balloon than children. The stimuli used in the experiment were pictures of scenes which differed on four dimensions; (1) adult or child; (2) stretched balloon or balloon dipped in water; (3) yellow or purple balloon; (4) and small or large balloon. For the disjunctive condition, a disjunctive rule defined the inflate category, i.e., that these balloons must be stretched or inflated by an adult. As the pretest study showed, this should be consistent with the background knowledge that the stretching of a balloon by an adult is more likely to lead to the balloon being inflated (i.e., adults are stronger and more capable to inflating a balloon than children, as well as the knowledge that balloons are stretched when they inflate). In the conjunctive condition, the target category (Alpha) was defined by the arbitrary rule, that these must be small and yellow. This rule is not consistent with any background knowledge about inflating a balloon. As expected, Pazzani found that learning was faster for the disjunctive-inflate condition than the conjunctive-Alpha condition. It was concluded that as the disjunctive-inflate condition was consistent with the existing background knowledge, it was easier to learn than the inconsistent disjunctive-Alpha condition. Pazzani concluded that this was evidence that demonstrated that a simple similarity function in the form of feature selection does not connect category knowledge, rather it is background knowledge which bind the category knowledge in these tasks.</p>
<p>The functional contextual (RFT) approach may be able to improve both the descriptive and predictive power of why the disjunctive rule was followed and not a simple similarity function. Here RFT can account and explain the specific context in which background knowledge emerges based on some hierarchical organization of rules which supersede a similarity function. More specifically, RFT can explain the context in why the disjunctive rule was followed in the Pazzani (1991) study, as derived relations between predicting whether the balloon would inflate, and the background knowledge provides relational clues about likely hypotheses such as the age of the person carrying out the action, and this (according to RFT) is structured within a complex hierarchical and relational network (i.e., inflating the balloon action "belongs to" a specific person who was stretching the balloon). Similar to the previous example about joggers, the context of the study provides clues as to what the relevant functions of the behavior are (i.e., someone inflating a balloon may be doing so to stretch it), and may, therefore, help determine which knowledge should be selected in the participant's hierarchal relational network in order to make a category decision. The specification of an explicit rule which is consistent with the hierarchical background knowledge associated with stretching a balloon, may supersede any similarity function in a similar way as any explicit rules supersede implicit integrated knowledge in procedural tasks. This RFT approach, again, may help provide greater context for solving the knowledge selection problem by specifying the functions relevant to a specific context, and outlining how this knowledge is connected dynamically within a participant's relational network, and utilized in a categorization task that draws on background knowledge.</p>
<p>To support this claim, there has been much empirical evidence for the way RFT structures knowledge within relational networks. For example, evidence of RFT has been able to accurately predict and specify complex ruled based organizations of hierarchical responding in categorization tasks (Greene, 1994;Slattery et al., 2011) which may be seen as a particular type of relational responding called hierarchical relational framing, and which may form via a non-arbitrary relational pattern such as containment. For hierarchical classification, the classes themselves are categorized into higher order classes (Greene, 1994;Slattery et al., 2011). An example of hierarchal classification could be ordering "Alsatian" into (contained within) the category "dog" and "dog" into (contained within) the category "Animal." This distinction of hierarchy seems similar to the cognitive interpretation of hierarchy, except the RFT model is providing a broader relational framework in which hierarchical processes occur. For example, in one study of hierarchical relational responding of categories (Gi et al., 2012), there were five phases to the study. In phase one, four arbitrary shaped stimuli were established as, and several contextual cues were given such as "includes, " "belongs to, " "same (similarity)." In the second phase, the arbitrary shaped stimuli were trained and tested for derived arbitrary sameness (equivalence), i.e., between the arbitrary stimuli and some nonsense words. In the third phase, deriving relations of containment between lower (novel and additional) and higher levels (identified through the cues "includes, " and "belongs to"), induced responding in accordance with higher levels in the hierarchical network. In the fourth phase, particular functions were established in particular stimuli (i.e., some stimuli were directly trained to associate a function, e.g., the function of fear) at different levels of the hierarchical network. In the final phase, patterns of ToF were demonstrated where stimuli acquired novel untrained functions because of their position in the network. Therefore, again, RFT can specific complex hierarchical networks for which background knowledge can be stored, relationally structured with other concepts and knowledge, and recalled to help the participant identify a category decision based on clues of functions relating to concepts, events, and behaviors given some specific context, and drawn to make categorization decisions.</p>
<p>Connectionist models in the form of neural networks have also been used to explain the influence of background knowledge (Gluck and Bower, 1988;Shanks, 1991). In these models, category learning is thought to correspond to a set of weighted association of nodes, which activate in response to an input pattern. Choi et al. (1993) used connectionist neural networks to model how learning disjunctively defined concepts is easier than learning conjunctively defined concepts. In connectionist neural networks these hypotheses can be simulated with negative (inhibitory) links between nodes for conjunctions and output nodes which correspond to category labels. After many variations, Choi and colleagues incorporated background knowledge into Kruschke (1992) attention, learning, covering map (ALCOVE) model which represents a hybrid between an exemplar (similarity) and connectionist model. In the original version of a two layer backpropagation model of ALCOVE, this did not fit rule-based data very well, however, when implementing background knowledge biases into and adapted version which consisted of a neural network, whereby the biases were captured by the network weighting (through training), categorization performance improved dramatically. This demonstrates the usefulness and flexibility of neural networks for the study of approximating background knowledge in category learning.</p>
<p>Other notable connectionist methods have included the, and the knowledge resonance model (KRES) (Rehder and Murphy, 2003) and the Baywatch model which is a Bayesian and connectionist model (Heit and Bott, 2000). The KRES model is a connectionist model which takes account of background knowledge, but unlike other approaches, it uses a recurrent network with bidirectional symmetric connections whereby the weights are updated by a Hebbian learning rule instead of a feedforward network which relies on a delta rule or backpropagation. Rehder and Murphy assume that knowledge is directly learned or attributed through an inferential process, and they have shown that some inferential properties can be captured through their network. The Baywatch model is very interesting and has had some success in tackling the knowledge selection problem. This is a neural network model which includes Bayesian probability, and converts the networks activation outputs into a probability measure of the likelihood categorizing in a particular way based on some given background knowledge. In order to do this, the model uses the logistic transformation as outlined in Gluck and Bower (1988) (see formal mathematical approach section below, there, this is utilized and expanded on for an RFT interpretation). The network was able to progressively learn which sources of background knowledge correspond to some target categories -hence identifies in some instances which knowledge is selected in these types of tasks.</p>
<p>However, though these connectionist models are useful, and heading in the right direction, they are currently overly simplistic with a single hidden layer and with only three layers in total. Much of the AI literature suggest that deep (multi-layered) networks are more able to capture knowledge properties (Mitchell, 2021). Furthermore, RFT goes beyond simple inference learning (which the connectionist networks are trying to capture). For example, evidence has shown that by using the RFT model, researchers are able to predict how relationally framed patters of ToF emerged throughout the network, and this makes this framework unique when compared to simple hierarchical or Bayesian inference frameworks of order which are typically described within the categorization literature (Murphy and Lassaline, 1997). The RFT approach, instead, precisely defines the controlling function of the stimuli and under what context does such inference occur. For example, Slattery and Stewart (2014) demonstrated many knowledge based properties which could be captured via the RFT approach, and argued that hierarchical relational framing involves two forms of hierarchical responding, both hierarchical classification as well as hierarchical containment. They found multiple properties of unilateral property induction, transitive class containment, and asymmetrical class containment, which again shows how RFT was able to model complex relational networks within hierarchical organizations applicable to categorization, and beyond the simple inference accounting and knowledge induction of previous connectionist models such as the Baywatch model (Heit and Bott, 2000).</p>
<p>One of the core advantages of RFT's approach to background knowledge, over and above the previous categorization models mentioned lies not only in its ability to account for high levels of complexity, inference, and context, but also to account for meaning and the effect of a given stimulus, through ToF. Consider the real world example where in a laboratory experiment participants are asked (these would be the dependent measures) to (1) categorize whether the woods are safe, and (2) whether the woods are safe enough to walk through. In this experiment, the participants are told that poisonous snakes live in these woods. The participant when deciding whether the woods are safe or not, may draw on their background knowledge about the snake and themselves. For example, when considering the concept of a snake, the relevant background knowledge can include the common rule "Stay away from snakes, they're dangerous, " and the very real fear that likely emerges for some when you are near a snake, even when it is in a terrarium. For RFT, fear is an established function of actual snakes and the word "snake" (fear and snake will be coordinated even if you have never seen a real snake). This also applied to the written word "snake" which is also coordinated with the actual "snake" and the verbal word "snake" (see Figure 2).</p>
<p>So, in a condition when the participant is told that there may be snakes in the woods. Even without seeing a snake there, the function of fear will be transferred to the woods as soon as you hear about the possibility of snakes living in the woods. This is because the concept of snakes (and the attached fear function) is contained (relationally) within the concept of woods, so that the fear of snakes transfers to woods and now you are afraid of just entering the woods (see Figure 3). In other words, woods helplessly evoke fear of snakes. It is even possible that if you are very afraid of snakes, you would avoid woods altogether, without consciously intending to do so (i.e., an avoidance function is established to woods).</p>
<p>As a result, the background knowledge of the participant's concept for woods as well as their behavior regarding woods can be altered considerably, and RFT provides a model for how background knowledge develops and changes over time. So, it is clear to see through this framework how the background knowledge of snake and woods are derived. In a background knowledge categorization task, where an individual is asked to categorize whether the woods in this circumstance (which contain snakes) is safe, then the knowledge selection clearly involves derived (induced) knowledge of fear functions about snakes and the woods. Of course, though, these derived relations can be scaled up and without any limit on scalability, to include many other derived relations which the individual may network together in terms of the concepts of safe and woods. RFT allows for this continuous scaling up, as new relevant information can be continually added to the relational network model as they are identified, and the framework can thus explain how the processes then further build in additional new background knowledge, and how this will affect a background knowledge related category decision.</p>
<p>It is also important to note that this background knowledge may not have been directly trained and is not based on any form of similarity function between woods and snakes, such as would be stipulated in the exemplar model such as the GCM that try to model background knowledge. In contrast, RFT can explain complex arbitrarily applied relationships among concepts and how these can activate complex behavioral functions in specific contexts. This approach thus goes some way in explaining what types of background information are relevant given the specific learning history of the individual and the context of the categorization task, thus providing greater context for further research to tackle the knowledge selection problem more generally.</p>
<p>In relation to a background knowledge categorization tasks specifically, for example, where we are trying to predict how an individual will categorize whether a particular woods is safe enough to walk through or not, then as suggested, this can be scaled up beyond simple fear of snake. RFT's framework for describing behavioral outcomes over a wide range of situations, through the frames defined of ME, CE, and ToF, may be helpful as this can help specify complex contextual histories which may help identify how background knowledge is developed, and changes over time, given different contextual settings.</p>
<p>In scaling up, further relations can be added. For example, if you had experienced many accidents within your life, and felt that something always bad happens to you, you may frame yourself in the context of "I" as "bad" and "a failure" where "always bad things happen to me, " thus is "likely to get bitten." This may then have affected your self-esteem and confidence in a negative way (see Figure 4), and with low self-esteem and confidence, with an expectation that something is always bad is going happen to you, this may cause more avoidant type behavior, and lead to greater certainty you would indeed categorize the woods as "something unsafe and to be avoided" (see Figure 5). Alternately, if the persons contextual history contained many examples of success, and praise from others, they may derive that their derived concept of self "I" is "good" and "successful" where "only good things happen to me" and this may lead to higher levels of self-esteem and confidence (see Figure 6). This may then lead you to conclude that despite feeling fear of the woods, you are confident that you will not get bitten, and as a result may still categorize the woods as "unsafe" but do not categorize the woods as "something to be avoided" (see Figure 7).</p>
<p>RECENT HYPERDIMENSIONAL RELATIONAL FRAME THEORY DEVELOPMENTS WHICH EXPANDS THE DYNAMICS OF RELATIONAL FRAMING WITHIN THE CONTEXT OF BACKGROUND KNOWLEDGE</p>
<p>There have been recent developments of the RFT model worth noting, which maybe additionally useful for studying background knowledge in categorization. The first is the recent development of an RFT framework called multidimensional, multilevel (MDML) framework . According to this framework, AARR is assumed explicitly to be able to account for much more complexity than suggested by the standard RFT model (Barnes-Holmes et al., 2001). MDML (RFT) assumes that AARR can develop from not just; (1) mutual entailment; and (2) simple networking involving frames (coordination, distinction, etc.); but also (3) more complex networking involving rules; (4) the relating of relations such as involved in analogical reasoning; and (5) relating relational networks which are involved in extended narratives, and advanced problem solving (which maybe typical for complex background knowledge narratives). The framework also specifies each of these five levels as having multiple dimensions: coherence, complexity, derivation, and flexibility, so has a broader analytic framework, which again maybe particularly useful in the study of background knowledge of categorization.</p>
<p>Coherence refers to the extent to which patterns of AARR are consistent with other patterns of AARR. For example, stating "A motorbike is larger than a train" would be lacking coherence with the wider verbal community (who may state the reverse, i.e., "a train is larger than a motorbike"). However, in another context the statement maybe coherent, if for example, the person verbalizing the statement was playing a game, where the objective of the game was to "state the opposite of how you believe concepts actually relate" (Barnes-Holmes et al., 2020). It is perhaps important to note that this extends the notion of coherence as expressed in the categorization literatures (Rosch and Mervis, 1975;Murphy and Medin, 1985) which assumes it relates to a similarly function of intuition, instead MDML (RFT) framework refers to the coherence of more specifically defined (contextual) derived learning.</p>
<p>Complexity refers to the level of detail or density of the AARR. For example, a mutually entailed relation of coordination maybe seen as less complex than a mutually entailed relation of comparison, because the later has two types of relations (if X is faster than Y, then Y must be slower than X) vs. the former which only has one relation (If X is the same as Y, then Y is the same as X). This is likely naturally important for studying background knowledge as some instances of knowledge will be more complex than others and therefore likely to require more modeling efforts to successfully capture such complexity. An important measure here, from a cognitive perspective, could be the level of entropy (uncertainty) in the network, with more complex networks naturally carrying more entropy. The success of the networks could be ultimately assessed by their ability to reduce entropy across the network by accurately capturing environmental patterns of AARR.</p>
<p>Derivation refers to how often a particular derived relational response has been emitted previously. The greater the derivation, the less derived those emitted responses become, because it establishes its own history beyond that of the derived relation that was initially made (the baseline relation). Again, this is an interesting dimension in this framework, and similar patterns of establishment have been observed in cognitive science such as within the unitization of sequence information. After much practice, the sequence information have been found to become compressed into their own unit of information inseparable to that of its sub-components (Perlman et al., 2010(Perlman et al., , 2016.</p>
<p>Flexibility refers to the extent to which a given instance of AARR is modifiable by current contextual variables. For example, if someone is asked to respond with the wrong answer to the question "Which is larger, a motorbike or a train?", the easier this would be for the participants to achieve, the more flexible their corresponding AARR network would be. Flexibility maybe particularly important when modeling background knowledge under changing context such as during task switching studies, and maybe heavily related to the other dimensions in this MDML framework such as coherence.</p>
<p>The MDML (RFT) framework, however, has been even further developed, as it focused mainly on entailment relation (C rel ) properties of AARR and largely ignored functional (C func ) properties of AARR. So, it was further integrated with another RFT adapted framework called differential arbitrary applicable relational responding; DAARRE (Finn et al., 2018) specifically for specifying functional (C func ) properties explicitly in the model. This integrated framework (integrating MDML with DAARRE) has been now called the hyperdimensional multilevel (HDML) framework (Barnes-Holmes et al., 2020). The HDML framework for RFT builds on the previous properties of RFT (DARRE and MDML) and specifies the dynamic interplay of AARR (called ROE; relating, orientation, and evoking) in verbally able humans, whereby: (1) relating refers to the myriad ways of events maybe verbally related; (2) orientating refers to noticing or attending to stimulus events; and (3) evoking refers to whether some noticed stimulus (e.g., a concept) or event is functionally appetitive, aversive, or neutral.</p>
<p>This recent work is likely useful in the study of background knowledge of categorization, as background knowledge is likely to involve complex extended narratives, which HDML (RFT) can account for through specifying, for example, the coherence,</p>
<p>Trained</p>
<p>Derived</p>
<p>Arbitrary applicable responding</p>
<p>Transformation of stimulus function</p>
<p>More likely to brave scary things in the future. Feelings of success. High selfesteem. FIGURE 7 | An RFT interpretation illustrating complex frames of derived background knowledge, and how concepts can transfer functions in category learning to develop new functional categories, thus building up the complexity of existing background knowledge(Images from adobe stock with license and permission to use and modify. Credit for image from left clockwise around: "Tardigrade," "AA + W," "kuritafsheen," and "iQoncept"). complexity, derivation, and flexibility of relevant AARR, and dynamically under different context. Specifying relating of relations and relating relational networks maybe particularly relevant, as background knowledge may compromise relating several networks which are related in some way. For example, this maybe applicable to the network for jogger, and a network for city location as in the study example given by Heit (1994), or a network for snake type, a network for the self, and a network for woods in the example provided in Figures 5, 7. This may encourage analysis of the knowledge networks that extend beyond the simple level of the frame and to take into account C rel and C func within a broader relational framework.</p>
<p>In an example of complexity, consider the example given in Figures 5, 7. Here, a specification of AARR was given about the individual (verbal) self ("I am. . . good or bad") in these scenarios. Here, verbal self becomes a network (see Figures 4, 6) with deictic (perspective-taking) relations (I-You, Here-There, Now-Then) which explain the self as becoming increasingly entangled as the complexity of the AARR network increases (Barnes-Holmes et al., 2020). So, in the example of whether the woods is safe enough to walk through, the verbal self plays an important role in this categorical decision, as well as its associated entangled relating networks. Figures 5, 7 (which are examples of relating relational networks) involve the (network 1) hierarchical relation of "I" within the woods and this naturally brings about the relevant AARR network relations that may define the verbal self ("I") in that context. For example, Figure 4 demonstrates an AARR network relation of an "I" that has derived failure, which then can be explained by HDML (RFT) as the network orientating thoughts about failing and getting hurt, and evoking feelings of failure, hopeless, low-level esteem, and therefore leads to a greater behavioral tendency for avoidance when confronted by difficult situations (such as a possible dangerous snake in the woods). In contrast, Figure 5 demonstrates an AARR network relation of an "I" that has derived success so orientates thoughts about being successful, and evokes feelings of being safe and confident, which therefore lead to a greater behavioral tendency for taking greater risk in the face of difficult situations such as when possibly confronted with a dangerous snake in the woods.</p>
<p>These scenarios (Figures 5, 7) relates (relating relational networks) of the verbal self-network 1 with another network (network 2) of the woods, whereby the snake specialist orientates the participant toward the danger of the woods, through relating C rel snake with danger, which evokes the feelings of fear and avoidance. This network extends the function (C func ) of fear of snakes to fear to the woods (through the relation of woods contains snakes), and relating with the network of self (network 1) which may then ultimately define the outcome of the background knowledge category decision. Therefore, in this framework it is the AARR relating of relational networks which is the correct level of analysis in order to explain the relevant background network knowledge in this case as accounted for by HDML (RFT). Modeling work here could also assess the levels of coherence and derivation there across these networks, and the complexity required to accurately predict categorization decisions involving complex AARR relational networks, as well as the flexibility of the networks under different contextual settings, to further increase the accuracy of the models prediction of some category decision based on some background network knowledge.</p>
<p>Some specific and relevant (to background knowledge) examples of empirical work which support the MDML and HDML frameworks in this area includes rule-governed behavior, which from a traditional behavioral perspective refers to verbal antecedents of stimuli that specify the dependence of relations between stimuli and events (Skinner, 1966). The standard RFTbased operant account (Barnes-Holmes et al., 2001), extends this to involve relations frames of similarity, difference, opposition, coordination, equivalence, temporal, hierarchy, and conditional if-then relations, etc. It is perhaps interesting to note that some of these properties are similar to that of logical semantic rules such as the conditional frames. However, some interesting (HDML) recent work has extended this work even further, specifically analyzing the relationship between rule following and coherence. For example, researchers (Bern et al., 2020) have found that coherence significantly impacted upon levels of rule resurgence, and that by manipulating coherence significantly impacted selfreport measures relating to certainty in their responding. In other areas of work, participants have shown that they prefer to follow rules which are coherent with the reinforced patterns of relational responding in contrast to rules which are not coherent (Bianchi et al., 2021).</p>
<p>Work on rules and derived relations has also been conducted (Harte et al., 2017), which demonstrated that when participants were either given a direct rule, a derived relation, or no rule, they found that the direct rule led to most rule-persistence, and the rule which contained a derived relation led to more rule persistence than the no rule condition. Another study (Harte et al., 2018) showed that lower levels of derivation generally produced more persistent rule-following than higher levels of derivation. Work has also systematically examined the impact of coherence on persistent rule-following at varying levels of derivation . The researchers found that by manipulating whether feedback was either present or absent for relevant derived relations when derivation was high influenced the outcomes of rule persistence, contingency sensitivity, and resurgence, as well as (a marginal significance) for rule compliance. They also found that associations between increased rule persistence and increased levels of self-reported compliance were positive.</p>
<p>Ultimately, this recent empirical work is promising and provides and important extension to the RFT analytic level required to study background knowledge for categorization, and to identify an appropriate model for. For example, it applies properties already generally accepted within existing cognitive categorization literature such as equivalence (Oaksford, 2008;Goldstone et al., 2018) but places it within a broader framework for which rules within categories can be studied (e.g., relating rules to other rules, assessing their coherence, and how they are derived, etc.), as well as specifying coherence more broadly, as the framework can draw on analysis of the coherence of any AARR networks which may be involved, and also the complexity, and flexibility of relations specified given some context of the background knowledge information provided. As such, the model has perhaps matured enough to accommodate a comprehensive mathematical framework for the study of background knowledge.</p>
<p>SOME MATHEMATICAL FORMALIZATION CONSIDERATIONS</p>
<p>In summary of existing mathematical models, similarity (mathematical) models such as GCM and many other exemplar based models have some advantage as they can model nonarbitrary components of similarity based on physical magnitude features (color, shape, size -form), but are limited in that they cannot model arbitrary (rule type) properties. The COVIS model, is designed specifically to capture arbitrary explicit verbal (rules) as well as some procedural (implicit) system components. However, outside of rules and procedural tasks, it cannot explain which knowledge is important to select, which context information is selected in, or how functional properties are determined and can carry through a relational network in a dynamic way. Therefore, in many ways, the COVIS model is limited for the study of background knowledge in categorization and the knowledge selection problem. Models such as ALCOVE, KRES, Baywatch model are neural network models (connectionist methods). These have perhaps the most potential for modeling important constructs in background knowledge which are relevant when making decisions in categorization tasks. ALCOVE (a similarity and connectionist model) was able to model biases in background knowledge. Baywatch is perhaps the most exciting approach in the connectionist categorization as it has made some progresses specifically modeling how background knowledge affect categorization decisions based on a Bayesian probability output of how likely a categorization decision is based on some background knowledge.</p>
<p>Our RFT approach extends the Baywatch model, with some inspiration from recent development of the AI literature which has suggested that deep neural (layered) networks (DNN) are more able to capture deep and rich context within a data set (i.e., the learning history in this case of background knowledge), but structure our DNN in line with a semantic network (Rogers and McClelland, 2011). We utilize the GCM for non-arbitrary similarity matching, expert system based on set theory, as well as deep neural network model to capture arbitrary properties of RFT (i.e., ME, CE, and ToF). This, approach, we believe, demonstrates that RFT can provide a useful and formalized framework to not just model the physical and functional similarities which occur in categories, but precisely how individuals participants engage and select relevant background knowledge in patterns of contextually controlled relational responding which can bring behavior under contextual control (i.e., to determine the category decision), thus, extending work beyond similarity of physical features, as well as simple inference modeling within existing connectionist approaches.</p>
<p>One potential problem with the RFT approach in the context of categorization research, is that a full mathematical model of this approach has not yet be formulated, so it is difficult to directly compare this with other categorization models such as the GCM, ALCOVE, COVIS, KRES, Baywatch, etc., which are all mathematically defined. A formal mathematical account for categorization research may give the model some advantages in terms of setting out very precise and testable predictions in the context of background knowledge. Some researchers (Shull, 1991;Myung and Pitt, 2002) suggest that mathematical models allow for greater precision and succinct predictions about how conceptual terms are related to one another, and provide higher descriptive and predictive power than models which are not defined in mathematical terms. Alternatively, they suggest that models which do not offer some mathematical description can be clumsy for describing the precise conceptual relationships of a model. This is perhaps why in many areas of science such as in medicine, biology, and neuroscience, these have provided such mathematical models in many of their work (Costanza and Sklar, 1985;Kaplan and Craver, 2011;Benzekry et al., 2014). So, as many of the other categorization models mentioned have specified a mathematical description of their model, here, we attempt to ensure consistency with this approach by offering some mathematical considerations when specifically modeling background knowledge effects using RFT. As such, some mathematical description of RFT is provided, for those who are mathematical modelers and who may be interested in these developments.</p>
<p>This section is structured in the following way; (1) demonstrating that the literature on AI indicates that DNNs have made huge advances in deep discovery of properties (such as with the game of Go) and are highly applicable for developing a model of context and background knowledge in which the properties of RFT emerge such as relational frames of coordination, opposition, etc. This will allow for precise and testable predictions to be made in laboratory experiments;</p>
<p>(2) non-arbitrary properties of RFT can be modeled through a similarity function of the GCM, whilst the more important (for background knowledge) arbitrary properties of RFT can be modeled through expert systems based on set theory (built from the feature outputs of the DNN); (3) that the DNN learning approaches from the AI literature can be applied to neural networks of Background knowledge such as by extending the Baywatch and semantic network architectures model specifically; (4) that these multi-modal approaches combined offer the most promising position to formalize the RFT model suitable for testing predictions of how background knowledge emerges and affects category decisions such as in a situation where an experimenter were to ask a participant to categorize, for example, whether the woods safe or not given some context. So, starting with the AI literature, it can perhaps be assumed that any mathematical model for background knowledge may benefit from drawing upon the many resources and recent developments in the field of machine learning (Silver et al., 2017;Brown et al., 2020), as many of these approaches are tackling a similar problem to background knowledge in AGI research, so, they may be of some benefit here. RFT is largely a relational networking of concepts defined through arbitrary language processes, so some of the developments within the AI community toward developing a machine learning approach, such as those suggested for natural language processing (NLP) may be directly applicable here (Greenway et al., 2010;Berkout et al., 2019).</p>
<p>The relevance of natural language is that it often draws upon background information in identifying the meaning and context of words. This is therefore an important area, however, there is an important difference, as the focus here is on background knowledge, and implementation of such knowledge specifically relevant to categorization studies, and not the generation of language (e.g., parsing and token tagging parts of speech into syntax trees, which occupies much of NLP) (Collins and Koo, 2005;Abebe and Tonella, 2010;Dos Santos and Zadrozny, 2014). It is also perhaps important to note that any implementation of an RFT mathematic model within the context of background knowledge, should be considered developed for the purposes of modeling category learning of background knowledge specifically, and not a general model, which may have to be adapted for other studies and context to fit specific purposes (such as NLP).</p>
<p>There have been some interesting advances in the area of machine learning artificial intelligence (AI), worth noting (as some of these approaches will be utilized in our model), such as DeepMind's AlphaGo (Silver et al., 2017) winning against the highest ranked player in the world at the time of play (Lee Sedol) in the game of Go. This used novel applications of a Monty Carlo tree search algorithm, as well as deep learning and reinforcement learning approaches. Open AI's GPT3, on the other hand, has made some advances in the area of NLP (Brown et al., 2020) which utilize novel deep learning methods such as the use of a transformer based neural network which is specialized for text classification, and allows it to predict, and create natural sounding text.</p>
<p>Perhaps the most interesting part of Deep Mind and GPT3 and may be key to their success, was their use of modeling with high accuracy very complex and noisy data through the use of deep learning networks. However, GPT3 is not designed to build on any knowledge structures, instead it utilizes vast DNNs (currently 175 billion parameters for GPT3) to scrape (learn from) the internet such as Twitter and Wikipedia, through application programming interfaces (APIs), to understand patterns of text but without any knowledge development policies of the text itself. Hence, this approach does not involve any account of knowledge representation, however, these kinds of deep learning methods could be applied for the purposed of modeling feature representations and associated RFT relational frames (context) within complex and noisy background knowledge information in order to identify what properties are important under what relational context.</p>
<p>Deep learning networks can be thought of as a regression and classification approach, which can pick up non-linearity within the data (Detienne et al., 2003;Lowe et al., 2003Lowe et al., , 2017. However, like DeepMind and GPT3, it is unlikely that deep learning alone will be sufficient for background knowledge categorization tasks, as an expert system would need to specify how RFT organizes the knowledge (i.e., ME, CE, and ToF), and specifically how complex relations emerge between relational networks identified by the DNN (as specified by RFTs most recent HDML framework) relating relational networks which seem relevant in the context of background knowledge.</p>
<p>Deep networks are able to identify non-linearity well, but for simple problems they tend to overgeneralize . So, an expert system can be usefully applied to avoid problems such as the bias-variance dilemma which is defined as the trade-off between data fitting and generalization when dealing with simple vs. complex background knowledge problems (Geman et al., 1992). In this case, here we propose a model which has several policy modules (expert and neural networks) to account for both arbitrary and non-arbitrary components of the RFT model.</p>
<p>It is important to remember that RFT specifies two key types of relational responding, that is the arbitrary and nonarbitrary responding. Arbitrary responding (the most interesting component of the RFT model) relates to relating through relations (and networks of relations) such as equivalence, opposition, distinction, etc. (see section on a functional contextual account of background knowledge), so for example, an object may be 1 by1 meters and another 10 by 10 meters, but they can arbitrarily be labeled as equivalent (despite obvious physical differences in size) given some context. However, non-arbitrary responding relates to a similarity function, i.e., which objects are most similar to each other in terms of physical magnitude (i.e., 1 by 1 meter objects are similar only to other 1 by 1 meter objects). RFT can define both of these properties, and so can our implemented RFT model through the different modules.</p>
<p>So, the GCM similarity model may be well placed for categorizing non-arbitrary physical feature based information of RFT, whilst both unsupervised and supervised deep learning networks may be optimal for learning the non-arbitrary components of relational representation. Hence, the specialized GCM module based on similarity functions and RFT expert module are useful for localized problems whilst the networks learning structure can be used to identify learning context about where ToF, ME, and CE occur, as well as when specific contextual functions play a role in background knowledge. So, the combining expert network components may be optimal, as suggested in previous studies (Ogidan et al., 2018).</p>
<p>Therefore, in our specification of non-arbitrary cases where physical features and dimensions are given, an expert system, in the form of the GCM model for simple similarity-based processing, and within the context of background knowledge, could be usefully applied. This approach is similar to that applied in the attention, learning, covering map (ALCOVE) model (Kruschke, 1992), whereby a feedforward neural network was combined with the GCM specifically for exemplar learning. The specific difference here is that Kruschke only modeled similarity in the form of exemplar theory whilst we were utilizing the GCM for only non-arbitrary situations where similarity exemplar modeling may be useful (arbitrary relational functions are modeled through the neural networks separately).</p>
<p>The GCM assumes that a new exemplar is categorized on the basis of greatest summed similarity. In this way, the similarity of a new item is summed with all of the items in each of the categories and a classification is made into the category with the greatest summed similarity. Thus, a new exemplar will be classified with category A and not category B if it is more similar to A's exemplars than B's exemplars. Specifically, a mathematical description of this model utilizes multidimensional space (Euclidean distance and city-block metric) to represent the exemplars. This can be denoted as follows, whereby the decision (or behavioral) probability of making a category A classification when given stimulus S i , when given only two possible categories (A and B), is expressed:
P (A |X ) = Î² A Î· XA Î² A Î· XA + Î² A Î· XB(2)
Where, P is the probability of making a category A response, when given instance (stimulus exemplar) X. Î² A is a response bias toward category A, whilst Î· XA and Î· XB are the similarity measures in the form of summed similarity (with quantifiable magnitudes such as size, color sound, etc.) of stimulus X toward all stored (in memory) exemplars of categories A and B, respectively. The summed similarity, can be given specifically as:
Î· XA = jâˆˆA exp âˆ’c D k=1 w k |y xk âˆ’ y jk | r 1/r q(3)
Where, c is an overall scaling (sensitivity) parameter, r is a Minkowski distance metric parameter, whereby r = 1 is a city-block metric, and r = 2 results in Euclidean distances. q determines the shape of the similarity function, y xk and y jk are the coordinates of stimulus X and the jth stored exemplar on dimension k, respectively, and w k are the dimensional attention weight of dimension k.</p>
<p>In order to formulate the arbitrary RFT components, a similarity function such as the GCM is not applicable. Instead, an expert system denoted through set theory can be used mathematically describe the expert non-arbitrary relational constructs (for ME, CE, and ToF). Hence, equivalence from RFT can be stated as follows for equivalent relational properties between two sets using set theory (the three horizontal bars sign denotes equivalence):
AR x B â‰¡ AR y B(4)
However, equation 4 can be expressed more succinctly in the form of ME if the symbol | | | is used to denote a shared relation (AND) within the set as suggested in a previous studies (Gilroy, 2015;Edwards, 2021). In the following example of ME, describing a five stripe snake (A) as being "more dangerous" (R x ) than a three stripe snake (B) derives the relation through ME that, therefore, a three stripe snake (B) must be "less dangerous" (R y ) than a five stripe snake (A), whereby a contextual relation is expressed by C rel within the set. In this way, ME can therefore be denoted as:
C rel {AR x B|||BR y A}(5)
Or in plain English:</p>
<p>In the woods (C rel) . . .{a 5 stripe snake (A) is "more dangerous" (R x ) than a 3 stripe snake (B) AND (| | |) a 3 stripe snake (B) is "less dangerous" (R y ) than a 5 stripe snake (A)}.</p>
<p>An additional condition can be included for CE, which can be denoted as: C rel {AR x B and BR y C|||AR p C and CR q A}</p>
<p>Or in plain English:</p>
<p>In the woods (C rel) . . ..{a 5 stripe snake (A) is "more dangerous" (R x ) than a 3 stripe snake (B) and a 3 stripe snake (B) is "more dangerous" (R y ) than a 2 stripe snake (C) AND (| | |) therefore, a 5 stripe snake (A) is "more dangerous" R p than a 2 stripe snake (C) and a 2 stripe snake (C) is "less dangerous" (R q ) than a 5 stripe snake (A)}.</p>
<p>A further condition can be included to account for ToF, whereby f 1 is the function "fear, " can be denoted as:
C func [C rel {AR x B and BR y C{B f1
Rp and C f2 Rq B|||A f3 }}]</p>
<p>Or in plain English: C func -WHEN told dangerous 5 stripe snakes live IN the woods.</p>
<p>C rel -WHILE talking to a snake specialist, and deciding whether to walk through the woods or not.</p>
<p>Here â†’ is used to show the direction of the ToF from one stimuli to another.</p>
<p>Woods (A) is "related to" (R x ) you (B; as you decide to walk through the woods) and you (B) are thus "related to" (R y ) dangerous 5 stripe snakes (C; who you are told live in the woods and may encounter one if you decide to walk through the woods) THEN you (B) are "fearful" (share functional property of fearf 1 Rp ) of woods (Câ†’A ToF; as you have been told the snakes that live in the woods are dangerous, so the fear of snakes entails with the fear of woods as you become afraid of the woods) AND woods (Câ†’A ToF) is "feared by" ( f 2 Rq ) you (B; as the ToF is mutually entailed). This implies that the woods (A) through ToF now has the function of fear ( f 3 ), and causes the feeling of fear when you think about walking through it.</p>
<p>In addition to this expert system, this may be supplemented by unsupervised learning neural network, in the form of a self-organizing map (SOM) (Kohonen, 2012) to support the discovery of learning context, such as under what context should (as predicted by the RFT model) mutual entailment, combinatorial entailment, and transfer of functions occur. This approach is an unsupervised clustering method which has already been formulated in the context of relational learning for RFT specifically (Ninness et al., 2005) to identify situations (types of learning problems) where ToF was not learned (i.e., there were errors in a task) after training, and which learning situations ToF occurred. This type of methodology could thus be applied more concretely to the area of background knowledge in categorization, in identifying the types of learning parameters and context for which ToF, ME, or CE, arise in background knowledge (e.g., to identify what learning context allows ToF to emerge as in the example outlined in Figures 5, 7).</p>
<p>A generic version of the SOM (Kohonen, 2001) used in the Ninness et al. study for ordering the mapping into a twodimensional grid, giving a model m i whereby data can then be considered n-dimensional Euclidean vectors, can be given here. Here, t is the index of data items in a given sequence and Î¾ is a given weight. This can be denoted as follows:
x (t) = <a href="8">Î¾ 1 (t) , Î¾ 2 (t) , . . . , Î¾ n (t)</a>
The model is iteratively updated. The ith model is defined as m i (t) and the new value m i (t + 1) is computed iteratively from the old value of m i (t) as new data item x t . The index i refers to the model under processing, and c refers to the index of the model which has the smallest distance from x (t) in the Euclidean signal space. Î± (t) is a scalar factor that defines the size of the correction, and its value decreases with the step indexed t. The factor h ci is a smoothing kernel, called neighborhood function. When i = c the neighborhood function is equal to 1. Its value decreases when the distance between the models m i and m c on the grid increases. This can be denoted as the following:
m i (t + 1) = m i (t) + Î± (t) h ci (t) <a href="9">x (t) âˆ’ m i (t)</a>
Then new models are computed as the following, whereby n j is the number of computed inputs into node j and node j runs over other nodes in the neighborhood of node i. In order to update m i , this scheme is iterated a few times using the same data to determine the meanx j :
m i = j n j h jixj j n j h ji(10)
In addition to the unsupervised SOM approach, deep learning a DNN (as the literature on AGI suggests) can also be utilized which has some unique advantages over SOM in some instances. One problem with SOM is that the mapping topography needs to be specified by the user, and it does not explore deep learning association properties (Golden, 2001). DNNs, on the other hand, can explore these deeper associations in order to identify what relational frames are relevant, and under what context, in situations where background knowledge is utilized in categorization tasks. Deep learning approaches have been used in combination with SOM in other studies to optimize task results (Asghar et al., 2019). One implementation of deep learning which may be helpful in modeling deep abstract arbitrary features in the form of functional properties, and can extend the SOM, is from the machine learning (AI) literature, called backpropagation neural network (BPN). Previous background models have focused on Bayesian and connectionist (network) model approaches such as by Heit and Bott (2000). However, Heit and Bott employed a shallow network (3 layer network), and it has only been in the last few years (Jeff Dean et al., 2018;Sejnowski, 2018;Buntine, 2020;Jeffrey Dean, 2020) that advances in computational power has allowed for deep learning networks to effectively process the many levels of weight adjustments and gradient decent required for modeling complex and noisy datasets which background knowledge involves. This massive scalability of deep learning increases its predictive power immensely as shown in thee AI literature, and is one of the main reasons for the successes of OpenAI's GPT3 NPL program in modeling complex information patterns (Brown et al., 2020), which has increased the size of its deep network to 175 billion parameters and 96 layers (from 1.5 billion parameters in GPT2), as well as DeepMind's AlphaGo which also has a large scale deep learning network (Silver et al., 2017;Li and Du, 2018).</p>
<p>So, a DNN maybe useful for learning in what situation and context functional control over behavior and decision making occur within background knowledge categorization tasks. In order to implement this DNN, this starts with the summation of inputs x = (x 0 , . . . , x k ) multiplied by weights w = (w 0 , . . . , w k ) and adding in a bias value (usually 1):
n i=1 (x i w i ) + bias(11)
The next step is specifying the activation function for each layer.</p>
<p>There are various functions which can be chosen, a useful and commonly used non-linear function is the sigmoid function Ïƒ:
Ïƒ = 1 1 + e âˆ’z(12)
A cost function C (usually sum of squared error) needs to then be defined to allow the network to adjust weight and bias. This can be defined as the average C, over the cost function C x for individual training examples, x:
C = 1 n x C x(13)
Gradient decent can be computed through partial derivatives âˆ‚C/âˆ‚w and âˆ‚C/âˆ‚b of the cost function C with respect to any weight w or bias b, so that these weights and biases can be adjusted to minimize the cost (error) function. The gradient of the error which is expressed as âˆ‡C and decent can be formulated as (and b can replace w in the case of bias):
âˆ‡C = âˆ‚C âˆ‚w 0 , . . . , âˆ‚C âˆ‚w n(14)
Perhaps most interesting in Heit and Bott (2000) Baywatch neural network model of is the inclusion of Bayesian probability, which converts the networks activation outputs into a probability measure of categorizing in a particular way based on some given background knowledge. In order to do this, the model uses the logistic transformation as outlined in Gluck and Bower (equation 7) (Gluck and Bower, 1988). Standard Bayes rule can be expressed as the following, whereby P is the probability of some hypothesis (H) being true, given some evidence (E), and denoted as:
P (H|E) = P (E|H) P(H) P(E) ,(15)
In our model, the same Bayesian probability equation as of Gluck and Bower (equation 7) (Gluck and Bower, 1988), can be utilized at the expert output level. If one lets S k represent one of the possible stimulus patterns, the logistic function can be denoted as the following, whereby P (R|S k ) is the probability of responding in a particular way given S k . O k , denotes the activation in the output node which results from S k being presented at the input nodes, Î¸ is a positive scaling parameter, and e is the error term (cost) which in learning the network attempts to reduce.
P k = P (R|S k ) = 1 1 + e âˆ’Î¸(0 K ) ,(16)
Given the complexity of background knowledge modeling, this approach of utilizing several modules of supervised, unsupervised, and expert systems seem the most promising approach. However, although there is perhaps universal agreement that the cortex and other areas of the brain processes information through a connectionist system of connected neurons (Levine, 1995;McLeod et al., 1998;Coltheart, 2004;Lin, 2017), one problem with existing (connectionist) neural networks is that they are unlikely biologically plausible in the sense that there is no evidence that the brain uses backpropagation when learning (Crick, 1989;O'reilly and Munakata, 2000;Whittington and Bogacz, 2017), therefore backpropagation may not be the best way to implement the network. More specifically, in a DNN, the change in each synapse is calculated as a global function of activities and weights of many neurons. However, in order to be biologically plausible (closer to how real neurons signal), the network must perform its learning algorithm locally, and the change in each synaptic weights must entirely depend on just the activity of pre and post-synaptic neurons (O'reilly and Munakata, 2000;O'Reilly et al., 2016;Whittington and Bogacz, 2017). As a result of this, a large amount of effort has been made into applying more biologically plausible connectionist DNNs, and these have been in the form of Hebbian learning networks which have been shown to approximate the backpropagation learning algorithm, whereby the local synaptic weights depend on the pre and post synaptic activity (O'reilly and Munakata, 2000;O'Reilly et al., 2016;Whittington and Bogacz, 2017). It has been suggested that these biologically plausible DNNs should ensure the following (O'reilly and Munakata, 2000;Whittington and Bogacz, 2017): (1) Local computation, whereby a neuron performs computation on the input it receives from other neurons and weights by the strengths of these local synaptic connections; (2) Local plasticity, synaptic weight changes is dependent on the neurons the synapse connects with; (3) Minimal external control, whereby computation of neurons is performed autonomously with little external control; (4) plausible architecture, where the connectivity patterns in the network should be consistent with the basic constraints of connectivity in the neocortex.</p>
<p>One very interesting adaptation of this comes in the form of predictive coding, from some of the most prominent and widely accepted models of neuron functioning proposed by Karl Friston and colleagues (Rao and Ballard, 1999;Friston, 2003Friston, , 2005 and is related to the autoencoder framework (Ackley et al., 1985;Hinton and McClelland, 1988;Dayan et al., 1995), which O'Reilly and colleagues' Hebbian learning GeneRec algorithm was also based upon, utilized in their Leabra DNN architecture (O'Reilly, 1996;O'Reilly et al., 2016) as well as other autoencoder versions implemented in a biological plausible DNN (Bengio, 2014;Bengio et al., 2015).</p>
<p>Here the backpropagation algorithm can be approximated with the predictive error term in a biologically plausible way, whereby instead of computing the backpropagation gradients via a chain rule which is used in the form of derivatives from calculus in the typical backpropagation network which shows how much the v i (which denotes the vector of activations in a layer) need to change in order to minimax the cost function C:
âˆ‚C âˆ‚v 0 = âˆ‚C âˆ‚v 1 âˆ‚v 1 âˆ‚v 0(17)
Instead, a biologically plausible predictive coding (Hebbian learning) algorithm is utilized:
v 0 = âˆ’âˆˆ 0 + âˆˆ 1 âˆ‚v 1 v o(18)
Where, in predictive coding, âˆˆ i is the prediction errors (errors made by parent nodes about the activation prediction of locally connected child nodes). Here, predictions and prediction errors are updated in parallel with only local information. Also, see Whittington and Bogacz (2017); Millidge et al. (2020) for full details. Prediction errors are computed in the following way:
v (a) b = Îµ (a) b + n (aâˆ’1) i=1 Îµ (aâˆ’1) i Î¸ (a) i,b f v (a) b(19)
Here, prediction errors âˆˆ refers to the non-linear transformation function which transforms and scales incoming input from lower-level nodes to a variable node. Once the network has reached its steady state it then updates its parameter weights Î¸ (l) i,j in this locally Hebbian driven learning which captures synaptic plasticity of real neurons.</p>
<p>DEEP LEARNING NEURAL NETWORK SEMANTIC ARCHITECTURE WITH REPRESENTATION AND RELATIONAL LAYERS</p>
<p>The DNN we use here (see Figure 8A), is similar to the structure of a semantic network (Rogers and McClelland, 2011) which extends previous work of distributed memory model ) and the semantic memory models (Hinton, 1986;Rumelhart, 1990;Rumelhart and Todd, 1993;Hinton and Anderson, 2014). This is optimized for processing information which involve both context independent and context (relational frame) dependent aspects and has been specifically designed for complex contextual knowledge representation which is suitable for emulating basic RFT properties. This network structure is a parallel distributed processing approach to cognition , and assumes cognitive (or behavioral) phenomena arises from the propagation of action amongst connected neuron-like processing units. These neuron unit nodes explicitly encode the state of the environment via direct sensory inputs. The hidden layer nodes mediate the flow of activation encodings between the input and output, and the output nodes explicitly encode representations of potential responses. The propagation of activation is constrained by weighted synaptic-like connections between neuron nodes, and the internal environmental representation take the form of distributed patterns of activations across some subset of hidden units which update overtime in response to input data from the environment.</p>
<p>The function of the semantic network architecture is to generate context and item appropriate inferences about the properties of the inputted data (concepts). It contains representation (concept) inputs as well as relation inputs (see Figure 8A), whereby the relation inputs provide information about the context that influences the representation inputs in the hidden layers (Rogers and McClelland, 2011) as well as similarity structure across relational contexts (Rogers and McClelland, 2008). The input layer directly encodes localist environmental representations of individual concepts, whilst the relation layer encodes localist environmental representations of different relational contexts relevant to the inputted corpus. In the example given the relation al frames are coordination, opposition, containment, but these can be extended to include all of the relational frames within RFT, and the network could learn through a larger training corpus that sentences within a corpus such as "lives in" involves the containment and coordination relations. So, the network develops its own equivalence class for word vectors in order to correctly encode and active the correct relational frames within the relation layer. Crucially, the representation layer encodes a context independent internal representation whilst the hidden layers encodes (receiving input from the relation layer) contextdependent representations.</p>
<p>In this framework, the internal representations that govern how knowledge generalizes are not considered discrete category representations, but instead are patterns of activations across continuously valued nodes distributed across the representation and hidden layers. The patterns of activity can be considered a point in a continuous high dimensional space, which each node encoding one dimension. Unlike exemplar theories in categorization, here, the dimensions of the space do not correspond to interpretable semantic features and there is no storage of exemplars -hence the information is only interpretable when considering patterns of activity across nodes within separate layers. Categories can be output form this model but are not contained within it, and instead correspond to densely occupied regions of the representation (nodes within layers) space.</p>
<p>This approach has the advantage of not needing to specify which categories are stored within background knowledge hence gets around the knowledge selection problem, instead the semantic network derived a function between the input and output properties through its distributed activations across layers. Further to this, it is important to note that this model could be expanded further (as an additional module) to include a reinforcement learning agent structured through a Markov decision process (MDP) as specified in previous work (Edwards, 2021), when more complex decision making is needed which requires the extracting of background knowledge for category decision making. This specifies the probability P given some action a, and is denoted as P a s, s 1 , s is the current state of 1 See (Edwards, 2021) for full details of this extended reinforcement framework. the environment and s is some new state transition if action a is carried out. This would help specify which concepts and instances are being reinforced and under which context as knowledge develops into more complex networks.</p>
<p>ENCODING OF INFORMATION TO NETWORK LAYERS AND GRAPH VISUAL EMBEDDINGS</p>
<p>As with the semantic network of previous work (Hinton, 1986;Rumelhart, 1990;Rumelhart and Todd, 1993;Rogers and McClelland, 2011;Hinton and Anderson, 2014), our proposed network (see Figure 8A) will store binary encodings to represent the concepts contained within the inputted corpus (within a representation layer), as well as the relational frames (of the RFT model in the relational layer), which will ultimately represent the background information needed to make some category decision (such as whether it is safe to walk through the woods). The output of this network, therefore, will be some category which is relevant in order to make some category decision (the semantic network has been adapted for this purpose).</p>
<p>In terms of granularity of encoding, it is anticipated that like convulsion neural network and other network representation layers (see Figures 8B,C) the level of detail (granularity) increases layer by layer within the DNN (such that layer one captures just the most basic features -edges for images or word structures for a text corpus, layer two captures textures or word relations, etc.), and therefore learning occurs layer to layer, and that each layer has all the information it needs to predict target output plus some noise, whereby noise decreases as the number of layers increase. Figure 8A shows that at the third layer the relational frame (from the RFT model) properties are integrated with the representation properties to forms relational representations (e.g., snake lives in the woods).</p>
<p>From this perspective, every layer becomes a partition of information, and these are known within the information theory literature as successive refinement of relevant information (Equitz and Cover, 1991;Gregor et al., 2015;Liu Y. et al., 2018). So, the input is slowly being encoded and decoded into the target output. From information theory, this can be expressed as the amount of information or entropy (uncertainty or noise) is contained at each layer (see Figure 8D; Tishby and Zaslavsky, 2015;Tax et al., 2017;Achille and Soatto, 2018;Yu et al., 2020). In other words, how much entropy H is removed from X (input information) at each layer if Y (output, respective categories) is known. Here, H(X) denotes the entropy of X, H(X|Y) is the conditional entropy of X given Y, and I (X, Y) = H (X) âˆ’ H(X|Y) denotes the mutual information (between X and Y). The mutual information between X and Y should decrease as the important and relevant information is selected, and the noise (non-relevant information) is discarded. This can be represented as a Markov Chain whereby every hidden layer becomes a single variable h, in a Markov Chain, represented as h 1 , h 2 , etc. As each variable in a Markov chain is only dependent on the previous layer, each layer can be observed as its own partition of information.</p>
<p>There are several ways to determine and interpret the specific encodings made on neurons within layers and plot them (for visualization purposes) in graphical form (see Figure 9). Coming out of the graph theory literature, explanatory graph analysis (Golino and Epskamp, 2017;Golino, Shi et al., 2020) has been recently introduced. These types of approaches have been useful in estimating a network and then developing clusters of communities of variables from the relationships between the variables within the network (Golino and Epskamp, 2017). This has been particularly useful in psychology in regards to applications of this framework for modeling network psychometrics (Epskamp et al., 2016), through the development of the network graph which are based on identifying the strength of correlations between psychometric variables (Christodoulou et al., 2019;Baker and Berghoff, 2021).</p>
<p>Despite the advantages of the network analysis approaches of direct correlations between psychometric variables, DNNs have the advantage over other approaches of network analysis. This is because they can leverage large amounts of complex data to identify some underlying function that describes some pattern in the data with high dimensionality such as speech, visual, and natural language processing (Liu B. et al., 2017;Deng and Liu, 2018;Voulodimos et al., 2018;Young et al., 2018;Nassif et al., 2019) which is particularly relevant to background knowledge categorization tasks, and emulates the way our brain actually process information (via a Hebbian learning error driven neuronal network) (O'Reilly, 1996;O'reilly and Munakata, 2000;O'Reilly et al., 2016;Whittington and Bogacz, 2017).</p>
<p>This DNN approach has been inspired by recent developments in neuroscience of brain network analysis methods (Liu J. et al., 2017;Garcia et al., 2018), which have shown that analyzing brain neural connections can give important insights into the architecture, development, and evolution of the brain networks. Applied into a DNN framework, here, instead of identifying the direct correlations between psychometric variables (Christodoulou et al., 2019;Baker and Berghoff, 2021), allows for a graph to develop directly from the neural network weight distributions, whereby correlations would be calculated between neuron nodes in order to identify communities within the network (Horta et al., 2021). As weight distributions within a network are difficult to visualize and interpret, Graphs can help the network distributions to become more comprehensible to humans who can then visualize the encodings within the network, allowing for the classic black box problem of interpretability to be overcome.</p>
<p>This problem of interpretability and explainability of how or why the DDN has made some set of connections is not trivial, and makes it difficult for researchers to traditionally understand what is being encoded on each neuron in each layer of the DNN (Towell and Shavlik, 1993;Liu X. et al., 2018;Kumar et al., 2020;Erasmus et al., 2021). This ability to understand some of the encodings can be important with applications such as medical decision making, law enforcement, financial analysis (Horta et al., 2021) as well as when attempting to model and explain the cognitive system (Cichy and Kaiser, 2019;Oita, 2019;Monte-Serrat and Cattani, 2021) such as in tasks relating to background knowledge which my further help researchers understand distributed knowledge encodings across layers and what the weight distributions actually mean in graphical form.</p>
<p>For many years, there been several attempts to extract meaningful encodings from what is traditionally understood as a black box of the DNN connectionist layers (Towell and Shavlik, 1993;Bartlett, 1994;Mak and Blanning, 1998), however it has only been with recent progress in computational resources has this been possible (Horta et al., 2021). Several approaches have made considerable progress in solving interpretability problem (Gilpin et al., 2018) by extracting knowledge from the DNN, such as the pedagogical rule extraction method (de Fortuny and Martens, 2015), and more recently architecture agnostic approaches which do not depend on fully connected networks (Horta et al., 2021).</p>
<p>These recent developments are inspired by co-activation graph methods (Horta and Mileo, 2019) which are similar to functional graphs based on statistical correlations between nodes in the DNN. Within a DNN, nodes represent neurons and the weighted relations between nodes indicate a statistical correlation between activation values. This allows for assessing connection pairs between any layer (including hidden layers) of the network and the output layer. Unlike in previous approaches, this makes it possible to study the relations between neurons within a DNN, whereby knowledge encoded on the in the co-activation graph reflect the knowledge acquired by the DNN in its learning phase (and the stages of evolution of this learning, encoded by the layers). This, therefore, allows for precise measures of encodings across the network (Horta and Mileo, 2019;Horta et al., 2021).</p>
<p>A co-activation graph can be represented (see Figure 9; Horta et al., 2021) through an undirected graph G = (V, E) where V = v 0, v 1,..., v n, is a set of nodes that represent the neurons of a DNN and E is a set of weighted relationships (expressed as edges in the graph) e ij = (v i, v j, w) between pairs of neurons v i and v j with weights w ij are obtained by applying a statistical correlation on A(v i, S) and A(v j, S) as depicted in the equation below:
w ij = Spearman_corr A(v i, S , A(v j, S)).(20)
Spearman coefficient is chosen as linear relations are not expected between the neuron's activations values. Edge weights vary from âˆ’1 to 1, and there are three steps on how to develop a covariation graph. For example, consider a DNN with neurons n and a data sample S = {s 0 , s 1 , . . . , s n } . The three steps are as follows:</p>
<p>The first step is to extract activation values. Here, the DNN needs to be input S, then for each neuron v i, and each data input s h âˆˆ S, where 0 â‰¤ h &lt; m , a single activation neuron a ih, needs to be extracted. The result is a set {A (v 0 , S) , A (v 1 , S) , . . . , A (v n , S)} where A (v i , S) represents for the whole dataset S, all activation values of each neuron in the network.</p>
<p>The second step is to define and calculate edge weights, which requires defining the relationships between pairs of neurons. For each pair of neurons v i and v j the correlation equation 20 is applied and utilizes activations A (v i , S) and A v j , S in order to establish the statistical correlation for the relationship weights w ij between each pair of neurons. This allows for a mathematical matrix which contains w ij for every neuron pair v i and v j which can then be utilized to construct a set of edges E within a graph and between neuron nodes, and for every neuron pair in the network in order to develop a complete graph.</p>
<p>The third step is to build and analyze the co-activation graph. In order to visualize the graph being developed this needs to be constructed within a computational tool for graphing structures such as Neo4j 2 . This provides a graph, whereby nodes represent neurons at any layer within the DNN that the research wishes to analyze the encodings from, and the weighted edges represents the non-linear correlations between the neuron node activation values.</p>
<p>The final part this approach is the analysis method adopted. Here, we first need to demonstrate that the co-activation graph is encoding the same knowledge as the DNN. This approach has been successfully tested with DNNs, whereby a community structure analysis and centrality analysis are conducted over several data sets (Horta and Mileo, 2019), which helps to observe how a graph algorithm applied to the co-activation graph can explain the DNN model. The community analysis applied to a deeper model helps to establish whether the results are consistent with more complex environments and therefore DNN models. The centrality analysis is applied to study and understand the association between node centrality and neurons which are important in the DNN (Horta and Mileo, 2019;Horta et al., 2021).</p>
<p>The community structure analysis is also important in order to identify interesting properties of the graph and the knowledge held locally with each community. The Louvain community detection algorithm (Blondel et al., 2008) has been applied effectively in previous work (Horta and Mileo, 2019;Horta et al., 2021), and it is useful as it can output a modularity coefficient which indicates how different the community structures identified differ from random graphs. It includes a parameter which allows for the resolution to be adjusted, when seeking larger or smaller communities. Horta et al. (2021) also explored the similarities within the communities and identified that the Louvain algorithm was able to cluster information within the communities which were semantically similar. For example, they found that community one included animals (deer, dog, horse, frog, bird, and cat) in one community whilst in another community this included means of travel (airplane, ship, truck, and automobile). They also found at a higher resolution, the algorithm was able to detect hierarchical class information such as clothing in community one (T-shirt, pullover, shirt, and dress) and footwear in community two (sandal, sneaker, and ankle boot).</p>
<p>Centrality analysis plays an important role in graph analysis, whereby identifying the centrality of a node provides valuable insights of the importance of the neuron node in a graph (and corresponding DNN). There are two different centralities used in this analysis, which are degree centrality and PageRank centrality (Page et al., 1999). Degree centrality of some node n i presents the number of relationships n i has with other neural nodes. This can be calculated by simply summing of the weights in the edges that connect n i with other nodes as in the equation below:
D (n i ) = Nâˆ’1 j=0 A ij(21)
Here, A is an adjacent mathematical matrix of size N, where A ij , 0 â‰¤ i &lt; N and 0 â‰¤ j &lt; N. The PageRank expands this equation, one step further by highlighting the importance of a given node's neighbors, and not just its centrality. Each node's PageRank is initialized to the value of 1 and then iteratively updated through equation 22, as stated below:
PR (n i ) = 1 âˆ’ d N + d n j âˆˆS n i A ij PR (n i ) D n j(22)
Here, the total nodes is denoted by N, whilst S n i is a set containing the neighboring nodes of n i , A ij , like in equation 21, denotes the weighted edge between nodes n i and n j . d is a damping factor which controls how often random jumps are made to other nodes, whilst D (n i ) is the degree centrality as in equation 21. From this, a graph (see Figure 9) is generated from the weight distributions, whereby each node represents a unique concept and are connected together in a strong or weak way (depicted by the width of the connecting lines) to other nodes within a cluster (broadly forming an equivalence class). In the figure, the clusters (blue, green, and orange) containing the connected nodes are related to one another through some properties of RFT, in this case a transfer of stimulus function. Th red arrow indicates the transfer of function "fear" from the green community (snake category) to the blue community (woods category), then finally to the orange community (verbal self). Here, in the example we gave in Figures 5, 7, community network 1 shows the relational attributes of the concept dangerous snakes living in (contained) in the woods, community network 2 shows the relational attributes of the woods also containing dangerous snakes, and network 3 which is the relational attribute of the verbal self. This impacts the decision as to whether the woods are ultimately categorized as safe enough to walk through or not, and is largely based on whether the verbal self has positive relational components (confident and successful), as depicted in Figure 6 or negative relational components (feeling of failing and low selfesteem), as depicted in Figure 4. As each community network is a relational network and are connected to other relational community networks (such as community network 1 and 2) through ToF in this example, this represents relating relational networks as explained by the HDML RFT framework.</p>
<p>It is perhaps important to note that by avoiding the woods, this may further strengthen the individual's feelings of failure and low self-esteem so may have important consequences in processed based therapy (PBT) work Hofmann, 2017, 2018;Hofmann and Hayes, 2019), and could be applied a clinical analysis and diagnostic tool.</p>
<p>As can be seen in Figure 9, the strength of the connection (edge) a is between nodes 1 and 2 and is weak to moderate in strength, so in this case the transfer of function may also be considered weak to moderate in strength and influence over the network. In contrast, the connection (edge) b is more bold and this represents a strong connection and increased influence over the network. This means that the verbal self would have a strong influence over the decision whether to decide to walk through the woods, and it also suggests that in the case of an avoidance response, then the negative impact on the verbal self would be strong. In a PBT setting, these techniques could be utilized in a way which brings about relating relational networks in a clinical graph (or structural equation) type approach helping the clinician or researcher to visualize the strength of these relations and therefore judge how likely one relational network would influence another (and hence where to target the intervention). This, therefore, could expand the toolbox of PBT diagnosis on what has already been proposed (Hofmann et al., 2021). Finally, based on the network and graph weighted outputs, the probably of some decision such as whether the woods is safe to walk through can be made. This relies on an aggregation of the data from the networks in graphical form (to visualize). The expert system then finally can connect community graph networks within the sets of ToF, mutual entailment, or combinatorial entailment as a form of relating relational networks as described in the HDML (RFT) framework, which may be easier than connecting two or more DNNs given the complexity of this task. The complete model with all modules explained in this section can be summarized as depicted in Figure 10.</p>
<p>SOME NOVEL EXPERIMENTAL CONSIDERATIONS</p>
<p>With the machine learning approaches suggested, it is perhaps important to note that novel experimental methods can be developed which expand on that utilized by Ninness et al. (2005). Ninness et al. identified situations (types of problems) where ToF was and was not learned after training (i.e., by clustering specific errors in learning ToF with specific learning tasks and context).</p>
<p>Similar approaches for deep learning could be developed, for example, which utilize participant confidence scales as inputs within a backpropagation network to represent individuals' background knowledge (e.g., confidence that the typical jogger in the United States is "healthy, " "runs once a week, " "is honest, " "owns running trainer, " "has two legs, " etc.) and this could be trained on a target of actual jogger reports on how confident they are they have these same features or factual reports about joggers (e.g., 70% of joggers in the United States are healthy, whilst 30% are obese).</p>
<p>Such an approach would allow for the identification of relevant perceived attributes and functions of the target category (e.g., jogger and woods) for specific participant subgroups. For example, given a background knowledge feature list, clustering methods such as k-means on the upper hidden layer could represent a novel way to explore which of the background features given by a given population subgroup are assumed to be important about a concept (e.g., what United States participants believe about joggers in the United States vs. what European participants believe about joggers in the United States), and how this relates to actual properties that "joggers" believe about themselves or other facts known. This type of approach has been used in other areas such as identifying important subgroup predictors in health psychology and other areas (Kimoto et al., 1990;Lowe et al., 2003Lowe et al., , 2017.</p>
<p>For this to work, data is converted into z scores a two-stage cluster analysis is performed (Milligan, 1980;Clatworthy et al., 2007) which involves a Ward (squared Euclidean distance) to identify the number of clusters (i.e., through the agglomeration schedule and dendrogram), then data conversion into cluster centroids (middle of cluster) followed by a K-means cluster method. This allows subgroups partitions to be identified which contain the relevant background knowledge features and functions. The final step allows the experiment to then compare each feature variable in each group "x" against the mean for that variable across all groups through a comparison of effect sizes calculated from the mean scores and pooled standard deviation.</p>
<p>CONCLUSION</p>
<p>The examples above illustrate how RFT offers a compelling explanation of how complex background knowledge emerges, with contextual sensitivities, without relying upon simple rules or formal similarly, as is typically the case with categorization models.</p>
<p>In relation to broader philosophical considerations, cognitive psychology typically takes a perspective of mentalism, such as in categorization research Margolis and Laurence (1999) assume a concept is a mental representation. However, there has been some accepting of functional aspects such as the functional equivalence of Sidman (1994) in the cognitive community (Goldstone et al., 2018), and these can be considered within a pure behavioral perspective or incorporated as part of mentalism and cognition. Indeed, some authors have suggested that this functionalanalytic approach could be fruitfully incorporated into a cognitive account, once cognitive phenomena are conceived of as complex environment-behavior relations that are mediated by information processing (Liefooghe and De Houwer, 2016;De Houwer et al., 2018). This review and conceptual paper sought to outline and explore the various approaches cognitive psychologists have used to study the influence of background knowledge on categorization processes. In doing this it was recognized that although much progress had been made in relation to identifying how background knowledge may affect a task such a when presenting congruent vs. incongruent information, induction, and similarity approaches, much progress was still needed. As such, the current review points to further uses of RFT, to provide some perspective on how to address the knowledge section problem, by expanding on some of the work developed in terms of exemplar, relational induction, and contextual inferences in learning categories.</p>
<p>Naturally, the development of this relationship would be assisted by work such as formalizing a mathematical account (as we have done) of this by incorporating aspects of more traditional cognitive approaches such as connectionist, and induction models. This may be fruitful as both approaches are specialized in different ways, categorization for similarity, rules, and induction, and RFT for modeling functional contextual properties, derived relations, and strength of associations. Future work should now explicitly test implementation of the RFT model specified and within the context of background knowledge. We suggest that attention should be made to some of the novel methodological approaches to test context and situations where RFT properties (e.g., ToF, ME, and CE) arise such as through the clustering approaches suggested (SOM and the deep learning network). This work represents some exciting opportunities for the formal representation of background knowledge, and new insights into how to address the knowledge selection problem, through applying various approaches and levels of heuristics (cognitive and behavioral). It also offers some novel avenues to help facilitate novel approaches in the AGI literature for accounting for crucial background knowledge and broadens existing work in semantic theories of general knowledge.</p>
<p>There are of course some limitations with the mentioned DNN connectionist approach. We explored the use of a biologically plausible network based on Hebbian learning instead of backpropagation (which is not biologically plausible). However, though this is closer to how real neurons learn within the neocortex and other brain areas when compared to standard backpropagation methods, more research should be conducted which ensures that these networks are able to capture the limitations of the human cognitive system (or behavioral learning) when modeling human learning performance.</p>
<p>Finally, the approaches within this modeling, could have some potential clinical applications in the form of process based therapy (PBT) work Hofmann, 2017, 2018;Hofmann and Hayes, 2019). As this models relations of relational networks within RFT and the HDML framework, it could help formulate visual graphs of community networks (as depicted in Figure 10) whereby relational networks could then be integrated and mathematically modeled further within the PBT work. This, therefore, could help researchers and clinicians design complex prediction models which relate RFT with background knowledge in categorization, to the structural equation modeling of PBT (Hofmann et al., 2021), and potentially could have important clinical implications.</p>
<p>AUTHOR CONTRIBUTIONS</p>
<p>DE designed and wrote the manuscript. YB-H and CM helped with the RFT articulation and provided some conceptual assistance. The mathematical equations and mathematical interpretation, as well as the illustrative figures, were developed solely by DE. All authors contributed to the article and approved the submitted version.</p>
<p>FIGURE 2 |
2An RFT interpretation of a simple example of trained vs. derived relations(Images from adobe stock with license and permission to use and modify. Credit for image on top "kuritafsheen," bottom right "Coloures-Pic," and bottom left "iushakovsky").</p>
<p>FIGURE 3 |
3An RFT interpretation of a simple example of transformation of stimulus function, as the individual learns in this context the category "woods are dangerous"(Images from adobe stock with license and permission to use and modify. Credit for image on top: "kuritafsheen," bottom right: "iQoncept," bottom left "AA + W").</p>
<p>FIGURE 4 |
4to avoid scary things in the future. Feelings of failure. Low selfesteem. An RFT interpretation of a simple example of transformation of stimulus function, as the individual learns and derives a relation of "self"(Images from adobe stock with license and permission to use and modify. Credit for image on top "Tardigrade," bottom right "Riska," and bottom left "Coloures-Pic").</p>
<p>FIGURE 5 |
5An RFT interpretation illustrating complex frames of derived background knowledge, and how concepts can transfer functions in category learning to develop new functional categories, thus building up the complexity of existing background knowledge(Images from adobe stock with license and permission to use and modify. Credit for image from left clockwise around: "Tardigrade," "AA + W," "kuritafsheen," and "iQoncept").</p>
<p>FIGURE 6 |
6An RFT interpretation of simple example of transformation of stimulus function, as the individual learns and derives relation of "self"(Images from adobe stock with license and permission to use and modify. Credit for image on top "Maridav," bottom right "Riska," and bottom left "Coloures-Pic").</p>
<p>also make predictions, but on the prediction error from the corresponding level and the lower level which are weighted by the synaptic weights. f v (a) b</p>
<p>FIGURE 8 |
8Illustrates RNN encodings for each layer -a representation layer, and a relation sub-input layer for determining output category classifications utilizing relational fames which represent context. For section B (Edges, Textures, Patters, Parts, and Objects), these were taken from Chris Olah (Google Brain Team), Alexander Mordvintsev (Google Research), Ludwig Schubert (Google Brain Team) (2017) (CC-BY 4.0, with permission) https://distill.pub/2017/feature-visualization/. (A) represents the neural network encoding relation information; (B) illustrates progress layer feature granularity in a typical CNN; (C) illustrates progressive contextualized word patterns which detect context in language; (D) illustrates decreased mutual information between input and output as the network places focus on important information whilst discarding irrelevant information.</p>
<p>, strength of associaï¿½on, and Bayesian components Mutual entailment (ME)-Crel {A Rx B ||| A Ry B} Combinatorial entailment (CE) -Crel{A Rx B and B Ry C ||| A Rp C and C Rq A} Transfer of funcï¿½on (TOF) etc. -Cfunc [Crel {A Rx B and B Ry C {A f1 ||| P) of a decision/behavior x -the woods are scary but not something to be avoided = categorizes the woods are most probably safe from background knowledge Transfer of funcï¿½on (ToF) ANN -Supervised, large data relaï¿½onal detecï¿½on and classificaï¿½on of shared funcï¿½onal properï¿½es ( | ) = + , FIGURE 10 | A simple schematic illustration of a multi-level computational model, which identifies GCM similarity in non-arbitrary situations and RFT relations through both unsupervised and supervised network components for learning the RFT framework.
March 2022 | Volume 13 | Article 745306
Frontiers in Psychology | www.frontiersin.org
See https://neo4j.com/ Frontiers in Psychology | www.frontiersin.org
Conflict of Interest:The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.Publisher's Note: All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.Copyright Â© 2022 Edwards, McEnteggart and Barnes-Holmes. This is an openaccess article distributed under the terms of the Creative Commons AttributionLicense (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.
Natural language parsing of program element names for concept extraction. S L Abebe, P Tonella, 10.1109/ICPC.2010.29IEEE 18th International Conference on Program Comprehension. New Jersey, NJIEEEin Paper presented at theAbebe, S. L., and Tonella, P. (2010). "Natural language parsing of program element names for concept extraction, " in Paper presented at the 2010 IEEE 18th International Conference on Program Comprehension, (New Jersey, NJ: IEEE). doi: 10.1109/ICPC.2010.29</p>
<p>Emergence of invariance and disentanglement in deep representations. A Achille, S Soatto, 10.1109/ITA.2018.8503149J. Machine Learn. Res. 19Achille, A., and Soatto, S. (2018). Emergence of invariance and disentanglement in deep representations. J. Machine Learn. Res. 19, 1947-1980. doi: 10.1109/ITA. 2018.8503149</p>
<p>A learning algorithm for Boltzmann machines. D H Ackley, G E Hinton, T J Sejnowski, 10.1207/s15516709cog0901_7Cognit. Sci. 9Ackley, D. H., Hinton, G. E., and Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognit. Sci. 9, 147-169. doi: 10.1207/s15516709cog0901_</p>
<p>The adaptive character of thought. Anderson , Lawrence Earlbaum Associates. IncHillsdale, NJAnderson (1990). The adaptive character of thought. Hillsdale, NJ: Lawrence Earlbaum Associates. Inc.</p>
<p>The adaptive nature of human categorization. Anderson , 10.1037/0033-295X.98.3.409Psychol. Rev. 98409Anderson (1991). The adaptive nature of human categorization. Psychol. Rev. 98:409. doi: 10.1037/0033-295X.98.3.409</p>
<p>Skinner and Chomsky 30 years later. Or: The return of the repressed. J Andresen, 10.1007/BF03392552Behav. Anal. 1449Andresen, J. (1991). Skinner and Chomsky 30 years later. Or: The return of the repressed. Behav. Anal. 14:49. doi: 10.1007/BF03392552</p>
<p>What some concepts might not be. S L Armstrong, L R Gleitman, H Gleitman, 10.1016/0010-0277(83)90012-4Cognition. 13Armstrong, S. L., Gleitman, L. R., and Gleitman, H. (1983). What some concepts might not be. Cognition 13, 263-308. doi: 10.1016/0010-0277(83)90012-4</p>
<p>Assessment of deep learning methodology for self-organizing 5g networks. M Z Asghar, M Abbas, K Zeeshan, P Kotilainen, T HÃ¤mÃ¤lÃ¤inen, 10.3390/app9152975Appl. Sci. 92975Asghar, M. Z., Abbas, M., Zeeshan, K., Kotilainen, P., and HÃ¤mÃ¤lÃ¤inen, T. (2019). Assessment of deep learning methodology for self-organizing 5g networks. Appl. Sci. 9:2975. doi: 10.3390/app9152975</p>
<p>A neuropsychological theory of multiple systems in category learning. F G Ashby, L A Alfonso-Reese, E M Waldron, 10.1037/0033-295X.105.3.442Psychol. Rev. 105442Ashby, F. G., Alfonso-Reese, L. A., and Waldron, E. M. (1998). A neuropsychological theory of multiple systems in category learning. Psychol. Rev. 105:442. doi: 10.1037/0033-295X.105.3.442</p>
<p>On the dominance of unidimensional rules in unsupervised categorization. F G Ashby, S Queller, P M Berretty, 10.3758/BF03207622Percept. Psychophys. 61Ashby, F. G., Queller, S., and Berretty, P. M. (1999). On the dominance of unidimensional rules in unsupervised categorization. Percept. Psychophys. 61, 1178-1199. doi: 10.3758/BF03207622</p>
<p>Embracing complex models: Exploratory network analyses of psychological (In) Flexibility processes and unique associations with psychiatric symptomology and quality of life. L D Baker, C R Berghoff, 10.1016/j.jcbs.2021.12.002J. Context. Behav. Sci. 23Baker, L. D., and Berghoff, C. R. (2021). Embracing complex models: Exploratory network analyses of psychological (In) Flexibility processes and unique associations with psychiatric symptomology and quality of life. J. Context. Behav. Sci. 23, 64-74. doi: 10.1016/j.jcbs.2021.12.002</p>
<p>Updating RFT (more field than frame) and its implications for process-based therapy. D Barnes-Holmes, Y Barnes-Holmes, C Mcenteggart, 10.1007/s40732-019-00372-3Psychol. Record. 2020Barnes-Holmes, D., Barnes-Holmes, Y., and McEnteggart, C. (2020). Updating RFT (more field than frame) and its implications for process-based therapy. Psychol. Record 2020, 1-20. doi: 10.1007/s40732-019-00372-3</p>
<p>From the IRAP and REC model to a multi-dimensional multi-level framework for analyzing the dynamics of arbitrarily applicable relational responding. D Barnes-Holmes, Y Barnes-Holmes, C Luciano, C Mcenteggart, 10.1016/j.jcbs.2017.08.001J. Context. Behav. Sci. 6Barnes-Holmes, D., Barnes-Holmes, Y., Luciano, C., and McEnteggart, C. (2017). From the IRAP and REC model to a multi-dimensional multi-level framework for analyzing the dynamics of arbitrarily applicable relational responding. J. Context. Behav. Sci. 6, 434-445. doi: 10.1016/j.jcbs.2017. 08.001</p>
<p>Relational frame theory: A post-Skinnerian account of human language and cognition. D Barnes-Holmes, S C Hayes, B Roche, 10.1016/S0065-2407(02)80063-5Springer Science &amp; Business MediaBerlinBarnes-Holmes, D., Hayes, S. C., and Roche, B. (2001). Relational frame theory: A post-Skinnerian account of human language and cognition. Berlin: Springer Science &amp; Business Media. doi: 10.1016/S0065-2407(02)80063-5</p>
<p>Frames, concepts, and conceptual fields. L W Barsalou, APAWashington, D.C.Barsalou, L. W. (1992). Frames, concepts, and conceptual fields. Washington, D.C.: APA.</p>
<p>Cognitive psychology: An overview for cognitive scientists. L W Barsalou, 10.4324/9781315807485East Sussex: Psychology PressBarsalou, L. W. (2014). Cognitive psychology: An overview for cognitive scientists. East Sussex: Psychology Press. doi: 10.4324/9781315807485</p>
<p>Self determination of input variable importance using neural networks. E B Bartlett, Neural Parallel Sci. Computat. 2Bartlett, E. B. (1994). Self determination of input variable importance using neural networks. Neural Parallel Sci. Computat. 2, 103-114.</p>
<p>How auto-encoders could provide credit assignment in deep networks via target propagation. arXiv. Y Bengio, PreprintBengio, Y. (2014). How auto-encoders could provide credit assignment in deep networks via target propagation. arXiv. [Preprint].</p>
<p>Y Bengio, D.-H Lee, J Bornschein, T Mesnard, Lin , Z , Towards biologically plausible deep learning. arXiv. PreprintBengio, Y., Lee, D.-H., Bornschein, J., Mesnard, T., and Lin, Z. (2015). Towards biologically plausible deep learning. arXiv. [Preprint].</p>
<p>Classical mathematical models for description and prediction of experimental tumor growth. S Benzekry, C Lamont, A Beheshti, A Tracz, J M Ebos, L Hlatky, 10.1371/journal.pcbi.1003800doi: 10.1371/ journal.pcbi.1003800PLoS Comput. Biol. 101003800Benzekry, S., Lamont, C., Beheshti, A., Tracz, A., Ebos, J. M., Hlatky, L., et al. (2014). Classical mathematical models for description and prediction of experimental tumor growth. PLoS Comput. Biol. 10:e1003800. doi: 10.1371/ journal.pcbi.1003800</p>
<p>Scaling-up assessment from a contextual behavioral science perspective: Potential uses of technology for analysis of unstructured text data. O V Berkout, A J Cathey, K K Kellum, 10.1016/j.jcbs.2018.06.007J. Context. Behav. Sci. 12Berkout, O. V., Cathey, A. J., and Kellum, K. K. (2019). Scaling-up assessment from a contextual behavioral science perspective: Potential uses of technology for analysis of unstructured text data. J. Context. Behav. Sci. 12, 216-224. doi: 10.1016/j.jcbs.2018.06.007</p>
<p>Relational coherence and persistent rule-following: The impact of targeting coherence in a 'non-critical'component of a relational network. R Bern, T Persdotter, C Harte, D Barnes-Holmes, 10.1007/s40732-020-00414-1Psychol. Record. 2020Bern, R., Persdotter, T., Harte, C., and Barnes-Holmes, D. (2020). Relational coherence and persistent rule-following: The impact of targeting coherence in a 'non-critical'component of a relational network. Psychol. Record 2020, 1-12. doi: 10.1007/s40732-020-00414-1</p>
<p>Effects of coherence on speaker preference and rule-following. P H Bianchi, W F Perez, C Harte, D Barnes-Holmes, 10.18761/PAC.2021.v12.RFT.07Perspect. Em AnÃ¡lise Do Comportamento. 12Bianchi, P. H., Perez, W. F., Harte, C., and Barnes-Holmes, D. (2021). Effects of coherence on speaker preference and rule-following. Perspect. Em AnÃ¡lise Do Comportamento 12, 214-227. doi: 10.18761/PAC.2021.v12.RFT.07</p>
<p>An introduction to relational frame theory: Basics and applications. J T Blackledge, 10.1037/h0099997Behav. Anal. Today. 3421Blackledge, J. T. (2003). An introduction to relational frame theory: Basics and applications. Behav. Anal. Today 3:421. doi: 10.1037/h0099997</p>
<p>Fast unfolding of communities in large networks. V D Blondel, J.-L Guillaume, R Lambiotte, E Lefebvre, 10.1088/1742-5468/2008/10/P10008J. Statist. Mechan. Theory Exp. 10008Blondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of communities in large networks. J. Statist. Mechan. Theory Exp. 2008:10008. doi: 10.1088/1742-5468/2008/10/P10008</p>
<p>Language models are few-shot learners. arXiv. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, PreprintBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., et al. (2020). Language models are few-shot learners. arXiv. [Preprint].</p>
<p>Machine learning after the deep learning revolution. W L Buntine, 10.1007/s11704-020-0800-8Front. Comput. Sci. 14146320Buntine, W. L. (2020). Machine learning after the deep learning revolution. Front. Comput. Sci. 14:146320. doi: 10.1007/s11704-020-0800-8</p>
<p>The ART of adaptive pattern recognition by a self-organizing neural network. G A Carpenter, S Grossberg, 10.1109/2.33Computer. 21Carpenter, G. A., and Grossberg, S. (1988). The ART of adaptive pattern recognition by a self-organizing neural network. Computer 21, 77-88. doi: 10.1109/2.33</p>
<p>Incorporating prior biases innetwork models of conceptual rule learning. S Choi, M A Mcdaniel, J R Busemeyer, 10.3758/BF03197172Mem. Cognit. 21Choi, S., McDaniel, M. A., and Busemeyer, J. R. (1993). Incorporating prior biases innetwork models of conceptual rule learning. Mem. Cognit. 21, 413-423. doi: 10.3758/BF03197172</p>
<p>Syntactic structures. N Chomsky, 10.1515/9783112316009doi: 10.1515/ 9783112316009De Gruyter MoutonBerlinChomsky, N. (1957). Syntactic structures. Berlin: De Gruyter Mouton. doi: 10.1515/ 9783112316009</p>
<p>Network analysis: A new psychometric approach to examine the underlying ACT model components. A Christodoulou, M Michaelides, M Karekla, 10.1016/j.jcbs.2018.10.002J. Context. Behav. Sci. 12Christodoulou, A., Michaelides, M., and Karekla, M. (2019). Network analysis: A new psychometric approach to examine the underlying ACT model components. J. Context. Behav. Sci. 12, 285-289. doi: 10.1016/j.jcbs.2018.10.002</p>
<p>An inquisitive perspective on modals and quantifiers. I Ciardelli, F Roelofsen, 10.1146/annurev-linguistics-011817-045626Annu. Rev. Linguist. 4Ciardelli, I., and Roelofsen, F. (2017). An inquisitive perspective on modals and quantifiers. Annu. Rev. Linguist. 4, 1-22. doi: 10.1146/annurev-linguistics- 011817-045626</p>
<p>Deep neural networks as scientific models. R M Cichy, D Kaiser, 10.1016/j.tics.2019.01.009Trends Cognit. Sci. 23Cichy, R. M., and Kaiser, D. (2019). Deep neural networks as scientific models. Trends Cognit. Sci. 23, 305-317. doi: 10.1016/j.tics.2019.01.009</p>
<p>Cluster analysis in illness perception research: A Monte Carlo study to identify the most appropriate method. J Clatworthy, M Hankins, D Buick, J Weinman, R Horne, 10.1080/14768320600774496doi: 10.1080/ 14768320600774496Psychol. Health. 22Clatworthy, J., Hankins, M., Buick, D., Weinman, J., and Horne, R. (2007). Cluster analysis in illness perception research: A Monte Carlo study to identify the most appropriate method. Psychol. Health 22, 123-142. doi: 10.1080/ 14768320600774496</p>
<p>Discriminative reranking for natural language parsing. M Collins, Koo , T , 10.1162/0891201053630273Computat. Linguist. 31Collins, M., and Koo, T. (2005). Discriminative reranking for natural language parsing. Computat. Linguist. 31, 25-70. doi: 10.1162/0891201053630273</p>
<p>Brain imaging, connectionism, and cognitive neuropsychology. M Coltheart, 10.1080/02643290342000159doi: 10.1080/ 02643290342000159Cognit. Neuropsychol. 21Coltheart, M. (2004). Brain imaging, connectionism, and cognitive neuropsychology. Cognit. Neuropsychol. 21, 21-25. doi: 10.1080/ 02643290342000159</p>
<p>Articulation, accuracy and effectiveness of mathematical models: a review of freshwater wetland applications. R Costanza, F H Sklar, 10.1016/0304-3800(85)90024-9Ecol. Modell. 27Costanza, R., and Sklar, F. H. (1985). Articulation, accuracy and effectiveness of mathematical models: a review of freshwater wetland applications. Ecol. Modell. 27, 45-68. doi: 10.1016/0304-3800(85)90024-9</p>
<p>The recent excitement about neural networks. F Crick, 10.1038/337129a0Nature. 337Crick, F. (1989). The recent excitement about neural networks. Nature 337, 129- 132. doi: 10.1038/337129a0</p>
<p>Acceptance and Commitment Therapy's Philosophical Foundation under Scrutiny: An In-Depth Discussion of A-Ontology. D David, C Mogoase, J. Evid. Based Psychotherap. 15169David, D., and Mogoase, C. (2015). Acceptance and Commitment Therapy's Philosophical Foundation under Scrutiny: An In-Depth Discussion of A-Ontology. J. Evid. Based Psychotherap. 15:169.</p>
<p>The helmholtz machine. P Dayan, G E Hinton, R M Neal, R S Zemel, 10.1162/neco.1995.7.5.889Neural Computat. 7Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. (1995). The helmholtz machine. Neural Computat. 7, 889-904. doi: 10.1162/neco.1995.7.5.889</p>
<p>Active learning-based pedagogical rule extraction. E J De Fortuny, D Martens, 10.1109/TNNLS.2015.2389037doi: 10. 1109/TNNLS.2015.2389037IEEE Transact. Neural Netw. Learn. Syst. 26de Fortuny, E. J., and Martens, D. (2015). Active learning-based pedagogical rule extraction. IEEE Transact. Neural Netw. Learn. Syst. 26, 2664-2677. doi: 10. 1109/TNNLS.2015.2389037</p>
<p>Advances in relational frame theory: Research and application. J De Houwer, New Harbinger PublicationsOakland, CADe Houwer, J. (2013). Advances in relational frame theory: Research and application. Oakland, CA: New Harbinger Publications.</p>
<p>What is cognition? A functional-cognitive perspective. J De Houwer, D Barnes-Holmes, Y Barnes-Holmes, Core Processes of Cognitive Behavioral Therapies. S. C. Hayes and S. G. HofmannOakland, CANew HarbingerDe Houwer, J., Barnes-Holmes, D., and Barnes-Holmes, Y. (2018). "What is cognition? A functional-cognitive perspective, " in Core Processes of Cognitive Behavioral Therapies, eds S. C. Hayes and S. G. Hofmann (Oakland, CA: New Harbinger).</p>
<p>1.1 The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design. J Dean, 10.1109/ISSCC19947.2020.9063049State Circuits Conference-(ISSCC). New Jersey, NJIEEEin Paper presented at the 2020 IEEEDean, J. (2020). "1.1 The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design, " in Paper presented at the 2020 IEEE International Solid-State Circuits Conference-(ISSCC), (New Jersey, NJ: IEEE). doi: 10.1109/ISSCC19947.2020.9063049</p>
<p>A new golden age in computer architecture: Empowering the machine-learning revolution. J Dean, D Patterson, Young , C , 10.1109/MM.2018.112130030IEEE Micro. 38Dean, J., Patterson, D., and Young, C. (2018). A new golden age in computer architecture: Empowering the machine-learning revolution. IEEE Micro 38, 21-29. doi: 10.1109/MM.2018.112130030</p>
<p>Deep learning in natural language processing. L Deng, Y Liu, 10.1007/978-981-10-5209-5SpringerBerlinDeng, L., and Liu, Y. (2018). Deep learning in natural language processing. Berlin: Springer. doi: 10.1007/978-981-10-5209-5</p>
<p>Neural networks as statistical tools for business researchers. K B Detienne, D H Detienne, S A Joshi, 10.1177/1094428103251907Organizat. Res. Methods. 6Detienne, K. B., Detienne, D. H., and Joshi, S. A. (2003). Neural networks as statistical tools for business researchers. Organizat. Res. Methods 6, 236-265. doi: 10.1177/1094428103251907</p>
<p>Learning character-level representations for part-of-speech tagging. Dos Santos, C Zadrozny, B , International Conference on Machine Learning. Baltimore, MLInternational Conference on Machine LearningDos Santos, C., and Zadrozny, B. (2014). "Learning character-level representations for part-of-speech tagging, " in Paper presented at the International Conference on Machine Learning, (Baltimore, ML: International Conference on Machine Learning).</p>
<p>Transformation of the discriminative and eliciting functions of generalized relational stimuli. M J Dougher, D A Hamilton, B C Fink, J Harrington, 10.1901/jeab.2007.45-05J. Exp. Anal. Behav. 88Dougher, M. J., Hamilton, D. A., Fink, B. C., and Harrington, J. (2007). Transformation of the discriminative and eliciting functions of generalized relational stimuli. J. Exp. Anal. Behav. 88, 179-197. doi: 10.1901/jeab.2007.45- 05</p>
<p>Mind over machine. H Dreyfus, S E Dreyfus, T Athanasiou, Simon and SchusterNew York, NYDreyfus, H., Dreyfus, S. E., and Athanasiou, T. (2000). Mind over machine. New York, NY: Simon and Schuster.</p>
<p>Ensuring Effective Public Health Communication: Insights and Modeling Efforts From Theories of Behavioral Economics, Heuristics, and Behavioral Analysis for Decision Making Under Risk. D J Edwards, 10.3389/fpsyg.2021.715159Front. Psychol. 12715159Edwards, D. J. (2021). Ensuring Effective Public Health Communication: Insights and Modeling Efforts From Theories of Behavioral Economics, Heuristics, and Behavioral Analysis for Decision Making Under Risk. Front. Psychol. 12:715159. doi: 10.3389/fpsyg.2021.715159</p>
<p>Relational versus absolute representation in categorization. D J Edwards, E M Pothos, A Perlman, 10.5406/amerjpsyc.125.4.0481doi: 10.5406/ amerjpsyc.125.4.0481Am. J. Psychol. 125Edwards, D. J., Pothos, E. M., and Perlman, A. (2012). Relational versus absolute representation in categorization. Am. J. Psychol. 125, 481-497. doi: 10.5406/ amerjpsyc.125.4.0481</p>
<p>. S Epskamp, G K Maris, L J Waldorp, D Borsboom, Network psychometrics. arXiv. [preprintEpskamp, S., Maris, G. K., Waldorp, L. J., and Borsboom, D. (2016). Network psychometrics. arXiv. [preprint].</p>
<p>Successive refinement of information. W H Equitz, T M Cover, 10.1109/18.75242IEEE Transact. Informat. Theory. 37Equitz, W. H., and Cover, T. M. (1991). Successive refinement of information. IEEE Transact. Informat. Theory 37, 269-275. doi: 10.1109/18. 75242</p>
<p>What is interpretability?. A Erasmus, T D Brunet, E Fisher, 10.1007/s13347-020-00435-2Philosop. Technol. 34Erasmus, A., Brunet, T. D., and Fisher, E. (2021). What is interpretability? Philosop. Technol. 34, 833-862. doi: 10.1007/s13347-020-00435-2</p>
<p>Frame semantics and the nature of language. C J Fillmore, 10.1111/j.1749-6632.1976.tb25467.xAnnals of the New York Academy of Sciences: Conference on the origin and development of language and speech. New York, NYNew York Academy of Sciencesin Paper presented at theFillmore, C. J. (1976). "Frame semantics and the nature of language, " in Paper presented at the Annals of the New York Academy of Sciences: Conference on the origin and development of language and speech, (New York, NY: New York Academy of Sciences). doi: 10.1111/j.1749-6632.1976.tb25467.x</p>
<p>Exploring the singletrial-type-dominance-effect in the IRAP: Developing a differential arbitrarily applicable relational responding effects (DAARRE) model. M Finn, D Barnes-Holmes, C Mcenteggart, 10.1007/s40732-017-0262-zPsychol. Record. 68Finn, M., Barnes-Holmes, D., and McEnteggart, C. (2018). Exploring the single- trial-type-dominance-effect in the IRAP: Developing a differential arbitrarily applicable relational responding effects (DAARRE) model. Psychol. Record 68, 11-25. doi: 10.1007/s40732-017-0262-z</p>
<p>Categorization of faces using unsupervised feature extraction. M K Fleming, G W Cottrell, 10.1109/IJCNN.1990.137696IJCNN International Joint Conference on Neural Networks. Glasgow: IJCNN)Fleming, M. K., and Cottrell, G. W. (1990). "Categorization of faces using unsupervised feature extraction, " in Paper presented at the 1990 IJCNN International Joint Conference on Neural Networks, (Glasgow: IJCNN). doi: 10.1109/IJCNN.1990.137696</p>
<p>AI and its new winter: from myths to realities. L Floridi, 10.1007/s13347-020-00396-6Philosop. Technol. 33Floridi, L. (2020). AI and its new winter: from myths to realities. Philosop. Technol. 33, 1-3. doi: 10.1007/s13347-020-00396-6</p>
<p>Learning and inference in the brain. K Friston, 10.1016/j.neunet.2003.06.005Neural Netw. 16Friston, K. (2003). Learning and inference in the brain. Neural Netw. 16, 1325- 1352. doi: 10.1016/j.neunet.2003.06.005</p>
<p>A theory of cortical responses. K Friston, 10.1098/rstb.2005.1622Philosop. Transact. R. Soc. B Biol. Sci. 360Friston, K. (2005). A theory of cortical responses. Philosop. Transact. R. Soc. B Biol. Sci. 360, 815-836. doi: 10.1098/rstb.2005.1622</p>
<p>Applications of community detection techniques to brain graphs: Algorithmic considerations and implications for neural function. J O Garcia, A Ashourvan, S Muldoon, J M Vettel, D S Bassett, 10.1109/JPROC.2017.2786710Proc. IEEE. IEEE106Garcia, J. O., Ashourvan, A., Muldoon, S., Vettel, J. M., and Bassett, D. S. (2018). Applications of community detection techniques to brain graphs: Algorithmic considerations and implications for neural function. Proc. IEEE 106, 846-867. doi: 10.1109/JPROC.2017.2786710</p>
<p>Conceptual spaces: The geometry of thought. P GÃ¤rdenfors, MIT pressCambridge, CAGÃ¤rdenfors, P. (2004). Conceptual spaces: The geometry of thought. Cambridge, CA: MIT press.</p>
<p>The geometry of meaning: Semantics based on conceptual spaces. P Gardenfors, 10.7551/mitpress/9629.001.0001MIT pressCambridge, CAGardenfors, P. (2014). The geometry of meaning: Semantics based on conceptual spaces. Cambridge, CA: MIT press. doi: 10.7551/mitpress/9629.001.0001</p>
<p>The processing of information and structure. W R Garner, APAWashington, D.CGarner, W. R. (1974). The processing of information and structure. Washington, D.C: APA.</p>
<p>S Geman, E Bienenstock, R Doursat, 10.1162/neco.1992.4.1.1Neural networks and the bias/variance dilemma. Neural Computat. 4Geman, S., Bienenstock, E., and Doursat, R. (1992). Neural networks and the bias/variance dilemma. Neural Computat. 4, 1-58. doi: 10.1162/neco.1992.4.1.1</p>
<p>A preliminary demonstration of transformation of functions through hierarchical relations. E Gi, F Ruiz, C Luciano, S Valdivia-Salas, Rev. Int. Psicol. Ter. Psicol. 12Gi, E., Ruiz, F., Luciano, C., and Valdivia-Salas, S. (2012). A preliminary demonstration of transformation of functions through hierarchical relations. Rev. Int. Psicol. Ter. Psicol. 12, 1-19.</p>
<p>Explaining explanations: An overview of interpretability of machine learning. L H Gilpin, D Bau, B Z Yuan, A Bajwa, M Specter, L Kagal, 10.1109/DSAA.2018.00018IEEE 5th International Conference on data science and advanced analytics (DSAA). New Jersey, NJIEEEin Paper presented at theGilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M., and Kagal, L. (2018). "Explaining explanations: An overview of interpretability of machine learning, " in Paper presented at the 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA), (New Jersey, NJ: IEEE). doi: 10.1109/DSAA. 2018.00018</p>
<p>Technology for establishing deictic repertoires in autism. S P Gilroy, 10.1016/j.rasd.2015.04.004Philadelphia, PATemple UniversityGilroy, S. P. (2015). Technology for establishing deictic repertoires in autism. Philadelphia, PA: Temple University. doi: 10.1016/j.rasd.2015. 04.004</p>
<p>From conditioning to category learning: An adaptive network model. M A Gluck, G H Bower, 10.1037/0096-3445.117.3.227J. Exp. Psychol. General. 117227Gluck, M. A., and Bower, G. H. (1988). From conditioning to category learning: An adaptive network model. J. Exp. Psychol. General 117:227. doi: 10.1037/0096- 3445.117.3.227</p>
<p>R Golden, 10.1016/B0-08-043076-7/00563-5Artificial neural networks: Neurocomputation. Berlin: ResearchGate. Golden, R. (2001). Artificial neural networks: Neurocomputation. Berlin: ResearchGate. doi: 10.1016/B0-08-043076-7/00563-5</p>
<p>Categorization and concepts. Stevens'. Handb. R L Goldstone, A Kersten, P F Carvalho, 10.1002/9781119170174.epcn308doi: 10.1002/ 9781119170174.epcn308Exp. Psychol. Cognit. Neurosci. 3Goldstone, R. L., Kersten, A., and Carvalho, P. F. (2018). Categorization and concepts. Stevens'. Handb. Exp. Psychol. Cognit. Neurosci. 3, 1-43. doi: 10.1002/ 9781119170174.epcn308</p>
<p>Exploratory graph analysis: A new approach for estimating the number of dimensions in psychological research. H F Golino, S Epskamp, 10.1371/journal.pone.0174035PLoS One. 12Golino, H. F., and Epskamp, S. (2017). Exploratory graph analysis: A new approach for estimating the number of dimensions in psychological research. PLoS One 12, e0174035. doi: 10.1371/journal.pone.0174035</p>
<p>Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial. Golino, D Shi, A P Christensen, L E Garrido, M D Nieto, R Sadana, 10.1037/met0000255Psychol. Methods. 25292Golino, Shi, D., Christensen, A. P., Garrido, L. E., Nieto, M. D., Sadana, R., et al. (2020). Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial. Psychol. Methods 25:292. doi: 10.1037/met0000255</p>
<p>A rational analysis of rule-based concept learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, 10.1080/03640210701802071Cognit. Sci. 32Goodman, N. D., Tenenbaum, J. B., Feldman, J., and Griffiths, T. L. (2008). A rational analysis of rule-based concept learning. Cognit. Sci. 32, 108-154. doi: 10.1080/03640210701802071</p>
<p>What kindergartners know about class inclusion hierarchies. T R Greene, 10.1006/jecp.1994.1004J. Exp. Child Psychol. 57Greene, T. R. (1994). What kindergartners know about class inclusion hierarchies. J. Exp. Child Psychol. 57, 72-88. doi: 10.1006/jecp.1994. 1004</p>
<p>Potential applications of relational frame theory to natural language systems. D E Greenway, E K Sandoz, D R Perkins, 10.1109/FSKD.2010.5569078Seventh International Conference on Fuzzy Systems and Knowledge Discovery. New Jersey, NJIEEEin Paper presented at theGreenway, D. E., Sandoz, E. K., and Perkins, D. R. (2010). "Potential applications of relational frame theory to natural language systems, " in Paper presented at the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery, (New Jersey, NJ: IEEE). doi: 10.1109/FSKD.2010.556 9078</p>
<p>Draw: A recurrent neural network for image generation. K Gregor, I Danihelka, A Graves, D Rezende, D Wierstra, International Conference on Machine Learning. Baltimore, MLInternational Conference on Machine LearningGregor, K., Danihelka, I., Graves, A., Rezende, D., and Wierstra, D. (2015). "Draw: A recurrent neural network for image generation, " in Paper presented at the International Conference on Machine Learning, (Baltimore, ML: International Conference on Machine Learning).</p>
<p>Knowledge is power: Prior knowledge aids memory for both congruent and incongruent events, but in different ways. A Greve, E Cooper, R Tibon, R N Henson, 10.1037/xge0000498J. Exp. Psychol. General. 148325Greve, A., Cooper, E., Tibon, R., and Henson, R. N. (2019). Knowledge is power: Prior knowledge aids memory for both congruent and incongruent events, but in different ways. J. Exp. Psychol. General 148:325. doi: 10.1037/xge0000498</p>
<p>Typicality, graded membership, and vagueness. J A Hampton, 10.1080/15326900701326402Cognit. Sci. 31Hampton, J. A. (2007). Typicality, graded membership, and vagueness. Cognit. Sci. 31, 355-384. doi: 10.1080/15326900701326402</p>
<p>Chomsky's other revolution. R A Harris, 10.1075/z.154.08harChomskyan Evolut. Harris, R. A. (2010). Chomsky's other revolution. Chomskyan Evolut. 2010, 238- 264. doi: 10.1075/z.154.08har</p>
<p>R A Harris, 10.1093/oso/9780199740338.001.0001The Linguistics Wars: Chomsky, Lakoff, and the Battle Over Deep Structure. OxfordOxford University PressHarris, R. A. (2021). The Linguistics Wars: Chomsky, Lakoff, and the Battle Over Deep Structure. Oxford: Oxford University Press. doi: 10.1093/oso/ 9780199740338.001.0001</p>
<p>The impact of high versus low levels of derivation for mutually and combinatorially entailed relations on persistent rule-following. C Harte, D Barnes-Holmes, Y Barnes-Holmes, C Mcenteggart, 10.1016/j.beproc.2018.08.005Behav. Proces. 157Harte, C., Barnes-Holmes, D., Barnes-Holmes, Y., and McEnteggart, C. (2018). The impact of high versus low levels of derivation for mutually and combinatorially entailed relations on persistent rule-following. Behav. Proces. 157, 36-46. doi: 10.1016/j.beproc.2018.08.005</p>
<p>Exploring the impact of coherence (through the presence versus absence of feedback) and levels of derivation on persistent rule-following. C Harte, D Barnes-Holmes, Y Barnes-Holmes, C Mcenteggart, 10.3758/s13420-020-00438-1Learn. Behav. 2020Harte, C., Barnes-Holmes, D., Barnes-Holmes, Y., and McEnteggart, C. (2020). Exploring the impact of coherence (through the presence versus absence of feedback) and levels of derivation on persistent rule-following. Learn. Behav. 2020, 1-18. doi: 10.3758/s13420-020-00438-1</p>
<p>Persistent rule-following in the face of reversed reinforcement contingencies: The differential impact of direct versus derived rules. C Harte, Y Barnes-Holmes, D Barnes-Holmes, C Mcenteggart, 10.1177/0145445517715871Behav. Modificat. 41Harte, C., Barnes-Holmes, Y., Barnes-Holmes, D., and McEnteggart, C. (2017). Persistent rule-following in the face of reversed reinforcement contingencies: The differential impact of direct versus derived rules. Behav. Modificat. 41, 743-763. doi: 10.1177/0145445517715871</p>
<p>A dynamic model of reasoning and memory. G E Hawkins, B K Hayes, E Heit, 10.1037/xge0000113J. Exp. Psychol. General. 145155Hawkins, G. E., Hayes, B. K., and Heit, E. (2016). A dynamic model of reasoning and memory. J. Exp. Psychol. General 145:155. doi: 10.1037/xge0000113</p>
<p>The third wave of cognitive behavioral therapy and the rise of process-based care. S C Hayes, S G Hofmann, 10.1002/wps.20442doi: 10. 1002/wps.20442World Psychiatry. 16245Hayes, S. C., and Hofmann, S. G. (2017). The third wave of cognitive behavioral therapy and the rise of process-based care. World Psychiatry 16:245. doi: 10. 1002/wps.20442</p>
<p>Process-based CBT: The science and core clinical competencies of cognitive behavioral therapy. S C Hayes, S G Hofmann, New Harbinger PublicationsOakland, CAHayes, S. C., and Hofmann, S. G. (2018). Process-based CBT: The science and core clinical competencies of cognitive behavioral therapy. Oakland, CA: New Harbinger Publications.</p>
<p>How similar are recognition memory and inductive reasoning?. B K Hayes, E Heit, 10.3758/s13421-013-0297-6Mem. Cognit. 41Hayes, B. K., and Heit, E. (2013). How similar are recognition memory and inductive reasoning? Mem. Cognit. 41, 781-795. doi: 10.3758/s13421-013- 0297-6</p>
<p>Models of the effects of prior knowledge on category learning. E Heit, 10.1037/0278-7393.20.6.1264J. Exp. Psychol. Learn. Mem. Cognit. 201264Heit, E. (1994). Models of the effects of prior knowledge on category learning. J. Exp. Psychol. Learn. Mem. Cognit. 20:1264. doi: 10.1037/0278-7393.20.6.1264</p>
<p>Belief revision in models of category learning. E Heit, Cognitive Science SocietyAustin, TXin Paper presented at the Proceedings of the 17th annual conference of the cognitive science societyHeit, E. (1995). "Belief revision in models of category learning, " in Paper presented at the Proceedings of the 17th annual conference of the cognitive science society, (Austin, TX: Cognitive Science Society).</p>
<p>Knowledge and concept learning. E Heit, Knowledge Concepts CategorHeit, E. (1997). Knowledge and concept learning. Knowledge Concepts Categor. 1997, 7-41.</p>
<p>Influences of prior knowledge on selective weighting of category members. E Heit, 10.1037/0278-7393.24.3.712J. Exp. Psychol. 24712Heit, E. (1998). Influences of prior knowledge on selective weighting of category members. J. Exp. Psychol. 24:712. doi: 10.1037/0278-7393.24.3.712</p>
<p>Background knowledge and models of categorization. E Heit, 10.1093/acprof:oso/9780198506287.003.0009APAWashington, D.C.Heit, E. (2001). Background knowledge and models of categorization. Washington, D.C.: APA. doi: 10.1093/acprof:oso/9780198506287.003.0009</p>
<p>Knowledge selection in category learning. E Heit, L Bott, 10.1016/S0079-7421(00)80034-1Psychol. Learn. Motivat. 39Heit, E., and Bott, L. (2000). Knowledge selection in category learning. Psychol. Learn. Motivat. 39, 163-199. doi: 10.1016/S0079-7421(00)80034-1</p>
<p>Similarity and property effects in inductive reasoning. E Heit, J Rubinstein, 10.1037/0278-7393.20.2.411J. Exp. Psychol. 20411Heit, E., and Rubinstein, J. (1994). Similarity and property effects in inductive reasoning. J. Exp. Psychol. 20:411. doi: 10.1037/0278-7393.20.2.411</p>
<p>Learning distributed representations of concepts. G E Hinton, Cognitive Science SocietyAustin, TXin Paper presented at the Proceedings of the eighth annual conference of the cognitive science societyHinton, G. E. (1986). "Learning distributed representations of concepts, " in Paper presented at the Proceedings of the eighth annual conference of the cognitive science society, (Austin, TX: Cognitive Science Society).</p>
<p>Implementing semantic networks in parallel hardware. G E Hinton, Anderson , J A , 10.4324/9781315807997-12doi: 10.4324/ 9781315807997-12Parallel models of associative memory. G. E. Hinton and J. A. Anderson (East SussexPsychology PressHinton, G. E., and Anderson, J. A. (2014). "Implementing semantic networks in parallel hardware, " in Parallel models of associative memory, eds G. E. Hinton and J. A. Anderson (East Sussex: Psychology Press), 201-232. doi: 10.4324/ 9781315807997-12</p>
<p>Learning representations by recirculation. G E Hinton, J L Mcclelland, MIT PressCambridge, MAin Paper presented at the Neural information processing systemsHinton, G. E., and McClelland, J. L. (1988). "Learning representations by recirculation, " in Paper presented at the Neural information processing systems, (Cambridge, MA: MIT Press).</p>
<p>The future of intervention science: Process-based therapy. S G Hofmann, S C Hayes, 10.1177/2167702618772296doi: 10.1177/ 2167702618772296Clin. Psychol. Sci. 7Hofmann, S. G., and Hayes, S. C. (2019). The future of intervention science: Process-based therapy. Clin. Psychol. Sci. 7, 37-50. doi: 10.1177/ 2167702618772296</p>
<p>Learning process-based therapy: A skills training manual for targeting the core processes of psychological change in clinical practice. S G Hofmann, S C Hayes, D N Lorscheid, New Harbinger PublicationsOakland, CAHofmann, S. G., Hayes, S. C., and Lorscheid, D. N. (2021). Learning process-based therapy: A skills training manual for targeting the core processes of psychological change in clinical practice. Oakland, CA: New Harbinger Publications.</p>
<p>Towards explaining deep neural networks through graph analysis. V A Horta, A Mileo, 10.1007/978-3-030-27684-3_20International Conference on Database and Expert Systems Applications. Munich: DEXA)Horta, V. A., and Mileo, A. (2019). "Towards explaining deep neural networks through graph analysis, " in Paper presented at the International Conference on Database and Expert Systems Applications, (Munich: DEXA). doi: 10.1007/978- 3-030-27684-3_20</p>
<p>Extracting knowledge from Deep Neural Networks through graph analysis. V A Horta, I Tiddi, S Little, A Mileo, 10.1016/j.future.2021.02.009Future Generat. Comput. Syst. 120Horta, V. A., Tiddi, I., Little, S., and Mileo, A. (2021). Extracting knowledge from Deep Neural Networks through graph analysis. Future Generat. Comput. Syst. 120, 109-118. doi: 10.1016/j.future.2021.02.009</p>
<p>The sapir-whorf hypothesis today. B A Hussein, -S , 10.4304/tpls.2.3.642-646Theory Pract. Lang. Stud. 2Hussein, B. A.-S. (2012). The sapir-whorf hypothesis today. Theory Pract. Lang. Stud. 2, 642-646. doi: 10.4304/tpls.2.3.642-646</p>
<p>A taxonomy of inductive problems. A Jern, C Kemp, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science SocietyAustin, TXCognitive Science Societyin Paper presented at theJern, A., and Kemp, C. (2009). "A taxonomy of inductive problems, " in Paper presented at the Proceedings of the Annual Meeting of the Cognitive Science Society, (Austin, TX: Cognitive Science Society).</p>
<p>The explanatory force of dynamical and mathematical models in neuroscience: A mechanistic perspective. D M Kaplan, C F Craver, 10.1086/661755Philosop. Sci. 78Kaplan, D. M., and Craver, C. F. (2011). The explanatory force of dynamical and mathematical models in neuroscience: A mechanistic perspective. Philosop. Sci. 78, 601-627. doi: 10.1086/661755</p>
<p>Semantic theory. J J Katz, Harper &amp; RowNew York, NYKatz, J. J. (1972). Semantic theory. New York, NY: Harper &amp; Row.</p>
<p>F Keil, Concepts, kinds, and cognitive development. Cambridge, MAMIT PressKeil, F. (1989). Concepts, kinds, and cognitive development. Cambridge, MA: MIT Press.</p>
<p>Stock market prediction system with modular neural networks. T Kimoto, K Asakawa, M Yoda, M Takeoka, 10.1109/IJCNN.1990.137535IJCNN international joint conference on neural networks. San Diego, CAIJCNNin Paper presented at theKimoto, T., Asakawa, K., Yoda, M., and Takeoka, M. (1990). "Stock market prediction system with modular neural networks, " in Paper presented at the 1990 IJCNN international joint conference on neural networks, (San Diego, CA: IJCNN). doi: 10.1109/IJCNN.1990.137535</p>
<p>The Sapir-Whorf hypothesis: A preliminary history and a bibliographical essay. E K Koerner, 10.1525/jlin.1992.2.2.173J. Linguist. Anthropol. 2Koerner, E. K. (1992). The Sapir-Whorf hypothesis: A preliminary history and a bibliographical essay. J. Linguist. Anthropol. 2, 173-198. doi: 10.1525/jlin.1992. 2.2.173</p>
<p>Learning vector quantization. T Kohonen, 10.1007/978-3-642-56927-2_6Self-organizing maps. BerlinSpringerKohonen, T. (2001). "Learning vector quantization, " in Self-organizing maps, (Berlin: Springer), 245-261. doi: 10.1007/978-3-642-56927-2_6</p>
<p>T Kohonen, Self-organizing maps. BerlinSpringer Science &amp; Business Media30Kohonen, T. (2012). Self-organizing maps, Vol. 30. Berlin: Springer Science &amp; Business Media.</p>
<p>Recent views of conceptual structure. L K Komatsu, 10.1037/0033-2909.112.3.500Psychol. Bull. 112500Komatsu, L. K. (1992). Recent views of conceptual structure. Psychol. Bull. 112:500. doi: 10.1037/0033-2909.112.3.500</p>
<p>ALCOVE: an exemplar-based connectionist model of category learning. J K Kruschke, 10.1037/0033-295X.99.1.22Psychol. Rev. 9922Kruschke, J. K. (1992). ALCOVE: an exemplar-based connectionist model of category learning. Psychol. Rev. 99:22. doi: 10.1037/0033-295X.99.1.22</p>
<p>Challenges in interpretability of neural networks for eye movement data. A Kumar, P Howlader, R Garcia, D Weiskopf, K Mueller, 10.1145/3379156.3391361ACM Symposium on Eye Tracking Research and Applications. New York CityACMin Paper presented at theKumar, A., Howlader, P., Garcia, R., Weiskopf, D., and Mueller, K. (2020). "Challenges in interpretability of neural networks for eye movement data, " in Paper presented at the ACM Symposium on Eye Tracking Research and Applications, (New York City: ACM). doi: 10.1145/3379156.3391361</p>
<p>The divergent autoencoder (DIVA) model of category learning. K J Kurtz, 10.3758/BF03196806Psychonomic Bull. Rev. 14Kurtz, K. J. (2007). The divergent autoencoder (DIVA) model of category learning. Psychonomic Bull. Rev. 14, 560-576. doi: 10.3758/BF03196806</p>
<p>Cognitive semantics and artificial intelligence. O Kuznetsov, 10.3103/S0147688213050067Sci. Technic. Informat. Proces. 40Kuznetsov, O. (2013). Cognitive semantics and artificial intelligence. Sci. Technic. Informat. Proces. 40, 269-276. doi: 10.3103/S0147688213050067</p>
<p>Women, fire, and dangerous things. G Lakoff, University of Chicago pressChicagoLakoff, G. (2008). Women, fire, and dangerous things. Chicago: University of Chicago press.</p>
<p>Exemplar models and category-specific deficits. Category Specific. K Lamberts, L Shapiro, Brain Mind. Lamberts, K., and Shapiro, L. (2002). Exemplar models and category-specific deficits. Category Specific. Brain Mind 2002, 291-314.</p>
<p>S Laurence, E Margolis, Concepts: core readings. Cambridge, MAMit PressLaurence, S., and Margolis, E. (1999). Concepts: core readings. Cambridge, MA: Mit Press.</p>
<p>Learning and encoding higher order rules in neural networks. D S Levine, 10.3758/BF03204727Behav. Res. Methods Instrum. Comput. 27Levine, D. S. (1995). Learning and encoding higher order rules in neural networks. Behav. Res. Methods Instrum. Comput. 27, 178-182. doi: 10.3758/BF03204727</p>
<p>General semantics. D Lewis, 10.1016/B978-0-12-545850-4.50007-8ElsevierAmsterdamin Montague grammarLewis, D. (1976). "General semantics, " in Montague grammar, (Amsterdam: Elsevier), 1-50. doi: 10.1016/B978-0-12-545850-4.50007-8</p>
<p>From AlphaGo to power system AI: What engineers can learn from solving the most complex board game. F Li, Y Du, 10.1109/MPE.2017.2779554IEEE Power Energy Magazine. 16Li, F., and Du, Y. (2018). From AlphaGo to power system AI: What engineers can learn from solving the most complex board game. IEEE Power Energy Magazine 16, 76-84. doi: 10.1109/MPE.2017.2779554</p>
<p>A functional approach for research on cognitive control: Analysing cognitive control tasks and their effects in terms of operant conditioning. B Liefooghe, De Houwer, J , 10.1002/ijop.12179Int. J. Psychol. 51Liefooghe, B., and De Houwer, J. (2016). A functional approach for research on cognitive control: Analysing cognitive control tasks and their effects in terms of operant conditioning. Int. J. Psychol. 51, 28-32. doi: 10.1002/ijop.12179</p>
<p>Artificial neural network related to biological neuron network: a review. J.-W Lin, 10.12988/asms.2017.753Adv. Stud. Med. Sci. 5Lin, J.-W. (2017). Artificial neural network related to biological neuron network: a review. Adv. Stud. Med. Sci. 5, 55-62. doi: 10.12988/asms.2017.753</p>
<p>Deep Neural Networks for High Dimension, Low Sample Size Data. B Liu, Y Wei, Y Zhang, Yang , Q , 10.24963/ijcai.2017/318IJCAI). Stockholmin Paper presented at the IJCAILiu, B., Wei, Y., Zhang, Y., and Yang, Q. (2017). "Deep Neural Networks for High Dimension, Low Sample Size Data, " in Paper presented at the IJCAI, (Stockholm: IJCAI). doi: 10.24963/ijcai.2017/318</p>
<p>Complex brain network analysis and its applications to brain disorders: a survey. J Liu, M Li, Y Pan, W Lan, R Zheng, F.-X Wu, 10.1155/2017/8362741Complexity. 8362741Liu, J., Li, M., Pan, Y., Lan, W., Zheng, R., Wu, F.-X., et al. (2017). Complex brain network analysis and its applications to brain disorders: a survey. Complexity 2017:8362741. doi: 10.1155/2017/8362741</p>
<p>Improving the interpretability of deep neural networks with knowledge distillation. X Liu, X Wang, S Matwin, 10.1109/ICDMW.2018.00132IEEE International Conference on Data Mining Workshops (ICDMW). New Jersey, NJIEEEin Paper presented atLiu, X., Wang, X., and Matwin, S. (2018). "Improving the interpretability of deep neural networks with knowledge distillation, " in Paper presented at the 2018 IEEE International Conference on Data Mining Workshops (ICDMW), (New Jersey, NJ: IEEE). doi: 10.1109/ICDMW.2018.00132</p>
<p>Semantic labeling in very high resolution images via a self-cascaded convolutional neural network. Y Liu, B Fan, L Wang, J Bai, S Xiang, C Pan, Liu, Y., Fan, B., Wang, L., Bai, J., Xiang, S., and Pan, C. (2018). Semantic labeling in very high resolution images via a self-cascaded convolutional neural network.</p>
<p>. Isprs J Photogramm, 10.1016/j.isprsjprs.2017.12.007Rem. Sens. 145ISPRS J. Photogramm. Rem. Sens. 145, 78-95. doi: 10.1016/j.isprsjprs.2017.12. 007</p>
<p>Concepts, frames and cascades in semantics, cognition and ontology. S LÃ¶bner, T Gamerschlag, T Kalenscher, M Schrenk, H Zeevat, 10.1007/978-3-030-50200-3Springer NatureBerlinLÃ¶bner, S., Gamerschlag, T., Kalenscher, T., Schrenk, M., and Zeevat, H. (2021). Concepts, frames and cascades in semantics, cognition and ontology. Berlin: Springer Nature. doi: 10.1007/978-3-030-50200-3</p>
<p>A connectionist implementation of the theory of planned behavior: Association of beliefs with exercise intention. R Lowe, P Bennett, I Walker, S Milne, G Bozionelos, 10.1037/0278-6133.22.5.464Health Psychol. 22464Lowe, R., Bennett, P., Walker, I., Milne, S., and Bozionelos, G. (2003). A connectionist implementation of the theory of planned behavior: Association of beliefs with exercise intention. Health Psychol. 22:464. doi: 10.1037/0278- 6133.22.5.464</p>
<p>Milieu matters: Evidence that ongoing lifestyle activities influence health behaviors. R Lowe, P Norman, P Sheeran, 10.1371/journal.pone.0179699PLoS One. 12179699Lowe, R., Norman, P., and Sheeran, P. (2017). Milieu matters: Evidence that ongoing lifestyle activities influence health behaviors. PLoS One 12:e0179699. doi: 10.1371/journal.pone.0179699</p>
<p>Artificial intelligence: structures and strategies for complex problem solving: Pearson education. G F Luger, PearsonLondonLuger, G. F. (2005). Artificial intelligence: structures and strategies for complex problem solving: Pearson education. London: Pearson.</p>
<p>Semantics, cross-cultural style. E Machery, R Mallon, S Nichols, S P Stich, 10.1016/j.cognition.2003.10.003Cognition. 92Machery, E., Mallon, R., Nichols, S., and Stich, S. P. (2004). Semantics, cross-cultural style. Cognition 92, B1-B12. doi: 10.1016/j.cognition.2003. 10.003</p>
<p>An empirical measure of element contribution in neural networks. B Mak, R W Blanning, 10.1109/5326.725342IEEE Transact. Syst. Man Cybernet. Part C. 28Mak, B., and Blanning, R. W. (1998). An empirical measure of element contribution in neural networks. IEEE Transact. Syst. Man Cybernet. Part C 28, 561-564. doi: 10.1109/5326.725342</p>
<p>E Margolis, Laurence , S , Concepts: core readings. Cambridge, MAMit PressMargolis, E., and Laurence, S. (1999). Concepts: core readings. Cambridge, MA: Mit Press.</p>
<p>A distributed model of human learning and memory. J L Mcclelland, D E Rumelhart, 10.7551/mitpress/5237.001.0001Parallel distributed processing: Explorations in the microstructure of cognition. J. L. Mcclelland and D. E. RumelhartCambridge, MAMIT Press2Psychological and biological modelsMcClelland, J. L., and Rumelhart, D. E. (1986). "A distributed model of human learning and memory, " in Parallel distributed processing: Explorations in the microstructure of cognition, Vol. 2: Psychological and biological models, eds J. L. Mcclelland and D. E. Rumelhart (Cambridge, MA: MIT Press), 170-215. doi: 10.7551/mitpress/5237.001.0001</p>
<p>Parallel distributed processing. J L Mcclelland, D E Rumelhart, P R Group, 10.7551/mitpress/5236.001.0001MIT press2Cambridge, MAMcClelland, J. L., Rumelhart, D. E., and Group, P. R. (1986). Parallel distributed processing, Vol. 2. Cambridge, MA: MIT press. doi: 10.7551/mitpress/5236.001. 0001</p>
<p>Introduction to connectionist modelling of cognitive processes. P Mcleod, K Plunkett, E T Rolls, Oxford University PressOxfordMcLeod, P., Plunkett, K., and Rolls, E. T. (1998). Introduction to connectionist modelling of cognitive processes. Oxford: Oxford University Press.</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, 10.1037/0033-295X.85.3.207Psychol. Rev. 85207Medin, D. L., and Schaffer, M. M. (1978). Context theory of classification learning. Psychol. Rev. 85:207. doi: 10.1037/0033-295X.85.3.207</p>
<p>B Millidge, A Tschantz, C L Buckley, Predictive coding approximates backprop along arbitrary computation graphs. arXiv. preprintMillidge, B., Tschantz, A., and Buckley, C. L. (2020). Predictive coding approximates backprop along arbitrary computation graphs. arXiv. [preprint].</p>
<p>An examination of the effect of six types of error perturbation on fifteen clustering algorithms. G W Milligan, 10.1007/BF02293907Psychometrika. 45Milligan, G. W. (1980). An examination of the effect of six types of error perturbation on fifteen clustering algorithms. Psychometrika 45, 325-342. doi: 10.1007/BF02293907</p>
<p>Category structure and the two learning systems of COVIS. F Milton, E M Pothos, 10.1111/j.1460-9568.2011.07847.xEur. J. Neurosci. 34Milton, F., and Pothos, E. M. (2011). Category structure and the two learning systems of COVIS. Eur. J. Neurosci. 34, 1326-1336. doi: 10.1111/j.1460-9568. 2011.07847.x</p>
<p>Prototypes in category learning: the effects of category size, category structure, and stimulus complexity. J P Minda, J D Smith, 10.1037/0278-7393.27.3.775J. Exp. Psychol. 27775Minda, J. P., and Smith, J. D. (2001). Prototypes in category learning: the effects of category size, category structure, and stimulus complexity. J. Exp. Psychol. 27:775. doi: 10.1037/0278-7393.27.3.775</p>
<p>Why AI is harder than we think. arXiv. M Mitchell, 10.1145/3449639.3465421doi: 10. 1145/3449639.3465421PreprintMitchell, M. (2021). Why AI is harder than we think. arXiv. [Preprint]. doi: 10. 1145/3449639.3465421</p>
<p>Universal grammar. R Montague, 10.1111/j.1755-2567.1970.tb00434.xdoi: 10.1111/j. 1755-2567.1970.tb00434.xTheoria. 36Montague, R. (1970). Universal grammar. Theoria 36, 373-398. doi: 10.1111/j. 1755-2567.1970.tb00434.x</p>
<p>Interpretability in neural networks towards universal consistency. D M Monte-Serrat, C Cattani, 10.1016/j.ijcce.2021.01.002Int. J. Cognit. Comput. Enginee. 2Monte-Serrat, D. M., and Cattani, C. (2021). Interpretability in neural networks towards universal consistency. Int. J. Cognit. Comput. Enginee. 2, 30-39. doi: 10.1016/j.ijcce.2021.01.002</p>
<p>Investigating Relational Framing of Categorization in Young Children. T Mulhern, I Stewart, J Mc Elwee, 10.1007/s40732-017-0255-ydoi: 10.1007/ s40732-017-0255-yPsychol. Record. 67Mulhern, T., Stewart, I., and Mc Elwee, J. (2017). Investigating Relational Framing of Categorization in Young Children. Psychol. Record 67, 519-536. doi: 10.1007/ s40732-017-0255-y</p>
<p>Hierarchical structure in concepts and the basic level of categorization. G L Murphy, M E Lassaline, Knowl. Concepts Categor. Murphy, G. L., and Lassaline, M. E. (1997). Hierarchical structure in concepts and the basic level of categorization. Knowl. Concepts Categor. 1997, 93-131.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, 10.1037/0033-295X.92.3.289Psychol. Rev. 92289Murphy, G. L., and Medin, D. L. (1985). The role of theories in conceptual coherence. Psychol. Rev. 92:289. doi: 10.1037/0033-295X.92.3.289</p>
<p>Theories and concept formation. G L Murphy, APAWashington, D.CMurphy, G. L. (1993). Theories and concept formation. Washington, D.C: APA.</p>
<p>The Big Book of Concepts. G L Murphy, 10.7551/mitpress/1602.001.0001MIT PressCambridge, MAMurphy, G. L. (2002). The Big Book of Concepts. Cambridge, MA: MIT Press. doi: 10.7551/mitpress/1602.001.0001</p>
<p>Mathematical modeling, " in Stevens' handbook of experimental psychology. I J Myung, M A Pitt, 10.1002/0471214426.pas0411J. T. Wixted, E. A. Phelps, and L. DavachiWileyNew Jersey, NYMyung, I. J., and Pitt, M. A. (2002). "Mathematical modeling, " in Stevens' handbook of experimental psychology, eds J. T. Wixted, E. A. Phelps, and L. Davachi (New Jersey, NY: Wiley). doi: 10.1002/0471214426.pas0411</p>
<p>Speech recognition using deep neural networks: A systematic review. A B Nassif, I Shahin, I Attili, M Azzeh, K Shaalan, 10.1109/ACCESS.2019.2896880IEEE Access. 7Nassif, A. B., Shahin, I., Attili, I., Azzeh, M., and Shaalan, K. (2019). Speech recognition using deep neural networks: A systematic review. IEEE Access 7, 19143-19165. doi: 10.1109/ACCESS.2019.2896880</p>
<p>Dyslexic participants show intact spontaneous categorization processes. D S Nikolopoulos, E M Pothos, 10.1002/dys.375Dyslexia. 15Nikolopoulos, D. S., and Pothos, E. M. (2009). Dyslexic participants show intact spontaneous categorization processes. Dyslexia 15, 167-186. doi: 10.1002/dys. 375</p>
<p>A relational frame and artificial neural network approach to computer-interactive mathematics. C Ninness, R Rumph, G Mcculler, E Vasquez, C Harrison, A M Ford, 10.1007/BF03395503doi: 10.1007/ BF03395503Psychol. Record. 55Ninness, C., Rumph, R., McCuller, G., Vasquez, E., Harrison, C., Ford, A. M., et al. (2005). A relational frame and artificial neural network approach to computer-interactive mathematics. Psychol. Record 55, 135-153. doi: 10.1007/ BF03395503</p>
<p>The use of statistical heuristics in everyday inductive reasoning. R E Nisbett, D H Krantz, C Jepson, Z Kunda, 10.1037/0033-295X.90.4.339doi: 10.1037/ 0033-295X.90.4.339Psychol. Rev. 90339Nisbett, R. E., Krantz, D. H., Jepson, C., and Kunda, Z. (1983). The use of statistical heuristics in everyday inductive reasoning. Psychol. Rev. 90:339. doi: 10.1037/ 0033-295X.90.4.339</p>
<p>Attention, similarity, and the identification-categorization relationship. R M Nosofsky, 10.1037/0096-3445.115.1.39J. Exp. Psychol. General. 11539Nosofsky, R. M. (1986). Attention, similarity, and the identification-categorization relationship. J. Exp. Psychol. General 115:39. doi: 10.1037/0096-3445.1 15.1.39</p>
<p>Similarity, frequency, and category representations. R M Nosofsky, 10.1037/0278-7393.14.1.54J. Exp. Psychol. 1454Nosofsky, R. M. (1988). Similarity, frequency, and category representations. J. Exp. Psychol. 14:54. doi: 10.1037/0278-7393.14.1.54</p>
<p>The leabra cognitive architecture: How to play 20 principles with nature. R C O&apos;reilly, T E Hazy, S A Herd, Oxford HandBook Congn. Sci. 91O'Reilly, R. C., Hazy, T. E., and Herd, S. A. (2016). The leabra cognitive architecture: How to play 20 principles with nature. Oxford HandBook Congn. Sci. 91, 91-116.</p>
<p>Stimulus equivalence and the origins of reasoning, language, and working memory. M Oaksford, Cognit. Stud. Bull. Jap. Cognit. Sci. Soc. 15Oaksford, M. (2008). Stimulus equivalence and the origins of reasoning, language, and working memory. Cognit. Stud. Bull. Jap. Cognit. Sci. Soc. 15, 392-407.</p>
<p>Machine learning for expert systems in data analysis. E T Ogidan, K Dimililer, Y K Ever, 10.1109/ISMSIT.2018.85672512nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT). New Jersey, NJIEEEin Paper presented atOgidan, E. T., Dimililer, K., and Ever, Y. K. (2018). "Machine learning for expert systems in data analysis, " in Paper presented at the 2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), (New Jersey, NJ: IEEE). doi: 10.1109/ISMSIT.2018.8567251</p>
<p>Reverse engineering creativity into interpretable neural networks. M Oita, 10.1007/978-3-030-12385-7_19FICC). San Francisco, CAin Paper presented at the Future of Information and Communication ConferenceOita, M. (2019). "Reverse engineering creativity into interpretable neural networks, " in Paper presented at the Future of Information and Communication Conference, (San Francisco, CA: FICC). doi: 10.1007/978-3-030-12385-7_19</p>
<p>Sapir-Whorf Hypothesis. S P O&apos;neill, 10.1002/9781118611463.wbielsi086Int. Encyclop. Lang. Soc. Interact. 2015O'Neill, S. P. (2015). Sapir-Whorf Hypothesis. Int. Encyclop. Lang. Soc. Interact. 2015, 1-10. doi: 10.1002/9781118611463.wbielsi086</p>
<p>Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm. R C O&apos;reilly, 10.1162/neco.1996.8.5.895Neural Computat. 8O'Reilly, R. C. (1996). Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm. Neural Computat. 8, 895-938. doi: 10.1162/neco.1996.8.5.895</p>
<p>Computational explorations in cognitive neuroscience: Understanding the mind by simulating the brain. R C O&apos;reilly, Y Munakata, 10.7551/mitpress/2014.001.0001MIT pressCambridge, MAO'reilly, R. C., and Munakata, Y. (2000). Computational explorations in cognitive neuroscience: Understanding the mind by simulating the brain. Cambridge, MA: MIT press. doi: 10.7551/mitpress/2014.001.0001</p>
<p>Categorybased induction. D N Osherson, E E Smith, O Wilkie, A Lopez, E Shafir, 10.1037/0033-295X.97.2.185Psychol. Rev. 97185Osherson, D. N., Smith, E. E., Wilkie, O., Lopez, A., and Shafir, E. (1990). Category- based induction. Psychol. Rev. 97:185. doi: 10.1037/0033-295X.97.2.185</p>
<p>Prior experience supports new learning of relations in aging. M L Ostreicher, S N Moses, R S Rosenbaum, J D Ryan, 10.1093/geronb/gbp081J. Gerontol. Ser. B Psychol. Sci. Soc. Sci. 65Ostreicher, M. L., Moses, S. N., Rosenbaum, R. S., and Ryan, J. D. (2010). Prior experience supports new learning of relations in aging. J. Gerontol. Ser. B Psychol. Sci. Soc. Sci. 65, 32-41. doi: 10.1093/geronb/gbp081</p>
<p>The PageRank citation ranking: Bringing order to the web. L Page, S Brin, R Motwani, T Winograd, Stanford InfoLabStanford, CAPage, L., Brin, S., Motwani, R., and Winograd, T. (1999). The PageRank citation ranking: Bringing order to the web. Stanford, CA: Stanford InfoLab.</p>
<p>Psychological essentialism: A review of. D C Palmer, 10.1901/jeab.2002.78-597J. Exp. Anal. Behav. E. Margolis and S. Laurence78Concepts: Core readingsPalmer, D. C. (2002). Psychological essentialism: A review of E. Margolis and S. Laurence (EDS.), Concepts: Core readings. J. Exp. Anal. Behav. 78, 597-607. doi: 10.1901/jeab.2002.78-597</p>
<p>Lexical semantics. C Paradis, 10.1002/9781405198431.wbeal0695The encyclopedia of applied linguistics. New Jersey, NJWiley-BlackwellParadis, C. (2012). "Lexical semantics, " in The encyclopedia of applied linguistics, (New Jersey, NJ: Wiley-Blackwell). doi: 10.1002/9781405198431.wbeal0695</p>
<p>Influence of prior knowledge on concept acquisition: Experimental and computational results. M J Pazzani, 10.1037/0278-7393.17.3.416J. Exp. Psychol. Learn. Mem. Cognit. 17416Pazzani, M. J. (1991). Influence of prior knowledge on concept acquisition: Experimental and computational results. J. Exp. Psychol. Learn. Mem. Cognit. 17:416. doi: 10.1037/0278-7393.17.3.416</p>
<p>World hypotheses. S C Pepper, University of California PressCalifornia, CAPepper, S. C. (1942). World hypotheses. California, CA: University of California Press.</p>
<p>The notion of contextual locking: Previously learnt items are not accessible as such when appearing in a less common context. Quart. A Perlman, Y Hoffman, J Tzelgov, E M Pothos, D J Edwards, 10.1080/17470218.2015.1054846J. Exp. Psychol. 69Perlman, A., Hoffman, Y., Tzelgov, J., Pothos, E. M., and Edwards, D. J. (2016). The notion of contextual locking: Previously learnt items are not accessible as such when appearing in a less common context. Quart. J. Exp. Psychol. 69, 410-431. doi: 10.1080/17470218.2015.1054846</p>
<p>Task-relevant chunking in sequence learning. A Perlman, E M Pothos, D J Edwards, J Tzelgov, 10.1037/a0017178J. Exp. Psychol. 36649Perlman, A., Pothos, E. M., Edwards, D. J., and Tzelgov, J. (2010). Task-relevant chunking in sequence learning. J. Exp. Psychol. 36:649. doi: 10.1037/a0017178</p>
<p>On the genesis of abstract ideas. M I Posner, S W Keele, 10.1037/h0025953J. Exp. Psychol. 77353Posner, M. I., and Keele, S. W. (1968). On the genesis of abstract ideas. J. Exp. Psychol. 77:353. doi: 10.1037/h0025953</p>
<p>A simplicity principle in unsupervised human categorization. E M Pothos, N Chater, 10.1207/s15516709cog2603_6Cognit. Sci. 26Pothos, E. M., and Chater, N. (2002). A simplicity principle in unsupervised human categorization. Cognit. Sci. 26, 303-343. doi: 10.1207/s15516709cog2603_6</p>
<p>One or two dimensions in spontaneous classification: A simplicity approach. E M Pothos, J Close, 10.1016/j.cognition.2007.11.007doi: 10.1016/j. cognition.2007.11.007Cognition. 107Pothos, E. M., and Close, J. (2008). One or two dimensions in spontaneous classification: A simplicity approach. Cognition 107, 581-602. doi: 10.1016/j. cognition.2007.11.007</p>
<p>Formal approaches in categorization. E M Pothos, A J Wills, 10.1017/CBO9780511921322Cambridge: University PressPothos, E. M., and Wills, A. J. (2011). Formal approaches in categorization. Cambridge: University Press. doi: 10.1017/CBO9780511921322</p>
<p>Measuring category intuitiveness in unconstrained categorization tasks. E M Pothos, A Perlman, T M Bailey, K Kurtz, D J Edwards, P Hines, 10.1016/j.cognition.2011.06.002Cognition. 121Pothos, E. M., Perlman, A., Bailey, T. M., Kurtz, K., Edwards, D. J., Hines, P., et al. (2011). Measuring category intuitiveness in unconstrained categorization tasks. Cognition 121, 83-100. doi: 10.1016/j.cognition.2011.06.002</p>
<p>C Potts, 10.1093/acprof:oso/9780199273829.001.0001The logic of conventional implicatures. OxfordOUP7Potts, C. (2004). The logic of conventional implicatures, Vol. 7. Oxford: OUP Oxford. doi: 10.1093/acprof:oso/9780199273829.001.0001</p>
<p>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. R P Rao, D H Ballard, 10.1038/4580Nat. Neurosci. 2Rao, R. P., and Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79-87. doi: 10.1038/4580</p>
<p>Pattern recognition and categorization. S K Reed, 10.1016/0010-0285(72)90014-XCognit. Psychol. 3Reed, S. K. (1972). Pattern recognition and categorization. Cognit. Psychol. 3, 382-407. doi: 10.1016/0010-0285(72)90014-X</p>
<p>A knowledge-resonance (KRES) model of category learning. B Rehder, G L Murphy, 10.3758/BF03196543doi: 10.3758/ BF03196543Psychonomic Bull. Rev. 10Rehder, B., and Murphy, G. L. (2003). A knowledge-resonance (KRES) model of category learning. Psychonomic Bull. Rev. 10, 759-784. doi: 10.3758/ BF03196543</p>
<p>Inductive judgments about natural categories. L J Rips, 10.1016/S0022-5371(75)80055-7J. Verb. Learn. Verb. Behav. 14Rips, L. J. (1975). Inductive judgments about natural categories. J. Verb. Learn. Verb. Behav. 14, 665-681. doi: 10.1016/S0022-5371(75)80 055-7</p>
<p>Similarity, typicality, and categorization. L J Rips, 10.1017/CBO9780511529863.004Similar. Anal. Reason. 2159Rips, L. J. (1989). Similarity, typicality, and categorization. Similar. Anal. Reason. 1989:2159. doi: 10.1017/CBO9780511529863.004</p>
<p>A simple model from a powerful framework that spans levels of analysis. T T Rogers, J L Mcclelland, 10.1017/S0140525X08006067Behav. Brain Sci. 31Rogers, T. T., and McClelland, J. L. (2008). A simple model from a powerful framework that spans levels of analysis. Behav. Brain Sci. 31, 729-749. doi: 10.1017/S0140525X08006067</p>
<p>Semantics without categorization. Formal Approac. Categoriz. T T Rogers, J L Mcclelland, 10.1017/CBO9780511921322.005Rogers, T. T., and McClelland, J. L. (2011). Semantics without categorization. Formal Approac. Categoriz. 2011, 88-119. doi: 10.1017/CBO9780511921322. 005</p>
<p>Family resemblances: Studies in the internal structure of categories. E Rosch, C B Mervis, 10.1016/0010-0285(75)90024-9Cognit. Psychol. 7Rosch, E., and Mervis, C. B. (1975). Family resemblances: Studies in the internal structure of categories. Cognit. Psychol. 7, 573-605. doi: 10.1016/0010-0285(75) 90024-9</p>
<p>Category-based predictions: influence of uncertainty and feature associations. B H Ross, G L Murphy, 10.1037/0278-7393.22.3.736J. Exp. Psychol. 22736Ross, B. H., and Murphy, G. L. (1996). Category-based predictions: influence of uncertainty and feature associations. J. Exp. Psychol. 22:736. doi: 10.1037/0278- 7393.22.3.736</p>
<p>Comparing exemplar-and rule-based theories of categorization. J N Rouder, R Ratcliff, 10.1111/j.0963-7214.2006.00397.xCurr. Direct. Psychol. Sci. 15Rouder, J. N., and Ratcliff, R. (2006). Comparing exemplar-and rule-based theories of categorization. Curr. Direct. Psychol. Sci. 15, 9-13. doi: 10.1111/j.0963-7214. 2006.00397.x</p>
<p>Brain style computation: Learning and generalization. D E Rumelhart, Introduct. Neural Electr. Netw. Rumelhart, D. E. (1990). Brain style computation: Learning and generalization. Introduct. Neural Electr. Netw. 1990, 405-420.</p>
<p>Learning and connectionist representations. D E Rumelhart, P M Todd, Attent. Perform. XIV Synerg. Exp. Psychol. Artific. Intellig. Cognit. Neurosci. 2Rumelhart, D. E., and Todd, P. M. (1993). Learning and connectionist representations. Attent. Perform. XIV Synerg. Exp. Psychol. Artific. Intellig. Cognit. Neurosci. 2, 3-30.</p>
<p>Feature discovery by competitive learning. D E Rumelhart, D Zipser, 10.1207/s15516709cog0901_5Cognit. Sci. 9Rumelhart, D. E., and Zipser, D. (1985). Feature discovery by competitive learning. Cognit. Sci. 9, 75-112. doi: 10.1207/s15516709cog0901_5</p>
<p>Learning representations by back-propagating errors. D E Rumelhart, G E Hinton, R J Williams, 10.1038/323533a0doi: 10.1038/ 323533a0Nature. 323Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by back-propagating errors. Nature 323, 533-536. doi: 10.1038/ 323533a0</p>
<p>Knowledge acquisition and design using semantics and perception: A case study for autonomous robots. C Russo, K Madani, A M Rinaldi, 10.1007/s11063-020-10311-xNeural Proces. Lett. 53Russo, C., Madani, K., and Rinaldi, A. M. (2021). Knowledge acquisition and design using semantics and perception: A case study for autonomous robots. Neural Proces. Lett. 53, 3153-3168. doi: 10.1007/s11063-020-10311-x</p>
<p>A more rational model of categorization. A Sanborn, T Griffiths, D Navarro, Lawrence ErlbaumMahwah NJSanborn, A., Griffiths, T., and Navarro, D. (2006). A more rational model of categorization. Mahwah NJ: Lawrence Erlbaum.</p>
<p>The deep learning revolution. T J Sejnowski, 10.7551/mitpress/11474.001.0001Mit PressCambridge, MASejnowski, T. J. (2018). The deep learning revolution. Cambridge, MA: Mit Press. doi: 10.7551/mitpress/11474.001.0001</p>
<p>A probabilistic model of cross-categorization. P Shafto, C Kemp, V Mansinghka, J B Tenenbaum, 10.1016/j.cognition.2011.02.010Cognition. 120Shafto, P., Kemp, C., Mansinghka, V., and Tenenbaum, J. B. (2011). A probabilistic model of cross-categorization. Cognition 120, 1-25. doi: 10.1016/j.cognition. 2011.02.010</p>
<p>Categorization by a connectionist network. D R Shanks, 10.1037/0278-7393.17.3.433J. Exp. Psychol. 17433Shanks, D. R. (1991). Categorization by a connectionist network. J. Exp. Psychol. 17:433. doi: 10.1037/0278-7393.17.3.433</p>
<p>Mathematical description of operant behavior: An introduction. R L Shull, 10.1016/B978-0-444-81251-3.50014-XTechniques in the behavioral and neural sciences. Amsterdam; BostonAuthors Cooperative6Stimulus equivalence: A research storyShull, R. L. (1991). "Mathematical description of operant behavior: An introduction, " in Techniques in the behavioral and neural sciences, Vol. 6, (Amsterdam: Elsevier), 243-282. doi: 10.1016/B978-0-444-81251-3.50014-X Sidman, M. (1994). Stimulus equivalence: A research story. Boston: Authors Cooperative.</p>
<p>Mastering the game of go without human knowledge. D Silver, J Schrittwieser, K Simonyan, I Antonoglou, A Huang, A Guez, 10.1038/nature24270Nature. 550Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., et al. (2017). Mastering the game of go without human knowledge. Nature 550, 354-359. doi: 10.1038/nature24270</p>
<p>. D Silver, S Singh, D Precup, R S Sutton, 10.1016/j.artint.2021.103535Reward is enough. Artific. Intellig. 2021103535Silver, D., Singh, S., Precup, D., and Sutton, R. S. (2021). Reward is enough. Artific. Intellig. 2021:103535. doi: 10.1016/j.artint.2021.103535</p>
<p>An operant analysis of problem solving. B F Skinner, Prob. Solv. Skinner, B. F. (1966). An operant analysis of problem solving. Prob. Solv. 1966, 225-257.</p>
<p>Hierarchical classification as relational framing. B Slattery, I Stewart, 10.1002/jeab.63J. Exp. Anal. Behav. 101Slattery, B., and Stewart, I. (2014). Hierarchical classification as relational framing. J. Exp. Anal. Behav. 101, 61-75. doi: 10.1002/jeab.63</p>
<p>Testing for transitive class containment as a feature of hierarchical classification. B Slattery, I Stewart, D Hora, 10.1901/jeab.2011.96-243J. Exp. Anal. Behav. 96Slattery, B., Stewart, I., and O'Hora, D. (2011). Testing for transitive class containment as a feature of hierarchical classification. J. Exp. Anal. Behav. 96, 243-260. doi: 10.1901/jeab.2011.96-243</p>
<p>Similarity-versus rule-based categorization. E E Smith, S A Sloman, 10.3758/BF03200864Mem. Cognit. 22Smith, E. E., and Sloman, S. A. (1994). Similarity-versus rule-based categorization. Mem. Cognit. 22, 377-386. doi: 10.3758/BF03200864</p>
<p>Alternative strategies of categorization. E E Smith, A L Patalano, Jonides , J , 10.1016/S0010-0277(97)00043-7Cognition. 65Smith, E. E., Patalano, A. L., and Jonides, J. (1998). Alternative strategies of categorization. Cognition 65, 167-196. doi: 10.1016/S0010-0277(97)00043-7</p>
<p>Semantics in cultural perspective overview. V Smith, K Florence, Maria , F , 10.37028/lingcure.v2n1.9Linguist. Cult. Rev. 2Smith, V., Florence, K., and Maria, F. (2018). Semantics in cultural perspective overview. Linguist. Cult. Rev. 2, 24-31. doi: 10.37028/lingcure.v2n1.9</p>
<p>Differential influences of gender schemata and gender constancy on children's information processing and behavior. C Stangor, D N Ruble, 10.1521/soco.1989.7.4.353Soc. Cognit. 7Stangor, C., and Ruble, D. N. (1989). Differential influences of gender schemata and gender constancy on children's information processing and behavior. Soc. Cognit. 7, 353-372. doi: 10.1521/soco.1989.7.4.353</p>
<p>Absolute identification by relative judgment. N Stewart, G D Brown, N Chater, 10.1037/0033-295X.112.4.881Psychol. Rev. 112881Stewart, N., Brown, G. D., and Chater, N. (2005). Absolute identification by relative judgment. Psychol. Rev. 112:881. doi: 10.1037/0033-295X.112.4.881</p>
<p>Artificial Intelligence: A Modern Approach. R Stuart, N Peter, Prentice HallUpper Saddle River, NJStuart, R., and Peter, N. (2020). Artificial Intelligence: A Modern Approach. Upper Saddle River, NJ: Prentice Hall.</p>
<p>The partial information decomposition of generative neural network models. T Tax, P A Mediano, M Shanahan, 10.3390/e19090474doi: 10. 3390/e19090474Entropy. 19474Tax, T., Mediano, P. A., and Shanahan, M. (2017). The partial information decomposition of generative neural network models. Entropy 19:474. doi: 10. 3390/e19090474</p>
<p>A frame-theoretic model of Bayesian category learning. S D Taylor, P R Sutton, 10.1007/978-3-030-50200-3_15Concepts, frames and cascades in semantics, cognition and ontology. ChamSpringerTaylor, S. D., and Sutton, P. R. (2021). "A frame-theoretic model of Bayesian category learning, " in Concepts, frames and cascades in semantics, cognition and ontology, (Cham: Springer), 329-349. doi: 10.1007/978-3-030-50200-3_15</p>
<p>Deep learning and the information bottleneck principle. N Tishby, N Zaslavsky, 10.1109/ITW.2015.7133169IEEE Information Theory Workshop (ITW). New Jersey, NJIEEEin Paper presented at theTishby, N., and Zaslavsky, N. (2015). "Deep learning and the information bottleneck principle, " in Paper presented at the 2015 IEEE Information Theory Workshop (ITW), (New Jersey, NJ: IEEE). doi: 10.1109/ITW.2015.7133169</p>
<p>A brief history of AI: how to prevent another winter (a critical review). A Toosi, A G Bottino, B Saboury, E Siegel, A Rahmim, 10.1016/j.cpet.2021.07.001PET clinics. 16Toosi, A., Bottino, A. G., Saboury, B., Siegel, E., and Rahmim, A. (2021). A brief history of AI: how to prevent another winter (a critical review). PET clinics 16, 449-469. doi: 10.1016/j.cpet.2021.07.001</p>
<p>Learning RFT: An introduction to relational frame theory and its clinical application. N Torneke, New Harbinger PublicationsOakland, CATorneke, N. (2010). Learning RFT: An introduction to relational frame theory and its clinical application. Oakland, CA: New Harbinger Publications.</p>
<p>Extracting refined rules from knowledgebased neural networks. G G Towell, J W Shavlik, 10.1007/BF00993103Machine Learn. 13Towell, G. G., and Shavlik, J. W. (1993). Extracting refined rules from knowledge- based neural networks. Machine Learn. 13, 71-101. doi: 10.1007/BF00993103</p>
<p>Attention in learning: Theory and research. T Trabasso, G H Bower, John Wiley and sonsNew Jersey, NJTrabasso, T., and Bower, G. H. (1968). Attention in learning: Theory and research. New Jersey, NJ: John Wiley and sons.</p>
<p>In search of abstraction: The varying abstraction model of categorization. W Vanpaemel, G Storms, 10.3758/PBR.15.4.732Psychonomic Bull. Rev. 15Vanpaemel, W., and Storms, G. (2008). In search of abstraction: The varying abstraction model of categorization. Psychonomic Bull. Rev. 15, 732-749. doi: 10.3758/PBR.15.4.732</p>
<p>A Voulodimos, N Doulamis, G Bebis, T Stathaki, 10.1155/2018/8141259Recent developments in deep learning for engineering applications. 2018Voulodimos, A., Doulamis, N., Bebis, G., and Stathaki, T. (2018). Recent developments in deep learning for engineering applications, Vol. 2018. London: Hindawi. doi: 10.1155/2018/8141259</p>
<p>An approximation of the error backpropagation algorithm in a predictive coding network with local Hebbian synaptic plasticity. J C Whittington, R Bogacz, 10.1162/NECO_a_00949Neural Computat. 29Whittington, J. C., and Bogacz, R. (2017). An approximation of the error backpropagation algorithm in a predictive coding network with local Hebbian synaptic plasticity. Neural Computat. 29, 1229-1262. doi: 10.1162/NECO_a_ 00949</p>
<p>Recent trends in deep learning based natural language processing. T Young, D Hazarika, S Poria, E Cambria, 10.1109/MCI.2018.2840738IEEE Computat. Intellig. Magazine. 13Young, T., Hazarika, D., Poria, S., and Cambria, E. (2018). Recent trends in deep learning based natural language processing. IEEE Computat. Intellig. Magazine 13, 55-75. doi: 10.1109/MCI.2018.2840738</p>
<p>Understanding convolutional neural networks with information theory: An initial exploration. S Yu, K WickstrÃ¸m, R Jenssen, J C Principe, 10.1109/TNNLS.2020.2968509IEEE Transact. Neural Netw. Learn. Syst. 32Yu, S., WickstrÃ¸m, K., Jenssen, R., and Principe, J. C. (2020). Understanding convolutional neural networks with information theory: An initial exploration. IEEE Transact. Neural Netw. Learn. Syst. 32, 435-442. doi: 10.1109/TNNLS. 2020.2968509</p>
<p>Non-representationalist cognitive science and realism. K Zahidi, 10.1007/s11097-013-9310-6Phenomenol. Cognit. Sci. 13Zahidi, K. (2014). Non-representationalist cognitive science and realism. Phenomenol. Cognit. Sci. 13, 461-475. doi: 10.1007/s11097-013-9310-6</p>
<p>Extracting Lexical Semantic Knowledge from Wikipedia and Wiktionary. T Zesch, C MÃ¼ller, I Gurevych, LREC). Marrakechin Paper presented at the LRECZesch, T., MÃ¼ller, C., and Gurevych, I. (2008). "Extracting Lexical Semantic Knowledge from Wikipedia and Wiktionary, " in Paper presented at the LREC, (Marrakech: LREC).</p>
<ol>
<li>Context dependence, " in HandbÃ¼cher zur Sprach-und Kommunikationswissenschaft/Handbooks of Linguistics and Communication Science. T E Zimmermann, 10.1515/9783110253382.2360J. Darquennes, J. C. Salmons, and W. VandenbusscheDe Gruyter MoutonBerlinZimmermann, T. E. (2012). "89. Context dependence, " in HandbÃ¼cher zur Sprach-und Kommunikationswissenschaft/Handbooks of Linguistics and Communication Science, eds J. Darquennes, J. C. Salmons, and W. Vandenbussche (Berlin: De Gruyter Mouton), 2360-2407. doi: 10.1515/9783110253382.2360</li>
</ol>            </div>
        </div>

    </div>
</body>
</html>