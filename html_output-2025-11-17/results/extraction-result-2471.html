<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2471 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2471</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2471</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-807003</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1602.04290v1.pdf" target="_blank">Designing Intelligent Instruments</a></p>
                <p><strong>Paper Abstract:</strong> Remote science operations require automated systems that can both act and react with minimal human intervention. One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take. This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning. This cycle is the basis of the Scientific Method. The three basic steps of this cycle are hypothesis generation, inquiry, and inference. Hypothesis generation is implemented by artificially supplying the instrument with a parameterized set of possible hypotheses that might be used to describe the physical system. The act of inquiry is handled by an inquiry engine that relies on Bayesian adaptive exploration where the optimal experiment is chosen as the one which maximizes the expected information gain. The inference engine is implemented using the nested sampling algorithm, which provides the inquiry engine with a set of posterior samples from which the expected information gain can be estimated. With these computational structures in place, the instrument will refine its hypotheses, and repeat the learning cycle by taking measurements until the system under study is described within a pre-specified tolerance. We will demonstrate our first attempts toward achieving this goal with an intelligent instrument constructed using the LEGO MINDSTORMS NXT robotics platform.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2471.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2471.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Intelligent Instrument (LEGO)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Adaptive Intelligent Instrument implemented on LEGO MINDSTORMS NXT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A robotic instrument that closes the loop between inference and experimental design: it infers model parameters with nested sampling and selects measurements by maximizing the expected information gain (Shannon entropy) of predicted sensor readings computed over posterior samples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian adaptive intelligent instrument (LEGO prototype)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A physical robotic arm (LEGO MINDSTORMS NXT) controlled by MATLAB that implements an inference engine (nested sampling) producing a set of posterior-weighted models (150 circle hypotheses) and an inquiry engine that evaluates candidate measurement locations by drawing predictive samples from the likelihood under each posterior sample, constructing a histogram of predicted measurement values, computing the Shannon entropy, and selecting the location that maximizes this entropy; measurement requests are executed by the robot, results returned to the laptop, posterior updated, and cycle repeated until parameter tolerances are met.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Autonomous experimental design and active sensing for spatial search/characterization tasks (demonstrated on a toy problem: locating and characterizing a white circle on a black field); generalizable to remote science, robotics, and search problems (e.g., land-mine detection).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates sensing actions (measurement locations) by computing the expected information gain (Shannon information) of each candidate measurement via the posterior predictive distribution approximated by sampling: for each posterior sample, draw a predictive likelihood for the measurement location, form an empirical distribution (histogram) of these predictive values, compute entropy, and pick the location with maximal entropy. Candidate locations are evaluated on a jittered grid to provide spatial diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Shannon information (entropy) of the predictive distribution of sensor readings at candidate measurement locations (estimated by histogram over predictive samples from posterior models).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Implicit: maximizing predictive entropy favors measurements where posterior models disagree (high uncertainty), effectively selecting binary-question-like probes that split the posterior (exploration focused on high-uncertainty regions); as posterior concentrates, selected measurements exploit boundary/edge regions to refine parameters. No explicit exploration/exploitation scheduling beyond the entropy objective.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity of hypotheses is provided implicitly by the posterior sample set (150 weighted samples from nested sampling) and by random jittering of the evaluation grid to consider varied candidate locations across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Parameter-accuracy stopping criterion (predefined tolerance on center position and radius); mentions potential for time/energy/bandwidth utility but these are not implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>The system stops taking measurements when model parameters (circle center and radius) reach predefined accuracy tolerances; no explicit optimization under time/energy/computational budgets is implemented, though the authors note such utility terms could be incorporated.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Qualitative and example numeric: simulation results show rapid convergence; example run nearly solved after 16 adaptive measurements (figures show improvement at 1, 10, 16 measurements). No formal quantitative metrics (e.g., wall-clock, FLOPs, dollars) reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Uniform/scan-based measurement strategy (scanning the scene) / non-adaptive exhaustive sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative: far fewer measurements required than an equivalent scanning system; authors state the adaptive approach dramatically reduces the number of necessary measurements but provide no precise numeric baseline comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reported as a large reduction in number of measurements compared to scanning; example run converged in O(10) measurements (e.g., 16) instead of many more required by exhaustive scans, but no percentage or multiplicative factor is given.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Limited within this paper: authors note the maximum-entropy approach is optimal under the assumption that measurement noise is independent of location and that utility functions could incorporate time/energy in future work; no explicit empirical analysis of tradeoffs between computational cost, information gain, hypothesis diversity, and breakthrough probability is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Maximizing the entropy of predicted measurements (expected information gain) yields measurement choices that act like efficient binary questions (each measurement tends to rule out roughly half of posterior models), producing rapid convergence in parameter inference; posterior sampling enables straightforward estimation of expected information for candidate experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Designing Intelligent Instruments', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2471.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2471.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian Adaptive Exploration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Adaptive Exploration (Loredo)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decision-theoretic framework for experimental design that chooses experiments by maximizing expected utility, with Shannon information (expected information gain) commonly used as the utility; the experiment selection integrates over posterior uncertainty and uses the posterior predictive distribution to evaluate candidate experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bayesian adaptive exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian adaptive exploration (method)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Methodology: compute expected utility of each candidate experiment by integrating the utility (here, information gain) over the posterior predictive distribution; select the experiment maximizing expected utility. In practice, the paper approximates expected information by sampling from the posterior and computing entropy of predictive measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General-purpose experimental design and active learning across scientific domains; instantiated here for robotic spatial measurements/characterization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate experiments by maximizing expected utility (Shannon information) computed via the posterior predictive distribution; candidate experiments are evaluated by simulating outcomes under posterior samples and computing expected information.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected information gain (mutual information) between model parameters and potential observations (Shannon information).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>The expected-information objective naturally trades exploration and exploitation by favoring experiments that reduce overall posterior uncertainty (exploration when uncertainty is broad, exploitation when uncertainty is focused); no additional mechanism (e.g., temperature, explicit exploration bonus) is described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Framework can incorporate utility terms reflecting resource costs (time, energy) but in this implementation such costs are not integrated; the decision rule is pure expected information maximization.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Conceptual: authors note utility functions other than information (including time/energy) could and should be used to capture resource tradeoffs, but no empirical tradeoff analysis is performed in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: selecting experiments that maximize expected information (posterior predictive entropy) produces efficient, often binary-question-like measurements that rapidly reduce model uncertainty; practical implementation requires posterior sampling to estimate expected information.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Designing Intelligent Instruments', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2471.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2471.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nested Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nested Sampling (Skilling)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Monte Carlo algorithm for Bayesian computation that samples from the prior subject to progressively increasing likelihood thresholds to produce posterior samples and an estimate of the model evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Nested sampling inference engine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Nested sampling is used to generate a weighted ensemble of posterior samples over circle parameters (center and radius) by iteratively sampling from the prior within a shrinking hard likelihood constraint; this yields both an approximation to the posterior (used by the inquiry engine) and an estimate of the marginal likelihood (evidence) for potential model comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Bayesian inference for model parameter estimation and evidence calculation; here used for geometric parameter estimation in an active sensing task.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Not an allocation mechanism itself; supplies posterior samples used by the inquiry engine which performs allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Nested sampling explores parameter space by maintaining live points and replacing the lowest-likelihood point with a new sample from the constrained prior; this creates a sequence favoring higher-likelihood (exploitation) regions while still sampling broadly early on (exploration).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Produces a diverse set of weighted posterior samples representing model uncertainty which the inquiry engine uses to estimate predictive distributions and entropy.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Operational finding in paper: nested sampling provides a convenient set of posterior samples for estimation of expected information and can also provide evidence estimates for model comparison (e.g., circle vs square), supporting the inquiry engine's allocation decisions; the paper does not analyze nested sampling's computational tradeoffs in detail.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Designing Intelligent Instruments', 'publication_date_yy_mm': '2016-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bayesian adaptive exploration. <em>(Rating: 2)</em></li>
                <li>Information-based objective functions for active data selection. <em>(Rating: 2)</em></li>
                <li>Maximum entropy sampling and optimal Bayesian experimental design. <em>(Rating: 2)</em></li>
                <li>On the measure of information provided by an experiment. <em>(Rating: 2)</em></li>
                <li>Theory of Optimal Experiments. <em>(Rating: 2)</em></li>
                <li>Probabilistic Robotics. <em>(Rating: 1)</em></li>
                <li>Turning ON and OFF. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2471",
    "paper_id": "paper-807003",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "Intelligent Instrument (LEGO)",
            "name_full": "Bayesian Adaptive Intelligent Instrument implemented on LEGO MINDSTORMS NXT",
            "brief_description": "A robotic instrument that closes the loop between inference and experimental design: it infers model parameters with nested sampling and selects measurements by maximizing the expected information gain (Shannon entropy) of predicted sensor readings computed over posterior samples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Bayesian adaptive intelligent instrument (LEGO prototype)",
            "system_description": "A physical robotic arm (LEGO MINDSTORMS NXT) controlled by MATLAB that implements an inference engine (nested sampling) producing a set of posterior-weighted models (150 circle hypotheses) and an inquiry engine that evaluates candidate measurement locations by drawing predictive samples from the likelihood under each posterior sample, constructing a histogram of predicted measurement values, computing the Shannon entropy, and selecting the location that maximizes this entropy; measurement requests are executed by the robot, results returned to the laptop, posterior updated, and cycle repeated until parameter tolerances are met.",
            "application_domain": "Autonomous experimental design and active sensing for spatial search/characterization tasks (demonstrated on a toy problem: locating and characterizing a white circle on a black field); generalizable to remote science, robotics, and search problems (e.g., land-mine detection).",
            "resource_allocation_strategy": "Allocates sensing actions (measurement locations) by computing the expected information gain (Shannon information) of each candidate measurement via the posterior predictive distribution approximated by sampling: for each posterior sample, draw a predictive likelihood for the measurement location, form an empirical distribution (histogram) of these predictive values, compute entropy, and pick the location with maximal entropy. Candidate locations are evaluated on a jittered grid to provide spatial diversity.",
            "computational_cost_metric": null,
            "information_gain_metric": "Shannon information (entropy) of the predictive distribution of sensor readings at candidate measurement locations (estimated by histogram over predictive samples from posterior models).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Implicit: maximizing predictive entropy favors measurements where posterior models disagree (high uncertainty), effectively selecting binary-question-like probes that split the posterior (exploration focused on high-uncertainty regions); as posterior concentrates, selected measurements exploit boundary/edge regions to refine parameters. No explicit exploration/exploitation scheduling beyond the entropy objective.",
            "diversity_mechanism": "Diversity of hypotheses is provided implicitly by the posterior sample set (150 weighted samples from nested sampling) and by random jittering of the evaluation grid to consider varied candidate locations across iterations.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Parameter-accuracy stopping criterion (predefined tolerance on center position and radius); mentions potential for time/energy/bandwidth utility but these are not implemented.",
            "budget_constraint_handling": "The system stops taking measurements when model parameters (circle center and radius) reach predefined accuracy tolerances; no explicit optimization under time/energy/computational budgets is implemented, though the authors note such utility terms could be incorporated.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Qualitative and example numeric: simulation results show rapid convergence; example run nearly solved after 16 adaptive measurements (figures show improvement at 1, 10, 16 measurements). No formal quantitative metrics (e.g., wall-clock, FLOPs, dollars) reported.",
            "comparison_baseline": "Uniform/scan-based measurement strategy (scanning the scene) / non-adaptive exhaustive sampling.",
            "performance_vs_baseline": "Qualitative: far fewer measurements required than an equivalent scanning system; authors state the adaptive approach dramatically reduces the number of necessary measurements but provide no precise numeric baseline comparison.",
            "efficiency_gain": "Reported as a large reduction in number of measurements compared to scanning; example run converged in O(10) measurements (e.g., 16) instead of many more required by exhaustive scans, but no percentage or multiplicative factor is given.",
            "tradeoff_analysis": "Limited within this paper: authors note the maximum-entropy approach is optimal under the assumption that measurement noise is independent of location and that utility functions could incorporate time/energy in future work; no explicit empirical analysis of tradeoffs between computational cost, information gain, hypothesis diversity, and breakthrough probability is provided.",
            "optimal_allocation_findings": "Maximizing the entropy of predicted measurements (expected information gain) yields measurement choices that act like efficient binary questions (each measurement tends to rule out roughly half of posterior models), producing rapid convergence in parameter inference; posterior sampling enables straightforward estimation of expected information for candidate experiments.",
            "uuid": "e2471.0",
            "source_info": {
                "paper_title": "Designing Intelligent Instruments",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "Bayesian Adaptive Exploration",
            "name_full": "Bayesian Adaptive Exploration (Loredo)",
            "brief_description": "A decision-theoretic framework for experimental design that chooses experiments by maximizing expected utility, with Shannon information (expected information gain) commonly used as the utility; the experiment selection integrates over posterior uncertainty and uses the posterior predictive distribution to evaluate candidate experiments.",
            "citation_title": "Bayesian adaptive exploration.",
            "mention_or_use": "use",
            "system_name": "Bayesian adaptive exploration (method)",
            "system_description": "Methodology: compute expected utility of each candidate experiment by integrating the utility (here, information gain) over the posterior predictive distribution; select the experiment maximizing expected utility. In practice, the paper approximates expected information by sampling from the posterior and computing entropy of predictive measurements.",
            "application_domain": "General-purpose experimental design and active learning across scientific domains; instantiated here for robotic spatial measurements/characterization.",
            "resource_allocation_strategy": "Allocate experiments by maximizing expected utility (Shannon information) computed via the posterior predictive distribution; candidate experiments are evaluated by simulating outcomes under posterior samples and computing expected information.",
            "computational_cost_metric": null,
            "information_gain_metric": "Expected information gain (mutual information) between model parameters and potential observations (Shannon information).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "The expected-information objective naturally trades exploration and exploitation by favoring experiments that reduce overall posterior uncertainty (exploration when uncertainty is broad, exploitation when uncertainty is focused); no additional mechanism (e.g., temperature, explicit exploration bonus) is described in this paper.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": "Framework can incorporate utility terms reflecting resource costs (time, energy) but in this implementation such costs are not integrated; the decision rule is pure expected information maximization.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Conceptual: authors note utility functions other than information (including time/energy) could and should be used to capture resource tradeoffs, but no empirical tradeoff analysis is performed in this work.",
            "optimal_allocation_findings": "Principle: selecting experiments that maximize expected information (posterior predictive entropy) produces efficient, often binary-question-like measurements that rapidly reduce model uncertainty; practical implementation requires posterior sampling to estimate expected information.",
            "uuid": "e2471.1",
            "source_info": {
                "paper_title": "Designing Intelligent Instruments",
                "publication_date_yy_mm": "2016-02"
            }
        },
        {
            "name_short": "Nested Sampling",
            "name_full": "Nested Sampling (Skilling)",
            "brief_description": "A Monte Carlo algorithm for Bayesian computation that samples from the prior subject to progressively increasing likelihood thresholds to produce posterior samples and an estimate of the model evidence.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Nested sampling inference engine",
            "system_description": "Nested sampling is used to generate a weighted ensemble of posterior samples over circle parameters (center and radius) by iteratively sampling from the prior within a shrinking hard likelihood constraint; this yields both an approximation to the posterior (used by the inquiry engine) and an estimate of the marginal likelihood (evidence) for potential model comparison.",
            "application_domain": "Bayesian inference for model parameter estimation and evidence calculation; here used for geometric parameter estimation in an active sensing task.",
            "resource_allocation_strategy": "Not an allocation mechanism itself; supplies posterior samples used by the inquiry engine which performs allocation.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Nested sampling explores parameter space by maintaining live points and replacing the lowest-likelihood point with a new sample from the constrained prior; this creates a sequence favoring higher-likelihood (exploitation) regions while still sampling broadly early on (exploration).",
            "diversity_mechanism": "Produces a diverse set of weighted posterior samples representing model uncertainty which the inquiry engine uses to estimate predictive distributions and entropy.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": "Operational finding in paper: nested sampling provides a convenient set of posterior samples for estimation of expected information and can also provide evidence estimates for model comparison (e.g., circle vs square), supporting the inquiry engine's allocation decisions; the paper does not analyze nested sampling's computational tradeoffs in detail.",
            "uuid": "e2471.2",
            "source_info": {
                "paper_title": "Designing Intelligent Instruments",
                "publication_date_yy_mm": "2016-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bayesian adaptive exploration.",
            "rating": 2,
            "sanitized_title": "bayesian_adaptive_exploration"
        },
        {
            "paper_title": "Information-based objective functions for active data selection.",
            "rating": 2,
            "sanitized_title": "informationbased_objective_functions_for_active_data_selection"
        },
        {
            "paper_title": "Maximum entropy sampling and optimal Bayesian experimental design.",
            "rating": 2,
            "sanitized_title": "maximum_entropy_sampling_and_optimal_bayesian_experimental_design"
        },
        {
            "paper_title": "On the measure of information provided by an experiment.",
            "rating": 2,
            "sanitized_title": "on_the_measure_of_information_provided_by_an_experiment"
        },
        {
            "paper_title": "Theory of Optimal Experiments.",
            "rating": 2,
            "sanitized_title": "theory_of_optimal_experiments"
        },
        {
            "paper_title": "Probabilistic Robotics.",
            "rating": 1,
            "sanitized_title": "probabilistic_robotics"
        },
        {
            "paper_title": "Turning ON and OFF.",
            "rating": 1,
            "sanitized_title": "turning_on_and_off"
        }
    ],
    "cost": 0.0104155,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Designing Intelligent Instruments</p>
<p>Kevin H Knuth 
Dept of Physics
Univ. at Albany
AlbanyNYUSA</p>
<p>Dept of Informatics
Univ. at Albany
AlbanyNYUSA</p>
<p>Philip M Erner 
Dept of Physics
Univ. at Albany
AlbanyNYUSA</p>
<p>Scott Frasso 
Dept. of Electrical and Computer Engineering
Northeastern Univ
BostonMAUSA</p>
<p>Designing Intelligent Instruments
2ABC3D17399E306C48912456848829E7intelligentroboticsexperimental designautomationinstrumentation
Remote science operations require automated systems that can both act and react with minimal human intervention.One such vision is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, decides which new measurements to take.This innovation implements experimental design and unites it with data analysis in such a way that it completes the cycle of learning.This cycle is the basis of the Scientific Method.The three basic steps of this cycle are hypothesis generation, inquiry, and inference.Hypothesis generation is implemented by artificially supplying the instrument with a parameterized set of possible hypotheses that might be used to describe the physical system.The act of inquiry is handled by an inquiry engine that relies on Bayesian adaptive exploration where the optimal experiment is chosen as the one which maximizes the expected information gain.The inference engine is implemented using the nested sampling algorithm, which provides the inquiry engine with a set of posterior samples from which the expected information gain can be estimated.With these computational structures in place, the instrument will refine its hypotheses, and repeat the learning cycle by taking measurements until the system under study is described within a pre-specified tolerance.We will demonstrate our first attempts toward achieving this goal with an intelligent instrument constructed using the LEGO MINDSTORMS NXT robotics platform.</p>
<p>INTRODUCTION</p>
<p>Remote science operations are currently being carried out using robotic explorers both on Mars and in deep sea studies here on Earth.These operations, which employ semiautomated systems that can carry out basic tasks such as locomotion and directed data collection, require human intervention when it comes to deciding where to go, which experiment to perform, and precisely where to place the sensors.However, as we expand to explore more remote worlds, we will require that our instruments be increasingly autonomous.The vision we present in this paper is that of an intelligent instrument that collects data in an automated fashion, and based on what it learns, the instrument decides which new measurements to take.The innovation we describe implements automated experimental design and unites the process with automated data analysis in such a way that it completes the cycle of learning.</p>
<p>Many researchers have worked on the problem of designing intelligent systems.Relevant to our approach are the concepts of cybernetics (Wiener, 1948) and experimental design (Lindley, 1956;Fedorov, 1972), which have been pursued and unified in various forms by several researchers.Of particular note is the work on cybernetics by Fry (2002), the active data selection approach of MacKay (1992), and maximum entropy sampling and Bayesian experimental design by Sebastiani and Wynn (2000).The maximum entropy sampling approach to experimental design was expounded upon by Loredo (2003) in his work on Bayesian adaptive exploration, which forms the basis of the approach we present here.</p>
<p>The first author of this paper, having been inspired by the work of Cox (1979) and Fry (2002), has been actively developing a calculus for questions (Knuth, 2002(Knuth, , 2003(Knuth, , 2005(Knuth, , 2006) ) based on bi-valuations on lattices (Knuth, 2007) with an explicit focus on experimental design.However, this framework, which is still in its infancy, is not yet suited for our efforts here.Instead, we employ proven computational technologies.</p>
<p>To create an intelligent instrument, we require three steps: hypothesis generation, experimental design, and data analysis.Hypothesis generation is implemented by programming the instrument with a parameterized model that represents a set of hypotheses that could be used to describe the physical system.Experimental design, which is an act of inquiry, is implemented using Bayesian adaptive exploration (Loredo, 2003), where the optimal experiment maximizes the expected information gain.Finally the data analysis, or inference, is handled using nested sampling FIGURE 1.A photograph of the robotic arm.The end of the arm is equipped with a light sensor that can make point measurements.The robot is built using the LEGO MINDSTORMS NXT system, and is locally controlled with the NXT brick.The NXT brick can communicate with a laptop computer using Bluetooth.The laptop computer (not shown) runs the inference and inquiry code in MATLAB.At the time of the workshop, the MATLAB to NXT communication was not completely operable, and the system was demonstrated via simulations.(Skilling, 2005;Sivia &amp; Skilling, 2006), which allows us to test various hypotheses given the newly collected data.At each stage, the instrument will refine its hypotheses and repeat the cycle taking measurements until the system is described within a prespecified tolerance.In the following sections, we describe our work in the context of a robotic arm solving a characterization problem.</p>
<p>THE EXPERIMENTAL SETUP</p>
<p>Choosing a problem that is at the same time interesting, challenging, and enlightening is extremely difficult.The problem we have chosen is indeed a toy problem, but one that is easily extended to problems encountered in the real world.We consider an instrument that is designed to locate and characterize a white circle on a black field.</p>
<p>The Experimental Problem</p>
<p>We have developed a robotic instrument that is designed to locate and characterize a white circle on a black background.The instrument is equipped with a light sensor which is able to take point measurements.We have purposely designed the system so that the sensor cannot simply scan the visual scene.Such scans result in numerous non-informative measurements that waste time, energy and transmission bandwidth.This limited sensor capability is intentional and will serve to highlight the power of the computational techniques we are developing.In addition, the light sensor has a rather large point spread function, which we will not consider in this initial presentation.Instead, we assume that the light sensor returns a measurement that is normally distributed about the mean light intensity, and ignore "edge-effects".This is clearly a search problem using an instrument with limited sensor capability.As such, the results here are readily extended to similar problems, such as land mine detection.To characterize the circle, the instrument will continue to take measurements until both the center position of the circle and its radius are known to within a predefined accuracy.Those familiar with information theory will realize that once the white circle has been detected, on average, only a small number of binary questions will be necessary to achieve this.We will show that our results agree with this expectation.</p>
<p>The Robot and its Brains</p>
<p>The instrument is a robotic arm built with the LEGO MINDSTORMS NXT system (Figure 1).The arm has three degrees of freedom, with the ability to rotate about the vertical axis (z-axis), and at two points about the y-axis (elbow and wrist).This gives the arm access to a large region of the horizontal plane.The light sensor, which is mounted at the end of the arm, is constrained to point vertically downward at all times.</p>
<p>The LEGO MINDSTORMS NXT Brick is the computer that directly controls the motors and sensors of the robot.The Brick is programmed in the NXT-G programming language, which is a variant of LabVIEW.The Brick has been programmed with a simple program that moves the arm from the home position to a position on the plane and records the light intensity.After writing the measurement result to a file, the arm returns to the home position.</p>
<p>The intelligence of the robot lives on a Dell Latitude D610 laptop computer.The software is programmed in MATLAB and operates within the Windows XP operating system.The laptop computer communicates with the robot via a Bluetooth Wireless connection to the LEGO Brick.The MATLAB software interacts with the Brick by reading files, writing files and starting programs on the Brick.To request a measurement at a specified location, the MATLAB software must compute the number of motor rotations for each motor and write these values to a file on the LEGO Brick.MATLAB then starts the motor program on the Brick, which reads this file and implements the instructions.When the robot is finished it creates a file containing the resulting light level value.The MATLAB software then reads this file to obtain the data and begin its analysis and evaluation.</p>
<p>While both the MATLAB and the Brick software are operational, we were unable to implement the MATLAB to NXT communication by the time of the workshop.Instead, our experiments were performed with the files being transferred manually.</p>
<p>INFERENCE AND INQUIRY</p>
<p>To accomplish this task in an intelligent manner, the instrument must be endowed with both an inference engine and an inquiry engine.The inference engine relies on Bayesian methods to infer the circle parameters from the acquired data.The inquiry engine relies on the posterior density over the space of circles to evaluate which measurement is expected to deliver the greatest amount of information.The following subsections describe these two engines.</p>
<p>The Inference Engine</p>
<p>We begin with the problem of using the available data to infer the circle parameters
} ), , {( r o y o x = C
(1) where ) , (
o o y x
is the circle center coordinates, and r is the circle radius.In this case, the data consist of a set of N light measurements taken at various points on a plane.We will denote these measurements collectively as D, and write them individually as
} , , , { 2 1 N d d d K = D (2) recorded at positions )} , ( , ), , ( ), , {( 2 2 1 1 N N y x y x y x K = X .(3)
In this initial exploration, the positions are assumed to be known with certainty.</p>
<p>The goal is to explore the posterior probability
) | ( ) , , | ( ) | ( ) , , | ( I p I p I p I p D X C D C X D C = ,(4)
where I represents our prior information.From this we can obtain a set of posterior samples, each representing a possible circle.We accomplish this using the nested sampling algorithm, which samples from the prior probability and explores within an ever-contracting hard likelihood constraint (Skilling, 2005;Sivia &amp; Skilling, 2006).</p>
<p>There are multiple benefits to this approach.First, the algorithm provides a set of posterior samples, which are later used by the inquiry engine to select measurement locations.Second, nested sampling produces an estimate of the evidence, which can be used in the event that the robot needs to test one model against another.A simple example of this would be if the robot is designed to identify whether the white object is a circle or a square.However, in this initial exploration, we focus only on circles.</p>
<p>Here we keep the probability assignments as simple as possible and assign uniform distributions over reasonable ranges of values
1 min max ) ( ) | (   = x x I x p o (5) 1 min max ) ( ) | (   = y y I y p o (6) 1 min max ) ( ) | (   = r r I r p . (7)
The results we present here are based on simulations on a playing field of 20cm x 30cm, so that cm 1 min = r and cm 15 max = r</p>
<p>. By assigning the prior for the center position to be independent of the prior for the radius, we are stating that the entire circle may not be in the playing field.This poses no problem for this investigation.</p>
<p>The likelihood function is again greatly simplified for these simulations.We do not consider the point-spread function of the light sensor and instead assume that the sensor will record the light intensity directly below the sensor with some Gaussian noise.The likelihood for one measurement i d taken at ) , (
i i o o i i i i  C . (8)      &gt;  +    +  = 2 2 2 2 2 2 ) ( ) ( if ) , ( ) ( ) ( if ) , ( r y y x x d N r y y x x d N o i o i B o i o i W   where ) , (   N
represents a Normal distribution with standard deviation , W d is the expected value of a light measurement on the white circle, and B d is the expected value of a light measurement on the black background.Clearly, this can be made more accurate by working with the point-spread function, however, our aim here is to tie the inference engine to the inquiry engine in real-time.</p>
<p>The nested sampling algorithm samples circles with centers uniformly distributed across the field, and radii uniformly distributed from 1cm to 15cm.The result is a set of weighted samples from which the mean and the variance of the circle parameters can be estimated.From this set of weighted samples, we obtain a set of 150 circles distributed according to the posterior probability.</p>
<p>The Inquiry Engine</p>
<p>This set of 150 circles is then used to examine the space of all possible measurements.This space is the set of locations in the field where the instrument can measure the light intensity.Each one of these possible measurements is a candidate experiment, so that choosing a measurement location is equivalent to designing an experiment.We will show that the fact that these circles are representative of the posterior probability simplifies the necessary computations.However, first we revisit the theory behind Bayesian adaptive estimation (Loredo, 2003).</p>
<p>Consider a proposed experiment E, which corresponds to taking a measurement at position ) , (
  . (10)
This can be simplified by observing that, if we knew the circle parameters C, we would not need the data D ) ),</p>
<p>Probability theory only takes us so far.In this problem, we wish to make a decision, and this requires us to maximize the expected utility according to an assigned utility function: U(outcome, action), so that
)) , (, ( ) ), , ( , | ( ) ,
where the location ) , ( e e y x is indicative of the action and the measurement e d is the outcome.Here we use a utility function based on the information provided by the measurement, so that we will choose the measurement that provides the greatest expected gain in information.Of course, other utility functions could be used that depend on the time it takes for the measurement to be taken, the energy required, etc. Utility functions such as these will surely be important in a fully-functioning automated instrument.Using the Shannon information for our utility function we find By writing the joint entropy for C and e d , and writing the integral two ways, one can show (Loredo, 2003) that the optimal experiment can be found by maximizing the entropy of the possible measurements This entropy can be easily estimated using the ensemble of models sampled from the posterior.For each measurement position ) , ( e e y x , we sample from the likelihood function of each sampled model thereby obtaining a set of potential measurements.The entropy of this set is rapidly estimated by constructing a histogram and computing the entropy directly.To enable the robot to consider a variety of positions, at each step we consider a grid on the space of possible measurements and compute the entropy only at the grid points.The alignment of this grid is randomly jittered so that a greater variety of points can be considered during the course of the experiment.With the optimal measurement position identified, the MATLAB software requests this particular measurement from the robotic instrument.Once the measurement is collected, the inference is updated, and the process is repeated until the system has estimated the model parameters with the desired accuracy.</p>
<p>RESULTS</p>
<p>At this point, we are still working on obtaining a fully-functioning Bluetooth connection between the laptop computer running MATLAB and the NXT Brick.While we have tested the system by manually transmitting the information between the laptop and NXT Brick via a USB connection, in this presentation, we have simulated the process entirely in MATLAB.The result we present here is typical and dramatically demonstrates that the number of measurements required by an intelligent instrument is much smaller than a similar scanning system.</p>
<p>Figure 2A shows the initial stages of the inference-inquiry procedure where the white area of the circle has not yet been located.For this reason, there are large regions of the measurement space that are potentially equally informative.These are indicated by the large regions of essentially equal entropy in Figure 2B.</p>
<p>After several iterations, the robot finds a white area belonging to the circle.The set of sampled models are now close to the true circle (Figure 2C).The entropy map (Figure 2D) shows that the optimal measurement locations are those that are in the region where the models do not agree.This procedure naturally selects a binary question that at each stage rules out half of the models, which results in an extremely rapid convergence dramatically reducing the number of necessary measurements.</p>
<p>CONCLUSION</p>
<p>This work constitutes an initial investigation into designing an intelligent instrument, which not only makes inferences from data, but also decides which measurements to take based on what the instrument has learned.The approach we have employed here relies on Bayesian adaptive exploration, which selects a measurement based on maximizing the entropy of the possible measurements obtained by querying a set of models sampled from the posterior.The results of this initial investigation reduces nicely to viewing the inquiry process as selecting efficient binary questions, which is known to be optimal from an information-theoretic perspective.It should be noted that these binary questions are not hard-wired into the system.</p>
<p>FIGURE 2 .
2
FIGURE 2. The panels on the left show the black playing field with the white circle.Overlaid on this are the set of 150 circles sampled from the posterior.Crosses indicate past measurement positions.The panels on the right show coarse entropy maps where the lighter shades indicate higher entropy.(A) One measurement has been taken (at the edge of the circles in upper right).This measurement has resulted in a set of hypothesized circles sampled from the posterior.(B) Much of the field is still unexplored indicated by the vast region of high entropy.The optimal measurement location is indicated by the dot with two arrows.(C) After 10 measurements, the algorithm is getting close to a solution.(D) Note that the region of high entropy is the region covered by the sampled circles.The chosen location divides the models into two.It will rule out half of the models with an efficient binary question.(E) After 16 measurements, the solution is almost obtained.(F) The corresponding entropy map is now focused on measurements at the edge of the circle.</p>
<p>Instead, they result as a natural application of maximizing the entropy of the potential measurement values given the model, the previous data, and our prior information.This maximum entropy approximation works as long as the noise level, described by the likelihood function, is independent of the sampling location(Loredo, 2003).This condition will not always hold, and must be considered in future efforts.Related maximum entropy techniques are finding their way into robotics(Thrun et al., 2005)and promise to enable these automated systems to interact with their environments in an intelligent manner.By creating joint environment-system models, the act of calibration becomes another potential experiment.In such a system, the instrument can decide to interact with the environment via measurement or itself via calibration giving rise to an instrument that actively self-calibrates during an experiment.Such advances are only the beginning.
Of inference and inquiry. R T Cox, The Maximum Entropy Formalism. R D Levine, M Tribus, CambridgeMIT Press1979</p>
<p>Theory of Optimal Experiments. V V Fedorov, 1972AcademicNew York</p>
<p>The engineering of cybernetic systems. R L Fry, Bayesian Inference and Maximum Entropy Methods in Science and Engineering. R L Fry, Baltimore MD, USA; Melville NYAIP2002617</p>
<p>What is a question?. K H Knuth, ID 2002Bayesian Inference and Maximum Entropy Methods in Science and Engineering. C Williams, Moscow; Melville NYAIP2002659</p>
<p>Intelligent machines in the 21st century: Automating the processes of inference and inquiry. K H Knuth, Phil. Trans. Roy. Soc. Lond. A, Triennial Issue. 3612003. 1813</p>
<p>Lattice duality: The origin of probability and entropy. K H Knuth, Neurocomputing. 672005</p>
<p>Valuations on lattices and their application to information theory. K H Knuth, Proceedings of the 2006 IEEE World Congress on Computational Intelligence (IEEE WCCI 2006. the 2006 IEEE World Congress on Computational Intelligence (IEEE WCCI 2006Vancouver, BC, Canada2006. July 2006Invited paper</p>
<p>Lattice Theory, Measures and Probability. K H Knuth, Bayesian Inference and Maximum Entropy Methods in Science and Engineering. K H Knuth, A Caticha, J Center, A Giffin, C C Rodrguez, Saratoga Springs NY USA; Melville NYAIP, In Press2007</p>
<p>On the measure of information provided by an experiment. D V Lindley, Ann. Math. Statist. 271956</p>
<p>Bayesian adaptive exploration. T J Loredo, Bayesian Inference and Maximum Entropy Methods in Science and Engineering. G J Erickson, Y Zhai, Jackson Hole WY, USA; Melville NYAIP2003707</p>
<p>Information-based objective functions for active data selection. D J C Mackay, Neural Computation. 441992</p>
<p>Maximum entropy sampling and optimal Bayesian experimental design. P Sebastiani, H P Wynn, J. Roy. Stat. Soc. B. 622000</p>
<p>. D S Sivia, J Skilling, Data Analysis A Bayesian Tutorial. 2006Oxford Univ. Press2nd Edition</p>
<p>Turning ON and OFF. J Skilling, Bayesian inference and Maximum Entropy Methods in Science and Engineering. K H Knuth, A E Abbas, R D Morris, J P Castle, San Jose, California, USA; Melville NYAIP2005803</p>
<p>Probabilistic Robotics. S Thrun, W Burgard, D Fox, 2005MIT PressCambridge</p>
<p>Cybernetics or Control and Communication in the Animal and the Machine. N Wiener, 1948MIT PressCambridge</p>            </div>
        </div>

    </div>
</body>
</html>