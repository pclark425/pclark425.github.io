<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1991 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1991</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1991</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-280148473</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2507.04034v1.pdf" target="_blank">Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving</a></p>
                <p><strong>Paper Abstract:</strong> While Large Language Models (LLMs) have demonstrated impressive abilities across various domains, they still struggle with complex problems characterized by multi-objective optimization, precise constraint satisfaction, immense solution spaces, etc. To address the limitation, drawing on the superior semantic understanding ability of LLMs and also the outstanding global search and optimization capability of genetic algorithms, we propose to capitalize on their respective strengths and introduce Lyria, a general LLM-driven genetic algorithm framework, comprising 7 essential components. Through conducting extensive experiments with 4 LLMs across 3 types of problems, we demonstrated the efficacy of Lyria. Additionally, with 7 additional ablation experiments, we further systematically analyzed and elucidated the factors that affect its performance.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1991.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1991.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lyria</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid GA framework that uses off-the-shelf LLMs as crossover/mutation/evaluation/error-detection operators (LLM-based operators) and alternates them with external (domain-specific, traditional) operators; evaluated on Sudoku, Graph Coloring, and TSP showing consistent gains over direct prompting and best-of-N sampling baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Lyria</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (LLM-based operators alternated with external/traditional operators)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM-based operators: LLM-based Crossover (LCO) and LLM-based Mutation (LMO) are prompt-driven uses of pretrained LLMs (GPT-4o-Mini, Qwen2.5:32B-Instruct, Qwen2.5:7B-Instruct, Mistral:7B-Instruct) that are given parent candidates plus error information (from the Error Detector) and asked to produce offspring or mutations; LLM-based Error Detector (ED) and LLM-based Fitness Evaluator (FE) are similarly prompt-driven. External operators (ECO/EMO) are hand-designed, domain-specific procedures (e.g., rule-based swapping, conflict resolution, route splicing) implemented programmatically and selected according to configurable external rates (ξ, µ). The framework alternates LLM-based and external operators controlled by external-crossover/mutation rates and uses an Experience Pool, Deduplicator, and Oracle/LLM fitness evaluators.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Combinatorial optimization: Sudoku (9x9, 50 instances), Graph Coloring (9 vertices, k=3, 50 instances), Traveling Salesman Problem (10 cities, Euclidean, 50 instances)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct Prompting (DP), Best-of-N Direct Prompting (BoN) with equalized number of LLM samples; internal ablations comparing LCO/LMO (LLM-based) vs ECO/EMO (external) via external rates ξ and µ</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Lyria (uses LLM-based operators as part of the hybrid) overall: averaged across models and problems, Lyria shows +7% and +5% on correctness and +35% and +7% on penalized score versus DP and BoN respectively. Example per-model/problem: GPT-4o-Mini GC P S improved 24% over DP and 11% over BoN; Qwen2.5:32B-Instruct showed SK CR improvements of 32% (vs DP) and 24% (vs BoN) and SK P S improvements of 56% (vs DP) and 11% (vs BoN). Aggregated: SK CR +10%/+7% and SK P S +34%/+6% (vs DP/BoN); GC P S +40%/+10%; TSP CR +10%/+7% and TSP P S +32%/+5%. (metrics are percentages where applicable)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td>Reported: hybrid configurations explored via external rates (ξ, µ). Example: For Graph Coloring, increasing ξ and µ (i.e., more use of external operators) raised GC P S from 91 to 97 (+6%). For Sudoku, raising external rates produced a 6% performance drop. For TSP, no significant change. (metrics are penalized score percentages)</td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Diversity controlled via Deduplicator (max dedup attempts τ) and Experience Pool replay rate ρ; no explicit numerical novelty/diversity metrics reported beyond deduplication behavior</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>Discussion: LLM-based Error Detector may hallucinate (i.e., produce unreliable error reports) compared to deterministic verifier-based EDs; no systematic training-data-bias experiments reported. Oracle FE vs LLM FE ablation shows large gap (Oracle FE penalized score 84 vs Qwen2.5:7B-Instruct 51 and GPT-4o-Mini 50), indicating LLM evaluators are weaker and potentially biased or insufficient for evaluation without external verification.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>Qualitative and quantitative notes: Lyria requires substantially more LLM queries leading to longer runtime and higher monetary cost; sampling count L is given analytically: L = n_p + n_p * η * (1 - ξ) + n_p * κ * (1 - µ) * n_g. Example numeric: for n_p=30, n_g=15, η=0.7, ξ=0.3, κ=0.3, µ=0.3, L = 345 samples. Paper flags cost and latency as an important limitation but does not provide wall-clock runtimes or monetary cost comparisons versus traditional operators.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td>Compared multiple off-the-shelf LLMs (GPT-4o-Mini, Qwen2.5:32B, Qwen2.5:7B, Mistral:7B). Observations: smaller LLMs (Qwen2.5:7B) still benefit from Lyria (e.g., GC P S +22%/+11%, TSP P S +61%/+7% vs DP/BoN in examples), but Oracle FE outperforms LLM-based FE by a large margin. No controlled study of domain-specific pretraining versus general pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Seven ablations performed: (1) scaling population/generations: Lyria scales better than BoN (BoN shows diminishing returns while Lyria increases gap as n_p,n_g grow); (2) Oracle FE vs LLM FE: Oracle FE dramatically better (84 vs ~50s penalized score); (3) ED/EP/DD: increasing max detected errors ϵ improves SK/GC modestly (SK +4%, GC +7%), Experience Pool replay rate ρ shows non-monotonic behavior (SK best at ρ=0.3); Deduplicator τ had little effect in these large search spaces; (4) ECO/EMO rates: external operator usage helped GC (+6%) but hurt SK (-6%) and had negligible effect for TSP; (5) others summarized in paper. Key finding: component design and rates materially affect whether external (traditional) operators help or harm.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>LLM-based operators adapt via prompt conditioning on candidate errors (ED output), fitness and Experience Pool contents; there is no online fine-tuning or gradient-based updating of LLM weights reported—adaptation is achieved by providing evolving context to the LLM prompts (i.e., prompt-adaptation but not model training).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Identified failure modes: (1) LLM-based evaluators/EDs can hallucinate and are weaker than deterministic verifiers (large Oracle vs LLM FE gap); (2) poorly designed external operators (ECO/EMO) can inject low-quality individuals and degrade performance (SK drop when ξ,µ increased); (3) computational cost/latency due to many LLM queries limits real-time / low-budget applicability; (4) when Experience Pool replay rate is too high it can cause premature convergence; (5) deduplicator may be ineffective in very large search spaces but necessary in small ones.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>LLM-based operators (as part of a hybrid GA) can substantially improve solution quality over static prompting and large-sample selection (BoN) because they supply informed, semantic-guided recombination/mutation (via prompts and error contexts) that helps escape local optima; however, gains depend strongly on component quality (especially the external operators and evaluator), hybridization rates, and problem domain—external hand-designed operators can further help if high-quality heuristics/constraints are encoded, but can also harm if poor; computational cost is a major trade-off; prompt-based LLM operators adapt via error-conditioned prompting rather than parameter updates, so their generalization depends on pretraining knowledge and prompt engineering rather than in-framework learning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1991.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1991.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hemberg2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Evolving code with a large language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work demonstrating replacement of traditional genetic programming operators with LLM-based operators to evolve code, showing feasibility of LLMs as evolutionary operators in GP contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evolving code with a large language model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hemberg et al. LLM-driven operators (as reported)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based operators replacing traditional GP operators</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Reported approach replaces traditional GP operators (crossover/mutation) with LLM-driven code edits and recombination; details not provided in this paper beyond citation.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Code evolution / genetic programming for code (as cited in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Traditional GP operators (implied by statement that they 'replace' GP operators)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Cited as demonstration that LLM-based operators can replace traditional GP operators; paper does not report details here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1991.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1991.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EVOPROMPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EVOPROMPT: Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An evolutionary algorithm that optimizes discrete prompts by leveraging LLMs, cited as prior work showing synergy between LLMs and evolutionary search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Connecting large language models with evolutionary algorithms yields powerful prompt optimizers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EVOPROMPT</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (evolutionary optimization over prompts used by LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>An EA framework that evolves discrete prompts and uses LLM evaluations to guide search; exact operator/training details not given in this paper (cited for context).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Prompt generation/optimization across LLM tasks (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Cited as evidence that combining EA and LLMs can outperform prior prompt generation methods; no direct operator-to-operator GP comparisons in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1991.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1991.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Morris2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM guided evolution - the automation of models advancing models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework where LLMs autonomously evolve neural network architectures by generating/modifying code guided by feedback (Evolution of Thought and Character Role Play).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLM guided evolution -the automation of models advancing models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Morris et al. framework</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based code-modification operators within an evolutionary loop</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM produces code modifications for neural architectures driven by feedback; treated as an evolution-of-architectures approach integrating LLM capabilities and evolutionary selection.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Neural architecture search / evolving neural network architectures</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Cited as another example of leveraging LLMs to perform operator-like roles in evolutionary systems, particularly for evolving model designs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1991.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1991.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMatic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMatic: Neural architecture search via large language models and quality diversity optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method integrating LLM code-generation abilities with Quality-Diversity evolutionary algorithms to discover network architectures efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llmatic: Neural architecture search via large language models and quality diversity optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLMatic</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-driven generation + Quality-Diversity evolutionary operators (hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM used to generate/modify neural architectures; combined with QD evolutionary search; paper only cited in related work—no experimental detail in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Neural architecture search</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Cited to show related LLM+EA approaches for architecture search; no direct experimental comparisons included here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1991.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1991.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pinna2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Improvement combined with LLMs for code generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work combining LLMs and genetic improvement techniques to improve code generation; cited as related work on LLM+GP-style integration for program improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing large language models-based code generation by leveraging genetic improvement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Improvement + LLM</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (genetic improvement operators applied together with LLM-generated code)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Combines genetic improvement methods (search/repair) with LLM code-generation capabilities; cited but details not reproduced in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Code generation / program improvement</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Cited as further corroboration that LLMs can be combined with genetic improvement techniques; no experimental detail present in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Evolving code with a large language model <em>(Rating: 2)</em></li>
                <li>Connecting large language models with evolutionary algorithms yields powerful prompt optimizers <em>(Rating: 2)</em></li>
                <li>LLM guided evolution -the automation of models advancing models <em>(Rating: 2)</em></li>
                <li>Llmatic: Neural architecture search via large language models and quality diversity optimization <em>(Rating: 2)</em></li>
                <li>Enhancing large language models-based code generation by leveraging genetic improvement <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1991",
    "paper_id": "paper-280148473",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "Lyria",
            "name_full": "Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving",
            "brief_description": "A hybrid GA framework that uses off-the-shelf LLMs as crossover/mutation/evaluation/error-detection operators (LLM-based operators) and alternates them with external (domain-specific, traditional) operators; evaluated on Sudoku, Graph Coloring, and TSP showing consistent gains over direct prompting and best-of-N sampling baselines.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Lyria",
            "operator_type": "hybrid (LLM-based operators alternated with external/traditional operators)",
            "operator_description": "LLM-based operators: LLM-based Crossover (LCO) and LLM-based Mutation (LMO) are prompt-driven uses of pretrained LLMs (GPT-4o-Mini, Qwen2.5:32B-Instruct, Qwen2.5:7B-Instruct, Mistral:7B-Instruct) that are given parent candidates plus error information (from the Error Detector) and asked to produce offspring or mutations; LLM-based Error Detector (ED) and LLM-based Fitness Evaluator (FE) are similarly prompt-driven. External operators (ECO/EMO) are hand-designed, domain-specific procedures (e.g., rule-based swapping, conflict resolution, route splicing) implemented programmatically and selected according to configurable external rates (ξ, µ). The framework alternates LLM-based and external operators controlled by external-crossover/mutation rates and uses an Experience Pool, Deduplicator, and Oracle/LLM fitness evaluators.",
            "training_data_description": null,
            "domain_or_benchmark": "Combinatorial optimization: Sudoku (9x9, 50 instances), Graph Coloring (9 vertices, k=3, 50 instances), Traveling Salesman Problem (10 cities, Euclidean, 50 instances)",
            "comparison_baseline": "Direct Prompting (DP), Best-of-N Direct Prompting (BoN) with equalized number of LLM samples; internal ablations comparing LCO/LMO (LLM-based) vs ECO/EMO (external) via external rates ξ and µ",
            "performance_learned_operator": "Lyria (uses LLM-based operators as part of the hybrid) overall: averaged across models and problems, Lyria shows +7% and +5% on correctness and +35% and +7% on penalized score versus DP and BoN respectively. Example per-model/problem: GPT-4o-Mini GC P S improved 24% over DP and 11% over BoN; Qwen2.5:32B-Instruct showed SK CR improvements of 32% (vs DP) and 24% (vs BoN) and SK P S improvements of 56% (vs DP) and 11% (vs BoN). Aggregated: SK CR +10%/+7% and SK P S +34%/+6% (vs DP/BoN); GC P S +40%/+10%; TSP CR +10%/+7% and TSP P S +32%/+5%. (metrics are percentages where applicable)",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": "Reported: hybrid configurations explored via external rates (ξ, µ). Example: For Graph Coloring, increasing ξ and µ (i.e., more use of external operators) raised GC P S from 91 to 97 (+6%). For Sudoku, raising external rates produced a 6% performance drop. For TSP, no significant change. (metrics are penalized score percentages)",
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Diversity controlled via Deduplicator (max dedup attempts τ) and Experience Pool replay rate ρ; no explicit numerical novelty/diversity metrics reported beyond deduplication behavior",
            "out_of_distribution_performance": null,
            "training_bias_evidence": "Discussion: LLM-based Error Detector may hallucinate (i.e., produce unreliable error reports) compared to deterministic verifier-based EDs; no systematic training-data-bias experiments reported. Oracle FE vs LLM FE ablation shows large gap (Oracle FE penalized score 84 vs Qwen2.5:7B-Instruct 51 and GPT-4o-Mini 50), indicating LLM evaluators are weaker and potentially biased or insufficient for evaluation without external verification.",
            "computational_cost_comparison": "Qualitative and quantitative notes: Lyria requires substantially more LLM queries leading to longer runtime and higher monetary cost; sampling count L is given analytically: L = n_p + n_p * η * (1 - ξ) + n_p * κ * (1 - µ) * n_g. Example numeric: for n_p=30, n_g=15, η=0.7, ξ=0.3, κ=0.3, µ=0.3, L = 345 samples. Paper flags cost and latency as an important limitation but does not provide wall-clock runtimes or monetary cost comparisons versus traditional operators.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": "Compared multiple off-the-shelf LLMs (GPT-4o-Mini, Qwen2.5:32B, Qwen2.5:7B, Mistral:7B). Observations: smaller LLMs (Qwen2.5:7B) still benefit from Lyria (e.g., GC P S +22%/+11%, TSP P S +61%/+7% vs DP/BoN in examples), but Oracle FE outperforms LLM-based FE by a large margin. No controlled study of domain-specific pretraining versus general pretraining.",
            "ablation_study_results": "Seven ablations performed: (1) scaling population/generations: Lyria scales better than BoN (BoN shows diminishing returns while Lyria increases gap as n_p,n_g grow); (2) Oracle FE vs LLM FE: Oracle FE dramatically better (84 vs ~50s penalized score); (3) ED/EP/DD: increasing max detected errors ϵ improves SK/GC modestly (SK +4%, GC +7%), Experience Pool replay rate ρ shows non-monotonic behavior (SK best at ρ=0.3); Deduplicator τ had little effect in these large search spaces; (4) ECO/EMO rates: external operator usage helped GC (+6%) but hurt SK (-6%) and had negligible effect for TSP; (5) others summarized in paper. Key finding: component design and rates materially affect whether external (traditional) operators help or harm.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "LLM-based operators adapt via prompt conditioning on candidate errors (ED output), fitness and Experience Pool contents; there is no online fine-tuning or gradient-based updating of LLM weights reported—adaptation is achieved by providing evolving context to the LLM prompts (i.e., prompt-adaptation but not model training).",
            "failure_modes": "Identified failure modes: (1) LLM-based evaluators/EDs can hallucinate and are weaker than deterministic verifiers (large Oracle vs LLM FE gap); (2) poorly designed external operators (ECO/EMO) can inject low-quality individuals and degrade performance (SK drop when ξ,µ increased); (3) computational cost/latency due to many LLM queries limits real-time / low-budget applicability; (4) when Experience Pool replay rate is too high it can cause premature convergence; (5) deduplicator may be ineffective in very large search spaces but necessary in small ones.",
            "key_findings_for_theory": "LLM-based operators (as part of a hybrid GA) can substantially improve solution quality over static prompting and large-sample selection (BoN) because they supply informed, semantic-guided recombination/mutation (via prompts and error contexts) that helps escape local optima; however, gains depend strongly on component quality (especially the external operators and evaluator), hybridization rates, and problem domain—external hand-designed operators can further help if high-quality heuristics/constraints are encoded, but can also harm if poor; computational cost is a major trade-off; prompt-based LLM operators adapt via error-conditioned prompting rather than parameter updates, so their generalization depends on pretraining knowledge and prompt engineering rather than in-framework learning.",
            "uuid": "e1991.0"
        },
        {
            "name_short": "Hemberg2024",
            "name_full": "Evolving code with a large language model",
            "brief_description": "Prior work demonstrating replacement of traditional genetic programming operators with LLM-based operators to evolve code, showing feasibility of LLMs as evolutionary operators in GP contexts.",
            "citation_title": "Evolving code with a large language model",
            "mention_or_use": "mention",
            "system_name": "Hemberg et al. LLM-driven operators (as reported)",
            "operator_type": "LLM-based operators replacing traditional GP operators",
            "operator_description": "Reported approach replaces traditional GP operators (crossover/mutation) with LLM-driven code edits and recombination; details not provided in this paper beyond citation.",
            "training_data_description": null,
            "domain_or_benchmark": "Code evolution / genetic programming for code (as cited in related work)",
            "comparison_baseline": "Traditional GP operators (implied by statement that they 'replace' GP operators)",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Cited as demonstration that LLM-based operators can replace traditional GP operators; paper does not report details here.",
            "uuid": "e1991.1"
        },
        {
            "name_short": "EVOPROMPT",
            "name_full": "EVOPROMPT: Connecting large language models with evolutionary algorithms yields powerful prompt optimizers",
            "brief_description": "An evolutionary algorithm that optimizes discrete prompts by leveraging LLMs, cited as prior work showing synergy between LLMs and evolutionary search.",
            "citation_title": "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers",
            "mention_or_use": "mention",
            "system_name": "EVOPROMPT",
            "operator_type": "hybrid (evolutionary optimization over prompts used by LLMs)",
            "operator_description": "An EA framework that evolves discrete prompts and uses LLM evaluations to guide search; exact operator/training details not given in this paper (cited for context).",
            "training_data_description": null,
            "domain_or_benchmark": "Prompt generation/optimization across LLM tasks (as cited)",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Cited as evidence that combining EA and LLMs can outperform prior prompt generation methods; no direct operator-to-operator GP comparisons in this paper.",
            "uuid": "e1991.2"
        },
        {
            "name_short": "Morris2024",
            "name_full": "LLM guided evolution - the automation of models advancing models",
            "brief_description": "A framework where LLMs autonomously evolve neural network architectures by generating/modifying code guided by feedback (Evolution of Thought and Character Role Play).",
            "citation_title": "LLM guided evolution -the automation of models advancing models",
            "mention_or_use": "mention",
            "system_name": "Morris et al. framework",
            "operator_type": "LLM-based code-modification operators within an evolutionary loop",
            "operator_description": "LLM produces code modifications for neural architectures driven by feedback; treated as an evolution-of-architectures approach integrating LLM capabilities and evolutionary selection.",
            "training_data_description": null,
            "domain_or_benchmark": "Neural architecture search / evolving neural network architectures",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Cited as another example of leveraging LLMs to perform operator-like roles in evolutionary systems, particularly for evolving model designs.",
            "uuid": "e1991.3"
        },
        {
            "name_short": "LLMatic",
            "name_full": "LLMatic: Neural architecture search via large language models and quality diversity optimization",
            "brief_description": "A method integrating LLM code-generation abilities with Quality-Diversity evolutionary algorithms to discover network architectures efficiently.",
            "citation_title": "Llmatic: Neural architecture search via large language models and quality diversity optimization",
            "mention_or_use": "mention",
            "system_name": "LLMatic",
            "operator_type": "LLM-driven generation + Quality-Diversity evolutionary operators (hybrid)",
            "operator_description": "LLM used to generate/modify neural architectures; combined with QD evolutionary search; paper only cited in related work—no experimental detail in this paper.",
            "training_data_description": null,
            "domain_or_benchmark": "Neural architecture search",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Cited to show related LLM+EA approaches for architecture search; no direct experimental comparisons included here.",
            "uuid": "e1991.4"
        },
        {
            "name_short": "Pinna2024",
            "name_full": "Genetic Improvement combined with LLMs for code generation",
            "brief_description": "Work combining LLMs and genetic improvement techniques to improve code generation; cited as related work on LLM+GP-style integration for program improvement.",
            "citation_title": "Enhancing large language models-based code generation by leveraging genetic improvement",
            "mention_or_use": "mention",
            "system_name": "Genetic Improvement + LLM",
            "operator_type": "hybrid (genetic improvement operators applied together with LLM-generated code)",
            "operator_description": "Combines genetic improvement methods (search/repair) with LLM code-generation capabilities; cited but details not reproduced in this paper.",
            "training_data_description": null,
            "domain_or_benchmark": "Code generation / program improvement",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "Cited as further corroboration that LLMs can be combined with genetic improvement techniques; no experimental detail present in this paper.",
            "uuid": "e1991.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Evolving code with a large language model",
            "rating": 2
        },
        {
            "paper_title": "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers",
            "rating": 2
        },
        {
            "paper_title": "LLM guided evolution -the automation of models advancing models",
            "rating": 2
        },
        {
            "paper_title": "Llmatic: Neural architecture search via large language models and quality diversity optimization",
            "rating": 2
        },
        {
            "paper_title": "Enhancing large language models-based code generation by leveraging genetic improvement",
            "rating": 1
        }
    ],
    "cost": 0.01800375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving
5 Jul 2025</p>
<p>Weizhi Tang weizhi.tang@ed.ac.uk 
University of Edinburgh</p>
<p>Kwabena Nuamah k.nuamah@ed.ac.uk 
University of Edinburgh</p>
<p>Vaishak Belle vbelle@ed.ac.uk 
University of Edinburgh</p>
<p>Lyria: A General LLM-Driven Genetic Algorithm Framework for Problem Solving
5 Jul 2025F12ACAEE11CB729AB662ECD84D30DDE1arXiv:2507.04034v1[cs.AI]
While Large Language Models (LLMs) have demonstrated impressive abilities across various domains, they still struggle with complex problems characterized by multi-objective optimization, precise constraint satisfaction, immense solution spaces, etc.To address the limitation, drawing on the superior semantic understanding ability of LLMs and also the outstanding global search and optimization capability of genetic algorithms, we propose to capitalize on their respective strengths and introduce Lyria, a general LLM-driven genetic algorithm framework, comprising 7 essential components.Through conducting extensive experiments with 4 LLMs across 3 types of problems, we demonstrated the efficacy of Lyria.Additionally, with 7 additional ablation experiments, we further systematically analyzed and elucidated the factors that affect its performance 1 .Data GenerationWe fixed the number of unfilled cells to 40 in each puzzle, generating a total of 50 distinct 9 × 9 SK instances.Metrics We evaluate SK solutions using 3 metrics, namely Correctness, Score, and Penalized Score.Correctness checks whether a solution satisfies all row, column, and sub-grid constraints, with the correct percentage across all solutions reported as SK CR .Score calculates the proportion of valid rows, columns, and subgrids in a solution and averages these three values, with higher scores indicating fewer errors.Since Score can be skewed by extremes, Penalized Score takes the geometric mean of those three proportions, dampening</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) have demonstrated versatile abilities across various domains and tasks, benefiting from the large-scale corpora they are trained on (Jiang et al., 2024;Valmeekam et al., 2023;Pan et al., 2023;Tang and Belle, 2024).Nevertheless, their performance remains inferior, especially when faced with complex problems, characterized by their immense solution spaces, precise constraint satisfaction, multi-objective optimization, and domain-specific prior knowledge, such as reasoning (Mittal et al., 2025), planning (Valmeekam et al., 2023), theorem proving (Song et al., 2025), code generation (Jiang et al., 2024), and etc.</p>
<p>Genetic algorithms, a subset of evolutionary algorithms inspired by natural selection, powered by their essential operators such as selection, crossover, and mutation, are commonly used to 1 Our code is available at https://github.com/RutaTang/Lyria.approach optimal solution by iteratively optimizing the population through generations (Katoch et al., 2021;Gen, 2019;Koza, 1994).They have been studied and applied across diverse fields, such as reasoning (Hameed et al., 2023;Schäfer and Schulz, 2015;Tamaddoni-Nezhad and Muggleton, 2001), planning (Burns et al., 2024;Elshamli et al., 2004), combinatorial optimization (Shao et al., 2023;Kobler, 2009), and symbolic regression (Bertschinger et al., 2024;Ashok et al., 2020), primarily due to their ability to escape local optima, conduct systematical searches, and flexibly integrate domain-specific knowledge, thereby enabling them to approach global optimal solutions (Katoch et al., 2021).</p>
<p>Leveraging the semantic understanding and extensive prior knowledge acquired by LLMs from large-scale corpora (Minaee et al., 2025;Tang et al., 2023), as well as the capacity of genetic algorithm to continuously optimize solutions within immense search spaces (Katoch et al., 2021;Gen, 2019), we propose to integrate them to capitalize on their respective strengths.Therefore, we introduce a general framework called Lyria, consisting of 7 essential components as illustrated in Figure 1, aiming to enhance the ability of LLMs to tackle complex problems.To evaluate its effectiveness, we conducted experiments using 4 LLMs on 3 NP problems against 2 baselines, demonstrating its significant performance improvements.We also executed 7 additional ablation experiments to analyze the impact of various factors on its performance.</p>
<p>We summarize our contributions as follows:</p>
<ol>
<li>
<p>We proposed Lyria, a general LLM-driven genetic algorithm framework for problem solving, and demonstrated its effectiveness by evaluating with 4 LLMs and 3 types of NP problems;</p>
</li>
<li>
<p>We constructed dedicated prompts and domain-specific operators tailored to each type of problem, ensuring that Lyria is aligned with their unique requirements;</p>
</li>
<li>
<p>We conducted 7 additional ablation experiments to comprehensively analyze the impact of various factors on the performance of Lyria.</p>
</li>
</ol>
<p>Related Work</p>
<p>Recently, research on the integration of LLMs and genetic algorithms has begun to emerge, demonstrating promising results across a variety of tasks.Through synergistically combining LLMs with evolutionary algorithms, EVOPROMPT (Guo et al., 2024) shows its efficacy to optimize discrete prompt generation, outperforming existing automatic prompt generation methods across various LLMs and tasks.In addition, Morris et al. (2024) proposed a novel framework which leverages LLMs to autonomously evolve neural network architectures through feedback-driven code modifications via Evolution of Thought and Character Role Play, while Nasir et al. (2024) proposed a method LLMatic that integrates the codegeneration capabilities of LLMs and Quality Diversity algorithms which are a subset of evolutionary algorithms (Cully and Demiris, 2017;Pugh et al., 2016) to efficiently discover network architectures.Furthermore, Hemberg et al. (2024) proposed and demonstrated the way to replace traditional genetic programming operators with LLM-based operators.</p>
<p>Moreover, Pinna et al. (2024) proposed an approach based on LLMs and Genetic Improvement to improve code generation.</p>
<p>Nevertheless, a general LLM-driven genetic algorithm framework along with a comprehensive analysis, has yet to be proposed, resulting in an incomplete and unclear understanding of it.Differing from prior work, this paper introduces a general LLM-driven framework comprising 7 principal components and offers a thorough, in-depth analysis of the various factors that may affect its performance.</p>
<p>Benchmarks</p>
<p>To evaluate Lyria, we selected 3 NP problems, i.e.Sudoku (Yato and Seta, 2003), Graph Coloring (Gent et al., 2017), and Traveling Salesman Problem (Papadimitriou and Steiglitz, 1976), characterized by their vast solution spaces and stringent constraints satisfaction requirements, thereby supposed to pose significant challenges to LLMs.It is worth noting that Lyria is not restricted to these problems, and the selection of them is only motivated by their complexity and the convenience of generating uncontaminated data.We describe each problem and their metrics in the following sections.</p>
<p>Sudoku</p>
<p>Sudoku (SK) is a number-placement puzzle played on a 9 × 9 grid, where each cell must be assigned a digit from 1 to 9. The grid is partitioned into nine 3 × 3 subgrids.A correct Sudoku solution requires that each row, column, and subgrid contains all digits from 1 to 9 exactly once.The puzzle is typically presented with some cells pre-filled, and a given solution must respect the constraints.solutions that over-optimize one constraint at the expense of others, with the average across all solutions reported as SK P S in a range from 0 to 100.We formally define each metrics and detail them in Appendix A.1.</p>
<p>Graph Coloring</p>
<p>Graph Coloring (GC) is the task of assigning colors to the vertices of a given graph such that no two adjacent vertices share the same color.Formally, given a graph G = (V, E) and a set of k distinct colors, the goal is to find a function f : V → {0, 1, . . ., k −1} such that for any edge (u, v) ∈ E, f (u) ̸ = f (v).</p>
<p>Data Generation We fixed the number of vertices |V | to 9, the size of the color set k to 3 and the edge connection probability to 0.5.This process yields 50 distinct GC instances.</p>
<p>Metrics We evaluate GC solutions using 5 metrics, namely Excess Color Usage, Conflict Ratio, Correctness, Score, and Penalized Score.Correctness verifies if a solution uses exactly k colors and no adjacent vertex is conflicted, with the correct percentage across all solutions reported as GC CR .Penalized Score is a modified score that penalizes solutions that use too many distinct colors, e.g., coloring each vertices with a distinct color, and it ranges from 0 to 100, where higher means better, with the average across all solutions reported as GC P S .We formally defined the 5 metrics and detailed them in Appendix A.2.</p>
<p>Traveling Salesman Problem</p>
<p>Traveling Salesman Problem (TSP) is a routefinding task defined on a set of cities and pairwise distances between them.Formally, let G = (V, E) be a complete undirected graph in which V = {v 1 , . . ., v n } is a set of vertices of the graph and
E = {(u, v) : u, v ∈ V, u ̸ = v} is a set of edges. A distance function d : V × V → R ≥0 assigns each edge (u, v) a nonnegative distance d(u, v).
The goal in the TSP is to find a Hamiltonian cycle in G whose total distance is minimized.Formally, a route r is any permutation π of V , with the first element also appearing at the end, forming a cycle, defined as a sequence r =
[v π(1) , . . . , v π(n) , v π(1) ].
The total distance of this route is given as:
D(r) = d(v π(n) , v π(1) )+ n−1 i=1 d(v π(i) , v π(i+1)
).Thus, the goal of TSP is to determine the route r * in all possible routes R such that ∀r ∈ R, D(r) ≥ D(r * ), i.e., r * = min r∈R D(r).</p>
<p>Dataset Generation</p>
<p>For each TSP problem, we fixed the number of cities |V | to 10.The coordinate (x v , y v ) of city v is sampled as x, y i.i.d ∼ U[0, 100] and the distance between cities are calculated by Euclidean distance.A start and end city is fixed and noted as v 1 .An optimal reference route is then derived by exhaustively enumerating all Hamiltonian cycles beginning and ending at v 1 .This procedure is repeated to produce 50 distinct TSP instances.</p>
<p>Metrics We evaluate TSP solutions using 4 metrics, namely Excess Distance Multiplier (EDM), Missing Cities (MC), Correctness, and Penalized Score.Correctness verifies if a route is the shortest cycle visiting all cities exactly once, with the correct percentage across all solutions reported as TSP CR .Penalized Score considers both EDM and MC as penalties and is given in a range of 0 and 100 where higher is better, with the average across solutions reported as TSP P S .We formally defined each of 4 metrics and detailed them in Appendix A.3.</p>
<p>Methodology</p>
<p>Lyria comprises 7 primary components: Error Detector, Experience Pool, Deduplicator, Fitness Evaluator, Selector, Crossover Operator, and Mutation Operator.We begin with a high-level overview of the framework, followed by a detailed elucidation of each component.</p>
<p>Initially, an LLM generates a population of candidate solutions.Every candidate is scored by the Fitness Evaluator and analyzed by the Error Detector.Evolution then proceeds in generations: a fraction of the lowest fitness individuals, determined by the replay rate, is replaced by the highest fitness candidates drawn from the Experience Pool; the Selector chooses appropriate parents; the Crossover Operator, guided by parental errors, generates offspring until the population size is restored; and the Mutation Operator modifies each candidate according to its own errors.After initialization and every crossover and mutation operations, the Deduplicator removes duplicates to maintain diversity.The updated population is re-evaluated and advanced in the next generation, until reaching the predetermined maximum number of generations.We demonstrate the pseudo code in Algorithm 1.</p>
<p>Error Detector</p>
<p>Inspired by Reflexion (Shinn et al., 2023) and Self-Refinement (Madaan et al., 2023), whenever a new candidate is generated, the error detector (ED) identifies its errors up to a predefined maximum detected errors, enabling crossover and mutation operators to learn from past mistakes, thereby promoting the generation of improved candidates.</p>
<p>In Lyria, we proposed two types of EDs.A Verifier-based ED invokes external instruments, e.g., parsers, compilers, test suites, model checkers, etc., to examine a candidate against formal criteria and to emit deterministic and unbiased diagnoses.By contrast, an LLM-based ED prompts an LLM to introspectively evaluate the candidate, harnessing its knowledge and reasoning abilities trained on corpora.While the latter may hallucinate on identifying errors, it still remains indispensable when external verifiers are unavailable.</p>
<p>Different problem types typically have distinct error spaces.For each type of problem, we designed dedicated EDs and implemented them in both the Verifier-based and LLM-based approaches.For the Verifier-based EDs, we realized them programmatically.For the LLM-based EDs, we crafted dedicated prompt templates and demonstrated them in Prompt Template 1, 2, and 3. Due to space constraints, we detailed all the EDs in Appendix D.</p>
<p>Deduplicator</p>
<p>During initialization, crossover, and mutation, the deduplicator (DD) discards any individual that duplicates an existing one, requesting replacements until a preset maximum deduplication attempts is reached.This prevents identical candidates from dominating and preserves diversity.</p>
<p>Formally, given a sequence of candidates
C = [c i ] k i=1
where k is the number of candidates generated, a newly generated candidate c k+1 , and a predefined maximum deduplication attempts τ , the deduplicator DD(C, c k+1 , τ ) operates as fol-
lows: if c k+1 / ∈ C, it returns c k+1 ; if ∃i ∈ {1, . . . , τ }, c (i) k+1 / ∈ C and ∀j &lt; i, c (j) k+1 ∈ C, it re- turns c (i) k+1 ; otherwise, it returns c (τ ) k+1 . Here, c (i) k+1
denotes a regenerated candidate.Hence, unique candidates are accepted immediately; duplicates trigger up to τ regenerations, with the first nonduplicate retained or the final candidate accepted if all fail.</p>
<p>Experience Pool</p>
<p>During initialization and after each generation, candidate solutions with their fitness scores and errors are recorded in the experience pool (EP).Before selection, the lowest fitness individuals in the population are systematically replaced with the highest fitness candidates in EP, with the number of replacements determined by a predefined replay rate.The EP preserves high-quality solutions and prevents inferior candidates from dominating the population, averting convergence toward suboptimal regions.</p>
<p>For the EP updating, formally, let EP t denote EP at generation t, which is initialized as:
EP 0 = {(c i , s i , e i ) | c i ∈ C 0 , s i ∈ S 0 , e i ∈ E 0 } , where C 0 = [c i ] n i=1 is a sequence of candi- dates representing the initial population, S 0 = [s i ] n
i=1 is a sequence of fitness score corresponding to each candidate in C 0 , and
E 0 = [e 1 ] n i=1
is a sequence of error information of each candidate in C 0 .After each generation t, the experience pool is updated as:
EP t+1 = EP t ∪ {(c i , s i , e i ) | c i ∈ C t , s i ∈ S t , e i ∈ E t } .
For the candidates replacement before selection, let C t−1 = {c 1 , . . ., c n } be the previous population and
C EP t = {c ⋆ 1 , . . . , c ⋆ m } be the candidates from EP at t. For the replay rate ρ, we define replacement count k = ⌊ρ • n⌋. Let permuta- tion σ ↑ sort C t−1 such that s σ ↑ (i) ≤ s σ ↑ (j) for all i &lt; j, and permutation σ ↓ sort C EP t such that s ⋆ σ ↓ (i) ≥ s ⋆ σ ↓ (j) for all i &lt; j. We construct the new population C ′ = [c ′ 1 , c ′ 2 , . . . , c ′ n ], in which c ′ i = c ⋆ σ ↓ (i) if 1 ≤ i ≤ k and s ⋆ σ ↓ (i) &gt; s σ ↑ (i) , other- wise c ′ i = c σ ↑ (i) .</p>
<p>Fitness Evaluator</p>
<p>The fitness evaluator
= c x i if s x i &gt; s y i , otherwise c tour i = c y i .
Thus, combining the truncation selection and tournament selection, the selector is defined as: Select(C, S, k e , k r ) = C trunc ∪ C tour .Hence, the candidates selected as the mating pool is C ′ = Select(C, S, k e , k r ).</p>
<p>Crossover Operator</p>
<p>The crossover operator (CO) selects parent pairs from the mating pool, governed by a predefined crossover rate.If crossover is skipped, a parent is randomly returned; otherwise, offspring are gen-erated.This iterates until the offspring population reaches the predefined population size.The objective of CO is to combine advantageous traits of parents while suppressing detrimental ones to produce improved offspring with higher fitness.In Lyria, we propose two COs, i.e.LLM-based CO (LCO) and External CO (ECO), which are alternated in evolution based on an external crossover rate, for which lower prioritizes LCO while higher prioritizes ECO.</p>
<p>LCO In LCO, an LLM is prompted to merge two parent candidates by integrating their advantageous attributes and excluding their deficiencies, drawing on the experience and prior knowledge of the LLM and their understanding of the error information of the candidates provided by the ED, to produce an improved child.This approach eliminates the need to manually specify any domain-specific strategy, instead fully delegating it to the LLM.We demonstrated the prompts we designed for each of the 3 problem types in Prompt Template 7, 8, and 9.</p>
<p>ECO In ECO, two parent candidates are combined via external procedures or tools, based on domain-specific strategies and also the error information of the given parents.Varying from domains, distinct strategies can be employed, e.g., leveraging external heuristics provided by domain experts, formal logical constraints, etc.We designed specific ECOs for each problem type and detailed all of them in Appendix E.</p>
<p>Mutation Operator</p>
<p>The mutation operator (MO) applies mutations to each candidate based on a predefined mutation rate, returning either the original or mutated candidate.This preserves population diversity and prevents premature convergence.In Lyria, we propose two MOs, i.e., LLM-based MO (LMO) and External MO (EMO), which are alternated in evolution via an external mutation rate, for which lower prioritizes LMO while higher prioritizes EMO.</p>
<p>LMO In LMO, an LLM is instructed to mutate a given candidate, by identifying and improving its inferior parts, based on the knowledge of LLMs and their understanding of error information.Similar to LCO, this approach eliminates the necessity to manually construct domain-specific strategies and enables the LLM to autonomously design strategies to modify the given candidate.We designed the prompt for each problem type and demonstrated  EMO In EMO, the mutation is handled by external procedures or tools, guided by domain-specific mutation strategies and also the error information of the candidate, to modify the candidate.We designed specific EMOs for each problem type and elucidated them in detail in Appendix F.</p>
<p>5 Main Experiment</p>
<p>Baselines</p>
<p>We adapted two baselines, i.e., Direct Prompting (DP) and Best-of-N Direct Prompting (BoN), for comparative evaluation.</p>
<p>For DP, an LLM is invoked once and prompted to generate a solution directly in a zero-shot manner.We designed the prompt templates for each problem type and demonstrated them in Prompt Template 13, 14, and 15.</p>
<p>Since Lyria may sample an LLM up to L times for a single problem, a naive comparison against DP could favor Lyria merely by virtue of increased sampling 2 .To ensure a fair comparison, we adopt the BoN approach.For each problem, BoN draws N = L independent responses from the LLM using the identical prompt template employed by DP and preserves the one with the best metrics as the answer.Additionally, same as Lyria, a deduplicator is introduced to remove redundant answers.This approach equalizes the number of sampling and 2The calculation of L is demonstrated in Appendix B.</p>
<p>ensures any observed performance improvements are attributable to the innovations of Lyria.</p>
<p>Experiment Settings</p>
<p>For a comprehensive evaluation, we selected 4 LLMs: GPT-4o-Mini, Qwen2.5:32B-Instruct,Qwen2.5:7B-Instruct, and Mistral:7B-Instruct.</p>
<p>For DP, we set the temperature to 0 for greedy decoding and the maximum generated tokens to 4096.</p>
<p>For BoN, we set the temperature at 0.7 to enable diverse generated answers, the maximum generated tokens at 4096, the sampling times N at 345 to align the number of queries with Lyria, and the maximum deduplication attempts at 3.</p>
<p>For Lyria, we switch on the Oracle-based FE.We set the temperature of LLM at 0.7, the maximum generated tokens at 4096, the population size at 30, the generations at 15, the maximum detected errors at 3, the maximum deduplication attempts at 3, the replay rate at 0.6, the crossover rate at 0.7, the external crossover rate at 0.3, the mutation rate at 0.3, and the external mutation rate at 0.3.</p>
<p>Results &amp; Analysis</p>
<p>As shown in Table 1, LLMs struggle across problems in DP3 .While BoN greatly improves the performance across the problems, Lyria demonstrates its ability to further consistently contribute significant improvement across various LLMs and problems.For example, Lyria improves GC P S for GPT-4o-Mini by 24% over DP and 11% over BoN, while enhancing SK CR by 32% and 24% and also SK P S by 56% and 11%, for Qwen2.5:32B-Instruct,compared to DP and BoN, respectively.In addition, for relatively small LLMs like Qwen2.5:7B-Instruct,Lyria also shows its efficacy, by 22% and 11% GC P S increases, and 61% and 7% TSP P S improved, compared to DP and BoN, respectively.</p>
<p>Furthermore, across all LLMs, for SK, Lyria shows an average 10% and 7% increases on SK CR with 34% and 6% increases on SK P S , compared to DP and BoN.For GC, Lyria shows 40% and 10% improvement on GC P S .For TSP, Lyria shows 10% and 7% increases on TSP CR with 32% and 5% improvement on TSP P S .Therefore, across all LLMs and problems, Lyria demonstrates 7% and 5% increases on the correctness and 35% and 7% improvements on the penalized score, compared to DP and BoN, respectively, demonstrating the consistent performance contribution offered by Lyria.</p>
<p>Ablation Experiments</p>
<p>To further investigate the impact of various factors that influence the performance of Lyria, we conducted 7 additional experiments.To avoid prohibitive costs, we selected Qwen2.5:7B-Instruct and limited the number of problems to 10. Unless otherwise specified, we adhere to the same parameter settings as in the main experiment and refer their performance to the penalized score metric.</p>
<p>Scaling Population Size and Generations</p>
<p>This experiment investigates the impact of scaling population size n p and generations n g on the performance of Lyria.We executed 6 experiment settings, each pairing a n p and n g : (5, 5), (10, 10), (20, 20), (30, 30), (40, 40) and (50, 50).For each setting, we applied the BoN baseline for comparison, with the corresponding values of N equal to 23, 80, 300, 660, 1160, and 1800.As demonstrated in Figure 2, averaged across problems, while BoN exhibits diminishing marginal gains as parameters scaled, Lyria demonstrated consistent improvements and increasingly larger performance gaps compared to BoN.We attribute the limitations of BoN to LLMs getting trapped in local optima without effective capacities to extricate themselves from it, resulting in even sampling an arbitrarily large number of answers yet still failing to yield further performance improvements.However, Lyria inherently possesses the capacity to escape local optima, driving substantial performance improvements while increasing n p and n g .</p>
<p>In addition, to disentangle the individual contribution of n p and n g , we conducted 6 additional experiments settings.We fixed the n p at 10 while varying n g at values of 10, 30, and 50, and conversely fixed n g at 10 while adjusting n p across values of 10, 30 and 50.For the former, averaged across problems, the penalized scores increase by 4%, while the latter one yields 7% gains.The modest 3% difference between them could result from the limited diversity in smaller populations, causing offspring becoming homologous to their parents, thereby suppressing evolutionary efficacy.However, given this minor gap, we cannot exclude the possibility that it arises from stochastic variation.</p>
<p>Oracle-Based FE VS LLM-Based FE</p>
<p>This experiment seeks to explore how the performance of Lyria varies when using an Oracle-based FE versus an LLM-based FE.We compared an Oracle-based FE with two LLM-based FEs, one built on Qwen2.5:7B-Instruct and the other on GPT-4o-Mini.</p>
<p>We observed that, averaged across problems, the Oracle-based FE achieved a penalized score of 84, whereas Qwen2.5:7B-Instruct and GPT-4o-Mini scored only 51 and 50, respectively.The superior result of Oracle-based FE, as expected, shows that a stronger evaluator markedly boosts the performance of Lyria.Additionally, it is also worth noting that the nearly identical scores of GPT-4o-Mini and Qwen2.5:7B-Instructindicate no significant difference in their evaluative capacity, although GPT-4o-Mini demonstrates a consistent better prob-lem solving ability than Qwen2.5:7B-instructas shown in Table 1.We expect the future work to seek to improve the ability of LLMs as evaluator and approach it to oracle level.Thus, the Oraclebased FE in Lyria can be fully replaced by LLMs, which is advantageous when an Oracle-based FE is unavailable or difficult to secure.</p>
<p>Impact of ED, EP, DD</p>
<p>This experiment aims to investigate the impact of the Error Detector, Experience Pool, and Deduplicator on Lyria.</p>
<p>For ED, we vary the maximum detected errors ϵ at values of 0, 3, 6, and 9.For TSP, we do not observe a significant impact when increasing ϵ.In contrast, for SK, as ϵ rises, the SK P S also increased, yielding 4% gains.For GC, increasing ϵ produced a significant 7% improvements.We attribute the performance differences across problems to the varying efficacy of their dedicated design of ECO and EMO.</p>
<p>For EP, we vary the replay rate ρ at values of 0, 0.3, and 0.6.We observed that varying ρ did not produce significant changes in GC P S and TSP P S .However, for SK, while setting ρ to 0 and 0.6 yielded scores of 59 and 62, setting ρ = 0.3 produces a score of 73, bringing up a significant improvement of 14% and 11% compared to the scores when ρ = 0 and ρ = 0.6.We attribute this discrepancy to the trade-offs of ρ.When ρ is too low or EP is dropped, since the population of each generation evolves solely by referring to its immediate predecessors, the lack of retained historical best solutions may bias the evolutionary direction.Conversely, when ρ is too high, overreliance on historical best solutions which may themselves be local optima, can homogenize the evolved population and lead to premature convergence on suboptimal solutions.</p>
<p>For DD, we vary the maximum deduplication attempts τ at the values of 0, 3, and 6.Averaged across problems, increasing τ does not bring up a significant improvement, which, nevertheless, is as expected and does not mean that the deduplicator is dispensable.Since the solution spaces of all the given problems are considerably immense, and when the population size remains much smaller than the solution space, it results in a low incidence of duplicate individuals, DD therefore may not be invoked.Thus, when encountering problems with comparatively smaller solution spaces, DD could effectively eliminate duplicates and thereby enhance population diversity.</p>
<p>Impact of ECO and EMO</p>
<p>This experiment aims to investigate the impact of External Crossover Operator and External Mutation Operator on Lyria.Given the close interdependence between these two operators, rather than evaluating their efficacy in isolation, we simultaneously vary both the external crossover rate ξ and the external mutation rate µ to investigate the efficacy of them.Thus, we construct 3 experiment settings, each pairing a ξ and µ: (0, 0), (0.3, 0.3), and (0.6, 0.6).</p>
<p>For GC, raising ξ and µ induces a 6% performance gain by improving GC P S from 91 to 97.However, for TSP, we did not observe a significant performance gain after increasing the rates.Furthermore, for SK, we observed a 6% performance drop after raising rates.The disparity of the results illustrates that the quality of ECO and EMO designs tailored to specific problems can markedly influence performance.High-quality ECO and EMO enable Lyria to evolve populations more effectively, leading to better performance.We consider that a high-quality ECO and EMO may contain, but are not limited to, extra or superior heuristics beyond what an LLM alone can provide, structural or precise constraints, or expert domain knowledge.Conversely, poor designed of them may trigger performance declines.We consider that inferior operators can synthesize solutions worse than their predecessors, especially when they are frequently used in the case that ξ and µ are elevated, which can introduce low-quality individuals into each generation, thereby degrading performance.Therefore, a meticulous and superior design of ECO and EMO is essential for Lyria.</p>
<p>Conclusion</p>
<p>In this work, we introduced Lyria, a general LLMdriven genetic algorithm framework, which integrates the semantic understanding and reasoning abilities of LLMs with the global and systematic search capacity of genetic algorithms, comprising 7 essential components, to solve complex problems.We conducted extensive experiments with 4 LLMs across 3 types of problems to show the superior ability of Lyria, and also conducted 7 additional ablation experiments to demonstrate how various factors affect its performance.We hope this work offers valuable insights into the integration of LLMs with genetic algorithms and sparks further exploration in this field.</p>
<p>Limitations</p>
<p>Although our evaluation of Lyria focuses on SK, GC, and TSP problems, the framework is not restricted to these domains.We believe Lyria can be applied in a broader range of domains, especially for those problems characterized by multi-objective or discrete optimization, precise constraints, immense solution spaces, while also needing semantic understanding, such as planning in a dynamic environment, code synthesis, music generation, and other real-world applications.We encourage and expect the integration of Lyria into these domains in future works.</p>
<p>While Lyria exerts significant performance improvements, especially when the population size and generations are increased, it necessarily induces more LLM queries, leading to longer response time and higher costs.At present, it may not therefore be suited to applications that demand immediate responses or have a low budget.Thereby, reducing this overhead is an important goal for subsequent work.</p>
<p>In addition, in Section 6.2, we observed a large performance gap between the Oracle-based FE and the LLM-based FE.Since we do not expect, in practice, an Oracle-based FE is always available, we believe replacing the Oracle-based FE with an LLM-based FE can greatly increase the applicability and convenience of Lyria in real-world applications.Thereby, we expect future work to improve the LLM-based FE to approach the Oracle-based FE.</p>
<p>Finally, to our best knowledge, no existing similar framework is directly comparable to Lyria.Consequently, this paper concentrates more on the internal analysis to ensure that the observed performance improvements arise from the virtue of the framework itself rather than from other factors, e.g., increasing samplings, and examining the contribution and necessity of each component.</p>
<p>A Metrics</p>
<p>A.1 Sudoku Given a SK solution s ′ as a 9 × 9 matrix with each cell filled, formally we have:
s ′ =        u 1,1 u 1,2 u 1,3 • • • u 1,9 u 2,1 u 2,2 u 2,3 • • • u 2,9 u 3,1 u 3,2 u 3,3 • • • u 3,9 . . . . . . . . . . . . . . . u 9,1 u 9,2 u 9,3 • • • u 9,9       
.</p>
<p>Let S denote the solutions to all SK problems.We mainly employ 3 metrics to assess the quality of the generated solutions:</p>
<p>Correctness The correctness of s ′ is defined as CR(s ′ ), which returns 1 if s ′ satisfies all the row, column, and subgrids constraints, otherwise 0. Formally, let R(s ′ , i) denote the values at row i, C(s ′ , j) denote the values at column j, and B(s ′ , k) denote the k-th 3×3 subgrids.The CR(s ′ ) is given as:
CR(s ′ ) =                1, if (∀i, |R(s ′ , i)| = 9) ∧(∀j, |C(s ′ , j)| = 9) ∧(∀k, |B(s ′ , k)| = 9) ∧(∀i, j, s ′ [i, j] ∈ {1, . . . , 9}) 0, otherwise
We report the correctness percentage of S as Sudoku CR .</p>
<p>Score Evaluating a Sudoku solution solely based on its correctness provides an overly narrow perspective, since when an LLM fails to provide a fully correct solution, it becomes challenging to observe and analyze whether it yields a highquality albeit suboptimal solution and how closely it approximates the optimal solution.Thus, we define the score of a given s ′ as the average of percentages of constraints sanctification of rows, columns, and subgrids.Higher score means s ′ approaches more to the optimal solution.Formally, let I(X) be an indicator function that returns
1 if X = {1, . . . , 9}, otherwise 0. Let I R s ′ = 9 i=1 I(R(s ′ , i)), I C s ′ = 9 j=1 I(C(s ′ , j)),andI B s ′ = 9 k=1 I(B(s ′ , k)).
We have SC(s ′ ) as:
SC(s ′ ) = 100 • 1 27 I R s ′ + I C s ′ + I B s ′ ,
We report the average of S as Sudoku SC Penalized Score To prevent a solution from resorting to extreme strategies to improve correctness, such as boosting row and column correctness while sacrificing subgrid correctness, and thus ending up far from the optimal solution despite a seemingly high score, we adopt the geometric mean to mitigate the impact of these extreme values on the overall score.Formally, we have PS(s ′ ) as:
PS(s ′ ) = 100 • 3 I R s ′ 9 • I C s ′ 9 • I B s ′ 9 ,
We report the average penalized score of S as Sudoku P S .</p>
<p>A.2 Graph Coloring</p>
<p>Given a GC solution f ′ , let F denote the solutions to all GC problems, we employ 5 metrics to more precisely evaluate the solution quality:</p>
<p>Correctness The correctness of f ′ indicates whether it assigns colors to each vertex such that no adjacent vertex has the same color.Formally:
CR(f ′ ) =        1, if ∀v ∈ V, f ′ (v) ∈ {i} k−1 i=0 ∧ ∀(u, v) ∈ E, f ′ (u) ̸ = f ′ (v) , 0, otherwise.
We report the correctness percentage for F as GC CR .</p>
<p>Excess Color Usage We define the excess color usage of a given f ′ as the number of distinct colors used that exceeds the allowed distinct colors k:
ECU(f ′ ) = { f ′ (v) | v ∈ V } − k.
We report the average of F as GC ECU .</p>
<p>Conflict Ratio We define the conflict ratio as the ratio of edges whose endpoints share the same color.Define an indicator function:
I CF (f ′ , u, v) = 1, if f ′ (u) = f ′ (v), 0, otherwise.
The conflict ratio CF for a given f ′ is given as:
CF(f ′ ) = (u,v) ∈ E I CF (f ′ , u, v) |E| .
We report the average of F as GC CF .</p>
<p>Score We define the score of a given f ′ as the percentage of edges colored properly as:
Score(f ′ ) = 1 − CF(f ′ ) • 100.
We report the average of F as GC SC .</p>
<p>Penalized Score The penalized score is a modified score that penalizes solutions using too many colors, e.g., coloring each vertices with a distinct color.Let k ′ = |{f ′ (v) : v ∈ V }| be the total number of distinct colors used.Formally, we have PS as:
PS(f ′ ) =      0, if k ′ ≥ |V |, Score(f ′ ), if k ′ ≤ k, Score(f ′ ) • R, otherwise. where R = (1 − k ′ − k |V | − k
) is the penalty ratio for the score.We report the average of F as GC P S .</p>
<p>A.3 Traveling Salesman Problem</p>
<p>Given a TSP solution r ′ ∈ R and
r ′ = [v ′ 1 , v ′ 2 , . . . , v ′ |V |+1
], let T denote the solutions to all problems, we employ 4 metrics to analyze the solution quality:</p>
<p>Correctness The correctness of r ′ indicates whether it is the shortest route while starting and ending at v ′ 1 .Formally:
CR(r ′ ) =            1, if (r ′ = min r∈R D(r)) ∧ (v ′ 1 = v ′ |v|+1 ) ∧ (|r ′ | = |V | + 1) 0, otherwise.
We report the average of T as TSP CR .</p>
<p>Excess Distance Multiplier The excess distance multiplier of r ′ quantifies the factor by which a solution's distance exceeds the optimal distance D(r * ).Formally:
EDM(r ′ ) = min 3, D(r ′ ) − D(r * ) D(r * )
The value of 0 indicates the solution's distance matches the optimal distance, while a value of 1 means the solution is twice as long as the option distance and so on.We make the value saturates at 3 as a default and maximum.We report the average of T as TSP EDM .</p>
<p>Missing Cities A given route r ′ may skip some cities or revisit others.To measure this, we count the number of distinct cities that are missed from the solution.Formally:
MC(r ′ ) = |V | − |{v | v ∈ r ′ }|.
We report the average of T as TSP M C .</p>
<p>Penalized Score The penalized score for r ′ measures how closely it approximates r * , while applying penalties to the exceeded distance and also the omission of cities.Let Dist = 1 − EDM(r ′ ) 3 and Miss = 1 − MC(r ′ )</p>
<p>|V | .Formally:
PS(r ′ ) = IS • min(Dist, Miss)
where IS = 100 is the initialized score.We report the average of T as TSP P S .</p>
<p>B L Calculation of Lyria</p>
<p>Lyria could sample an LLM up to L times for a single problem.Let n p be the population size, n g be the generations, η be the crossover rate, ξ be the external crossover rate, κ be the mutation rate, and µ be the external mutation rate.The sample times L are given as:
L = n p + n p • η • (1 − ξ) + n p • κ • (1 − µ) • n g</p>
<p>C Lyria Pseudo Code</p>
<p>We  return best_solution 48: end procedure At Line 2, we initialize essential parameters.From Line 3 to 12, we use DPPROMPT to construct the prompt.For example, we use prompt templates shown in Prompt Template 13, 14, and 15 to construct the prompt for each problem type.Then, llm uses this prompt to generate new candidate.Deduplicator removes redundant candidates, FE assigns fitness score to the candidate, ED detect its errors up to ϵ for which we show the prompt templates we used in Prompt Templates 1, 2, and 3.For Line 13-46, Lyria starts evolution.At Line 14, EP intervenes to replace the lowest fitness candidates from the previous population with the highest fitness candidates from EP along with their fitness scores and errors.At Line 15-16, the selector selects appropriate candidates along with their fitness scores and errors.For Line 17-28, the crossover rate η determines whether to apply the crossover operation, while the external crossover rate ξ determines whether ECO is prioritized.For LCO, we demonstrate the prompt templates we used for each problem type in Prompt Template 7, 8, and 9.For Line 29-41, the mutation rate κ determines whether to apply the mutation operation, while the external mutation rate µ determines whether EMO is prioritized.For LMO, we demonstrate the prompt templates we used for each problem type in Prompt Template 10, 11, and 12.For Line 42-45, population, f itness, errors, and EP are updated, and the evolution advances into the next generation.
if child ∈ mutated and τ ′ &lt; τ then τ ′ ← τ ′ + 1; Continue else τ ′ ← 0 39: mutated, mt_f itness ← mutated ∥ [child], mt_f itness ∥ [F E(child)]
In addition, in practice, to prevent unnecessary additional overhead, especially when best_f itenss attains its optima, we also introduce a fitness threshold.During both initialization and the end of each generation, we check whether best_f itness meets or exceeds the fitness threshold.The best_solution is returned earlier if it meets the threshold.For every type of problem, the fitness threshold is set to 100.</p>
<p>D Error Detectors D.1 SK ED</p>
<p>Given a SK solution s ′ , we define 2 error types as follows:</p>
<p>Syntax Error (XE) For any generated SK solution by LLMs, we require it to be in the format of a 9 × 9 matrix, with each cell separated by a space, as described in Prompt Template 13.XE indicates whether s ′ is in a valid format.If the format is correct, XE(s ′ ) = 0, otherwise XE(s ′ ) = 1.</p>
<p>Semantic Error (SE) It consists of indices of cells that do not satisfy its row, column, and subgrid constraints.We define it as: SE(c) = {(i, j, t) | i, j ∈ {1, . . ., 9} ∧ t ∈ {0, 1, 2}}}, where i, j are row and column index respectively and t indicates the unsatisfied constraint, in which 0 indicates row, 1 means column, and 2 refers to subgrid.</p>
<p>D.2 GC ED</p>
<p>Given a GC solution f ′ , represented as a sequence
F ′ = [o ′ 1 , o ′ 2 , . . . , o ′ |V | ] where o i = f ′ (v i
) is a color assignment for v i ∈ V .We define two error types:</p>
<p>Syntax Error (SX) For any generated GC solution by LLMs, we require it to be in the format of a list of digits separated by commas, as described in Prompt Template 14. SX verifies whether F ′ is in a valid format.If the format is valid, SX(F ′ ) = 0, otherwise 1.</p>
<p>Semantic Error (SE) It comprises two components:</p>
<p>• Conflict Edges (CE): It consists of a set of edges where adjacent nodes share the same color, violating coloring constraints:
CE(f ′ ) = {(u, v) | (u, v) ∈ E ∧ f ′ (u) = f ′ (v)}
• Excess Colors Count (ECC): It indicates the number of distinct colors used that exceeds the specified color count k:
ECC(f ′ ) = |F ′ | − k Thus, SE for f ′ is given as: SE(f ′ ) = (CE(f ′ ), ECC(f ′ )).</p>
<p>D.3 TSP ED</p>
<p>Given a TSP solution r ′ , we define two error types:</p>
<p>Syntax Error (XE) For any generated TSP solution by LLMs, we require it to be in the format of a list of digits separated by commas, with the first and last city being the same and equal to 0 and each city index in the range from 0 to number_of _cities − 1, as described in Prompt Template 15.XE indicates whether the solution is a route in a valid format.If it is valid, XE(r ′ ) = 0, otherwise 1.</p>
<p>Semantic Error (SE) It comprises two components:</p>
<p>• Missing Cities (MC): It consists of the cities omitted in r ′ : MC(r
′ ) = {v | v ∈ V ∧ v / ∈ r ′ }.
• Excess Distance (ED): It indicates the difference between the distance used in r ′ and r * :
ED(r ′ ) = D(r ′ ) − D(r * ).
Thus, SE is given as: SE(r ′ ) = (MC(r ′ ), ED(r ′ )).</p>
<p>E External Crossover Operators E.1 SK ECO</p>
<p>Let c 1 , c 2 be parent candidates as two 9 × 9 matrix.Let P removed denote the initially removed positions of the puzzle and {(i, j) | (i, j, t) ∈ SE(c)} ⊆ P removed .The crossover operator CO Sudoku (c 1 , c 2 ) produces the child c child as:
c child =      c 1 if SE(c 1 ) = ∅, c 2 if SE(c 2 ) = ∅, Φ(c 2 , P corr (c 1 )) otherwise,
where P corr (c 1 ) = P removed \ {(i, j) | (i, j, t) ∈ SE(c 1 )} are c 1 's corrected positions, and Φ(c, P corr ) updates c by replacing c's values at {(i, j) | (i, j, t) ∈ SE(c)} ∩ P corr .</p>
<p>E.2 GC ECO</p>
<p>Let c 1 , c 2 be two parent candidates, which are two GC solutions of which each represented as a sequence of color assignments, i.
∀i, c child [i] =                c 2 [i] if i ∈ CV(c 1 ) \CV(c 2 ), c 1 [i] if i ∈ CV(c 2 ) \CV(c 1 ), R(c 1 [i], c 2 [i]) otherwise,
where i ∈ {1, . . ., |V |} indicates both an index in a color assignment sequence and also a city, and R(x, y) denotes uniform random selection between x and y.Thus, CO GC transfers non-conflicting colors between parents while preserving valid vertex assignments.</p>
<p>E.3 TSP ECO</p>
<p>Let c 1 , c 2 be two parent candidates, which are two routines, for which each routine is a sequence of visited cities.The external crossover operator ECO TSP generates the child c child as:
c child =      c 1 if SE(c 1 ) = (∅, 0), c 2 if SE(c 2 ) = (∅, 0), Ψ(c 1 , c 2 , k) otherwise, where k i.i.d. ∼ U[1, n − 1] is a uniformly random crossover point, and ∀i, Ψ(c 1 , c 2 , k)[i] = c 1 [i] for i ≤ k, c 2 [i] for i &gt; k,
where i ∈ {1, . . ., |V |} is an index of a seqeunce.Thus, CO T SP merges partial routes from both parents while preserving order.</p>
<p>F External Mutation Operators</p>
<p>F.1 SK EMO Given a candidate c as a 9 × 9 matrix, the mutation operator MO Sudoku is given as:
EMO Sudoku (c) = c if SE(c) = ∅, Θ(c, p, v) otherwise, where p i.i.d. ∼ U({(i, j) | (i, j, t) ∈ SE(c)}) is an error position, v i.i.d.
∼ U[1, 9] is a random value, and Θ(c, p, v) denotes replacing c's value at the position p with the value v.</p>
<p>F.2 GC EMO</p>
<p>Given a candidate c as a sequence of color assignments, the mutation operator MO GC proceeds as:
EMO GC (c) = Γ(Λ(c)).
It is composed of two main components, i.e., Conflict Edges Resolution and Excess Colors Correction, denoted as Λ and Γ respectively.</p>
<p>Conflict Edges Resolution is given as:
Λ(c)[i] = y if c[i] ∈ CV(c) c[i] otherwise, where i i.i.d. ∼ U[1, |c|] is a randomly selected index, and y i.i.d. ∼ U({0, . . . , k −1}{c[i]}) is a new color value. Hence, it reassigns a new color to a vertex if it is conflicted such that y ̸ = c[i].
Excess Colors Correction is given as:
∀i, Γ(c)[i] = z if c[i] ∈ O, c[i] otherwise.</p>
<p>F.3 TSP EMO</p>
<p>Give a candidate c as a route, which is a sequence of visited cities, let Y be a set of duplicated cities in c, and let M = MC(c) be the missing cities, the mutation operator EMO TSP is given as:
EMO TSP (c) = c if M = ∅, Ω(c) otherwise,
where Ω is defined as:
∀i, Ω(c)[i] = φ(i) if c[i] ∈ Y c[i] otherwise,</p>
<p>G Additional Results</p>
<p>We demonstrate the results of all metrics for each problem type in  (1) For Type 1 Error Msg: "Syntax is wrong" wrapped in triple backticks as a code block;</p>
<p>(2) For Type 2 Error Msg: a.Each error is in the format as "i,j,type", where i is the row number and j is the column number starting from 0 and type is the conflict type, "row", "col", or "subgrid"; b.Each error is separated by a newline; c.All errors should be wrapped in triple backticks as a code block;</p>
<p>(3) For (1) The graph is represented by the adjacency matrix with {n_vertices} vertices, in which "y" means the two vertices are adjacent and "n" means the two vertices are not adjacent;</p>
<p>(2) The goal is to color the vertices with {color_count} colors such that no two adjacent vertices have the same color; 3. Given its candidate solution, you should find all the errors in the candidate solution; 4. The correctness of the solution depends on:</p>
<p>(1) Correct Syntax: the solution should be a list of {n_vertices} integers separated by comma such as "0,1,2", each integer represents the color of the corresponding vertex, and the colors should be integers from 0 to {color_count -1};</p>
<p>(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should be different; 4. If the syntax is incorrect, the errors should be "Syntax is wrong" (Noted as Type 1 Error Msg); 5.If the syntax is correct, the errors messages should be in two types:</p>
<p>(1) Type 2.1 Error Msg: the error msg are in the format as "i,j,color", where i is the vertex number, j is the vertex number, and color is the conflict color, and all of them are integers and separated by comma;</p>
<p>(2) Type 2.2 Error Msg: the error msg are in a number which indicates the number of exceeded colors, such as "0" means no exceeded colors, "1" means one exceeded color, "-1" means the colors used are less than the allowed color count, and so on; 6.You should find all the errors in the candidate solution; 7. If there are no errors, the errors should be "No errors" (Noted as Type 3 Error Msg); 8.You can think it thoroughly in any way you want, but You MUST give the errors in the end of your thinking in the format as:</p>
<p>(1) For Type 1 Error Msg: "Syntax is wrong" wrapped in triple backticks as a code block with the language indicator as "t1";</p>
<p>(2) For Type 2.1 Error Msg: a.Each error is in the format as "i,j,color", where i is the vertex number, j is the vertex number, and color is the conflict color, and all of them are integers and separated by comma; b.Each error is separated by a newline; c.All errors should be wrapped in triple backticks as a code block with the language indicator as "t2.1";</p>
<p>(3) For Type 2.2 Error Msg: the number of exceeded colors wrapped in triple backticks as a code block with the language indicator as "t2.2";</p>
<p>(3) For Type 3 Error Msg: "No errors" wrapped in triple backticks as a code block with the language indicator as "t3 (1) The distance matrix is a 2D matrix with {n_cities} rows and {n_cities} columns, in which each element represents the distance of traveling from the city in the row to the city in the column;</p>
<p>(2) The goal is to find the shortest path that visits each city exactly once and returns to the origin city; 3. Given its candidate solution, you should find all the errors in the candidate solution; 4. The correctness of the solution depends on:</p>
<p>(1) Correct Syntax: a. the solution should be a list of {n_cities} integers separated by comma such as "0,1,2", each integer represents the index of the city in the path, and the indexes should be integers from 0 to {n_cities -1}; b. the first and last city should be the same and should be 0, which means the path should return to the origin city which is 0; c. the index of city should be in the range from 0 to {n_cities -1};</p>
<p>(2) Correct Semantics: a.No missing city: the path should visit each city exactly once and return to the origin city; b.Optimal path: the path should be the shortest path; 5.If the syntax is incorrect, the errors should be "Syntax is wrong" (Noted as Type 1 Error Msg); 6.If the syntax is correct, the errors messages should be in two types:</p>
<p>(1) Type 2.1 Error Msg: the error msg are in the format of list separated by comma, where each element is a missing city in the path, such as "0,1,2", where 0, 1, 2 are the missing cities, and all of them are integers and separated by comma;</p>
<p>(2) Type 2.2 Error Msg: the error msg are in a number which indicates the exceeded distance, such as "0" means the distance is the optimal distance, "10.5" means the distance exceeds the optimal distance by 10.5, and it should be a float; 6.You should find all the errors in the candidate solution; 7. If there are no errors, the errors should be "No errors" (Noted as Type 3 Error Msg); 8.You can think it thoroughly in any way you want, but You MUST give the errors in the end of your thinking in the format as:</p>
<p>(1) For Type 1 Error Msg: "Syntax is wrong" wrapped in triple backticks as a code block with the language indicator as "t1";</p>
<p>(2) For Type 2.1 Error Msg: a. the error msg are in the format of list separated by comma, where each element is a missing city in the path, such as "0,1,2", where 0, 1, 2 are the missing cities, and all of them are integers and separated by comma; c. the error should be wrapped in triple backticks as a code block with the language indicator as "t2.1";</p>
<p>(3) For Type 2.2 Error Msg: the exceeded distance wrapped in triple backticks as a code block with the language indicator as "t2.2";</p>
<p>(3) For Type 3 Error Msg: "No errors" wrapped in triple backticks as a code block with the language indicator as "t3"; (4) You can give comments or explanations before or after the code block but you MUST NOT give any comments or explanations in the code block; ===Type 1 Error Msg Example=== <code>t1 Syntax is wrong
``= ==Type 2.1 Error Msg Example===</code>t2.1 0,1,2 <code>= ==Type 2.2 Error Msg Example=== ```t2.2 10.5</code>= ==Type 3 Error Example=== <code>`t3 No errors</code>= ==Distance Matrix=== <code>{ distance_matrix}</code>=
==Candidate Solution=== <code>{ candidate}</code>P rompt Template 4: Sudoku LLM-based Fitness Evaluator ===Instructions=== 1.You are a Sudoku expert who can evaluate whether a sudoku candidate solution is correct or not, or how close it is to the correct solution; 2. Given this Sudoku puzzle and its candidate solution, you should evaluate its score.The score is to measure how close the candidate is to the solution; 3. The correctness of the solution depends on:</p>
<p>(1) Correct Syntax: it has a correct format, meaning each row, column, and {subgrid_size}x{subgrid_size} square exactly contain {puzzle_grid_size} number, and each cell is separated by space.The solution format must be in the same format as the given puzzle but there is no unfilled dot;</p>
<p>(2) Correct Semantics: for each row, column, and {subgrid_size}x{subgrid_size} square, the numbers 1 to {puzzle_grid_size} should appear exactly once; 4. If the syntax is incorrect, the fitness score should be 0.0; 5.If the syntax is correct, the score is calculated based on the number of correct numbers in rows, columns, and subgrids, and shown in percentage.R = number of correct rows / {puzzle_grid_size} + {delta}, C = number of correct columns / {puzzle_grid_size} + {delta}, and S = number of correct subgrids / {puzzle_grid_size} + {delta}.The fitness score is calculated based on geometric mean as (R x C x S) ** (1/3) * 100.0, in which higher is better and 0.0 means the candidate is wrong at all while 100.0 means the candidate is correct; 6.In most of time, you should NOT give a score of 0.0 unless &lt;4&gt; are satisfied; You should give a score between 0.0 and 100.0 to indicate how close the candidate is to the correct solution; 7. (1) The graph is represented by the adjacency matrix with {n_vertices} vertices, in which "y" means the two vertices are adjacent and "n" means the two vertices are not adjacent;</p>
<p>(2) The goal is to color the vertices with {color_count} colors such that no two adjacent vertices have the same color; 3. Given its candidate solution, you should evaluate its score.The score is to measure how close the candidate is to the solution; 4. The correctness of the solution depends on:</p>
<p>(1) Correct Syntax: the solution should be a list of {n_vertices} integers separated by comma such as "0,1,2", each integer represents the color of the corresponding vertex, and the colors should be integers from 0 to {color_count -1};</p>
<p>(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should be different; 4. If the syntax is incorrect, the fitness score should be 0.0; 5.If the syntax is correct, the score is calculated based on:</p>
<p>(1) Number of Conflicted Edges (noted as CE): the number of edges that two adjacent vertices have the same color;</p>
<p>(2) Number of Exceeded Colors (noted as EC): the number of colors exceeded the allowed color count;</p>
<p>(3) The score is now calculated as: Max(0, (1 -(CE/{n_edges})) * (1 -EC/({n_vertices -color_count}))) * 100, which means the score does not only depend on the number of conflicted edges but also the number of exceeded colors and ranges from 0.0 to 100.0; 6.In most of time, you should NOT give a score of 0.0 unless your are very sure; You should give a score between 0.0 and 100.0 to indicate how close the candidate is to the correct solution; 7. (1) The distance matrix is a 2D matrix with {n_cities} rows and {n_cities} columns, in which each element represents the distance of traveling from the city in the row to the city in the column;</p>
<p>(2) The goal is to find the shortest path that visits each city exactly once and returns to the origin city; 3. Given its candidate solution, you should evaluate its score.The score is to measure how close the candidate is to the solution; 4. The correctness of the solution depends on:</p>
<p>(1) Correct Syntax: a. the solution should be a list of {n_cities} integers separated by comma such as "0,1,2", each integer represents the index of the city in the path, and the indexes should be integers from 0 to {n_cities -1}; b. the first and last city should be the same and should be 0, which means the path should return to the origin city which is 0; c. the index of city should be in the range from 0 to {n_cities -1};  (1) The distance matrix is a 2D matrix with {n_cities} rows and {n_cities} columns, in which each element represents the distance of traveling from the city in the row to the city in the column;</p>
<p>(2) The goal is to find the shortest path that visits each city exactly once and returns to the origin city; 2. Given these two candidate solutions, you should thoroughly think both good and bad parts of each candidate and whether they are correct solutions to the puzzle; 3.If you think one of them are already correct, you can give the correct solution directly; 4. If you think the two candidates have good parts or bad parts, you can combine the good parts of both candidates, exclude the bad parts of both candidates, or do both of them simultaneously, aiming at creating a new candidate solution which can be better than the original candidates and approach more to the correct solution; 5.If you think it is not necessary to combine the two candidates, you can also give a new candidate solution which is totally different from the original candidates, aiming at approaching more to the correct solution; 6.After crossover, the solution should approach or become correct, which means:</p>
<p>(1) Correct Syntax: a. the solution should be a list of {n_cities} integers separated by comma such as "0,1,2", each integer represents the index of the city in the path, and the indexes should be integers from 0 to {n_cities -1}; b. the first and last city should be the same and should be 0, which means the path should return to the origin city which is 0; c. the index of city should be in the range from 0 to {n_cities -1};</p>
<p>( (1) The graph is represented by the adjacency matrix with {n_vertices} vertices, in which "y" means the two vertices are adjacent and "n" means the two vertices are not adjacent;</p>
<p>(2) The goal is to color the vertices with {color_count} colors such that no two adjacent vertices have the same color; 2. Given this candidate solution, you should thoroughly think about the good and bad parts of the candidate and whether it is a correct solution to the puzzle; 3.If you think the candidate is already correct, you can give the correct solution directly; 4. If you think the candidate has bad parts, you can change or improve the bad parts to make it good, aiming at creating a new candidate solution which can be better than the original candidate and approach more to the correct solution; 5.If you think it is not necessary to change the candidate, you can also give a new candidate solution which is totally different from the original candidate, aiming at approaching more to the correct solution; 6.After mutation, the solution should approach or become correct, which means:</p>
<p>(1) Correct Syntax: the solution should be a list of {n_vertices} integers separated by comma such as "0,1,2", each integer represents the color of the corresponding vertex, and the colors should be integers from 0 to {color_count -1};</p>
<p>(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should be different; (1) The distance matrix is a 2D matrix with {n_cities} rows and {n_cities} columns, in which each element represents the distance of traveling from the city in the row to the city in the column;</p>
<p>(2) The goal is to find the shortest path that visits each city exactly once and returns to the origin city; 2. Given this candidate solution, you should thoroughly think about the good and bad parts of the candidate and whether it is a correct solution to the puzzle; 3.If you think the candidate is already correct, you can give the correct solution directly; 4. If you think the candidate has bad parts, you can change or improve the bad parts to make it good, aiming at creating a new candidate solution which can be better than the original candidate and approach more to the correct solution; 5.If you think it is not necessary to change the candidate, you can also give a new candidate solution which is totally different from the original candidate, aiming at approaching more to the correct solution; 6.After mutation, the solution should approach or become correct, which means:</p>
<p>(1) Correct Syntax: a. the solution should be a list of {n_cities} integers separated by comma such as "0,1,2", each integer represents the index of the city in the path, and the indexes should be integers from 0 to {n_cities -1}; b. the first and last city should be the same and should be 0, which means the path should return to the origin city which is 0; c. the index of city should be in the range from 0 to {n_cities -1};</p>
<p>(</p>
<p>Figure 1 :
1
Figure 1: The Lyria framework, consisting of 7 essential components, i.e., Error Detector, Experience Pool, Deduplicator, Fitness Evaluator, Selector, Crossover Operator, and Mutation Operator, enables evolving candidate solutions through generations to obtain superior solution.</p>
<p>Figure 2 :
2
Figure 2: The figure shows the performance comparison between Lyria and BoN, in which the x-axis indexes each parameter set, e.g., index 0 means the pair of (n p = 5, n g = 5) for Lyria and N = 23 for BoN, and the yaxis shows the corresponding score averaging across SK P S , GC P S , and TSP P S .</p>
<p>Thus, for example, given n p = 30, n g = 15, η = 0.7, ξ = 0.3, κ = 0.3, µ = 0.3, we have L = 30+(30•0.7•(1−0.3)+30•0.3•(1−0.3))•15= 345.</p>
<p>∪ {(c, s, e) | c ∈ population, s ∈ f itness, e ∈ errors} 45: Update best_solution and best_f itness 46: end for 47:</p>
<p>e., c = [o 1 , o 2 , . . ., o |V | ] where o i is a color assignment for v i ∈ V .Let CV(c) = {v | ∃(v, u) ∈ CE(c)} denote conflict vertices in candidate c.The external crossover operator ECO GC generates the child c child as:</p>
<p>in which i ∈ {1, . . ., |c|}, φ is an injection from the first r = min(|Y |, |M |) elements of Y into M .Hence, it resolves errors by substituting duplicates with missing cities, ensuring the mutated child becomes a route without missing cities.</p>
<p>(2) Correct Semantics: a.No missing city: the path should visit each city exactly once and return to the origin city; b.Optimal path: the path should be the shortest path; 4. If the syntax is incorrect, the fitness score should be 0.0; 5.If the syntax is correct, the score is calculated based on: (1) Number of Missing Cities (noted as MC): the number of missing cities in the path; (2) Used Distance (noted as UD): the total distance of the path; (3) The score is computed as follows (in range of [0...100]): 1) Let base_score = 100; 2) Let OD = the sum of the shortest distances of the path; (You should try to the best to think about its optimal distance) 3) Let ED = UD -OD; 4) Let ED_Multiplier = ED / OD; (calculate how much the distance exceeds the optimal distance, it MUST be in range of [0...{DEFAULT_EDM}]) 5) distance_excess_ratio = ED_Multiplier / {DEFAULT_EDM}; (in range of [0...1]) 6) distance_correctness = base_score -(base_score * distance_excess_ratio); (in range of [0...100]) 7) missing_ratio = MC / (the length of the path -1); (in range of [0...1]) 8) missing_correctness = base_score -(base_score * missing_ratio); (in range of [0...100]) 9) The final score is min(distance_correctness, missing_correctness), then clamped so it never goes below 0 or above 100.6.In most of time, you should NOT give a score of 0.0 unless your are very sure; You should give a score between 0.0 and 100.0 to</p>
<p>Table 1 :
1
The results of Correctness and Penalized Score for SK, GC, TSP.For each LLM, across the three methods, the best correctness and penalized score are highlighted with a bold font.Blue arrows ↑↓ indicate performance differences relative to the DP baseline, while red arrows ↑↓ denote differences relative to the BoN baseline.
them in Prompt Template 10, 11, and 12.</p>
<p>demonstrate the pseudo code of Lyria in Algorithm 1, in which P means the problem, n p means population size, n g means generations, k e means the number of fittest candidates that are directly carried forward in truncation selection, ϵ means the maximum detected errors, ρ means replay rate, τ means the maximum deduplication attempts, η means crossover rate, ξ means external crossover rate, κ means mutation rate, µ means external mutation rate, FE means the fitness evaluator which can either be Oracle-based or LLMbased, ED means the error detector which can either be Verifier-based or LLM-based, LCO means the LLM-based crossover operator, ECO means the external crossover operator, LMO means the LLMbased mutation operator, EMO means the external mutation operator, and llm indicates the LLM which accepts a prompt and returns a response.: procedure LYRIA(P, n p , n g , k e , ϵ, ρ, τ, η, ξ, κ, µ, FE, ED, LCO, ECO, LMO, EMO, llm) 2: population, f itness, best_f itness, best_solution, errors, EP, τ ′ ← [], [], −∞, ∅, [], ∅, 0
Algorithm 1 Lyria3:while |population| &lt; n p do▷ Initialization4:prompt ← DPPROMPT(P)5:candidate ← llm(prompt)8:errors ← errors ∥ [ED(candidate, ϵ)]9:if f itness[−1] &gt; best_f itness then10:best_solution, best_f itness ← candidate, f itness[−1]11:end if12:end while13:for n ′ g ← 1 to n g do▷ Start Evolution14:18:while |of f spring| &lt; n p do▷ Crossover Phase19:24:end if25:28:end while29:30:while |mutated| &lt; n p do▷ Mutation Phase31:i ← |mutated|32:35:else36:child ← c37:end if38:
16:if child ∈ population and τ ′ &lt; τ then τ ′ ← τ ′ + 1; Continue else τ ′ ← 0 ▷ Deduplicator 7:population, f itness ← population ∥ [candidate], f itness ∥ [FE(candidate)]population, f itness, errors ← Replacing ⌊n p • ρ⌋ candidates with EP ▷ EP Replay 15: selected ← SELECT(population, f itness, k e , |population| − k e ) ▷ Selection Phase 16: Update f itness, errors to align with selected 17: of f spring, os_f itness, os_errors, τ ′ ← [], [], [], 0 c 1 , c 2 , s 1 , s 2 , e 1 , e 2 ← RANDOMCHOICE(selected, f itness, errors) 20: if RD() &lt; η then ▷ Apply ECO or LCO , and RD() means x i.i.d.∼ U[0, 1] 21: child ← ECO(P, c 1 , c 2 , e 1 , e 2 ) if RD() &lt; ξ else LCO(P, c 1 , c 2 , s 1 , s 2 , e 1 , e 2 , llm) 22: else 23: child ← RANDOMCHOICE([c 1 , c 2 ]) if child ∈ of f spring and τ ′ &lt; τ then τ ′ ← τ ′ + 1; Continue else τ ′ ← 0 26: of f spring, os_f itness ← of f spring ∥ [child], os_f itness ∥ [F E(child)] 27: os_errors ← os_errors ∥ [ED(child, ϵ)] mutated, mt_f itness, mt_errors, τ ′ ← [], [], [], 0 c, e, s ← of f spring[i], errors[i], f itness[i] 33: if RD() &lt; κ then ▷ Apply EMO or LMO 34: child ← EMO(P, c, e) if RD() &lt; µ else LMO(P, c, s, e, llm)</p>
<p>Table 2 :
2
The results of all metrics for SK.1}) and O = {k, . . ., k + ECC(c)}.Hence, it replaces all color values ≥ k with random valid colors z ∈ {0, . . ., k − 1}.</p>
<p>where i ∈ {1, . .., |c|}, z i.i.d.∼ U({0, . . ., k −</p>
<p>Table 2, 3, and 4.
ModelMethodGC CRGC SCGC P SGC ECUGC CFDP07373027GPT-4o-MiniBoN08686014Lyria0979704DP07474026Qwen2.5:32B-InstructBoN08787013Lyria0969604DP01000120Mistral:7B-InstructBoN08684015Lyria0939207DP07373027Qwen2.5:7B-InstructBoN08484016Lyria0959505H PromptsPrompt Template 1: Sudoku LLM-BasedError Detector===Instructions===1. You are a Sudoku expert who can findthe errors in a sudoku candidate solution;2. Given this Sudoku puzzle and itscandidate solution, you should find theerrors in the candidate solution;3. The correctness of the solution dependson:(1) Correct Syntax: it has a correct format,meaning each row, column, and{subgrid_size}x{subgrid_size} squareexactly contain {puzzle_grid_size} number,and each cell is separated by space. Thesolution format must be in the same formatas the given puzzle but there is no unfilleddot;(2) Correct Semantics: for each row,column, and {subgrid_size}x{subgrid_size}square, the numbers 1 to {puzzle_grid_size}should appear exactly once;4. If the syntax is incorrect, the errorsshould be "Syntax is wrong" (Noted asType 1 Error Msg);5. If the syntax is correct, the errors shouldbe the positions of the wrong numbers inthe candidate solution with its conflict type,"row", "col", or "subgrid" (Noted as Type 2Error Msg);</p>
<p>Table 3 :
3
The results of all metrics for GC.
ModelMethodTSP CRTSP P STSP EDMTSP M CDP0790.640GPT-4o-MiniBoN4940.180Lyria6960.130DP0810.580Qwen2.5:32B-InstructBoN8970.090Lyria30990.040DP0601.202Mistral:7B-InstructBoN0800.610Lyria0890.310DP0341.975Qwen2.5:7B-InstructBoN0880.360Lyria4950.150</p>
<p>Table 4 :
4
The results of all metrics for TSP.
6. You should find all the errors in thecandidate solution;7. If there are no errors, the errors should be"No errors" (Noted as Type 3 Error Msg);8. You can think it thoroughly in any wayyou want, but You MUST give the errors inthe end of your thinking in the format as:</p>
<p>Think it carefully and do NOT randomly guess the score; 8.You can think it thoroughly in any way you want, but You MUST give the score as a float number in the end of your thinking.
<code>àdjacency_matrix_str</code>===Candidate Solution===<code>{candidate}</code>Prompt Template 6: Travel Salesman Prob-lem LLM-based Fitness Evaluator===Instructions===1. You are a Travel Salesman Problemexpert who can evaluate whether a TSPcandidate solution is correct or not, or howclose it is to the correct solution;2. Given this Traveling Salesman Problempuzzle:===Graph Adjacency Matrix===</p>
<p>Now, keep the score and errors in mind and think about how to change the candidate to create a new candidate solution that is better than the original candidate.You can think in any way but you must finally give a candidate solution wrapped in triple backticks as a code block in the same format as the puzzle:
10. You can give thinking steps or 100.0 means the candidate is correct)make it good, aiming at creating a newexplanation before or after code block but Errors of Candidate Solution:candidate solution which can be better thanyou MUST NOT give any comments or {error}the original candidate and approach more toexplanations in the code block;the correct solution;===Distance Matrix===4. If you think it is not necessary to change<code>{the candidate, you can also give a newdistance_matrix}candidate solution which is totally different</code>=from the original candidate, aiming at==Candidate Solution 1===approaching more to the correct solution;<code>{5. After mutation, the solution shouldc1}approach or become correct, which means:</code>S(1) Correct Syntax: it has a correct format,core of Candidate Solution 1: {s1} (0.0meaning each row, column, andmeans the candidate is wrong at all while{subgrid_size}x{subgrid_size} square100.0 means the candidate is correct) Prompt Template 11: Graph Coloring LMOexactly contain {puzzle_grid_size} number,Errors of Candidate Solution 1:and each cell is separated by space. The{c1_error} ===Instructions===solution format must be in the same format===Candidate Solution 2=== 1. Given this Graph Coloring puzzle:as the given puzzle but there is no unfilled<code>{dot;c2}(2) Correct Semantics: for each row,</code>Scolumn, and {subgrid_size}x{subgrid_size}core of Candidate Solution 2: {s2} (0.0square, the numbers 1 to {puzzle_grid_size}means the candidate is wrong at all whileshould appear exactly once;100.0 means the candidate is correct)6. You should check the syntax carefully. IfErrors of Candidate Solution 2:the syntax is incorrect, you should give a{c2_error}new solution which obey the rule "correctsyntax";Now, keep the scores and errors in mind7. You should check the semantics carefully.and think about how to combine the twoIf the semantics is incorrect, you shouldcandidates to create a new candidategive a new solution which obey the rulesolution that is better than the original2) Correct Semantics: "correct semantics";candidates.a. No missing city: the path should visit 8. You can think whatever way you want,You can think in any way but you musteach city exactly once and return to the but at the end of thinking, the final solutionfinally give a candidate solution as a list oforigin city; should be given and written in the sameintegers separated by comma wrapped inb. Optimal path: the path should be the format as the puzzle wrapped in tripletriple backticks as a code block:shortest path; backticks as a code block;7. You should check the syntax carefully. If 9. You can give thinking steps orthe syntax is incorrect, you should give a explanation before or after code block butPrompt Template 10: Sudoku LMOnew solution which obey the rule "correct you MUST NOT give any comments orsyntax"; explanations in the code block;===Instructions===8. You should check the semantics carefully. ===Sudoku Puzzle===1. Given this Sudoku puzzle and this Sudoku candidate solution, you shouldIf the semantics is incorrect, you should give a new solution which obey the rule <code>{ puzzle}thoroughly think about the good and bad parts of the candidate and whether it is a"correct semantics"; 9. You can think whatever way you want,</code>= ==Candidate Solution===correct solution to the puzzle; 2. If you think the candidate is alreadybut at the end of thinking, the final solution should be given and written in a list of <code>{ candidate}correct, you can give the correct solution directly;integers separated by comma wrapped in triple backticks as a code block;</code>S core of Candidate Solution: {score} (0.03. If you think the candidate has bad parts,means the candidate is wrong at all whileyou can change or improve the bad parts to</p>
<ol>
<li>You should check the syntax carefully.If the syntax is incorrect, you should give a new solution which obey the rule "correct syntax"; 8.You should check the semantics carefully.If the semantics is incorrect, you should give a new solution which obey the rule "correct semantics"; 9.You can think whatever way you want, but at the end of thinking, the final solution should be given and written in a list of integers separated by comma wrapped in triple backticks as a code block; 10.You can give thinking steps or explanation before or after code block but you MUST NOT give any comments or explanations in the code block; Now, keep the score and errors in mind and think about how to change the candidate to create a new candidate solution that is better than the original candidate.You can think in any way but you must finally give a candidate solution as a list of integers separated by comma wrapped in triple backticks as a code block:
===Graph Adjacency Matrix===<code>{adjacency_matrix}</code>===Candidate Solution===<code>{candidate}</code>Score of Candidate Solution: {score} (0.0means the candidate is wrong at all while100.0 means the candidate is correct)Errors of Candidate Solution:{error}Prompt Template 12: Travel Salesman Prob-lem LMO===Instructions===1. Given this Traveling Salesman Problempuzzle:</li>
</ol>
<p>2) Correct Semantics: a.No missing city: the path should visit each city exactly once and return to the origin city; b.Optimal path: the path should be the shortest path; 7.You should check the syntax carefully.If the syntax is incorrect, you should give a new solution which obey the rule "correct syntax"; 8.You should check the semantics carefully.If the semantics is incorrect, you should give a new solution which obey the rule "correct semantics"; 9.You can think whatever way you want, but at the end of thinking, the final solution should be given and written in a list of integers separated by comma wrapped in triple backticks as a code block; 10.You can give thinking steps or explanation before or after code block but you MUST NOT give any comments or explanations in the code block; core of Candidate Solution: {score} (0.0 means the candidate is wrong at all while 100.0 means the candidate is correct) Errors of Candidate Solution: {error} Now, keep the score and errors in mind and think about how to change the candidate to create a new candidate solution that is better than the original candidate.You can think in any way but you must finally give a candidate solution as a list of integers separated by comma wrapped in triple backticks as a code block: Correct Syntax: it has a correct format, meaning each row, column, and {subgrid_size}x{subgrid_size} square exactly contain {puzzle_grid_size} number, and each cell is separated by space.The solution format must be in the same format c. the index of city should be in the range from 0 to {n_cities -1}; (2) Correct Semantics: a.No missing city: the path should visit each city exactly once and return to the origin city; b.Optimal path: the path should be the shortest path; 3.You should check the syntax carefully.If the syntax is incorrect, you should give a new solution which obey the rule "correct syntax"; 4.You should check the semantics carefully.If the semantics is incorrect, you should give a new solution which obey the rule "correct semantics"; 5.You can think whatever way you want, but at the end of thinking, the final solution should be given and written in a list of integers separated by comma wrapped in triple backticks as a code block; 6.You can give thinking steps or explanation before or after code but you MUST NOT give any comments or explanations in the code block;
===Distance Matrix===<code>{distance_matrix}</code>===Candidate Solution===<code>{candidate}</code>SPrompt Template 13: Sudoku Direct Prompting ===Instructions=== 1. Given this Sudoku puzzle, you should fill in the missing numbers represented by dots; 2. The solution should be correct, which means: (1) ===Distance Matrix=== ``{ distance_matrix} ```2
Results of all metrics for each problem type is shown in Appendix G.
Takayuki Yato and Takahiro Seta. 2003. Complexity and completeness of finding another solution and its application to puzzles. IEICE transactions on fundamentals of electronics, communications and computer sciences, 86(5):1052-1060.
as the given puzzle but there is no unfilled dot;(2) Correct Semantics: for each row, column, and {subgrid_size}x{subgrid_size} square, the numbers 1 to {puzzle_grid_size} should appear exactly once; 3. The puzzle is guaranteed to have a unique solution; 4.You should check the syntax carefully.(1) The graph is represented by the adjacency matrix with {n_vertices} vertices, in which "y" means the two vertices are adjacent and "n" means the two vertices are not adjacent;(2) The goal is to color the vertices with {color_count} colors such that no two adjacent vertices have the same color; 2. The solution should be correct, which means:(1) Correct Syntax: the solution should be a list of {n_vertices} integers separated by comma such as "0,1,2", each integer represents the color of the corresponding vertex, and the colors should be integers from 0 to {color_count -1};(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should be different; (1) The distance matrix is a 2D matrix with {n_cities} rows and {n_cities} columns, in which each element represents the distance of traveling from the city in the row to the city in the column;(2) The goal is to find the shortest path that visits each city exactly once and returns to the origin city; 2. The solution should be correct, which means:(1) Correct Syntax: a. the solution should be a list of {n_cities} integers separated by comma such as "0,1,2", each integer represents the index of the city in the path, and the indexes should be integers from 0 to {n_cities -1}; b. the first and last city should be the same and should be 0, which means the path should return to the origin city which is 0;
. Metaheuristics Handbook, 10.1007/978-3-319-91086-4International Series in Operations Research &amp; Management Science. 272Springer International Publishing</p>
<p>Logic guided genetic algorithms. Dhananjay Ashok, Joseph Scott, Sebastian , Johann Wetzel, Maysum Panju, Vijay Ganesh, ArXiv, abs/2010.113282020</p>
<p>Evolving form and function: Dualobjective optimization in neural symbolic regression networks. Amanda Bertschinger, James Bagrow, Joshua Bongard, 10.1145/3638529.3654030Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '24. the Genetic and Evolutionary Computation Conference, GECCO '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Plancritic: Formal planning with human feedback. Owen Burns, Dana Hughes, Katia Sycara, arXiv:2412.003002024Preprint</p>
<p>Quality and diversity optimization: A unifying modular framework. Antoine Cully, Yiannis Demiris, IEEE Transactions on Evolutionary Computation. 2222017</p>
<p>Genetic algorithm for dynamic path planning. A Elshamli, H A Abdullah, S Areibi, 10.1109/CCECE.2004.1345203Canadian Conference on Electrical and Computer Engineering. 2004. 20042</p>
<p>Complexity of n-queens completion. Ian P Gent, Christopher Jefferson, Peter Nightingale, Journal of Artificial Intelligence Research. 592017</p>
<p>Connecting large language models with evolutionary algorithms yields powerful prompt optimizers. Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang, arXiv:2309.085322024Preprint</p>
<p>An optimized case-based software project effort estimation using genetic algorithm. Shaima Hameed, Yousef Elsheikh, Mohammad Azzeh, formation and Software Technology. 1531070882023</p>
<p>Evolving code with a large language model. Erik Hemberg, Stephen Moskal, Una-May O' Reilly, Genetic Programming and Evolvable Machines. 252212024</p>
<p>A survey on large language models for code generation. Juyong Jiang, Fan Wang, Jiasi Shen, Sungju Kim, Sunghun Kim, arXiv:2406.005152024Preprint</p>
<p>A review on genetic algorithm: past, present, and future. Multimedia Tools and Applications. Sourabh Katoch, Sumit Singh Chauhan, Vijay Ku, 10.1007/s11042-020-10139-6mar. 202180</p>
<p>Evolutionary algorithms in combinatorial optimizationEvolutionary Algorithms in Combinatorial Optimization. Daniel Kobler, 10.1007/978-0-387-74759-0_1672009Springer USBoston, MA</p>
<p>Genetic programming as a means for programming computers by natural selection. Johnr, Koza, 10.1007/BF00175355Statistics and Computing. 421994</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, Peter Clark, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Large language models: A survey. Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, Jianfeng Gao, arXiv:2402.061962025Preprint</p>
<p>Fcorebench: Can large language models solve challenging first-order combinatorial reasoning problems?. Chinmay Mittal, Krishna Kartik, Parag Mausam, Singla, arXiv:2402.026112025Preprint</p>
<p>Llm guided evolution -the automation of models advancing models. Clint Morris, Michael Jurado, Jason Zutty, 10.1145/3638529.3654178Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '24. the Genetic and Evolutionary Computation Conference, GECCO '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Llmatic: Neural architecture search via large language models and quality diversity optimization. Sam Muhammad Umair Nasir, Julian Earle, Steven Togelius, Christopher James, Cleghorn, 10.1145/3638529.3654017Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '24. the Genetic and Evolutionary Computation Conference, GECCO '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Logic-LM: Empowering large language models with symbolic solvers for faithful logical reasoning. Liangming Pan, Alon Albalak, Xinyi Wang, William Wang, 10.18653/v1/2023.findings-emnlp.248Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023</p>
<p>Some complexity results for the traveling salesman problem. Christos H Papadimitriou, Kenneth Steiglitz, 10.1145/800113.803625Proceedings of the Eighth Annual ACM Symposium on Theory of Computing, STOC '76. the Eighth Annual ACM Symposium on Theory of Computing, STOC '76New York, NY, USAAssociation for Computing Machinery1976</p>
<p>Enhancing large language models-based code generation by leveraging genetic improvement. Giovanni Pinna, Damiano Ravalico, Luigi Rovito, Luca Manzoni, Andrea De Lorenzo, Genetic Programming. ChamSpringer Nature Switzerland2024</p>
<p>Quality diversity: A new frontier for evolutionary computation. Justin K Pugh, Lisa B Soros, Kenneth O Stanley, Frontiers in Robotics and AI. 3402016</p>
<p>Breeding theorem proving heuristics with genetic algorithms. Simon Schäfer, Stephan Schulz, GCAI. Citeseer2015</p>
<p>Multi-objective neural evolutionary algorithm for combinatorial optimization problems. Yinan Shao, Jerry , Chun-Wei Lin, Gautam Srivastava, Dongdong Guo, Hongchun Zhang, Hu Yi, Alireza Jolfaei, 10.1109/TNNLS.2021.3105937IEEE Transactions on Neural Networks and Learning Systems. 3442023</p>
<p>Reflexion: language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Lean copilot: Large language models as copilots for theorem proving in lean. Peiyang Song, Kaiyu Yang, Anima Anandkumar, arXiv:2404.125342025Preprint</p>
<p>Using genetic algorithms for learning clauses in first-order logic. Alireza Tamaddoni, -Nezhad , Stephen Muggleton, Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation. the 3rd Annual Conference on Genetic and Evolutionary Computation2001</p>
<p>Tom-lm: Delegating theory of mind reasoning to external symbolic executors in large language models. Weizhi Tang, Vaishak Belle, 10.1007/978-3-031-71170-1_20Neural-Symbolic Learning and Reasoning: 18th International Conference. NeSy; Barcelona, Spain; Berlin, HeidelbergSpringer-Verlag2024. 2024. September 9-12, 2024Proceedings, Part II</p>
<p>Large language models are in-context semantic reasoners rather than symbolic reasoners. Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, Muhan Zhang, arXiv:2305.148252023arXiv preprint</p>
<p>On the planning abilities of large language models: a critical investigation. Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, Subbarao Kambhampati, Proceedings of the 37th International Conference on Neural Information Processing Systems, NIPS '23. the 37th International Conference on Neural Information Processing Systems, NIPS '23Red Hook, NY, USACurran Associates Inc2023</p>            </div>
        </div>

    </div>
</body>
</html>