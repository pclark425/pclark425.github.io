<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2211 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2211</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2211</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-58.html">extraction-schema-58</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <p><strong>Paper ID:</strong> paper-278739825</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.12039v1.pdf" target="_blank">AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research</a></p>
                <p><strong>Paper Abstract:</strong> The Science of Science (SoS) explores the mechanisms underlying scientific discovery, and offers valuable insights for enhancing scientific efficiency and fostering innovation. Traditional approaches often rely on simplistic assumptions and basic statistical tools, such as linear regression and rule-based simulations, which struggle to capture the complexity and scale of modern research ecosystems. The advent of artificial intelligence (AI) presents a transformative opportunity for the next generation of SoS, enabling the automation of large-scale pattern discovery and uncovering insights previously unattainable. This paper offers a forward-looking perspective on the integration of Science of Science with AI for automated research pattern discovery and highlights key open challenges that could greatly benefit from AI. We outline the advantages of AI over traditional methods, discuss potential limitations, and propose pathways to overcome them. Additionally, we present a preliminary multi-agent system as an illustrative example to simulate research societies, showcasing AI's ability to replicate real-world research patterns and accelerate progress in Science of Science research.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2211.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2211.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based multi-agent simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Preliminary LLM-based Multi-Agent Scientific Society Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end, LLM-driven multi-agent system that simulates scientist agents who form teams, generate ideas, write abstracts, undergo peer review, publish, and accrue citations; used in this paper as a proof-of-concept to reproduce population-level Science-of-Science (SoS) patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>LLM-based multi-agent system (preliminary AI4SoS simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Science of Science / Computational Social Science</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>low-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is performed by computational comparison of population-level outputs (citation counts, correlations between citation and diversity/ranking metrics) from the simulated society against historical bibliometric data (Open Academic Graph papers from 2010–2011). The simulation includes a peer-review loop (3 reviewers per paper; acceptance threshold score >5), citation updates when agents retrieve references during idea generation, and embedding-based retrieval (mxbai-embedlarge). Statistical correlations and p-values are used to compare simulated vs. real-world patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Low-to-moderate fidelity: social/scientific behaviors are approximated via LLM agents (LLaMA3.1-8b) rather than detailed mechanistic models; no physical/biological physics is modeled. Approximations include simplified agent memory (max 5 entries), capped references per utterance (up to 9), exponential sampling of team sizes, and omission of detailed funding/policy mechanisms and internal cognitive processes. Fidelity is sufficient to reproduce some high-level bibliometric correlations but not fine-grained causal mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Simulation outputs were compared to empirical bibliometric data from 2010 and 2011. The simulator reproduced positive correlations between citation counts and ethnicity diversity and negative correlations with affiliation ranking, but correlations were weaker than in real data. Some simulated relationships (e.g., affiliation diversity vs. citations) were not statistically significant (p > 0.05). No numerical goodness-of-fit metrics beyond reported correlation trends and p-values are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported as a percentage. Qualitatively: several real-world correlations were partially reproduced (success in directionality), but effect sizes were weaker and some results were non-significant (e.g., affiliation diversity correlation had p > 0.05).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper argues SoS validation should be multidimensional and domain-specific: use scientometric measures (citation counts, h-index), expert peer review, time-series/longitudinal analysis, and simulation-to-historical-data comparisons. No single unified standard exists; authors call for integrating scientometrics, expert review, longitudinal tracking, and ethical benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors propose simulation may be sufficient for hypothesis generation, sandboxing policy experiments, and long-term scenario analysis when (a) the simulator is carefully calibrated against historical data, (b) key real-world factors (timelines, agent heterogeneity) are modeled, and (c) uncertainty and biases are characterized; however, they caution simulations alone are insufficient for definitive empirical claims without careful calibration and explainability.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper documents weaker-than-real correlations and at least one non-significant relationship (affiliation diversity vs. citations). It also notes missing components (realistic funding and policy influences, richer individual career models) that likely cause discrepancies and limit realism.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Limited: authors report statistical significance testing (p-values) for correlations and recommend Z-score calculations and model-based peer-review scoring for novelty assessment, but no comprehensive uncertainty quantification (e.g., confidence intervals around simulated trajectories or ensemble/model variance reports) is provided for the simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly implemented. The paper suggests anomaly detection / unsupervised learning to detect deviations in simulation, and recommends transparency and ethical benchmarks to detect problematic/ fabricated outputs, but does not provide a concrete fabrication-detection pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computational validation cost/time reported: implementation used 32 NVIDIA A100 GPUs (4 ports per GPU) running LLaMA3.1-8b, and a million-agent simulation required approximately one week. No physical experimental costs are reported because no laboratory experiments were performed.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Authors acknowledge key limitations: incomplete modeling of individual trajectories, absence of funding/policy mechanisms, imperfect agent cognition emulation, potential bias amplification (e.g., 'rich get richer'), and lack of comprehensive uncertainty quantification. They stress the simulation is preliminary and needs more components for rigorous validation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues credibility requires multidimensional evaluation and human expert involvement; simulations that reproduce known empirical patterns increase credibility but full community acceptance demands transparency, explainability (causal inference/XAI), and domain expert validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Compared simulated outputs to historical bibliometric records (OAG 2010–2011) as the de-facto gold standard. Agreement was partial (directional matches) but effect sizes were weaker and some relations lacked statistical significance; no explicit numerical performance metrics (e.g., RMSE) against gold-standard time-series are provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2211.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Empirical comparison validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Computational validation via comparison to historical bibliometric data (2010–2011)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A validation approach where outputs of the AI-driven simulation are compared against historical real-world bibliometric records (Open Academic Graph 2010–2011) using scientometric metrics and statistical tests to assess whether simulated patterns match observed patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Historical-data computational validation (bibliometric comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Science of Science / Bibliometrics</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Paper uses bibliometric benchmarks (OAG 2002–2009 as reference database; 2010–2011 as validation database). Validation metrics include citation counts, correlation analyses between citation count and variables (ethnicity diversity, affiliation diversity, affiliation ranking), p-values for statistical significance, and comparisons of scatterplots between real and simulated datasets. The peer-review acceptance and citation update mechanisms in simulation create synthetic time-series for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable: method is a validation procedure rather than a physics-based simulation; relies on historical bibliometric data fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Direct computational comparison (simulation vs. historic bibliometrics). Results: qualitative alignment in direction of correlations (e.g., higher ethnicity diversity associated with higher citations) but weaker effect sizes in simulation and some non-significant results (p > 0.05 for affiliation diversity). No numeric overall accuracy score reported.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not provided as a fraction; the paper reports partial reproduction of known patterns (directional agreement) but weaker magnitude and some non-significant relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper endorses scientometric benchmarks (citation counts, h-index, Z-score for novelty) and recommends incorporating domain expert review and long-term simulations to meet validation standards in SoS.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Paper implies simulation validated by matching multiple independent empirical patterns across datasets and years (2010 and 2011) may be considered sufficiently validated for hypothesis-generation and policy sandboxing, but emphasizes need for further modeling completeness.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Observed weaker correlations compared to historical data; inability to reproduce significance in some relationships; missing real-world mechanisms expected to cause failures.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Uses classical statistical testing (p-values) for correlation significance; recommends Z-scores and model-based peer-review scoring, but lacks comprehensive propagation-of-uncertainty analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not explicitly discussed for this validation method; computational comparison can reveal mismatches but does not address detection of fabricated papers or outputs beyond statistical discrepancies.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computational costs limited to simulation and analysis; historical data used are large (OAG tens of millions of records) but no explicit processing-time metrics are given for the validation step alone.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Relies on quality and completeness of bibliometric databases; sensitive to missing metadata (author ethnicity, fields) which authors filled using classifiers and heuristics — these imputations introduce uncertainty. Also, reproduction of aggregate correlations does not prove causal correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues that reproducing known empirical regularities bolsters system credibility, but community acceptance requires interpretability, expert confirmation, and addressing biases from training data and imputed metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Historical bibliometric records are treated as the gold standard; the paper reports qualitative agreement but no comprehensive quantitative performance metrics (e.g., effect-size differences) beyond mentioning weaker correlations and p-values.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2211.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Peer-review simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulated Peer-Review and Indexing System (scored peer review within simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulated peer-review pipeline in which each agent-generated paper is reviewed by three reviewers and scored 1–10; papers scoring above a threshold (score > 5) are accepted and added to the reference database, enabling downstream citation dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>In-simulation peer-review scoring</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Science of Science / Scholarly Publishing Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>The peer-review module serves as an internal validation gate: each simulated paper receives three reviewer scores based on multidisciplinary guidelines adapted from NeurIPS reviewing criteria (originality, quality, clarity, significance, ethics). Acceptance threshold is score > 5. Accepted papers are indexed and can be cited by agents, enabling endogenous validation via citation accumulation compared against real-world citation patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Simplified: reviewer behavior is emulated via LLM agents following provided reviewer guidelines; peer review is modeled as numeric scoring without full meta-review processes; cross-disciplinary nuance captured via adapted guidelines but not domain-expert adjudication.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Functionally, accepted simulated papers contribute to citation dynamics evaluated against empirical data. The paper does not report separate validation of the peer-review model against real-world peer-review outcomes (e.g., acceptance rates, reviewer variability).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported numerically; peer-review module enabled generation of simulated publications whose citation behaviors were then analyzed for alignment to historical patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors adopt and adapt established conference review criteria (NeurIPS-style multi-item scoring) as the simulation standard and recommend multidisciplinary reviewer prompts and ethical question checks for validity.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>The peer-review simulation is sufficient as an internal publication filter for generating plausible bibliometric dynamics when reviewer behavior is well-calibrated and scoring criteria align with real-world venues; authors caution that without real-world reviewer variability and domain expertise, the module is an approximation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No explicit empirical benchmarking of simulated reviewer behavior vs. actual reviewer scores; risk that LLM reviewers follow different scoring distributions and may bias acceptance in ways not reflective of real venues.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Peer-review scores are numeric and used deterministically in acceptance; no probabilistic model of reviewer noise or inter-reviewer variance is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Peer-review criteria include ethics checks but do not implement automated fabrication detection (e.g., plagiarism or AI-generated text detection) in the simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Peer review is simulated within the agent system; computational overhead not separated from overall simulation costs. Each paper receives three reviews; timeline mapping allows for multi-epoch review cycles (one action per epoch).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Reviewer emulation via LLMs may not capture true diversity of expertise and decision-making; cross-disciplinary evaluations are approximated by adapted prompts but lack real domain-expert adjudication, limiting external validity.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper posits that including a peer-review step improves realism and credibility of simulated publications, but stresses that community acceptance requires calibration to actual reviewer behavior and external human validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison to real-world peer-review score distributions or acceptance rates is presented; gold-standard peer review is not used for benchmarking in this study.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2211.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scientometric metrics validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scientometric quantitative validation (citation counts, h-index, Z-score)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of established scientometric measures — primarily citation counts, with suggestions to use h-index for career-level impact and Z-scores for novelty/impact evaluation — to validate AI-generated outputs and simulated patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Scientometric metric-based validation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Bibliometrics / Science of Science</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>The paper uses citation count as the primary metric to measure impact of simulated papers; it recommends using h-index for individual career simulation validation and Z-scores (journal pairing Z-scores) or large-model-based peer-review scoring to assess novelty. These quantitative metrics are suggested as objective comparators between simulation outputs and real-world data.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable (metrics-based validation). Metrics are applied to both simulated and historical datasets; fidelity depends on accuracy of the underlying simulation and completeness of metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Citation counts from the simulation are compared to real-world citation distributions and correlations; results match directionally but differ in effect strength.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not provided as a percentage; metrics reveal partial reproduction of empirical patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper states scientometrics (citations, h-index) are standard domain-accepted measures but acknowledges their limitations and suggests complementing them with expert review and diversified metrics to avoid overreliance on traditional measures.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Simulation validated via multiple scientometric metrics and across multiple years/datasets may be sufficient for certain SoS analyses (trend detection, policy sandboxing) but not for causal attribution without additional causal analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Reliance on citation metrics can misrepresent novelty and quality; simulation that matches citation patterns does not ensure causal fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Statistical tests (p-values) on correlations are reported; authors suggest model-based peer-review scoring and Z-scores to quantify novelty but do not present calibrated uncertainty intervals for metric estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>No explicit metric-based fabrication detection is implemented; however, deviations in citation patterns and anomalous metric values could indicate fabricated outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computationally inexpensive compared to simulation itself — computing citation counts and h-index on large datasets is scalable but depends on dataset size; no explicit timing given.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Authors note traditional scientometric metrics are insufficient alone, can be biased, and may incentivize mainstream topics; recommend diversified metrics and expert review.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Using established scientometric metrics facilitates communication with the SoS community and provides an initial credibility baseline, but acceptance requires addressing metric limitations and adding interpretability and domain-expert validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Citation counts and h-index are treated as standard evaluation metrics (de facto gold standards in scientometrics); simulation reproduces some aggregate behaviors but quantitative discrepancies remain.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2211.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Timeline calibration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Temporal calibration / timeline alignment techniques for simulations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposed dynamic calibration methods to align simulation epochs with real-world time and events, ensuring that simulated timelines map meaningfully to calendar years for longitudinal validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Dynamic timeline calibration for agent-based simulations</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Agent-based modeling / Computational Social Science</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>The paper suggests building flexible, event-driven calibration methods that adjust the simulation's temporal parameters based on context and real-world event data (e.g., calibrate how many simulation epochs equal one real year). Calibration may use historical event markers and timeline-dependent statistics to align simulated outputs with empirical time series.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable (procedural calibration technique). The calibration improves apparent fidelity by synchronizing simulated events with historical temporal patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not performed in this paper beyond general discussion; timeline alignment is proposed as a pathway to improve simulation-to-history comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors recommend explicit calibration as necessary for longitudinal validation in SoS; no single standardized method is prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Timeline calibration is considered necessary for simulations to be sufficient for longitudinal claims; without it, temporal comparisons to real-world data may be misleading.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper notes misaligned timelines can produce incorrect mapping between simulated epochs and real-world evolution, reducing validity of temporal comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>No specific UQ method described for timeline calibration; authors recommend dynamic calibration techniques responsive to event-driven data.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Not quantified; calibration adds computational/analytical overhead but specifics depend on chosen calibration method and data.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Authors note difficulty in selecting appropriate correspondence between simulated epochs and real time and that calibration is non-trivial when unobservable factors influence dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Proper calibration is framed as important for credible temporal validation; lack of it undermines confidence in longitudinal simulation claims.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison provided; calibration is a recommended step toward matching simulations to historical gold-standard time-series.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2211.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Anomaly detection for simulation stability</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unsupervised anomaly detection to monitor and adjust simulations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed pathway using unsupervised learning (e.g., clustering) to identify deviations from expected agent behaviors and adjust simulation parameters to ensure stability and continuity of long-running simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Unsupervised anomaly detection (clustering-based) for agent simulations</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine Learning / Simulation Monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors propose using unsupervised methods (clustering) to detect deviations from expected behavior trajectories in the simulation; upon detection, simulation parameters would be adjusted to recover stable behavior. This is a proposed operational validation technique for long-running, automated SoS simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>None provided; proposal intended to maintain internal simulation validity rather than compare to experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Presented as a practical engineering safeguard rather than a domain-standard validation approach; authors cite anomaly detection as part of ensuring continuous operation of automated discovery systems.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Anomaly detection helps make long-term simulations reliable; sufficiency depends on detection sensitivity, false-positive rates, and corrective policies.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No concrete failure cases are reported, but authors warn that without mechanisms to handle unexpected exceptions, continuous automated discovery could break.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not detailed; anomaly detection would typically yield anomaly scores but the paper does not specify thresholds or confidence measures.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly targeted at fabrication detection; could help surface abnormal outputs suggestive of fabrication but not a dedicated approach.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Not quantified; anomaly detection introduces additional compute for monitoring and potential reruns.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Authors acknowledge that anomaly detection cannot replace principled model validation and that corrective adjustments may mask deeper model misspecifications.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Operational anomaly detection increases system robustness but does not by itself satisfy scientific community expectations for validation or explainability.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2211.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal & XAI validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal inference and Explainable AI methods for validating AI-driven SoS outputs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper recommends applying causal modeling (e.g., Propensity Score Matching, Coarsened Exact Matching, SEM) and explainable AI techniques (counterfactual analysis, causal graphical models) to interpret and validate simulation results and AI-generated recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Causal inference and XAI (PSM, CEM, SEM, counterfactuals)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Causal Inference / Explainable AI / Science of Science</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors propose integrating causal methods (PSM, CEM, structural equation modeling, causal graphical models) and XAI techniques (counterfactual analysis) to make AI-driven outputs auditable, interpretable, and to clarify causal pathways behind recommendations. These are proposed as validation layers that complement correlation-based checks.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>No direct applications are reported in the paper; methods are proposed to improve interpretability and causal validation of future simulations and AI outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable / not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper stresses the need for causal analysis in SoS to move beyond correlation; suggests established causal methods as domain-appropriate tools for robust validation and policy-relevant claims.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Authors imply that simulation outputs supplemented by causal modeling and XAI can be treated as stronger evidence, particularly when counterfactuals and matched observational strategies produce consistent findings; still, they do not claim simulation alone suffices for causal claims.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No concrete counterexamples provided where causal/XAI reversed simulation findings, but the authors caution that correlations without causal analysis undermine trust.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Causal inference methods typically yield effect estimates and confidence intervals; paper recommends these but does not present applied interval estimates within the study.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly addressed; causal inconsistency could flag suspicious outputs but no explicit fabrication-detection pipeline proposed here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Applying causal methods requires high-quality labeled data and domain expertise; authors do not quantify costs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Causal methods require careful identification strategies and often stronger assumptions (e.g., no unmeasured confounding); authors note the complex, multivariate nature of SoS makes causal identification challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues that adding causal and explainable analyses is key to community acceptance and policy adoption of AI4SoS results.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison; causal/XAI methods are recommended as complementary to gold-standard practices like controlled experiments when those are infeasible.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2211.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ethical benchmarks & transparency</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ethical benchmarks, alignment, and transparency for validation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Discussion of ethical evaluation, transparency, and alignment techniques as part of validation — including use of ethical benchmarks to evaluate societal impacts and alignment procedures to improve trustworthiness of AI-generated SoS outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Ethical benchmarks and transparency mechanisms</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>AI Ethics / Science Policy</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors recommend ethical benchmarks (citations to existing benchmarks), alignment of model preferences, transparency measures (recording decision-making pathways), and human oversight as validation of social and ethical acceptability. They cite moral/ethical benchmark works (e.g., LocalValueBench, MoralBench) as relevant evaluation tools.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Not applicable. Ethical benchmarks are suggested as a complementary validation axis, not as an empirical comparison to experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable / not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors advocate integrating ethical benchmarks and alignment testing into validation frameworks for AI4SoS; refer to community standards and recent benchmark efforts as references.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Simulations addressing ethical concerns with benchmarking and human oversight may be acceptable for policy sandboxing, but authors stress ongoing oversight is necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>No specific cases, but authors warn opacity and unexamined biases in training data risk producing ethically problematic outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Ethical evaluation is largely qualitative; authors recommend transparency and explainability to reduce epistemic uncertainty but do not prescribe quantitative uncertainty measures for ethics.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Ethical benchmarks and transparency can help surface credibility issues, but no concrete technical fabrication-detection method is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Implementing ethical benchmarks and transparency measures requires annotation, benchmarking runs, and human oversight; no quantitative cost provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Benchmarks may be incomplete, cultural/contextual, and evolve over time; ethical compliance does not guarantee empirical validity.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues ethical benchmarks and transparency are essential for public and community trust in AI4SoS outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison to a gold standard; ethical benchmarks serve as community-aligned standards rather than empirical gold standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2211.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2211.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multidimensional evaluation framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Proposed multidimensional evaluation framework combining scientometrics, expert review, time-series analysis, and ethical checks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recommended, composite validation scheme that integrates quantitative scientometric tests, domain expert assessments (peer review), longitudinal/time-series analyses, causal/XAI methods, and ethical benchmarks to robustly validate AI4SoS outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Multidimensional evaluation framework for AI4SoS</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Science of Science / Evaluation Methodology</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Authors propose assembling multiple validation axes: (1) quantitative scientometrics (citations, h-index, Z-scores), (2) human expert peer review and domain-specific metrics, (3) time-series and longitudinal tracking, (4) causal/XAI analyses to explain mechanisms, and (5) ethical benchmarks. The framework is intended to handle heterogeneity of SoS tasks and to provide both short-term and long-term validation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Not applicable; the framework is agnostic to simulation fidelity but requires simulation outputs to be compatible with multiple validation modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Framework calls for direct comparisons of simulation outputs to multiple empirical benchmarks and expert judgments; the paper implements portions (scientometric comparisons and peer-review simulations) but not the full hybrid framework.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td>Not applicable; framework is prescriptive rather than reporting success rates.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Authors argue no single standard suffices in SoS; propose the multidimensional framework as an emergent standard combining domain-specific and cross-cutting evaluation methods.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Under the framework, a simulation might be considered sufficient if it passes multiple validation axes: reproduces empirical patterns, obtains favorable expert review, has plausible causal explanations via XAI, and satisfies ethical benchmark checks.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Authors note that failing any major validation axis (e.g., poor empirical fit, lack of explainability, ethical failures) undermines overall validity.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Framework calls for adoption of statistical testing, Z-scores, model-based scoring, and longitudinal uncertainty analyses, but specific UQ pipelines are left to future work.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Framework recommends transparency and ethical benchmarks which could assist detection of fabricated or misleading outputs, but does not detail automated fabrication detection algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Hybrid validation is acknowledged to be resource-intensive: requires computational resources for simulation, domain expert time for reviews, and infrastructure for longitudinal tracking; authors provide a concrete example of simulation compute (32 A100 GPUs, 1 week for 1M agents) but not combined validation costs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Implementing a full multidimensional framework is costly and requires interdisciplinary collaboration; authors note data imbalance, bias, and missing model components remain obstacles to fully reliable validation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Authors present this framework as necessary to achieve community acceptance and policy relevance; argue that passing multiple validation axes is more persuasive than single-mode validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Framework recommends comparison to historical/empirical gold standards where available (e.g., OAG bibliometrics) and to domain expert consensus; no single gold standard is elevated above others.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation <em>(Rating: 2)</em></li>
                <li>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning <em>(Rating: 2)</em></li>
                <li>Oasis: Open agents social interaction simulations on one million agents <em>(Rating: 2)</em></li>
                <li>Large language models empowered agent-based modeling and simulation: A survey and perspectives <em>(Rating: 2)</em></li>
                <li>Choosing experiments to accelerate collective discovery <em>(Rating: 2)</em></li>
                <li>Calibrating real-world city traffic simulation model using vehicle speed data <em>(Rating: 1)</em></li>
                <li>On modeling and predicting individual paper citation count over time <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2211",
    "paper_id": "paper-278739825",
    "extraction_schema_id": "extraction-schema-58",
    "extracted_data": [
        {
            "name_short": "LLM-based multi-agent simulation",
            "name_full": "Preliminary LLM-based Multi-Agent Scientific Society Simulation",
            "brief_description": "An end-to-end, LLM-driven multi-agent system that simulates scientist agents who form teams, generate ideas, write abstracts, undergo peer review, publish, and accrue citations; used in this paper as a proof-of-concept to reproduce population-level Science-of-Science (SoS) patterns.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "LLM-based multi-agent system (preliminary AI4SoS simulator)",
            "scientific_domain": "Science of Science / Computational Social Science",
            "validation_type": "low-fidelity simulation",
            "validation_description": "Validation is performed by computational comparison of population-level outputs (citation counts, correlations between citation and diversity/ranking metrics) from the simulated society against historical bibliometric data (Open Academic Graph papers from 2010–2011). The simulation includes a peer-review loop (3 reviewers per paper; acceptance threshold score &gt;5), citation updates when agents retrieve references during idea generation, and embedding-based retrieval (mxbai-embedlarge). Statistical correlations and p-values are used to compare simulated vs. real-world patterns.",
            "simulation_fidelity": "Low-to-moderate fidelity: social/scientific behaviors are approximated via LLM agents (LLaMA3.1-8b) rather than detailed mechanistic models; no physical/biological physics is modeled. Approximations include simplified agent memory (max 5 entries), capped references per utterance (up to 9), exponential sampling of team sizes, and omission of detailed funding/policy mechanisms and internal cognitive processes. Fidelity is sufficient to reproduce some high-level bibliometric correlations but not fine-grained causal mechanisms.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Simulation outputs were compared to empirical bibliometric data from 2010 and 2011. The simulator reproduced positive correlations between citation counts and ethnicity diversity and negative correlations with affiliation ranking, but correlations were weaker than in real data. Some simulated relationships (e.g., affiliation diversity vs. citations) were not statistically significant (p &gt; 0.05). No numerical goodness-of-fit metrics beyond reported correlation trends and p-values are provided.",
            "validation_success_rate": "Not reported as a percentage. Qualitatively: several real-world correlations were partially reproduced (success in directionality), but effect sizes were weaker and some results were non-significant (e.g., affiliation diversity correlation had p &gt; 0.05).",
            "domain_validation_standards": "Paper argues SoS validation should be multidimensional and domain-specific: use scientometric measures (citation counts, h-index), expert peer review, time-series/longitudinal analysis, and simulation-to-historical-data comparisons. No single unified standard exists; authors call for integrating scientometrics, expert review, longitudinal tracking, and ethical benchmarks.",
            "when_simulation_sufficient": "Authors propose simulation may be sufficient for hypothesis generation, sandboxing policy experiments, and long-term scenario analysis when (a) the simulator is carefully calibrated against historical data, (b) key real-world factors (timelines, agent heterogeneity) are modeled, and (c) uncertainty and biases are characterized; however, they caution simulations alone are insufficient for definitive empirical claims without careful calibration and explainability.",
            "simulation_failures": "Paper documents weaker-than-real correlations and at least one non-significant relationship (affiliation diversity vs. citations). It also notes missing components (realistic funding and policy influences, richer individual career models) that likely cause discrepancies and limit realism.",
            "uncertainty_quantification": "Limited: authors report statistical significance testing (p-values) for correlations and recommend Z-score calculations and model-based peer-review scoring for novelty assessment, but no comprehensive uncertainty quantification (e.g., confidence intervals around simulated trajectories or ensemble/model variance reports) is provided for the simulations.",
            "fabrication_detection": "Not directly implemented. The paper suggests anomaly detection / unsupervised learning to detect deviations in simulation, and recommends transparency and ethical benchmarks to detect problematic/ fabricated outputs, but does not provide a concrete fabrication-detection pipeline.",
            "validation_cost_time": "Computational validation cost/time reported: implementation used 32 NVIDIA A100 GPUs (4 ports per GPU) running LLaMA3.1-8b, and a million-agent simulation required approximately one week. No physical experimental costs are reported because no laboratory experiments were performed.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Authors acknowledge key limitations: incomplete modeling of individual trajectories, absence of funding/policy mechanisms, imperfect agent cognition emulation, potential bias amplification (e.g., 'rich get richer'), and lack of comprehensive uncertainty quantification. They stress the simulation is preliminary and needs more components for rigorous validation.",
            "acceptance_credibility": "Paper argues credibility requires multidimensional evaluation and human expert involvement; simulations that reproduce known empirical patterns increase credibility but full community acceptance demands transparency, explainability (causal inference/XAI), and domain expert validation.",
            "comparison_to_gold_standard": "Compared simulated outputs to historical bibliometric records (OAG 2010–2011) as the de-facto gold standard. Agreement was partial (directional matches) but effect sizes were weaker and some relations lacked statistical significance; no explicit numerical performance metrics (e.g., RMSE) against gold-standard time-series are provided.",
            "uuid": "e2211.0"
        },
        {
            "name_short": "Empirical comparison validation",
            "name_full": "Computational validation via comparison to historical bibliometric data (2010–2011)",
            "brief_description": "A validation approach where outputs of the AI-driven simulation are compared against historical real-world bibliometric records (Open Academic Graph 2010–2011) using scientometric metrics and statistical tests to assess whether simulated patterns match observed patterns.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Historical-data computational validation (bibliometric comparison)",
            "scientific_domain": "Science of Science / Bibliometrics",
            "validation_type": "computational validation",
            "validation_description": "Paper uses bibliometric benchmarks (OAG 2002–2009 as reference database; 2010–2011 as validation database). Validation metrics include citation counts, correlation analyses between citation count and variables (ethnicity diversity, affiliation diversity, affiliation ranking), p-values for statistical significance, and comparisons of scatterplots between real and simulated datasets. The peer-review acceptance and citation update mechanisms in simulation create synthetic time-series for comparison.",
            "simulation_fidelity": "Not applicable: method is a validation procedure rather than a physics-based simulation; relies on historical bibliometric data fidelity.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Direct computational comparison (simulation vs. historic bibliometrics). Results: qualitative alignment in direction of correlations (e.g., higher ethnicity diversity associated with higher citations) but weaker effect sizes in simulation and some non-significant results (p &gt; 0.05 for affiliation diversity). No numeric overall accuracy score reported.",
            "validation_success_rate": "Not provided as a fraction; the paper reports partial reproduction of known patterns (directional agreement) but weaker magnitude and some non-significant relationships.",
            "domain_validation_standards": "Paper endorses scientometric benchmarks (citation counts, h-index, Z-score for novelty) and recommends incorporating domain expert review and long-term simulations to meet validation standards in SoS.",
            "when_simulation_sufficient": "Paper implies simulation validated by matching multiple independent empirical patterns across datasets and years (2010 and 2011) may be considered sufficiently validated for hypothesis-generation and policy sandboxing, but emphasizes need for further modeling completeness.",
            "simulation_failures": "Observed weaker correlations compared to historical data; inability to reproduce significance in some relationships; missing real-world mechanisms expected to cause failures.",
            "uncertainty_quantification": "Uses classical statistical testing (p-values) for correlation significance; recommends Z-scores and model-based peer-review scoring, but lacks comprehensive propagation-of-uncertainty analyses.",
            "fabrication_detection": "Not explicitly discussed for this validation method; computational comparison can reveal mismatches but does not address detection of fabricated papers or outputs beyond statistical discrepancies.",
            "validation_cost_time": "Computational costs limited to simulation and analysis; historical data used are large (OAG tens of millions of records) but no explicit processing-time metrics are given for the validation step alone.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Relies on quality and completeness of bibliometric databases; sensitive to missing metadata (author ethnicity, fields) which authors filled using classifiers and heuristics — these imputations introduce uncertainty. Also, reproduction of aggregate correlations does not prove causal correctness.",
            "acceptance_credibility": "Paper argues that reproducing known empirical regularities bolsters system credibility, but community acceptance requires interpretability, expert confirmation, and addressing biases from training data and imputed metadata.",
            "comparison_to_gold_standard": "Historical bibliometric records are treated as the gold standard; the paper reports qualitative agreement but no comprehensive quantitative performance metrics (e.g., effect-size differences) beyond mentioning weaker correlations and p-values.",
            "uuid": "e2211.1"
        },
        {
            "name_short": "Peer-review simulation",
            "name_full": "Simulated Peer-Review and Indexing System (scored peer review within simulation)",
            "brief_description": "A simulated peer-review pipeline in which each agent-generated paper is reviewed by three reviewers and scored 1–10; papers scoring above a threshold (score &gt; 5) are accepted and added to the reference database, enabling downstream citation dynamics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "In-simulation peer-review scoring",
            "scientific_domain": "Science of Science / Scholarly Publishing Simulation",
            "validation_type": "computational validation",
            "validation_description": "The peer-review module serves as an internal validation gate: each simulated paper receives three reviewer scores based on multidisciplinary guidelines adapted from NeurIPS reviewing criteria (originality, quality, clarity, significance, ethics). Acceptance threshold is score &gt; 5. Accepted papers are indexed and can be cited by agents, enabling endogenous validation via citation accumulation compared against real-world citation patterns.",
            "simulation_fidelity": "Simplified: reviewer behavior is emulated via LLM agents following provided reviewer guidelines; peer review is modeled as numeric scoring without full meta-review processes; cross-disciplinary nuance captured via adapted guidelines but not domain-expert adjudication.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Functionally, accepted simulated papers contribute to citation dynamics evaluated against empirical data. The paper does not report separate validation of the peer-review model against real-world peer-review outcomes (e.g., acceptance rates, reviewer variability).",
            "validation_success_rate": "Not reported numerically; peer-review module enabled generation of simulated publications whose citation behaviors were then analyzed for alignment to historical patterns.",
            "domain_validation_standards": "Authors adopt and adapt established conference review criteria (NeurIPS-style multi-item scoring) as the simulation standard and recommend multidisciplinary reviewer prompts and ethical question checks for validity.",
            "when_simulation_sufficient": "The peer-review simulation is sufficient as an internal publication filter for generating plausible bibliometric dynamics when reviewer behavior is well-calibrated and scoring criteria align with real-world venues; authors caution that without real-world reviewer variability and domain expertise, the module is an approximation.",
            "simulation_failures": "No explicit empirical benchmarking of simulated reviewer behavior vs. actual reviewer scores; risk that LLM reviewers follow different scoring distributions and may bias acceptance in ways not reflective of real venues.",
            "uncertainty_quantification": "Peer-review scores are numeric and used deterministically in acceptance; no probabilistic model of reviewer noise or inter-reviewer variance is reported.",
            "fabrication_detection": "Peer-review criteria include ethics checks but do not implement automated fabrication detection (e.g., plagiarism or AI-generated text detection) in the simulation.",
            "validation_cost_time": "Peer review is simulated within the agent system; computational overhead not separated from overall simulation costs. Each paper receives three reviews; timeline mapping allows for multi-epoch review cycles (one action per epoch).",
            "hybrid_validation_approach": false,
            "validation_limitations": "Reviewer emulation via LLMs may not capture true diversity of expertise and decision-making; cross-disciplinary evaluations are approximated by adapted prompts but lack real domain-expert adjudication, limiting external validity.",
            "acceptance_credibility": "Paper posits that including a peer-review step improves realism and credibility of simulated publications, but stresses that community acceptance requires calibration to actual reviewer behavior and external human validation.",
            "comparison_to_gold_standard": "No direct comparison to real-world peer-review score distributions or acceptance rates is presented; gold-standard peer review is not used for benchmarking in this study.",
            "uuid": "e2211.2"
        },
        {
            "name_short": "Scientometric metrics validation",
            "name_full": "Scientometric quantitative validation (citation counts, h-index, Z-score)",
            "brief_description": "Use of established scientometric measures — primarily citation counts, with suggestions to use h-index for career-level impact and Z-scores for novelty/impact evaluation — to validate AI-generated outputs and simulated patterns.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "Scientometric metric-based validation",
            "scientific_domain": "Bibliometrics / Science of Science",
            "validation_type": "computational validation",
            "validation_description": "The paper uses citation count as the primary metric to measure impact of simulated papers; it recommends using h-index for individual career simulation validation and Z-scores (journal pairing Z-scores) or large-model-based peer-review scoring to assess novelty. These quantitative metrics are suggested as objective comparators between simulation outputs and real-world data.",
            "simulation_fidelity": "Not applicable (metrics-based validation). Metrics are applied to both simulated and historical datasets; fidelity depends on accuracy of the underlying simulation and completeness of metadata.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": "Citation counts from the simulation are compared to real-world citation distributions and correlations; results match directionally but differ in effect strength.",
            "validation_success_rate": "Not provided as a percentage; metrics reveal partial reproduction of empirical patterns.",
            "domain_validation_standards": "Paper states scientometrics (citations, h-index) are standard domain-accepted measures but acknowledges their limitations and suggests complementing them with expert review and diversified metrics to avoid overreliance on traditional measures.",
            "when_simulation_sufficient": "Simulation validated via multiple scientometric metrics and across multiple years/datasets may be sufficient for certain SoS analyses (trend detection, policy sandboxing) but not for causal attribution without additional causal analysis.",
            "simulation_failures": "Reliance on citation metrics can misrepresent novelty and quality; simulation that matches citation patterns does not ensure causal fidelity.",
            "uncertainty_quantification": "Statistical tests (p-values) on correlations are reported; authors suggest model-based peer-review scoring and Z-scores to quantify novelty but do not present calibrated uncertainty intervals for metric estimates.",
            "fabrication_detection": "No explicit metric-based fabrication detection is implemented; however, deviations in citation patterns and anomalous metric values could indicate fabricated outputs.",
            "validation_cost_time": "Computationally inexpensive compared to simulation itself — computing citation counts and h-index on large datasets is scalable but depends on dataset size; no explicit timing given.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Authors note traditional scientometric metrics are insufficient alone, can be biased, and may incentivize mainstream topics; recommend diversified metrics and expert review.",
            "acceptance_credibility": "Using established scientometric metrics facilitates communication with the SoS community and provides an initial credibility baseline, but acceptance requires addressing metric limitations and adding interpretability and domain-expert validation.",
            "comparison_to_gold_standard": "Citation counts and h-index are treated as standard evaluation metrics (de facto gold standards in scientometrics); simulation reproduces some aggregate behaviors but quantitative discrepancies remain.",
            "uuid": "e2211.3"
        },
        {
            "name_short": "Timeline calibration",
            "name_full": "Temporal calibration / timeline alignment techniques for simulations",
            "brief_description": "Proposed dynamic calibration methods to align simulation epochs with real-world time and events, ensuring that simulated timelines map meaningfully to calendar years for longitudinal validation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Dynamic timeline calibration for agent-based simulations",
            "scientific_domain": "Agent-based modeling / Computational Social Science",
            "validation_type": "other",
            "validation_description": "The paper suggests building flexible, event-driven calibration methods that adjust the simulation's temporal parameters based on context and real-world event data (e.g., calibrate how many simulation epochs equal one real year). Calibration may use historical event markers and timeline-dependent statistics to align simulated outputs with empirical time series.",
            "simulation_fidelity": "Not applicable (procedural calibration technique). The calibration improves apparent fidelity by synchronizing simulated events with historical temporal patterns.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "Not performed in this paper beyond general discussion; timeline alignment is proposed as a pathway to improve simulation-to-history comparisons.",
            "validation_success_rate": "Not reported.",
            "domain_validation_standards": "Authors recommend explicit calibration as necessary for longitudinal validation in SoS; no single standardized method is prescribed.",
            "when_simulation_sufficient": "Timeline calibration is considered necessary for simulations to be sufficient for longitudinal claims; without it, temporal comparisons to real-world data may be misleading.",
            "simulation_failures": "Paper notes misaligned timelines can produce incorrect mapping between simulated epochs and real-world evolution, reducing validity of temporal comparisons.",
            "uncertainty_quantification": "No specific UQ method described for timeline calibration; authors recommend dynamic calibration techniques responsive to event-driven data.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "Not quantified; calibration adds computational/analytical overhead but specifics depend on chosen calibration method and data.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Authors note difficulty in selecting appropriate correspondence between simulated epochs and real time and that calibration is non-trivial when unobservable factors influence dynamics.",
            "acceptance_credibility": "Proper calibration is framed as important for credible temporal validation; lack of it undermines confidence in longitudinal simulation claims.",
            "comparison_to_gold_standard": "No direct comparison provided; calibration is a recommended step toward matching simulations to historical gold-standard time-series.",
            "uuid": "e2211.4"
        },
        {
            "name_short": "Anomaly detection for simulation stability",
            "name_full": "Unsupervised anomaly detection to monitor and adjust simulations",
            "brief_description": "A proposed pathway using unsupervised learning (e.g., clustering) to identify deviations from expected agent behaviors and adjust simulation parameters to ensure stability and continuity of long-running simulations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Unsupervised anomaly detection (clustering-based) for agent simulations",
            "scientific_domain": "Machine Learning / Simulation Monitoring",
            "validation_type": "other",
            "validation_description": "Authors propose using unsupervised methods (clustering) to detect deviations from expected behavior trajectories in the simulation; upon detection, simulation parameters would be adjusted to recover stable behavior. This is a proposed operational validation technique for long-running, automated SoS simulations.",
            "simulation_fidelity": "Not applicable.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "None provided; proposal intended to maintain internal simulation validity rather than compare to experiments.",
            "validation_success_rate": "Not reported.",
            "domain_validation_standards": "Presented as a practical engineering safeguard rather than a domain-standard validation approach; authors cite anomaly detection as part of ensuring continuous operation of automated discovery systems.",
            "when_simulation_sufficient": "Anomaly detection helps make long-term simulations reliable; sufficiency depends on detection sensitivity, false-positive rates, and corrective policies.",
            "simulation_failures": "No concrete failure cases are reported, but authors warn that without mechanisms to handle unexpected exceptions, continuous automated discovery could break.",
            "uncertainty_quantification": "Not detailed; anomaly detection would typically yield anomaly scores but the paper does not specify thresholds or confidence measures.",
            "fabrication_detection": "Not directly targeted at fabrication detection; could help surface abnormal outputs suggestive of fabrication but not a dedicated approach.",
            "validation_cost_time": "Not quantified; anomaly detection introduces additional compute for monitoring and potential reruns.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Authors acknowledge that anomaly detection cannot replace principled model validation and that corrective adjustments may mask deeper model misspecifications.",
            "acceptance_credibility": "Operational anomaly detection increases system robustness but does not by itself satisfy scientific community expectations for validation or explainability.",
            "comparison_to_gold_standard": "Not applicable.",
            "uuid": "e2211.5"
        },
        {
            "name_short": "Causal & XAI validation",
            "name_full": "Causal inference and Explainable AI methods for validating AI-driven SoS outputs",
            "brief_description": "The paper recommends applying causal modeling (e.g., Propensity Score Matching, Coarsened Exact Matching, SEM) and explainable AI techniques (counterfactual analysis, causal graphical models) to interpret and validate simulation results and AI-generated recommendations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Causal inference and XAI (PSM, CEM, SEM, counterfactuals)",
            "scientific_domain": "Causal Inference / Explainable AI / Science of Science",
            "validation_type": "other",
            "validation_description": "Authors propose integrating causal methods (PSM, CEM, structural equation modeling, causal graphical models) and XAI techniques (counterfactual analysis) to make AI-driven outputs auditable, interpretable, and to clarify causal pathways behind recommendations. These are proposed as validation layers that complement correlation-based checks.",
            "simulation_fidelity": "Not applicable.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "No direct applications are reported in the paper; methods are proposed to improve interpretability and causal validation of future simulations and AI outputs.",
            "validation_success_rate": "Not applicable / not reported.",
            "domain_validation_standards": "Paper stresses the need for causal analysis in SoS to move beyond correlation; suggests established causal methods as domain-appropriate tools for robust validation and policy-relevant claims.",
            "when_simulation_sufficient": "Authors imply that simulation outputs supplemented by causal modeling and XAI can be treated as stronger evidence, particularly when counterfactuals and matched observational strategies produce consistent findings; still, they do not claim simulation alone suffices for causal claims.",
            "simulation_failures": "No concrete counterexamples provided where causal/XAI reversed simulation findings, but the authors caution that correlations without causal analysis undermine trust.",
            "uncertainty_quantification": "Causal inference methods typically yield effect estimates and confidence intervals; paper recommends these but does not present applied interval estimates within the study.",
            "fabrication_detection": "Not directly addressed; causal inconsistency could flag suspicious outputs but no explicit fabrication-detection pipeline proposed here.",
            "validation_cost_time": "Applying causal methods requires high-quality labeled data and domain expertise; authors do not quantify costs.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Causal methods require careful identification strategies and often stronger assumptions (e.g., no unmeasured confounding); authors note the complex, multivariate nature of SoS makes causal identification challenging.",
            "acceptance_credibility": "Paper argues that adding causal and explainable analyses is key to community acceptance and policy adoption of AI4SoS results.",
            "comparison_to_gold_standard": "No direct comparison; causal/XAI methods are recommended as complementary to gold-standard practices like controlled experiments when those are infeasible.",
            "uuid": "e2211.6"
        },
        {
            "name_short": "Ethical benchmarks & transparency",
            "name_full": "Ethical benchmarks, alignment, and transparency for validation",
            "brief_description": "Discussion of ethical evaluation, transparency, and alignment techniques as part of validation — including use of ethical benchmarks to evaluate societal impacts and alignment procedures to improve trustworthiness of AI-generated SoS outputs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Ethical benchmarks and transparency mechanisms",
            "scientific_domain": "AI Ethics / Science Policy",
            "validation_type": "other",
            "validation_description": "Authors recommend ethical benchmarks (citations to existing benchmarks), alignment of model preferences, transparency measures (recording decision-making pathways), and human oversight as validation of social and ethical acceptability. They cite moral/ethical benchmark works (e.g., LocalValueBench, MoralBench) as relevant evaluation tools.",
            "simulation_fidelity": "Not applicable.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "Not applicable. Ethical benchmarks are suggested as a complementary validation axis, not as an empirical comparison to experiments.",
            "validation_success_rate": "Not applicable / not reported.",
            "domain_validation_standards": "Authors advocate integrating ethical benchmarks and alignment testing into validation frameworks for AI4SoS; refer to community standards and recent benchmark efforts as references.",
            "when_simulation_sufficient": "Simulations addressing ethical concerns with benchmarking and human oversight may be acceptable for policy sandboxing, but authors stress ongoing oversight is necessary.",
            "simulation_failures": "No specific cases, but authors warn opacity and unexamined biases in training data risk producing ethically problematic outputs.",
            "uncertainty_quantification": "Ethical evaluation is largely qualitative; authors recommend transparency and explainability to reduce epistemic uncertainty but do not prescribe quantitative uncertainty measures for ethics.",
            "fabrication_detection": "Ethical benchmarks and transparency can help surface credibility issues, but no concrete technical fabrication-detection method is provided.",
            "validation_cost_time": "Implementing ethical benchmarks and transparency measures requires annotation, benchmarking runs, and human oversight; no quantitative cost provided.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Benchmarks may be incomplete, cultural/contextual, and evolve over time; ethical compliance does not guarantee empirical validity.",
            "acceptance_credibility": "Paper argues ethical benchmarks and transparency are essential for public and community trust in AI4SoS outputs.",
            "comparison_to_gold_standard": "No direct comparison to a gold standard; ethical benchmarks serve as community-aligned standards rather than empirical gold standards.",
            "uuid": "e2211.7"
        },
        {
            "name_short": "Multidimensional evaluation framework",
            "name_full": "Proposed multidimensional evaluation framework combining scientometrics, expert review, time-series analysis, and ethical checks",
            "brief_description": "A recommended, composite validation scheme that integrates quantitative scientometric tests, domain expert assessments (peer review), longitudinal/time-series analyses, causal/XAI methods, and ethical benchmarks to robustly validate AI4SoS outputs.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_or_method_name": "Multidimensional evaluation framework for AI4SoS",
            "scientific_domain": "Science of Science / Evaluation Methodology",
            "validation_type": "hybrid",
            "validation_description": "Authors propose assembling multiple validation axes: (1) quantitative scientometrics (citations, h-index, Z-scores), (2) human expert peer review and domain-specific metrics, (3) time-series and longitudinal tracking, (4) causal/XAI analyses to explain mechanisms, and (5) ethical benchmarks. The framework is intended to handle heterogeneity of SoS tasks and to provide both short-term and long-term validation.",
            "simulation_fidelity": "Not applicable; the framework is agnostic to simulation fidelity but requires simulation outputs to be compatible with multiple validation modalities.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "Framework calls for direct comparisons of simulation outputs to multiple empirical benchmarks and expert judgments; the paper implements portions (scientometric comparisons and peer-review simulations) but not the full hybrid framework.",
            "validation_success_rate": "Not applicable; framework is prescriptive rather than reporting success rates.",
            "domain_validation_standards": "Authors argue no single standard suffices in SoS; propose the multidimensional framework as an emergent standard combining domain-specific and cross-cutting evaluation methods.",
            "when_simulation_sufficient": "Under the framework, a simulation might be considered sufficient if it passes multiple validation axes: reproduces empirical patterns, obtains favorable expert review, has plausible causal explanations via XAI, and satisfies ethical benchmark checks.",
            "simulation_failures": "Authors note that failing any major validation axis (e.g., poor empirical fit, lack of explainability, ethical failures) undermines overall validity.",
            "uncertainty_quantification": "Framework calls for adoption of statistical testing, Z-scores, model-based scoring, and longitudinal uncertainty analyses, but specific UQ pipelines are left to future work.",
            "fabrication_detection": "Framework recommends transparency and ethical benchmarks which could assist detection of fabricated or misleading outputs, but does not detail automated fabrication detection algorithms.",
            "validation_cost_time": "Hybrid validation is acknowledged to be resource-intensive: requires computational resources for simulation, domain expert time for reviews, and infrastructure for longitudinal tracking; authors provide a concrete example of simulation compute (32 A100 GPUs, 1 week for 1M agents) but not combined validation costs.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Implementing a full multidimensional framework is costly and requires interdisciplinary collaboration; authors note data imbalance, bias, and missing model components remain obstacles to fully reliable validation.",
            "acceptance_credibility": "Authors present this framework as necessary to achieve community acceptance and policy relevance; argue that passing multiple validation axes is more persuasive than single-mode validation.",
            "comparison_to_gold_standard": "Framework recommends comparison to historical/empirical gold standards where available (e.g., OAG bibliometrics) and to domain expert consensus; no single gold standard is elevated above others.",
            "uuid": "e2211.8"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation",
            "rating": 2
        },
        {
            "paper_title": "Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning",
            "rating": 2
        },
        {
            "paper_title": "Oasis: Open agents social interaction simulations on one million agents",
            "rating": 2
        },
        {
            "paper_title": "Large language models empowered agent-based modeling and simulation: A survey and perspectives",
            "rating": 2
        },
        {
            "paper_title": "Choosing experiments to accelerate collective discovery",
            "rating": 2
        },
        {
            "paper_title": "Calibrating real-world city traffic simulation model using vehicle speed data",
            "rating": 1
        },
        {
            "paper_title": "On modeling and predicting individual paper citation count over time",
            "rating": 1
        }
    ],
    "cost": 0.02231875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research
17 May 2025</p>
<p>Renqi Chen 
Shanghai Artificial Intelligence Laboratory</p>
<p>Haoyang Su 
Shanghai Artificial Intelligence Laboratory</p>
<p>Shixiang Tang 
Shanghai Artificial Intelligence Laboratory</p>
<p>Department of Information Engineering
Chinese University of Hong Kong</p>
<p>Zhenfei Yin 
Department of Engineering Science
University of Oxford</p>
<p>Qi Wu 
Shanghai Institute for Science of Science</p>
<p>Hui Li 
Shanghai Institute for Science of Science</p>
<p>Ye Sun 
School of Mathematics
Southeast University</p>
<p>Nanqing Dong dongnanqing@pjlab.org.cn 
Shanghai Artificial Intelligence Laboratory</p>
<p>Wanli Ouyang 
Shanghai Artificial Intelligence Laboratory</p>
<p>Department of Information Engineering
Chinese University of Hong Kong</p>
<p>Philip Torr 
Department of Engineering Science
University of Oxford</p>
<p>AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research
17 May 2025918871C0DF3B560F1FFE6D5A59EFAEDBarXiv:2505.12039v1[cs.AI]
The Science of Science (SoS) explores the mechanisms underlying scientific discovery, and offers valuable insights for enhancing scientific efficiency and fostering innovation.Traditional approaches often rely on simplistic assumptions and basic statistical tools, such as linear regression and rule-based simulations, which struggle to capture the complexity and scale of modern research ecosystems.The advent of artificial intelligence (AI) presents a transformative opportunity for the next generation of SoS, enabling the automation of large-scale pattern discovery and uncovering insights previously unattainable.This paper offers a forward-looking perspective on the integration of Science of Science with AI for automated research pattern discovery and highlights key open challenges that could greatly benefit from AI.We outline the advantages of AI over traditional methods, discuss potential limitations, and propose pathways to overcome them.Additionally, we present * Equal contributions.</p>
<p>Introduction</p>
<p>Science of Science (SoS), a pivotal and rapidly evolving field, serves as a strategic compass for guiding the trajectory of scientific and technological progress.By analyzing the complex dynamics of research collaboration and scientific output across geographic and temporal scales, it sheds light on the factors that drive creativity and the emergence of scientific discoveries, with the goal of developing tools and policies to accelerate scientific advancement [1].Unlike broader social sciences that examine societal structures, SoS delves deep into the mechanisms that fuel scientific breakthroughs [2][3][4]-illuminating the hidden forces that propel discovery and transformation.Ultimately, SoS underscores that groundbreaking advancements are not solely the result of talented minds and quality data, but are profoundly shaped by effective resource allocation, supportive policies and well-designed organizational structures [5,6].</p>
<p>In recent years, the deep fusion of AI and SoS has become more feasible and promising than ever before.First, the increasing availability of large-scale scholarly data-publications, funding records, and collaboration networks-provides unprecedented opportunities to gain deeper insights into the evolution of scientific progress.Second, rapid advancements in AI technologies, such as large language models (LLMs), along with improvements in computational power, have greatly enhanced our ability to analyze and interpret complex scientific information with unprecedented accuracy and scale.These technological breakthroughs mark a critical moment for integrating AI into SoS, paving the way for a more data-driven approach to understanding and guiding research pattern discovery.While some recent works have begun exploring autonomous scientific discovery, the field remains in its infancy, and there is still much progress to be made before realizing its full potential.</p>
<p>In this paper, we take a step forward by providing the first glimpse into the integration of AI and SoS for automated research pattern discovery.We take the position that AI has the potential to revolutionize SoS, enabling the next generation of research by not only automating traditional research processes but also providing a sandbox for SoS research, allowing scientists to observe research processes in action and validate their hypotheses.As illustrated in Fig. 1, traditional SoS methods have primarily relied on manual data processing, bibliometric-based data analysis, rule-based system simulations, and real-world pattern validation.In contrast, AI-driven SoS leverages automated techniques to assist scientists  in processing and analyzing data while offering more advanced and comprehensive systems for simulation and validation.This shift from human-driven to AI-driven methodologies unlocks the potential for more efficient, scalable, and data-driven analysis, ultimately providing deeper and more actionable insights into the mechanisms that shape scientific progress.Thus, we define AI for SoS (AI4SoS) as a cross-disciplinary field that not only focuses on facilitating each step within the research process but also aims to achieve fully automated SoS research to uncover the hidden forces driving scientific innovation.This distinguishes AI4SoS from existing AI for Science approaches, which focus on using AI tools to solve domain-specific scientific problems [7][8][9].</p>
<p>To consolidate our insights, we propose a forward-looking hierarchy of different levels of AI4SoS automation in Sec.2.3, which outlines a possible step-by-step approach to achieving the goal of fully automated SoS discovery.Within each level, we describe the key differences compared to previous levels and provide related examples.In Sec. 3, we highlight critical open problems in SoS where AI offers advantages.Despite its promise, we discuss challenges such as data imbalance across disciplines in Sec. 4, overwhelming parameters in the simulation system of scientific societies, and the need for a reasonable evaluation system to validate the reliability of the simulation.We also propose possible pathways to overcome these challenges.Last but not least, we introduce a preliminary multi-agent system to simulate research societies in Sec. 5, illustrating AI's capability to enable fully automated pattern discovery.</p>
<p>AI4SoS</p>
<p>Comparison between AI for Science and AI4SoS</p>
<p>Both AI for Science (AI4S) and AI4SoS aim to leverage AI to solve scientific problems.However, they differ in research goals.AI4S focuses on solving a particular scientific problem directly, such as weather prediction, drug discovery, and materials science.AI4SoS takes a meta-level approach, focusing on understanding the mechanisms of scientific progress to facilitate and accelerate research.More specifically, AI4SoS focuses on factors such as innovation drivers, research collaboration patterns, and the evolution of scientific knowledge, which are not bound to a single scientific problem.</p>
<p>Hierarchy of Automation Degree in AI4SoS</p>
<p>The integration of AI techniques into scientific research follows a progressive hierarchy, reflecting the increasing autonomy and sophistication of AI systems in advancing the SoS field.As illustrated in Fig. 2, we define five levels of autonomy, ranging from no AI involvement in pattern recognition and analysis to full autonomy in uncovering new scientific insights and guiding research strategies.Level 0: Non-automated SoS Discovery At this level, scientific pattern discovery is entirely human-driven and relies on traditional statistical methods.Researchers apply fundamental techniques such as probabilistic models, linear regression, and hypothesis testing to analyze scientific data and uncover patterns.AI is not involved in the process, and all tasks are conducted manually using well-established statistical procedures.Notable studies in this domain include the application of regression analysis to identify research trends [10], correlation analysis to examine relationships between variables [11], and statistical estimation methods to explain observed scientific phenomena [12,13].</p>
<p>Level 1: AI-Assisted SoS Discovery In Level 1, AI only supports scientific data processing.Specifically, AI methods are able to transform real-world scientific data into a more comprehensible form, including tasks such as completing and structuring bibliometric data, extracting key features such as author networks and institutional collaborations, and converting text information (e.g., papers, scientists) into embedding representations, thereby enhancing the efficiency and accuracy of data handling.However, AI's role remains supplementary, with human researchers still conducting data analysis, understanding and prediction.From the perspective of AI4SoS, some related works include: utilizing text-to-embedding methods for mapping papers to vector space [14], extracting key information from papers using named entity recognition [15], and constructing networks for faculty mobility [16].</p>
<p>Level 2: Partially Automated SoS Discovery In Level 2, AI techniques (e.g., supervised learning), play a central role in analyzing scientific data, enabling tasks such as predicting emerging trends, research hotspots and collaboration opportunities, based on historical patterns.This marks a shift from AI-assisted data processing to AI-driven data analysis.However, in this level, AI struggles to design and implement experiments automatically.For instance, a simulation environment that can automatically conduct scientific experiments is not available, therefore it is difficult to model hidden dynamic</p>
<p>AI4SoS</p>
<p>processes within the scientific ecosystem.Related works include the use of machine learning models to predict individual paper citation counts [17], neural networks for forecasting research trends and generating novel ideas [18], clustering publications based on citation relationships [19], and applying structural topic models to extract topics from scientific texts [20].Level 3: Highly Automated SoS Discovery In Level 3, AI not only drives the analysis but also designs and implements experiments to simulate scientific patterns in the real world.In this case, researchers can compare results generated by simulation systems and those in the real world to explore strategies in SoS for potential real-world applications.While AI can support automatic experiment conduction, human supervision is required to define the specific application scenarios and corresponding experimental parameters (e.g., scientist information, boundary conditions) based on system feedback.Consequently, the authenticity and rationality of the system depends on whether the researchers have considered all relevant factors, making the automatic pattern validation difficult.Research at this level is still in its early stages, including systems simulating specific research scenarios to propose hypotheses [21], AI predicting outcomes under different simulation conditions to provide insights into collaboration patterns [22].and systems reproducing historical events based on specific environmental settings [23].Currently, most research remains at Level 2 or below, with only limited progress observed at Level 3, while fully automated SoS discovery is still in the exploratory stage.Looking ahead, several potential tasks are envisioned, including automated discovery of new collaboration patterns within the simulated scientific community [22], systems capable of simulating and conducting experiments in real-world settings [24], and AI that continuously refines research directions based on emerging data [25].</p>
<p>Advantages of Automatic SoS Discovery</p>
<p>In this section, we delve into critical open problems within the SoS that stand to benefit substantially from AI-driven automation.These problems are categorized into two primary areas: Forecasting Trends in Technology and Innovation and Understanding the Dynamics of Research Society.For each subproblem, we provide a brief background and outline key opportunities where AI offers advantages.</p>
<p>Forecasting Trends in Technology and Innovation</p>
<p>Background of Problem</p>
<p>Accurately forecasting the trajectory of science and technology is a crucial aspect of SoS, as it informs decisions related to funding, policy-making, and research prioritization.Two major challenges are predicting technological trends and identifying interdisciplinary opportunities.The Trend in Technological Development Technological development follows intricate and often non-linear trajectories, making prediction difficult.To predict these trends, it is essential to understand which technologies are gaining momentum, identify emerging breakthroughs, and anticipate when they will transition from research to real-world applications [26].Traditional methods, such as historical data analysis, often fall short in scalability and struggle to keep pace with rapid advancements.The Interdisciplinary Future of Innovation Interdisciplinary research, which often serves as the pivotal role for major breakthroughs, presents another significant challenge.With the rapid growth of scientific literature across diverse fields, manual identification of promising cross-disciplinary opportunities has become increasingly unfeasible [27].The complexity and scale of this task call for automated solutions capable of discovering novel connections across fields.</p>
<p>Advantages of AI4SoS</p>
<p>AI offers an opportunity for tackling challenges in the SoS by leveraging its capacity to process vast datasets and identify complex patterns beyond human discernment.In the context of forecasting technological development, AI models can analyze citation networks, research metadata, and publication trends to detect emerging technological trajectories with enhanced precision [28].</p>
<p>Moreover, AI-driven methods excel in uncovering interdisciplinary opportunities by representing scientific knowledge as graph structures and employing advanced similarity metrics.Graph neural networks, for instance, have demonstrated the ability to model intricate relationships across scientific literature, facilitating the discovery of latent connections and novel collaborations across disparate domains [29].This capability empowers researchers to target high-potential interdisciplinary collaborations, fostering innovation at the convergence of fields.</p>
<p>AI4SoS</p>
<p>Understanding the Dynamics of Research Society</p>
<p>Background of Problem</p>
<p>The dynamics of research societies play a fundamental role in shaping scientific progress, which encompass how scientist research patterns evolve, how different team constructions influence the impact of research output, and how current research society influences scientists.The Dynamics and Mechanics of Scientist Career The role of studying scientific careers is to provide personalized support to the academic community, thereby enhancing individual innovation capabilities, optimize team collaboration efficiency, and improving the allocation of research resources [1].However, challenges include the highly individualized nature of career development paths, data scarcity and bias, and the complexity of external environmental factors [30].The Dynamics and Mechanics of Research Team The composition and dynamics of scientific teams play a crucial role in improving research outcomes, with elements such as size, diversity, and collaboration patterns influencing team creativity and productivity [11,31].Over time, shifts in team structures and researcher mobility have reflected broader changes in the research landscape.Understanding these evolving dynamics presents challenges, as the relationships between team composition and research impact are multifaceted [32,33].The Dynamics and Mechanics of Research Society The organization and dynamics of research societies play a crucial role in shaping the progression and fairness of scientific endeavors.Studies have highlighted persistent inequalities in academic representation, participation, and recognition, both within and across nations [6,34].These disparities, influenced by systemic and structural factors, hinder the equitable generation and dissemination of knowledge.On a broader scale, imbalances in citation patterns and collaboration networks often reflect biases rooted in reputation and resources rather than research quality [35].</p>
<p>Advantages of AI4SoS</p>
<p>AI offers potential for understanding and improving the dynamics of research societies.By analyzing large-scale historical datasets-such as collaboration patterns, research trajectories, and external influences-AI can uncover critical factors driving individual career development.This enables personalized researcher support and helps institutions optimize talent management.Techniques such as predictive modeling have proven effective in tracking and forecasting team member mobility patterns [36].</p>
<p>Moreover, AI-driven agents can simulate complex team dynamics, providing insights into how various factors, such as diversity and team size, influence research productivity and innovation.Taking this a step further, AI can simulate entire scientific societies, not only uncovering hidden patterns and problems but also guiding the policymaking process by validating potential policies within the simulated environment.For instance, multi-agent systems have been employed to model team formation processes and predict collaboration outcomes under varying settings [22].</p>
<p>Challenges and Pathways</p>
<p>Achieving fully automated SoS discovery centers on effectively utilizing AI techniques to process scientific data.This endeavor involves addressing four key challenges: data-related issues, comprehensive system construction, robust system evaluation, and system explainability.For each of these challenges, we provide a detailed analysis along with potential pathways for resolution.</p>
<p>Data Issues</p>
<p>Challenges Data issues mainly include data imbalance across disciplines and training data bias.For the first issue, many disciplines, such as computer science and engineering, produce large volumes of well-structured data readily used by AI systems [37,38].However, other fields, such as social sciences or humanities, often suffer from smaller datasets, less structured data, or incomplete information, which makes it difficult for AI models to provide accurate predictions [39,40].This imbalance can lead to skewed results where AI predictions are disproportionately driven by well-represented fields, neglecting potentially valuable insights from underrepresented areas of research.Another issue is training data bias.When predicting reproducible patterns from data, machine learning models inevitably incorporate and perpetuate biases present in the data, often in opaque ways [41].For example, the training data and alignment methods of LLMs (whether open-source or closed-source) are not fully disclosed [42][43][44], making it impossible to objectively assess their bias and fairness.Therefore, the fairness of machine learning becomes a heavily debated issue in applications ranging from the criminal justice system to hiring processes [45].Pathway To address issues of data imbalance and biases in training data, constructing a large and diverse dataset is essential to improve data representativeness, ensuring coverage across various domains, groups, and contexts.Several large-scale, cross-disciplinary academic datasets are currently available for SoS research, including the Microsoft Academic Graph (MAG) [46], Open Academic Graph (OAG) [47], and SciSciNet [48], where the statistical information of each dataset is summarized in Table 2.In the process of data auditing and filtering, it is crucial to examine data sources and mitigate any potential historical or socio-cultural biases to ensure the dataset is free from implicit biases [49].Additionally, employing multi-annotator strategies, conducting group balance checks, and performing fairness evaluations can further ensure the fairness and diversity of the dataset [50].These measures not only enhance the model's generalization ability but also reduce unfairness stemming from data biases.</p>
<p>Comprehensive System Construction</p>
<p>Challenges Simulating a research society using AI for fully automated SoS discovery, particularly through an agent-based system, presents numerous challenges.Each scientist-agent requires detailed modeling of their research expertise, career trajectory, and collaborative networks, which are often too complex to be fully captured in the simulation system [51,52].Critical but unobservable factors, such as internal cognitive processes and informal discussions that drive real-world decision-making, remain challenging to replicate accurately.These limitations inevitably make simulations discrete and less representative of actual societal dynamics.Moreover, the simulation process itself introduces complexities.Aligning the simulated timeline with real-world events necessitates careful calibration; for instance, determining how many simulation epochs correspond to a year in reality [53].Determining the appropriate size of the simulated society is also crucial; an overly small-scale model risks failing to capture the emergent behaviors of a real research ecosystem, while an overly large model may become impractical to manage and analyze [54,55].Another pressing challenge lies in bias amplification when designing AI systems-a concern that builds on the broader implications of how AI interacts with societal structures.Since AI systems are often designed to optimize based on historical data of SoS, they risk perpetuating existing paradigms, funding trends, and citation networks.This aligns with the well-documented "rich get richer" effect in citation and funding dynamics [56][57][58].If an AI system prioritizes high-impact metrics, it may inadvertently favor mainstream topics and established researchers, further marginalizing unconventional or disruptive ideas.Without explicit mechanisms to value novelty and diversity, such systems could unintentionally confine the scientific community to existing trends, hindering pathways to groundbreaking innovation.Lastly, the system must account for unexpected exceptions to ensure the simulation operates smoothly and continuously for fully automated scientific discovery.Striking a balance between realism and feasibility remains a persistent and fundamental challenge in these simulations.</p>
<p>Pathway Several potential pathways can help address these complexities.</p>
<p>With the continuous advancement of LLMs' comprehensive capabilities, handling complex multi-level modeling is becoming increasingly feasible.By defining agent models with distinct roles and appropriately assigning tasks, the behaviors of scientists at various levels can be more accurately simulated [59].</p>
<p>Fine-tuning LLMs on extensive academic datasets can further optimize the behavioral patterns of agents [60], enhancing their adaptability to reflect realworld research dynamics.One solution for timeline alignment is to build flexible, dynamic calibration techniques that adjust the simulation's temporal parameters based on context and event-driven data [23].In determining the appropriate scale for the simulated society, agent-based sampling methods (random or rule-based) or dynamic population expansion techniques can be utilized [22].When addressing bias in AI systems, it is crucial to consider the nature of SoS, a discipline dedicated to analyzing historical data and uncovering biases or patterns within the scientific community.To ensure alignment between simulations and real-world dynamics, it is essential to incorporate these biases into SoS studies, as AI designed for this field seeks to enhance and advance SoS research.At the same time, such biases can be mitigated through targeted adjustments to system parameters.For instance, to counteract the "rich get richer" effect in citations, one effective approach could involve reducing the likelihood of citing highly cited papers when an agent selects a reference.Instead, assigning higher probabilities to less-cited, more novel papers can help promote diversity in citation practices and encourage the exploration of unconventional ideas.Moreover, the system can integrate robust anomaly detection and recovery mechanisms to handle unexpected situations.Using unsupervised learning techniques (such as clustering), the model can identify deviations from expected behaviors and adjust simulation parameters accordingly to ensure stability and continuity [61].These potential solutions try to strike a balance between realism and operational feasibility, providing a technological foundation for research society simulations.</p>
<p>AI4SoS</p>
<p>Comprehensive System Evaluation</p>
<p>Challenges Evaluating the validity of outputs generated by AI systems in the field of SoS is a complex and multifaceted challenge.SoS research addresses a broad range of problems and lacks unified evaluation standards, with different tasks often necessitating tailored metrics [41].Moreover, innovation-a key attribute of AI outputs-is inherently subjective and context-dependent, making it difficult to quantify accurately using traditional methods [22,62].Validity assessments also heavily rely on specific domain contexts.However, the interdisciplinary nature of SoS compounds the complexity, requiring the integration of knowledge and evaluation standards from diverse fields.Additionally, the dynamic nature and long-term implications of AI-generated outputs present further challenges, as their true impact on scientific progress often cannot be evaluated in the short term [63].Addressing this requires advanced tools, such as time-series analysis and virtual scientist simulations, to facilitate longitudinal tracking.Furthermore, AI-generated scientific recommendations may raise ethical issues and have far-reaching consequences for scientific communities and research practices [64].Therefore, a comprehensive and adaptable evaluation framework is necessary, integrating scientometric methodologies, multidisciplinary expert reviews, dynamic analytical approaches, and stringent ethical guidelines.</p>
<p>Pathway To address these challenges, appropriate solutions can be implemented.First, collaborating with domain experts to define task-specific evaluation metrics is essential, and then quantitative evaluation methods based on scientometrics should be developed.For instance, citation counts can be used as a measure of influence when evaluating the impact of system outputs, and they can also track knowledge flow [41].In simulating a scientist's career, individual impact metrics such as the h-index, which reflects both productivity and impact, can be applied.Additionally, to assess output novelty, feasible approaches include large model-based peer-review scoring [22,65] or calculating the Z-score for each pairing of referenced journals [62].With the ongoing expansion of LLMs' expertise and improved reasoning capabilities, interdisciplinary testing and long-term large-scale simulations have become increasingly feasible.Moreover, LLMs are now being employed in social simulations [23], assuming role-based agents.In terms of ethical and social impacts, aligning model preferences and improving transparency can partially address ethical concerns and enhance user trust, while ethical benchmarks [66,67] can be used to test the validity of system outputs.By integrating these strategies, a multidimensional evaluation framework can be established.</p>
<p>Explainability and Causal Inference</p>
<p>Challenges While the AI framework emphasizes automated discovery and evaluation, it lacks mechanisms to explain the causal pathways behind AIgenerated outputs [68,69].This limitation makes it difficult for researchers and policymakers to trust and adopt AI-driven insights, as they may not fully understand the underlying logic or relationships.Moreover, the complex and interdisciplinary nature of SoS often involves interactions between numerous variables, such as collaborations, funding patterns, and citation networks [1,70], which cannot be adequately captured through correlationbased approaches.Without explicit causal explanations, it is challenging to ensure the auditability, accountability, and interpretability of the system, undermining its credibility and ethical alignment.Pathway To address these challenges, it is crucial to introduce causal modeling [71,72] and explainable AI (XAI) [73,74] techniques to assist in interpreting and validating simulation results.Approaches such as Counterfactual Analysis can clarify the logical origins of AI-driven recommendations or discoveries, making the reasoning process more transparent.Relevant methods in the SoS domain include causal inference techniques like Propensity Score Matching (PSM) and Coarsened Exact Matching (CEM), which are useful for identifying causal relationships in complex systems [75,76].Additionally, causal graphical models and structural equation modeling (SEM) can be applied to analyze scientific impact by modeling the flow of influence across variables such as collaboration networks or funding distributions [77][78][79].These tools provide a robust foundation for explaining AI-generated outputs.</p>
<p>Proof-of-Concept Studies</p>
<p>In this section, we present case studies to illustrate a practical application scenarios in AI4SoS.Specifically, by constructing a simplified preliminary multi-agent system to replicate phenomena observed in real-world scientific societies and uncover underlying patterns in SoS, we aim to demonstrate the possibility of automated pattern discovery.</p>
<p>Environment Construction</p>
<p>We construct a preliminary multi-agent system to simulate a society-level scientific collaboration through an end-to-end pipeline, including collaborator selection, topic discussion, idea generation, novelty assessment, abstract generation, and peer review, inspired by [22,65,80].Existing studies primarily focus on simulating individual scientists or small research teams within specific fields (e.g., computer science) and are often constrained to isolated settings that do not capture the broader research ecosystem.In contrast, our work enhances the system's complexity by incorporating realistic factors such as multidisciplinary data, a review and indexing system, and scalable simulation across multiple research teams.The overview of our system is shown in Fig. 3. Multidisciplinary Data We use the OAG 3.11 as the initial database for our system, which developed from the Open Academic Graph [47].This data set includes 35,774,510 authors and 130,710,733 papers as of 2023, spanning diverse domains such as physics, chemistry, and computer science.In Table 3, we present the disciplines and fields of paper in the Open Academic Graph,  The overview of our preliminary multi-agent system for scientific collaboration simulation.We place the simulation within a community of scientists.After a scientist leads his/her team in submitting a paper, it undergoes peer review.If accepted, it is added to the reference database and can be cited by other scientists in subsequent epochs.Due to varying author information, the citation count of the final research output differs, then we can analyze the correlation between them-understanding the dynamics of research organizations, which is important in the field of SoS.Review and Indexing System To better simulate and reveal the patterns of scientific collaboration mechanisms, we introduce a review and indexing system.Papers written by scientist teams are peer-reviewed and scored (ranging from 1 to 10), and those that exceed the acceptance threshold (with score larger than 5) are added to the reference paper database as newly published papers.The peer review criteria are discussed in Appx.B, considering that the outcomes are cross-disciplinary.Besides, the indexing system allows agents to retrieve published papers as references, and the citation count of referenced papers is updated accordingly, which is later used for metric evaluation.</p>
<p>AI4SoS</p>
<p>Table 5: Different strategies are adopted for various pieces of information regarding papers.The papers in the initial database have None for this information due to its absence, while the papers published by the agent contain the names of the cited papers</p>
<p>None</p>
<p>Discipline</p>
<p>Use GPT-4 to classify the papers into disciplines based on their keywords and titles.Refer to Table 3</p>
<p>for all the disciplines used Environmental Science</p>
<p>Scalable Simulation To better replicate the phenomenon of free collaboration in real scientific cooperation, we implement an adaptive concurrent distributed system based on the OASIS [23].The system's asynchronous mechanism achieves concurrent processing by queuing multiple requests from agents in an inference channel and then distributing them to different ports for sending and receiving, where each port has deployed an LLM responsible for chatting or embedding.Furthermore, to reduce CPU load, we set the channel allocation wait time based on the number of pending requests in the channel, thereby enabling long-term large-scale asynchronous simulation.This mechanism serves the two purposes: 1. Enabling scientist agents from different teams to communicate simultaneously, including both intra-team and cross-team collaboration, and 2. Accelerating the simulation process to enable large-scale simulations at the million-agent level.We test the time cost of our simulation system under different number of agents, illustrated in Fig. 4. It could be found that we realize a fast large-scale agent system, where a simulation of a million agent society takes only one week.</p>
<p>Experiments</p>
<p>Implementation Details We implement our system on 32 NVIDIA A100 GPUs, with 4 ports deployed on each GPU, and each port running the LLaMA3.1-8bmodel.We allow each agent to create up to 3 teams simultaneously, with team sizes following an exponential distribution.This is because we analyze the team sizes of papers published between 2002 and 2009 in the OAG (over 1,000,000 papers), as shown in Fig. 5.The red fitting line indicates that the team sizes in the real data follow an exponential distribution.Therefore, in our simulation, the team size of each agent is also modeled using an exponential distribution.</p>
<p>In idea generation and novelty assessment, each agent can cite up to 9 references per speech, where the retrieval results are obtained based on the similarity between the embeddings of the query terms and the embeddings of the papers in the database.The model used for embedding is mxbai-embedlarge.To avoid storage issues, each agent's memory retains a maximum of 5 entries.Each paper undergoes peer review by 3 reviewers.In terms of the  timeline, each epoch allows for 1 action, meaning a complete scientific collaboration can be completed in 6 epochs if the team progresses without any delays or interruptions.In our final experiment, the size of our society is maintained at 1 million agents, with a total of 40 epochs.</p>
<p>Involved Metrics Following the settings of [11,30,82], we measure the impact of scientific output by the number of citations a paper receives.In the simulation, the citation counts are updated each time a paper is retrieved during the idea generation phase.For validation, we analyze the citation counts of agent-generated papers to assess whether the system can replicate patterns observed in real-world data from the years 2010 to 2011.To evaluate AI's potential in pattern discovery, we examine the influence of three key factors on citation counts: ethnicity diversity, affiliation diversity, and average university ranking.Specifically, we measure diversity using Shannon entropy.For instance, the ethnicity diversity d eth of paper s is calculated as:
d eth = − k i=1 p i (s) ln p i (s),(1)
where k represents the total number of ethnicity categories, and p i (s) is the proportion of authors from the i-th ethnicity category in paper s.</p>
<p>Simulation Results</p>
<p>The experimental results presented in Fig. 6 compare real-world data in 2010 with the outcomes generated by our preliminary LLM-based multi-agent system.Both the real-world and simulated data show that higher citation counts are positively correlated with greater ethnicity diversity, which aligns with  existing findings in SoS literature [11], although the correlations are slightly weaker in the simulation.Additionally, the negative correlation between affiliation ranking and citation counts is also reproduced in the simulated data, suggesting that institutions with higher rankings may achieve higher citation counts per research output.A similar comparison using real-world data from 2011 and the simulated result is provided in Fig. 7.The statistical analysis of the 2011 data exhibits similar trends to those observed in Fig. 6, which presents the comparison using 2010 data.The positive correlation between citation counts and ethnicity AI4SoS diversity, as well as the negative correlation between affiliation ranking and citation counts, are consistently reflected in both years.However, minor variations in correlation strength are observed, highlighting the dynamic nature of scientific collaboration trends over time.</p>
<p>However, while both real-world and simulated data indicate a positive correlation between citation counts and affiliation diversity, the pattern observed in the simulation is not statistically significant, with a p-value greater than 0.05.These results suggest that the preliminary AI-driven simulations have the potential to replicate and uncover key patterns in scientific research, but there remains significant room for improvement.For instance, the current system lacks several critical components, such as comprehensive modeling of individual research trajectories and realistic funding and policy influences.These limitations contribute to the preliminary nature of our approach, as the absence of such factors restricts the system's ability to fully capture the complexity of real-world scientific ecosystems.Developing a more comprehensive and sophisticated simulation framework will enhance the system's capability to automatically model complex scientific dynamics with greater accuracy and reliability.</p>
<p>Alternative Views</p>
<p>The application of AI in SoS is often seen as transformative, promising to accelerate discovery.However, critics highlight significant limitations and risks, questioning its unqualified benefits.These concerns focus on systemic issues and unintended consequences [83][84][85].Key counterarguments include: (1) Reinforcement of Existing Inequalities: AI systems rely heavily on historical data, which often mirror long-standing inequities within the scientific community.For instance, datasets may disproportionately represent well-established disciplines, regions, or researchers, thereby perpetuating an imbalanced view of scientific contributions.Critics argue that this could stifle innovation by overlooking emerging fields and underrepresented groups, ultimately reinforcing the leading trend rather than fostering diversity.(2) Overreliance on Traditional Metrics: Academic evaluation metrics, such as citation counts and journal impact factors, are central to many AI applications in SoS.These metrics have been criticized for prioritizing mainstream research while marginalizing unconventional or nascent ideas.Opponents caution that AIdriven analyses might amplify this bias, narrowing the scope of scientific discovery and undervaluing novel contributions.</p>
<p>While these critiques highlight significant challenges, they underscore the importance of addressing fairness, and inclusivity in AI applications for SoS [86][87][88].To mitigate these concerns, the following strategies can be adopted: (1) Promoting Diversity in Data and Metrics: Expanding data curation efforts to include a wider range of disciplines, regions, and research communities is critical for minimizing biases.Additionally, developing diversified scientific impact metrics beyond citation counts can ensure a more equitable evaluation of research contributions.(2) Incorporating Bias Mitigation Techniques: Embedding bias detection and correction mechanisms in AI systems can help identify and address inequities in the data and algorithms.These techniques should be complemented by rigorous validation to ensure fairness and reliability.</p>
<p>Outlook</p>
<p>As AI4SoS progresses toward full autonomy, we envision a future where scientific discovery itself becomes a more self-reflective, adaptive, and strategically guided process.In this envisioned landscape, AI agents are trained on vast corpora of scholarly data and historical innovation patterns, which will not only map the contours of scientific fields but also anticipate emerging disciplines and recommend actionable research agendas.</p>
<p>Automated SoS systems will continuously monitor the evolving structure of scientific collaboration, offering dynamic guidance to policymakers, institutions, and individual researchers.Research teams may be formed or optimized based on predicted synergy and complementary expertise, while funding strategies could adapt in real time to maximize long-term innovation impact.Moreover, AI4SoS could democratize scientific foresight, making sophisticated analyses accessible to a broader range of stakeholders, from early-career researchers to global research organizations.The resulting ecosystem would be one where science is not only accelerated but also made more transparent, inclusive, and responsive to societal needs.</p>
<p>To enhance real-world applicability, we also envision deployment scenarios in which AI4SoS integrates directly with existing scientific ecosystems.For instance, it could serve as a sandbox environment for evaluating national research policies, allowing simulated assessments before implementation.Within academic institutions, AI4SoS could support internal research strategy formulation, identifying growth areas and optimizing resource allocation.Additionally, it could assist governmental and funding bodies in planning emerging discipline layouts and national innovation agendas.These integration pathways would significantly boost the practical value, societal impact, and credibility of AI4SoS.</p>
<p>Achieving this vision will demand sustained interdisciplinary collaboration, ethical oversight, and robust infrastructure, but the potential payoff is immense: a future in which the SoS is not just studied, but actively shaped by intelligent systems.</p>
<p>Conclusion</p>
<p>This paper presents a forward-looking perspective on the future of AI4SoS, proposing a five-level autonomy framework for understanding the progression toward automated SoS discovery.We emphasize the importance of AI4SoS by demonstrating its potential in two critical domains: forecasting trends in AI4SoS technology and innovation, and analyzing the evolution of research communities.Furthermore, we discuss key challenges and future directions, supporting our vision with literature reviews and proof-of-concept studies that showcase early applications.Ultimately, AI4SoS holds the promise of enabling automated SoS discovery, thereby enhancing scientific efficiency and promoting interdisciplinary innovation.</p>
<p>Impact Statement</p>
<p>We believe that sustained collaboration between AI researchers and SoS scholars is essential for advancing our understanding of complex scientific processes.This study leverages the complementary expertise of both fields to address key SoS challenges, improving scientific efficiency and fostering interdisciplinary innovation.</p>
<p>However, from an ethical perspective, the integration of AI with SoS research may present several concerns.First, accountability: When AI participates in scientific decision-making, it is crucial to clarify responsibility.For instance, if an AI-generated prediction leads to errors, should developers bear full responsibility?We suggest enhancing AI system transparency (e.g., recording decision-making pathways) and explainability (e.g., providing reasoning behind decisions) to help researchers and regulators delineate accountability more clearly.Second, fairness and bias: AI systems rely on training data, which may contain inherent biases related to gender, geography, or economic disparities.These biases can lead to unjust scientific conclusions.Therefore, AI development and application should include rigorous data preprocessing and incorporate fairness constraints within algorithms to mitigate the risk of bias propagation.Finally, public trust: AI-driven automation tools, due to their complexity, may create a sense of detachment among the public.When AI decision-making processes are opaque, concerns about the credibility of scientific findings may arise.To foster trust, it is essential to develop more interpretable AI models and ensure human oversight in scientific processes.</p>
<p>From a societal perspective, the complexity of SoS demands innovative approaches.Conventional statistical studies, which depend largely on historical data, frequently struggle to uncover causal mechanisms.In contrast, agentbased AI provides a dynamic, causality-driven alternative.By elucidating the mechanisms behind the evolution of scientific knowledge, these methods can clarify how government policies influence research funding, academic publishing, and interdisciplinary collaboration.As AI4SoS advances, it will foster more effective knowledge exchange among academia, industry, and government, accelerating technological and theoretical innovation.Through intelligent analysis and predictive modeling, researchers can more precisely identify scientific challenges, significantly enhancing the efficiency of discovery.</p>
<p>AI4SoS</p>
<p>A Related Work</p>
<p>A.1 AI for Science</p>
<p>In recent years, AI has become increasingly common in science and is expected to become the center of research practice [89].AI has demonstrated great potential to accelerate experimental design, data analysis, optimization problem solving, and discovery of new theories [90][91][92].Specifically, deep neural networks are used to predict the relationship between molecular structures and biological activity [93,94], reinforcement learning is used to discover unknown materials with superior properties [95,96], and agent-based systems are introduced to simulate social science scenarios [97,98].In addition, as a subfield of science, AI has undergone some preliminary explorations in the SoS [11,14,22], revealing promising results.</p>
<p>A.2 Large Language Models</p>
<p>The role of large language models (LLMs) can be articulated from two perspectives: chat (T5 [99], GPT-4 [100], and LLaMA3.1 [101]) and embedding (BERT [102] and DNABERT [103]) generation.First, the capability of dialogue generation enables LLMs to understand user input in natural language and generate contextually relevant responses in various conversational contexts such as knowledge testing, game play, and software programming [98,[104][105][106].Additionally, embedding generation allows LLMs to convert input text into fixed-dimensional vector representations, which effectively capture the semantic information of the text and can be used for tasks such as text similarity computation, information retrieval, and sentiment analysis [107][108][109][110]. Therefore, the capabilities of LLMs in both text generation and embedding generation make them applications spanning from natural language processing tasks to more complex domains such as SoS, where they can assist in understanding research dynamics, scientific discovery, and scientific collaboration.</p>
<p>B Review and Indexing System</p>
<p>In Table 6 and 7, we present the peer review criteria used in our simulation system, which is based on the modified Neural Information Processing Systems review guidelines2 considering that the papers produced by cross-discipline agents are not all in the field of computer science.Although this criteria comes from a computer science conference, the basic evaluation metrics can be applied in multiple areas.You are a researcher from a multidisciplinary background reviewing a paper that has been submitted to a venue that involves multiple scientific disciplines.Be critical and cautious in your decision-making.If the paper has significant weaknesses or you are uncertain about its quality, provide lower scores and recommend rejection.Below are the questions you will be asked on the review form for each paper and some guidelines on what to consider when answering these questions.Reviewer Guidelines for Multidisciplinary Paper Review: 1. Summary: Provide a brief summary of the paper and its contributions.This is not the place to critique the paper.The authors should generally agree with a well-written summary, which reflects an accurate understanding of their work from a multidisciplinary perspective.2. Strengths and Weaknesses: Please provide a thorough assessment of the strengths and weaknesses of the paper, touching on each of the following dimensions:</p>
<p>-Originality: Are the tasks or methods novel within each of the relevant disciplines?Does the work represent an innovative combination of techniques or concepts from different fields?Is it clear how this work distinguishes itself from previous contributions in each discipline involved?-Quality: Is the submission technically sound in each of the relevant fields?Are claims well-supported by evidence (e.g., theoretical analysis or experimental results)?Are the methods used appropriately for each discipline involved?Is this a complete piece of work, or still a work in progress?Are the authors transparent and honest in evaluating both the strengths and weaknesses of their work?-Clarity: Is the paper written in a way that is accessible to readers from multiple disciplines?Is it well-organized, with clear explanations of concepts across different fields?If not, please suggest improvements for clarity.Does it provide sufficient detail for an expert in each relevant field to understand the methodology and reproduce results?-Significance: Are the results important?Are others (researchers or practitioners) likely to use the ideas or build on them?Does the submission address a difficult task in a better way than previous work?Does it advance the state of the art in a demonstrable way?Does it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?3. Questions: Please list any questions or suggestions that could help clarify the paper's limitations or improve its quality.Responses from the authors could change your opinion or address areas of confusion.This feedback can be critical for the rebuttal and discussion phase with the authors.</p>
<p>Figure 1 :
1
Figure 1: An illustration comparing human-driven and AI-driven research processes in the SoS, highlighting step-by-step differences across four key stages in order: data processing, data analysis, system simulation, and pattern validation.</p>
<p>Figure 3 :
3
Figure3: The overview of our preliminary multi-agent system for scientific collaboration simulation.We place the simulation within a community of scientists.After a scientist leads his/her team in submitting a paper, it undergoes peer review.If accepted, it is added to the reference database and can be cited by other scientists in subsequent epochs.Due to varying author information, the citation count of the final research output differs, then we can analyze the correlation between them-understanding the dynamics of research organizations, which is important in the field of SoS.</p>
<p>Figure 4 :
4
Figure 4: The time taken for a complete scientific collaboration with agents of different scales.A simulation of a million-agent society takes only one week.</p>
<p>AI4SoS</p>
<p>Figure 5 :
5
Figure 5: The statistics of team sizes for papers published between 2002 and 2009 in the OAG, with the red fitting line revealing that the distribution follows an exponential pattern.</p>
<p>Figure 6 :
6
Figure 6: Comparison of real-world (2010) and AI-simulated scientific research patterns.The scatter plots illustrate the relationships between Ethnicity Diversity, Affiliation Diversity, and Affiliation Ranking with Citation Count in both real-world (top row) and simulated (bottom row) data.Strong correlations observed in real data are partially reproduced by the AI-driven multi-agent system, demonstrating its potential to uncover meaningful patterns in scientific research and support automated SoS studies.</p>
<p>Figure 7 :
7
Figure 7: Comparison of real-world (2011) and AI-simulated scientific research patterns.</p>
<p>Table 1 :
1
Comparison between AI for Science and AI for Science of Science.
FeatureAI for ScienceAI for Science of ScienceFocusSolving domain-specificUnderstanding mechanismsscientific problems.of scientific progress.Approach Direct application of AI toMeta-level analysis toaddress scientific challenges.enhance the research process.Examples Predicting weather,Studying researchdesigning new drugs,collaboration trends,optimizing materials.analyzing innovation triggers,mapping knowledge growth.</p>
<p>An overview of the five progressively advancing levels of autonomy in AI4SoS, with more green areas indicating that higher levels correspond to greater degrees of autonomy.Current research is primarily at Level 2 or below, with very limited work at Level 3, while fully automated SoS discovery remains in the prospective stage.
Research ProcessPattern Validatione.g., Social experimentse.g., A simulated society for collaboration pattern discovery, …System Simulatione.g., Rule-based simulatione.g., Multi-agent systems for simulating specific research scenarios to propose hypotheses or reproduce historical events, …e.g., Correlatione.g., Machine learning models for predicting individual paper citationData Analysisanalysis for variablecounts, neural networks for forecasting research trends and generatingrelationshipsunexpected ideas, …Data Processinge.g., Manual data cleaninge.g., Text-to-Embedding methods for mapping papers to vector space, named entity recognition for extracting key information from papers, …Level 0:Level 1:Level 2:Level 3:Level 4:Autonomy LevelsNon-automatedAssistedPartially AutomatedHighly AutomatedFully AutomatedFigure 2:</p>
<p>Table 2 :
2
Summary table of large-scale cross-discipline academic datasets.
DatasetsMAGOAGSciSciNetDue202020232021DomainArt, Biology,Art, Biology,Art, Biology,Business,Business,Business,Chemistry,Chemistry,Chemistry,Computer Science,Computer Science,Computer Science,Economics,Economics,Economics,Engineering,Engineering,Engineering,EnvironmentalEnvironmentalEnvironmentalScience,Science,Science,Geography,Geography,Geography,Geology, History,Geology, History,Geology, History,Materials Science,Materials Science,Materials Science,Mathematics,Mathematics,Mathematics,Philosophy,Philosophy,Medicine,Physics, PoliticalPhysics, PoliticalPhilosophy,Science,Science,Physics, PoliticalPsychology,Psychology,Science,SociologySociologyPsychology,SociologyAuthor261,445,82535,774,510134,197,162Paper247,389,875130,710,733134,129,188Affiliation25,811143,74926,998</p>
<p>Goal: Analysis of Science of Science Goal: Analysis of Science of Science Scientist Society
Collaborator SelectionAuthor InformationIncludeName/Affiliation/Ethnicity/Citation…Topic DiscussionLarge Fail?Idea GenerationReference DatabaseIncludeTitle/Abstract/Year/ Author/Citation…Novelty Assessment1. Record new published paperAbstract GenerationPeer Review2. Update the citation of cited papersSmall Fail?Multi-Agent System</p>
<p>Table 3 :
3
[11]ary table of disciplines and fields[11].
FieldDisciplineHumanities, Literature &amp; Arts [Art, History, Philosophy, Psychology]Life Science &amp; Earth Sciences[Biology, Environmental Science, Geogra-phy, Geology]Business, Economics &amp;[Business, Economics]ManagementEngineering &amp; Computer[Computer Science, Engineering]ScienceChemical &amp; Material Sciences[Chemistry, Materials Science]Physics &amp; Mathematics[Mathematics, Physics]Health &amp; Medical Sciences[Medicine]Social Sciences[Political Science, Sociology]which is used to analyze the potential different patterns in various areas. Weuse papers from 2002 to 2009 as the reference database and papers from 2010 to2011 as the validation database. To address missing author ethnicity and paper
field information-key elements for validating SoS findings-we employ several data completion strategies.Specifically, we adopt corresponding approaches for the various pieces of author information and paper information in this dataset for our simulation, shown in Table4 and 5.</p>
<p>Table 4 :
4
Different strategies are adopted for various pieces of information regarding authors.
FieldStrategyExampleNameAuthor InformationNameUse the anonymization techniqueScientist 1EthnicityUse the name ethnicity classifier [81]BritishAffiliationRetain the original content[King's CollegeLondon]AffiliationUse THE World University Rankings36Ranking2025 1CitationExtract the author's published papers be-1800tween 2010 to 2020 and calculate the totalnumber of citations for the papers; In thesimulation, it will be updated if his/herpaper is citedCo-author Extract the author's published papers be-[Scientist 10,tween 2010 to 2020 and record the collab-Scientist 201,orators in the papers; In the simulation,Scientist 1002,it will be updated if there are new collab-. . . ]oratorsDisciplineExtract the author's published papers be-Psychologytween 2010 to 2020 and assign the au-thor's discipline as the one that appearsmost frequentlyResearchExtract the author's published papers[Neuropsychology,topicbetween 2010 to 2020 and record theCognitivekeywords in the papers; Use GPT-4 toflexibility, Atten-summarize these keywords into researchtional bias, . . . ]topics</p>
<p>Table 6 :
6
Prompt Tailored for Multidisciplinary Reviewers Prompt Tailored for Multidisciplinary Reviewers (1/2)</p>
<p>https://open.aminer.cn/open/article?id=65bf053091c938e5025a31e2
https://www.timeshighereducation.com/world-university-rankings/latest /world-ranking
https://neurips.cc/Conferences/2024/ReviewerGuidelines
AcknowledgementsThis work is supported by Shanghai Artificial Intelligence Laboratory.AI4SoSAI4SoSTable7: Prompt Tailored for Multidisciplinary Reviewers Prompt Tailored for Multidisciplinary Reviewers (2/2) 4. Ethical Concerns: Flag any ethical concerns, particularly those that may arise from interdisciplinary collaboration.Ensure any ethical issues related to research design, data usage, or broader implications are addressed.5. Overall Score: Provide a final score based on the paper's strengths and weaknesses.Use the following scale:-10: Award Quality: A technically flawless paper with groundbreaking impact across one or more disciplines, with exceptionally strong evaluation, reproducibility, and resources, and no unaddressed ethical concerns.-9: Very Strong Accept: A technically flawless paper with groundbreaking impact in at least one area and strong impact on multiple areas, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical concerns.-8: Strong Accept: A technically strong paper with novel ideas, significant impact on at least one discipline or moderate-to-high impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical concerns.-7: Accept: A technically solid paper with moderate-to-high impact in one or more subfields, good-to-excellent evaluation, reproducibility, and resources, and no unaddressed ethical concerns.-6: Weak Accept: A solid paper with moderate impact, no major concerns in terms of evaluation, reproducibility, and ethical considerations.-5: Borderline Accept: A technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation.Use sparingly.-4: Borderline Reject: A technically solid paper where reasons to reject outweigh reasons to accept, e.g., limited evaluation.Use sparingly.-3: Reject: A paper with technical flaws, weak evaluation, inadequate reproducibility, or incompletely addressed ethical concerns.-2: Strong Reject: A paper with major technical flaws, poor evaluation, limited impact, poor reproducibility, or mostly unaddressed ethical considerations.-1: Very Strong Reject: A paper with trivial results, poor evaluation, or unaddressed ethical issues.
. S Fortunato, C T Bergstrom, K Börner, J A Evans, D Helbing, S Milojević, A M Petersen, F Radicchi, R Sinatra, B Uzzi, Science of science. 35963791852018Science</p>
<p>Scientific discovery and topological transitions in collaboration networks. L M Bettencourt, D I Kaiser, J Kaur, Journal of Informetrics. 332009</p>
<p>Weaving the fabric of science: Dynamic network models of science's unfolding structure. F Shi, J G Foster, J A Evans, Social Networks. 432015</p>
<p>Which type of citation analysis generates the most accurate taxonomy of scientific and technical knowledge. R Klavans, K W Boyack, Journal of the Association for Information Science and Technology. 6842017</p>
<p>The science of science. D Wang, L Liu, Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020. the ACM/IEEE Joint Conference on Digital Libraries in 20202020</p>
<p>Quantifying hierarchy and dynamics in us faculty hiring and retention. K H Wapman, S Zhang, A Clauset, D B Larremore, Nature. 61079302022</p>
<p>Drugclip: Contrasive protein-molecule representation learning for virtual screening. B Gao, B Qiang, H Tan, Y Jia, M Ren, M Lu, J Liu, W.-Y Ma, Y Lan, Advances in Neural Information Processing Systems. 362024</p>
<p>Accurate structure prediction of biomolecular interactions with alphafold 3. J Abramson, J Adler, J Dunger, R Evans, T Green, A Pritzel, O Ronneberger, L Willmore, A J Ballard, J Bambrick, Nature. 2024</p>
<p>Bidirectional generation of structure and properties through a single molecular foundation model. J Chang, J C Ye, Nature Communications. 15123232024</p>
<p>Choosing experiments to accelerate collective discovery. A Rzhetsky, J G Foster, I T Foster, J A Evans, Proceedings of the National Academy of Sciences. 112472015</p>
<p>The preeminence of ethnic diversity in scientific collaboration. B K Alshebli, T Rahwan, W L Woon, Nature communications. 915163</p>
<p>. Ai4sos, 2018</p>
<p>Hot streaks in artistic, cultural, and scientific careers. L Liu, Y Wang, R Sinatra, C L Giles, C Song, D Wang, Nature. 55977142018</p>
<p>Quantifying the dynamics of failure across science, startups and security. Y Yin, Y Wang, J A Evans, D Wang, Nature. 57577812019</p>
<p>Surprising combinations of research contents and contexts are related to impact and emerge with scientific outsiders from distant disciplines. F Shi, J Evans, Nature Communications. 1416412023</p>
<p>Named entity recognition and normalization applied to large-scale information extraction from the materials science literature. L Weston, V Tshitoyan, J Dagdelen, O Kononova, A Trewartha, K A Persson, G Ceder, A Jain, Journal of chemical information and modeling. 5992019</p>
<p>Systematic inequality and hierarchy in faculty hiring networks. A Clauset, S Arbesman, D B Larremore, Science advances. 1114000052015</p>
<p>On modeling and predicting individual paper citation count over time. S Xiao, J Yan, C Li, B Jin, X Wang, X Yang, S M Chu, H Zha, Ijcai. 2016</p>
<p>Predicting research trends with semantic and neural networks with an application in quantum physics. M Krenn, A Zeilinger, Proceedings of the National Academy of Sciences. 11742020</p>
<p>Citation-based clustering of publications using citnetexplorer and vosviewer. N J Van Eck, L Waltman, Scientometrics. 1112017</p>
<p>The diversity-innovation paradox in science. B Hofstra, V V Kulkarni, Munoz-Najar, S Galvez, B He, D Jurafsky, D A Mcfarland, Proceedings of the National Academy of Sciences. 117172020</p>
<p>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning. A Ghafarollahi, M J Buehler, arXiv:2409.055562024arXiv preprint</p>
<p>Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation. H Su, R Chen, S Tang, X Zheng, J Li, Z Yin, W Ouyang, N Dong, arXiv:2410.094032024arXiv preprint</p>
<p>Z Yang, Z Zhang, Z Zheng, Y Jiang, Z Gan, Z Wang, Z Ling, J Chen, M Ma, B Dong, arXiv:2411.11581Oasis: Open agents social interaction simulations on one million agents. 2024arXiv preprint</p>
<p>Ai energized hydrogel design, optimization and application in biomedicine. Z Li, P Song, G Li, Y Han, X Ren, L Bai, J Su, Materials Today Bio. 1010142024</p>
<p>Artificial intelligence research: A review on dominant themes, methods, frameworks and future research directions. K Ofosu-Ampong, Telematics and Informatics Reports. 1001272024</p>
<p>Network dynamics of innovation processes. I Iacopini, S Milojević, V Latora, Physical review letters. 1204483012018</p>
<p>Educating the future generation of researchers: A cross-disciplinary survey of trends in analysis methods. T Bolt, J S Nomi, D Bzdok, L Q Uddin, PLoS biology. 19730013132021</p>
<p>Forecasting innovations in science, technology, and education. K Börner, W B Rouse, P Trunfio, H E Stanley, Proceedings of the National Academy of Sciences. 115502018</p>
<p>J Zhou, G Cui, S Hu, Z Zhang, C Yang, Z Liu, L Wang, C Li, M Sun, Graph neural networks: A review of methods and applications. AI open 1. 2020</p>
<p>Early-career setback and future career impact. Y Wang, B F Jones, D Wang, Nature communications. 10143312019</p>
<p>Large teams develop and small teams disrupt science and technology. L Wu, D Wang, J A Evans, Nature. 5662019</p>
<p>The increasing dominance of teams in production of knowledge. S Wuchty, B F Jones, B Uzzi, Science. 31658272007</p>
<p>Genderdiverse teams produce more novel and higher-impact scientific ideas. Y Yang, T Y Tian, T K Woodruff, B F Jones, B Uzzi, Proceedings of the National Academy of Sciences. 1193622008411192022</p>
<p>Non-white scientists appear on fewer AI4SoS editorial boards, spend more time under review, and receive fewer citations. F Liu, T Rahwan, B Alshebli, Proceedings of the National Academy of Sciences. 1201322153241202023</p>
<p>Leading countries in global science increasingly receive more citations than other countries doing similar research. C J Gomez, A C Herman, P Parigi, Nature Human Behaviour. 672022</p>
<p>Team assembly mechanisms determine collaboration network structure and team performance. R Guimera, B Uzzi, J Spiro, L A N Amaral, Science. 30857222005</p>
<p>An insight into imbalanced big data classification: outcomes and challenges. A Fernández, S Del Río, N V Chawla, F Herrera, Complex &amp; Intelligent Systems. 32017</p>
<p>A systematic review on imbalanced data challenges in machine learning: Applications and solutions. H Kaur, H S Pannu, A K Malhi, ACM computing surveys (CSUR). 5242019</p>
<p>A survey on addressing high-class imbalance in big data. J L Leevy, T M Khoshgoftaar, R A Bauder, N Seliya, Journal of Big Data. 512018</p>
<p>Survey on deep learning with class imbalance. J M Johnson, T M Khoshgoftaar, Journal of big data. 612019</p>
<p>Data, measurement and empirical methods in the science of science. L Liu, B F Jones, B Uzzi, D Wang, Nature human behaviour. 772023</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>A Dubey, A Jauhri, A Pandey, A Kadian, A Al-Dahle, A Letman, A Mathur, A Schelten, A Yang, A Fan, arXiv:2407.21783The llama 3 herd of models. 2024arXiv preprint</p>
<p>A Yang, B Yang, B Zhang, B Hui, B Zheng, B Yu, C Li, D Liu, F Huang, H Wei, arXiv:2412.15115Qwen2. 5 technical report. 2024arXiv preprint</p>
<p>A survey on bias and fairness in machine learning. N Mehrabi, F Morstatter, N Saxena, K Lerman, A Galstyan, ACM computing surveys (CSUR). 5462021</p>
<p>An overview of microsoft academic service (mas) and applications. A Sinha, Z Shen, Y Song, H Ma, D Eide, B.-J Hsu, K Wang, Proceedings of the 24th International Conference on World Wide Web. the 24th International Conference on World Wide Web2015</p>
<p>Oag: Linking entities across largescale heterogeneous knowledge graphs. F Zhang, X Liu, J Tang, Y Dong, P Yao, J Zhang, X Gu, Y Wang, E Kharlamov, B Shao, IEEE Transactions on Knowledge and Data Engineering. 3592022</p>
<p>Sciscinet: A large-scale open data lake for the science of science research. Z Lin, Y Yin, L Liu, D Wang, Scientific Data. 1013152023</p>
<p>Tackling the issue of bias in artificial intelligence to design ai-driven fair and inclusive service systems. how human biases are breaching into ai algorithms, with severe impacts on individuals and societies, and what designers can do to face this phenomenon and change for the better. V Scatiggio, 2020</p>
<p>V Prabhakaran, A M Davani, M Diaz, arXiv:2110.05699On releasing annotator-level labels and information in datasets. 2021arXiv preprint</p>
<p>Informal approaches to developing simulation models. E Norling, B Edmonds, R Meyer, Simulating Social Complexity: A Handbook. 2017</p>
<p>Large language models empowered agent-based modeling and simulation: A survey and perspectives. C Gao, X Lan, N Li, Y Yuan, J Ding, Z Zhou, F Xu, Y Li, Humanities and Social Sciences Communications. 1112024</p>
<p>Calibrating real-world city traffic simulation model using vehicle speed data. S Khaleghian, H Neema, M Sartipi, T Tran, R Sen, A Dubey, 2023 IEEE International Conference on Smart Computing (SMARTCOMP). IEEE2023</p>
<p>Agent-based modelling of social-ecological systems: achievements, challenges, and a way forward. J Schulze, B Müller, J Groeneveld, V Grimm, Journal of Artificial Societies and Social Simulation. 2022017</p>
<p>Challenges, tasks, and opportunities in modeling agent-based complex systems. L An, V Grimm, A Sullivan, B Turner Ii, N Malleson, A Heppenstall, C Vincenot, D Robinson, X Ye, J Liu, Ecological Modelling. 457I4S2021</p>
<p>How to receive more funding for your research? get connected to the right people. A Ebadi, A Schiffauerova, PloS one. 1071330612015</p>
<p>The evolutions of the rich get richer and the fit get richer phenomena in scholarly networks: The case of the strategic management journal. G A Ronda-Pupo, T Pham, Scientometrics. 11612018</p>
<p>Metrics of inequality: The concentration of resources in the us biomedical elite. Y Katz, U Matter, Science as Culture. 2942020</p>
<p>Chatdev: Communicative agents for software development. C Qian, W Liu, H Liu, N Chen, Y Dang, J Li, C Yang, W Chen, Y Su, X Cong, J Xu, D Li, Z Liu, M Sun, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. the 62nd Annual Meeting of the Association for Computational Linguistics2024</p>
<p>Large language model based multi-agents: A survey of progress and challenges. T Guo, X Chen, Y Wang, R Chang, S Pei, N V Chawla, O Wiest, X Zhang, arXiv:2402.016802024arXiv preprint</p>
<p>C Aldrich, L Auret, Unsupervised Process Monitoring and Fault Diagnosis with Machine Learning Methods. Springer201316</p>
<p>The philosopher's stone for science-the catalyst change of ai for scientific creativity. Pin and Wang, Dashun, The Philosopher's Stone for Science-The Catalyst Change of AI for Scientific Creativity. Q Chen, Y.-J I Ho, P Sun, D Wang, March 5, 2024. 2024</p>
<p>The road ahead: Emerging trends, unresolved issues, and concluding remarks in generative ai-a comprehensive review. S Balasubramaniam, V Chirchi, S Kadry, M Agoramoorthy, S P Gururama, K K Satheesh, T Sivakumar, International Journal of Intelligent Systems. 20242024</p>
<p>Navigating the future of large language models in scientific research: Opportunities, challenges, and ethical considerations. Challenges, and Ethical Considerations. M Lissack, B Meagher, September 02, 2024. 2024</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, arXiv:2408.062922024arXiv preprint</p>
<p>Localvaluebench: A collaboratively built and extensible benchmark for evaluating localized value alignment and ethical safety in large language models. G I Meadows, N W L Lau, E A Susanto, C L Yu, A Paul, arXiv:2408.014602024arXiv preprint</p>
<p>J Ji, Y Chen, M Jin, W Xu, W Hua, Y Zhang, arXiv:2406.04428Moralbench: Moral evaluation of llms. 2024arXiv preprint</p>
<p>Interpreting black-box models: a review on explainable artificial intelligence. V Hassija, V Chamola, A Mahapatra, A Singal, D Goel, K Huang, S Scardapane, I Spinelli, M Mahmud, A Hussain, Cognitive Computation. 1612024</p>
<p>Towards scientific discovery with generative ai: Progress, opportunities, and challenges. C K Reddy, P Shojaee, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Scientific collaboration. D H Sonnenwald, Annu. Rev. Inf. Sci. Technol. 4112007</p>
<p>Causal models and learning from data: integrating causal modeling and statistical estimation. M L Petersen, M J Van Der Laan, Epidemiology. 2532014</p>
<p>Causal machine learning for predicting treatment outcomes. S Feuerriegel, D Frauen, V Melnychuk, J Schweisthal, K Hess, A Curth, S Bauer, N Kilbertus, I S Kohane, M Van Der Schaar, Nature Medicine. 3042024</p>
<p>Explainable ai (xai): Core ideas, techniques, and solutions. R Dwivedi, D Dave, H Naik, S Singhal, R Omer, P Patel, B Qian, Z Wen, T Shah, G Morgan, ACM Computing Surveys. 5592023</p>
<p>Explainable artificial intelligence (xai) 2.0: A manifesto of open challenges and interdisciplinary research directions. L Longo, M Brcic, F Cabitza, J Choi, R Confalonieri, J Del Ser, R Guidotti, Y Hayashi, F Herrera, A Holzinger, Information Fusion. 1061023012024</p>
<p>Comparative effectiveness of matching methods for causal inference. Unpublished manuscript. G King, R Nielsen, C Coberley, J E Pope, A Wells, 2011Cambridge, MAInstitute for Quantitative Social Science, Harvard University</p>
<p>G W Imbens, D B Rubin, Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge university press2015I4S</p>
<p>Applications of structural equation modeling in social sciences research. J De Carvalho, F O Chima, American International Journal of Contemporary Research. 412014</p>
<p>Methodological research on partial least squares structural equation modeling (pls-sem) an analysis based on social network approaches. G F Khan, M Sarstedt, W.-L Shiau, J F Hair, C M Ringle, M P Fritze, Internet Research. 2932019</p>
<p>Mapping of machine learning approaches for description, prediction, and causal inference in the social and health sciences. A K Leist, M Klee, J H Kim, D H Rehkopf, S P Bordas, G Muniz-Terrera, S Wade, Science Advances. 84219422022</p>
<p>B Qi, K Zhang, K Tian, H Li, Z.-R Chen, S Zeng, E Hua, H Jinfang, B Zhou, arXiv:2407.08940Large language models as biomedical hypothesis generators: A comprehensive evaluation. 2024arXiv preprint</p>
<p>Nameethnicity classification from open sources. A Ambekar, C Ward, J Mohammed, S Male, S Skiena, Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining2009</p>
<p>Early coauthorship with top scientists predicts success in academic careers. W Li, T Aste, F Caccioli, G Livan, Nature communications. 10151702019</p>
<p>Fairness in machine learning: Lessons from political philosophy. R Binns, Conference on Fairness, Accountability and Transparency. PMLR2018</p>
<p>Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products. I D Raji, J Buolamwini, Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. the 2019 AAAI/ACM Conference on AI, Ethics, and Society2019</p>
<p>Artificial intelligence and illusions of understanding in scientific research. L Messeri, M Crockett, Nature. 6272024</p>
<p>Improving fairness in machine learning systems: What do industry practitioners need?. K Holstein, J Wortman Vaughan, Iii Daumé, H Dudik, M Wallach, H , Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. the 2019 CHI Conference on Human Factors in Computing Systems2019</p>
<p>A proposal for identifying and managing bias in artificial intelligence. R Schwartz, L Down, A Jonas, E Tabassi, Draft NIST Special Publication. 12702021</p>
<p>R Schwartz, R Schwartz, A Vassilev, K Greene, L Perine, A Burt, P Hall, Towards a Standard for Identifying and Managing Bias in Artificial Intelligence. 20223US Department of Commerce, National Institute of Standards and Technology</p>
<p>Ai and science: what 1,600 researchers think. R Van Noorden, J M Perkel, Nature. 62179802023</p>
<p>Artificial intelligence within the interplay between natural and artificial computation: Advances in data science, trends and applications. J M Górriz, J Ramírez, A Ortiz, F J Martinez-Murcia, F Segovia, J Suckling, M Leming, Y.-D Zhang, J R Álvarez-Sánchez, G Bologna, Neurocomputing. 4102020</p>
<p>Innovation and design in the age of artificial intelligence. R Verganti, L Vendraminelli, M Iansiti, Journal of product innovation management. 3732020</p>
<p>Ai-powered innovations in high-tech research and development: From theory to practice. M Madanchian, H Taherdoost, Computers, Materials &amp; Continua. 8122024</p>
<p>Atomnet: a deep convolutional neural network for bioactivity prediction in structure-based drug discovery. I Wallach, M Dzamba, A Heifets, arXiv:1510.028552015arXiv preprint</p>
<p>Machine learning in drug design: Use of artificial intelligence to explore the chemical structure-biological activity relationship. M Staszak, K Staszak, K Wieszczycka, A Bajek, K Roszkowski, B Tylkowski, Wiley Interdisciplinary Reviews: Computational Molecular Science. 12215682022</p>
<p>Evolving the materials genome: How machine learning is fueling the next generation of materials discovery. C Suh, C Fare, J A Warren, E O Pyzer-Knapp, Annual Review of Materials Research. 5012020</p>
<p>Materials discovery with extreme properties via reinforcement learning-guided combinatorial chemistry. H Kim, H Choi, D Kang, W B Lee, J Na, Chemical Science. 2024</p>
<p>Avalonbench: Evaluating llms playing the game of avalon. J Light, M Cai, S Shen, Z Hu, NeurIPS 2023 Foundation Models for Decision Making Workshop. 2023I4S</p>
<p>Z Du, C Qian, W Liu, Z Xie, Y Wang, Y Dang, W Chen, C Yang, arXiv:2406.08979Multi-agent software development through cross-team collaboration. 2024arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Journal of machine learning research. 211402020</p>
<p>OpenAI: GPT-4 technical report. CoRR2023</p>
<p>A Dubey, A Jauhri, A Pandey, A Kadian, A Al-Dahle, A Letman, A Mathur, A Schelten, A Yang, A Fan, arXiv:2407.21783The llama 3 herd of models. 2024arXiv preprint</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J D Kenton, M.-W C Toutanova, L K , Proceedings of naacL-HLT. naacL-HLTMinneapolis, Minnesota201912</p>
<p>Dnabert: pre-trained bidirectional encoder representations from transformers model for dna-language in genome. Y Ji, Z Zhou, H Liu, R V Davuluri, Bioinformatics. 37152021</p>
<p>D Zhang, W Liu, Q Tan, J Chen, H Yan, Y Yan, J Li, W Huang, X Yue, D Zhou, arXiv:2402.06852Chemllm: A chemical large language model. 2024arXiv preprint</p>
<p>Benchmarking large language models on cmexam-a comprehensive chinese medical exam dataset. J Liu, P Zhou, Y Hua, D Chong, Z Tian, A Liu, H Wang, C You, Z Guo, L Zhu, Advances in Neural Information Processing Systems. 362024</p>
<p>Exploring collaboration mechanisms for LLM agents: A social psychology view. J Zhang, X Xu, N Zhang, R Liu, B Hooi, S Deng, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. the 62nd Annual Meeting of the Association for Computational Linguistics2024</p>
<p>R Nogueira, K Cho, arXiv:1901.04085Passage re-ranking with bert. 2019arXiv preprint</p>
<p>From word embeddings to pre-trained language models: A state-of-the-art walkthrough. M Mars, Applied Sciences. 121788052022</p>
<p>Improving sentiment analysis for social media applications using an ensemble deep learning language model. A Alsayat, Arabian Journal for Science and Engineering. 4722022</p>
<p>A Petukhova, J P Matos-Carvalho, N Fachada, arXiv:2403.15112Text clustering with llm embeddings. 2024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>