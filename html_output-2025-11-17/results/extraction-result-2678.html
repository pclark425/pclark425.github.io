<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2678 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2678</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2678</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-3763c501e5523fe5fcd0d370af226d7da9348c8c</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3763c501e5523fe5fcd0d370af226d7da9348c8c" target="_blank">A Bayesian machine scientist to aid in the solution of challenging scientific problems</a></p>
                <p><strong>Paper Venue:</strong> Science Advances</p>
                <p><strong>Paper TL;DR:</strong> A Bayesian machine scientist is introduced, which establishes the plausibility of models using explicit approximations to the exact marginal posterior over models and establishes its prior expectations about models by learning from a large empirical corpus of mathematical expressions.</p>
                <p><strong>Paper Abstract:</strong> A Bayesian machine scientist uncovers closed-form mathematical models from data. Closed-form, interpretable mathematical models have been instrumental for advancing our understanding of the world; with the data revolution, we may now be in a position to uncover new such models for many systems from physics to the social sciences. However, to deal with increasing amounts of data, we need “machine scientists” that are able to extract these models automatically from data. Here, we introduce a Bayesian machine scientist, which establishes the plausibility of models using explicit approximations to the exact marginal posterior over models and establishes its prior expectations about models by learning from a large empirical corpus of mathematical expressions. It explores the space of models using Markov chain Monte Carlo. We show that this approach uncovers accurate models for synthetic and real data and provides out-of-sample predictions that are more accurate than those of existing approaches and of other nonparametric methods.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2678.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2678.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian machine scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian machine scientist (Guimerà et al., 2020)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic symbolic-regression system that samples closed-form mathematical expressions via MCMC, assigns each expression a marginal-posterior plausibility using an explicit approximation to the model evidence (description length ≈ BIC/2 - log prior), and learns a prior over expression structure from an empirical corpus of formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian machine scientist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Symbolic Bayesian inference system that represents closed-form expressions as expression trees; defines a prior over expression structure by fitting an exponential-random-graph-style maximum-entropy model to a corpus of 4,080 Wikipedia formulas; evaluates model plausibility via the marginal posterior p(f|D) approximated through a description length L(f) ≈ B(f)/2 - log p(f) (B is BIC); explores expression space using Metropolis-style MCMC with three move types (node replacement, root addition/removal, elementary-tree replacement), augmented with parallel tempering; canonicalizes expressions via Sympy to avoid duplicates; fits continuous parameters by least squares/maximum likelihood when computing BIC; produces posterior predictive distributions by averaging sampled expressions weighted by p(f|D) and selects a 'median predictive model' for a single interpretable closed form.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Bayesian symbolic regression / probabilistic symbolic model-averaging</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General-purpose: physics (Rössler, turbulent friction), fluid mechanics (Nikuradse dataset), ecology, cell biology, socioeconomics (funding success), and synthetic benchmark functions (Bessel functions).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate hypotheses (closed-form mathematical expressions) by stochastic moves on expression-tree space (node replacement, root addition/removal, elementary-tree replacement) within an MCMC sampler; candidate models are proposed from an enumerated set of possible elementary trees and operations and accepted/rejected using Metropolis rules based on change in description length ΔL (which encodes fit via BIC and prior over expressions). Parallel tempering is used to escape local minima.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility measured by marginal posterior p(f|D) approximated via description length L(f) ≈ BIC(f)/2 - log p(f); p(f) is a learned prior over expression structure (maximum-entropy model matching corpus counts); high plausibility corresponds to low description length.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Balance achieved implicitly by the posterior: goodness-of-fit enters via the BIC term (penalizes poor fit), while structural complexity and prior expectations about realistic formula structure enter via the learned prior p(f); for large datasets the BIC dominates, while for small/noisy datasets the prior regularizes against structurally overfitting models.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Description length (L ≈ BIC/2 - log p(f)) as the primary scalar; BIC; out-of-sample prediction error metrics such as mean absolute error (MAE) / cross-validation error reported in experiments; also inspection of posterior predictive distribution and whether true generating model lies among high-plausibility models in synthetic tests.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational validation on synthetic datasets (recovering known closed-form models and differential equations like the Rössler system, Bessel-function approximations), and empirical validation on real datasets (Nikuradse turbulent-friction data, ecological and socio-economic small datasets); comparisons to alternative symbolic/regression methods (Eureqa, EPLEX, EFS) and to Gaussian processes for out-of-sample predictive performance; evaluation includes whether the true model is among high-plausibility samples and predictive MAE on held-out data.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Code and data publicly available on Bitbucket; canonicalization of expression trees via Sympy to avoid duplicate equivalent expressions; explicit specification of operations, maximum tree size, MCMC move probabilities, and prior-fitting procedure (hyperparameter update loop) to allow replication.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Structural regularization via an empirically learned prior over expression forms (reduces structurally overfitting, i.e., implausible complex formulas that fit noise); BIC-based penalization of parameter complexity; canonicalization to prevent redundant/degenerate formula representations.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Full Bayesian uncertainty over discrete model space approximated by MCMC samples of p(f|D); posterior predictive distribution p(y|D,x) approximated by averaging point predictions of sampled models weighted by their posterior plausibilities; use of ensemble statistics (median predictive model) and reporting distributions of description lengths among sampled models as uncertainty diagnostics.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Synthetic datasets (drawn closed-form functions, Rössler system trajectories with added noise, Bessel-function data), real datasets including Nikuradse turbulent-friction measurements, datasets on funding success, cell-to-cell stresses, and salmon stocks; corpus of 4,080 Wikipedia expressions used to learn the prior (not a benchmark but an empirical source).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported qualitative and graphical results: recovers true generating closed-form expressions on synthetic data (e.g., recovers chosen two-variable formula with 400 points and as few as 100 points in some cases), recovers Rössler differential equations under moderate noise, produces out-of-sample predictions with lower MAE than Eureqa, EFS, EPLEX and Gaussian processes on the Nikuradse dataset; exact numeric metric values are presented in figures and supplementary tables but not enumerated as single summary numbers in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared empirically against Eureqa (genetic-programming symbolic regression), EPLEX (genetic programming variant), EFS (genetic-generation of basis + sparse regression), and Gaussian processes; the Bayesian machine scientist yields better out-of-sample predictive accuracy and more consistent recovery of true expressions in synthetic tests, while other methods tended to structurally overfit or fail to recover the true generating forms.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Produced interpretable closed-form models for the Nikuradse turbulent-friction dataset that fit the data well and predict the correct asymptotic scaling; however, the paper reports model discovery and predictive validation on existing experimental data rather than reporting new experimental validation beyond data-fitting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>MCMC sampling can be slow and may require many restarts/parallel tempering to explore rugged expression landscapes; description-length approximation via BIC can fail for small or very noisy datasets and may require more accurate marginal-likelihood estimation (generalized BIC or numerical integration); prior learned from Wikipedia corpus is somewhat arbitrary and may need tailoring (domain-specific priors) to avoid violating required physical constraints (dimensional consistency, limiting behavior); expression-tree size is artificially limited (50 nodes) in implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2678.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2678.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureqa (Schmidt & Lipson)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic-programming-based symbolic regression system that evolves populations of candidate formulas to fit data, using a user-specified complexity penalty per operation and fitness-driven selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distilling free-form natural laws from experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Genetic programming symbolic-regression tool that represents candidate expressions as tree-structured programs, evolves populations via crossover and mutation, and uses a fitness function (typically trade-off between error and user-defined complexity penalties) to select and refine models. In the paper it was run with default operation complexity penalties and evaluated as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Genetic-programming symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General-purpose; used as a baseline across multiple domains in the paper (physics/fluid mechanics datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Population-based genetic programming: stochastically generates and evolves expressions via evolutionary operators (crossover, mutation) guided by fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Fitness combining fit-to-data and user-specified complexity penalties; complexity penalties per operation were set to defaults in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Fitness (default settings used), mean squared error for model selection in experiments, and out-of-sample MAE for comparative evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical performance on the same synthetic and real datasets used by the Bayesian machine scientist; out-of-sample predictive comparisons (MAE) and model structural inspection.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Runs performed with default penalties and extensive evaluation (authors ran Eureqa until ≥10^13 expressions evaluated); Eureqa desktop is available publicly (reference provided).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Used as baseline on Nikuradse and synthetic datasets in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Performed worse than the Bayesian machine scientist on out-of-sample prediction for the Nikuradse dataset (figures show lower MAE for the Bayesian approach); exact numeric MAE values are presented in figures/supplement but not enumerated in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Eureqa served as a baseline; Bayesian machine scientist produced models with better predictive accuracy and, in many synthetic cases, recovered the true generating model where Eureqa did not.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires manual setting of operation complexity penalties; can structurally overfit and may fail to explore model space in a way that yields true generating expressions for some problems (as observed in comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2678.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2678.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EPLEX</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ε-lexicase selection (EPLEX)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming variant using ε-lexicase selection designed to improve generalization in symbolic regression; used as a benchmark in the paper but performed worse than other baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EPLEX</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Genetic-programming-based symbolic regression method that employs ε-lexicase selection to pick individuals based on performance across cases, intended to maintain diverse solutions and avoid premature convergence. In this paper it was run with configurations from a prior benchmark study and used as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Genetic-programming symbolic regression (lexicase selection variant)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General-purpose; used as a baseline for symbolic regression tasks in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Evolves populations of candidate expressions via genetic operators; ε-lexicase selection chooses parents based on per-case performance criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Fitness-based selection with lexicase selection dynamics; standard fitness metrics used for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Population fitness, out-of-sample MAE used for comparison; EPLEX was reported to give worse results than Eureqa in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Evaluated on the same synthetic and real datasets as other baselines; results included in supplementary materials.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Executed following settings from prior benchmark work; implementation references provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Included in comparisons on synthetic and Nikuradse datasets (results worse than other baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to perform considerably worse than Eureqa and the Bayesian machine scientist in the authors' experiments; exact numeric values are in supplementary materials.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Served as one baseline but underperformed relative to Eureqa and the Bayesian machine scientist.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>In these experiments it yielded worse predictive performance; may be less consistent than other genetic-programming approaches in practice according to authors' benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2678.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2678.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EFS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EFS (Evolutionary Feature Synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fast method that combines genetic generation of candidate basis functions with sparse regression to produce closed-form models; used as a baseline in experiments and notable for speed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EFS</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Generates basis functions automatically via a genetic algorithm (feature synthesis) and then applies sparse regression to select and weight a small subset, producing interpretable closed-form models; fast enough to run many repeats and thereby select the best model by empirical fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Hybrid genetic-programming + sparse regression</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General-purpose symbolic/regression modeling; used as baseline on multiple datasets in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Genetic generation of candidate basis functions followed by sparse regression (e.g., L0/L1-style selection) to form parsimonious linear combinations of basis terms.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Model fitness (mean squared error) combined with sparsity enforced by the regression step.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Mean squared error for model selection; out-of-sample MAE used for comparison in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical evaluation on synthetic and real datasets; repeated many runs and selected best-performing model by default fitness measure.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Implementation publicly available; authors repeated training 100 times per experiment to select best model.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Used in comparisons on synthetic tasks and the Nikuradse dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Fast and capable of producing models within seconds; in this paper EFS produced models but the Bayesian machine scientist and Eureqa outperformed it on several benchmarks (figures and supplementary tables contain detailed numeric comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>EFS served as a fast baseline; Bayesian machine scientist outperformed EFS in out-of-sample predictive accuracy in the reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Although fast, EFS can be inconsistent and in some tasks underperformed more sophisticated search/regularization schemes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2678.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2678.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sparse regression / SINDy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse identification of nonlinear dynamical systems (SINDy) / sparse regression methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sparse-regression-based approaches that assume the governing equations are sparse linear combinations of candidate basis functions and recover differential equations by selecting a few active terms; cited as particularly suited to learning dynamical systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discovering governing equations from data by sparse identification of nonlinear dynamical systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sparse regression (SINDy)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Formulates model discovery as sparse linear regression over a library of candidate (possibly nonlinear) basis functions; identifies a small number of terms that best explain derivatives/observed dynamics (often via L1 or sequential thresholding), and is particularly effective for discovering ODEs/PDEs from data when the true dynamics are sparse in the chosen library.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Sparse regression / symbolic sparse identification</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Dynamical systems, physics, engineering (ODE/PDE discovery).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Constructs a library of candidate basis functions and uses sparse regression techniques to select a parsimonious linear combination that models derivatives or dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Sparsity-regularized fit (e.g., LASSO-like penalties or sequential thresholding) with model selection criteria; consistency arguments for recoverability under sufficient data/noise conditions are discussed in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Sparsity (number of nonzero terms), fit to derivatives, and information criteria (BIC/AIC) in follow-up model selection discussions.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Mentioned as an alternative approach that can recover differential equations (and compared conceptually in the paper); not directly run by the authors except as discussed in comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Cited in context of differential-equation discovery tasks (Rössler system mentioned as a task where sparse-regression methods are effective).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Paper notes that sparse regression methods are particularly suited to reverse-engineer differential equations and in some cases would recover true expressions where other symbolic methods failed; but SINDy was not the primary experimental baseline in the main comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Depends on having an appropriate library of candidate basis functions; may struggle when true model is not sparse in the chosen library or when basis functions are not included.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2678.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2678.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gaussian processes (GP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian process regression (nonparametric Bayesian)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Nonparametric Bayesian regression method that models functions as draws from a Gaussian process prior and yields predictive distributions (mean and variance) at test points; used as a nonparametric baseline for predictive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian processes</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Nonparametric Bayesian regression where function values are modeled by a multivariate normal prior with covariance specified by a kernel; posterior predictive mean and variance are computed given observed data. In the paper, scikit-learn GP implementation was used, multiple kernels were tested (RBF + white noise chosen), and logarithmic transforms of features were considered.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Nonparametric Bayesian regression</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General-purpose regression/prediction across domains; used here for out-of-sample prediction comparison in fluid-mechanics dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Does not generate closed-form symbolic hypotheses; instead produces predictive distributions directly via kernel-based nonparametric inference.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Predictive uncertainty via posterior variance; model comparison via marginal likelihood (not detailed) and cross-validated predictive errors used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Out-of-sample MAE used for comparison; kernel selection performed by empirical performance on validation.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Held-out predictive performance on Nikuradse dataset compared to symbolic methods; chosen kernel (RBF + white) with log-transformed feature produced best baseline results reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Used scikit-learn implementation with tested kernel families; specific kernel reported in methods.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>GP provides posterior predictive variance (not extensively discussed in text beyond being a standard property); used as a benchmark for point-prediction accuracy, not for symbolic discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Nikuradse turbulent-friction dataset (out-of-sample predictive comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In the Nikuradse out-of-sample prediction comparisons, the Bayesian machine scientist achieved lower MAE than the GP baseline; numeric MAE values are plotted in figures and supplementary materials.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>GP used as a nonparametric Bayesian benchmark; Bayesian machine scientist produced superior out-of-sample predictive performance on the Nikuradse data.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Does not yield interpretable closed-form symbolic models; predictive but not explanatory in the symbolic sense pursued by the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Bayesian machine scientist to aid in the solution of challenging scientific problems', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Distilling free-form natural laws from experimental data <em>(Rating: 2)</em></li>
                <li>Discovering governing equations from data by sparse identification of nonlinear dynamical systems <em>(Rating: 2)</em></li>
                <li>A Comprehensive Study of Symbolic Regression Methods (Orzechowski et al. GECCO 2018 benchmark) <em>(Rating: 2)</em></li>
                <li>FFX: Fast, scalable, deterministic symbolic regression technology <em>(Rating: 1)</em></li>
                <li>Bayesian model averaging: A tutorial <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2678",
    "paper_id": "paper-3763c501e5523fe5fcd0d370af226d7da9348c8c",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "Bayesian machine scientist",
            "name_full": "Bayesian machine scientist (Guimerà et al., 2020)",
            "brief_description": "A probabilistic symbolic-regression system that samples closed-form mathematical expressions via MCMC, assigns each expression a marginal-posterior plausibility using an explicit approximation to the model evidence (description length ≈ BIC/2 - log prior), and learns a prior over expression structure from an empirical corpus of formulas.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Bayesian machine scientist",
            "system_description": "Symbolic Bayesian inference system that represents closed-form expressions as expression trees; defines a prior over expression structure by fitting an exponential-random-graph-style maximum-entropy model to a corpus of 4,080 Wikipedia formulas; evaluates model plausibility via the marginal posterior p(f|D) approximated through a description length L(f) ≈ B(f)/2 - log p(f) (B is BIC); explores expression space using Metropolis-style MCMC with three move types (node replacement, root addition/removal, elementary-tree replacement), augmented with parallel tempering; canonicalizes expressions via Sympy to avoid duplicates; fits continuous parameters by least squares/maximum likelihood when computing BIC; produces posterior predictive distributions by averaging sampled expressions weighted by p(f|D) and selects a 'median predictive model' for a single interpretable closed form.",
            "system_type": "Bayesian symbolic regression / probabilistic symbolic model-averaging",
            "scientific_domain": "General-purpose: physics (Rössler, turbulent friction), fluid mechanics (Nikuradse dataset), ecology, cell biology, socioeconomics (funding success), and synthetic benchmark functions (Bessel functions).",
            "hypothesis_generation_method": "Generates candidate hypotheses (closed-form mathematical expressions) by stochastic moves on expression-tree space (node replacement, root addition/removal, elementary-tree replacement) within an MCMC sampler; candidate models are proposed from an enumerated set of possible elementary trees and operations and accepted/rejected using Metropolis rules based on change in description length ΔL (which encodes fit via BIC and prior over expressions). Parallel tempering is used to escape local minima.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility measured by marginal posterior p(f|D) approximated via description length L(f) ≈ BIC(f)/2 - log p(f); p(f) is a learned prior over expression structure (maximum-entropy model matching corpus counts); high plausibility corresponds to low description length.",
            "novelty_plausibility_balance": "Balance achieved implicitly by the posterior: goodness-of-fit enters via the BIC term (penalizes poor fit), while structural complexity and prior expectations about realistic formula structure enter via the learned prior p(f); for large datasets the BIC dominates, while for small/noisy datasets the prior regularizes against structurally overfitting models.",
            "hypothesis_quality_metrics": "Description length (L ≈ BIC/2 - log p(f)) as the primary scalar; BIC; out-of-sample prediction error metrics such as mean absolute error (MAE) / cross-validation error reported in experiments; also inspection of posterior predictive distribution and whether true generating model lies among high-plausibility models in synthetic tests.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational validation on synthetic datasets (recovering known closed-form models and differential equations like the Rössler system, Bessel-function approximations), and empirical validation on real datasets (Nikuradse turbulent-friction data, ecological and socio-economic small datasets); comparisons to alternative symbolic/regression methods (Eureqa, EPLEX, EFS) and to Gaussian processes for out-of-sample predictive performance; evaluation includes whether the true model is among high-plausibility samples and predictive MAE on held-out data.",
            "reproducibility_measures": "Code and data publicly available on Bitbucket; canonicalization of expression trees via Sympy to avoid duplicate equivalent expressions; explicit specification of operations, maximum tree size, MCMC move probabilities, and prior-fitting procedure (hyperparameter update loop) to allow replication.",
            "hallucination_prevention_method": "Structural regularization via an empirically learned prior over expression forms (reduces structurally overfitting, i.e., implausible complex formulas that fit noise); BIC-based penalization of parameter complexity; canonicalization to prevent redundant/degenerate formula representations.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Full Bayesian uncertainty over discrete model space approximated by MCMC samples of p(f|D); posterior predictive distribution p(y|D,x) approximated by averaging point predictions of sampled models weighted by their posterior plausibilities; use of ensemble statistics (median predictive model) and reporting distributions of description lengths among sampled models as uncertainty diagnostics.",
            "benchmark_dataset": "Synthetic datasets (drawn closed-form functions, Rössler system trajectories with added noise, Bessel-function data), real datasets including Nikuradse turbulent-friction measurements, datasets on funding success, cell-to-cell stresses, and salmon stocks; corpus of 4,080 Wikipedia expressions used to learn the prior (not a benchmark but an empirical source).",
            "performance_metrics": "Reported qualitative and graphical results: recovers true generating closed-form expressions on synthetic data (e.g., recovers chosen two-variable formula with 400 points and as few as 100 points in some cases), recovers Rössler differential equations under moderate noise, produces out-of-sample predictions with lower MAE than Eureqa, EFS, EPLEX and Gaussian processes on the Nikuradse dataset; exact numeric metric values are presented in figures and supplementary tables but not enumerated as single summary numbers in the main text.",
            "comparison_with_baseline": "Compared empirically against Eureqa (genetic-programming symbolic regression), EPLEX (genetic programming variant), EFS (genetic-generation of basis + sparse regression), and Gaussian processes; the Bayesian machine scientist yields better out-of-sample predictive accuracy and more consistent recovery of true expressions in synthetic tests, while other methods tended to structurally overfit or fail to recover the true generating forms.",
            "validated_on_real_science": true,
            "novel_discoveries": "Produced interpretable closed-form models for the Nikuradse turbulent-friction dataset that fit the data well and predict the correct asymptotic scaling; however, the paper reports model discovery and predictive validation on existing experimental data rather than reporting new experimental validation beyond data-fitting.",
            "limitations": "MCMC sampling can be slow and may require many restarts/parallel tempering to explore rugged expression landscapes; description-length approximation via BIC can fail for small or very noisy datasets and may require more accurate marginal-likelihood estimation (generalized BIC or numerical integration); prior learned from Wikipedia corpus is somewhat arbitrary and may need tailoring (domain-specific priors) to avoid violating required physical constraints (dimensional consistency, limiting behavior); expression-tree size is artificially limited (50 nodes) in implementation.",
            "uuid": "e2678.0",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Eureqa",
            "name_full": "Eureqa (Schmidt & Lipson)",
            "brief_description": "A genetic-programming-based symbolic regression system that evolves populations of candidate formulas to fit data, using a user-specified complexity penalty per operation and fitness-driven selection.",
            "citation_title": "Distilling free-form natural laws from experimental data.",
            "mention_or_use": "use",
            "system_name": "Eureqa",
            "system_description": "Genetic programming symbolic-regression tool that represents candidate expressions as tree-structured programs, evolves populations via crossover and mutation, and uses a fitness function (typically trade-off between error and user-defined complexity penalties) to select and refine models. In the paper it was run with default operation complexity penalties and evaluated as a baseline.",
            "system_type": "Genetic-programming symbolic regression",
            "scientific_domain": "General-purpose; used as a baseline across multiple domains in the paper (physics/fluid mechanics datasets).",
            "hypothesis_generation_method": "Population-based genetic programming: stochastically generates and evolves expressions via evolutionary operators (crossover, mutation) guided by fitness.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Fitness combining fit-to-data and user-specified complexity penalties; complexity penalties per operation were set to defaults in experiments.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Fitness (default settings used), mean squared error for model selection in experiments, and out-of-sample MAE for comparative evaluation.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirical performance on the same synthetic and real datasets used by the Bayesian machine scientist; out-of-sample predictive comparisons (MAE) and model structural inspection.",
            "reproducibility_measures": "Runs performed with default penalties and extensive evaluation (authors ran Eureqa until ≥10^13 expressions evaluated); Eureqa desktop is available publicly (reference provided).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Used as baseline on Nikuradse and synthetic datasets in paper.",
            "performance_metrics": "Performed worse than the Bayesian machine scientist on out-of-sample prediction for the Nikuradse dataset (figures show lower MAE for the Bayesian approach); exact numeric MAE values are presented in figures/supplement but not enumerated in the main text.",
            "comparison_with_baseline": "Eureqa served as a baseline; Bayesian machine scientist produced models with better predictive accuracy and, in many synthetic cases, recovered the true generating model where Eureqa did not.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Requires manual setting of operation complexity penalties; can structurally overfit and may fail to explore model space in a way that yields true generating expressions for some problems (as observed in comparisons).",
            "uuid": "e2678.1",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "EPLEX",
            "name_full": "ε-lexicase selection (EPLEX)",
            "brief_description": "A genetic programming variant using ε-lexicase selection designed to improve generalization in symbolic regression; used as a benchmark in the paper but performed worse than other baselines.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "EPLEX",
            "system_description": "Genetic-programming-based symbolic regression method that employs ε-lexicase selection to pick individuals based on performance across cases, intended to maintain diverse solutions and avoid premature convergence. In this paper it was run with configurations from a prior benchmark study and used as a baseline.",
            "system_type": "Genetic-programming symbolic regression (lexicase selection variant)",
            "scientific_domain": "General-purpose; used as a baseline for symbolic regression tasks in the paper.",
            "hypothesis_generation_method": "Evolves populations of candidate expressions via genetic operators; ε-lexicase selection chooses parents based on per-case performance criteria.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Fitness-based selection with lexicase selection dynamics; standard fitness metrics used for evaluation.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Population fitness, out-of-sample MAE used for comparison; EPLEX was reported to give worse results than Eureqa in these experiments.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Evaluated on the same synthetic and real datasets as other baselines; results included in supplementary materials.",
            "reproducibility_measures": "Executed following settings from prior benchmark work; implementation references provided.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Included in comparisons on synthetic and Nikuradse datasets (results worse than other baselines).",
            "performance_metrics": "Reported to perform considerably worse than Eureqa and the Bayesian machine scientist in the authors' experiments; exact numeric values are in supplementary materials.",
            "comparison_with_baseline": "Served as one baseline but underperformed relative to Eureqa and the Bayesian machine scientist.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "In these experiments it yielded worse predictive performance; may be less consistent than other genetic-programming approaches in practice according to authors' benchmarking.",
            "uuid": "e2678.2",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "EFS",
            "name_full": "EFS (Evolutionary Feature Synthesis)",
            "brief_description": "A fast method that combines genetic generation of candidate basis functions with sparse regression to produce closed-form models; used as a baseline in experiments and notable for speed.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "EFS",
            "system_description": "Generates basis functions automatically via a genetic algorithm (feature synthesis) and then applies sparse regression to select and weight a small subset, producing interpretable closed-form models; fast enough to run many repeats and thereby select the best model by empirical fitness.",
            "system_type": "Hybrid genetic-programming + sparse regression",
            "scientific_domain": "General-purpose symbolic/regression modeling; used as baseline on multiple datasets in the paper.",
            "hypothesis_generation_method": "Genetic generation of candidate basis functions followed by sparse regression (e.g., L0/L1-style selection) to form parsimonious linear combinations of basis terms.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Model fitness (mean squared error) combined with sparsity enforced by the regression step.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Mean squared error for model selection; out-of-sample MAE used for comparison in experiments.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirical evaluation on synthetic and real datasets; repeated many runs and selected best-performing model by default fitness measure.",
            "reproducibility_measures": "Implementation publicly available; authors repeated training 100 times per experiment to select best model.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Used in comparisons on synthetic tasks and the Nikuradse dataset.",
            "performance_metrics": "Fast and capable of producing models within seconds; in this paper EFS produced models but the Bayesian machine scientist and Eureqa outperformed it on several benchmarks (figures and supplementary tables contain detailed numeric comparisons).",
            "comparison_with_baseline": "EFS served as a fast baseline; Bayesian machine scientist outperformed EFS in out-of-sample predictive accuracy in the reported experiments.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Although fast, EFS can be inconsistent and in some tasks underperformed more sophisticated search/regularization schemes.",
            "uuid": "e2678.3",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Sparse regression / SINDy",
            "name_full": "Sparse identification of nonlinear dynamical systems (SINDy) / sparse regression methods",
            "brief_description": "Sparse-regression-based approaches that assume the governing equations are sparse linear combinations of candidate basis functions and recover differential equations by selecting a few active terms; cited as particularly suited to learning dynamical systems.",
            "citation_title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems.",
            "mention_or_use": "mention",
            "system_name": "Sparse regression (SINDy)",
            "system_description": "Formulates model discovery as sparse linear regression over a library of candidate (possibly nonlinear) basis functions; identifies a small number of terms that best explain derivatives/observed dynamics (often via L1 or sequential thresholding), and is particularly effective for discovering ODEs/PDEs from data when the true dynamics are sparse in the chosen library.",
            "system_type": "Sparse regression / symbolic sparse identification",
            "scientific_domain": "Dynamical systems, physics, engineering (ODE/PDE discovery).",
            "hypothesis_generation_method": "Constructs a library of candidate basis functions and uses sparse regression techniques to select a parsimonious linear combination that models derivatives or dynamics.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Sparsity-regularized fit (e.g., LASSO-like penalties or sequential thresholding) with model selection criteria; consistency arguments for recoverability under sufficient data/noise conditions are discussed in the literature.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Sparsity (number of nonzero terms), fit to derivatives, and information criteria (BIC/AIC) in follow-up model selection discussions.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Mentioned as an alternative approach that can recover differential equations (and compared conceptually in the paper); not directly run by the authors except as discussed in comparison.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Cited in context of differential-equation discovery tasks (Rössler system mentioned as a task where sparse-regression methods are effective).",
            "performance_metrics": null,
            "comparison_with_baseline": "Paper notes that sparse regression methods are particularly suited to reverse-engineer differential equations and in some cases would recover true expressions where other symbolic methods failed; but SINDy was not the primary experimental baseline in the main comparisons.",
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Depends on having an appropriate library of candidate basis functions; may struggle when true model is not sparse in the chosen library or when basis functions are not included.",
            "uuid": "e2678.4",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Gaussian processes (GP)",
            "name_full": "Gaussian process regression (nonparametric Bayesian)",
            "brief_description": "Nonparametric Bayesian regression method that models functions as draws from a Gaussian process prior and yields predictive distributions (mean and variance) at test points; used as a nonparametric baseline for predictive performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Gaussian processes",
            "system_description": "Nonparametric Bayesian regression where function values are modeled by a multivariate normal prior with covariance specified by a kernel; posterior predictive mean and variance are computed given observed data. In the paper, scikit-learn GP implementation was used, multiple kernels were tested (RBF + white noise chosen), and logarithmic transforms of features were considered.",
            "system_type": "Nonparametric Bayesian regression",
            "scientific_domain": "General-purpose regression/prediction across domains; used here for out-of-sample prediction comparison in fluid-mechanics dataset.",
            "hypothesis_generation_method": "Does not generate closed-form symbolic hypotheses; instead produces predictive distributions directly via kernel-based nonparametric inference.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Predictive uncertainty via posterior variance; model comparison via marginal likelihood (not detailed) and cross-validated predictive errors used in experiments.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Out-of-sample MAE used for comparison; kernel selection performed by empirical performance on validation.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Held-out predictive performance on Nikuradse dataset compared to symbolic methods; chosen kernel (RBF + white) with log-transformed feature produced best baseline results reported.",
            "reproducibility_measures": "Used scikit-learn implementation with tested kernel families; specific kernel reported in methods.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "GP provides posterior predictive variance (not extensively discussed in text beyond being a standard property); used as a benchmark for point-prediction accuracy, not for symbolic discovery.",
            "benchmark_dataset": "Nikuradse turbulent-friction dataset (out-of-sample predictive comparison).",
            "performance_metrics": "In the Nikuradse out-of-sample prediction comparisons, the Bayesian machine scientist achieved lower MAE than the GP baseline; numeric MAE values are plotted in figures and supplementary materials.",
            "comparison_with_baseline": "GP used as a nonparametric Bayesian benchmark; Bayesian machine scientist produced superior out-of-sample predictive performance on the Nikuradse data.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Does not yield interpretable closed-form symbolic models; predictive but not explanatory in the symbolic sense pursued by the paper.",
            "uuid": "e2678.5",
            "source_info": {
                "paper_title": "A Bayesian machine scientist to aid in the solution of challenging scientific problems",
                "publication_date_yy_mm": "2020-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Distilling free-form natural laws from experimental data",
            "rating": 2
        },
        {
            "paper_title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems",
            "rating": 2
        },
        {
            "paper_title": "A Comprehensive Study of Symbolic Regression Methods (Orzechowski et al. GECCO 2018 benchmark)",
            "rating": 2
        },
        {
            "paper_title": "FFX: Fast, scalable, deterministic symbolic regression technology",
            "rating": 1
        },
        {
            "paper_title": "Bayesian model averaging: A tutorial",
            "rating": 1
        }
    ],
    "cost": 0.01881675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Bayesian machine scientist to aid in the solution of challenging scientific problems</h1>
<p>Roger Guimerà ${ }^{1,2 *}$, Ignasi Reichardt ${ }^{2}$, Antoni Aguilar-Mogas ${ }^{2,3}$, Francesco A. Massucci ${ }^{2,4}$, Manuel Miranda ${ }^{2}$, Jordi Pallarès ${ }^{5}$, Marta Sales-Pardo ${ }^{2}$</p>
<h4>Abstract</h4>
<p>Closed-form, interpretable mathematical models have been instrumental for advancing our understanding of the world; with the data revolution, we may now be in a position to uncover new such models for many systems from physics to the social sciences. However, to deal with increasing amounts of data, we need "machine scientists" that are able to extract these models automatically from data. Here, we introduce a Bayesian machine scientist, which establishes the plausibility of models using explicit approximations to the exact marginal posterior over models and establishes its prior expectations about models by learning from a large empirical corpus of mathematical expressions. It explores the space of models using Markov chain Monte Carlo. We show that this approach uncovers accurate models for synthetic and real data and provides out-of-sample predictions that are more accurate than those of existing approaches and of other nonparametric methods.</p>
<h2>INTRODUCTION</h2>
<p>Since the scientific revolution, interpretable closed-form mathematical models have been instrumental for advancing our understanding of the world. Think, for example, of Newton's law of gravitation and how it has enabled us to predict astronomical phenomena with great accuracy and, perhaps more importantly, to interpret seemingly unrelated physical phenomena. With the data revolution, we may now be in a position to uncover closed-form, interpretable mathematical models of natural and even socioeconomic systems that were previously not amenable to quantitative analysis.</p>
<p>To be able to do this, however, we need to develop algorithms for automatically identifying these models (1-4). Following Evans and Rzhetsky, here, we call these algorithms, which would assist human scientists, "machine scientists" (2).</p>
<p>Attempts to design machine scientists date back to, at least, the 1970s and have led to very successful approaches in recent years. One of these approaches is based on genetic programming $(5,6)$. In this approach, closed-form mathematical expressions are represented as graphs, and, given a goodness-of-fit metric, populations of expressions are created and evolved in such a way that high-fitness expressions are selected for further exploration. Another successful approach is based on sparse regression (7-11). In this approach, closed-form mathematical models are assumed to be linear combinations of some (linear or nonlinear) "basis functions" of the independent variables, and sparse regression is used to select and weigh the relevant basis functions. This approach is particularly suited to learn differential equations (8-11), whose form often follows the assumption of linearity on relatively simple basis functions. For more general situations, sparse regression can be combined with genetic programs that automatically generate the basis functions, thus relaxing the need to know them a priori $(12,13)$.</p>
<p>Despite this remarkable progress, machine scientists have stumbled upon two major challenges. First, algorithms must balance goodness</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>of fit and model complexity, thus avoiding overfitting. In general, this issue is dealt with by defining model complexity heuristically and then applying model selection criteria to the models that lay on the fit-complexity Pareto front. Both the definition of complexity and the choice of model-selection criterion are, however, hard to generalize and systematize. Second, machine scientists should, in principle, explore an arbitrarily large space of closed-form mathematical models. This is typically addressed by using methods such as genetic programming, which have no guarantees of actually exploring the best models more frequently; or by restricting the search space, for example, to linear combinations of the basis functions in sparse regression approaches, thus leaving out potentially valid models.</p>
<p>Here, we propose a Bayesian approach to the definition of machine scientists. To address the fit-complexity trade-off, we obtain the posterior probability of each expression from basic probabilistic arguments and explicit approximations. The posterior, which leads to consistent model selection, naturally combines the goodness of fit and a prior over expressions that accounts for model complexity. To establish the prior over expressions, we compile a corpus of closed-form mathematical models from Wikipedia and then use a maximum entropy approach to formalize a prior that is statistically consistent with the corpus (14). To address the challenges related to the exploration of the space of closed-form mathematical expressions, we introduce a Markov chain Monte Carlo (MCMC) algorithm that samples from the posterior over expressions. We demonstrate that the Bayesian machine scientist successfully recovers the true generating model when fed with synthetic data, even in situations in which state-of-the-art machine scientists fail (4). We also demonstrate that the machine is able to uncover accurate, closed-form mathematical models for systems for which no closedform model has agreed on. Last, we find that the machine scientist provides out-of-sample predictions that are more accurate than those of other machine scientists and of standard nonparametric machine learning approaches, such as Gaussian processes (15).</p>
<h2>RESULTS</h2>
<h2>Bayesian formulation of the problem and expression plausibility</h2>
<p>Let us first formalize the problem in probabilistic terms. Consider a property $y$ that can be expressed as an unknown, closed-form mathematical</p>
<p>function $y=F(x, \theta)$ of $K$ variables $x=\left{x_{1}, \ldots, x_{K}\right}$ and $L$ parameters $\theta \in$ $R^{L}$ [for example, $y=\sin \left(\theta_{1} x_{1}\right)$ or $y=\theta_{1} x_{1}+\theta_{3} x_{2}$ ]. Given some data $D=$ $\left{\left(y^{1}, x^{1}\right), \ldots,\left(y^{N}, x^{N}\right)\right}$, and assuming that the measurements have some experimental error $y^{k}=F\left(x^{k}, \theta\right)+\epsilon^{k}$, the Bayesian machine scientist assigns to each possible closed-form mathematical expression $f_{i}$ a plausibility $p\left(f_{i} \mid D\right)$ given by the marginal posterior</p>
<p>$$
p\left(f_{i} \mid D\right)=\frac{1}{Z} \int_{\Theta_{i}} d \theta_{i} p\left(D \mid f_{i}, \theta_{i}\right) p\left(\theta_{i} \mid f_{i}\right) p\left(f_{i}\right)=\frac{\exp \left[-\mathcal{L}\left(f_{i}\right)\right]}{Z}
$$</p>
<p>where $\theta_{i}$ are the parameters associated with expression $f_{i}$, the integral is over the space $\Theta_{i}$ of possible values of these parameters, $Z=p(D)$ does not depend on $f_{i}$, and $p\left(f_{i}\right)$ is the prior over expressions. The quantity</p>
<p>$$
\begin{aligned}
\mathcal{L}\left(f_{i}\right) &amp; \equiv-\log \left[p\left(D, f_{i}\right)\right] \
&amp; =-\log \left[\int_{\Theta_{i}} d \theta_{i} p\left(D \mid f_{i}, \theta_{i}\right) p\left(\theta_{i} \mid f_{i}\right) p\left(f_{i}\right)\right]
\end{aligned}
$$</p>
<p>is the description length of model $f_{i}$, that is, the number of nats needed to jointly encode the data and the model with an optimal code (16). Although in general the description length cannot be calculated exactly, it can be approximated in a number of ways $(17,18)$; here, we take one of the simplest approximations</p>
<p>$$
\mathcal{L}\left(f_{i}\right) \approx \frac{B\left(f_{i}\right)}{2}-\log p\left(f_{i}\right)
$$</p>
<p>where $B\left(f_{i}\right)$ is the Bayesian information criterion (BIC) of expression $f_{i}$ and can be readily calculated from the data (Supplementary text S1) (11, 17). This is a first-order approximation to the description length and holds when the likelihood $p\left(D \mid f_{i}, \theta_{i}\right)$ is peaked around the maximum likelihood parameters $\theta_{i}^{\prime}$ and the prior is smooth in this region; when the number of experimental points is small, the approximation may fail, and one would need to get more precise estimates of the description length such as the generalized BIC (19) or even calculate numerically the integral over the parameters. Beyond these potential limitations, Eqs. 1 to 3 naturally combine the goodness of fit of a model and its structural complexity, which is captured by the prior over expressions. In addition, in the limit of large datasets, we have $\left|B\left(f_{i}\right)\right| \gg$ $\left[\log p\left(f_{i}\right)\right]$; since $B\left(f_{i}\right)$ is consistent, the machine scientist is also consistent, that is, in this limit it prefers the correct expression over any other expression with probability approaching 1 .</p>
<h2>Sampling from the posterior distribution over expressions</h2>
<p>The Bayesian machine scientist explores the space of closed-form mathematical expressions using MCMC. In particular, we introduce three move types that enable one to go from any closed-form expression to any other closed-form expression, thus enabling the machine scientist to explore, given enough time, the whole space of closed-form mathematical expressions (Materials and Methods) (Fig. 1). Regardless of the frequency of each move and other parameters of the Markov chain, MCMC samples expressions $f_{i}$ from the stationary distribution $p\left(f_{i} \mid D\right)$ (fig. S1). Although MCMC is slower than some alternative machine scientists that put emphasis on speed, such as evolutionary
feature synthesis (EFS), the only dependency on the number of data points is in the estimation of the BIC of each model, and therefore its complexity scales as any other method using least squares to fit model parameters.</p>
<p>For model selection, the Bayesian machine scientist can use the most plausible expression from an MCMC run, that is, the maximum a posteriori (or minimum description length) expression. However, MCMC naturally samples over the whole space of models, thus generating arbitrarily long sequences of expressions; as we show below, this leads to a more complete characterization of the expression space and to higher out-of-sample prediction accuracy.</p>
<h2>Estimation of prior probabilities using a corpus of mathematical expressions</h2>
<p>For the Bayesian machine scientist to be able to estimate the plausibility of a given expression, it needs to estimate the prior probabilities $p\left(f_{i}\right)$. A common approach in model selection is to have no a priori preference for any given model over the others and assume that $p\left(f_{i}\right)$ is the same for all models $(17,18)$. In that case, and within our approximation for the description length, the most plausible model is simply the one with the lowest BIC. This is a consistent approach and generally reasonable when comparing a small number of simple models. However, it is inappropriate when considering a finite dataset and a very large (potentially infinite) space of mathematical expressions because one can always find a very complex model that fits the data arbitrarily well even with very few parameters. These unnecessarily complex models are likely to generalize very poorly in the same way that models with many parameters do-this structural overfitting is thus akin to traditional overfitting but arises from the large number of mathematical models considered rather than the large number of parameters (Supplementary text S4 and fig. S5). From this perspective, the prior over expressions acts as a model regularizer. It would also be possible to add other regularizers to expression trees, but, within our Bayesian framework, tree regularizers could still be cast as nonuniform priors, although they may be formally more complex and harder to interpret than the ones that we introduce below.</p>
<p>Given these considerations, the machine scientist needs to "learn" the a priori plausibility of models. Human scientists obtain this prior knowledge by studying science books and becoming familiar with the mathematical expressions that appear in them. We take a similar empirical approach to define the prior expectations of the machine scientist-we compiled a corpus of 4080 mathematical expressions that are included in Wikipedia entries (Materials and Methods)and use these expressions to shape the prior expectations of the machine scientist, that is, to establish the statistical properties expected a priori for expressions (Fig. 2). To do this, we use an approach based on exponential random graphs (20-23). In particular, we choose a prior that generates expressions with the same average number of each type of operation [and their squares $(23,24)$ ] as in the empirical corpus and, given this constraint, satisfies the maximum entropy principle $(14,23)$ (Materials and Methods; Supplementary text S2, fig. S2, and tables S3 and S4). As we show in Fig. 2, this prior generates mathematical expressions statistically consistent with the corpus. Note that the Bayesian machine scientist is not restricted to the 4080 expressions in the corpus, or even to arbitrary combinations of these expressions-all closed-form mathematical expressions are valid and can be visited by the MCMC; those that are statistically similar to the corpus are simply more plausible a priori. Note also that, as mentioned earlier, for large amounts of data, the prior washes out and</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. MCMC to systematically explore the space of closed-form mathematical expressions. (A) Closed-form mathematical expressions can be represented as trees, whose internal nodes are functions (operations) and whose leaves are variables and parameters. To explore the space of mathematical expressions, we implemented three move types (Materials and Methods): (i) root addition/removal—we added/removed the root of the tree; (ii) elementary tree replacement (we define an elementary tree as a subtree containing, at most, one function)—we replaced one elementary tree by another (for example, c1x by x); (iii) node replacement—we replaced one node (function, variable, or parameter) by another. Each of these moves was proposed with a certain frequency and accepted or rejected using the Metropolis' rule (Materials and Methods) (36). (B) To validate the MCMC, we explored the space of all expressions with one variable, one parameter and using only the functions (+, sin). For this experiment only, we restricted the size of the expression tree to be smaller than eight nodes, and we assume that all expressions are equally plausible a priori, p(fi) = const. Each node in the network represents a different expression, and links represent jumps from one expression to another resulting from the MCMC moves described in (A). The size of each node is proportional to the number of times they are visited by the MCMC. In the absence of data, the MCMC explores all possible expressions with equal probability. (C) We generated synthetic data with the expression y = a + x + sin (x), to which we added noise (circles). We show how the correct expression and two closely related expressions fit the data. (D) We explored the same space as in (B) but considering the synthetic data in (C). When data are taken into account, expressions that are more plausible given the data are visited more frequently (larger nodes), and many expressions are too implausible and, therefore, not visited at all (fig. S1). The color of each node corresponds to the color of the curves in (C).</p>
<p>the description length, as approximated in Eq. 3, is consistent regardless of the selection of prior.</p>
<h3>Validation of the Bayesian machine scientist with synthetic data</h3>
<p>Having addressed the methodological challenges in the definition of the Bayesian machine scientist, we next demonstrate the ways in which it can be used and illustrate how one can get insights by using it. First, we test that, when fed with synthetic data, the machine scientist recovers the models that truly generated the data. We start by selecting an arbitrary expression and setting its parameters to values uniformly selected from [-2, 2]. The selected expression (Fig. 3) is F(x1, x2; θ1, θ2) = x1(θ1 + x2) cos(x1)/(θ2 log(θ2)], with θ1 = -1.19 and θ2 = 0.29. Note that this expression is not one of the expressions present in our empirical corpus.</p>
<p>We then feed the machine scientist with 400 noisy data points generated using this expression. The Bayesian machine scientist finds the correct model and assigns to it the maximum plausibility or, equivalently, the minimum description length (Fig. 3). To evaluate to which extent it is remarkable that the Bayesian machine scientist finds the correct model in this situation, we attempt the same task with state-of-the-art machine scientists (4), including two methods based on genetic programming [Eureqa (5) and ε-lexicase selection (EPLEX) (6)] and a method that combines genetic programming with sparse regression (Materials and Methods) [EFS; (13)]. We find that, from the same dataset, none of these methods are able to recover the correct model and that they tend to structurally overfit the data (Supplementary text S3).</p>
<p>The ability of the Bayesian machine scientist (and of any other method) to identify the correct model requires a minimum amount of data points. We find that, for this synthetic dataset, and even though the other approaches do not identify the correct expression with 400 points, the Bayesian machine recovers the true model with as few as 100 points (Supplementary text S3 and fig. S3).</p>
<p>Next, we investigate whether the machine is able to recover the differential equations that govern the Rössler system (25), and what is the effect of increasing observational noise in the equation discovery process. Since we are mostly interested in the effect of increasing noise in the target variable, we assume that the only measurement error is in the derivatives, although in some real situations derivatives may need to be estimated numerically from noisy measurements of the variables. In those situations, it may be necessary to use advanced techniques to estimate the derivatives (26). Under the conditions of our experiment, we find that the machine is able to recover the correct differential equations when the derivatives are measured with moderate noise (Fig. 4). When the measurement noise is high, the true expressions are still regarded as very plausible, but the machine identifies as the most plausible ones expressions that are "regularized" versions of the exact models. In these regularized models, small terms are disregarded; in all</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p><strong>Fig. 2. The prior probability distribution generates plausible expressions. (A)</strong> We extracted 4080 mathematical expressions from Wikipedia pages listed under the category "List of scientific equations named after people", for example, the page devoted to "Newton's law of universal gravitation" (see also table S2). (<strong>B</strong>) After parsing each expression (Materials and Methods), we counted the number of each operation in the expression and the square of these numbers. In Newton's law of gravitation, we counted two products, one division, and one square. The complete list of operations is listed in table S1. Then, we parametrized the prior distributions <em>p</em>(<em>f</em><sub><em>i</em></sub>) and fit the parameters so as to generate expressions that have realistic numbers (and squares) of each operation (Materials and Methods). (<strong>C</strong> to <strong>H</strong>) We ran the MCMC to draw sets of 4080 synthetic expressions from the prior distribution. We compared these sets of 4080 synthetic expressions with the 4080 empirical expressions obtained from Wikipedia. In particular, for each set of 4080 expressions, we counted the mean number 〈<em>n</em><sub><em>n</em></sub>〉 of each operation <em>o</em> per expression {(<em>C</em>) sine, (<em>D</em>) logarithm, (<em>E</em>) sum}, or the mean 〈<em>n</em><sub><em>x</em></sub>〉 of the square of those numbers (<strong>F</strong> to <strong>H</strong>) and plot their probability density function (PDF; pink). The red vertical line indicates the mean of the distribution, which is close to the empirical observation, represented by a dashed black line. The empirical value is always well within the expected ranges of the expressions generated by the MCMC. The results in the figure correspond to expressions with up to five variables and eight parameters.</p>
<p>cases, the most plausible models are almost indistinguishable from the true ones (fig. S4). Thus, as expected, the machine scientist automatically adjusts the complexity of the models to the quality of the data (Supplementary text S4). Again, these results stand in contrast to those of alternative machine scientists [with the exception of pure sparse regression methods particularly suited to reverse-engineer differential equations (8–11), which would be able to recover the true expressions, at least in the case with low noise]. Even for the simplest case in this experiment (inference of <em>ẋ</em> with a low level of noise), all benchmark machine scientists fail to recover the true model and tend to overfit structurally (Supplementary text S4).</p>
<p>Last, we test the behavior of the machine scientist when presented with data that are generated from a model that does not have a closed-form mathematical expression in terms of the basic functions that it uses. In particular, we generate synthetic data using Bessel functions <em>J</em><sub><em>α</em></sub>(<em>x</em>) with <em>α</em> ∈ {0, 1, 2, 3, 4}. We find that the machine scientist is able to identify closed-form expressions that are as accurate as high-order Taylor expansions of the exact functions. We also find that, when the synthetic data are noisy and the machine scientist is restricted to choose among low-order series expansions, it consecutively chooses first-order, second-order, or third-order expansions, as the range of observed data increases and as the noise decreases, as one would expect (Supplementary text S5 and fig. S6).</p>
<h3><strong>Use of the machine scientist on small datasets and on the Nikuradse dataset</strong></h3>
<p>Next, we turn to the analysis of real datasets. First, we analyze how the machine scientist provides insights into problems for which there are scarce and noisy data. We focus on three datasets that have been the subject of recent analyses and for which models have been proposed: a dataset on funding success in different European countries (27); a dataset on cell-to-cell stresses (28); and a dataset on stocks of salmon in the Fraser River in British Columbia, Canada (29).</p>
<p>For each of these three datasets, we compare existing models to models identified by the machine scientist in terms of their plausibility <em>p</em>(<em>f</em><sub><em>i</em></sub> | <em>D</em>), their BIC <em>B</em>(<em>f</em><sub><em>i</em></sub>), and their cross-validation error (Supplementary text S6 and tables S5 to S7). In all cases, the machine scientist identifies at least one model that is better than existing models in a Pareto sense, namely, better in at least one of the three performance metrics without being worse in any of the others.</p>
<p>Last, we show in more detail how the machine scientist can help us to solve major open scientific problems. For this, we focus on the classical experiment of turbulent friction in rough pipes performed in the early 1930s by Johann Nikuradse (30–33). In his experiments, Nikuradse measured the turbulent friction <em>λ</em> as a function of the roughness <em>x</em><sub><em>D</em></sub> of the pipe and the Reynolds number <em>x</em><sub><em>R</em></sub>. We take the original Nikuradse dataset and feed it to the machine scientist to study possible analytical expressions for the turbulent friction. A typical MCMC run uncovers numerous expressions that fit all observed data remarkably well (Fig. 5, A and B). We compare these expressions to the best expressions uncovered by other machine scientists (Materials and Methods): Eureqa (5), EFS (13), and EPLEX (6) (see Supplementary text S7 and fig. S10 for EPLEX). The expressions uncovered by the Bayesian machine scientist fit the Nikuradse dataset better than those uncovered by Eureqa, which, in turn, is significantly better than all other benchmark methods.</p>
<p>The Bayesian machine scientist does not find any candidate expression that is overwhelmingly more plausible than all the others;</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p><strong>Fig. 3. Recovery of an arbitrary expression from synthetic data.</strong> We drew an expression with two variables (<em>x</em><sub>1</sub> and <em>x</em><sub>2</sub>) and two parameters (θ<sub>1</sub> and θ<sub>2</sub>) from the prior distribution <em>p</em>(<em>f</em><sub><em>i</em></sub>); the drawn function is <em>F</em>(<em>x</em><sub>1</sub><em>x</em><sub>2</sub>; θ<sub>1</sub><em>θ</em><sub>2</sub>) = <em>x</em><sub>1</sub>(θ<sub>1</sub> + <em>x</em><sub>2</sub>) cos (<em>x</em><sub>1</sub>)/[θ<sub>2</sub> log (θ<sub>2</sub>)], with θ<sub>1</sub> = −1.19 and θ<sub>2</sub> = 0.29. With this function, we generated 400 synthetic points <em>y</em><sup>k</sup> = <em>F</em>(<em>x</em><sub>1</sub><em>k</em><sub>2</sub><em>; θ<sub>1</sub></em>θ<em><sub>2</sub>) + ε<sup>k</sup>, with (</em>x<em><sub>1</sub></em>k<em><sub>2</sub></em>), uniformly chosen in [−2,2]<sup>2</sup>, and ε ~ <em>N</em>(0,1) normally distributed [points in (<strong>A</strong>) and (<strong>D</strong>) to (<strong>G</strong>); the color of the points corresponds to the value of <em>y</em> as indicated by the color bar]. We fed these synthetic data to the Bayesian machine scientist and run 2500 steps of the MCMC algorithm. (<strong>A</strong>) After 2500 steps, the most plausible model identified (blue surface) is <em>f</em>(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>; θ<sub>1</sub>, θ<sub>2</sub>) = <em>x</em><sub>1</sub>(<em>c</em><sub>1</sub> + <em>c</em><sub>2</sub><em>x</em><sub>2</sub>) cos <em>x</em><sub>1</sub>, which coincides with the correct model up to indeterminacies in the dependency on the parameters that cannot be resolved without varying their values (see movie S1 for the complete evolution of the MCMC). (<strong>B</strong>) The blue line indicates the evolution of the description length <em>L</em> during the MCMC (up to an irrelevant additive constant that comes from the prior normalization and therefore affects all points equally). Lower description lengths correspond to more plausible models. The MCMC starts from an expression with high description length, but after 1000 to 1500 steps, it equilibrates and samples from the stationary distribution <em>p</em>(<em>f</em><sub><em>i</em></sub>|<em>D</em>). (<strong>C</strong>) The blue line indicates the evolution of the mean absolute error of each model sampled by the MCMC with respect to the true model. The error is calculated over a grid in [−2,2]<sup>2</sup>, that is, not at the observed points. (<strong>D</strong> to <strong>G</strong>) The MCMC is prone to getting trapped in local maxima of the plausibility (local minima of the description length). To explore the expression space more efficiently, we used parallel tempering (<em>38</em>), a technique used in statistical physics to study disordered systems with rugged energy landscapes (Materials and Methods). Besides the main MCMC in (<strong>A</strong>), parallel tempering keeps a number of parallel MCMCs that sample the distributions <em>p</em>(<em>f</em><sub><em>i</em></sub><em>T</em><sub><em>k</em></sub>) = exp [−<em>B</em>(<em>f</em><sub><em>i</em></sub>)<em>T</em><sub><em>k</em></sub>] + log <em>p</em>(<em>f</em><sub><em>i</em></sub>)] parametrized by "temperatures" <em>T</em><sub><em>k</em></sub> (Materials and Methods). In our case, higher temperatures correspond to simpler expressions. At each MCMC step, we attempted a swap of expressions at contiguous <em>T</em><sub><em>k</em></sub> using Metropolis' rule. The evolution of the description length and the mean absolute error of the parallel MCMCs are represented in (<strong>B</strong>) and (<strong>C</strong>) with the same colors as in (<strong>D</strong>) to (<strong>G</strong>).</p>
<p>rather, it uncovers a collection of similarly plausible models. This has two important implications. First, it points toward the need to revisit our tendency to look for single "best models" from data. Second, it suggests that, when using the machine scientist to make predictions, we should average over the whole ensemble of plausible models (<em>34, 35</em>). In particular, the posterior predictive distribution for a point <em>y</em><sup>k</sup> can be approximated as</p>
<p>$$p(y^k \mid D; x^k) \approx \sum_i \delta(y^k - f_i(x^k, \theta_i^*) p(f_i \mid D) \tag{4}$$</p>
<p>where θ<sub><em>i</em></sub><sup><em></sup> is the maximum likelihood estimator of </em>f<em><sub></em>i<em></sub>'s parameters, δ(</em>x<em>) is the Dirac delta function, and the sum runs over all possible expressions </em>f<em><sub></em>i<em></sub>. Note that estimating the posterior predictive distribution in this way makes interpretation of the predictions harder—even if each model </em>f<em><sub></em>i<em></sub> is interpretable, averaging leads to a noninterpretable effective model. However, it is important to point out that this is the most comprehensive approach possible, in the sense that, even if one is certain that the data were generated with a single, unknown model </em>F<em>, the best predictive distribution comes from taking all models into consideration, each weighted by its plausibility </em>p<em>(</em>f<em><sub></em>i<em></sub>|</em>D<em>) (</em>34*).</p>
<p>In practice, the average over models can be computed using the MCMC sample collected by the machine scientist, and we can use the median of the posterior distribution <em>p</em>(<em>y</em><sup>k</sup> | <em>D</em>; <em>x</em><sup>k</sup>) to make predictions for <em>y</em><sup>k</sup> that minimize the mean absolute predictive error. By considering, among all sampled models, the one that most resembles this median prediction, we obtain a single closed-form mathematical model that is optimally predictive—we call this model the median predictive model. To test the predictive power of the median predictive</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Recovery of the differential equations governing the Rössler system. (A) We generated synthetic data for the Rössler system (equations shown in the panels) with $a=b=0.2$ and $c=5.7$. We assume that $(x, y, z)$ are measured without error, but the functions that we aim to recover $(\hat{x}, \hat{y}, \hat{z})$ are measured with two levels of Gaussian noise [e.g., $\hat{x}^{k}=F\left(x^{k}, y^{k}, z^{k}\right)+\varepsilon^{k}$ with $\varepsilon^{k} \sim N\left(0, \sigma_{x}\right)$; orange, $\sigma_{x}=1$; blue, $\sigma_{x}=5$. (B) Trajectories in velocity space $(\hat{x}, \hat{y}, \hat{z})$ for the levels of noise that we considered. (C to J) For each level of noise, we sampled 10,000 models for $\hat{x}$ using the machine scientist and the same for $\hat{y}$ and $\hat{z}$. (C and G), For each level of noise, we plot the most plausible model obtained. (D to F and H to J) We plot the distribution of description lengths (up to an irrelevant additive constant) for the models sampled. (D to F) For low noise, the most plausible model among those sampled always coincides with the true model, as indicated by the dashed vertical line. (H to J) For high noise, $\hat{x}$ was recovered exactly, whereas for $\hat{y}$ and $\hat{z}$, the most plausible models corresponded to regularized versions of the true models, in which terms that are comparatively small because of the factor 0.2 are dropped. In all cases, the true model (dashed vertical line) is, at least, among the most plausible ones.
model in the Nikuradse dataset, we compare it to the alternative machine scientists (Eureqa, EPLEX, and EFS), as well as to a standard nonparametric Bayesian approach, Gaussian processes (15). In particular, we test the ability of all approaches to generalize to data never seen before (Fig. 5, C and D). We find that the predictions of the Bayesian machine scientist are significantly more accurate than those of all alternative approaches.</p>
<p>The median predictive model, being a function of the roughness only for large Reynolds numbers, also predicts the expected limiting scaling for the turbulent friction (Fig. 5, E and F), which is remarkable considering that (i) most of the observed data correspond to a regime with different physics (31) and (ii) many of the sampled models do not scale correctly (fig. S9). Last, to fully exploit the potential of the machine scientist to obtain interpretable models of turbulent friction, we use it in combination with the known physics of the problem. In 1933, Prandtl
suggested that the function $\hat{\lambda}=(100 \lambda)^{-1 / 2}-2 \log D / r$ should be a universal function depending only on the so-called roughness Reynolds number $k_{r}^{\prime \prime}(\operatorname{Re}, r / D)(30,33)$. We use the machine scientist to obtain the most plausible form for such universal function and get $\hat{\lambda}=1.73+$ $0.64 \times 0.96^{k_{r}^{\prime \prime}}-2.62 \times 0.64^{k_{r}^{\prime \prime}}$ (Fig. 5G); this very simple model on the scaled variable does indeed provide an excellent fit to the original (unscaled) data (Fig. 5H).</p>
<h2>DISCUSSION</h2>
<p>In the age of data, there is a pressing need to design algorithms capable of helping in the scientific process, from assisting in the proof of theorems to parsing scientific texts. Discovering closed-form mathematical models was one of the earliest tasks attempted, and yet, despite much progress in the area, two related difficulties have arisen repeatedly-deciding what is</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p><strong>Fig. 5. The machine scientist gives accurate closed-form models and out-of-sample predictions for the Nikuradse dataset.</strong> The dataset contains measurements of the turbulent friction λ in rough pipes as a function of the Reynolds number <em>x</em><sup>R</sup> and the inverse of the relative roughness <em>x</em><sub>D</sub>. (<strong>A</strong> and <strong>B</strong>) We fed the machine scientist with the Nikuradse dataset (gray) and sample more than 18,000 models using MCMC as described in the text. The two graphs show the fit of two of the most plausible models (red), indicated at the top of each panel. For comparison, we show the best models identified by alternative machine scientists Eureqa (green) and EFS (orange). The inset in each graph shows the mean absolute error (MAE) of the machine scientist (MS), Eureqa (EU), and EFS (EF) (Materials and Methods), and error bars indicate the 95% confidence interval for the mean. (<strong>C</strong> and <strong>D</strong>) We fed the machine scientist with the data points in gray and sample 20,000 models using MCMC. We made predictions (red) for the unobserved data (black) using the median predictive model (see text). For comparison, we show the predictions of Eureqa, EFS, and Gaussian processes (GP) (Materials and Methods). The inset in each graph shows the mean absolute error for all approaches. (<strong>E</strong>) We considered, again, the models obtained from the whole data as in (<strong>A</strong>) and (<strong>B</strong>) but asked what the median predictive model predicts in the fully turbulent regime, well above the highest observed Reynold number (<em>31</em>). Despite the fact that individual sampled models have different behaviors in this region (fig. S5), the median predictive model [obtained as in (<strong>C</strong>) and (<strong>D</strong>)] predicts that turbulent friction stays constant at large Reynolds numbers, in agreement with theory (<em>31–33</em>). (<strong>F</strong>) The machine scientist also predicts the correct scaling (Z <em>r</em> <em>r</em>)<sup>−1/2</sup> for the turbulent friction in this regime (dashed line). (<strong>G</strong>) Scaling of the Nikuradse dataset proposed by Prandtl (with <em>k</em><sub>c</sub><sup>c</sup> (Re, <em>r</em> / <em>D</em>) = Re × √<em>λ</em>/32 × <em>D</em> / <em>r</em>) (<em>30, 33</em>) and most plausible model identified by the machine scientist for the universal scaling function. (<strong>H</strong>) When unscaled, this simple universal function provides a good description of all the data.</p>
<p>the correct balance between goodness of fit and model complexity and searching systematically through the space of models.</p>
<p>These are fundamental difficulties that stem from the nature of the problem that we aim to solve, and, therefore, no approach can possibly avoid them completely—one cannot establish an assumption-free measure of model complexity that serves all purposes or make the search space small without risking to leave out valid models or even the true generating model.</p>
<p>However, the Bayesian approach that we have introduced here forces us to be explicit and transparent about all the necessary assumptions and approximations to deal with these challenges. With regard to the fit-complexity trade-off, model complexity enters through our prior expectations about expressions. The use of an empirical corpus is somewhat arbitrary, and one may need to tune the corpus to the problem at hand; but it is reasonable to expect that, lacking any data, the machine scientist should propose models that statistically resemble existing phenomenological models in the literature. With our maximum entropy approach, we guarantee that the prior distribution is the most agnostic distribution satisfying this constraint. Besides, our approach makes it clear that, given enough data, prior expectations become irrelevant, and the machine scientist will consistently prefer the true model with probability approaching 1. With regard to the search through the space of models, MCMC guarantees that, asymptotically (that is, given enough data and time), the Bayesian machine scientist samples from the posterior distribution and, because it is consistent, visits the true model with the highest frequency.</p>
<p>Despite these advantages, our approach is not, of course, exempt of difficulties, the most pressing of which we have already pointed out. First, despite the virtues of MCMC for sampling the expression space, it may be necessary to develop more efficient approaches for very large datasets, without losing the guarantees provided by MCMC. Evidence for the need for these approaches would come from the observation that different MCMC runs on the same dataset result in different description length distributions, which would indicate that the stationary posterior is not being sampled correctly. Alternatives to sampling the full posterior using MCMC may range from Bayesian inference methods such as variational approximations to mathematical optimization methods, if suitable representations of the problem can be found and we are content with obtaining a single model and some bounds to its optimality. Second, it may be desirable to develop and compare other approaches to setting priors for expressions, perhaps based on noninformative priors or symmetry considerations, or empirical approaches different from the one that we have adopted here. A situation in which this need would be obvious is when the proposed models clearly violate some basic features of the desired solution, such as some particular limiting behavior or dimensional consistency. If such additional information is available, then it would be appropriate to formalize it in the prior. Last, in some situations involving small datasets and leading to broad likelihoods in parameter space, it may be necessary to use approximations to the description length that are more accurate than those based on the BIC, for example, the generalized BIC (<em>18</em>). However, this problem would be more difficult to diagnose in a practical situation because, even for a single dataset, the BIC can be a good approximation for some models but not for others. In any case, situations in which the BIC is a poor approximation are likely to involve small or very noisy datasets, situations in which the importance of the BIC is relatively small compared to that of the prior and simple models will be sampled anyway.</p>
<p>These challenges notwithstanding, our results suggest that, in practice, the Bayesian machine scientist is able to uncover models that are</p>
<p>good in terms of both describing the observed data and predicting new data. Our approach can also be used in other contexts, for example when a phenomenological model has been proposed from data, and we aim to find whether there are other models that are more plausible or, at least, similarly plausible. Or, given two conflicting theories for the same process, the Bayesian machine scientist could be used to establish which one is more plausible and to what extent, and whether there exist other reasonable models. From a broader perspective, our approach sets the basis for further developing theories of model discoverability: Is it always possible to identify the correct model given the data? And if not, then under which conditions is the true model discoverable? In addition, our approach opens the door to addressing fundamental questions related to the limits of predictability for mathematical models: To what extent can a system be accurately predicted? Are closed-form, interpretable models as expressive as machine learning models such as deep neural networks? And if so, why? These are all important questions whose answer may lead to significant new insights about the scientific process and about our capacity to understand and describe the world using mathematics.</p>
<h2>MATERIALS AND METHODS</h2>
<h2>MCMC moves for mathematical expression sampling</h2>
<p>To perform a systematic exploration of the space of closed-form mathematical expressions, we represented closed-form mathematical expressions as expression trees. In these trees, internal nodes represent operations (for example, sum or exponential) and leaves represent variables or parameters (Fig. 1). To avoid problems with improper priors, we limited the size of expressions trees to 50 nodes. Although, in principle, one could make this number arbitrarily large, all parameter values and results in the paper are obtained using this value.</p>
<p>We classified the nodes of the expression tree based on the number of offspring that they have. Leaves (variables and parameters) have no offspring, whereas operations can have one offspring (operations that take only one argument, like the exponential function) or two offspring (operations that take two arguments, such as the sum). In table S1, we list all the operations that the machine scientist uses for building models.</p>
<p>An elementary tree (ET) is an expression tree (thus, a mathematical expression) that contains at most one operation. For the implementation of the Markov chain, we used a variety of moves (described in detail below) that operate by adding, removing, replacing, or modifying ETs. We call those ETs whose operation has $k$ offspring $k$-ET. For example, $x+a$ is a 2 -ET (because the sum has two offspring: $x$ and $a$ ), $\sin x$ is a 1-ET (because the sine function has a single offspring: $x$ ), and $x$ is a 0 -ET. Expressions such as $\sin (x+a)$ are not ETs because they contain more than one operation.</p>
<p>We designed an MCMC algorithm to sample expressions from the posterior distribution $p\left(f_{i} \mid D\right)$, which gives the plausibility of an expression given the observed data. This distribution is given by Eq. 3. We used three types of move to update mathematical expressions (Fig. 1):</p>
<p>1) Node replacement. We replaced a node in the expression tree (selected uniformly at random among all nodes in the tree) by a randomly selected node, with the only restriction that the replacement must have the same number of offspring as the original node (for example, a " + " node can be replaced by a "*" node but not by an "exp" node). The offspring branches remain unchanged.
2) Root addition (RA). We added a new root to the expression tree. The new root can be any operation. If the operation takes one off-
spring, then the old expression tree becomes the offspring of the new root; otherwise, the old expression tree becomes the leftmost offspring of the operation, with the other offspring being randomly chosen 0 -ETs (that is, variables or parameters). To be more precise, at the beginning of a sampling process, all possible replacement roots are enumerated (all operations with all possible 0 -ET offspring in all positions other than the leftmost branch, which is left empty); when a RA is attempted, the new root is chosen uniformly among this list of candidates. The reverse move, root removal (RR), consists of removing the root of the expression tree and all its offspring except for the leftmost branch, which becomes the new expression tree. RR is only possible when all branches except the leftmost one are 0 -ETs.
3) Elementary tree replacement (ETR). We replaced a randomly selected ET in the complete expression tree by another randomly selected ET. At the beginning of a sampling process, all possible ETs are enumerated (all operations with all possible 0 -ET offspring). In each move, an ET (chosen uniformly at random among all ETs in the expression tree) is replaced by an ET chosen uniformly at random among all possible ETs.</p>
<p>The ETR move introduces small variations to expression trees and is therefore the major source of expression variation. By contrast, node replacement moves often introduce major changes in expressions (for example, replacing a sum by a product often alters a model very significantly) and are therefore not very efficient. However, they are useful in that they represent long jumps in the space of models. Last, root replacement is the only move that can make trees grow/shrink at the top and is useful to add/remove terms to models that are already reasonable. Without root replacement, adding an additive term to an expression tree would require disassembling the whole tree and assembling it again with the additional term from the beginning.</p>
<h2>MCMC acceptance rules</h2>
<p>At each MCMC step, we attempt one of the three moves described above and accept or reject the proposed move according to Metropolis' rule (36)</p>
<p>$$
p_{\text {accept }}\left(f_{i} \rightarrow f_{\mathrm{f}}\right)=\min \left{1 \frac{p\left(f_{\mathrm{f}} \mid D\right) g\left(f_{i} \mid f_{\mathrm{f}}\right)}{p\left(f_{\mathrm{f}} \mid D\right) g\left(f_{\mathrm{f}} \mid f_{i}\right)}\right}
$$</p>
<p>where $g\left(f_{\mathrm{f}} \mid f_{i}\right)$ is the distribution of movement proposal $f_{i} \rightarrow f_{\mathrm{f}}$ (where f and i stand for final and initial, respectively). This rule ensures that the stationary distribution is $p\left(f_{i} \mid D\right)$</p>
<p>$$
p\left(f_{i} \mid D\right)=\frac{1}{Z} \exp \left[-\mathcal{L}\left(f_{i}\right)\right]
$$</p>
<p>with $Z$ being a normalizing constant and $\mathcal{L}\left(f_{i}\right)$ being the description length, as defined and approximated in the main text</p>
<p>$$
\mathcal{L}\left(f_{i}\right) \approx \frac{B\left(f_{i}\right)}{2}-\log p\left(f_{i}\right)
$$</p>
<p>For all samples in the paper, we attempt a root replacement move 5\% of the time, a node replacement move $45 \%$ of the time, and an ETR 50\% of the time. These rates are arbitrary and should not affect the achievement or the equilibrium distribution but do have an effect on how fast the Markov chain converges to the equilibrium distribution.</p>
<p>In what follows, we describe the specific form of the acceptance (Eq. 5) rule for each movement.</p>
<p>1) Node replacement (NR). Since the node to change is chosen uniformly at random and so is the new node, the move is symmetric, that is, the probability of attempting a move and its reverse are the same $g\left(f_{\mathrm{f}} \mid f_{\mathrm{i}}\right)=g\left(f_{\mathrm{i}} \mid f_{\mathrm{f}}\right)$. Therefore, the acceptance probability in this case is given simply by the difference in the description lengths of the expression trees</p>
<p>$$
p_{\text {accept }}^{\mathrm{NR}}=\min {1, \exp [-\Delta \mathcal{L}]}
$$</p>
<p>2) RA and RR. In this case, the proposal distribution for the RA and RR movements is not symmetric. The RR move is deterministic in that it always affects the existing root of the expression tree. By contrast, the RA move involves selecting uniformly at random among all possible $N_{\text {root }}$ roots that can be added (which are enumerated once at the beginning of the sampling process, as described above). Therefore, if $p_{\mathrm{RR}}$ is the probability of selecting this type of move, then $g(\mathrm{RR})=p_{\mathrm{RR}}$ and $g(\mathrm{RA})=p_{\mathrm{RR}} / N_{\text {root }}$ so that $g(\mathrm{RR}) / g(\mathrm{RA})=N_{\text {root }}$, which gives the following acceptance rules</p>
<p>$$
\begin{gathered}
p_{\text {accept }}^{\mathrm{RA}}=\min \left{1, N_{\text {root }} \exp [-\Delta \mathcal{L}]\right} \
p_{\text {accept }}^{\mathrm{RR}}=\min \left{1, \frac{\exp [-\Delta \mathcal{L}]}{N_{\text {root }}}\right}
\end{gathered}
$$</p>
<p>where $N_{\text {root }}$ is the number of possible roots among which we choose in the RA move.
3) ETR. The ETR move is the most involved in terms of defining the move proposal probabilities necessary to define the acceptance rule. First, we need to specify exactly how we choose the attempted move. We start by selecting the orders $o_{\mathrm{i}}$ and $o_{\mathrm{f}}$ of the existing (initial, i) and replacement (final, f) ETs. For example, we may choose to replace a 0 -ET ( $o_{\mathrm{i}}=0$, a constant or a variable) by a 2 -ET ( $o_{\mathrm{f}}=2$, e.g., a sum or a product). In this initial choice, we need to take into consideration the number $n_{\mathrm{if}}$ of options that we have to choose $o_{\mathrm{i}}$ and $o_{\mathrm{f}}$ (for example, if a tree has reached the maximum allowed size $o_{\mathrm{f}} \leq o_{\mathrm{i}}$ necessarily). Once the orders $o_{\mathrm{i}}$ and $o_{\mathrm{f}}$ are selected, we need to account for (i) all the possible ETs of order $o_{\mathrm{i}}$ in the initial tree $\Omega_{\mathrm{i}}$ that we can choose to replace and (ii) all the possible ETs of order $o_{\mathrm{f}}$ that we can choose to replace the ET in the initial tree, $s_{\mathrm{f}}$. If $p_{\text {ETR }}$ is the probability with which we choose this move, then taking into account the previous considerations $g\left(o_{\mathrm{f}} \mid o_{\mathrm{i}}\right)=p_{\mathrm{ETR}} \times 1 / n_{\mathrm{if}} \times 1 / \Omega_{\mathrm{i}} \times 1 / s_{\mathrm{f}}$. Conversely, $g\left(o_{\mathrm{i}} \mid o_{\mathrm{f}}\right)=p_{\mathrm{ETR}} \times 1 / n_{\mathrm{fi}} \times$ $1 / \Omega_{\mathrm{f}} \times 1 / s_{\mathrm{i}}$, so that the acceptance rule is</p>
<p>$$
p_{\text {accept }}^{\mathrm{ETR}}=\min \left{1, \frac{n_{\mathrm{if}} \Omega_{\mathrm{i}} s_{\mathrm{f}}}{n_{\mathrm{f}} \Omega_{\mathrm{f}} s_{\mathrm{i}}} \exp [-\Delta \mathcal{L}]\right}
$$</p>
<p>To validate that these moves and these acceptance rules lead to sampling from the equilibrium distribution $p\left(f_{\mathrm{i}} \mid D\right)$, we use the same example as in Fig. 1. We generate data as in Fig. 1 and sample expressions using MCMC, limiting the expressions to use only " + " and "sin" operations, a single variable $x$, a single parameter $a$, and a maximum of seven nodes. In fig. S1, we show that, as expected, the equilibrium distribution is $p\left(f_{\mathrm{i}} \mid D\right)$.</p>
<h2>Avoidance of expression duplicates in MCMC</h2>
<p>The mapping of expressions to expression trees is not one to one because several expression trees can represent the same expression (for example, the expression $x+a$ can be encoded in an expression tree with $x$ or with $a$ on the left branch). To avoid overcounting expressions, we internally reduce all expression trees to a "canonical form" using the Python module Sympy (37). Then, if an expression tree that is visited for the first time reduces to an expression that is equivalent to that of a previously visited expression tree, then the current tree is forbidden (assigned infinite description length) and never visited again, so that only one representative of each expression remains.</p>
<h2>Parallel tempering MCMC</h2>
<p>The search space for the MCMC is extremely rugged, with some neighboring expressions having very different description lengths. This makes the sampling process problematic and prone to getting trapped in local minima. To partly alleviate this problem, we used parallel tempering (38). In traditional parallel tempering (typically used in physics for spin glasses and other disordered systems), several replicas of the sampling process are kept at logarithmically spaced and increasing temperatures-at high temperatures, the sampling easily escapes local minima, whereas at low temperatures, the sampling explores configurations that are physically more meaningful. From time to time, samples at consecutive temperatures are switched with a rule that guarantees detailed balance at all temperatures. Therefore, the lowest temperature sample is always equilibrated at the desired temperature, but the configuration space is explored more efficiently because of the high temperature samples exploring larger portions of the space.</p>
<p>For our purposes here, we introduce a computational temperature $T$ and sample from the distributions</p>
<p>$$
p\left(f_{\mathrm{i}}, T_{k}\right)=\frac{1}{Z} \exp \left[-\frac{B\left(f_{\mathrm{i}}\right)}{2 T_{k}}+\log p\left(f_{\mathrm{i}}\right)\right]
$$</p>
<p>With this definition, $p\left(f_{\mathrm{i}}, T=1\right)=p\left(f_{\mathrm{i}} \mid D\right)$ is the equilibrium distribution from which we aim to sample, and $p\left(f_{\mathrm{i}}, T=\infty\right)=p\left(f_{\mathrm{i}}\right)$ is the prior distribution, independent of the data.</p>
<p>The results of the manuscript were obtained with 40 different temperatures defined as $T_{k}=1.05^{k}$, with $k={0,1, \ldots, 39}$. From all these, we take expressions only from the $T_{0}=1$ sample (Fig. 3). In addition, for the Nikuradse dataset, we used four restarts of the parallel tempering MCMC so that the sampling is even better equilibrated.</p>
<h2>Parsing of Wikipedia expressions for expression priors</h2>
<p>We compiled all the mathematical expressions included in pages listed under Wikipedia's "List of scientific equations named after people," which we surmise often correspond to phenomenological models of the kind that we aim to identify (as opposed, for example, to derivations of mathematical identities, proofs of mathematical theorems, etc.).</p>
<p>In Wikipedia, expressions are encoded in such a way that some of them are ambiguous without the context provided by the text in the page, so fully automatic parsing of expressions is virtually impossible. For example, the expression $x^{\alpha}+x^{b}$ could represent the sum of the two components of a vector or the sum of two powers of $x$. We designed an algorithm that parses Wikipedia expressions into Sympy (37), using heuristics for the ambiguous cases (the full code for expression parsing is available at https://bitbucket.org/rguimera/machine-scientist/src/ no_degeneracy/Process-Formulas/). We then selected three random</p>
<p>subsets of 200 expressions out of the 4080 expressions that could be parsed and verified manually that the parsings were meaningful (accepting parsings that may be wrong once the context is known but that are otherwise mathematically correct). We refined the heuristics until we found that there were fewer than $5 \%$ of errors in the parsed expressions of all three subsets. In table S2, we show a small sample of the corpus.</p>
<h2>Prior definition</h2>
<p>To define the prior distribution over mathematical expressions, we took advantage of the fact that mathematical expressions can be represented as graphs and used an approach based on exponential random graph models (20-23). As in exponential random graphs models, we aimed to generate mathematical expressions (graphs) with statistical properties similar to those in the corpus. Specifically, we aimed to generate mathematical expressions for which the average number of each operation per expression is the same as in the corpus (for example, in the corpus, the average number of sums per expression is $\left\langle n_{+}\right\rangle=$ 0.312 ). We also aimed to reproduce the average of the square of the number of each operation per expression (for example, the average of the square of the number of sums per expression, $\left\langle n_{+}^{2}\right\rangle=0.731$ ) $(23,24)$. As in exponential random graph models, we selected the prior probability $p(f)$ that generates expressions with these desired average properties and that, at the same time, is maximally uninformative and therefore consistent with the maximum entropy principle $(14,23,39)$. This prior is given by</p>
<p>$$
p\left(f_{i}\right)=\sum_{o \in O}\left[\alpha_{o} n_{o}\left(f_{i}\right)+\beta_{o} n_{o}^{2}\left(f_{i}\right)\right]
$$</p>
<p>where the sum is over all operations considered $\mathcal{O}={+, \exp , \ldots}$ (table S1), and $\alpha_{o}$ and $\beta_{o}$ are hyperparameters that we fitted so that expressions generated from the prior were consistent with the corpus $(22,23)$.</p>
<h2>Fitting of prior hyperparameters</h2>
<p>To fit the $\alpha_{o}$ and $\beta_{o}$ hyperparameters, we proceeded as follows:</p>
<p>1) Obtain, from the empirical corpus of mathematical expressions, the average number $\left\langle n_{o}\right\rangle^{\text {target }}$ of each operation $o$ per expression and the average of the square $\left\langle n_{o}^{2}\right\rangle^{\text {target }}$ of the number of each operation per expression.
2) Set some initial values for the parameters.
3) Repeat until the change in parameters values is small enough:
(i) Generate, using the MCMC, a large number of expressions (typically 1 million to 10 million).
(ii) Measure $\left\langle n_{o}\right\rangle^{\text {measured }}$ and $\left\langle n_{o}^{2}\right\rangle^{\text {measured }}$ in the generated formulas.
(iii) Update the $\alpha_{o}$ parameters as follows</p>
<p>$$
\alpha_{o} \leftarrow \alpha_{o}+\varepsilon \lambda \frac{\left\langle n_{o}\right\rangle^{\text {measured }}-\left\langle n_{o}\right\rangle^{\text {target }}}{\left\langle n_{o}\right\rangle^{\text {target }}}
$$</p>
<p>where $\lambda$ is a fixed parameter (typically between 0.01 and 0.05 ) and $\varepsilon$ is a random number in $[0,1]$ generated independently for each update.
(iv) Update the $\beta_{o}$ parameters as follows</p>
<p>$$
\beta_{o} \leftarrow \beta_{o}+\varepsilon \lambda \frac{\left\langle n_{o}^{2}\right\rangle^{\text {measured }}-\left\langle n_{o}^{2}\right\rangle^{\text {target }}}{\left\langle n_{o}^{2}\right\rangle^{\text {target }}}
$$</p>
<p>where $\lambda$ is a fixed parameter (typically between 0.01 and 0.05 ) and $\varepsilon$ is a random number in $[0,1]$ generated independently for each update. If one $\beta_{o}$ becomes negative, then its value is set to 0 .
(v) Repeat from (i).</p>
<p>This method is adapted from an exisiting method to fit the parameters of exponential random graphs (22). A typical evolution of the parameter values is shown in fig. S2, and the parameter values obtained are listed in tables S3 and S4 (Supplementary text S2).</p>
<h2>Benchmark machine scientists</h2>
<p>We benchmarked the performance of the Bayesian machine scientist against three other machine scientists: Eureqa (5), EPLEX (6), and EFS (13). Eureqa uses a genetic algorithm to search the space of expressions (5). Eureqa requires that a complexity penalty is set for each operation type; we set these penalties to their default values and selected the same basic operations used by the Bayesian machine scientist. We also selected the default fitness function. We ran Eureqa for several weeks in each experiment, until the number of evaluated expressions is, at least, $10^{13}$. Eureqa is available at www.nutonian.com/download/eureqa-desktop-download/.</p>
<p>EPLEX is another algorithm based on genetic programming and was the top performer in a recent systematic comparison of state of the art machine scientists (4). We ran EPLEX in the same conditions as in that study (implementation available at https://epistasislab.github.io/ellyn/); in particular, we obtained $10^{6}$ models with a population size of 1000 and 1000 generations. Moreover, we repeated this procedure 10 times and selected the realization with the best fitness among the 10 repetitions. However, in all our experiments, EPLEX gives results that are considerably worse than Eureqa's, so we do not show its results in the main text (Supplementary text S7 and fig. S10).</p>
<p>Last, EFS is a method based on sparse regression that generates basis functions automatically using a genetic algorithm (13). Thus, this approach has the advantages of sparse regression, and, at the same time, it does not require a priori knowledge of the basis functions. EFS is an evolution of multiple regression genetic programming (12), which was also a top performer in (4), although somehow more inconsistent than EPLEX. EFS is fast and gives expressions within seconds. Thus, we were able to repeat the training process 100 times for each experiment and select the model with the best default fitness measure (mean squared error). We used the implementation of EFS available at http://flexgp. github.io/efs/.</p>
<h2>Gaussian process models</h2>
<p>For the comparison of the out-of-sample predictions of Gaussian process models to those of the machine scientist, we proceeded as follows. We trained the Gaussian process using the scikit-learn implementation (40). We tested different kernels (including radial-basis function kernels, Matérn kernels, white kernels, rational quadratic kernels, exponential kernels, and linear and quadratic combinations of these), and we also tested the effects of using $D / r$ or its logarithm as the feature. Among these, we selected the combination that gave the best results (an radial-basis function plus white kernel with logarithmic $D / r$ )-all results reported in the main text correspond to this combination.</p>
<h2>SUPPLEMENTARY MATERIALS</h2>
<p>Supplementary material for this article is available at http://advances.sciencemag.org/cgi/ content/full/6/5/eaav6971/DC1
Supplementary Text S1. Calculation of the BIC
Supplementary Text S2. Prior parameter values</p>
<p>Supplementary Text S3. Validation and benchmarking on synthetic data
Supplementary Text S4. Rössler system
Supplementary Text S5. Recovery of Bessel functions
Supplementary Text S6. Results for small datasets
Supplementary Text S7. Nikuradse dataset
Table S1. Operations used by the machine scientist and their properties.
Table S2. Sample of the expressions in the empirical corpus.
Table S3. Values of the $\alpha$ prior parameters for different number of variables, $N_{\alpha}$, and parameters $N_{p}$.
Table S4. Values of the $\beta$ prior parameters for different number of variables, $N_{\alpha}$, and parameters $N_{p}$.
Table S5. Models for the funding application success in different European countries as a function of socioeconomic indicators of the countries and of their ability to attract and retain scientific talent.
Table S6. Models for the cell-to-cell stresses as a function of the concentration of several cell adhesion proteins.
Table S7. Models for the (logarithm of the) Seymour stock of salmon in the Fraser River system in British Columbia, Canada as a function of several ecological indicators.
Fig. S1. Equilibrium distribution of the MCMC.
Fig. S2. Fitting of the parameters of the prior distribution for expressions.
Fig. S3. Ability of the Bayesian machine scientist to identify the correct model from synthetic data as a function the number of observed points.
Fig. S4. True and most plausible models of the Rössler system in high-noise scenarios. Fig. S5. True and minimum BIC models of the Rössler system.
Fig. S6. Recovery of Bessel functions.
Fig. S7. Out-of-sample predictions for small datasets.
Fig. S8. Energy distribution for the Nikuradse dataset.
Fig. S9. Sampled models.
Fig. S10. EPLEX models and out-of-sample predictions for the Nikuradse dataset.
Movie S1. Video of the Bayesian machine scientist finding models for a synthetic dataset.</p>
<h2>REFERENCES AND NOTES</h2>
<ol>
<li>S. Džeroski, L. Todorovski, Lecture Notes in Artificial Intelligence, in Computational Discovery of Scientific Knowledge (Springer, 2007).</li>
<li>J. Evans, A. Rzhetsky, Machine science. Science 329, 399-400 (2010).</li>
<li>B. C. Daniels, I. Nemenman, Automated adaptive inference of phenomenological dynamical models. Nat. Commun. 6, 8133 (2015).</li>
<li>P. Orzechowski, W. La Cava, J. H. Moore, Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '18 (ACM, 2018), pp. 1183-1190.</li>
<li>M. Schmidt, H. Lipson, Distilling free-form natural laws from experimental data. Science 324, 81-85 (2009).</li>
<li>W. La Cava, L. Spector, K. Danai, Proceedings of the Genetic and Evolutionary Computation Conference 2016, GECCO '16 (ACM, 2016), pp. 741-748.</li>
<li>T. McConaghy, FFX: Fast, scalable, deterministic symbolic regression technology, in Genetic Programming Theory and Practice IX, R. Riolo,E. Vladislavleva, J. H. Moore, Eds. (Springer New York, 2011), pp. 235-260.</li>
<li>S. L. Brunton, J. L. Proctor, J. N. Kutz, Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proc. Natl. Acad. Sci. U.S.A. 133, 3932-3937 (2016).</li>
<li>Z. T. Wilson, N. V. Sahinidis, The ALAMO approach to machine learning. Comput. Chem. Eng. 106, 785-795 (2017).</li>
<li>S. H. Rudy, S. L. Brunton, J. L. Proctor, J. N. Kutz, Data-driven discovery of partial differential equations. Sci. Adv. 3, e1602614 (2017).</li>
<li>N. M. Mangan, J. N. Kutz, S. L. Brunton, J. L. Proctor, Model selection for dynamical systems via sparse regression and information criteria. Proc. R. Soc. A 473, 20170009 (2017).</li>
<li>I. Arnaldo, K. Krawiec, U.-M. O'Reilly, Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation, GECCO '14 (ACM, 2014), pp. 879-886.</li>
<li>I. Arnaldo, U.-M. O'Reilly, K. Veeramachaneni, Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation, GECCO '15 (ACM, 2015), pp. 983-990.</li>
<li>E. T. Jaynes, Information theory and statistical mechanics. Phys. Rev. 106, 620-630 (1957).</li>
<li>D. Barber, Bayesian Reasoning and Machine Learning (Cambridge Univ. Press, 2012).</li>
<li>P. D. Grünwald, The Minimum Description Length Principle (The MIT Press, 2007).</li>
<li>G. Schwarz, Estimating the dimension of a model. Ann. Stat. 6, 461-464 (1978).</li>
<li>T. Ando, Bayesian Model Selection and Statistical Modeling (CRC Press, 2010).</li>
<li>S. Konishi, T. Ando, S. Imoto, Bayesian information criteria and smoothing parameter selection in radial basis function networks. Biometrika 91, 27-43 (2004).</li>
<li>G. Robins, P. Pattison, Y. Kalish, D. Lusher, An introduction to exponential random graph $\left(p^{a}\right)$ models for social networks. Soc. Netw. 29, 173-191 (2007).</li>
<li>T. A. B. Snijders, Statistical models for social networks. Annu. Rev. Sociol. 37, 131-153 (2011).</li>
<li>A. Caimo, N. Friel, Bayesian inference for exponential random graphs. Soc. Netw. 33, 41-55 (2011).</li>
<li>S. Horvát, E. Czabarka, Z. Toroczkai, Reducing degeneracy in maximum entropy models of networks. Phys. Rev. Lett. 114, 158701 (2015).</li>
<li>R. Fischer, J. C. Ledda, T. P. Peixoto, E. G. Altmann, Sampling motif-constrained ensembles of networks. Phys. Rev. Lett. 115, 188701 (2015).</li>
<li>O. E. Rössler, An equation for continuous chaos. Phys. Lett. A 57, 397-398 (1976).</li>
<li>M. Quade, M. Abel, K. Shafi, R. K. Niven, B. R. Noack, Prediction of dynamical systems by symbolic regression. Phys. Rev. E 94, 012214 (2016).</li>
<li>M. De Domenico, A. Arenas, Researcher incentives: EU cash goes to the sticky and attractive. Nature 531, 580 (2016).</li>
<li>E. Bazellières, V. Conte, A. Elosegui-Artola, X. Serra-Picamal, M. Bintanel-Morcillo, P. Roca-Cusachs, J. J. Muñoz, M. Sales-Pardo, R. Guimerà, X. Trepat, Control of cell-cell forces and collective cell dynamics by the intercellular adhesome. Nat. Cell Biol. 17, 409-420 (2015).</li>
<li>H. Ye, R. J. Beamish, S. M. Glaser, S. C. H. Grant, C.-H. Hsieh, L. J. Richards, J. T. Schnute, G. Sugihara, Equation-free mechanistic ecosystem forecasting using empirical dynamic modeling. Proc. Natl. Acad. Sci. U.S.A. 112, E1569-E1576 (2015).</li>
<li>Reprinted in English in J. Nikuradse, NACA Tech. Memo.1292 (1950).</li>
<li>G. Gioia, P. Chakraborty, Turbulent friction in rough pipes and the energy spectrum of the phenomenological theory. Phys. Rev. Lett. 96, 044502 (2006).</li>
<li>N. Goldenfeld, Roughness-induced critical phenomena in a turbulent flow. Phys. Rev. Lett. 96, 044503 (2006).</li>
<li>Z.-S. She, Y. Wu, X. Chen, F. Hussain, A multi-state description of roughness effects in turbulent pipe flow. New J. Phys. 14, 093054 (2012).</li>
<li>J. A. Hoeting, D. Madigan, A. E. Raftery, C. T. Volinsky, Bayesian model averaging: A tutorial. Stat. Sci. 14, 382417 (1999).</li>
<li>N. Simidjievski, L. Todorovski, S. Džeroski, Modeling dynamic systems with efficient ensembles of process-based models. PLOS ONE 11, e0153507 (2016).</li>
<li>N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, E. Teller, Equation of state calculations by fast computing machines. J. Chem. Phys. 21, 1087-1092 (1953).</li>
<li>A. Meurer, C. P. Smith, M. Paprocki, O. Čertik, S. B. Kirpichev, M. Rocklin, A. Kumar, S. Ivanov, J. K. Moore, S. Singh, T. Rathnayake, S. Vig, B. E. Granger, R. P. Muller, F. Bonazzi, H. Gupta, S. Vats, F. Johansson, F. Pedregosa, M. J. Curry, A. R. Terrel, S. Roučka, A. Saboo, I. Fernando, S. Kulal, R. Cimrman, A. Scopatz, Sympy: symbolic computing in python. PeerJ Comput. Sci. 3, e103 (2017).</li>
<li>D. J. Earl, M. W. Deem, Parallel tempering: Theory, applications, and new perspectives. Phys. Chem. Chem. Phys. 7, 3910-3916 (2005).</li>
<li>E. T. Jaynes, Probability Theory: The Logic of Science (Cambridge Univ. Press, 2003).</li>
<li>F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay, Scikit-learn: Machine learning in Python. J. Mach. Learn. Res. 12, 2825-2830 (2011).</li>
</ol>
<p>Acknowledgments: We thank E. G. Altmann, L. A. N. Amaral, A. Arenas, J. Bonet Avalos, and D. Shasha for helpful comments and suggestions. We thank I. Arnaldo for help with the EFS software. We thank A. Arenas for pointing us toward the Nikuradse dataset. We thank M. De Domenico and A. Arenas for sharing the financial success dataset. We thank E. Bazellières and X. Trepat for sharing the cell adhesion dataset. Funding: This project has received funding from the Spanish Ministerio de Economia y Competitividad (FIS2015-71563-ERC, FIS2016-78904-C3-P-1, and DPI2016-75791-C2-1-P). F.A.M. acknowledges financial support by the Spanish MINECO grant PTQ-14-06718 (2016-2019) of the Torres Quevedo Programme. Author contributions: R.G. conceived the research. R.G., I.R., A.A.-M., F.A.M., M.M., and M.S.-P. contributed methods, wrote code for the computational experiments, and carried out computational experiments. All authors designed the computational experiments and interpreted the results, and wrote and edited the manuscript. Competing interests: The authors declare that they have no competing interests. Data and materials availability: A Python implementation of the Bayesian machine scientist and all data needed to evaluate the conclusions in the paper are publicly available from Bitbucket at https://bitbucket.org/iguimera/machine-scientist. Additional data related to this paper may be requested from the authors.</p>
<p>Submitted 11 October 2018
Accepted 20 November 2019
Published 31 January 2020
10.1126/sciadv.aav6971</p>
<p>Citation: R. Guimerà, I. Reichardt, A. Aguilar-Mogas, F. A. Massucci, M. Miranda, J. Pallarés, M. Sales-Pardo, A Bayesian machine scientist to aid in the solution of challenging scientific problems. Sci. Adv. 6, eaav6971 (2020).</p>
<h1>ScienceAdvances</h1>
<h2>A Bayesian machine scientist to aid in the solution of challenging scientific problems</h2>
<p>Roger Guimerà, Ignasi Reichardt, Antoni Aguilar-Mogas, Francesco A. Massucci, Manuel Miranda, Jordi Pallarès and Marta Sales-Pardo</p>
<p>Sci Adv 6 (5), eaav6971.
DOI: 10.1126/sciadv.aav6971</p>
<p>ARTICLE TOOLS
SUPPLEMENTARY MATERIALS
REFERENCES</p>
<p>PERMISSIONS
http://advances.sciencemag.org/content/6/5/eaav6971
http://advances.sciencemag.org/content/suppl/2020/01/27/6.5.eaav6971.DC1</p>
<p>This article cites 29 articles, 4 of which you can access for free
http://advances.sciencemag.org/content/6/5/eaav6971#BIBL
http://www.sciencemag.org/help/reprints-and-permissions</p>
<p>Use of this article is subject to the Terms of Service</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Science Advances (ISSN 2375-2548) is published by the American Association for the Advancement of Science, 1200 New York Avenue NW, Washington, DC 20005. The title Science Advances is a registered trademark of AAAS.
Copyright © 2020 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>