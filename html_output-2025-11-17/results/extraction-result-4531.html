<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4531 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4531</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4531</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-100.html">extraction-schema-100</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-694d9b45adcffa4bbc130e4ccaa681e275640128</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/694d9b45adcffa4bbc130e4ccaa681e275640128" target="_blank">Enhancing Knowledge Graph Construction Using Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper created pipelines for the automatic creation of Knowledge Graphs from raw texts, and findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text.</p>
                <p><strong>Paper Abstract:</strong> The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4531.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4531.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>REBEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relation Extraction By End-to-end Language generation (REBEL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An auto-regressive seq2seq relation-extraction model (based on BART) that 'translates' raw text into triplet outputs using special tokens and a parsing function to recover subject–predicate–object triples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Rebel: Relation extraction by end-to-end language generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>REBEL end-to-end relation-extraction</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>REBEL is an auto-regressive sequence-to-sequence model built on BART that performs joint entity and relation extraction by generating serialized triplets. During training and decoding it emits special markers (e.g., <triplet>, <subj>, <obj>) to delimit triples; outputs are parsed by a provided function into subject–predicate–object triples. In this paper REBEL was used as a component in a pipeline: input news articles are tokenized (512-token max), long articles are split into 256-token batches, each batch is processed independently by REBEL, and extracted triplets are merged and post-processed with entity linking (DBpedia).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>BART-based seq2seq model (REBEL); original REBEL paper reports BART backbone (no size specified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Generative seq2seq translation-to-triplets (end-to-end relation extraction with special delimiters), applied on tokenized batches</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Knowledge graph construction by merging triplets across batches/articles and entity linking to DBpedia; no explicit multi-document theory synthesis beyond graph assembly</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>94 news articles (dataset used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Sustainability news/articles</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured triples (subject–relation–object), knowledge graph nodes and edges</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Counts of entities/relations/triples (entities, relations, triples); REBEL model reported micro-F1 (74) and macro-F1 (51) in its original paper; manual qualitative KG-quality principles (18 principles) used for downstream evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On the 94-article sustainability corpus: REBEL produced 805 entities, 105 relations, and 854 triples; original REBEL reported 74 micro-F1 and 51 macro-F1 (from REBEL paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly against ChatGPT-based extraction in this study</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Compared to ChatGPT extraction: REBEL produced fewer entities (805 vs 1158) and fewer relations (105 vs 677) but a similar number of triples (854 vs 826); REBEL produced more normalized/concept-like entities while ChatGPT often output phrase-level entities.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>REBEL, as a model trained for joint entity–relation extraction, yields more concise, normalized entities and interlinked triples suitable for KG construction; it's robust in producing standard relations but constrained by input token limits and by batch-splitting artifacts when processing long documents.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>512-token input limitation requiring splitting into 256-token batches causes potential sentence-boundary cuts and missed relations; entity linking depends on DBpedia presence (entities absent in DBpedia cannot be linked); no built-in ontology generation or high-level concept abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Paper does not present systematic scaling experiments; practical constraints noted: token-length limits force batch processing for longer documents, which can degrade relation extraction if sentences are split across batches; no analysis of behavior with larger document counts or larger backbone models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Knowledge Graph Construction Using Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4531.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4531.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (LLM pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (OpenAI conversational generative model; RLHF-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conversational generative LLM (RLHF-refined) used here via structured prompting to extract relations, generate triples, and—with refined prompts—directly produce OWL ontologies and RDF/Turtle instances from article text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gpt-4 technical report</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChatGPT-based ontology & KG generation pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper applies ChatGPT in two experiments: (1) prompting the model to extract entity–relation triples from each news article and post-processing those with entity linking to DBpedia; (2) refined prompting that instructs ChatGPT to generate an OWL ontology (classes, properties) and instances per article and output RDF/Turtle, thereby directly producing an ontology + populated KG. The ChatGPT model is used with temperature set to 0 for determinism. The ChatGPT stack is described generally as SFT (GPT-3 style), reward models, and RLHF-based policy optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>ChatGPT (OpenAI conversational model derived from GPT-family; paper references GPT-3 training lineage and cites GPT-4 technical report; exact model variant/size not specified in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Instruction/prompt-based generation (structured prompting), i.e., asking the LLM to output triples or OWL/RDF; followed by entity linking post-processing (DBpedia).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Direct ontology generation and instance population per article (RDF/Turtle), followed by assembling per-article ontologies/instances into a knowledge base; knowledge graph construction and potential ontology unification proposed for multi-document synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>94 news articles (dataset used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Sustainability news/articles</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Extracted triples, OWL ontologies, RDF/Turtle instances, populated knowledge graphs</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Counts of entities/relations/triples (paper table); qualitative evaluation against 18 KG-quality principles; no automated factuality metric reported. Temperature set to 0 to reduce nondeterminism.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On the 94-article corpus: ChatGPT (experiment 1) produced 1158 entities, 677 relations, and 826 triples. In raw outputs ChatGPT often emits phrase-level entities and many unique relations, making ontology induction harder until prompts were refined; refined prompts yielded higher-quality ontologies and instance population for single articles (qualitatively judged better by the authors).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against REBEL (end-to-end RE model) and qualitative manual inspection</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ChatGPT extracts more entity mentions and many more relation types than REBEL (1158 entities vs 805; 677 relations vs 105), but many ChatGPT entities are phrase-level (less normalized) and many relations are non-standard, reducing usefulness for unified ontology construction; with refined prompts ChatGPT could produce ontology + instances that were judged qualitatively superior.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ChatGPT, with careful prompt engineering, can directly generate ontologies and instance data (OWL/RDF), enabling fewer manual steps to build KGs from unstructured text; however, default prompts produce noisy, phrase-level entities and many ad-hoc relations. Prompt specificity and formatting requests (e.g., RDF Turtle) substantially improve output quality.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Tendency to output long phrase-level entities and non-standard relations (hallucination/over-specificity); variability in outputs requiring prompt engineering and manual refinement; inability to prompt across all 94 articles at once due to input token-length limits; occasional syntactic or factual errors in generated OWL/Turtle that required correction; lack of deterministic ontology unification across articles.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>No explicit scaling experiments for number of papers or model size; practical limits observed: prompt/input token length prevents defining an ontology across the entire corpus in a single prompt, suggesting scaling requires iterative unification strategies or external orchestration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Knowledge Graph Construction Using Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4531.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4531.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-assisted KG & Ontology Pipeline (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-assisted Knowledge Graph construction and automatic ontology generation pipeline (combined use of REBEL/ChatGPT + entity linking + post-processing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-component pipeline that collects domain documents (News API), applies LLM-based relation extraction (REBEL or ChatGPT), post-processes outputs with entity linking (DBpedia), and—when using refined prompts—has ChatGPT generate OWL ontologies and RDF/Turtle instances to produce a populated knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-assisted Knowledge Graph & Ontology Construction pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pipeline components: (1) Data collection via News API; (2) Preprocessing/tokenization and batching to respect LLM token limits; (3a) Option A: REBEL (BART-based) applied per token batch to generate triplets, then merge; (3b) Option B: ChatGPT prompted to extract triplets (experiment 1) or to generate OWL ontology + instances in RDF/Turtle per article (experiment 2); (4) Entity linking to DBpedia to normalize entities; (5) Merge/visualize triples into knowledge graph; (6) Manual or automated post-processing to correct OWL syntax and unify ontologies across articles is proposed future work.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>REBEL (BART-based seq2seq) and ChatGPT (OpenAI conversational models; GPT-family RLHF-tuned), exact sizes not specified in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Generative seq2seq extraction (REBEL) or instruction-based generation (ChatGPT prompts requesting triples or OWL/RDF outputs); token-batching for long texts; entity linking for normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Assembly of per-article triples/ontologies into a knowledge graph; ontology generation by LLM (ChatGPT) and proposal to unify per-article ontologies across corpus for broader synthesis and link prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>94 news articles processed in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Sustainability (news/articles)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Populated knowledge graphs, OWL ontologies, RDF/Turtle instance data, extracted triplets</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Counts of entities/relations/triples, manual qualitative evaluation against 18 KG-quality principles; REBEL reported micro-F1/macro-F1 in its original paper but no end-to-end automated metrics for the pipeline were used here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Using REBEL pipeline: 805 entities / 105 relations / 854 triples. Using ChatGPT extraction pipeline: 1158 entities / 677 relations / 826 triples. With refined ChatGPT ontology prompt (per-article), the team obtained qualitatively higher-quality ontology+instances for single articles (manual inspection).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Comparison between REBEL-based pipeline and ChatGPT-based pipeline (no human baseline quantified), and qualitative judgement using KG-quality principles.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ChatGPT pipeline yields more entity mentions and relation types but more noisy/phrase-level entries; REBEL pipeline yields more normalized entities and more concise relations suitable for traditional KG assembly; refined ChatGPT prompting can outperform in producing ontologies and populated instances for single articles (qualitatively).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining LLMs with semantic technologies can produce meaningful domain knowledge graphs from unstructured text; specialized RE models (REBEL) yield more canonical triplets while large conversational LLMs (ChatGPT) can be prompted to generate ontologies and instances with fewer pipeline steps when given carefully engineered prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Token length limits constrain per-prompt corpus-level ontology induction; ChatGPT outputs require careful prompt engineering and often need manual correction for syntactic or factual issues; entity linking limited by coverage of the chosen KB (DBpedia); splitting long documents into batches leads to missed relations; lack of automated KG-quality metrics with ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Paper does not provide empirical scaling curves; practical scaling constraints reported include input token limits (preventing single-prompt ontology over entire corpus), batch-splitting artifacts for REBEL, and growing noise in ChatGPT outputs when aggregating many un-unified ontologies; authors propose ontology unification and graph-based link prediction as future work to scale.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Knowledge Graph Construction Using Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4531.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4531.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt engineering (LLM instruction design)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The practice of designing and refining LLM input prompts to elicit desired outputs and formats; in this work, refined prompts substantially improved ChatGPT's ability to generate OWL ontologies and RDF/Turtle instance data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Prompt engineering for ontology & triple generation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Iterative design of prompts that instruct ChatGPT to: (a) extract triples in a prescribed serialized format, (b) map extracted mentions to ontology classes, or (c) directly generate an OWL ontology and RDF/Turtle instances. The paper demonstrates that adding explicit instructions and output format constraints (e.g., 'return RDF Turtle') produces markedly different and higher-quality results.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>ChatGPT (GPT-family conversational models referenced), not a model itself</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Structured prompting and format-constrained generation (detailed instructions, temperature=0 for determinism)</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Prompt-guided ontology generation and per-article instance population enabling downstream merging across documents</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Used on the same 94-article corpus in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Sustainability news/articles</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Improved triples, ontologies (OWL), RDF/Turtle instances</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative comparison of output before/after prompt refinement and manual assessment against KG-quality principles</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Refined prompts enabled ChatGPT to produce coherent ontology classes (e.g., Organizations, Practices, Actions) and populate instances for single articles; no numerical metric reported for prompt efficacy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Default/naive prompts (initial ChatGPT experiment) vs refined prompt (experiment 2)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Refined prompts produced clearer concept classes and instances where naive prompts yielded phrase-level noisy entities and many non-standard relations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prompt engineering is critical: explicit output format and ontology-related instructions markedly improve ChatGPT's suitability for KG/ontology generation; small prompt changes can cause large output differences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Prompting cannot entirely eliminate hallucinations or guarantee ontology consistency across many documents; input-token limits constrain the scope of single-prompt ontology induction.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Paper notes prompt length and LLM token limits restrict the ability to define an ontology using a single prompt over the full corpus; scaling will require iterative/unified prompting or external orchestration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Knowledge Graph Construction Using Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4531.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4531.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Entity Linking (DBpedia)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entity Linking to DBpedia knowledge base</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A post-processing step that maps extracted entity mentions to canonical DBpedia entities (by URL) to normalize nodes in the knowledge graph; used here to reduce duplication and enable linkage across articles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Entity linking with a knowledge base: Issues, techniques, and solutions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DBpedia-backed entity linking</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>After LLM-based extraction (REBEL or ChatGPT), entity mentions are matched to DBpedia entries; two mentions are considered identical if they share the same DBpedia URL. This normalizes entities across triplets before KG assembly. The paper notes that this approach fails when entities are absent from DBpedia.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Not an LLM itself; used as a downstream normalization step for LLM outputs</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>KB-based entity disambiguation and linking</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Normalization of nodes prior to KG merge/assembly</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Applied to outputs from the 94-article corpus</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Sustainability news/articles</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Normalized KG nodes (DBpedia URIs), improved triplet consistency</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not quantified numerically in the paper; described qualitatively (matching by DBpedia URL)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Used to refine extracted relations; coverage limited to entities present in DBpedia (no numeric coverage reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No linking vs DBpedia-backed linking</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>DBpedia linking reduces duplication for entities present in the KB but cannot resolve or normalize entities absent from DBpedia.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Entity linking to a KB is useful to normalize LLM outputs prior to KG assembly but is constrained by KB coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>KB coverage limits: entities not present in DBpedia remain unlinked and cannot be normalized; phrase-level entities produced by ChatGPT complicate linking.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>No explicit scaling experiments; practical limitation: as the number of extracted mentions grows, reliance on KB coverage becomes more significant and unlinked/ambiguous mentions increase.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Knowledge Graph Construction Using Large Language Models', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Rebel: Relation extraction by end-to-end language generation <em>(Rating: 2)</em></li>
                <li>Gpt-4 technical report <em>(Rating: 2)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 2)</em></li>
                <li>BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension <em>(Rating: 2)</em></li>
                <li>Entity linking with a knowledge base: Issues, techniques, and solutions <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
                <li>Owl web ontology language overview <em>(Rating: 2)</em></li>
                <li>Prompt Engineering Guide <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4531",
    "paper_id": "paper-694d9b45adcffa4bbc130e4ccaa681e275640128",
    "extraction_schema_id": "extraction-schema-100",
    "extracted_data": [
        {
            "name_short": "REBEL",
            "name_full": "Relation Extraction By End-to-end Language generation (REBEL)",
            "brief_description": "An auto-regressive seq2seq relation-extraction model (based on BART) that 'translates' raw text into triplet outputs using special tokens and a parsing function to recover subject–predicate–object triples.",
            "citation_title": "Rebel: Relation extraction by end-to-end language generation",
            "mention_or_use": "use",
            "system_name": "REBEL end-to-end relation-extraction",
            "system_description": "REBEL is an auto-regressive sequence-to-sequence model built on BART that performs joint entity and relation extraction by generating serialized triplets. During training and decoding it emits special markers (e.g., &lt;triplet&gt;, &lt;subj&gt;, &lt;obj&gt;) to delimit triples; outputs are parsed by a provided function into subject–predicate–object triples. In this paper REBEL was used as a component in a pipeline: input news articles are tokenized (512-token max), long articles are split into 256-token batches, each batch is processed independently by REBEL, and extracted triplets are merged and post-processed with entity linking (DBpedia).",
            "llm_model_used": "BART-based seq2seq model (REBEL); original REBEL paper reports BART backbone (no size specified in this paper)",
            "extraction_technique": "Generative seq2seq translation-to-triplets (end-to-end relation extraction with special delimiters), applied on tokenized batches",
            "synthesis_technique": "Knowledge graph construction by merging triplets across batches/articles and entity linking to DBpedia; no explicit multi-document theory synthesis beyond graph assembly",
            "number_of_papers": "94 news articles (dataset used in experiments)",
            "domain_or_topic": "Sustainability news/articles",
            "output_type": "Structured triples (subject–relation–object), knowledge graph nodes and edges",
            "evaluation_metrics": "Counts of entities/relations/triples (entities, relations, triples); REBEL model reported micro-F1 (74) and macro-F1 (51) in its original paper; manual qualitative KG-quality principles (18 principles) used for downstream evaluation",
            "performance_results": "On the 94-article sustainability corpus: REBEL produced 805 entities, 105 relations, and 854 triples; original REBEL reported 74 micro-F1 and 51 macro-F1 (from REBEL paper).",
            "comparison_baseline": "Compared directly against ChatGPT-based extraction in this study",
            "performance_vs_baseline": "Compared to ChatGPT extraction: REBEL produced fewer entities (805 vs 1158) and fewer relations (105 vs 677) but a similar number of triples (854 vs 826); REBEL produced more normalized/concept-like entities while ChatGPT often output phrase-level entities.",
            "key_findings": "REBEL, as a model trained for joint entity–relation extraction, yields more concise, normalized entities and interlinked triples suitable for KG construction; it's robust in producing standard relations but constrained by input token limits and by batch-splitting artifacts when processing long documents.",
            "limitations_challenges": "512-token input limitation requiring splitting into 256-token batches causes potential sentence-boundary cuts and missed relations; entity linking depends on DBpedia presence (entities absent in DBpedia cannot be linked); no built-in ontology generation or high-level concept abstraction.",
            "scaling_behavior": "Paper does not present systematic scaling experiments; practical constraints noted: token-length limits force batch processing for longer documents, which can degrade relation extraction if sentences are split across batches; no analysis of behavior with larger document counts or larger backbone models.",
            "uuid": "e4531.0",
            "source_info": {
                "paper_title": "Enhancing Knowledge Graph Construction Using Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "ChatGPT (LLM pipeline)",
            "name_full": "ChatGPT (OpenAI conversational generative model; RLHF-tuned)",
            "brief_description": "A conversational generative LLM (RLHF-refined) used here via structured prompting to extract relations, generate triples, and—with refined prompts—directly produce OWL ontologies and RDF/Turtle instances from article text.",
            "citation_title": "Gpt-4 technical report",
            "mention_or_use": "use",
            "system_name": "ChatGPT-based ontology & KG generation pipeline",
            "system_description": "The paper applies ChatGPT in two experiments: (1) prompting the model to extract entity–relation triples from each news article and post-processing those with entity linking to DBpedia; (2) refined prompting that instructs ChatGPT to generate an OWL ontology (classes, properties) and instances per article and output RDF/Turtle, thereby directly producing an ontology + populated KG. The ChatGPT model is used with temperature set to 0 for determinism. The ChatGPT stack is described generally as SFT (GPT-3 style), reward models, and RLHF-based policy optimization.",
            "llm_model_used": "ChatGPT (OpenAI conversational model derived from GPT-family; paper references GPT-3 training lineage and cites GPT-4 technical report; exact model variant/size not specified in experiments)",
            "extraction_technique": "Instruction/prompt-based generation (structured prompting), i.e., asking the LLM to output triples or OWL/RDF; followed by entity linking post-processing (DBpedia).",
            "synthesis_technique": "Direct ontology generation and instance population per article (RDF/Turtle), followed by assembling per-article ontologies/instances into a knowledge base; knowledge graph construction and potential ontology unification proposed for multi-document synthesis.",
            "number_of_papers": "94 news articles (dataset used in experiments)",
            "domain_or_topic": "Sustainability news/articles",
            "output_type": "Extracted triples, OWL ontologies, RDF/Turtle instances, populated knowledge graphs",
            "evaluation_metrics": "Counts of entities/relations/triples (paper table); qualitative evaluation against 18 KG-quality principles; no automated factuality metric reported. Temperature set to 0 to reduce nondeterminism.",
            "performance_results": "On the 94-article corpus: ChatGPT (experiment 1) produced 1158 entities, 677 relations, and 826 triples. In raw outputs ChatGPT often emits phrase-level entities and many unique relations, making ontology induction harder until prompts were refined; refined prompts yielded higher-quality ontologies and instance population for single articles (qualitatively judged better by the authors).",
            "comparison_baseline": "Compared against REBEL (end-to-end RE model) and qualitative manual inspection",
            "performance_vs_baseline": "ChatGPT extracts more entity mentions and many more relation types than REBEL (1158 entities vs 805; 677 relations vs 105), but many ChatGPT entities are phrase-level (less normalized) and many relations are non-standard, reducing usefulness for unified ontology construction; with refined prompts ChatGPT could produce ontology + instances that were judged qualitatively superior.",
            "key_findings": "ChatGPT, with careful prompt engineering, can directly generate ontologies and instance data (OWL/RDF), enabling fewer manual steps to build KGs from unstructured text; however, default prompts produce noisy, phrase-level entities and many ad-hoc relations. Prompt specificity and formatting requests (e.g., RDF Turtle) substantially improve output quality.",
            "limitations_challenges": "Tendency to output long phrase-level entities and non-standard relations (hallucination/over-specificity); variability in outputs requiring prompt engineering and manual refinement; inability to prompt across all 94 articles at once due to input token-length limits; occasional syntactic or factual errors in generated OWL/Turtle that required correction; lack of deterministic ontology unification across articles.",
            "scaling_behavior": "No explicit scaling experiments for number of papers or model size; practical limits observed: prompt/input token length prevents defining an ontology across the entire corpus in a single prompt, suggesting scaling requires iterative unification strategies or external orchestration.",
            "uuid": "e4531.1",
            "source_info": {
                "paper_title": "Enhancing Knowledge Graph Construction Using Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "LLM-assisted KG & Ontology Pipeline (this work)",
            "name_full": "LLM-assisted Knowledge Graph construction and automatic ontology generation pipeline (combined use of REBEL/ChatGPT + entity linking + post-processing)",
            "brief_description": "A multi-component pipeline that collects domain documents (News API), applies LLM-based relation extraction (REBEL or ChatGPT), post-processes outputs with entity linking (DBpedia), and—when using refined prompts—has ChatGPT generate OWL ontologies and RDF/Turtle instances to produce a populated knowledge graph.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LLM-assisted Knowledge Graph & Ontology Construction pipeline",
            "system_description": "Pipeline components: (1) Data collection via News API; (2) Preprocessing/tokenization and batching to respect LLM token limits; (3a) Option A: REBEL (BART-based) applied per token batch to generate triplets, then merge; (3b) Option B: ChatGPT prompted to extract triplets (experiment 1) or to generate OWL ontology + instances in RDF/Turtle per article (experiment 2); (4) Entity linking to DBpedia to normalize entities; (5) Merge/visualize triples into knowledge graph; (6) Manual or automated post-processing to correct OWL syntax and unify ontologies across articles is proposed future work.",
            "llm_model_used": "REBEL (BART-based seq2seq) and ChatGPT (OpenAI conversational models; GPT-family RLHF-tuned), exact sizes not specified in paper.",
            "extraction_technique": "Generative seq2seq extraction (REBEL) or instruction-based generation (ChatGPT prompts requesting triples or OWL/RDF outputs); token-batching for long texts; entity linking for normalization.",
            "synthesis_technique": "Assembly of per-article triples/ontologies into a knowledge graph; ontology generation by LLM (ChatGPT) and proposal to unify per-article ontologies across corpus for broader synthesis and link prediction.",
            "number_of_papers": "94 news articles processed in experiments",
            "domain_or_topic": "Sustainability (news/articles)",
            "output_type": "Populated knowledge graphs, OWL ontologies, RDF/Turtle instance data, extracted triplets",
            "evaluation_metrics": "Counts of entities/relations/triples, manual qualitative evaluation against 18 KG-quality principles; REBEL reported micro-F1/macro-F1 in its original paper but no end-to-end automated metrics for the pipeline were used here.",
            "performance_results": "Using REBEL pipeline: 805 entities / 105 relations / 854 triples. Using ChatGPT extraction pipeline: 1158 entities / 677 relations / 826 triples. With refined ChatGPT ontology prompt (per-article), the team obtained qualitatively higher-quality ontology+instances for single articles (manual inspection).",
            "comparison_baseline": "Comparison between REBEL-based pipeline and ChatGPT-based pipeline (no human baseline quantified), and qualitative judgement using KG-quality principles.",
            "performance_vs_baseline": "ChatGPT pipeline yields more entity mentions and relation types but more noisy/phrase-level entries; REBEL pipeline yields more normalized entities and more concise relations suitable for traditional KG assembly; refined ChatGPT prompting can outperform in producing ontologies and populated instances for single articles (qualitatively).",
            "key_findings": "Combining LLMs with semantic technologies can produce meaningful domain knowledge graphs from unstructured text; specialized RE models (REBEL) yield more canonical triplets while large conversational LLMs (ChatGPT) can be prompted to generate ontologies and instances with fewer pipeline steps when given carefully engineered prompts.",
            "limitations_challenges": "Token length limits constrain per-prompt corpus-level ontology induction; ChatGPT outputs require careful prompt engineering and often need manual correction for syntactic or factual issues; entity linking limited by coverage of the chosen KB (DBpedia); splitting long documents into batches leads to missed relations; lack of automated KG-quality metrics with ground truth.",
            "scaling_behavior": "Paper does not provide empirical scaling curves; practical scaling constraints reported include input token limits (preventing single-prompt ontology over entire corpus), batch-splitting artifacts for REBEL, and growing noise in ChatGPT outputs when aggregating many un-unified ontologies; authors propose ontology unification and graph-based link prediction as future work to scale.",
            "uuid": "e4531.2",
            "source_info": {
                "paper_title": "Enhancing Knowledge Graph Construction Using Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Prompt engineering",
            "name_full": "Prompt engineering (LLM instruction design)",
            "brief_description": "The practice of designing and refining LLM input prompts to elicit desired outputs and formats; in this work, refined prompts substantially improved ChatGPT's ability to generate OWL ontologies and RDF/Turtle instance data.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Prompt engineering for ontology & triple generation",
            "system_description": "Iterative design of prompts that instruct ChatGPT to: (a) extract triples in a prescribed serialized format, (b) map extracted mentions to ontology classes, or (c) directly generate an OWL ontology and RDF/Turtle instances. The paper demonstrates that adding explicit instructions and output format constraints (e.g., 'return RDF Turtle') produces markedly different and higher-quality results.",
            "llm_model_used": "ChatGPT (GPT-family conversational models referenced), not a model itself",
            "extraction_technique": "Structured prompting and format-constrained generation (detailed instructions, temperature=0 for determinism)",
            "synthesis_technique": "Prompt-guided ontology generation and per-article instance population enabling downstream merging across documents",
            "number_of_papers": "Used on the same 94-article corpus in experiments",
            "domain_or_topic": "Sustainability news/articles",
            "output_type": "Improved triples, ontologies (OWL), RDF/Turtle instances",
            "evaluation_metrics": "Qualitative comparison of output before/after prompt refinement and manual assessment against KG-quality principles",
            "performance_results": "Refined prompts enabled ChatGPT to produce coherent ontology classes (e.g., Organizations, Practices, Actions) and populate instances for single articles; no numerical metric reported for prompt efficacy.",
            "comparison_baseline": "Default/naive prompts (initial ChatGPT experiment) vs refined prompt (experiment 2)",
            "performance_vs_baseline": "Refined prompts produced clearer concept classes and instances where naive prompts yielded phrase-level noisy entities and many non-standard relations.",
            "key_findings": "Prompt engineering is critical: explicit output format and ontology-related instructions markedly improve ChatGPT's suitability for KG/ontology generation; small prompt changes can cause large output differences.",
            "limitations_challenges": "Prompting cannot entirely eliminate hallucinations or guarantee ontology consistency across many documents; input-token limits constrain the scope of single-prompt ontology induction.",
            "scaling_behavior": "Paper notes prompt length and LLM token limits restrict the ability to define an ontology using a single prompt over the full corpus; scaling will require iterative/unified prompting or external orchestration.",
            "uuid": "e4531.3",
            "source_info": {
                "paper_title": "Enhancing Knowledge Graph Construction Using Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Entity Linking (DBpedia)",
            "name_full": "Entity Linking to DBpedia knowledge base",
            "brief_description": "A post-processing step that maps extracted entity mentions to canonical DBpedia entities (by URL) to normalize nodes in the knowledge graph; used here to reduce duplication and enable linkage across articles.",
            "citation_title": "Entity linking with a knowledge base: Issues, techniques, and solutions",
            "mention_or_use": "use",
            "system_name": "DBpedia-backed entity linking",
            "system_description": "After LLM-based extraction (REBEL or ChatGPT), entity mentions are matched to DBpedia entries; two mentions are considered identical if they share the same DBpedia URL. This normalizes entities across triplets before KG assembly. The paper notes that this approach fails when entities are absent from DBpedia.",
            "llm_model_used": "Not an LLM itself; used as a downstream normalization step for LLM outputs",
            "extraction_technique": "KB-based entity disambiguation and linking",
            "synthesis_technique": "Normalization of nodes prior to KG merge/assembly",
            "number_of_papers": "Applied to outputs from the 94-article corpus",
            "domain_or_topic": "Sustainability news/articles",
            "output_type": "Normalized KG nodes (DBpedia URIs), improved triplet consistency",
            "evaluation_metrics": "Not quantified numerically in the paper; described qualitatively (matching by DBpedia URL)",
            "performance_results": "Used to refine extracted relations; coverage limited to entities present in DBpedia (no numeric coverage reported).",
            "comparison_baseline": "No linking vs DBpedia-backed linking",
            "performance_vs_baseline": "DBpedia linking reduces duplication for entities present in the KB but cannot resolve or normalize entities absent from DBpedia.",
            "key_findings": "Entity linking to a KB is useful to normalize LLM outputs prior to KG assembly but is constrained by KB coverage.",
            "limitations_challenges": "KB coverage limits: entities not present in DBpedia remain unlinked and cannot be normalized; phrase-level entities produced by ChatGPT complicate linking.",
            "scaling_behavior": "No explicit scaling experiments; practical limitation: as the number of extracted mentions grows, reliance on KB coverage becomes more significant and unlinked/ambiguous mentions increase.",
            "uuid": "e4531.4",
            "source_info": {
                "paper_title": "Enhancing Knowledge Graph Construction Using Large Language Models",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Rebel: Relation extraction by end-to-end language generation",
            "rating": 2
        },
        {
            "paper_title": "Gpt-4 technical report",
            "rating": 2
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 2
        },
        {
            "paper_title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
            "rating": 2
        },
        {
            "paper_title": "Entity linking with a knowledge base: Issues, techniques, and solutions",
            "rating": 2
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1
        },
        {
            "paper_title": "Owl web ontology language overview",
            "rating": 2
        },
        {
            "paper_title": "Prompt Engineering Guide",
            "rating": 1
        }
    ],
    "cost": 0.01436,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Enhancing Knowledge Graph Construction Using Large Language Models</h1>
<p>$1^{\text {st }}$ Milena Trajanoska<br>Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University Skopje, Macedonia<br>milena.trajanoska@finki.ukim.mk<br>ORCID: 0000-0003-0105-7693</p>
<p>$2^{\text {nd }}$ Riste Stojanov<br>Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University<br>Skopje, Macedonia<br>riste.stojanov@finki.ukim.mk<br>ORCID: 0000-0003-2067-3467</p>
<p>$3^{\text {rd }}$ Dimitar Trajanov
Faculty of Comp. Sci. and Eng.
Ss. Cyril and Methodius University
Skopje, Macedonia
dimitar.trajanov@finki.ukim.mk
ORCID: 0000-0002-3105-6010</p>
<p>Abstract-The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs.</p>
<p>Index Terms-ChatGPT, REBEL, LLMs, Relation-extraction, NLP, Sustainability</p>
<h2>I. INTRODUCTION</h2>
<p>The technological advancements, together with the availability of Big Data, have led to a surge in the development of Large Language Models (LLMs) [1]. This trend has paved the way for a cascade of new models being released on a regular basis, each outperforming its predecessors. These models have started a revolution in the field with their capability to process massive amounts of unstructured text data and by achieving state-of-the-art results on multiple Natural Language Processing (NLP) tasks.</p>
<p>However, one of the aspects which have not yet taken over the spotlight is the combined application of these models with semantic technologies to enable reasoning and inference. This paper attempts to fill this gap by making a connection between the Deep Learning (DL) space and the semantic space, through the use of NLP for creating Knowledge Graphs [2].</p>
<p>Knowledge Graphs are structured representations of information that capture the relationships between entities in a particular domain. They are used extensively in various applications, such as search engines, recommendation systems, and question-answering systems.</p>
<p>On a related note, there is a significant amount of raw texts available on the Web which contain valuable information. Nevertheless, this information is unusable if it cannot be
extracted from the texts and applied for intelligent reasoning. This fact has motivated us to use some of the state-of-the-art models in an attempt to extract information from text data on the Web.</p>
<p>Yet, creating Knowledge Graphs from raw text data is a complex task that requires advanced NLP techniques such as Named Entity Recognition [3], Relation Extraction [4], and Semantic Parsing [5]. Large language models such as GPT-3 [6], T5 [7], and BERT [8] have shown remarkable performance in these tasks, and their use has resulted in significant improvements in the quality and accuracy of knowledge graphs.</p>
<p>To evaluate our approach in connecting both fields, we chose to analyze the specific use case of sustainability. Sustainability is a topic of great importance for our future, and a lot of emphasis has been placed on identifying ways to create more sustainable practices in organizations. Sustainability has become the norm for organizations in developed countries, mainly due to the rising awareness of their consumers and employees. However, this situation is not reflected in developing and underdeveloped countries to this extent. Although the perception of sustainability has improved, progress toward sustainable development has been slower, indicating the need for more concrete guidance [9]. Moreover, theoretical research has attempted to link strategic management and sustainable development in corporations in order to encourage the integration of sustainability issues into corporate activities and strategies [10]. Even though research has set a basis for developing standards and policies in favor of sustainability, a more empirical approach is needed for policy definitions and analyzing an organization's sustainability level with respect to the defined policies.</p>
<p>In this study, the goal is to make a connection between LLMs and semantic reasoning to automatically generate a Knowledge Graph on the topic of sustainability and populate it with concrete instances using news articles available on the Web. For this purpose, we create multiple experiments where we utilize popular NLP models, namely Relation Extraction By End-to-end Language generation (REBEL) [11] and ChatGPT [12]. We show that although REBEL is specifically trained for relation extraction, ChatGPT, a conversational agent using a generative model, can streamline the process</p>
<p>of automatically creating accurate Knowledge Graphs from an unstructured text when provided with detailed instructions.</p>
<p>The rest of the paper is structured as follows: Section II presents a brief literature overview, Section III describes the methods and experimental setup, Section IV outlines the results of the information extraction process, Section V states the propositions for future work, and finally section VI gives the conclusion of the work done in this paper.</p>
<h2>II. Literature Review</h2>
<h2>A. Algorithms</h2>
<p>Our study focuses on the task of information extraction from news and reports available on the Web. For this purpose, we compare the capabilities of NLP models to generate a useful Knowledge Base on the topic.</p>
<p>A Knowledge Base represents information stored in a structured format, ready to be used for analysis or inference. Often, Knowledge Bases are stored in the form of a graph and are then called Knowledge Graphs.</p>
<p>In order to create such a Knowledge Base, we need to extract information from the raw texts in a triplet format. An example of a triplet would be $&lt;$ Person, Location, City $&gt;$. In the triplet, we have a structure consisting of the following links Entity $-&gt;$ Relation $-&gt;$ Entity, where the first entity is referred to as the subject, the relation is a predicate, and the second entity represents the object. In order to achieve this structured information extraction, we need to identify entities in the raw texts, as well as the relations connecting these entities.</p>
<p>In the past, this process was implemented by leveraging multi-step pipelines, where one step included Named-entity Recognition (NER) [3], and another step was Relation classification (RC) [13]. However, these multi-step pipelines often prove to have unsatisfactory performance due to the propagation of errors from the steps. In order to tackle this problem, end-to-end approaches have been implemented, referred to as Relation-Extraction (RE) [4] methods.</p>
<p>One of the models utilized in this study is REBEL (Relation Extraction By End-to-end Language generation) [11], which is an auto-regressive seq2seq model based on BART [14] that performs end-to-end relation extraction for more than 200 different relation types. The model achieves 74 micro-F1 and 51 macro-F1 scores. It was created for the purpose of joint entity-relation extraction.</p>
<p>REBEL is a generative seq2seq model which attempts to "translate" the raw text into a triple format. The REBEL model outputs additional tokens, which are used during its training to identify a triplet. These tokens include $&lt;$ triplet $&gt;$, which represents the beginning of a triplet, $&lt;$ subj $&gt;$, which represents the end of the subject and the start of the predicate, and $&lt;$ obj $&gt;$, which represents the end of the predicate and start of the object. The authors of the paper for REBEL provide a parsing function for extracting the triplet from the output of REBEL.</p>
<p>The second approach we took was to use ChatGPT [12], as a conversational agent and compare the performance in the task of entity-relation extraction and creation of a common</p>
<p>Knowledge Base. The agent consists of three steps, including separate models: a supervised fine-tuning (SFT) model based on GPT-3 [6], a reward model, and a reinforcement learning model.</p>
<p>ChatGPT was trained using Reinforcement Learning from Human Feedback (RLHF) [15], employing methods similar to InstructGPT with minor variations in data collection. An initial model is trained through supervised fine-tuning, with human AI trainers engaging in conversations, assuming both user and AI assistant roles. To aid in formulating responses, trainers were given access to model-generated suggestions. The newly created dialogue dataset was then combined with the InstructGPT dataset, which was transformed into a dialogue format. In order to establish a reward model for reinforcement learning, comparison data needed to be gathered, consisting of two or more model responses ranked by quality. This data was collected by taking conversations between AI trainers and the chatbot, randomly selecting a model-generated message, sampling multiple alternative completions, and having AI trainers rank them. The reward models enabled fine-tuning of ChatGPT using Proximal Policy Optimization [16], and several iterations of this procedure were executed.</p>
<h2>B. Use case: Sustainability</h2>
<p>The Global sustainability study of 2022 has reported that $71 \%$ out of 11,500 surveyed consumers around the world are making changes to the way they live and the products they buy in an effort to live more sustainably [17]. This shows that corporations not only need to change their operations to be more sustainable for the sake of the environment but also to be able to stay competitive.</p>
<p>With the vast amount of unstructured data available on the Web, it is crucial to develop methods that can automatically identify sustainability-related information from news, reports, papers, and other forms of documents. One such study identifies this opportunity and attempts to create a method for directly extracting non-financial information generated by various media to provide objective ESG information [18]. The authors have trained an ESG classifier and recorded a classification accuracy of $86.66 \%$ on 4-class on texts which they manually labeled. On a related note, researchers have taken a step further to extract useful ESG information from texts. In this article [19], the authors have trained a joint entity and relation extraction model on a private dataset consisting of ESG and CSR reports annotated internally at Crédit Agricole. They were able to identify entities such as coal activities and environmental or social issues. In [20], the authors presented an approach for knowledge graph generation based on ESGrelated news and company official documents.</p>
<h2>III. Methods</h2>
<p>This section describes the methods used in this research, including the data collection process and the entity-relation extraction algorithms used to analyze the gathered data.</p>
<h2>A. Data Collecting Process</h2>
<p>In order to conduct the experimental comparison of the two approaches for entity-relation extraction, news data was gathered from the Web on the topic of sustainability. For this purpose, the News API [21] system was used. News API is an HTTP REST API for searching and retrieving live articles from all over the Web. It provides the ability to search through the articles posted on the Web by specifying the following options: keyword or phrase, date of publication, source domain name, and language.</p>
<p>Using News API, 94 news articles from 2023-02-15 to 2023-03-19 on the topic of sustainability have been collected. The collected texts contained various numbers of words ranging from 50 to over 4200 . With the limitation of the number of tokens that can be passed as input to a language model, additional pre-processing steps needed to be taken to account for the texts consisting of a large number of words.</p>
<h2>B. Relation-Extraction Methods</h2>
<p>Relation-extraction is a fundamental task in NLP that aims to identify the semantic relationships between entities in a sentence or document. The task is challenging because it requires understanding the context in which the entities appear and the types of relationships that exist between them.</p>
<p>In this subsection, we describe how we utilize REBEL and ChatGPT for the task of relation extraction.</p>
<p>1) REBEL: Our first approach was to use REBEL in an attempt to extract relations from unstructured news articles. In order for REBEL to be able to use the provided texts, they need to be tokenized with the corresponding tokenizer function. Tokenization is the process of separating the raw text into smaller units called tokens. Tokens can refer to words, characters, or sub-words. The model has a token limitation of 512 tokens, which means that the collected articles which are longer need to be pre-processed before sending them to the model for triplets extraction.</p>
<p>To address this limitation, we tokenize the raw text and divide the tokens into 256-token batches. These batches are processed separately by the REBEL model, and the results are subsequently merged to extract relations for longer texts. Metadata is also added to the extracted relations, referencing the token batch from which the relation was derived. With this approach, some relations may not be extracted accurately because the batch of tokens might begin or end in the middle of the sentence. However, the number of cases where this happens is insignificant. Thus, we leave their handling for future work.</p>
<p>Once the entity-relation extraction process is finished, the extracted information is stored in a triplet structure. To further normalize the extracted entities, we perform Entity Linking [22]. Entity Linking refers to the identification and association of entity mentions in raw text with their corresponding entities in a Knowledge Base. The process of Entity Linking is not part of the REBEL model, and it is an additional post-processing step that is used to refine the extracted relations. In this study, we utilize DBpedia as our Knowledge Base and consider two entities identical if they share the same DBpedia URL. This approach will not work for entities that are not present on DBpedia.
2) ChatGPT: The second approach taken in this paper uses OpenAI's ChatGPT [12]. We have created two experiments using ChatGPT.</p>
<p>The first experiment prompts ChatGPT to extract relations from the collected news articles. After extracting the relations, we follow the same steps as with the REBEL model in order to create a comprehensive Knowledge Base.</p>
<p>The second experiment focuses on creating a prompt that would directly generate the entire Knowledge Base and write an ontology describing the concepts identified in the texts. This approach has the goal of reducing the number of manual steps which need to be performed in order to obtain the final Knowledge Graph.</p>
<p>For both experiments, we set the value of the parameter 'temperature' to 0 in order to get more deterministic outputs since OpenAI models are non-deterministic by nature.</p>
<p>Experiment 1. For the first experiment, we prompt ChatGPT to extract relations connected to sustainability. ChatGPT was able to successfully extract entities and connect them with relations, and return the results in a triple format. After the relations had been extracted, the same post-processing step of Entity Linking was implemented on the results from ChatGPT.</p>
<p>Although ChatGPT was able to extract entities from the articles and link them with relations, it was not successful at abstracting concepts. The entities and relations identified often represented whole phrases instead of concepts.</p>
<p>To overcome the obstacle, we prompted ChatGPT to map identified entities and relations to a suitable OWL ontology [23]. However, ChatGPT failed to identify relevant sustainability concepts or define their instances. The identified classes, such as Company, Customer, MarketingEcosystem, Resource, CustomerExperience, Convenience, and DigitalMarketing, had some potential relevance to sustainability, but ChatGPT did not identify any instances for these classes.</p>
<p>Experiment 2. In the second experiment, we refined the prompt to ask ChatGPT to explicitly generate an OWL ontology on sustainability, which includes concepts like organizations, actions, practices, policies, and related terms. We also allowed ChatGPT to create additional classes and properties if necessary. We explicitly requested the results to be returned in RDF Turtle format.</p>
<p>Providing additional information to ChatGPT resulted in the creation of an improved Knowledge Base. ChatGPT was able to define concepts such as organizations, actions, practices, and policies, as well as identify suitable relations to connect them together. Moreover, it was able to create instances of the defined classes and properties and link them together. This shows that adding more specific instructions to the prompts for ChatGPT can produce drastically different results.</p>
<h2>IV. ReSults</h2>
<p>This section presents the results from the experiments described in Section III. A comparison of the created Knowledge Base from both methods is given, and the characteristics of the</p>
<p>generated Knowledge Bases are outlined. Table I represents the Knowledge Bases from the REBEL model and the first experiment with ChatGPT, respectively. The table shows the number of entities, relations, and triplets extracted from the raw texts on sustainability.</p>
<p>TABLE I
KNOWLEDGE BASE STRUCTURE COMPARISON</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">Entities</th>
<th style="text-align: left;">Relations</th>
<th style="text-align: left;">Triples</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">REBEL</td>
<td style="text-align: left;">805</td>
<td style="text-align: left;">105</td>
<td style="text-align: left;">854</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: left;">1158</td>
<td style="text-align: left;">677</td>
<td style="text-align: left;">826</td>
</tr>
</tbody>
</table>
<p>As it is evident from the table, the number of triplets extracted by both algorithms is similar. However, the number of entities that ChatGPT extracts are larger than those from REBEL. Although this is true, a lot of the extracted entities are not connected to each other via any relation, thus defeating the purpose of creating a Knowledge Base. Moreover, the number of unique relations is far too large for ChatGPT to be able to produce an ontology that can be used for further experimentation.</p>
<p>The most frequent relation for the REBEL model is the 'subclass of' relation, being part of 120 triplets. For ChatGPT, it's the 'has' relation, being identified in 29 triplets. In addition, ChatGPT often fails to generate standard relations and entities which represent abstract concepts and instead outputs an entire phrase, such as in the example 'has already surpassed a goal set in 2019 to install 100,000 heat pumps in homes and businesses', where it identifies this phrase as a relation.</p>
<p>The following subsections represent a visual display of a subset of the generated Knowledge Bases from both algorithms.</p>
<h2>A. REBEL</h2>
<p>In order to be able to analyze the Knowledge Base generated using the REBEL model more accurately, we have created a visualization in a graph format, where each entity represents a node in the graph, and each relation represents an edge. Fig. IV-A displays a subset of the extracted Knowledge Base.</p>
<p>It is visible from the figure that the model successfully identifies entities related to sustainability, such as 'sustainability', 'recycling', 'clean technology', 'business model', 'repurposing', and even links corporations such as 'Samsung' to these entities. We can notice that multiple entities are interlinked in a meaningful way.</p>
<h2>B. ChatGPT</h2>
<p>The same visualization for the Knowledge Base generated by the first experiment with ChatGPT is represented in this subsection. Fig. IV-B displays a subset of the extracted Knowledge Base.</p>
<p>We can see from the figure that ChatGPT is able to identify entities related to sustainability, but they are represented as phrases instead of concepts. For example, ChatGPT extracts 'small high-value items in jumbo packaging', 'steps and waste from its supply chain', and 'suppliers to use recycled and recyclable materials', as entities.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Subset of the Knowledge Base generated using the REBEL model. The Knowledge Base is displayed in a graph format where entities are represented as nodes and relations are represented as edges.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. Subset of the Knowledge Base generated using the first experiment with ChatGPT. The Knowledge Base is displayed in a graph format where entities are represented as nodes and relations are represented as edges.</p>
<p>Although these phrases are related to sustainability, they do not represent specific entities. This happens as a result of the fact that ChatGPT is a conversational model trained on a task to generate responses to a provided prompt and not specifically trained to be able to recognize entities and relations. On the other hand, ChatGPT is able to identify some concepts that REBEL does not, and additionally, it is able to link corporations to specific sustainability-related phrases.</p>
<p>Prompt engineering [24] is of great importance when it comes to the results generated from ChatGPT [12]. Since it is a generative model, small variations in the input sequence can create large differences in the produced output.</p>
<p>Observing the full Knowledge Base generated using ChatGPT, most of the time, the extracted entities represent phrases or whole sentences, which is not beneficial for creating a Knowledge Base because it’s hard to normalize the entities and relations and create a more general ontology consisting of the concepts represented in the graph.</p>
<p>For this reason, we conducted the second experiment with ChatGPT, where we defined a more detailed prompt and instructed ChatGPT to generate an ontology based on each article it sees and additionally define instances of the generated ontology based on the information present in each article.</p>
<p>Figure IV-B presents the results of the refined prompt, with the ontology and instances generated from a single article out of the 94 collected articles.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Knowledge Base generated with ChatGPT for the first article. The identified concepts are represented as yellow rectangles, and the instances are represented with green rectangles.</p>
<p>Not only does ChatGPT create an ontology using the concepts it was instructed to use, but it also defines classes on its own and is able to create instances of most of the classes accurately.</p>
<p>As an example, it identifies the entity "Soluna" as an "instanceOf" the class "Organizations". Furthermore, it is able to identify the triplet <Soluna, utilizes, Excess Energy>, and <Excess Energy, instanceOf, Practices>.</p>
<p>These types of triplets already start representing an initial knowledge base, which can answer queries on companies that implement practices that use excess energy. Although the hierarchy of concepts can be better defined so that more complex queries can be answered, this method represents a solid start in building a shared Knowledge Base, using only unstructured texts.</p>
<p>Using another article, the ontology and instances given in Fig.IV-B have been generated. Looking at this second example, we can see that ChatGPT links practices, actions, and policies to the organizations, which was not the case in the previous example.</p>
<p>Additionally, it identifies the triplets <Starbucks, instanceOf, Organization>, and &lt;Starbucks, hasPractice,</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Knowledge Base generated with ChatGPT for the second article. The identified concepts are represented as yellow rectangles, and the instances are represented with green rectangles.</p>
<p>ResourceSharing&gt;. This also allows for answering complex queries in the sustainability domain.</p>
<p>While the consistency of the generated ontologies may be limited, our analysis reveals that there are significant similarities between them. Therefore, future research can explore methods for unifying these ontologies across all articles, which has the potential to enhance the overall definition of concepts and their interrelationships in the sustainability domain.</p>
<p>It is important to mention that due to the limitations of the length of the input prompt passed to ChatGPT, it was not possible to prompt the model first to define an ontology based on all articles on sustainability and then create instances from all the other articles using the same ontology.</p>
<h3>C. Quality Evaluation</h3>
<p>Since the evaluation of a Knowledge Base cannot be created in an automated way based on some metric, when ground truth data is not available, we need to utilize qualitative principles in order to evaluate the results. Based on the practical framework defined in the study [25], the following 18 principles identified:</p>
<ol>
<li>Triples should be concise</li>
<li>Contextual information of entities should be captured</li>
<li>Knowledge graph does not contain redundant triples</li>
<li>Knowledge graph can be updated dynamically</li>
<li>Entities should be densely connected</li>
<li>Relations among different types of entities should be included</li>
<li>Data source should be multi-field</li>
<li>Data for constructing a knowledge graph should in different types and from different resources</li>
<li>Synonyms should be mapped, and ambiguities should be eliminated to ensure reconcilable expressions</li>
<li>Knowledge graph should be organized in structured triples for easily processed by machine</li>
<li>The scalability with respect to the KG size</li>
<li>The attributes of the entities should not be missed</li>
<li>Knowledge graph should be publicly available and proprietary</li>
<li>Knowledge graph should be an authority</li>
<li>Knowledge graph should be concentrated</li>
<li>The triples should not contradict each other</li>
<li>For domain-specific tasks, the knowledge graph should be related to that field</li>
</ol>
<p>18) Knowledge graph should contain the latest resources to guarantee freshness
According to these principles, in our use case, we manually inspected the Knowledge Graphs generated with the proposed methods, and we can conclude that the second ChatGPT approach creates a Knowledge Graph of greater quality compared to the other two Knowledge Bases.</p>
<p>However, it should be noted that to create these Knowledge Bases, a few steps of refining the answers from ChatGPT are needed. Sometimes the produced output is erroneous and needs to be corrected before proceeding. Thus, this calls for methods for automatically identifying incorrect OWL syntax and requesting to fix the previous output.</p>
<h2>V. CONCLUSION</h2>
<p>In this paper, we presented a Natural Language Processingbased method for constructing a Knowledge Graph on the topic of sustainability using raw documents available on the Web. The study demonstrated that meaningful information could be extracted from unstructured data through an automated process, which can subsequently be utilized for decision-making and process modeling. The focus on sustainability served as a concrete use case, illustrating the effectiveness and potential of the presented approach.</p>
<p>Although the experiments were conducted on the use case of sustainability, the primary emphasis is on the methodology itself, which lays the foundation for empirical analysis of qualitative data derived from various sources. The construction of a Knowledge Base using the presented approach can serve as a first step for analyzing diverse aspects of any subject matter and answering complex queries based on the gathered information.</p>
<p>In future research, first, we plan to adopt a more formal framework for assessing the quality of generated knowledge graphs. Such a framework will enable us to effectively evaluate the quality of KGs and provide a standardized means of assessing their overall quality. We also want to extend the presented methodology to other domains, unifying generated knowledge bases and employing graph-based modeling to predict missing links between concepts and relationships for a given domain.</p>
<h2>REFERENCES</h2>
<p>[1] T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean, "Large language models in machine translation," in Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 858-867, Association for Computational Linguistics, June 2007.
[2] X. Chen, S. Jia, and Y. Xiang, "A review: Knowledge reasoning over knowledge graph," Expert Systems with Applications, vol. 141, p. 112948, 2020.
[3] A. Mikheev, M. Moens, and C. Grover, "Named entity recognition without gazetteers," in Ninth Conference of the European Chapter of the Association for Computational Linguistics, pp. 1-8, 1999.
[4] G. Zhou, J. Su, J. Zhang, and M. Zhang, "Exploring various knowledge in relation extraction," in Proceedings of the 43rd annual meeting of the association for computational linguistics (acl'05), pp. 427-434, 2005.
[5] A. Kamath and R. Das, "A survey on semantic parsing," arXiv preprint arXiv:1812.00978, 2018.
[6] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.
[7] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," The Journal of Machine Learning Research, vol. 21, no. 1, pp. 5485-5551, 2020.
[8] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.
[9] U. Nations, "World's poorest nations left behind in reaching sustainable development goals, delegates stress as second committee begins general debate," 2018. https://press.un.org/en/2018/gaef3495.doc.htm.
[10] R. J. Baumgartner and R. Rauter, "Strategic perspectives of corporate sustainability management to develop a sustainable organization," Journal of Cleaner Production, vol. 140, pp. 81-92, 2017.
[11] P.-L. H. Cabot and R. Navigli, "Rebel: Relation extraction by end-to-end language generation," in Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2370-2381, 2021.
[12] OpenAI, "Gpt-4 technical report," arXiv preprint arXiv:2303.08774, 2023.
[13] D. Zeng, K. Liu, S. Lai, G. Zhou, and J. Zhao, "Relation classification via convolutional deep neural network," in Proceedings of COLING 2014, the 25th international conference on computational linguistics: technical papers, pp. 2335-2344, 2014.
[14] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer, "BART: Denoising sequence-tosequence pre-training for natural language generation, translation, and comprehension," in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, (Online), pp. 7871-7880, Association for Computational Linguistics, July 2020.
[15] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., "Training language models to follow instructions with human feedback," Advances in Neural Information Processing Systems, vol. 35, pp. 27730-27744, 2022.
[16] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, "Proximal policy optimization algorithms," arXiv preprint arXiv:1707.06347, 2017.
[17] Simon-Kucher, "2022 global sustainability study: The growth potential of environmental change." https://www.simon-kucher.com/en/insights/2022-global-sustainability-study-growth-potential-environmental-change.
[18] J. Lee and M. Kim, "Esg information extraction with cross-sectoral and multi-source adaptation based on domain-tuned language models," Expert Systems with Applications, p. 119726, 2023.
[19] A. Ehrhardt and M. T. Nguyen, "Automated esg report analysis by joint entity and relation extraction," in Machine Learning and Principles and Practice of Knowledge Discovery in Databases: International Workshops of ECML PKDD 2021, Virtual Event, September 13-17, 2021, Proceedings, Part II, pp. 325-340, Springer, 2022.
[20] I. Vodenska, R. Trajanov, L. Chitkushev, and D. Trajanov, "Challenges and opportunities in esg investments," in Computer Science and Education in Computer Science: 18th EAI International Conference, CSECS 2022, On-Site and Virtual Event, June 24-27, 2022, Proceedings, pp. 168-179, Springer, 2022.
[21] NewsAPI.org, "Newsapi." "https://newsapi.org/".
[22] W. Shen, J. Wang, and J. Han, "Entity linking with a knowledge base: Issues, techniques, and solutions," IEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 2, pp. 443-460, 2014.
[23] D. L. McGuinness, F. Van Harmelen, et al., "Owl web ontology language overview," W3C recommendation, vol. 10, no. 10, p. 2004, 2004.
[24] E. Saravia, "Prompt Engineering Guide," https://github.com/dairai/Prompt-Engineering-Guide, 122022.
[25] H. Chen, G. Cao, J. Chen, and J. Ding, "A practical framework for evaluating the quality of knowledge graph," in Knowledge Graph and Semantic Computing: Knowledge Computing and Language Understanding: 4th China Conference, CCKS 2019, Hangzhou, China, August 24-27, 2019, Revised Selected Papers 4, pp. 111-122, Springer, 2019.</p>            </div>
        </div>

    </div>
</body>
</html>