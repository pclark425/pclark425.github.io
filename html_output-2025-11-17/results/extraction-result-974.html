<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-974 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-974</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-974</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-23.html">extraction-schema-23</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <p><strong>Paper ID:</strong> paper-003ef1cd670d01af05afa0d3c72d72228f494432</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/003ef1cd670d01af05afa0d3c72d72228f494432" target="_blank">LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> LLM+P is the first framework that incorporates the strengths of classical planners into large language models, and is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most Problems.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.\footnote{The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e974.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e974.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM+P</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model plus Planner (LLM+P)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that uses an LLM to translate natural-language planning problems into PDDL problem files, invokes a classical PDDL planner to compute optimal plans, and then uses the LLM to translate planner output back to natural language or robot actions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM+P</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LLM+P takes a natural language description of a planning instance and (1) uses an LLM (GPT-4 in the experiments) as a PDDL writer to produce a grounded problem PDDL file using in-context learning, (2) supplies the generated problem PDDL together with a provided domain PDDL to a classical planner (FAST-DOWNWARD) to compute an (often optimal) symbolic plan, and (3) translates the symbolic PDDL plan back to natural language via the LLM for presentation or execution. The pipeline assumes domain PDDL is provided by a human expert and relies on a single example (problem, PDDL) pair as context for reliable LLM generation.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Uses the Planning Domain Definition Language (PDDL) split into a domain file (lifted predicates, actions with preconditions and effects defining symbolic action set A and transition function f) and a problem file (objects, initial state s_init encoded as ground predicates, and goal conditions S^G). Representation is deterministic classical planning (factored finite state space, symbolic preconditions and effects). No probabilistic transition model is used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>world model construction (translate NL to problem PDDL) and plan-to-language translation</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Classical symbolic planning via FAST-DOWNWARD (SEQ-OPT-FDSS-1 alias for optimal search; LAMA alias as suboptimal fallback)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Natural-language described robot planning domains (7 domains from PDDL generators: BlockSWORLD, BARMAN, Floortile, GRIPPERS, Storage, TERMES, TyReWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Each problem is presented as a natural language description of a robot planning instance (initial facts, object locations, goals). These are not interactive text-adventure environments like TextWorld, but are NL-to-PDDL translation tasks where the LLM must encode the initial state and goal into a PDDL problem file for symbolic planners. Domains are drawn from standard PDDL planning benchmarks and are moderately complex, involving spatial relations and object manipulations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Success rate (percentage of problems for which planner returned a correct/optimal plan) and plan optimality (minimize total-cost metric when provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Across 7 domains and 20 tasks each: LLM+P achieves high success rates on many domains (examples: BlockSWORLD 90% success, GRIPPERS 95% success (100% with suboptimal alias), Storage 85%, BARMAN 20% (100% when reporting suboptimal alias); several domains where failures are due to mis-specified PDDL by LLM). Reported in Table I of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to direct LLM-as-planner approaches: LLM-AS-P (LLM alone) and Tree of Thoughts (LLM^{ToT}). LLM-AS-P largely fails (many infeasible plans); LLM+P substantially outperforms these baselines (e.g., BlockSWORLD: LLM+P 90% vs LLM 15%-30% depending on variant; GRIPPERS: LLM+P 95% vs LLM 35%).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Paper reports the importance of contextual example (one (problem, PDDL) pair) for reliable LLM-to-PDDL translation: without context the LLM often outputs incorrect/missing initial predicates and LLM+P fails. No ablation is reported that compares planning with vs without explicit modeling of LLM or state uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Translating NL problem descriptions into formal PDDL using an LLM and delegating planning to a sound classical planner yields far more reliable and often optimal plans than asking the LLM to produce plans directly; however, LLM+P as presented uses deterministic PDDL and does not model LLM output uncertainty or probabilistic state transitions, and failures are primarily due to LLM mis-specification of problem PDDL (missing facts). Contextual in-context examples are crucial for accurate PDDL generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e974.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e974.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PDDL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Planning Domain Definition Language (PDDL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standard symbolic language for encoding classical planning domains (lifted predicates and action schemas) and problem instances (objects, initial grounded facts, and goal conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An introduction to the planning domain definition language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PDDL (used as symbolic world model)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PDDL provides a lifted representation of predicates and action schemata (preconditions and effects). A domain file captures action models (the symbolic transition function f) and a problem file grounds objects and lists initial facts and goals. PDDL in this paper is used deterministically (STRIPS-like semantics, optional numeric fluents and metric optimization) to represent states and transitions for classical planners.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL (deterministic classical planning language)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>States are represented as sets of ground predicates over objects (factored finite discrete state space). Actions are symbolic with preconditions and deterministic effects; numeric fluents and a total-cost metric can be included, but the core model is non-probabilistic. Transitions are deterministic application of action effects given that preconditions hold.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Serves as input to classical planners (e.g., FAST-DOWNWARD); planning performed by search-based planners (A*/heuristic search variants) outside PDDL itself.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>Natural-language described planning instances converted to PDDL (benchmark tasks from PDDL generators)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Not an interactive text-adventure; PDDL encodes the world for symbolic planners. Tasks are provided as NL descriptions that the LLM translates into PDDL problem files.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>N/A (PDDL is a representation format).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PDDL is a suitable deterministic symbolic world model for translating NL-specified problems into representations that sound, complete classical planners can solve; the paper uses PDDL as the canonical symbolic representation but does not extend it to probabilistic variants (e.g., PPDDL) or belief-state planning in the LLM+P pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e974.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e974.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FAST-DOWNWARD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fast Downward Planning System</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used classical planning system that takes PDDL domain and problem files as input and runs heuristic search to produce plans; supports multiple search algorithms and aliases for optimal or satisficing search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The fast downward planning system</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FAST-DOWNWARD (planner)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>FAST-DOWNWARD is used as the classical planner backend for LLM+P. The authors feed the LLM-generated problem PDDL and the provided domain PDDL into FAST-DOWNWARD and run either an alias guaranteed to find optimal plans (SEQ-OPT-FDSS-1) or a satisficing alias (LAMA) as fallback, with a 200-second search timeout per problem.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>PDDL (deterministic symbolic planning)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Operates on grounded PDDL representations: states are sets of ground atoms, actions are grounded operator instances with deterministic preconditions/effects. Planning is deterministic heuristic search with numeric fluents supported if present.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Heuristic search-based planners (aliases used: SEQ-OPT-FDSS-1 for optimal search and LAMA for satisficing search).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>PDDL benchmark domains converted from NL descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Planner solves the deterministic PDDL problems produced by the LLM; not an interactive text-based game environment.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Success rate on produced PDDL problems; ability to find optimal plans within time limit.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>When supplied correct PDDL, FAST-DOWNWARD finds optimal plans in many domains within the 200s limit (used to report LLM+P success rates; exact per-domain details provided in paper Table I).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FAST-DOWNWARD reliably produces optimal plans when given correctly specified PDDL problem files; thus delegating planning to a classical planner is effective provided the LLM correctly encodes the problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e974.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e974.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SayCan</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SayCan (Grounding language in robotic affordances)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior approach that grounds natural-language requests using learned affordance functions to inform robot action selection, combining language understanding with action feasibility scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Do as i can, not as i say: Grounding language in robotic affordances</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SayCan</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited in related work as an approach that enables robot planning from natural-language service requests by combining language model outputs with affordance functions that score the feasibility or utility of candidate actions; the approach grounds NL to actions and ranks them by affordance likelihoods to guide execution.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Affordance-based grounding (not specified as PDDL/PPDDL in citation within this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Represents action feasibility via learned affordance functions (scores or probabilities over actions given context and language); does not appear in this paper as a PDDL-based probabilistic symbolic world model, but is cited as an LLM-augmented planner that accounts for action feasibility.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>Language understanding and proposal of candidate actions given NL goals (combined with affordance scoring to select feasible actions)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Affordance-weighted action selection; not framed as classical PDDL planning within this paper's discussion</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Mentioned as a robot planning system that accepts NL requests; the paper cites it as related work but does not evaluate it or provide environment-level metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an example of combining LLM/NL understanding with affordance functions to account for action feasibility; considered complementary to the LLM+P philosophy of combining language models with external modules, but not a PDDL/PPDDL probabilistic symbolic world model within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e974.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e974.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Integrated TAMP in Belief Space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Integrated Task and Motion Planning in Belief Space</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task-and-motion planning approach that reasons about uncertainty by planning in belief space (distributions over continuous states) combining discrete task planning and continuous motion planning under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Integrated task and motion planning in belief space</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Integrated Task and Motion Planning (belief-space TAMP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced in background as a form of TAMP that combines discrete symbolic planning with motion planning while representing state uncertainty as belief distributions; typically used for robotic domains where uncertainty in perception and motion is important.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Belief-space representation (probability distributions over continuous/pose states combined with discrete task-level representations)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Represents the robot's state as a belief (probability distribution), propagates uncertainty through actions and observations, and composes symbolic task-level decisions with continuous motion planning under uncertainty; inherently probabilistic and intended to handle aleatoric and perceptual uncertainty in robotic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>State uncertainty / perceptual and motion uncertainty (beliefs)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Belief-state representations (probability distributions) used in integrated planning; exact methods depend on cited work (e.g., belief propagation, POMDP-like reasoning) but paper only cites the approach in background.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Hierarchical TAMP combining discrete symbolic planning and continuous motion planning in belief space (methods vary by cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Referenced as robotic planning literature that explicitly reasons about uncertainty; not evaluated in this paper's NL-to-PDDL experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as an example of planning approaches that explicitly maintain belief states (probabilistic symbolic/continuous world models) â€” relevant to the query because it embodies probabilistic symbolic/continuous world modelling, but it is only cited in background and not integrated with LLM uncertainty in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Do as i can, not as i say: Grounding language in robotic affordances <em>(Rating: 2)</em></li>
                <li>Integrated task and motion planning in belief space <em>(Rating: 2)</em></li>
                <li>Robots that ask for help: Uncertainty alignment for large language model planners <em>(Rating: 2)</em></li>
                <li>PDDL planning with pretrained large language models <em>(Rating: 2)</em></li>
                <li>Leveraging pre-trained large language models to construct and utilize world models for model-based task planning <em>(Rating: 2)</em></li>
                <li>Generalized planning in pddl domains with pretrained large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-974",
    "paper_id": "paper-003ef1cd670d01af05afa0d3c72d72228f494432",
    "extraction_schema_id": "extraction-schema-23",
    "extracted_data": [
        {
            "name_short": "LLM+P",
            "name_full": "Large Language Model plus Planner (LLM+P)",
            "brief_description": "A framework that uses an LLM to translate natural-language planning problems into PDDL problem files, invokes a classical PDDL planner to compute optimal plans, and then uses the LLM to translate planner output back to natural language or robot actions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LLM+P",
            "system_description": "LLM+P takes a natural language description of a planning instance and (1) uses an LLM (GPT-4 in the experiments) as a PDDL writer to produce a grounded problem PDDL file using in-context learning, (2) supplies the generated problem PDDL together with a provided domain PDDL to a classical planner (FAST-DOWNWARD) to compute an (often optimal) symbolic plan, and (3) translates the symbolic PDDL plan back to natural language via the LLM for presentation or execution. The pipeline assumes domain PDDL is provided by a human expert and relies on a single example (problem, PDDL) pair as context for reliable LLM generation.",
            "world_model_type": "PDDL",
            "world_model_description": "Uses the Planning Domain Definition Language (PDDL) split into a domain file (lifted predicates, actions with preconditions and effects defining symbolic action set A and transition function f) and a problem file (objects, initial state s_init encoded as ground predicates, and goal conditions S^G). Representation is deterministic classical planning (factored finite state space, symbolic preconditions and effects). No probabilistic transition model is used in experiments.",
            "uses_llm": true,
            "llm_role": "world model construction (translate NL to problem PDDL) and plan-to-language translation",
            "llm_model_name": "GPT-4",
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Classical symbolic planning via FAST-DOWNWARD (SEQ-OPT-FDSS-1 alias for optimal search; LAMA alias as suboptimal fallback)",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "Natural-language described robot planning domains (7 domains from PDDL generators: BlockSWORLD, BARMAN, Floortile, GRIPPERS, Storage, TERMES, TyReWorld)",
            "text_environment_description": "Each problem is presented as a natural language description of a robot planning instance (initial facts, object locations, goals). These are not interactive text-adventure environments like TextWorld, but are NL-to-PDDL translation tasks where the LLM must encode the initial state and goal into a PDDL problem file for symbolic planners. Domains are drawn from standard PDDL planning benchmarks and are moderately complex, involving spatial relations and object manipulations.",
            "performance_metric": "Success rate (percentage of problems for which planner returned a correct/optimal plan) and plan optimality (minimize total-cost metric when provided).",
            "performance_value": "Across 7 domains and 20 tasks each: LLM+P achieves high success rates on many domains (examples: BlockSWORLD 90% success, GRIPPERS 95% success (100% with suboptimal alias), Storage 85%, BARMAN 20% (100% when reporting suboptimal alias); several domains where failures are due to mis-specified PDDL by LLM). Reported in Table I of the paper.",
            "baseline_comparison": "Compared to direct LLM-as-planner approaches: LLM-AS-P (LLM alone) and Tree of Thoughts (LLM^{ToT}). LLM-AS-P largely fails (many infeasible plans); LLM+P substantially outperforms these baselines (e.g., BlockSWORLD: LLM+P 90% vs LLM 15%-30% depending on variant; GRIPPERS: LLM+P 95% vs LLM 35%).",
            "has_ablation_uncertainty": false,
            "ablation_results": "Paper reports the importance of contextual example (one (problem, PDDL) pair) for reliable LLM-to-PDDL translation: without context the LLM often outputs incorrect/missing initial predicates and LLM+P fails. No ablation is reported that compares planning with vs without explicit modeling of LLM or state uncertainty.",
            "key_findings": "Translating NL problem descriptions into formal PDDL using an LLM and delegating planning to a sound classical planner yields far more reliable and often optimal plans than asking the LLM to produce plans directly; however, LLM+P as presented uses deterministic PDDL and does not model LLM output uncertainty or probabilistic state transitions, and failures are primarily due to LLM mis-specification of problem PDDL (missing facts). Contextual in-context examples are crucial for accurate PDDL generation.",
            "uuid": "e974.0",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "PDDL",
            "name_full": "Planning Domain Definition Language (PDDL)",
            "brief_description": "A standard symbolic language for encoding classical planning domains (lifted predicates and action schemas) and problem instances (objects, initial grounded facts, and goal conditions).",
            "citation_title": "An introduction to the planning domain definition language",
            "mention_or_use": "use",
            "system_name": "PDDL (used as symbolic world model)",
            "system_description": "PDDL provides a lifted representation of predicates and action schemata (preconditions and effects). A domain file captures action models (the symbolic transition function f) and a problem file grounds objects and lists initial facts and goals. PDDL in this paper is used deterministically (STRIPS-like semantics, optional numeric fluents and metric optimization) to represent states and transitions for classical planners.",
            "world_model_type": "PDDL (deterministic classical planning language)",
            "world_model_description": "States are represented as sets of ground predicates over objects (factored finite discrete state space). Actions are symbolic with preconditions and deterministic effects; numeric fluents and a total-cost metric can be included, but the core model is non-probabilistic. Transitions are deterministic application of action effects given that preconditions hold.",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Serves as input to classical planners (e.g., FAST-DOWNWARD); planning performed by search-based planners (A*/heuristic search variants) outside PDDL itself.",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "Natural-language described planning instances converted to PDDL (benchmark tasks from PDDL generators)",
            "text_environment_description": "Not an interactive text-adventure; PDDL encodes the world for symbolic planners. Tasks are provided as NL descriptions that the LLM translates into PDDL problem files.",
            "performance_metric": "N/A (PDDL is a representation format).",
            "performance_value": "",
            "baseline_comparison": "",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "PDDL is a suitable deterministic symbolic world model for translating NL-specified problems into representations that sound, complete classical planners can solve; the paper uses PDDL as the canonical symbolic representation but does not extend it to probabilistic variants (e.g., PPDDL) or belief-state planning in the LLM+P pipeline.",
            "uuid": "e974.1",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "FAST-DOWNWARD",
            "name_full": "Fast Downward Planning System",
            "brief_description": "A widely used classical planning system that takes PDDL domain and problem files as input and runs heuristic search to produce plans; supports multiple search algorithms and aliases for optimal or satisficing search.",
            "citation_title": "The fast downward planning system",
            "mention_or_use": "use",
            "system_name": "FAST-DOWNWARD (planner)",
            "system_description": "FAST-DOWNWARD is used as the classical planner backend for LLM+P. The authors feed the LLM-generated problem PDDL and the provided domain PDDL into FAST-DOWNWARD and run either an alias guaranteed to find optimal plans (SEQ-OPT-FDSS-1) or a satisficing alias (LAMA) as fallback, with a 200-second search timeout per problem.",
            "world_model_type": "PDDL (deterministic symbolic planning)",
            "world_model_description": "Operates on grounded PDDL representations: states are sets of ground atoms, actions are grounded operator instances with deterministic preconditions/effects. Planning is deterministic heuristic search with numeric fluents supported if present.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Heuristic search-based planners (aliases used: SEQ-OPT-FDSS-1 for optimal search and LAMA for satisficing search).",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "PDDL benchmark domains converted from NL descriptions",
            "text_environment_description": "Planner solves the deterministic PDDL problems produced by the LLM; not an interactive text-based game environment.",
            "performance_metric": "Success rate on produced PDDL problems; ability to find optimal plans within time limit.",
            "performance_value": "When supplied correct PDDL, FAST-DOWNWARD finds optimal plans in many domains within the 200s limit (used to report LLM+P success rates; exact per-domain details provided in paper Table I).",
            "baseline_comparison": "",
            "has_ablation_uncertainty": false,
            "ablation_results": "",
            "key_findings": "FAST-DOWNWARD reliably produces optimal plans when given correctly specified PDDL problem files; thus delegating planning to a classical planner is effective provided the LLM correctly encodes the problem.",
            "uuid": "e974.2",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "SayCan",
            "name_full": "SayCan (Grounding language in robotic affordances)",
            "brief_description": "A prior approach that grounds natural-language requests using learned affordance functions to inform robot action selection, combining language understanding with action feasibility scoring.",
            "citation_title": "Do as i can, not as i say: Grounding language in robotic affordances",
            "mention_or_use": "mention",
            "system_name": "SayCan",
            "system_description": "Cited in related work as an approach that enables robot planning from natural-language service requests by combining language model outputs with affordance functions that score the feasibility or utility of candidate actions; the approach grounds NL to actions and ranks them by affordance likelihoods to guide execution.",
            "world_model_type": "Affordance-based grounding (not specified as PDDL/PPDDL in citation within this paper)",
            "world_model_description": "Represents action feasibility via learned affordance functions (scores or probabilities over actions given context and language); does not appear in this paper as a PDDL-based probabilistic symbolic world model, but is cited as an LLM-augmented planner that accounts for action feasibility.",
            "uses_llm": true,
            "llm_role": "Language understanding and proposal of candidate actions given NL goals (combined with affordance scoring to select feasible actions)",
            "llm_model_name": null,
            "uncertainty_modeling": null,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Affordance-weighted action selection; not framed as classical PDDL planning within this paper's discussion",
            "planning_integrates_uncertainty": null,
            "text_environment_name": null,
            "text_environment_description": "Mentioned as a robot planning system that accepts NL requests; the paper cites it as related work but does not evaluate it or provide environment-level metrics.",
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Cited as an example of combining LLM/NL understanding with affordance functions to account for action feasibility; considered complementary to the LLM+P philosophy of combining language models with external modules, but not a PDDL/PPDDL probabilistic symbolic world model within this paper.",
            "uuid": "e974.3",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "Integrated TAMP in Belief Space",
            "name_full": "Integrated Task and Motion Planning in Belief Space",
            "brief_description": "A task-and-motion planning approach that reasons about uncertainty by planning in belief space (distributions over continuous states) combining discrete task planning and continuous motion planning under uncertainty.",
            "citation_title": "Integrated task and motion planning in belief space",
            "mention_or_use": "mention",
            "system_name": "Integrated Task and Motion Planning (belief-space TAMP)",
            "system_description": "Referenced in background as a form of TAMP that combines discrete symbolic planning with motion planning while representing state uncertainty as belief distributions; typically used for robotic domains where uncertainty in perception and motion is important.",
            "world_model_type": "Belief-space representation (probability distributions over continuous/pose states combined with discrete task-level representations)",
            "world_model_description": "Represents the robot's state as a belief (probability distribution), propagates uncertainty through actions and observations, and composes symbolic task-level decisions with continuous motion planning under uncertainty; inherently probabilistic and intended to handle aleatoric and perceptual uncertainty in robotic tasks.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "State uncertainty / perceptual and motion uncertainty (beliefs)",
            "uncertainty_method": "Belief-state representations (probability distributions) used in integrated planning; exact methods depend on cited work (e.g., belief propagation, POMDP-like reasoning) but paper only cites the approach in background.",
            "planning_algorithm": "Hierarchical TAMP combining discrete symbolic planning and continuous motion planning in belief space (methods vary by cited work).",
            "planning_integrates_uncertainty": true,
            "text_environment_name": null,
            "text_environment_description": "Referenced as robotic planning literature that explicitly reasons about uncertainty; not evaluated in this paper's NL-to-PDDL experiments.",
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Mentioned as an example of planning approaches that explicitly maintain belief states (probabilistic symbolic/continuous world models) â€” relevant to the query because it embodies probabilistic symbolic/continuous world modelling, but it is only cited in background and not integrated with LLM uncertainty in this work.",
            "uuid": "e974.4",
            "source_info": {
                "paper_title": "LLM+P: Empowering Large Language Models with Optimal Planning Proficiency",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Do as i can, not as i say: Grounding language in robotic affordances",
            "rating": 2
        },
        {
            "paper_title": "Integrated task and motion planning in belief space",
            "rating": 2
        },
        {
            "paper_title": "Robots that ask for help: Uncertainty alignment for large language model planners",
            "rating": 2
        },
        {
            "paper_title": "PDDL planning with pretrained large language models",
            "rating": 2
        },
        {
            "paper_title": "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning",
            "rating": 2
        },
        {
            "paper_title": "Generalized planning in pddl domains with pretrained large language models",
            "rating": 1
        }
    ],
    "cost": 0.015609,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>LLM+P: Empowering Large Language Models with Optimal Planning Proficiency</h1>
<p>Bo Liu ${ }^{<em> \dagger}$, Yuqian Jiang ${ }^{</em> \dagger}$, Xiaohan Zhang ${ }^{\ddagger}$, Qiang Liu ${ }^{\dagger}$, Shiqi Zhang ${ }^{\ddagger}$, Joydeep Biswas ${ }^{\dagger}$, Peter Stone ${ }^{\dagger \S}$</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon robot planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from robot planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems. We also show LLM+P enables a home robot to solve a complex manipulation task that is specified by the user in natural language. ${ }^{\dagger}$</p>
<h2>I. INTRODUCTION</h2>
<p>Ever since the birth of the field, AI researchers have sought to create programs that can converse in natural language with the same grace and flexibility as people. While even relatively simple models, such as Eliza from 1966 [1], can generate responses to some prompts that seem reasonable, it has always been relatively easy to generate prompts that expose their weaknesses compared to people - their lack of true "understanding."</p>
<p>While large language models (LLMs) such as GPT-4 [2] and ChatGPT [3] have far surpassed expectations of just a few years ago, they are no different in this respect. Indeed the internet is now awash with examples of people reveling in getting ChatGPT to generate output that even a 5-year-old human child would know to be ill-advised.</p>
<p>Given how LLMs are designed and trained, this phenomenon should come as no surprise. They are not specifically built to demonstrate understanding. They are trained</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>to generate sequences of words that might be plausible to a human given a prior context. In the terms of Mahowald et al. [4] LLMs have become amazingly proficient at linguistic competence - knowing how to say things; but they are not nearly as good at functional competence - knowing what to say. Specifically, they can be (relatively) easily fooled by, for example, asking for the result of a straightforward arithmetic problem that does not appear in their training corpus or by asking for the solution to a novel planning problem that requires knowledge about how the world works.</p>
<h2>A Failure Example of GPT-4 in Planning</h2>
<p>Problem (P1): You have 5 blocks. One cannot place more than one block on another block. b5 is on top of b3. b4 is on top of b2. b2 is on top of b1. b3 is on top of b4. b1 is on the table. b5 is clear. Your arm is empty.
Your goal is to move the blocks. b1 should be on top of b2. b3 should be on top of b5. b4 should be on top of b1.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>GPT-4:</p>
<ol>
<li>Move b5 from b3 to the table.</li>
<li>Move b3 from b4 to b5.</li>
<li>Move b4 from b2 to the table.</li>
<li>Move b2 from b1 to b5.</li>
<li>Move b1 from the table to b2.</li>
<li>Move b4 from the table to b1.</li>
</ol>
<p>Does that mean that we should increase efforts to include all arithmetic and planning problems in their training corpus? Clearly, that is a fool's errand. On the other hand, why should it be necessary? We already have calculators and generalpurpose symbolic planners that are guaranteed to produce correct answers. Thus a natural alternative approach, and one that we are admittedly not the first to explore, is to connect LLMs to such tools.</p>
<p>With this motivation in mind, the objective of the research reported in this paper is, for the first time, to enable LLMs to solve planning problems correctly. We aim to do so without altering the LLMs themselves, even with finetuning [5], [6]. Rather, we introduce a methodology, called LLM+P by which, when posed a natural language description of a planning problem, the LLM:</p>
<p>1) outputs a problem description suitable as input to a</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 1: LLM+P makes use of a large language model (LLM) to produce the PDDL description of the given problem, then leverages a classical planner for finding an <em>optimal</em> plan, then translates the raw plan back to natural language using the LLM again.</p>
<p>general-purpose planner;</p>
<p>2) solves the problem using the general-purpose planner; and</p>
<p>3) converts the output of the planner back to natural language (or connects to action executors of a robot).</p>
<p>Our extensive empirical evaluations indicate that LLM+P is able to generate correct solutions to many more planning problems than are LLMs on their own. While demonstrated in this paper on planning problems, this general methodology can be applied to any class of problems for which we have a sound and complete solver, such as arithmetic problems (by leveraging calculators).</p>
<p><strong>Limitation:</strong> In this paper, we do not ask the LLM to <em>recognize</em> that it has been posed a prompt that is suitable for processing using the proposed LLM+P pipeline. A valuable future research direction will be to consider recognizing when a prompt should be processed by LLM+P.</p>
<h2>II. BACKGROUND</h2>
<p>This section introduces the notation we use for representing a planning problem to be solved by LLMs, and recaps the standard representation of classical planners.</p>
<h3>A. The Classical Planning Problem</h3>
<p>Formally, the input of a planning problem <em>P</em> is defined by a tuple $\langle\mathscr{S}, s^{init},\mathscr{S}^{G},\mathscr{A}, f\rangle$:</p>
<ul>
<li>$\mathscr{S}$ is a finite and discrete set of states used to describe the world's state (i.e., state space). We assume a factored state space such that each state $s \in \mathscr{S}$ is defined by the values of a fixed set of variables.</li>
<li>$s^{init} \in \mathscr{S}$ is an initial world state.</li>
<li>$\mathscr{S}^{G} \subset \mathscr{S}$ is a set of goal states. $\mathscr{S}^{G}$ are usually specified as a list of <em>goal conditions</em>, all of which must hold in a goal state.</li>
<li>$\mathscr{A}$ is a set of symbolic actions.</li>
<li>$f$ is the underlying state transition function. $f$ takes the current state and an action as input and outputs the corresponding next state.</li>
</ul>
<p>A solution to a planning problem <em>P</em> is a symbolic plan $\pi$ in the form of $\langle a_1, a_2, \ldots, a_N \rangle$, such that the preconditions of $a_1$ hold in $s^{init}$, the preconditions of $a_2$ hold in the state that results from applying $a_1$, and so on, with the goal conditions all holding in the state that results after applying $a_N$.</p>
<h3>B. Planning Domain Definition Language (PDDL)</h3>
<p>The planning domain definition language (PDDL) serves as a standardized encoding of classical planning problems [7], [8]. The PDDL representation of a planning problem <em>P</em> is separated into two files: a domain file and a problem file. The domain PDDL file provides a lifted representation of the underlying rules of the world. It includes a set of predicates that define the state space $\mathscr{S}$ and the actions (i.e., $\mathscr{A}$) with their preconditions and effects (i.e., the transition function $f$). The problem PDDL file provides a list of objects to ground the domain, the problem's initial state $s^{init}$ and goal conditions $\mathscr{S}^{G}$. There exists a rich set of symbolic planners that implement efficient search algorithms to solve planning problems formalized in PDDL. In this work, we aim to take a natural language prompt which describes the initial state $s^{init}$ and goal conditions $\mathscr{S}^{G}$, formulate it in PDDL,</p>
<p>and leverage symbolic planners to output correct plans. We assume the domain rules are available (See the assumptions in Section III).</p>
<h2>III. Method</h2>
<p>This section first uses a running example to investigate ways for formulating planning prompts in PDDL and then introduces the LLM+P method.</p>
<h2>A. Large Language Model as a PDDL Writer</h2>
<p>LLMs are bad at planning (or long-horizon reasoning) [9] but they are good at describing and translating textual inputs, including re-writing planning prompts in the PDDL format. The intuition is that we can view PDDL as a different language than English, so re-writing planning prompts in PDDL is essentially a "machine translation" task that LLMs are known to excel at. Here we provide an example of a PDDL problem file written by GPT-4 without any promptengineering. As we see, the generated file appears to have the correct PDDL syntax but uses a made-up predicate (empty) and misses the initial condition that b1 is on the table.</p>
<h2>An Example PDDL Problem File Written by GPT-4</h2>
<p>Prompt: Description of Problem (P1) + Provide me with the problem PDDL file that describes the planning problem directly without further explanations.</p>
<h2>GPT-4 (the generated problem PDDL):</h2>
<p>(:objects b1 b2 b3 b4 b5 - block)
(:init (on b5 b3) (on b4 b2) (on b2
b1) (on b3 b4) (clear b5) (empty))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))</p>
<h2>B. In-Context Learning</h2>
<p>LLMs are known to be capable of in-context learning without finetuning their parameters. By in-context learning, we mean LLMs' ability to perform unseen downstream tasks by simply conditioning on a few input-label pairs (demonstrations) [10]. Here is a pair of problem descriptions in natural language and in PDDL provided to GPT-4 as context. When the context is included with the prompt from the example above, the resulting PDDL problem file is directly solvable by the planner.</p>
<h2>An Example PDDL Problem File Written by GPT-4 with Context</h2>
<h2>Context (shaded):</h2>
<p>An example planning problem is: You have 5 blocks. b2 is on top of b5. b5 is on top of b1. b1 is on top of b4. b3 is on top of b2. b4 is on the table. b3 is clear. Your arm is empty. Your goal is to move the blocks. b4 should be on top of b3. The problem PDDL is:
(:objects b1 b2 b3 b4 b5)
(:init (arm-empty) (on b1 b4) (on
b2 b5) (on b3 b2)
(on-table b4) (on b5 b1)
(clear b3))
(:goal (and (on b4 b3))))
Prompt: Description of Problem (P1) + Context + Provide me with the problem PDDL file that describes the planning problem directly without further explanations.</p>
<h2>GPT-4 (the generated problem PDDL):</h2>
<p>(:objects b1 b2 b3 b4 b5 )
(:init (arm-empty) (on-table b1)
(on b2 b1) (on b3 b4)
(on b4 b2) (on b5 b3) (clear
b5)))
(:goal (and (on b1 b2) (on b3 b5)
(on b4 b1)))</p>
<h2>Planner:</h2>
<p>(unstack b5 b3) (putdown b5)
(unstack b3 b4) (stack b3 b5)
(unstack b4 b2) (putdown b4)
(unstack b2 b1) (putdown b2)
(pickup b1) (stack b1 b2) (pickup
b4) (stack b4 b1)</p>
<h2>C. Large Language Model + Classical Planner (LLM+P)</h2>
<p>Having introduced the LLM's ability to encode problems in PDDL and in-context learning, we are ready to introduce the proposed LLM+P solution (the bottom of Fig. 1). In particular, we assume that for each problem domain, a human expert can provide a domain description (i.e. action preconditions and effects) that will be fixed for all problem instances that happen in that domain. While the problem of automatically generating the description is another valuable research question, in this proposed work, we assume that the description is available as a PDDL domain file. The LLM+P method is directly applicable as a natural language interface for giving tasks to robot systems. For instance, assume we want a robot to act as a bartender to make cocktails. It is reasonable to tell it what actions it can take, but leave itself to infer how to make new cocktails most efficiently given a set of ingredients to combine. Moreover, we assume the agent is provided with a minimal example that demonstrates what an example problem PDDL looks like for a simple</p>
<p>problem inside that domain. Next, the agent is provided with a new (potentially quite complicated) problem $(P)$. The LLM then uses the in-context learning to infer the problem PDDL file corresponding to $P$. Once the problem PDDL file is generated, we feed it into any classical planner, together with the provided domain PDDL file, to generate a PDDL plan [11]. In the end, the LLM translates the PDDL plan back into the natural language to finish up the LLM+P pipeline. To summarize, the assumptions we need for LLM+P are:</p>
<ol>
<li>A robot knows when to trigger LLM+P based on its conversation with a human user.</li>
<li>A domain PDDL is provided to define the actions that the robot is capable of. This specification is taskagnostic - the entities relevant to the task are specified in the LLM-generated problem PDDL.</li>
<li>A simple problem description in natural language and its corresponding problem PDDL file are also provided.</li>
</ol>
<h2>IV. Related Work</h2>
<p>This section first provides a brief overview of classical planning algorithms. Then it summarizes recent advances in using large language models for planning tasks. It concludes with a discussion of recent research on augmenting LLMs with external modules.</p>
<h2>A. Classical Planning</h2>
<p>Automated planning (or classical planning) techniques can be used for computing a sequence of actions that achieves a given goal [12], [13], [14]. Automated planning algorithms have been widely used in robot systems. Shakey is the first robot that was equipped with a planning component, which was constructed using STRIPS [15]. Some previous generalpurpose planning architectures were also demonstrated to be useful for robot planning, such as PRODIGY [16] and HTN [17]. Recent classical planning systems designed for robotics frequently use planning domain description language (PDDL) or answer set programming (ASP) as the underlying action language for the planners [18], [19], [20], [21]. For example, researchers have used classical planning algorithms for sequencing actions for a mobile robot working on delivery tasks [22], reasoning about safe and efficient urban driving behaviors for autonomous vehicles [23], and planning actions for a team of mobile robots [24]. Task and motion planning (TAMP) is a hierarchical planning framework that combines classical planning in discrete spaces and robot motion planning in continuous space [25], [26].</p>
<p>Most of the above-mentioned planning methods require domain-specific programming languages as the underlying representation of the problems and their solutions. LLM+P, on the other hand, takes advantage of LLMs and serves as a natural language interface for robots to solve complex planning tasks. The main feature that motivates us to use such classical planning systems is that most of these planners are sound and complete, meaning that they are guaranteed to be logically correct and will output a plan if one exists. Many are also able to find optimal (shortest) plans, at least if given sufficient time.</p>
<h2>B. Planning with Large Language Models</h2>
<p>Various large language models (LLMs) have been developed in recent years, such as Bert [27], CodeX [28], Opt [29], GPT-3 [10], ChatGPT [30], GPT-4 [2], Llama [31], Llama2 [32], and PaLM [33]. As LLMs are pretrained with a tremendous amount of offline text data, they can emerge with surprising zero-shot generalization ability, which can be leveraged for robot planning tasks [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45]. Several recent methods had successes in extracting task knowledge from LLMs to decompose commands or instructions for robots in natural language. For instance, the work of Huang et al. showed that LLMs can be used for task planning in household domains by iteratively augmenting prompts [38]. SayCan is another approach that enabled robot planning with affordance functions to account for action feasibility, where the service requests are specified in natural language [34]. Vemprala et al. recently studied how ChatGPT can be applied to generalized robotics domains [3].</p>
<p>However, a major drawback of existing LLMs is their lack of long-horizon reasoning ability for complex tasks (See [9], [46] and Section 8.2 from [2]). Specifically, the output they produce when presented with such a task is often incorrect in the sense that following the output plan will not actually solve the task. Therefore, in this work, we focus on resolving this issue by leveraging the properties of classical planners. Similarly, some recent work also investigates approaches for combining classical planning with LLMs [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57]. They either use prompting or fine-tuning to make LLMs capable of solving PDDL planning problems. Improvements to longhorizon planning capabilities have also been made by iteratively querying LLMs, as demonstrated in Minecraft [58]. In contrast, we do not solely rely on LLM as the problem solver, but are more into taking the advantage of both the planner (i.e., generating accurate and optimal plans) and the LLM itself (i.e., 1-shot generalization for translating naturallanguage problem descriptions into PDDL).</p>
<h2>C. Augmenting LLMs with External Modules</h2>
<p>Recently developed methods have shown that the performance of downstream tasks of LLMs can be improved by combining them with external modules. For instance, WebGPT [59] is a fine-tuned version of GPT-3 by combining web knowledge to answer open-ended questions. Lazaridou et al. studied how search engines like Google can be utilized as external tools for LLMs [60]. MemPrompt [61] presented a human-in-the-loop system where a growing memory of errors and user feedback is served as past experience adding to the prompts for more accurately answering new questions. REPLUG [62] is another retrieval-augmented language modeling paradigm that treats the language model as a black box and augments it with a tuneable retrieval model. Specifically, people have investigated using calculators for computation [63], [64]. In very recent work related to ours, Schick et al. trained a model called ToolFormer that can decide when and how to call certain tool APIs by in-line</p>
<p>augmentation on prompts for LLMs [65]. In this work, we propose that classical planners can be another particularly useful external module. In comparison, LLM+P, does not rely on any fine-tuning or re-training of LLMs. By simply incorporating knowledge from classical planners, LLM+P incorporates long-horizon reasoning and planning capabilities into existing LLMs.</p>
<p>The authors are informed that a concurrent work [66] presents preliminary results of integrating LLMs with PDDL using the SayCan dataset [34]. However, the SayCan dataset has a limited scope, as it contains only three predefined actions. Consequently, all model variants evaluated in the original paper achieved a success rate of approximately $90 \%$. Due to the homogeneity of the SayCan dataset, Lyu et al. did not necessitate a rigorous definition of the domain PDDL, which can lead to infeasible plans. As a result, we consider our LLM+P method as a more comprehensive investigation into enhancing LLMs with optimal planning proficiency.</p>
<h2>V. EXPERIMENTS</h2>
<p>We conduct experiments to answer these questions:</p>
<p>1) How well does LLM-AS-P work? To what extent can state-of-the-art LLMs and LLM-based reasoning methods be directly used for planning? (Not at all)
2) How well does LLM+P work compare to LLM-AS-P? (Much better)
3) What role does the context play in the success of LLM+P? (It's crucial)
4) Can LLM+P help make service robots more efficient on realistic tasks? (Yes)</p>
<h2>A. Benchmark Problems</h2>
<p>We present seven robot planning domains borrowed from past International Planning Competitions and 20 automatically generated tasks for each domain [67]. Below is a list of the planning domains, along with a brief summary of each.</p>
<p>1) BlockSWORLD: Given a set of piles of blocks on a table, a robot is tasked with rearranging them into a specified target configuration.
2) BARMAN: A robot bartender is tasked with creating cocktails for a customer's order, utilizing the available ingredients and containers.
3) Floortile: A set of robots are tasked to use paint color patterns on floor tiles. Robots can move around and change colors but cannot step on painted tiles.
4) GRIPPERS: A set of robots with two grippers is given a task to move objects among different rooms.
5) Storage: Given a set of hoists, the goal is to lift and drop crates using the hoists into a depot. Crates are initially stored in different areas and hoists can be moved among storage areas.
6) TERMES: A robot is tasked to build complex structures by carrying and placing blocks, and also climbing on them so that it can build towers.
7) TyReWorld: The robot is given a task to replace flat tires by, for example, inflating tires, tightening nuts,
and moving tools back to the boot when done, all in the proper order.
For each problem $P, P$ comes with a natural language description and a ground-truth problem PDDL file. Each domain also includes an example problem description, a corresponding PDDL file, and a plan description, used as context in various approaches. We assume each problem domain has its own domain PDDL file given by the user or a domain expert prior to addressing any planning problems in that domain. This dataset is made publicly available in our codebase for reproducibility.</p>
<h2>B. Experiment Setup</h2>
<p>We leverage the GPT-4 model provided by OpenAI ${ }^{2}$ for all experiments. We set the temperature to 0 , and use the top probability response. As a result, the response returned from the LLM is deterministic. Once a text PDDL response is generated, we feed it into the FAST-DOWNWARD planner ${ }^{3}$ and try both aliases SEQ-OPT-FDSS-1 (guaranteed optimal) and LAMA (not guaranteed optimal) with a maximum search time of 200 seconds. We report the success rate of the optimal alias, and for the domains that time out, we show the success rate of the sub-optimal alias in parentheses. For the baseline methods, we manually count the number of optimal plans, and report the number of correct plans in parentheses (if there are any sub-optimal plans).</p>
<p>We also evaluate a recent LLM-based approach for deliberate reasoning called Tree of Thoughts [68], referred to as LLM-AS-P (ToT). We adapt the breadth-first-search algorithm from the original ToT implementation ${ }^{4}$ for planning. The LLM is prompted to expand the search tree from allowed actions and evaluate the paths on their likelihood of reaching the goal. The same time limit of 200 seconds is applied.</p>
<h2>C. Results and Analysis</h2>
<p>The results of applying LLM-AS-P and LLM+P across 7 domains are provided in Table I.</p>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Success Rate \%</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>LLM $^{-}$</td>
<td>LLM</td>
<td>LLM $^{T o T}$</td>
<td>LLM+P $^{-}$</td>
<td>LLM+P</td>
</tr>
<tr>
<td>BARMAN</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>20 (100)</td>
</tr>
<tr>
<td>BlockSWORLD</td>
<td>20</td>
<td>15 (30)</td>
<td>0 (5)</td>
<td>0</td>
<td>90</td>
</tr>
<tr>
<td>Floortile</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>GRIPPERS</td>
<td>25 (60)</td>
<td>35 (50)</td>
<td>10 (20)</td>
<td>0</td>
<td>95 (100)</td>
</tr>
<tr>
<td>Storage</td>
<td>0</td>
<td>0 (25)</td>
<td>0</td>
<td>0</td>
<td>85</td>
</tr>
<tr>
<td>TERMES</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>20</td>
</tr>
<tr>
<td>TyReWorld</td>
<td>5</td>
<td>15</td>
<td>0</td>
<td>0</td>
<td>10 (90)</td>
</tr>
</tbody>
</table>
<p>TABLE I: Success rate \% of applying LLM-AS-P without context (LLM ${ }^{-}$), LLM-AS-P (LLM), Tree of Thoughts (LLM ${ }^{T o T}$ ), LLM+P without context (LLM ${ }^{-}$), and LLM+P.</p>
<p>Findings (LLM-AS-P):</p>
<p>1) We observe that though LLM-AS-P provides a plan in natural language for every problem, most of these</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup> <sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>: ${ }^{2}$ We use the most recent model as of September 2023. https:// platform.openai.com/docs/models/gpt-4 ${ }^{3}$ https://github.com/aibasel/downward/tree/ release-22.12.0 ${ }^{4}$ https://github.com/princeton-nlp/ tree-of-thought-1lm/</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 2: Demonstration of the optimal tidy-up plan. The robot starts at the coffee table and 1) picks up the bottle, 2) navigates to a room with the side table and the recycle bin, 3) puts down the bottle, 4) grasps the soup can, 5) puts the soup can in the recycle bin, 6) re-grasps the bottle, 7) navigates to the kitchen, 8) places the bottle in the pantry.</p>
<p>plans are not feasible. The main reason is that LLM-AS-P lacks the ability to reason about preconditions.</p>
<p>2) In most cases, LLM-AS-P fails in the same way with or without the example plan as context. In particular, in the BlockSwordD domain, LLM-AS-P cannot keep track of properties like ON and Clear. In the BARMAN domain, LLM-AS-P's plans fail to clean shot glasses before using them again.</p>
<p>3) The hardest domains are the ones with complex spatial relationship. The LLM-AS-P methods (with or without context) completely fail at this type of problems. In the FLOORTILE domain, LLM-AS-P generates "move right to tile.0-4 and paint tile.1-2 black" but the robot can only paint neighboring tiles. In TERMES and STORAGE, LLM-AS-P ignores the requirement that the robot cannot unload the block/crate at the same position it occupies.</p>
<p>4) LLM-AS-P (ToT) calls the LLM at each tree node to provide a list of available actions, and then calls the LLM to evaluate each new path on the tree as a partial plan. We find that the LLM is able to give reasonable rankings on the partial plans, but it often fails to recognize whether the plan reaches the goal. LLM-AS-P (ToT) times out in most cases due to the large number of LLM calls, so it is not suitable for solving long-horizon problems.</p>
<h3>Findings (LLM+P):</h3>
<p>1) The proposed LLM+P produces an optimal plan for the majority of problems. Most failed cases are due to mis-specified problem files, such as missing one of the initial conditions (e.g. leaving the tiles disconnected in FLOORTILE), causing the planning problem to be unsolvable.</p>
<p>2) Without the context (i.e., an example problem and its corresponding problem PDDL), we observe that LLMs fail to produce correct problem PDDL files. Therefore, the context is important for LLM+P to work.</p>
<h3><em>D. Robot Demonstration</em></h3>
<p>We verify that LLM+P can efficiently solve realistic service robot problems by deploying it on a real robot tasked with tidying up a home. The user asks the robot to move a mustard bottle from the coffee table to the pantry, and throws away the empty soup can from the side table. Since the side table and the recycle bin are on the way from the coffee table to the pantry, the optimal plan is to take the mustard bottle to the side table, and re-grasps it after throwing away the soup can, with a total cost of 22. Fig. 2 shows the optimal plan found by LLM+P. Parts of the prompt and the generated PDDL are shown below. LLM-AS-P outputs a sub-optimal plan which takes the bottle to the pantry first and travels back for the soup can, with a total cost of 31.</p>
<h3><strong>Tidy-Up Problem PDDL Generated by LLM+P</strong></h3>
<p><strong>Problem (P):</strong> You are a home robot with one gripper. The distance between coffee table and side table is 10. The distance between coffee table and pantry is 20... You are at the coffee table. There is a mustard bottle... Your goal is to move objects to their destinations...</p>
<h3><strong>Problem PDDL generated by LLM+P:</strong></h3>
<div class="codehilite"><pre><span></span><code>(:objects coffee-table side-table
recycle-bin pantry - location
mustard-bottle soup-can - object)
(:init (= (total-cost) 0) (= (distance coffee-table side-table)
10) (= (distance coffee-table
pantry) 20) ... (robot-at
coffee-table) (at mustard-bottle
coffee-table) (at soup-can
side-table) (hand-empty) )
(:goal (and (at mustard-bottle
pantry) (at soup-can recycle-bin)))
(:metric minimize (total-cost)) )
</code></pre></div>

<h3>VI. CONCLUSION AND FUTURE WORK</h3>
<p>In this work, we propose to leverage classical planners to empower large language models with optimal planning capabilities. The key design choice of the proposed LLM+P framework is to focus LLMs on translating the planning problem from natural language to structured PDDL format. Moreover, we show that it is important to also make LLMs aware of a simple (problem, PDDL) pair as a demonstration (or the context) for in-context learning. Some interesting directions to further extend the LLM+P framework include: 1) enabling the LLM to auto-detect when and how to apply LLM+P; and 2) reducing LLM+P's dependency on information by humans, potentially involving finetuning.</p>
<h2>REFERENCES</h2>
<p>[1] J. Weizenbaum, "Eliza-a computer program for the study of natural language communication between man and machine," Communications of the ACM, vol. 9, no. 1, pp. 36-45, 1966.
[2] OpenAI, "Opt-4 technical report," 2023.
[3] S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor, "Chatgpt for robotics: Design principles and model abilities," Microsoft, Tech. Rep. MSR-TR-2023-8, February 2023. [Online]. Available: https://www.microsoft.com/en-us/research/publication/ chatgpt-for-robotics-design-principles-and-model-abilities/
[4] K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B. Tenenbaum, and E. Fedorenko, "Dissociating language and thought in large language models: a cognitive perspective," arXiv preprint arXiv:2301.06627, 2023.
[5] C. Lee, K. Cho, and W. Kang, "Mixout: Effective regularization to finetune large-scale pretrained language models," arXiv preprint arXiv:1909.11299, 2019.
[6] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, "Finetuned language models are zero-shot learners," arXiv preprint arXiv:2109.01652, 2021.
[7] D. McDermott, M. Ghallab, A. Howe, C. Knoblock, A. Ram, M. Veloso, D. Weld, and D. Wilkins, "Pddl-the planning domain definition language," 1998.
[8] P. Haslum, N. Lipovetzky, D. Magazzeni, and C. Muise, "An introduction to the planning domain definition language," Synthesis Lectures on Artificial Intelligence and Machine Learning, vol. 13, no. 2, pp. $1-187,2019$.
[9] K. Valmeekam, A. Olmo, S. Sreedharan, and S. Kambhampati, "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)," arXiv preprint arXiv:2206.10498, 2022.
[10] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.
[11] M. Helmert, "The fast downward planning system," Journal of Artificial Intelligence Research, vol. 26, pp. 191-246, 2006.
[12] T. Bylander, "The computational complexity of propositional STRIPS planning," Artificial Intelligence, vol. 69, no. 1-2, pp. 165-204, 1994.
[13] J. McCarthy, "Situations, actions, and causal laws," Stanford University Technical Report, Tech. Rep., 1963.
[14] R. E. Fikes and N. J. Nilsson, "Strips: A new approach to the application of theorem proving to problem solving," Artificial intelligence, vol. 2, no. 3-4, pp. 189-208, 1971.
[15] N. J. Nilsson et al., "Shakey the robot," 1984.
[16] J. Carbonell, O. Etzioni, Y. Gil, R. Joseph, C. Knoblock, S. Minton, and M. Veloso, "Prodigy: An integrated architecture for planning and learning," ACM SIGART Bulletin, vol. 2, no. 4, pp. 51-55, 1991.
[17] D. S. Nau, T.-C. Au, O. Ilghami, U. Kuter, J. W. Murdock, D. Wu, and F. Taman, "Shop2: An htn planning system," Journal of artificial intelligence research, 2003.
[18] Y.-q. Jiang, S.-q. Zhang, P. Khandelwal, and P. Stone, "Task planning in robotics: an empirical comparison of pddl-and asp-based systems," Frontiers of Information Technology \&amp; Electronic Engineering, vol. 20, pp. 363-373, 2019.
[19] G. Brewka, T. Eiter, and M. TruszczyÅ„ski, "Answer set programming at a glance," Communications of the ACM, vol. 54, no. 12, pp. 92-103, 2011.
[20] V. Lifschitz, "Answer set programming and plan generation," Artificial Intelligence, vol. 138, no. 1-2, pp. 39-54, 2002.
[21] M. Fox and D. Long, "Pddl2. 1: An extension to pddl for expressing temporal planning domains," Journal of artificial intelligence research, vol. 20, pp. 61-124, 2003.
[22] S. Zhang, F. Yang, P. Khandelwal, and P. Stone, "Mobile robot planning using action language bc with an abstraction hierarchy," in International Conference on Logic Programming and Nonmonotonic Reasoning. Springer, 2015, pp. 502-516.
[23] Y. Ding, X. Zhang, X. Zhan, and S. Zhang, "Task-motion planning for safe and efficient urban driving," in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020.
[24] Y. Jiang, H. Yedidsion, S. Zhang, G. Sharon, and P. Stone, "Multi-robot planning with conflicts and synergies," Autonomous Robots, vol. 43, no. 8, pp. 2011-2032, 2019.
[25] F. Lagriffoul, N. T. Dantam, C. Garrett, A. Akbari, S. Srivastava, and L. E. Kavraki, "Platform-independent benchmarks for task and motion planning," IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 3765-3772, 2018.
[26] L. P. Kaelbling and T. Lozano-PÃ©rez, "Integrated task and motion planning in belief space," The International Journal of Robotics Research, vol. 32, no. 9-10, pp. 1194-1227, 2013.
[27] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.
[28] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al., "Evaluating large language models trained on code," arXiv preprint arXiv:2107.03374, 2021.
[29] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al., "Opt: Open pre-trained transformer language models," arXiv preprint arXiv:2205.01068, 2022.
[30] OpenAI, "Chatgpt," Accessed: 2023-02-08, 2023, cit. on pp. 1, 16. [Online]. Available: https://openai.com/blog/chatgpt/
[31] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. RoziÃ¨re, N. Goyal, E. Hambro, F. Azhar, et al., "Llama: Open and efficient foundation language models," arXiv preprint arXiv:2302.13971, 2023.
[32] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al., "Llama 2: Open foundation and fine-tuned chat models," arXiv preprint arXiv:2307.09288, 2023.
[33] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., "Palm: Scaling language modeling with pathways," arXiv preprint arXiv:2204.02311, 2022.
[34] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al., "Do as i can, not as i say: Grounding language in robotic affordances," arXiv preprint arXiv:2204.01691, 2022.
[35] Y. Ding, X. Zhang, C. Paxton, and S. Zhang, "Task and motion planning with large language models for object rearrangement," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023.
[36] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al., "Palm-e: An embodied multimodal language model," arXiv preprint arXiv:2303.03378, 2023.
[37] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, et al., "Inner monologue: Embodied reasoning through planning with language models," arXiv preprint arXiv:2207.05608, 2022.
[38] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents," in International Conference on Machine Learning. PMLR, 2022, pp. 9118-9147.
[39] Y. Kant, A. Ramachandran, S. Yenamandra, I. Gilitschenski, D. Batra, A. Szot, and H. Agrawal, "Housekeep: Tidying virtual households using commonsense reasoning," in Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part XXXIX. Springer, 2022, pp. 355-373.
[40] I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay, D. Fox, J. Thomason, and A. Garg, "Progprompt: Generating situated robot task plans using large language models," arXiv preprint arXiv:2209.11302, 2022.
[41] K. Lin, C. Agia, T. Migimatsu, M. Pavone, and J. Bohg, "Text2motion: From natural language instructions to feasible plans," arXiv preprint arXiv:2303.12353, 2023.
[42] Y. Yang, J.-R. Gaglione, C. Neary, and U. Topcu, "Automaton-based representations of task knowledge from generative language models," arXiv preprint arXiv:2212.01944, 2023.
[43] Y. Ding, X. Zhang, S. Amiri, N. Cao, H. Yang, A. Kaminski, C. Esselink, and S. Zhang, "Integrating action knowledge and llms for task planning and situation handling in open worlds," arXiv preprint arXiv:2305.17590, 2023.
[44] A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown, P. Xu, L. Takayama, F. Xia, J. Varley, et al., "Robots that ask for help: Uncertainty alignment for large language model planners," arXiv preprint arXiv:2307.01928, 2023.
[45] Y. Chen, J. Arkin, Y. Zhang, N. Roy, and C. Fan, "Autotamp:</p>
<p>Autoregressive task and motion planning with llms as translators and checkers," arXiv preprint arXiv:2306.06531, 2023.
[46] K. Valmeekam, S. Sreedharan, M. Marquez, A. Olmo, and S. Kambhampati, "On the planning abilities of large language models (a critical investigation with a proposed benchmark)," arXiv preprint arXiv:2302.06706, 2023.
[47] T. Silver, V. Hariprasad, R. S. Shuttleworth, N. Kumar, T. LozanoPÃ©rez, and L. P. Kaelbling, "PDDL planning with pretrained large language models," in NeurIPS 2022 Foundation Models for Decision Making Workshop, 2022. [Online]. Available: https: //openreview.net/forum?id=1QMMUB4zfl
[48] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, L. Horesh, B. Srivastava, F. Fabiano, and A. Loreggia, "Plansformer: Generating symbolic plans using transformers," arXiv preprint arXiv:2212.08681, 2022.
[49] D. Arora and S. Kambhampati, "Learning and leveraging verifiers to improve planning capabilities of pre-trained language models," arXiv preprint arXiv:2305.17077, 2023.
[50] L. Guan, K. Valmeekam, S. Sreedharan, and S. Kambhampati, "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning," arXiv preprint arXiv:2305.14909, 2023.
[51] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. P. Kaelbling, and M. Katz, "Generalized planning in pddl domains with pretrained large language models," arXiv preprint arXiv:2305.11014, 2023.
[52] V. Pallagani, B. Muppasani, K. Murugesan, F. Rossi, B. Srivastava, L. Horesh, F. Fabiano, and A. Loreggia, "Understanding the capabilities of large language models for automated planning," arXiv preprint arXiv:2305.16151, 2023.
[53] K. Valmeekam, M. Marquez, S. Sreedharan, and S. Kambhampati, "On the planning abilities of large language models-a critical investigation," arXiv preprint arXiv:2305.15771, 2023.
[54] Y. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh, "Translating natural language to planning goals with large-language models," arXiv preprint arXiv:2302.05128, 2023.
[55] R. Hazra, P. Z. D. Martires, and L. De Raedt, "Saycanpay: Heuristic planning with large language models using learnable domain knowledge," arXiv preprint arXiv:2308.12682, 2023.
[56] K. Rana, J. Haviland, S. Garg, J. Abou-Chakra, I. Reid, and N. Suenderhauf, "Sayplan: Grounding large language models using 3d scene graphs for scalable task planning," arXiv preprint arXiv:2307.06135, 2023.
[57] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, "Isr-llm: Iterative self-refined large language model for long-horizon sequential task planning," arXiv preprint arXiv:2308.13724, 2023.
[58] Z. Wang, S. Cai, A. Liu, X. Ma, and Y. Liang, "Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents," arXiv preprint arXiv:2302.01560, 2023.
[59] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders, et al., "Webgpt: Browserassisted question-answering with human feedback," arXiv preprint arXiv:2112.09332, 2021.
[60] A. Lazaridou, E. Gribovskaya, W. Stokowiec, and N. Grigorev, "Internet-augmented language models through few-shot prompting for open-domain question answering," arXiv preprint arXiv:2203.05115, 2022.
[61] A. Madaan, N. Tandon, P. Clark, and Y. Yang, "Memory-assisted prompt editing to improve gpt-3 after deployment," 2023.
[62] W. Shi, S. Min, M. Yasunaga, M. Seo, R. James, M. Lewis, L. Zettlemoyer, and W.-t. Yih, "Replug: Retrieval-augmented black-box language models," arXiv preprint arXiv:2301.12652, 2023.
[63] W. Chen, X. Ma, X. Wang, and W. W. Cohen, "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks," arXiv preprint arXiv:2211.12588, 2022.
[64] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig, "Pal: Program-aided language models," arXiv preprint arXiv:2211.10435, 2022.
[65] T. Schick, J. Dwivedi-Yu, R. DessÃ¬, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom, "Toolformer: Language models can teach themselves to use tools," arXiv preprint arXiv:2302.04761, 2023.
[66] Q. Lyu, S. Havaldar, A. Stein, L. Zhang, D. Rao, E. Wong, M. Apidianaki, and C. Callison-Burch, "Faithful chain-of-thought reasoning," arXiv preprint arXiv:2301.13379, 2023.
[67] J. Seipp, Ã. Torralba, and J. Hoffmann, "PDDL generators," https: //doi.org/10.5281/zenodo.6382173, 2022.
[68] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan, "Tree of thoughts: Deliberate problem solving with large language models," arXiv preprint arXiv:2305.10601, 2023.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Equal contribution.
${ }^{\dagger}$ Department of Computer Science, The University of Texas at Austin {bliu, lqiang, joydeep, pstone}@cs.utexas.edu, jiangyuqian@utexas.edu
${ }^{\ddagger}$ Department of Computer Science, State University of New York at Binghamton {xzhan244, zhangs}@binghamton.edu
${ }^{\S}$ Sony AI
${ }^{\dagger}$ The code and results are publicly available at https://github. com/Cranial-XIX/llm-pddl.git.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>