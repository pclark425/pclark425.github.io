<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-697 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-697</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-697</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-255300316</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.10041v1.pdf" target="_blank">Risk Assessment of Lymph Node Metastases in Endometrial Cancer Patients: A Causal Approach</a></p>
                <p><strong>Paper Abstract:</strong> Assessing the pre-operative risk of lymph node metastases in endometrial cancer patients is a complex and challenging task. In principle, machine learning and deep learning models are flexible and expressive enough to capture the dynamics of clinical risk assessment. However, in this setting we are limited to observational data with quality issues, missing values, small sample size and high dimensionality: we cannot reliably learn such models from limited observational data with these sources of bias. Instead, we choose to learn a causal Bayesian network to mitigate the issues above and to leverage the prior knowledge on endometrial cancer available from clinicians and physicians. We introduce a causal discovery algorithm for causal Bayesian networks based on bootstrap resampling, as opposed to the single imputation used in related works. Moreover, we include a context variable to evaluate whether selection bias results in learning spurious associations. Finally, we discuss the strengths and limitations of our findings in light of the presence of missing data that may be missing-not-at-random, which is common in real-world clinical settings.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e697.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e697.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bootstrap+StructuralEM (custom)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bootstrap-based Causal Discovery with Structural EM (custom variant introduced in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A custom causal discovery pipeline that combines bootstrap resampling with Structural EM to learn causal Bayesian network structure from incomplete observational clinical data, estimating edge strength by relative frequency across bootstraps and constructing an average graph via thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bootstrap-based Causal Discovery with Structural EM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Repeatedly resample the training data with replacement (n bootstraps, m samples each), run Structural EM on each bootstrap sample to learn a DAG, accumulate counts of included directed edges into a confidence matrix C, normalize by n to get edge strengths, and build an "average graph" by inserting edges whose strength exceeds a threshold λ; finally fit parameters (EM) on the selected structure. This yields edge-strength estimates for model averaging and for filtering spurious/weak edges.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multicenter observational clinical cohort (endometrial cancer dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A retrospective, multicenter observational clinical dataset (763 patients across 10 hospitals) with heterogeneous, missing, and potentially MNAR data; non-interactive, passive observational environment with no active interventions or experimental control.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Bootstrap model averaging to estimate edge strengths and thresholding to filter low-frequency edges; inclusion of context variables (e.g., Hospital) to reveal selection-bias-related spurious links.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Selection bias / sampling heterogeneity across sites, missing-not-at-random (MNAR) induced spurious associations, irrelevant/weak edges due to finite-sample noise and imputation bias.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detect spurious signals by low relative frequency (low strength) of an edge across bootstrap-resampled causal graphs and by edges originating from context variables (Hospital) that indicate selection bias or MNAR mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit downweighting via averaging: edges that appear infrequently across bootstraps obtain low strength and can be filtered out by threshold λ; no explicit reweighting of samples reported.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No experimental/interventional refutation performed; spurious edges are flagged (e.g., Hospital→p53) by their bootstrap strength and by semantic interpretation of context-variable edges rather than by active refutation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>CBN fitted on the recovered graph that included Hospital (i.e., using the bootstrap+context approach) achieved an out-of-sample AUC of 0.883 (95% CI 0.775-0.991) for predicting lymph node metastases on the test set; structure-level robustness reported qualitatively via edge-strength clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Prior ENDORISK model reported AUCs between 0.82 and 0.85 in referenced work [26]; the paper notes their procedure produces higher AUC but no direct head-to-head controlled comparison or ablation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Bootstrap resampling combined with Structural EM provides edge-strength estimates that enable model-averaging and filtering of low-confidence edges, helps surface clusters of structural solutions, and—when combined with a context variable (Hospital)—highlights likely spurious associations (e.g., Hospital→p53) that may stem from MNAR or selection bias; this approach produced a higher AUC for LNM prediction compared to prior reported models, but no formal ablation or interventional refutation was performed.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e697.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e697.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structural EM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Structural Expectation-Maximization (Structural EM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative algorithm that alternates between imputing missing data (E-step / EM) and learning the network structure (M-step / structure search) to perform causal or graphical model discovery with incomplete data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Bayesian Structural EM</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Structural EM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Iteratively performs expectation-maximization to impute missing values given a current model, and then runs a score-based structure learning step (e.g., greedy search) to update the DAG; repeats until convergence, thereby jointly estimating structure and parameters under missingness.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multicenter observational clinical cohort (endometrial cancer dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational clinical data with missing values (potentially MNAR), non-interactive and non-experimental.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Can be affected by imputation-induced spurious correlations (paper notes imputation can induce bias); used primarily to address missing data, not distractors per se.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Structural EM is used as the base causal-discovery-with-missing-data routine, but the authors note that a single imputation approach can induce spurious correlations; they mitigate this by embedding Structural EM inside a bootstrap resampling pipeline rather than relying on a single imputation run.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e697.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e697.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Greedy Search / Hill-Climbing (GS/HC)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy Score-based Search (Hill-Climbing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A score-based causal discovery method that explores DAG space by greedy local moves (add/delete/reverse edges) and accepts moves improving a scoring criterion until a local optimum is reached.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Greedy Search (Hill-Climbing)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Traverse the space of DAGs by iteratively proposing local edits (edge addition, deletion, reversal); evaluate each move with a score function S (e.g., BIC, marginal likelihood) and accept moves that improve S, stopping at a local optimum. Can incorporate structural constraints (required/forbidden edges or partial orderings) to shrink the search space.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multicenter observational clinical cohort (endometrial cancer dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational clinical dataset with missing values; structure elicited under prior knowledge constraints and then used to estimate LNM probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Can reduce spurious edges indirectly by encoding prior knowledge as required/forbidden edges (constraint on search space); otherwise does not explicitly handle distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Finite-sample noise leading to incorrect edges; spurious associations due to missing-data imputation if combined naïvely with EM.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detection is implicit via scoring: spurious edges are less likely to improve the global score; no specific detection mechanism for distractors described.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Greedy score-based search is the backbone for structure optimization and benefits from encoding prior knowledge (required/forbidden edges / partial orderings) to avoid implausible edges; however, it remains susceptible to imputation-induced spurious correlations unless combined with robustness measures (e.g., bootstrap).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e697.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e697.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Context variable (Hospital)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Inclusion of Hospital as a Context Variable to Reveal Selection Bias</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Treating hospital-of-treatment as a context/proxy variable to detect selection bias, latent heterogeneity, and MNAR mechanisms by observing edges from Hospital to clinical/biomarker variables.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Context-variable inclusion for selection-bias detection</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Introduce a categorical context variable (Hospital, 10 levels) into the causal discovery process; interpret edges from this variable to other nodes not as true causal effects but as indicators/proxies of unobserved confounding, selection bias, or systematic differences in measurement/recording across sites.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multicenter observational clinical cohort (endometrial cancer dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Non-interventional multicenter cohort where Hospital encodes population and practice heterogeneity; the environment is observational and not designed for active experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Variable inclusion as an explicit context variable / proxy for latent confounders; use semantic interpretation (domain knowledge) to flag edges as spurious (e.g., Hospital→p53 likely MNAR or selection bias).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Selection bias, sampling heterogeneity across hospitals, measurement/recording differences, MNAR missingness patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detection by presence and orientation of edges from Hospital to other variables in the recovered graph and by discrepant independence statements after Hospital inclusion; such edges are interpreted as flags for latent biases.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No explicit refutation via experiments; the paper suggests careful interpretation and further analyses needed (e.g., assessing impact of selection bias mediated by Hospital).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Including Hospital in the model changed independence statements and revealed edges suggestive of bias; the model that included Hospital produced the reported AUC of 0.883 when used for prediction (see bootstrap+StructuralEM result).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Adding a context variable (Hospital) surfaced likely spurious associations (e.g., Hospital→p53, Hospital→PostoperativeGrade) that are plausibly due to MNAR or selection bias; the authors recommend treating Hospital edges as proxies for latent variables and performing further targeted analysis to assess impact.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e697.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e697.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Test-wise deletion (constraint-based mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Test-wise Deletion for Constraint-based Causal Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A strategy for handling missing data in constraint-based causal discovery where conditional independence tests are performed using available cases for each test (test-wise deletion), reducing bias from listwise deletion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Test-wise deletion</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each conditional independence test, use only the samples that have observed values for the variables involved in that test (i.e., delete samples with missingness only for those variables), enabling constraint-based algorithms to operate under incomplete data with better statistical efficiency than global listwise deletion.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Not applied—mentioned as general approach</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Mentioned as an approach used by constraint-based causal discovery algorithms to mitigate missingness impact; no specific experimental application in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Non-random missingness can bias CI tests; test-wise deletion is designed to reduce the loss of data when missingness is present but does not in itself correct MNAR.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as a method used by constraint-based algorithms to handle missing data efficiently; the paper cites literature noting test-wise deletion can enable faster causal inference under non-random missingness but does not evaluate it empirically here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e697.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e697.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prior-knowledge constraints</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Encoding Prior Knowledge as Required/Forbidden Edges and Partial Orderings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use clinician-elicited or literature-derived causal constraints to restrict the DAG search space by specifying required edges, forbidden edges, and partial temporal/causal orderings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Prior-knowledge encoding (required/forbidden lists)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Programmatically enforce domain knowledge during structure learning by specifying edges that must appear, edges that are forbidden, and partial orderings among variables; reduces spurious solutions by constraining the admissible graph space for the score-based search.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Multicenter observational clinical cohort (endometrial cancer dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to clinical variables and biomarkers, including constraints derived from randomized controlled trials and clinician elicitation (e.g., therapy node has no incoming edges for RCTs).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Structural constraints to prevent implausible edges and reduce risk of learning spurious associations that contradict domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious edges due to finite-sample noise or implausible orientations that contradict established biological/temporal knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Prevention rather than detection: disallow edges that would represent implausible causal directions; conflicts between learned edges and prior constraints reveal potential spuriousness.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Encoding domain knowledge helped shape the recovered graph (e.g., therapy node structure) and reduces the plausibility of spurious edges; however, some recovered structures still differed from the purely expert-derived reference, highlighting limits of constraints when data indicate alternative dependencies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Data Analysis with Bayesian Networks: A Bootstrap Approach <em>(Rating: 2)</em></li>
                <li>The Bayesian Structural EM <em>(Rating: 2)</em></li>
                <li>Fast causal inference with non-random missingness by test-wise deletion <em>(Rating: 2)</em></li>
                <li>A Survey on Causal Discovery: Theory and Practice <em>(Rating: 2)</em></li>
                <li>Bayesian network models for incomplete and dynamic data <em>(Rating: 1)</em></li>
                <li>Structural causal bandits: Where to intervene? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-697",
    "paper_id": "paper-255300316",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "Bootstrap+StructuralEM (custom)",
            "name_full": "Bootstrap-based Causal Discovery with Structural EM (custom variant introduced in this paper)",
            "brief_description": "A custom causal discovery pipeline that combines bootstrap resampling with Structural EM to learn causal Bayesian network structure from incomplete observational clinical data, estimating edge strength by relative frequency across bootstraps and constructing an average graph via thresholding.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Bootstrap-based Causal Discovery with Structural EM",
            "method_description": "Repeatedly resample the training data with replacement (n bootstraps, m samples each), run Structural EM on each bootstrap sample to learn a DAG, accumulate counts of included directed edges into a confidence matrix C, normalize by n to get edge strengths, and build an \"average graph\" by inserting edges whose strength exceeds a threshold λ; finally fit parameters (EM) on the selected structure. This yields edge-strength estimates for model averaging and for filtering spurious/weak edges.",
            "environment_name": "Multicenter observational clinical cohort (endometrial cancer dataset)",
            "environment_description": "A retrospective, multicenter observational clinical dataset (763 patients across 10 hospitals) with heterogeneous, missing, and potentially MNAR data; non-interactive, passive observational environment with no active interventions or experimental control.",
            "handles_distractors": true,
            "distractor_handling_technique": "Bootstrap model averaging to estimate edge strengths and thresholding to filter low-frequency edges; inclusion of context variables (e.g., Hospital) to reveal selection-bias-related spurious links.",
            "spurious_signal_types": "Selection bias / sampling heterogeneity across sites, missing-not-at-random (MNAR) induced spurious associations, irrelevant/weak edges due to finite-sample noise and imputation bias.",
            "detection_method": "Detect spurious signals by low relative frequency (low strength) of an edge across bootstrap-resampled causal graphs and by edges originating from context variables (Hospital) that indicate selection bias or MNAR mechanisms.",
            "downweighting_method": "Implicit downweighting via averaging: edges that appear infrequently across bootstraps obtain low strength and can be filtered out by threshold λ; no explicit reweighting of samples reported.",
            "refutation_method": "No experimental/interventional refutation performed; spurious edges are flagged (e.g., Hospital→p53) by their bootstrap strength and by semantic interpretation of context-variable edges rather than by active refutation.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "CBN fitted on the recovered graph that included Hospital (i.e., using the bootstrap+context approach) achieved an out-of-sample AUC of 0.883 (95% CI 0.775-0.991) for predicting lymph node metastases on the test set; structure-level robustness reported qualitatively via edge-strength clusters.",
            "performance_without_robustness": "Prior ENDORISK model reported AUCs between 0.82 and 0.85 in referenced work [26]; the paper notes their procedure produces higher AUC but no direct head-to-head controlled comparison or ablation.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Bootstrap resampling combined with Structural EM provides edge-strength estimates that enable model-averaging and filtering of low-confidence edges, helps surface clusters of structural solutions, and—when combined with a context variable (Hospital)—highlights likely spurious associations (e.g., Hospital→p53) that may stem from MNAR or selection bias; this approach produced a higher AUC for LNM prediction compared to prior reported models, but no formal ablation or interventional refutation was performed.",
            "uuid": "e697.0"
        },
        {
            "name_short": "Structural EM",
            "name_full": "Bayesian Structural Expectation-Maximization (Structural EM)",
            "brief_description": "An iterative algorithm that alternates between imputing missing data (E-step / EM) and learning the network structure (M-step / structure search) to perform causal or graphical model discovery with incomplete data.",
            "citation_title": "The Bayesian Structural EM",
            "mention_or_use": "use",
            "method_name": "Structural EM",
            "method_description": "Iteratively performs expectation-maximization to impute missing values given a current model, and then runs a score-based structure learning step (e.g., greedy search) to update the DAG; repeats until convergence, thereby jointly estimating structure and parameters under missingness.",
            "environment_name": "Multicenter observational clinical cohort (endometrial cancer dataset)",
            "environment_description": "Observational clinical data with missing values (potentially MNAR), non-interactive and non-experimental.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Can be affected by imputation-induced spurious correlations (paper notes imputation can induce bias); used primarily to address missing data, not distractors per se.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Structural EM is used as the base causal-discovery-with-missing-data routine, but the authors note that a single imputation approach can induce spurious correlations; they mitigate this by embedding Structural EM inside a bootstrap resampling pipeline rather than relying on a single imputation run.",
            "uuid": "e697.1"
        },
        {
            "name_short": "Greedy Search / Hill-Climbing (GS/HC)",
            "name_full": "Greedy Score-based Search (Hill-Climbing)",
            "brief_description": "A score-based causal discovery method that explores DAG space by greedy local moves (add/delete/reverse edges) and accepts moves improving a scoring criterion until a local optimum is reached.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Greedy Search (Hill-Climbing)",
            "method_description": "Traverse the space of DAGs by iteratively proposing local edits (edge addition, deletion, reversal); evaluate each move with a score function S (e.g., BIC, marginal likelihood) and accept moves that improve S, stopping at a local optimum. Can incorporate structural constraints (required/forbidden edges or partial orderings) to shrink the search space.",
            "environment_name": "Multicenter observational clinical cohort (endometrial cancer dataset)",
            "environment_description": "Observational clinical dataset with missing values; structure elicited under prior knowledge constraints and then used to estimate LNM probabilities.",
            "handles_distractors": false,
            "distractor_handling_technique": "Can reduce spurious edges indirectly by encoding prior knowledge as required/forbidden edges (constraint on search space); otherwise does not explicitly handle distractors.",
            "spurious_signal_types": "Finite-sample noise leading to incorrect edges; spurious associations due to missing-data imputation if combined naïvely with EM.",
            "detection_method": "Detection is implicit via scoring: spurious edges are less likely to improve the global score; no specific detection mechanism for distractors described.",
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Greedy score-based search is the backbone for structure optimization and benefits from encoding prior knowledge (required/forbidden edges / partial orderings) to avoid implausible edges; however, it remains susceptible to imputation-induced spurious correlations unless combined with robustness measures (e.g., bootstrap).",
            "uuid": "e697.2"
        },
        {
            "name_short": "Context variable (Hospital)",
            "name_full": "Inclusion of Hospital as a Context Variable to Reveal Selection Bias",
            "brief_description": "Treating hospital-of-treatment as a context/proxy variable to detect selection bias, latent heterogeneity, and MNAR mechanisms by observing edges from Hospital to clinical/biomarker variables.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Context-variable inclusion for selection-bias detection",
            "method_description": "Introduce a categorical context variable (Hospital, 10 levels) into the causal discovery process; interpret edges from this variable to other nodes not as true causal effects but as indicators/proxies of unobserved confounding, selection bias, or systematic differences in measurement/recording across sites.",
            "environment_name": "Multicenter observational clinical cohort (endometrial cancer dataset)",
            "environment_description": "Non-interventional multicenter cohort where Hospital encodes population and practice heterogeneity; the environment is observational and not designed for active experimentation.",
            "handles_distractors": true,
            "distractor_handling_technique": "Variable inclusion as an explicit context variable / proxy for latent confounders; use semantic interpretation (domain knowledge) to flag edges as spurious (e.g., Hospital→p53 likely MNAR or selection bias).",
            "spurious_signal_types": "Selection bias, sampling heterogeneity across hospitals, measurement/recording differences, MNAR missingness patterns.",
            "detection_method": "Detection by presence and orientation of edges from Hospital to other variables in the recovered graph and by discrepant independence statements after Hospital inclusion; such edges are interpreted as flags for latent biases.",
            "downweighting_method": null,
            "refutation_method": "No explicit refutation via experiments; the paper suggests careful interpretation and further analyses needed (e.g., assessing impact of selection bias mediated by Hospital).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Including Hospital in the model changed independence statements and revealed edges suggestive of bias; the model that included Hospital produced the reported AUC of 0.883 when used for prediction (see bootstrap+StructuralEM result).",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Adding a context variable (Hospital) surfaced likely spurious associations (e.g., Hospital→p53, Hospital→PostoperativeGrade) that are plausibly due to MNAR or selection bias; the authors recommend treating Hospital edges as proxies for latent variables and performing further targeted analysis to assess impact.",
            "uuid": "e697.3"
        },
        {
            "name_short": "Test-wise deletion (constraint-based mention)",
            "name_full": "Test-wise Deletion for Constraint-based Causal Discovery",
            "brief_description": "A strategy for handling missing data in constraint-based causal discovery where conditional independence tests are performed using available cases for each test (test-wise deletion), reducing bias from listwise deletion.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Test-wise deletion",
            "method_description": "For each conditional independence test, use only the samples that have observed values for the variables involved in that test (i.e., delete samples with missingness only for those variables), enabling constraint-based algorithms to operate under incomplete data with better statistical efficiency than global listwise deletion.",
            "environment_name": "Not applied—mentioned as general approach",
            "environment_description": "Mentioned as an approach used by constraint-based causal discovery algorithms to mitigate missingness impact; no specific experimental application in this paper.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Non-random missingness can bias CI tests; test-wise deletion is designed to reduce the loss of data when missingness is present but does not in itself correct MNAR.",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as a method used by constraint-based algorithms to handle missing data efficiently; the paper cites literature noting test-wise deletion can enable faster causal inference under non-random missingness but does not evaluate it empirically here.",
            "uuid": "e697.4"
        },
        {
            "name_short": "Prior-knowledge constraints",
            "name_full": "Encoding Prior Knowledge as Required/Forbidden Edges and Partial Orderings",
            "brief_description": "Use clinician-elicited or literature-derived causal constraints to restrict the DAG search space by specifying required edges, forbidden edges, and partial temporal/causal orderings.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Prior-knowledge encoding (required/forbidden lists)",
            "method_description": "Programmatically enforce domain knowledge during structure learning by specifying edges that must appear, edges that are forbidden, and partial orderings among variables; reduces spurious solutions by constraining the admissible graph space for the score-based search.",
            "environment_name": "Multicenter observational clinical cohort (endometrial cancer dataset)",
            "environment_description": "Applied to clinical variables and biomarkers, including constraints derived from randomized controlled trials and clinician elicitation (e.g., therapy node has no incoming edges for RCTs).",
            "handles_distractors": true,
            "distractor_handling_technique": "Structural constraints to prevent implausible edges and reduce risk of learning spurious associations that contradict domain knowledge.",
            "spurious_signal_types": "Spurious edges due to finite-sample noise or implausible orientations that contradict established biological/temporal knowledge.",
            "detection_method": "Prevention rather than detection: disallow edges that would represent implausible causal directions; conflicts between learned edges and prior constraints reveal potential spuriousness.",
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Encoding domain knowledge helped shape the recovered graph (e.g., therapy node structure) and reduces the plausibility of spurious edges; however, some recovered structures still differed from the purely expert-derived reference, highlighting limits of constraints when data indicate alternative dependencies.",
            "uuid": "e697.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Data Analysis with Bayesian Networks: A Bootstrap Approach",
            "rating": 2,
            "sanitized_title": "data_analysis_with_bayesian_networks_a_bootstrap_approach"
        },
        {
            "paper_title": "The Bayesian Structural EM",
            "rating": 2,
            "sanitized_title": "the_bayesian_structural_em"
        },
        {
            "paper_title": "Fast causal inference with non-random missingness by test-wise deletion",
            "rating": 2,
            "sanitized_title": "fast_causal_inference_with_nonrandom_missingness_by_testwise_deletion"
        },
        {
            "paper_title": "A Survey on Causal Discovery: Theory and Practice",
            "rating": 2,
            "sanitized_title": "a_survey_on_causal_discovery_theory_and_practice"
        },
        {
            "paper_title": "Bayesian network models for incomplete and dynamic data",
            "rating": 1,
            "sanitized_title": "bayesian_network_models_for_incomplete_and_dynamic_data"
        },
        {
            "paper_title": "Structural causal bandits: Where to intervene?",
            "rating": 1,
            "sanitized_title": "structural_causal_bandits_where_to_intervene"
        }
    ],
    "cost": 0.013389499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Risk Assessment of Lymph Node Metastases in Endometrial Cancer Patients: A Causal Approach
May 18, 2023</p>
<p>Alessio Zanga 
Department of Informatics, Systems and Communication (DISCo)
University of Milano -Bicocca
MilanItaly</p>
<p>Data Science and Advanced Analytics
F. Hoffmann -La Roche Ltd
BaselSwitzerland</p>
<p>Alice Bernasconi 
Department of Informatics, Systems and Communication (DISCo)
University of Milano -Bicocca
MilanItaly</p>
<p>Department of Research
Evaluative Epidemiology Unit
Fondazione IRCCS Istituto Nazionale dei Tumori
MilanItaly</p>
<p>Peter J F Lucas 
University of Twente
EnschedeThe Netherlands</p>
<p>Hanny Pijnenborg 
RadboudUMC
NijmegenThe Netherlands</p>
<p>Casper Reijnen 
RadboudUMC
NijmegenThe Netherlands</p>
<p>Marco Scutari 
Istituto Dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA)
LuganoSwitzerland</p>
<p>Fabio Stella 
Department of Informatics, Systems and Communication (DISCo)
University of Milano -Bicocca
MilanItaly</p>
<p>Risk Assessment of Lymph Node Metastases in Endometrial Cancer Patients: A Causal Approach
May 18, 2023
Assessing the pre-operative risk of lymph node metastases in endometrial cancer patients is a complex and challenging task. In principle, machine learning and deep learning models are flexible and expressive enough to capture the dynamics of clinical risk assessment. However, in this setting we are limited to observational data with quality issues, missing values, small sample size and high dimensionality: we cannot reliably learn such models from limited observational data with these sources of bias. Instead, we choose to learn a causal Bayesian network to mitigate the issues above and to leverage the prior knowledge on endometrial cancer available from clinicians and physicians. We introduce a causal discovery algorithm for causal Bayesian networks based on bootstrap resampling, as opposed to the single imputation used in related works. Moreover, we include a context variable to evaluate whether selection bias results in learning spurious associations. Finally, we discuss the strengths and limitations of our findings in light of the presence of missing data that may be missing-not-at-random, which is common in real-world clinical settings.</p>
<p>Introduction</p>
<p>Artificial Intelligence in Medicine</p>
<p>State of the Art. Artificial Intelligence (AI) has found many applications in medicine [15] and, more specifically, in cancer research [32] in the form of predictive models for diagnosis [14], prognosis [6] and therapy planning [12]. As a subfield of AI, Machine Learning (ML) and in particular Deep Learning (DL) has achieved significant results, especially in image processing [3]. Nonetheless, ML and DL models have limited explainability [13] because of their black-box design, which limits their adoption in the clinical field: clinicians and physicians are reluctant to include models that are not transparent in their decision process [24]. While recent research on Explainable AI (XAI) [11] has attacked this problem, DL models are still opaque and difficult to interpret. In contrast, in Probabilistic Graphical Models (PGMs) the interactions between different variables are encoded explicitly: the joint probability distribution P of the variables of interest factorizes according to a graph G, hence the "graphical" connotation. Bayesian Networks (BNs) [23], which we will describe in Section 3.1, are an instance of PGMs that can be used as causal models. In turn, this makes them ideal to use as decision support systems and overcome the limitations of the predictions based on probabilistic associations produced by other ML models [1,19].</p>
<p>Lymph Node Metastases in Endometrial Cancer Patients</p>
<p>Background. The present paper focuses on the development of a BN predictive model for endometrial cancer (EC). Endometrial cancer is cancer of the mucous lining, or endometrium, of the uterus. It is a common gynecological disease affecting hundreds of thousands of women worldwide. Although most patients with EC are diagnosed at an early stage of the disease and have a favorable prognosis, approximately 90,000 patients around the world die every year because of EC [4]. Surgery to remove the uterus (hysterectomy), possibly together with the ovaries (ovariectomy), is the typical initial treatment for EC; the choice of neo-adjuvant (pre-surgery) or adjuvant (post-surgery) treatments depends on patient outcome prognosis. The presence of pelvic and/or para-aortic lymph node metastases (LNM) is one of the most important prognostic factors for poor outcome. The identification of LNM during the primary treatment makes it possible to choose a suitable adjuvant treatment and improve survival in node-positive EC [5,20]. However, no consensus exists on how to determine which patients will benefit from lymphadenectomy (or lymph node dissection): this procedure is usually performed after or concomitant with surgery to evaluate evidence for the spread of cancer, which helps the medical team determine the progress of and treatment options for a patient's malignancy). In clinical early-stage EC, lymphadenectomy has been observed to have a marginal impact on EC outcomes and to be associated with substantial long-term comorbidities.</p>
<p>The diagnostic accuracy for LNM is limited: approximately 50% of LNM is found in low-or intermediate-risk patients [2,31].</p>
<p>Objectives. This work uses the BN model from Reijnen et al. [26] as a starting point to improve the state of the art in two ways:</p>
<p>• Extending the BN model to include the hospital of treatment as an additional variable to detect, estimate and control for potential selection bias.</p>
<p>• Addressing the bias introduced by the missing imputation step, which could induce spurious correlations, hindering the interpretability of the discovered relationships.</p>
<p>• Developing a causal model that integrates domain expert knowledge with observational data to better identify patients with EC designated as low or intermediate risk to develop LNM, in order to support stakeholders for decision-making.</p>
<p>Related Work</p>
<p>Individualized treatment aims to minimize unnecessary exposure to therapyrelated morbidity and at the same time offers proper management according to patients' risk-stratification. In the context of EC, predicting the risk of LNM before surgical treatment has received limited attention in the literature. Koskas et al. [17] evaluated the performance of BNs models within their cohort of 519 patients. Only one model achieved an AUC greater than 0.75, 1 highlighting the need for improved pre-operative risk stratification. Subsequent works [10,16,25] identified biomarkers such as p53 and L1CAM as potential prognostic predictors, together with patients baseline comorbidities and tumors characteristics such as histology, grading and staging. More recently, Reijnen et al. [26] developed a model for the prediction of LNM and of disease-specific survival (DSS) in EC patients. This model, called ENDORISK, is a BN built on clinical, histopathological and molecular biomarkers that can be assessed preoperatively, allowing for patient counseling and shared decision-making before surgery. ENDORISK was shown to be competitive in both goodness of fit and predictive accuracy, achieving AUC values between 0.82 and 0.85 [33].</p>
<p>Methods</p>
<p>Causal Bayesian Networks</p>
<p>Firstly, we will summarize those key definitions for BNs and causal models that we will need to describe our contributions in Section 3.</p>
<p>Definition 1 (Graph)</p>
<p>A graph G =(V, E) is a mathematical object represented by a tuple of two sets: a finite set of nodes V and a finite set of edges E ⊆ V × V. In the following pages (V, E) will be omitted if not specified otherwise.</p>
<p>We will focus on directed graphs where (X, Y ) = (Y, X), which is graphically represented as X → Y . A directed graph encodes a set of ordinal relationships, i.e. in X → Y the node X is called parent of Y and Y is said to be the child of X. Therefore, the set of parents of X is Pa(X), while the set of children of X is Ch(X).</p>
<p>A directed path π is a finite ordered set of nodes π = (V 0 → · · · → V n ) such that each adjacent pair of nodes (V i , V i+1 ) in π is a directed edge in E. A cycle is a path where the first and the last node are the same node. A graph is acyclic if it contains no cycle, also called a Directed Acyclic Graph (DAG).
Definition 2 (Causal Graph) A causal graph G = (V, E) [1]
is a graph that encodes the cause-effect relationships of a system.</p>
<p>Causes &amp; Effects. The set V contains the variables that describe the behavior of the system under study, whereas the set E contains the edges that make explicit the interplay of the variables. In particular, for each directed edge (X, Y ) ∈ E, X is said to be a direct cause of Y , whereas Y is called direct effect of X. This definition is recursive: a variable Z that is the direct cause of X, but not of Y , is said to be an indirect cause of Y .</p>
<p>This mapping between a causal graph G and the cause-effect relationships is formalized by the causal edge assumption [22].
Definition 3 (Causal Edge Assumption) Let G = (V, E) be a causal graph.
The value assigned to each variable X ∈ V is completely determined by the function f given its parents:
X := f (Pa(X)) ∀X ∈ V(1)
The causal edge assumption allows us to interpret the edges of a causal graph in a non-ambiguous way: it enforces a recursive relationship over the structure of the graph, establishing a chain of functional dependencies. Hence, this class of graphical models is inherently explainable, even for researchers approaching them for the first time.</p>
<p>When the causal graph is not known a priori, it is possible to recover it from a combination of prior knowledge and data driven approaches. Such problem is called Causal Discovery [34].</p>
<p>Definition 4 (Causal Discovery) Let G * be the true but unknown graph in the space of possible graphs G from which the data set D has been generated.</p>
<p>The Causal Discovery problem consists in recovering G * given the data set D and the prior knowledge K.</p>
<p>Once the causal graph G * is recovered, it is possible to build a PGM with the given structure. For example, BNs [23] are a widely known type of PGM.</p>
<p>Definition 5 (Bayesian Network) Let be G a DAG and let P (X) be a global probability distribution with parameters Θ. A BN B = (G, Θ) is a model in which each variable of X is a vertex of G and P (X) factorizes into local probability distributions according to G:
P (X) = X∈X P (X | Pa(X))(2)
The key difference between a BN and a Causal BN (CBN) is the semantic interpretation of its edges. Indeed, in a CBN an edge represents a cause-effect relationship between two variables, whereas the same edge in a BN entails only a probabilistic dependence.
Definition 6 (Causal Bayesian Network) A Causal BN B = (G, Θ) is a BN where the associated DAG G is a causal graph.</p>
<p>Causal Discovery with Observational and Missing Data</p>
<p>Causal discovery algorithms are usually divided into two classes: constraintbased and score-based. The two classes have been extended to handle missing data in different ways: constraint-based algorithms rely on test-wise deletion [30] to perform conditional independence tests efficiently in order to mitigate the impact of missing observations, while score-based approaches alternate data imputation and causal discovery [8].</p>
<p>Causal Discovery with Missing Data. By default, causal discovery algorithms are not designed to handle incomplete data. However, we can combine them with missing value imputation approaches to complete the data and reduce the problem to a standard causal discovery. A widely-used application of this idea is the Expectation Maximization (EM) [18] algorithm. In particular, the Structural EM [8] algorithm is specifically designed to iteratively run the imputation step performed by EM and a causal discovery step performed by a score-based algorithm, alternating them until convergence.</p>
<p>Greedy Search: The Hill-Climbing Approach. A widely applied scorebased algorithm for causal discovery is Greedy Search (GS) [28]. GS traverses the space G of the possible DAGs over the set of variables V, selecting the optimal graph G * by a greedy evaluation of a function S, known as the scoring criterion. There are multiple strategies to implement GS, one of which is called Hill-Climbing (HC). At its core, HC repeatedly applies three fundamental operations to change the current recovered structure, moving from a graph to another, across the graphs space G. These "moves" are the addition, deletion or reversal of an edge. If a move improves the score S, then the graph is updated accordingly. The procedure halts when no moves improve the score and returns a DAG.</p>
<p>While the graphs space G contains every graph that could be generated given the vertices V, only a subset of them are compatible with the probability distribution induced by the observed data. Moreover, not every graph compatible with said distribution is necessarily causal. Therefore, it is possible to shrink the search space by adding constraints in terms of structural properties, that is, by requiring or forbidding the existence of an edge in the optimal graph G * .</p>
<p>Encoding Prior Knowledge. One could restrict the set of admissible graphs by encoding prior knowledge through required or forbidden edge lists [21]. For instance, it is possible to leverage expert knowledge to identify known relationships and encode them as required edges. These lists can also encode a partial ordering when potential causes of other variables are known.</p>
<p>For example, suppose that clinicians want to include their prior knowledge on the interaction between biomarkers and LNM into the CBN. This inclusion would happen during the execution of the causal discovery algorithm and, therefore, requires that the experts' knowledge is encoded programmatically. Causal discovery algorithms essentially learn a set of ordinal, parent-child relationships: it is natural to encode prior knowledge in the same form. For instance, if we know that p53 is not a direct cause of LNM, then the translation of such a concept would be p53 ∈ Pa(LNM). If, on the other hand, we know that LNM is a direct cause of L1CAM then we would have L1CAM ∈ Pa(LNM) . This is a direct consequence of the Causal Edge Assumption (Definition 3). Even this simple example shows the flexibility of this approach, allowing to encode different sources of prior knowledge without any restrictions.</p>
<p>Experimental Results</p>
<p>Causal discovery algorithms provide a correct solution to the causal discovery problem in the limit of the number of samples [29]. However, in real-world applications the available data are finite, especially in medicine, where data samples are usually small. As a result, even small amounts of noise in the data may result in a different structure. Therefore, it is important to quantify our confidence in the presence of each edge in the causal BN, also called the "strength" of an edge.</p>
<p>Estimating Edge Strength: A Bootstrap Approach. The estimation of the strength of an edge was performed through a bootstrap approach [9]. Here, a custom version with Structural EM is reported in Algorithm 1, described as follows. Line 1, the procedure takes as input a data set D, prior knowledge K, hyperparameters α α α for Structural EM, number of bootstraps n and number of samples to draw m. Line 2, the confidence matrix C is initialized. Lines 3-6, the data set D is re-sampled n times with replacement, drawing m observations for each bootstrap following a uniform distribution. For each sampled data set D i ⊆ D, the causal discovery algorithm is applied to induce a corresponding graph G i . Finally, line 7, is responsible to compute the strength of each edge as the relative frequency of inclusion across the n bootstraps.</p>
<p>The causal discovery algorithm developed is described in Algorithm 2. Line 1 is based on the confidence matrix estimation computed by Algorithm 1. Line 2, the causal graph G is initialized to the empty graph and, line 3, the associated confidence matrix C, i.e. the matrix containing the edges strength, is computed. Line 4 describes a generic strategy to select the edges to insert into G given C. Here, we relied on a threshold λ to filter irrelevant edges to build the "average graph". Lines 5-6, the CBN parameters Θ are fitted given G by applying EM [18] to the data set D with missing data.</p>
<p>Definition and Selection of Variables.</p>
<p>To conduct this analysis we used the cohort presented by Reijnen et al. An overview of the cohort and the procedures done for data collection can be found in [26]. Briefly, the retrospective multicenter cohort study included 763 patients, with a median age 65 years, surgically treated for endometrial cancer between 1995 and 2013 at one of the 10 participating European hospitals. Clinical and histopathological variables with prognostic value for the prediction of LNM were identified by a systematic review of the literature. The used variables could be divided into three major temporal tiers: All the described variables are discrete variables, with cardinality ranging from 2 to 3. Two main changes were done in comparison to published works: addition of hospital of treatment (10 levels) in the model and separation of adjuvant therapy into two different dichotomous variables (chemotherapy and radiotherapy).</p>
<p>Training and Testing. The data set D was split in a train set and a test set following a 70/30 ratio. For each configuration of hyperparameters (α α α, n, m, λ), we applied Algorithm 2 to the train set, with the same prior knowledge K.</p>
<p>The resulting BNs were evaluated on the test set by estimating the probability of LNM. The hyperparameter tuning was performed following a grid search, as suggested in [29]. While cross validation (CV) is generally preferred over a naïve train-test splitting, hyperparameter tuning over a learning procedure based on Structural EM is computationally expensive and, therefore, it would require a nonignorable amount of time when coupled with CV. Moreover, we considered the possibility to further split the train set to obtain a validation set, but the reduced sample size hindered the feasibility of this additional step. Finally, we computed the sensitivity, specificity, ROC and AUC 2 for each CBN model. 
T P R = T P T P + F N (3) T P R = T N T N + F P (4)
The T P R and T N R are also called sensitivity and specificity, respectively.  C ← 0 Initialize a |V| × |V| matrix, with V the variables in D.</p>
<p>3:</p>
<p>for i ∈ [1, n] do 4:
D i ← Sample(D, m)
Sample from D with replacement.</p>
<p>5:</p>
<p>G i ← StructuralEM(D i , K, α α α) Learn G i from D i and K. 6:
C[X, Y ] ← C[X, Y ] + 1, ∀ (X, Y ) ∈ E i
Increment the edge count.</p>
<p>7:</p>
<p>C ← C/n Normalize the confidence matrix.</p>
<p>8:</p>
<p>return C Figure 1 is a scatter plot of the results of the execution of Algorithm 2. The color mapping allows to clearly distinguish three well-separated clusters, grouped by the parents space cardinality. Specifically, the red cluster represents the models where LNM has no parents, the light-red cluster contains models where LNM has only Chemotherapy as parent, and finally the blue cluster where both Chemotherapy and Histology are parents of LNM.</p>
<p>Algorithm 2 Learn CBN from missing data and prior knowledge. G ← (V, ∅) Initialize an empty graph over the variables V in D.</p>
<p>3:</p>
<p>C ← ConfidenceMatrix(D, K, α α α, n, m) Compute the confidence matrix.</p>
<p>4:</p>
<p>Insert edges into G following a strategy w.r.t. C and λ. 5:Θ ← EM(G, D)</p>
<p>Estimate the parameters using EM.  The structure presented in Figure 2 is built by encoding prior causal knowledge elicited by clinicians and randomized controlled trials (RCTs). The encoding process is performed by adding a directed edge from the expected cause to its effect. Each edge addition is supported by biological and physiological knowledge, either obtained by querying experts or from reviewed literature, without observational data. Note, for example, that the Therapy node does not have incoming edges, since therapy is always assigned at random in an RCT (and only the outcome matters).</p>
<p>The graph presented in Figure 3 is the result of the application of Algorithm 2 on the collected data set and encoded prior knowledge based on partial temporal ordering of variables. The Therapy node is split into Radiotherapy and Chemotherapy to highlight the different impact of adjuvant treatments.</p>
<p>The two graphs share a common subset of edges, e.g. the ones related to Recurrence and Survivals. A major difference stands in the edges related to the biomarkers cluster. Indeed, while in Figure 2 biomarkers, such as p53, CA125 and L1CAM, are assumed to be strongly related to LNM, in the recovered graph the PreoperativeGrade is observed as common parent of the variables contained in such cluster. Moreover, no biomarker is directly connected to LNM, not as a parent nor as a child, calling for further analyses of the collected data.</p>
<p>Such similarities and differences also appear in Figure 4, where Hospital is introduced to explore the potential presence of latent effects and selection bias. While the graph in Figure 4 is not completely different from the one in Figure 3 in terms of observed substructures, the latter encodes different independence statements due to the presence of the newly introduced Hospital.</p>
<p>The crucial difference stands in the semantic interpretation of Hospital, which in this case is not to be intended as a direct cause of its children, but rather as a proxy for others unobserved variables or biases, i.e. a context variable. Indeed, while it could be that population heterogeneity across hospitals affects the choice of adjuvant treatments, it would be nonsensical to conclude that Hospital is a cause of Ca-125. Nonetheless, the causal discovery procedure includes a set of edges that are related to spurious associations present in the data set. For example, the directed edge that connects Hospital to p53 is an instance of such pattern, which could be caused by a missing-not-at-random (MNAR) mechanism [27]. Another example of the impact of biases is represented by the directed edge from Hospital to PostoperativeGrade. In this case, an unbalanced distribution of patients' grading across geographical regions, which Hospital is a proxy of, could act as a potential source of selection bias [7].</p>
<p>The ROC curve depicted in Figure 5 is obtained by predicting the probability of the LNM class on the test set, given the CBN fitted on the structure in Figure 4 and the train set. It achieves an AUC of 0.883, with associated 95% CI 0.775-0.991, which is higher than the one obtained in [26], although it was not possible to compare the metrics using a significance test due to the different test sets.  Figure 2. In particular, green edges are present both in reference and recovered graph with the same orientation, orange edges are present both in reference and recovered graph with reversed orientation, gray nodes and edges cannot be directly compared due to different node sets, and, finally, black edges are present only in the recovered graph.  Figure 4 and train data.</p>
<p>Conclusions and Future Works</p>
<p>Given the known limitations of data-driven approaches when applied to observational data, causal discovery techniques are used to explore and mitigate the impact of spurious associations during the learning process. In this work we explored the task of learning a causal representation to assess the pre-operative risk of developing LNM in endometrial cancer patients. Furthermore, the recovered models were extended to include information from context variables, aiming to uncover previously unobserved effects.</p>
<p>The resulting procedure takes advantage of pre-existing techniques to reduce the bias introduced during the imputation step in a bootstrap approach. This enabled us to compute the strength of the observed associations in the obtained models across multiple re-sampled instances, allowing a step of model averaging to recover less frequent substructures. The risk assessment is performed by predicting the probability of developing LNM using a CBN fitted on the recovered structure and given train set, showing an increased AUC over previous works.</p>
<p>Still, we highlighted a set of potential issues that need to be addressed in future works.</p>
<p>Missingness Mechanism. With the introduction of the Hospital variable we observed a set of edges that hint to the presence of a potential missing-not-atrandom pattern. If this is the case, then it would require careful consideration in order to reduce the bias introduced during the missing imputation step.</p>
<p>Effect of Adjuvant Therapy. Once a causal graph is obtained, it is theoretically possible to estimate the causal effect of each adjuvant therapy, either single or combined, on the development of LNM. Before directly computing the the effect, there are assumptions that need to be carefully verified, e.g. positivity, consistency, unconfoundedness and non interference [22].</p>
<p>Impact of Selection Bias. While it is clear that observing an association between Hospital and other variables it is not sufficient to conclude that, indeed, there is a selection bias, it is a strong hint that there are other unobserved variables that influence the causal mechanism. It could be interesting to assess which is the impact of the selection bias mediated by the Hospital variable alone.</p>
<p>•
Pre-operative clinical, histopathological variables and biomarkers: Estrogen Receptor (ER) expression, Progesteron Recepter (PR) expression, L1CAM (cell migration) expression, p53 (tumour suppressor gene) expression, cervical cytology, platelets counts (thrombocytosis), lymphadenopathy on MRI or CT, lymphovascular space invasion (LVSI), Ca-125 serum levels and pre-operative tumor grade, • Post-operative/treatment variables: adjuvant therapy (Chemotherapy and/or Radiotherapy), post-operative tumour grade, • Late post-operative outcomes: 1-,3-,5-year disease-specific survival (DSS), Lymph Nodes Metastases (LNM), Myometrial Invasion.</p>
<p>Definition 7 (
7Sensitivity &amp; Specificity) Given a binary classification problem, the confusion matrix is a 2 × 2 squared integer matrix resulting from the application of a classification algorithm. The values on the main diagonal are called true positives (T P ) and true negatives (T N ), while the values on the off diagonal are false positives (F P ) and false negatives (F N ). Then, the true positive ratio (T P R) and the true negative ratio (T N R) are defined as follows:</p>
<p>Definition 8 (
8ROC &amp; AUC) The Receiving Operating Characteristic (ROC) curve is a plot of sensitivity and (1 -specificity) measures at different thresholds. The Area Under the Curve (AUC) is the area under the ROC curve.Algorithm 1 Confidence matrix from missing data and prior knowledge.</p>
<p>sample vs. Out−of−sample AUC Scatterplot</p>
<p>Figure 1 :Figure 2 :
12Scatter plot of the results of Algorithm 2. Each dot is a CBN with achieved in-sample and out-of-sample AUC on the horizontal and vertical axes, respectively. Dots color depend on the cardinality of the space of the parents of the target node LNM. To the right, a zoom of the cluster of those CBN that achieved higher values of AUC. Reference graph obtained by experts' knowledge and randomized controlled trial.</p>
<p>Figure 3 :
3Strength plot of recovered CBN. The edges thickness depends on the strength of the edge itself, which is estimated by the confidence matrix C. The nodes and edges are colored to ease the comparison with the reference graph</p>
<p>Figure 4 : 3 Figure 5 :
435Strength plot of recovered CBN with the addition of the previously unobserved Hospital variable. The edges thickness and the coloring schema are the same of Figure ROC curve and AUC value of the CBN model fitted from the graph in
The "Area Under the Curve", defined in page 8.
We are aware of the issues related to the selection of a causal model based on its classification performances, hence, we took into account both in-sample and out-of-sample metrics.
AcknowledgmentsAlessio Zanga was granted a Ph.D. scholarship by F. Hoffmann-La Roche Ltd.
On Pearl's Hierarchy and the Foundations of Causal Inference. Elias Bareinboim, Juan D Correa, Duligur Ibelind, Thomas Icard, Probabilistic and Causal Inference: The Works of Judea Pearl. Elias Bareinboim, Juan D. Correa, Duligur Ibelind, and Thomas Icard. On Pearl's Hierarchy and the Foundations of Causal Inference. In Probabilistic and Causal Inference: The Works of Judea Pearl, pages 1-62, 2020.</p>
<p>Just how accurate are the major risk stratification systems for early-stage endometrial cancer?. S Bendifallah, P Canlorbe, Collinet, Arsène, C Huguet, Coutant, Hudry, Graesslin, C Raimond, Touboul, M Daraï, Ballester, British Journal of Cancer. 112S Bendifallah, G Canlorbe, P Collinet, E Arsène, F Huguet, C Coutant, D Hudry, O Graesslin, E Raimond, C Touboul, E Daraï, and M Ballester. Just how accurate are the major risk stratification systems for early-stage endometrial cancer? British Journal of Cancer, 112:793-801, 3 2015.</p>
<p>. Linda Wenya, Ahmed Bi, Matthew B Hosny, Maryellen L Schabath, Nicolai J Giger, Alireza Birkbak, Tavis Mehrtash, Omar Allison, Christopher Arnaout, Ian F Abbosh, Raymond H Dunn, Rulla M Mak, Clare M Tamimi, Charles Tempany, Udo Swanton, Hoffmann, Lawrence HWenya Linda Bi, Ahmed Hosny, Matthew B. Schabath, Maryellen L. Giger, Nicolai J. Birkbak, Alireza Mehrtash, Tavis Allison, Omar Ar- naout, Christopher Abbosh, Ian F. Dunn, Raymond H. Mak, Rulla M. Tamimi, Clare M. Tempany, Charles Swanton, Udo Hoffmann, Lawrence H.</p>
<p>Artificial intelligence in cancer imaging: Clinical challenges and applications. Robert J Schwartz, Raymond Y Gillies, Hugo J W L Huang, Aerts, CA: A Cancer Journal for Clinicians. 22019Schwartz, Robert J. Gillies, Raymond Y. Huang, and Hugo J. W. L. Aerts. Artificial intelligence in cancer imaging: Clinical challenges and applica- tions. CA: A Cancer Journal for Clinicians, page caac.21552, 2 2019.</p>
<p>Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. Freddie Bray, Jacques Ferlay, Isabelle Soerjomataram, Rebecca L Siegel, Lindsey A Torre, Ahmedin Jemal, CA: A Cancer Journal for Clinicians. 68Freddie Bray, Jacques Ferlay, Isabelle Soerjomataram, Rebecca L. Siegel, Lindsey A. Torre, and Ahmedin Jemal. Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries. CA: A Cancer Journal for Clinicians, 68:394-424, 11 2018.</p>
<p>Adjuvant chemoradiotherapy versus radiotherapy alone in women with high-risk endometrial cancer (portec-3): patterns of recurrence and post-hoc survival analysis of a randomised phase 3 trial. Melanie E Stephanie M De Boer, Linda Powell, Mileshkin, The Lancet Oncology. 202019Stephanie M de Boer, Melanie E Powell, Linda Mileshkin, et al. Adjuvant chemoradiotherapy versus radiotherapy alone in women with high-risk en- dometrial cancer (portec-3): patterns of recurrence and post-hoc survival analysis of a randomised phase 3 trial. The Lancet Oncology, 20:1273-1285, 9 2019.</p>
<p>Artificial intelligence in cancer research, diagnosis and therapy. Olivier Elemento, Christina Leslie, Johan Lundin, Georgia Tourassi, Nature Reviews Cancer. 21122021Olivier Elemento, Christina Leslie, Johan Lundin, and Georgia Tourassi. Artificial intelligence in cancer research, diagnosis and therapy. Nature Reviews Cancer, 21(12):747-752, 12 2021.</p>
<p>The Necessity of Construct and External Validity for Generalized Causal Claims. M Kevin, David Esterling, Eric Brady, Schwitzgebel, OSF Preprints. Kevin M Esterling, David Brady, and Eric Schwitzgebel. The Necessity of Construct and External Validity for Generalized Causal Claims. OSF Preprints, pages 1-41, 2021.</p>
<p>The Bayesian Structural EM. Nir Friedman, Proceedings of the Fourteenth Conference on Uncertainty and Artificial Intelligence. the Fourteenth Conference on Uncertainty and Artificial IntelligenceNir Friedman. The Bayesian Structural EM. Proceedings of the Fourteenth Conference on Uncertainty and Artificial Intelligence, 1998.</p>
<p>Data Analysis with Bayesian Networks: A Bootstrap Approach. Nir Friedman, Moises Goldszmidt, Abraham Wyner, 1Nir Friedman, Moises Goldszmidt, and Abraham Wyner. Data Analysis with Bayesian Networks: A Bootstrap Approach. 1 2013.</p>
<p>Integrated genomic characterization of endometrial carcinoma. Gad Getz, Stacey B Gabriel, Kristian Cibulskis, Nature. 497Gad Getz, Stacey B. Gabriel, Kristian Cibulskis, et al. Integrated genomic characterization of endometrial carcinoma. Nature, 497, 2013.</p>
<p>. David Gunning, Mark Stefik, Jaesik Choi, Timothy Miller, Simone Stumpf, Guang-Zhong Yang, XAI-Explainable artificial intelligence. Science Robotics. 4372019David Gunning, Mark Stefik, Jaesik Choi, Timothy Miller, Simone Stumpf, and Guang-Zhong Yang. XAI-Explainable artificial intelligence. Science Robotics, 4(37), 12 2019.</p>
<p>Artificial intelligence in cancer therapy. Dean Ho, Science. 3676481Dean Ho. Artificial intelligence in cancer therapy. Science (New York, N.Y.), 367(6481):982-983, 2 2020.</p>
<p>Causability and explainability of artificial intelligence in medicine. Andreas Holzinger, Georg Langs, Helmut Denk, Kurt Zatloukal, Heimo Müller, WIREs Data Mining and Knowledge Discovery. 941312Andreas Holzinger, Georg Langs, Helmut Denk, Kurt Zatloukal, and Heimo Müller. Causability and explainability of artificial intelligence in medicine. WIREs Data Mining and Knowledge Discovery, 9(4):e1312, 7 2019.</p>
<p>Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges. Shigao Huang, Jie Yang, Simon Fong, Qi Zhao, Cancer Letters. 471Shigao Huang, Jie Yang, Simon Fong, and Qi Zhao. Artificial intelligence in cancer diagnosis and prognosis: Opportunities and challenges. Cancer Letters, 471:61-71, 2 2020.</p>
<p>History of artificial intelligence in medicine. Vivek Kaul, Sarah Enslin, Seth A Gross, Gastrointestinal Endoscopy. 924Vivek Kaul, Sarah Enslin, and Seth A. Gross. History of artificial intelli- gence in medicine. Gastrointestinal Endoscopy, 92(4):807-812, 10 2020.</p>
<p>L1cam further stratifies endometrial carcinoma patients with no specific molecular risk profile. K F Felix, Anthony N Kommoss, Friedrich Karnezis, Aline Kommoss, Talhouk, Andrei Florin, Annette Taran, C Blake Staebler, David G Gilks, Bernhard Huntsman, Sara Y Krämer, Jessica N Brucker, Stefan Mcalpine, Kommoss, British Journal of Cancer. 119Felix K.F. Kommoss, Anthony N. Karnezis, Friedrich Kommoss, Aline Tal- houk, Florin Andrei Taran, Annette Staebler, C. Blake Gilks, David G. Huntsman, Bernhard Krämer, Sara Y. Brucker, Jessica N. McAlpine, and Stefan Kommoss. L1cam further stratifies endometrial carcinoma patients with no specific molecular risk profile. British Journal of Cancer, 119, 2018.</p>
<p>Evaluation of models to predict lymph node metastasis in endometrial cancer: A multicentre study. Martin Koskas, Marie Fournier, Anke Vanderstraeten, Francine Walker, Dirk Timmerman, Ignace Vergote, Frédéric Amant, European Journal of Cancer. 61Martin Koskas, Marie Fournier, Anke Vanderstraeten, Francine Walker, Dirk Timmerman, Ignace Vergote, and Frédéric Amant. Evaluation of mod- els to predict lymph node metastasis in endometrial cancer: A multicentre study. European Journal of Cancer, 61:52-60, 7 2016.</p>
<p>The EM algorithm for graphical association models with missing data. L Steffen, Lauritzen, Computational Statistics and Data Analysis. 192Steffen L. Lauritzen. The EM algorithm for graphical association models with missing data. Computational Statistics and Data Analysis, 19(2), 1995.</p>
<p>Structural causal bandits: Where to intervene?. Sanghack Lee, Elias Bareinboim, Advances in Neural Information Processing Systems, volume 2018-Decem. Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? In Advances in Neural Information Processing Systems, volume 2018-Decem, pages 2568-2578, 2018.</p>
<p>Adjuvant chemotherapy plus radiation for locally advanced endometrial cancer. Daniela Matei, Virginia Filiaci, Marcus E Randall, New England Journal of Medicine. 3802019Daniela Matei, Virginia Filiaci, Marcus E. Randall, et al. Adjuvant chemotherapy plus radiation for locally advanced endometrial cancer. New England Journal of Medicine, 380:2317-2326, 6 2019.</p>
<p>Strong Completeness and Faithfulness in Bayesian Networks. Christopher Meek, Christopher Meek. Strong Completeness and Faithfulness in Bayesian Net- works. 2013.</p>
<p>Causal inference in statistics: A primer. Judea Pearl, Madelyn Glymour, Nicholas P Jewell, John Wiley \&amp; SonsJudea Pearl, Madelyn Glymour, and Nicholas P Jewell. Causal inference in statistics: A primer. John Wiley \&amp; Sons, 2016.</p>
<p>. Judea Pearl, Stuart Russell Bayesian, Networks, Technical reportJudea Pearl and Stuart Russell. BAYESIAN NETWORKS. Technical report, 2003.</p>
<p>Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study. Luisa Pumplun, Mariska Fecho, Nihal Wahl, Felix Peters, Peter Buxmann, Journal of Medical Internet Research. 231029301Luisa Pumplun, Mariska Fecho, Nihal Wahl, Felix Peters, and Peter Bux- mann. Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study. Journal of Medical Internet Research, 23(10):e29301, 10 2021.</p>
<p>L1cam expression in endometrial carcinomas: An enitec collaboration study. J M Louis, Nicole C M Van Der Putten, Koen Visser, Van De, Maria Vijver, Peter Santacana, Johan Bronsert, Marc Bulten, Eva Hirschfeld, Antonio Colas, Angel Gil-Moreno, Gemma Garcia, Fransesc Mancebo, Jone Alameda, Reidun K Trovik, Jutta Kopperud, Stefanie Huvila, Schrauwen, British Journal of Cancer. Koskas, Francine Walker, Vit Weinberger, Lubos Minar, Eva Jandakova, Marc P.L.M. Snijders, Saskia Van Den Berg-Van Erp, Xavier Matias-Guiu, Helga B. Salvesen, Frederic Amant, Leon F.A.G. Massuger, and Johanna M.A. Pijnenborg115Louis J.M. Van Der Putten, Nicole C.M. Visser, Koen Van De Vijver, Maria Santacana, Peter Bronsert, Johan Bulten, Marc Hirschfeld, Eva Colas, Antonio Gil-Moreno, Angel Garcia, Gemma Mancebo, Fransesc Alameda, Jone Trovik, Reidun K. Kopperud, Jutta Huvila, Stefanie Schrauwen, Mar- tin Koskas, Francine Walker, Vit Weinberger, Lubos Minar, Eva Jandakova, Marc P.L.M. Snijders, Saskia Van Den Berg-Van Erp, Xavier Matias- Guiu, Helga B. Salvesen, Frederic Amant, Leon F.A.G. Massuger, and Johanna M.A. Pijnenborg. L1cam expression in endometrial carcinomas: An enitec collaboration study. British Journal of Cancer, 115, 2016.</p>
<p>Preoperative risk stratification in endometrial cancer (ENDORISK) by a Bayesian network model: A development and validation study. Casper Reijnen, Evangelia Gogou, Nicole C M Visser, Hilde Engerud, Jordache Ramjith, J M Louis, Koen Van Der Putten, Van De, Maria Vijver, Peter Santacana, Johan Bronsert, Marc Bulten, Eva Hirschfeld, Antonio Colas, Armando Gil-Moreno, Gemma Reques, Camilla Mancebo, Jone Krakstad, Ingfrid S Trovik, Jutta Haldorsen, Martin Huvila, Vit Koskas, Weinberger, PLoS Medicine. Marketa Bednarikova, Jitka Hausnerova, Anneke A.M. Van Der Wurff, Xavier Matias-Guiu, Frederic Amant, Leon F.A.G. Massuger, Marc P.L.M. Snijders, Heidi V.N. Kusters-Vandevelde, Peter J.F. Lucas, and Johanna M.A. Pijnenborg1752020Casper Reijnen, Evangelia Gogou, Nicole C.M. Visser, Hilde Engerud, Jor- dache Ramjith, Louis J.M. Van Der Putten, Koen Van De Vijver, Maria Santacana, Peter Bronsert, Johan Bulten, Marc Hirschfeld, Eva Colas, Antonio Gil-Moreno, Armando Reques, Gemma Mancebo, Camilla Krak- stad, Jone Trovik, Ingfrid S. Haldorsen, Jutta Huvila, Martin Koskas, Vit Weinberger, Marketa Bednarikova, Jitka Hausnerova, Anneke A.M. Van Der Wurff, Xavier Matias-Guiu, Frederic Amant, Leon F.A.G. Massuger, Marc P.L.M. Snijders, Heidi V.N. Kusters-Vandevelde, Peter J.F. Lucas, and Johanna M.A. Pijnenborg. Preoperative risk stratification in endome- trial cancer (ENDORISK) by a Bayesian network model: A development and validation study. PLoS Medicine, 17(5), 2020.</p>
<p>Bayesian network models for incomplete and dynamic data. Marco Scutari, Marco Scutari. Bayesian network models for incomplete and dynamic data. 2020.</p>
<p>Learning Bayesian networks from big data with greedy search: computational complexity and efficient implementation. Marco Scutari, Claudia Vitolo, Allan Tucker, Statistics and Computing. 29Marco Scutari, Claudia Vitolo, and Allan Tucker. Learning Bayesian net- works from big data with greedy search: computational complexity and efficient implementation. Statistics and Computing, 29:1095-1108, 2019.</p>
<p>Causation, prediction, and search. Peter Spirtes, N Clark, Richard Glymour, David Scheines, Heckerman, MIT pressPeter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.</p>
<p>Fast causal inference with non-random missingness by test-wise deletion. Eric V Strobl, Shyam Visweswaran, Peter L Spirtes, International Journal of Data Science and Analytics. 61Eric V. Strobl, Shyam Visweswaran, and Peter L. Spirtes. Fast causal inference with non-random missingness by test-wise deletion. International Journal of Data Science and Analytics, 6(1):47-62, 8 2018.</p>
<p>Hormone receptor loss in endometrial carcinoma curettage predicts lymph node metastasis and poor outcome in prospective multicentre trial. Jone Trovik, Elisabeth Wik, M J Henrica, Camilla Werner, Harald Krakstad, Ingrid Helland, Tormund S Vandenput, Njolstad, M Ingunn, Janusz Stefansson, Solveig Marcickiewicz, Anne C Tingulstad, Frederic Staff, Lars A Amant, Helga B Akslen, Salvesen, European Journal of Cancer. 492013Jone Trovik, Elisabeth Wik, Henrica M.J. Werner, Camilla Krakstad, Har- ald Helland, Ingrid Vandenput, Tormund S. Njolstad, Ingunn M. Stefans- son, Janusz Marcickiewicz, Solveig Tingulstad, Anne C. Staff, Frederic Amant, Lars A. Akslen, and Helga B. Salvesen. Hormone receptor loss in endometrial carcinoma curettage predicts lymph node metastasis and poor outcome in prospective multicentre trial. European Journal of Can- cer, 49:3431-3441, 11 2013.</p>
<p>. Olga Troyanskaya, Zlatko Trajanoski, Anne Carpenter, Sebastian Thrun, Narges Razavian, Nuria Oliver, Artificial intelligence and cancer. Nature cancer. 12Olga Troyanskaya, Zlatko Trajanoski, Anne Carpenter, Sebastian Thrun, Narges Razavian, and Nuria Oliver. Artificial intelligence and cancer. Na- ture cancer, 1(2):149-152, 2 2020.</p>
<p>External validation study of endometrial cancer preoperative risk stratification model (endorisk). Petra Vinklerová, Petra Ovesná, Jitka Hausnerová, Johanna M A Pijnenborg, J F Peter, Casper Lucas, Stephanie Reijnen, Vít Vrede, Weinberger, Frontiers in Oncology. 122022Petra Vinklerová, Petra Ovesná, Jitka Hausnerová, Johanna M. A. Pijnen- borg, Peter J. F. Lucas, Casper Reijnen, Stephanie Vrede, and Vít Wein- berger. External validation study of endometrial cancer preoperative risk stratification model (endorisk). Frontiers in Oncology, 12, 8 2022.</p>
<p>A Survey on Causal Discovery: Theory and Practice. Alessio Zanga, Elif Ozkirimli, Fabio Stella, International Journal of Approximate Reasoning. 1512022Alessio Zanga, Elif Ozkirimli, and Fabio Stella. A Survey on Causal Discov- ery: Theory and Practice. International Journal of Approximate Reasoning, 151:101-129, 12 2022.</p>            </div>
        </div>

    </div>
</body>
</html>