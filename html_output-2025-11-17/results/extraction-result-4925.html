<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4925 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4925</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4925</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-107.html">extraction-schema-107</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-264426738</p>
                <p><strong>Paper Title:</strong> <a href="https://aclanthology.org/2023.emnlp-main.540.pdf" target="_blank">MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation</a></p>
                <p><strong>Paper Abstract:</strong> Curated datasets for healthcare are often limited due to the need of human annotations from experts. In this paper, we present MedEval, a multi-level, multi-task, and multi-domain medical benchmark to facilitate the development of language models for healthcare. MedEval is comprehensive and consists of data from several healthcare systems and spans 35 human body regions from 8 examination modalities. With 22,779 collected sentences and 21,228 reports, we provide expert annotations at multiple levels, offering a granular potential usage of the data and supporting a wide range of tasks. Moreover, we systematically evaluated 10 generic and domain-specific language models under zero-shot and finetuning settings, from domain-adapted baselines in healthcare to general-purposed state-of-the-art large language models (e.g., ChatGPT). Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction tuning for few-shot usage of large language models. Our investigation paves the way toward benchmarking language models for healthcare and provides valuable insights into the strengths and limitations of adopting large language models in medical domains, informing their practical applications and future advancements.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4925",
    "paper_id": "paper-264426738",
    "extraction_schema_id": "extraction-schema-107",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0049515,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MEDEVAL: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation</p>
<p>Zexue He zehe@ucsd.edu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Yu Wang 
University of California
San Diego, La JollaCAUnited States</p>
<p>An Yan ayan@ucsd.edu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Yao Liu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Eric Y Chang e8chang@ucsd.edu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Veterans Affairs San Diego Healthcare System
San DiegoCAUnited States</p>
<p>Amilcare Gentili agentili@ucsd.edu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Veterans Affairs San Diego Healthcare System
San DiegoCAUnited States</p>
<p>Julian Mcauley jmcauley@ucsd.edu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Chun-Nan Hsu 
University of California
San Diego, La JollaCAUnited States</p>
<p>Veterans Affairs San Diego Healthcare System
San DiegoCAUnited States</p>
<p>Veterans Affairs National Artificial Intelligence Institute
WashingtonDCUnited States</p>
<p>MEDEVAL: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation
047EF78E752EB299886AEF8A1F8126B7No pleural effusions. Ground Truth: Normal. Sentence Level Document Level Classification Generation Abnormality Identification Chest Input: Lungs are grossly clear. Ground Truth: Ambiguous The thoracic spine is otherwise unremarkable. Ground Truth: Ambiguous. Generation Disambiguated Rewriting Ambiguity Identification No. Ground Truth: the heart are normal No Ground Truth: free fluid is not identified. Classification Report Coding Classification Edema positivePneumonia negativeAll other unknown Transmetatarsal amputation of the right foot has occurred. no radiographic… Ground Truth: Enthesopathy: PositiveOsteomyelitis: PositiveAll Other Negative
Curated datasets for healthcare are often limited due to the need of human annotations from experts.In this paper, we present MEDEVAL, a multi-level, multi-task, and multi-domain medical benchmark to facilitate the development of language models for healthcare.MEDEVAL is comprehensive and consists of data from several healthcare systems and spans 35 human body regions from 8 examination modalities.With 22,779 collected sentences and 21,228 reports, we provide expert annotations at multiple levels, offering a granular potential usage of the data and supporting a wide range of tasks.Moreover, we systematically evaluated 10 generic and domain-specific language models under zero-shot and finetuning settings, from domain-adapted baselines in healthcare to general-purposed state-of-the-art large language models (e.g., ChatGPT).Our evaluations reveal varying effectiveness of the two categories of language models across different tasks, from which we notice the importance of instruction tuning for few-shot usage of large language models.Our investigation paves the way toward benchmarking language models for healthcare and provides valuable insights into the strengths and limitations of adopting large language models in medical domains, informing their practical applications and future advancements 1 .</p>
<p>Introduction</p>
<p>Recent advanced language models, e.g., GPT-3, ChatGPT, and LLaMa (Touvron et al., 2023a), are effective in various general tasks, suggesting their potential to healthcare use cases, such as alleviating the burden on human experts in decisionmaking and patient care.However, training, adapt-1 We will release the data set and source codes at https: //github.com/ZexueHe/MedEvalThe data set will also be available at the Department of Veterans Affairs Open Data Portal https://www.data.va.gov  ing, and evaluating these models requires highquality domain-specific datasets, which are often challenging to obtain.Previous medical datasets have been collected from healthcare-related literature (Dernoncourt and Lee, 2017;Gupta et al., 2021;Jin et al., 2019b;Banarescu et al., 2013) or web pages on the Internet (McCreery et al., 2020;Ammar et al., 2018).While these datasets are large, they may lack quality with heterogeneous topics (e.g., scientific literature about nutrition may offer limited help in the decision-making process of an X-ray analysis).On the other hand, high-quality clinical data is typically obtained by annotating records from healthcare systems like MIMIC-CXR (Johnson et al., 2019;Yan et al., 2021a).However, such data is either limited in size (Tsatsaronis et al., 2015), or may only cover certain dominant systems and specific domains2 , such as chest X-rays (John-son et al., 2016) or eye diseases (Otmakhova et al., 2022).Other approaches involve automatically generating medical corpus using templates (Pampari et al., 2018;Pappas et al., 2018) or using language models (Guo et al., 2023;Tang et al., 2023), but they have been noted to be limited in diversity, complexity, and quality (Gupta et al., 2021).</p>
<p>To tackle the aforementioned challenges and facilitate research in clinical NLP, we introduce MEDEVAL, a large-scale medical benchmark with multi-level curated labels for multiple tasks and multiple domains.MEDEVAL comprises 22,779 sentence-level datapoints from radiology reports, including expert-crafted classification labels (e.g., abnormality identification labels) and ground truth for generation tasks (e.g., disambiguated rewritings).Additionally, we include 21,228 complete reports with expert-annotated medical codes for disease classification (e.g., for ankle radiology studies) and golden output for generation tasks (e.g., summarization of radiology reports).Besides the ability to support multi-tasks at different levels, MEDE-VAL's uniqueness also lies in its diverse data coverage for different body parts (such as chest, foot, and ankle) and different modalities (X-rays, ultrasound, etc.), and the incorporated novel tasks/data that are collected from the U.S. Department of Veterans Affairs (VA) health care system nationwide.To the best of our knowledge, MEDEVAL represents the first expert-curated medical NLP benchmark that is both comprehensive and large-scale.MEDE-VAL will be released to facilitate future research.</p>
<p>We further conduct a comprehensive evaluation of multiple state-of-the-art language model baselines, including domain-adapted PLMs followed by in-domain fine-tuning (e.g., fine-tuned BERT (Devlin et al., 2018)) and general-purposed LLMs utilized with few-shot in-context learning (e.g., Chat-GPT).We evaluate their performance on sentencelevel and document-level NLU and NLG tasks.We observe the effectiveness of both categories of models in different healthcare tasks, with surprisingly comparable performances from LLMs only using few-shot learning to domain-adapted PLMs in certain generation tasks.Our comprehensive evaluation indicates language models are strong candidates in medical tasks whose data is already seen/similar to their training data.Our investigation provides insights into the potentials and X-ray, CT, Ultrasound, etc) and examined body parts (e.g., chest, abdomen, etc).limitations of LLMs in healthcare domains, guiding the appropriate use of LLM-assisted healthcare decision-making systems in the future.Overall, our contributions are summarized as:</p>
<p>• We propose a large-scale medical benchmark, namely MEDEVAL, with a broad coverage for various tasks and domains to facilitate future research in clinical NLP.</p>
<p>• We provide expert annotations for multiple tasks with multi-granularity, from sentence classification and rewriting, to report classification and summarization.</p>
<p>• We systematically evaluate various language models, and shed light on the strengths and weaknesses of these models for healthcare applications.</p>
<p>2 Related Work  et al., 2016, 2019, 2023)).Several works have been proposed based on their databases.For instance, MIMIC-CXR (Johnson et al., 2019) is a dataset consisting of pairs of radiology images and reports of chest X-ray exams.MIMIC PERform Dataset (Charlton et al., 2022) comprises physiological signals related to critically-ill patients.Additionally, Edin et al. (2023) collected document summary pairs labeled with diagnosis and procedure codes from Johnson et al. (2023).Though their collection may be one of the most comprehensive, there are many domains not included.A more recent attempt was made to alleviate the incompleteness concern by introducing M3 (Otmakhova et al., 2022), a multi-domain medical benchmark that incorporates multi-level expert annotations.By only considering studies on ophthalmology, M3 offers limited help in providing a fully comprehensive solution.To complement these existing efforts, we collect a large-scale dataset of real medical reports from another healthcare system that offers broader coverage including 35 human body regions from 8 examination modalities (e.g., X-ray, CT, etc.).</p>
<p>Language Models for Healthcare Large pretrained language models are being widely adopted to solve healthcare tasks.One line of research involves adapting general language models to the biomedical domain through continuous training on domain-specific data and tasks.For instance, Yan et al. (2021b) enhanced BERT with contrastive learning for chest report generation.ClinicBERT (Huang et al., 2019) was proposed by continuously training BERT on clinic notes using masked language modeling, and Yan et al. (2022) developed RadBERT by continuously training BERT on a vast collection of radiology reports.Other adaptations of BERT, such as BioBERT (Lee et al., 2020), Blue-BERT (Peng et al., 2019), SciBERT (Beltagy et al., 2019), and BioMegatron (Shin et al., 2020), involved training on large publicly available medical corpora like PubMed or Semantic Scholar.Furthermore, LLMs of alternative architectures have also been employed, including BioELMo (Jin et al., 2019a), BioBART (Yuan et al., 2022), and BioMed-RoBERTa (Gururangan et al., 2020a).Another research direction capitalizes on the generaliza-tion capabilities of recent LLMs, where biomedical problems are addressed through prompting LLMs in zero-shot or few-shot settings.This approach has been utilized in various applications, such as medical report summarization (Otmakhova et al., 2022), medical writing (Biswas, 2023), and medical named entity recognition (Hu et al., 2023), etc.In this work, we propose MEDEVAL, a multilevel data with curated annotations at various granularity to comprehensively evaluate the strengths and limitations of LMs in healthcare.</p>
<p>Dataset Design</p>
<p>MEDEVAL (shown in Figure 2) is designed with multiple NLU and NLG tasks at both the sentence and document levels, based on medical data collected from two different healthcare databases.Our data covers diverse combinations of human body parts and examination modalities.We first introduce the data sources where we collected the text input (Section 3.1).Then we present the expertannotated ground truth labels3 created by our medical team4 (Section 3.2).</p>
<p>Input Data Composition</p>
<p>Sentence-Level Corpora The sentence-level corpora used in this study are sourced from two wellconstructed datasets: the sentence-level OpenIannotated dataset (Demner-Fushman et al., 2016), which consists of sentences from chest studies, and the VA-annotated dataset (He et al., 2023b), which includes sentences about different body parts examined by different modalities.These datasets have undergone de-identification, completion of missing terms and uniqueness checks.More details about the data preprocessing is given in Appendix A. We use the officially released versions of the OpenI-annotated and VA-annotated datasets.In addition, we provide new annotations for sentencelevel tasks on these data sources.</p>
<p>Report-Level corpora We collect the raw radiology reports from two distinct sources: (1) text corpus from MIMIC-CXR, which comprises records related to human chests (Johnson et al., 2019), (2) text corpus from the databases of a nationwide government healthcare system.We randomly collect data points about different body parts and exam modalities, resulting in multiple domains under different data distributions.The distribution of the domain is illustrated in Figure 1.The collected data are processed with automatic de-identification, followed by a thorough human inspection to verify that no private information about patients or doctors is disclosed or hinted at in the text.We also employ an offline paraphrasing tool (Damodaran, 2021) to revise the text data collected from the second source.The paraphrasing is followed by another human inspection to filter out any unqualified records where the rewriting deviates significantly from the original report.The resulting data set can be considered "synthesized" and containing no privacy information but retaining realistic clinical conditions as the source data.</p>
<p>For each evaluation task, we split the data in a ratio of 7:1:2 for train/validate/test.</p>
<p>Expert Labels and Evaluation Tasks</p>
<p>Sentence-level Labels</p>
<p>NLU Tasks Identifying sentences with certain diagnostic properties is a practical use case in a real-world healthcare system.For example, identifying if a report sentence implies an abnormal finding about the patient or not.To test if language models can capture the medical semantics of single sentences, we first include abnormal sentence identification into our evaluation pool.We use the sentence-level corpora and the associated abnormality labels to classify abnormal sentences.</p>
<p>Ambiguous sentences appear in radiology reports mainly due to the use of medical jargon whose meaning is different from daily usage, contradictory findings within the same sentence, or grammatical errors that mislead interpretation (He et al., 2023b).Accurate identification of such sentences is crucial, as they impede patients' comprehension of diagnostic decisions, leading to potential treatment delays and irreparable consequences.To the best of our knowledge, as a novel task proposed recently, current LMs may not readily include such a task into its pre-training stage.Therefore, evaluation of this task allows us to investigate how language models perform when the tasks are unfamiliar.We leverage the report sentences and their associated ambiguous labels, and our medical team re-examined and re-annotated the labels for ambiguous sentences.</p>
<p>NLG Task Expanding beyond the previous ambiguous sentence identification, we include the task of sentence disambiguation as a sentence-level generation task.Proposed in He et al. (2023b), sentence disambiguation aims to rewrite an ambiguous sentence in a way that its diagnostic findings are more explicitly expressed while at the same time, the original content of the report sentence is faithfully maintained.This requires rewritten sentences to avoid the change of the original pathological findings or introducing new findings.Similar to ambiguous sentence identification, disambiguated rewriting presents a challenging generation task, not only because both the data and task formulation are not likely to be covered in the pre-training stage of existing language models, but also because there are two objectives that need to be optimized at the same time.In this task, based on the ambiguous sentences and their associated diagnostic labels, our medical team manually created the dis-ambiguated rewritings as the ground truth.</p>
<p>Document-level Labels</p>
<p>NLU Task To access if language models can capture the key findings of a radiology report, we consider Report Codes Prediction as an evaluation task.This task involves categorizing reports into specific diagnostic codes based on the mentioned pathological findings.Therefore, different from sentencelevel abnormality identification, this task requires a multi-label multi-class classification.Our medical team manually labels the medical codes of each report.Detailed information regarding the codes is provided in Table 1.More details about the expertlabeling procedure are provided in Appendix A.</p>
<p>NLG Task Automatic medical summarization plays a crucial role in healthcare literature, by providing concise summaries, it saves time and manual effort for medical professionals when assessing the effectiveness of medical interventions.In our evaluation, we include report summarization as a task to assess the generation capability of language models.The impression section in each report serves as a summary that captures the supportive evidence for clinical decisions.To ensure data quality, we conduct a manual inspection of all collected <report, impression> pairs, filtering out any pairs where the impression does not align with the corresponding report.It is worth noting that the curated parallel data of reports and summaries provide valuable support for future work in related fields.</p>
<p>Evaluated Language Models</p>
<p>We evaluate two categories of language models with MEDEVAL5 : (1) domain-adapted pre-trained language models (Adapted PLMs), which are trainable models adapted on certain domain data, and (2) general-purpose large language models (Prompted LLMs) which are used by zero/few-shot prompting.</p>
<p>Domain-adapted PLMs</p>
<p>Recent literature found it is effective to adapt pretrained language models to certain narrow domains such as biomedical text by a continued training step on domain-specific data (Gururangan et al., 2020a), following which we take a pre-trained (or generally adapted) language model, and test it on the MEDEVAL test set.We also fine-tuned the models from this category to customize it to fit the tasks of MEDEVAL, with their corresponding training data.</p>
<p>For NLU tasks at both levels, we follow the evaluation setting of Yan et al. (2022) and investigate how: BERTbase (Devlin et al., 2018), RadBERT (Yan et al., 2022), BioBERT (Lee et al., 2020), clinicalBERT (Huang et al., 2019), BlueBERT (Peng et al., 2019), and BioMed-ReBERTa-base (Gururangan et al., 2020b) perform on MEDEVAL.More details about those models are included in Section 2.</p>
<p>For the sentence-level NLG task, we follow the the setting of He et al. (2023b) by evaluating: (1) style transformer (Dai et al., 2019) which transfers the original sentence into a less ambiguous style, (2) PPLM (Dathathri et al., 2020) which adds perturbation to LM to move the (re-)generation towards a less ambiguous direction, (3) DEPEN (He et al., 2021a) which is built upon PPLM and only re-generates ambiguous tokens detected before, and (4) MedDEPEN (He et al., 2023b), a biomedical-adapted DEPEN by introducing contrastive pre-training.Each work has included a transformer-based language model.We refer the reader to the original papers for more details.</p>
<p>For the document-level NLG task, we follow the setting of Yan et al. (2022) and customize previously adapted BERT-based models used before for the summarization task.</p>
<p>Prompted LLMs</p>
<p>We include the following general-purpose large language models to test their generalization in the healthcare domain: (1) GPT3: GPT-style large language models with 175B parameters (Brown et al., 2020).We use davinci-003.(2) Chat-GPT6 : GPT-style large language model trained with Reinforcement Learning from Human Feedback (RLHF).We use GPT3.5-turbo.(3) Vicuna-7B (Chiang et al., 2023): The finetuned version of LLaMa-7B (Touvron et al., 2023a) with 70K user-shared ChatGPT conversations, which is capable of generating more detailed and well-structured answers.(4) BioMedLM7 : a 2.7B GPT-style language model trained exclusively on biomedical abstracts and papers from The Pile (Gao et al., 2020).</p>
<p>We prompt those LLMs under zero/few-shot settings, where we randomly select the examples from the training set of each task to compose prompts 5  times.We report the test results with the prompts which obtain optimal results on the validation set.See Appendix C for more details.</p>
<p>Evaluation Metrics</p>
<p>For NLU tasks, we report classification metrics including accuracy and F1 scores.For NLG tasks, we report BLEU and ROUGE scores with respect to the ground truths labeled by our medical team.For sentence-level generation tasks (i.e., rewriting), to evaluate the objective of disambiguation, we follow the setting of He et al. (2023b) to report accuracy decrements of the ambiguity classifier (∆Acc am ) as the disambiguation metric.To evaluate the rewriting fidelity, we report the content distortion score, which is defined as the decrement of the accuracy from an abnormality classifier (∆Acc ab ).Therefore, higher distortion indicates a lower content fidelity.</p>
<p>Results and Discussion</p>
<p>In this section, We first present the results for sentence-level NLU tasks (Ambiguity Identification and Abnormality Identification) in Table 2, then sentence-level NLG task (Disambiguated Rewriting) in Table 3, finally document-level NLU (Code Prediction) and NLG (Report Summarization) tasks in Table 4 and Table 5.</p>
<p>The Effectiveness of Instruction Tuning While BioMed LM is the first large language model customized for the biomedical domain, we observe that it does not outperform adapted PLMs and most prompted LLMs in the majority of tasks.Particu- larly, BioMed LM has been found to be the weakest performer in tasks such as sentence identification, disambiguated rewriting, and report summarization.We would like to highlight that, unlike other prompted LLMs such as ChatGPT, GPT-3, and Vicuna, BioMed LM lacks an Instruction Tuning step in its model training.This omission significantly impacts BioMed LM's ability to generate replies following the instructions from the given options.</p>
<p>In zero-shot NLU tasks, only 40% of the test cases receive appropriate responses at the sentence level and the qualified rate drops to less than 1% at the document level (so we did not report the results in Table 4).In few-shot report codes prediction, the document-based prompts often exceed BioMed LM's maximum threshold of 1024 tokens, resulting in query errors.In generation tasks, BioMed LM keeps returning irrelevant text.Our manual inspection reveals that the outputs rarely adhere to the given instructions in prompts or address the queries.This is further supported by the remarkably low BLEU or ROUGE scores in Table 3 and Table 5.We provide more discussions in Appendix D.1.These findings underscore the significance of Instruction Tuning and establish it as a crucial step when adapting prompted LLMs for specialized applications like healthcare decision-making.</p>
<p>In the remainder of this section, we focus on addressing more intriguing questions based on average performance across a range of baselines (e.g., the average accuracy of adapted PLMs versus prompted LLMs), where we exclude BioMed LM from further consideration.</p>
<p>Discussion on Task Type and Granularity In this section, we aim to determine the proficiency of language models at different levels and tasks.To achieve this, we begin by calculating the average accuracy scores of all adapted PLM baselines and  First, examining the results presented in Figure 3, we observe that both adapted PLMs and prompted LLMs perform relatively similarly across different data levels.However, it becomes apparent that adapted PLMs outperform prompted LLMs in NLU tasks, no matter whether it's on the sentence or document level.This suggests that fine-tuning provides a more effective means of injecting specific knowledge about narrow domains or tasks.On the other hand, consistently superior performance of prompted LLMs compared to adapted PLMs is observed in generation tasks, at both the sentence and document levels.This can be attributed to multiple advantages of large-scale pre-training such as a larger model size or the benefits HFRL in the LLMs we utilized, such as ChatGPT.These models demonstrate a capability to generate language that is more akin to human-like expressions, thereby achieving better generation scores.These imply that fine-tuning PLM models can be a viable choice for NLU tasks, while prompting-based LLMs may be more suitable when healthcare professionals require an AI writer to help their work.Common v.s.Rare Domains In Table 6, we explore the impact of the domain on language models in the healthcare field.We compute the average accuracy of adapted PLMs and prompted LLMs in abnormality identification v.s.ambiguity identification.We consistently observe higher performance from both adapted PLMs and prompted LLMs when working with data from the chest domain compared to miscellaneous domains.This superior performance can be attributed to the similarity between the chest data we tested and the pre-training data of the language models -chestrelated healthcare text is widely available in the public domain and can be included in the training corpus of PLMs.Similarly, LMs are expected to excel in abnormality identification tasks, which are a common research topic in current literature.</p>
<p>The most challenging scenario arises when both the data and task are unseen, specifically in the case of ambiguous identification within the miscellaneous domain.In such situations, there are limited or no examples available in the public domain.Therefore, querying language models with (zero) few-shot learning proves to be less effective.</p>
<p>Family of LLMs and Few Shot Learning</p>
<p>In this analysis, we examine the behavior of different language models (LLMs) with varying numbers of shots across different tasks.We calculate the average accuracy of ChatGPT, GPT3, and Vicuna-7B in NLU tasks and the average BLEU scores in NLG tasks.Additionally, we consider the average performance achieved in zero-shot or few-shot settings (Table 7).From the table, it is evident that in most cases, providing additional examples assists LMs in making predictions for NLU tasks.However, in NLG tasks, no consistent trend is observed, indicating the need for further research to discover optimal prompts.We do not observe a clear advantage of any specific LLM family over others, suggesting that the choice of the optimal LLM family for a given task may vary on a case-by-case basis.</p>
<p>Conclusion</p>
<p>We introduce MEDEVAL, a multi-task, multi-level, and multi-domain medical benchmark designed to serve as a comprehensive testbed for advanced language models.Through extensive evaluation experiments, we thoroughly analyze the capabilities and limitations of current LLMs in tackling various medical tasks, such as the effectiveness of instruction tuning and the performance disparities between adapted and prompted LMs in NLU and NLG tasks.Our findings provide valuable insights and serve as a handbook for future research in utilizing LLMs to enhance healthcare practices.</p>
<p>Limitations</p>
<p>In our efforts to provide a comprehensive testbed for current advanced language models, we have included multiple tasks.However, we acknowledge that there may be other tasks of interest that could have been analyzed, such as medical named entity recognition, multi-document report summarization, etc.We plan to expand the range of test tasks in future iterations of the MEDEVAL benchmark.We'd like to note that due to computing constraints, we were unable to evaluate some large language models such as Vicuna-60B or OPT-175B (Zhang et al., 2022).Our evaluation was focused on popular large language models with reasonably large sizes.In future work, we consider addressing this limitation by incorporating these larger language models into our testbed.</p>
<p>Ethics Statement</p>
<p>Our data underwent a rigorous de-identification process and were carefully reviewed by human evaluators following strict anonymization criteria.Moreover, the collection of data from real-world healthcare systems has received the necessary IRB approval (DC VAMC protocol 1736644, VASDHS IRB protocol 200086), ensuring compliance with ethical standards.To further ensure ethical usage, before inputting the data into large language models, including commercial ones like ChatGPT, we conducted data synthesis and subjected it to additional human inspection.These steps were taken to address any potential ethical concerns associated with the data.</p>
<p>It is important to highlight that the responsible and safe usage of biomedical data is a critical requirement in AI for healthcare, especially in the use case of large language models which are noticed to suffer from different kinds of potential harms (Leino et al., 2019;Lloyd, 2018;He et al., 2021b;Xu et al., 2022;He et al., 2022) and weaknesses (Ribeiro et al., 2020;Stuart-Ulin, 2018;He et al., 2023a).Therefore, we strongly recommend that our benchmark be used in conjunction with expert auditing to ensure the highest level of safety in real-world applications.</p>
<p>A Data Preparation</p>
<p>A.1 Preprocess of sentence-level corpora OpenI In the original OpenI release, many non-sensitive terms were incorrectly masked as "xxxx" by the de-identification software described in (Demner-Fushman et al., 2016).Our medical team manully fills in the missing information based on the context of the reports and additional information associated with it.</p>
<p>A.2 Preprocess of the document-level corpra</p>
<p>Manual De-identification Criteria We hire human reviewers to manually inspect the reports after the automatic de-identification tools.According to our criteria, we will discard a datapoint if it contains • real names of the patient, or the healthcare professions,</p>
<p>• home address, working address, or locations of the patient or healthcare professionals.</p>
<p>• contact information (e.g., phone number) about the patient, or healthcare professionals.</p>
<p>In the second round of human inspection about de-identification, 99.8% of the data are well deidentified in the automatic stage, and 0.2% of the data are discarded.</p>
<p>Diseases Code Preparation Before experts examine the disease codes of a report, we first group data by their resources.For reports sourced from MIMIC-CXR, we employ CheXpert (Irvin et al., 2019), a rule-based automatic labeler to generate pseudo-labels for the diagnostic codes.Each label has three options: positive, negative, and unknown.In the case of reports from the second source, we customized a rule-based automatic labeler called pyConText NLP8 , which generates pseudo-codes according to the keywords of each domain.In the last step, our medical team manually reviews, correct the codes where there is a conflict (e.g., positive "no finding" appears with certain positive diseases), and writes down the correct codes for each report.</p>
<p>A.3 Medical Team</p>
<p>Our medical expert team consists of 4 members, including 2 senior board-certified radiologists with more than 15 years of experience in healthcare and a doctor who has more than 10 years of experience serving as a PI of medical research.We follow standard labeling practices, involving multiple rounds of iterative review by different experts until Cohen's kappa coefficient reaches 0.85.Any remaining disagreements are collectively resolved.</p>
<p>B Implementation details</p>
<p>Models All adapted transformers are implemented based on the HuggingFace9 libraries.All prompted LLMs are implemented with its original release in their official webpage or GitHub.</p>
<p>The model sizes are listed in the Section 2.  The configurations for fine-tuning adapted languages models are: learning rate=0.0001,weight decay=0, optimizer=Adam, training epoch=10, batch size=64, max length=256, All codes are implemented with Python3.8 and PyTorch1.7.1 with CUDA10.1.operated on Ubuntu (16.04.7 LTS) server with 2 NVIDIA GeForce GTS A6000 GPUs.Each has memory of 49GB.</p>
<p>Experiment Hyperparameters</p>
<p>C Prompts used for Querying LLM C.1 Number of examples in few-shot settings</p>
<p>In our study, we maintain a balanced and unbiased approach by setting the number of examples equal to the number of classes when prompting the language models (especially in NLU tasks).Additionally, we explore alternative numbers of examples, such as 1, 3, 5, 7, or 9.The NLU experiment results presented in our paper utilize a 2-shot approach, while the NLG results employ a 3-shot approach.</p>
<p>"ambiguous" or "unambiguous", without saying anything else.Sentence: {} Label:</p>
<p>Similarly, we will add more examples for the prompts built for more than two-shot situations.For NLG tasks, we have the following prompts:</p>
<p>Zero-shot Rewriting tasks Here is a task to rewrite ambiguous sentences to be less ambiguous.</p>
<p>Given a sentence in a radiology report, written by a radiologist, please rewrite it to be more explicit about the diagnostic decision reflected in the sentence, however, maintain the main meaning of the original sentence.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable;</p>
<p>(2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Now given a new sentence, answer me with its rewrite, without saying anything else.</p>
<p>Sentence: {}.Rewrite:</p>
<p>Three-shot Rewriting tasks Here is a task to rewrite ambiguous sentences to be less ambiguous.</p>
<p>Given a sentence in a radiology report, written by a radiologist, please rewrite it to be more explicit about the diagnostic decision reflected in the sentence, however, maintain the main meaning of the original sentence.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable;</p>
<p>(2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.the joint spaces are not noticeable.there is a deformity of the hallux valgus.the angle of pitch is within normal limits.three views of the left foot show no fracture dislocation foreign body pathologic calcification or soft tissue swelling.the joint spaces are not noticeable.hallux valgus minor.the angle of pitch is within normal limits.</p>
<p>Summary: 1 bilateral hallux valgus deformities.2 no acute osseous abnormalities.ssn7312ptc1job no.1157.Report: there has been no significant change in the patient's condition since the patient's exam which was earlier in the day.the heart size is normal and the lungs are free of disease.on the left base is again noted a small granulom.Summary: for a active disease in the chest there is no evidence.Report: the cardiovascular-mediastinal silhouette is normal.it's not unusual for pulmonary vessels.the bones appear to be intact.Summary: chest x-rays within normal ranges.no change in date 2010-06-28.Now given a new report, answer me with its summary only, without saying anything else.Report: {}.Summary: D More Discussions D.1 Case Studies of BioMed LM BioMed LM, a GPT-style LLM trained on PubMed, lacks instruction fine-tuning in its training process.As a result, the model's outputs often lack a unified format, making it challenging to conduct follow-up statistical evaluations.To assess the model's performance, we introduce the concept of a qualified rate, which represents the proportion of test cases where the model provides a relevant prediction for the given task, such as identifying abnormalities by including only one of the "normal" or "abnormal" in the response.We report the qualified rate here: Sentence Report Zero-shot NLU 40% 1% Few-shot NLU 92% 85% In zero-shot settings, BioMed LM struggles to adhere to the instructions in the prompt, generating outputs that are freestyle and not aligned with the expected format.In a few-shot setting, particularly in document-level tasks, the length of the prompts exceeds the maximum input capacity of BioMed LM (1024 tokens).To address this issue, we employ two solutions: (1) chunking the input into 1024-token segments and (2) discarding test cases that exceed the maximum length.However, both solutions have drawbacks.The chunked uncompleted input approach leads to more "freestyle" outputs, resulting in a lower qualified rate.On the other hand, discarding examples introduces a high variance in the statistics.We show some examples of the "freestyle" outputs at the end of this section.</p>
<p>Considering these challenges, we treat BioMed LM as an exception and exclude it when analyzing results across different categories of LMs.Nonetheless, we emphasize the importance of further investigation into biomedical LLMs for future research.</p>
<p>Example Output of BioMed LM We show some examples of unqualified "free-style" outputs from BioMed LM in the following:</p>
<p>Sentence Level, NLU-Zero-shot Note that we expect the model to return a single word from "normal", "abnormal", "ambiguous", or "unambiguous".However, BioMed LM returns the following output: Prompt: Given a sentence from a radiology report, written by a radiologist, please tell if the following sentence indicates "normal" or "abnormal" findings.Sentence: median sternotomy wires appear intact.Label: Returned Text: median sternotomy wires appear intact.</p>
<p>Sentence Level, NLU-Two-shot In this case, we expect the model to return a single word "normal", "abnormal", "ambiguous", "unambiguous".However, the output from BioMed is: Prompt: Here is a task to classify ambiguous sentences.Given a sentence in a radiology report, written by a radiologist, please tell if it is ambiguous.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable;</p>
<p>(2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Here are 2 examples.Sentence: lungs are unremarkable.Label: ambiguous.Sentence: unchanged chronic appearance of the left lung.Label: unambiguous.Now given a new sentence, answer me with "ambiguous" or "unambiguous".Sentence: findings: there is a cystic, approximately 3. 6 x 2. 6 x 6.</p>
<p>6 cm, mass with its epicenter in the left submandibular region, with extension into the left submental space, left sublingual space, left base of tongue, and superiorly into the left peripharyngeal space.Label: Returned Text: cystic mass.Sentence: there is a cystic, approximately 3. 6 x 2. 6 x 6. 6 cm, mass with its epicenter in the left submandibular region, with extension pathologic calcification or soft tissue swelling.</p>
<p>the joint spaces are not noticeable.there is a deformity of the hallux valgus.the angle of pitch is within normal limits.three views of the left foot show no fracture dislocation foreign body pathologic calcification or soft tissue swelling.the joint spaces are not noticeable.hallux valgus minor.the angle of pitch is within normal limits.</p>
<p>Summary: 1 bilateral hallux valgus deformities.2 no acute osseous abnormalities.ssn7312ptc1job no.1157.Report: there has been no significant change in the patient's condition since the patient's exam which was earlier in the day.the heart size is normal and the lungs are free of disease.on the left base is again noted a small granulom.Summary: for a active disease in the chest there is no evidence.Report: right and left feet have severe hammertoes.calcaneus on the left shows an achilles spur.</p>
<p>the severe hallux valgus configuration of the feet is observed.a dominant finding was the degree of luxation and deviation of first metatarsal proximal phalangeal joint.. Summary: Returned Text: 1 bilateral hammertoes. 2 no acute osseous abnormalities.ssn7312ptc1job no.1157.Report: the patient has been seen in the clinic for a routine checkup.The patient has</p>
<p>E More Results</p>
<p>We considered popular LLMs such as GPT3, Chat-GPT, and Vicuna-7B (the instruction finetuned LLaMa) in the main context.But we also keep in mind that LLMs are rapidly developing and we are following up by adding the newest models into our evaluation.In Table 10, Table 11, Table 12, and Table 13, we provide more results with GPT410 , LLaMa2 (Touvron et al., 2023b), LLaMa2-chat (Touvron et al., 2023b), GPT-NeoX citegpt-neox-20b, PMC-LLaMa (Wu et al., 2023), BioGPT (Luo et al., 2022) etc, which align with the findings already in the paper.We will keep working on followups and add more evaluation results here (and also Table 13: More results on document-level NLG tasks.</p>
<p>Figure 1: A summary of the multi-level multi-task and multi-domain medical benchmark (MEDEVAL).Classification tasks are highlighted in green and generation tasks are highlighted in red.</p>
<p>Figure 3 :
3
Figure 3: Average performance of adapted PLM and prompted LLM on different tasks and at different levels.</p>
<p>The configurations of querying LLMs are listed as follows:</p>
<p>Table 1 :
1
Report disease codes covered in MEDEVAL.
Disease Codes of MEDEVALEnlarged Cardiomediastinum CardiomegalyLung OpacityLung LesionEdemaConsolidationAtelectasisPneumothoraxPleural EffusionPleural Other Support DevicesPneumoniaDislocationOsteonecrosisFractureGoutMetatarsus Primus VarusGasSwellingPsoriasisEnthesopathyHammer ToeOsteomyelitisMassArthritisPes PlanusRheumatoidCppdHardwareErosionPes CavusCoalitionSubluxationFractureNoduleRuptureHallux ValgusPneumoniaArthritisNo Finding</p>
<p>Table 2 :
2
Evaluation (accuracy)over two categories of PLMs on abnormality identification and ambiguity identification tasks (sentence-level NLU).Bold: the highest performance.Underlined: the lowest.
Models Adapted PLMs with Fine-Tuning ClinicalBERT BERT RadBERT BioBERT BlueBERTChest Abnormality ↑ Ambiguity ↑ Abnormality↑ Ambiguity ↑ Miscellaneous Domains 0.9791 0.9607 0.9749 0.9893 0.9794 0.9869 0.9640 0.9813 0.9791 0.9862 0.9614 0.9743 0.9874 0.9588 0.9736 0.9809 0.9803 0.9867 0.9601 0.9775BioMed-ReBERTa0.95690.97580.97760.9788zero-shot ChatGPT0.92770.65840.88800.5206few-shot ChatGPT0.94980.58310.90990.5354zero-shot GPT-30.87620.87420.82430.6448LLMs Prompted byfew-shot GPT-30.92150.83200.90540.6371Zero/Few Shotzero-shot Vicuna-7B0.69870.21300.72610.3739few-shot Vicuna-7B0.80710.07850.81660.2844zero-shot BioMed LM0.66790.34850.62730.3726few-shot BioMedLM0.79050.68040.76380.6804Adapted PLMs with Fine-TuningModel Style Transfer PPLM DEPEN MedDEPENDisambiguation ∆Acc am ↑ 0.5010 0.3860 0.5000 0.4960Chest Content Distortion ∆Acc ab ↓ 0.0510 0.1150 0.0520 0.0320BLEU4 ↑ 27.92 57.88 60.48 57.88Miscellaneous Domains Disambiguation ∆Acc am ↑ Content Distortion ∆Acc ab ↓ 0.3110 0.2350 0.2700 0.1460 0.3530 0.0470 0.4810 0.0090BLEU4 ↑ 31.17 60.14 67.86 68.88zero-shot ChatGPT few-shot ChatGPT0.6337 0.5875-0.0297 0.000060.73 68.920.6539 0.63700.1483 0.081560.64 67.98LLMs Prompted by Zero/Few Shotszero-shot GPT-3 few-shot GPT-3 zero-shot Vicuna-7B few-shot Vicuna-7B0.6799 0.6139 0.6230 0.5311-0.0132 0.0000 0.0693 0.191461.78 76.33 66.65 62.550.8022 0.7146 0.6771 0.48110.1528 0.0607 0.3653 0.273961.05 77.09 64.64 63.72zero-shot BioMed LM0.22110.006623.400.15280.141624.11few-shot BioMed LM0.1386-0.026223.300.39330.364023.48</p>
<p>Table 3 :
3
Evaluation</p>
<p>on disambiguated rewriting Tasks (sentence-level NLG).We report the disambiguation score, content distortion score (where smaller content distortion indicates higher fidelity), and BLEU4 score.Bold: the best performance.Underlined: the worst.</p>
<p>Table 4 :
4
avg EMR ↑ avg Accuracy avg EMR ↑ avg Accuracy ↑ avg EMR ↑ Evaluation on report codes prediction Task (Document-level NLU).We report the average accuracy over all classes of diseases and the exact match rate (EMR) between predictions and labels.Bold: the highest performance.Underlined: the lowest.
Chest avg Accuracy ↑ Adapted PLMs Model BERT 0.8779 RadBERT 0.8785 with BioBERT 0.8782 ClinicalBERT 0.8780 Fine-Tuning BlueBERT 0.8843 BioMed-ReBERTa 0.85790.2263 0.1941 0.2400 0.2341 0.2380 0.14150.9754 0.9710 0.9750 0.9731 0.9703 0.9692Foot0.5635 0.4910 0.5617 0.5372 0.5939 0.4631Ankle 0.9787 0.9773 0.9801 0.9798 0.9761 0.97520.6141 0.5710 0.6266 0.6224 0.5752 0.5522zero-shot ChatGPT0.52720.10240.96210.44490.96600.4491few-shot ChatGPT0.64850.19510.96210.41860.96900.4875LLMs Prompted by Zero/Few Shotszero-shot GPT-3 few-shot GPT-3 zero-shot Vicuna-7B few-shot Vicuna-7B0.2744 0.8160 0.8216 0.82280.1424 0.1805 0.0672 0.07820.9621 0.9617 0.9617 0.51560.4449 0.4186 0.4186 0.10410.1887 0.9691 0.9691 0.91220.6273 0.4908 0.4908 0.4153few-shot BioMed LM0.83200.06890.96670.46640.97190.4980ModelBERTMiscellaneous Domains ROUGE-1 ↑ ROUGE-2 ↑ ROUGE-L↑ Sum ↑ BLEU4↑ 20.48 7.46 18.57 46.52 30.28RadBERT20.967.6318.9047.5030.77Adapted PLMs with Fine-TuningBioBERT ClinicalBERT BlueBERT BioMed-ReBERTa20.79 21.22 20.83 21.197.62 7.85 7.78 7.8518.78 19.18 18.90 19.1447.19 48.26 47.51 48.1830.49 30.81 30.93 30.88zero-shot ChatGPT24.647.9722.0554.6632.30LLMs Prompted by Zero/Few Shotsfew-shot ChatGPT zero-shot GPT-3 few-shot GPT-3 zero-shot Vicuna-7B few-shot Vicuna-7B24.96 24.06 24.73 20.93 21.428.43 8.67 9.14 6.96 7.2622.23 21.52 22.16 18.71 19.2255.62 54.24 56.03 46.60 47.9035.43 24.43 34.72 20.94 22.00zero-shot BioMed LM17.705.1116.4939.3015.43few-shot BioMed LM12.153.5011.2226.8720.27</p>
<p>Table 5 :
5
Evaluation on report summarization task (Document-level NLG).We report the Rouge scores and BLEU4 scores.</p>
<p>Bold: the highest performance.Underlined: the lowest.</p>
<p>Table 6 :
6
Average accuracy of adapted PLMs and prompted
ModelAbnormality ↑ Chest Miscellaneous Chest Miscellaneous Ambiguity ↑Adapted PLM 0.97580.95260.98360.9621Prompted LLM 0.86350.84510.53990.4893LLMs in NLU over different domainsprompted LLM baselines in sentence identificationtasks. Similarly, we compute the average accuracyof adapted PLM and prompted LLM baselines in adocument-level code classification task.</p>
<p>Table 7 :
7
Average accuracy and BLEU of various LM families with zero/few shots.
Model Family# shotNLU (Accuracy↑ ) Individual Average Individual Average NLG (BLEU↑ )ChatGPT0-shot Few-shot0.78 0.790.7951.22 43.0847.15GPT-30-shot Few-shot0.66 0.860.7649.08 62.7155.90Vicuna-7B0-shot Few-shot0.71 0.750.7350.74 49.4250.08Average0-shot Few-shot0.72 0.8050.35 51.74</p>
<p>Table 8 :
8
Configuration of ChatGPT and GPT-3</p>
<p>Here are three examples.
identifie.Diagnostic:Abnormal.Rewrite: Cardiomegaly and hiatal hernia .Without an acute abnormality identified.Now given a new sentence, answer me withits rewrite, without saying anything else.Sentence: {}. Rewrite:C.4 Document-level TasksFor NLU tasks, we use the following prompts:Zero-shot Summarization Tasks Here is asummarization task. Given a radiologyreport written by a radiologist, pleasewrite a summary of the report. Answerme with its summary only, without sayinganything else. Report: {}. Summary:Three-shot Summarization Tasks Here is asummarization task. Given a radiologyreport written by a radiologist, pleasewrite a summary of the report. Here are5 examples.Report:clinical history 62-year-oldmale with bilateral bunions.pleaseperform weighted views.a lateralweight bearing view of bilateral feetas well as a lateral non-weight bearingview of bilateral feet are studied.three views of the right foot showno fracture dislocation foreign bodypathologic calcification or soft tissueswelling.Sentence:Lungs are unremarkable.Diagnostic: Normal. Rewrite: Lungs arenormal.Sentence: The lung volumes are low normal.Diagnostic: Normal. Rewrite: The lungvolumes are in the lower range of normallimit.Sentence:Cardiomegaly and hiatalhernia without an acute abnormality</p>
<p>Table 9 :
9
Qualified Rate of BioMed LM on NLU tasks</p>
<p>We use domain to describe data sets that are different in distribution, caused by the modality of the examination (e.g.,
We use "ground truth labels" to represent both discriminative labels for NLU and golden sentences for NLG tasks.
  4  See description of the medical team in Appendix A.3.
The results presented are based on models evaluated as of the time of paper acceptance. We've added more results (e.g., on GPT4, LLaMa2, etc.) and will continue to include the newest ones in the Appendix E.
https://openai.com/blog/chatgpt
https://crfm.stanford.edu/2022/12/15/ biomedlm.html
https://github.com/chapmanbe/pyConTextNLP
https://huggingface.co/models
https://openai.com/gpt-4 in our Github repository):
AcknowledgmentsThe authors would like to thank NVIDIA corporation for the award of two RTX A6000 GPUs to CNH through the Applied Research Accelerator Program.C.2 Templates Used in PromptingFor zero-shot settings we design prompts using the following template:We The options for the placeholder are:• TASK: {abnormal identification, ambiguous identification, rewrite an ambiguous sentence to be less ambiguous, summarization }• LEVEL NMAE: {sentence, report}.• TASK CONTENT:{Tell if the sentence indicates abnormal findings or not, Tell if it is ambiguous, a sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable;(2) contradictory findings in the same sentence;(3) misleading grammatical errors such as no period between full sentences, , Observed pathology findings, The summary }• N: {1, 2, 3, 4, 5, 7, 9}In the following sections, we provide some examples of the prompts we use to query LLM.C.3 Sentence-Level TasksFor sentence-level tasks, there are the following different types of prompts for NLU tasks: A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable; (2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Now given a new sentence, answer me with "ambiguous" or "unambiguous", without saying anything else.Sentence: {} Label: Two-shot Classification for Ambiguity: Here is a task to classify ambiguous sentences.Given a sentence in a radiology report, written by a radiologist, please tell if it is ambiguous.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable; (2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Here are 2 examples.Sentence: lungs are unremarkable.Label: ambiguous.Sentence: unchanged chronic appearance of the left lung.Label: unambiguous.Now given a new sentence, answer me with into the Sentence Level, NLG-Zero-shot Here we show an unqualified example in the ambiguous rewriting task, where the output does not follow the instruction of "without saying anything else".Prompt: Here is a task to rewrite ambiguous sentences to be less ambiguous.Given a sentence in a radiology report, written by a radiologist, please rewrite it to be more explicit about the diagnostic decision reflected in the sentence, however, maintain the main meaning of the original sentence.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable;(2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Now given a new sentence, answer me with its rewrite, without saying anything else.Sentence: aorta appears unchanged as compared to the study.Diagnostic: Abnormal.Rewrite: Returned Text: \... aorta appears unchanged as compared to the study.----------------------------------------In this unqualified example, the BioMed LM does not follow the instruction and just output an irrelevant sentence.Prompt: Here is a task to rewrite ambiguous sentences to be less ambiguous.Given a sentence in a radiology report, written by a radiologist, please rewrite it to be more explicit about the diagnostic decision reflected in the sentence, however, maintain the main meaning of the original sentence.A sentence is defined to be ambiguous because of (1) medical jargon with meanings different from everyday general usage, such as unremarkable; (2) contradictory findings in the same sentence; (3) misleading grammatical errors such as no period between full sentences.Now given a new sentence, answer me with its rewrite, without saying anything else.Sentence: apparent scarring within the lingula otherwise unremarkable.Diagnostic: Abnormal.Rewrite:---------------------------------------Document Level, NLU-Zero-shot In this task, we expect the output to have a prediction for every disease.However, BioMed LM just repeats the disease code as the output.Prompt: Here is a task to classify the observations of the chest reports.Given a radiology report written by a radiologist, please predict if every one of the following 14 observations is positive, negative, or unknown.
Construction of the literature graph in semantic scholar. Waleed Ammar, Dirk Groeneveld, Chandra Bhagavatula, Iz Beltagy, Miles Crawford, Doug Downey, Jason Dunkelberger, Ahmed Elgohary, Sergey Feldman, Vu Ha, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies20183Industry Papers</p>
<p>Abstract meaning representation for sembanking. Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, Nathan Schneider, Proceedings of the 7th linguistic annotation workshop and interoperability with discourse. the 7th linguistic annotation workshop and interoperability with discourse2013</p>
<p>Iz Beltagy, Kyle Lo, Arman Cohan, arXiv:1903.10676Scibert: A pretrained language model for scientific text. 2019arXiv preprint</p>
<p>Chatgpt and the future of medical writing. Som Biswas, 2023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Detecting beats in the photoplethysmogram: benchmarking open-source algorithms. Kevin Peter H Charlton, Elisa Kotzen, Philip J Mejía-Mejía, Karthik Aston, Jonathan Budidha, Callum Mant, Joachim A Pettit, Panicos A Behar, Kyriacou, Physiological Measurement. 438850072022</p>
<p>Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality. </p>
<p>Style transformer: Unpaired text style transfer without disentangled latent representation. Ning Dai, Jianze Liang, Xipeng Qiu, Xuanjing Huang, 10.18653/v1/P19-1601Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019</p>
<p>Parrot: Paraphrase generation for NLU. Prithiviraj Damodaran, 2021</p>
<p>. / Prithivirajdamodaran, Parrot_Paraphraser, </p>
<p>Plug and play language models: A simple approach to controlled text generation. Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, Rosanne Liu, International Conference on Learning Representations. 2020</p>
<p>Preparing a collection of radiology examinations for distribution and retrieval. Dina Demner-Fushman, Marc D Kohli, Sonya E Marc B Rosenman, Laritza Shooshan, Sameer Rodriguez, George R Antani, Clement J Thoma, Mcdonald, Journal of the American Medical Informatics Association. 2322016</p>
<p>Pubmed 200k rct: a dataset for sequential sentence classification in medical abstracts. Franck Dernoncourt, Ji Young Lee, 2017. 2017308</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. Bert2018arXiv preprint</p>
<p>Joakim Edin, Alexander Junge, Jakob D Havtorn, Lasse Borgholt, Maria Maistro, Tuukka Ruotsalo, Lars Maaløe, arXiv:2304.10909Automated medical coding on mimiciii and mimic-iv: A critical review and replicability study. 2023arXiv preprint</p>
<p>Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, arXiv:2101.00027The pile: An 800gb dataset of diverse text for language modeling. 2020arXiv preprint</p>
<p>Dr. llama: Improving small language models in domain-specific qa via generative data augmentation. Zhen Guo, Peiqi Wang, Yanwei Wang, Shangdi Yu, arXiv:2305.078042023arXiv preprint</p>
<p>Sumpubmed: Summarization dataset of pubmed scientific articles. Vivek Gupta, Prerna Bharti, Pegah Nokhiz, Harish Karnick, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop2021</p>
<p>Don't stop pretraining: Adapt language models to domains and tasks. Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, Noah A Smith, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020a</p>
<p>Don't stop pretraining: Adapt language models to domains and tasks. Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, Noah A Smith, Proceedings of ACL. ACL2020b</p>
<p>Detect and perturb: Neutral rewriting of biased and sensitive text via gradient-based decoding. Zexue He, Bodhisattwa Prasad Majumder, Julian Mcauley, 10.18653/v1/2021.findings-emnlp.352Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational Linguistics2021a</p>
<p>Detect and perturb: Neutral rewriting of biased and sensitive text via gradient-based decoding. Zexue He, Bodhisattwa Prasad Majumder, Julian Mcauley, Findings of the Association for Computational Linguistics: EMNLP 2021. 2021b</p>
<p>Zexue He, Marco Tulio Ribeiro, Fereshte Khani, arXiv:2305.17804Targeted data generation: Finding and fixing model weaknesses. 2023aarXiv preprint</p>
<p>Controlling bias exposure for fair interpretable predictions. Zexue He, Yu Wang, Julian Mcauley, Bodhisattwa Prasad Majumder, 10.18653/v1/2022.findings-emnlp.431Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab Emirates2022Association for Computational Linguistics</p>
<p>Nothing abnormal": Disambiguating medical reports via contrastive knowledge infusion. Zexue He, An Yan, Amilcare Gentili, Julian Mcauley, Chun-Nan Hsu, arXiv:2305.08300Proceedings of the 37th AAAI Conference on Artificial Intelligence. the 37th AAAI Conference on Artificial Intelligence2023bArXiv preprint</p>
<p>Zero-shot clinical entity recognition using chatgpt. Yan Hu, Iqra Ameer, Xu Zuo, Xueqing Peng, Yujia Zhou, Zehan Li, Yiming Li, Jianfu Li, Xiaoqian Jiang, Hua Xu, arXiv:2303.164162023arXiv preprint</p>
<p>Clinicalbert: Modeling clinical notes and predicting hospital readmission. Kexin Huang, Jaan Altosaar, Rajesh Ranganath, arXiv:1904.053422019arXiv preprint</p>
<p>Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison. Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201933</p>
<p>Probing biomedical embeddings from language models. NAACL HLT. Qiao Jin, Bhuwan Dhingra, William W Cohen, Xinghua Lu, 2019a. 201982</p>
<p>Pubmedqa: A dataset for biomedical research question answering. Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, Xinghua Lu, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingEMNLP-IJCNLP2019b</p>
<p>Mimic-iv, a freely accessible electronic health record dataset. Lucas Alistair Ew Johnson, Lu Bulgarelli, Alvin Shen, Ayad Gayles, Steven Shammout, Tom J Horng, Benjamin Pollard, Brian Moody, Gow, Li-Wei H Lehman, Scientific data. 10112023</p>
<p>Tom J Alistair Ew Johnson, Nathaniel R Pollard, Greenbaum, Chih-Ying Matthew P Lungren, Yifan Deng, Zhiyong Peng, Roger G Lu, Seth J Mark, Steven Berkowitz, Horng, arXiv:1901.07042Mimic-cxr-jpg, a large publicly available database of labeled chest radiographs. 2019arXiv preprint</p>
<p>Mimic-iii, a freely accessible critical care database. Tom J Alistair Ew Johnson, Lu Pollard, Li-Wei H Shen, Mengling Lehman, Mohammad Feng, Benjamin Ghassemi, Peter Moody, Leo Szolovits, Roger G Anthony Celi, Mark, Scientific data. 312016</p>
<p>Biobert: a pre-trained biomedical language representation model for biomedical text mining. Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang, Bioinformatics. 3642020</p>
<p>Feature-wise bias amplification. Klas Leino, Matt Fredrikson, Emily Black, Shayak Sen, Anupam Datta, International Conference on Learning Representations. 2019</p>
<p>Bias amplification in artificial intelligence systems. Kirsten Lloyd, arXiv:1809.078422018arXiv preprint</p>
<p>BioGPT: generative pre-trained transformer for biomedical text generation and mining. Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, Tie-Yan Liu, 10.1093/bib/bbac409Briefings in Bioinformatics. 6232022Bbac409</p>
<p>Effective transfer learning for identifying similar questions: matching user questions to covid-19 faqs. Namit Clara H Mccreery, Anitha Katariya, Manish Kannan, Xavier Chablani, Amatriain, Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 26th ACM SIGKDD international conference on knowledge discovery &amp; data mining2020</p>
<p>M3: Multi-level dataset for multi-document summarisation of medical studies. Julia Otmakhova, Karin Verspoor, Timothy Baldwin, Antonio Jimeno Yepes, Jey Han Lau, Findings of the Association for Computational Linguistics: EMNLP 2022. 2022</p>
<p>emrqa: A large corpus for question answering on electronic medical records. Anusri Pampari, Preethi Raghavan, Jennifer Liang, Jian Peng, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language Processing2018</p>
<p>Bioread: A new dataset for biomedical reading comprehension. Dimitris Pappas, Proceedings of the Eleventh International Conference on Language Resources and Evaluation. the Eleventh International Conference on Language Resources and Evaluation2018. 2018Ion Androutsopoulos, and Harris Papageorgiou</p>
<p>Transfer learning in biomedical natural language processing: An evaluation of bert and elmo on ten benchmarking datasets. Yifan Peng, Shankai Yan, Zhiyong Lu, Proceedings of the 2019 Workshop on Biomedical Natural Language Processing. the 2019 Workshop on Biomedical Natural Language Processing2019. 2019</p>
<p>Beyond accuracy: Behavioral testing of nlp models with checklist. Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, Sameer Singh, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational Linguistics2020</p>
<p>Biomegatron: Larger biomedical domain language model. Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, Raghav Mani, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)2020</p>
<p>Microsoft's politically correct chatbot is even worse than its racist one. Chloe Rose Stuart-Ulin2018Quartz Ideas31</p>
<p>Does synthetic data generation of llms help clinical text mining?. Ruixiang Tang, Xiaotian Han, Xiaoqian Jiang, Xia Hu, arXiv:2303.043602023arXiv preprint</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Aurelien Azhar, Armand Rodriguez, Joulin, arXiv:2302.13971Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models. arXiv preprint</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023barXiv preprint</p>
<p>Sergios Petridis, Dimitris Polychronopoulos, et al. 2015. An overview of the bioasq large-scale biomedical semantic indexing and question answering competition. George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Dirk Michael R Alvers, Anastasia Weissenborn, Krithara, BMC bioinformatics. 161</p>
<p>Pmc-llama: Towards building open-source language models for medicine. Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie, 2023</p>
<p>Leashing the inner demons: Selfdetoxification for language models. Canwen Xu, Zexue He, Zhankui He, Julian Mcauley, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>An Yan, Zexue He, Xing Lu, Jiang Du, Eric Chang, Amilcare Gentili, Julian Mcauley, Chun-Nan Hsu, arXiv:2109.12242Weakly supervised contrastive learning for chest x-ray report generation. 2021aarXiv preprint</p>
<p>Weakly supervised contrastive learning for chest X-ray report generation. An Yan, Zexue He, Xing Lu, Jiang Du, Eric Chang, Amilcare Gentili, Julian Mcauley, Chun-Nan Hsu, 10.18653/v1/2021.findings-emnlp.336Findings of the Association for Computational Linguistics: EMNLP 2021. Punta CanaDominican Republic. Association for Computational Linguistics2021b</p>
<p>Radbert: Adapting transformer-based language models to radiology. An Yan, Julian Mcauley, Xing Lu, Jiang Du, Eric Y Chang, Amilcare Gentili, Chun-Nan Hsu, Radiology: Artificial Intelligence. 44e2102582022</p>
<p>Biobart: Pretraining and evaluation of a biomedical generative language model. Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, Sheng Yu, 2022</p>
<p>Opt: Open pre-trained transformer language models. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, arXiv:2205.010682022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>