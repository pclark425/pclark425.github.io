<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-787 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-787</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-787</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-21.html">extraction-schema-21</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <p><strong>Paper ID:</strong> paper-265295561</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.10751v2.pdf" target="_blank">ProAgent: From Robotic Process Automation to Agentic Process Automation</a></p>
                <p><strong>Paper Abstract:</strong> From ancient water wheels to robotic process automation (RPA), automation technology has evolved throughout history to liberate human beings from arduous tasks. Yet, RPA struggles with tasks needing human-like intelligence, especially in elaborate design of workflow construction and dynamic decision-making in workflow execution. As Large Language Models (LLMs) have emerged human-like intelligence, this paper introduces Agentic Process Automation (APA), a groundbreaking automation paradigm using LLM-based agents for advanced automation by offloading the human labor to agents associated with construction and execution. We then instantiate ProAgent, an LLM-based agent designed to craft workflows from human instructions and make intricate decisions by coordinating specialized agents. Empirical experiments are conducted to detail its construction and execution procedure of workflow, showcasing the feasibility of APA, unveiling the possibility of a new paradigm of automation driven by agents. Our code is public at https://github.com/OpenBMB/ProAgent.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e787.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e787.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROAGENT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PROAGENT (instantiation of Agentic Process Automation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based agentic automation system that uses GPT-4 to autonomously construct and execute workflows (JSON for data flow, Python for control flow), and that orchestrates specialized sub-agents (DataAgent and ControlAgent) to handle dynamic decision-making and complex data processing inside workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PROAGENT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A system built on GPT-4 that treats workflow construction as code generation (Agentic Workflow Description Language: JSON for action I/O, Python for control flow). Key components: (1) GPT-4 backbone used with Function Calling to generate actions, I/O schemas, and mainWorkflow Python code; (2) Python executor that runs generated workflows; (3) DataAgent and ControlAgent primitives that are inserted as actions/decision nodes; (4) engineering techniques including Testing-on-Constructing, Chain-of-Thought comments/plans, and function-level testing to validate generated code prior to execution.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>n8n workflow platform / web-based app integration environment</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A web-integrations workflow environment where nodes correspond to apps/APIs (Google Sheets, Slack, Gmail, Webhooks, etc.). The environment is primarily text/API driven: inputs are webhook payloads and structured data, and outputs are API calls (messages, emails, etc.). Challenges arise from heterogeneous APIs, variable input schemas and the need for dynamic branching and data processing, but the paper does not treat this as a canonical partially-observable text benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>n8n apps/APIs (Google Sheets, Slack, Gmail, Webhook triggers), Python interpreter (workflow executor), GPT-4 (LLM backbone). The paper also discusses general external tools agents can use (search engines, web browser, calculator, other APIs) in the Discussion but does not instantiate all of them in the experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Structured JSON (action input/output schemas and return values), text snippets (emails, Slack messages), API responses (success/failure, data rows), and Python function return values/logs.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>No explicit probabilistic or persistent belief-state representation is described. State is handled by the workflow's dataflow: standardized JSON objects are passed as parameters and return values between actions and stored in variables within the generated Python control flow. Chain-of-thought comments/plans act as ephemeral reasoning traces during generation but are not described as a long-lived belief store.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Tool outputs (action return JSON) are returned from action functions and are fed into subsequent actions via Python variables and JSON keys; ControlAgent receives current input data (which may include prior tool outputs) and chooses a branch; DataAgent returns JSON outputs that become new workflow data. Updates are procedural (assignment and passing of JSON objects) rather than explicit belief fusion or probabilistic updating.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>LLM-based programmatic planning: PROAGENT generates an explicit workflow program (Python + JSON) constituting a plan. During execution, ReAct-style per-action reasoning is used inside DataAgent; chain-of-thought comments and Function Calling guide generation. Planning is therefore a combination of code-generation (high-level plan) and per-action LLM reasoning (local planning).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PROAGENT demonstrates that an LLM (GPT-4) can autonomously generate executable workflows that integrate external tools/APIs, and that inserting specialized LLM-driven primitives (DataAgent for data processing and ControlAgent for branching) provides flexibility for dynamic decision-making; workflow state is managed by standardizing action I/O as JSON and by using Python control flow, but the system lacks an explicit belief-state model and quantitative evaluations of tool-enabled performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ProAgent: From Robotic Process Automation to Agentic Process Automation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e787.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e787.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DataAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DataAgent (LLM-driven data-processing action)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A workflow action implemented as an LLM-operated function that accepts a natural-language task description plus structured input and autonomously performs complex data processing, returning standardized JSON outputs so it can be seamlessly stitched into workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>DataAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An action primitive within PROAGENT implemented by an LLM (the paper says it initiates a ReACT-based agent) that receives task text and input_data (JSON), uses chain-of-thought reasoning and tool calls as needed to accomplish the data-processing subtask, and returns a JSON-structured result. Designed to encapsulate arbitrary complex transformations (e.g., writing an email, generating a report) that rule-based nodes cannot express.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>workflow action execution environment (n8n apps and Python executor)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates as a single node inside a workflow that receives structured JSON and may call out to external APIs/tools; environment is API/text-based and task-specific rather than an explicit partially-observable text world benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>Invokable external tools via a tool(...) interface in the generated code (implicitly: web APIs, python interpreter, and any configured APIs such as Gmail/Slack/Google Sheets); the paper states DataAgent initiates a ReACT-based agent able to use external tools but does not enumerate a fixed toolset for DataAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Textual outputs (emails, reports), structured JSON return objects to be consumed by subsequent workflow actions, and API response metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>No explicit persistent belief state; DataAgent uses the incoming JSON input_data as its local context and produces JSON outputs; chain-of-thought comments provide internal reasoning traces during execution but are not stored as a global belief.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Tool outputs produced during DataAgent execution become the JSON return value of the action and are thus incorporated into the workflow's dataflow for later nodes. There is no described aggregation beyond overwriting/adding JSON fields in the workflow context.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Per-action ReAct-style reasoning (thought/action traces) and chain-of-thought inside the LLM to decide which sub-steps/tools to call to fulfill the data task.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DataAgent provides a modular way to delegate complex, hard-to-rule data-processing tasks to LLM reasoning and tool use while preserving workflow composability by returning structured JSON; enables handling of tasks (e.g., writing tailored emails) that static workflows cannot.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ProAgent: From Robotic Process Automation to Agentic Process Automation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e787.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e787.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ControlAgent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ControlAgent (LLM-driven control/branch decision primitive)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A workflow primitive that uses an LLM to implement control-flow decisions: given a natural-language judgement criterion, input data, and candidate branches, the agent selects which branch to execute and returns the option to the workflow.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ControlAgent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A decision-action inserted into the generated Python control flow. It encapsulates an LLM prompt containing the decision task and candidate options; during execution the LLM evaluates the current input_data (JSON) against the judgment criterion and returns the selected branch option. Designed to replace brittle rule-based branching with flexible natural-language-anchored decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>workflow control environment (generated Python mainWorkflow running n8n app actions)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates inside the Python control flow of a workflow over structured JSON data; interacts with outputs of other actions (which may be results from external APIs). The environment is not defined as a partially-observable text world.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>Primarily the LLM (GPT-4) for decision-making. Indirectly consumes outputs from other tools/actions in the workflow (Google Sheets, API nodes); paper mentions ReAct-based style but ControlAgent is described as an LLM decision oracle rather than a multi-tool planner.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Chosen option string, sometimes accompanied by textual rationale (chain-of-thought stored as comments/plans during construction but not as persistent structured belief).</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>No explicit belief model; decisions are made based on the current JSON input_data passed into the ControlAgent; workflow variables serve as the de-facto state.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>The ControlAgent's returned option (a string or indicator) directs subsequent control flow in the Python workflow; this is how its decision updates the effective state of execution. No formal belief fusion is described.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Decision-time LLM reasoning (natural-language decision prompts) â€” effectively local planning/decision selection rather than multi-step global planning.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ControlAgent enables dynamic control-flow branching by replacing rule-based conditionals with LLM-based judgments; it consumes action outputs (JSON) and returns a branch choice that alters subsequent workflow execution, increasing flexibility but without a described formal belief model.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ProAgent: From Robotic Process Automation to Agentic Process Automation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e787.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e787.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct (Reasoning and Acting framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that interleaves reasoning traces ('thoughts') and actions to make LLM-based agents both explainable and capable of tool use; cited and partially used as the execution model inside DataAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ReAct-style agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An agent framework where the model alternates between generating intermediate reasoning (thoughts) and invoking actions (tool calls), producing a transparent chain-of-thought + action trace that guides multi-step tasks and tool interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>General text-and-tool interaction paradigm; the paper uses a ReAct-based agent as the internal executor for DataAgent, but does not place it in a canonical partially-observable text environment.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>ReAct supports arbitrary external tools; the paper indicates DataAgent uses a ReAct-based agent to invoke tools (e.g., web APIs, Python) but does not list a fixed set for the ReAct instance beyond workflow APIs.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Tool responses (text/JSON) and intermediate reasoning traces (text).</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>ReAct produces chain-of-thought traces which serve as ephemeral local reasoning state; ReAct itself does not prescribe a persistent belief-state representation in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Tool outputs are consumed at each ReAct step and influence subsequent thoughts/actions; the paper does not describe aggregation into a persistent belief store.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Interleaved reasoning + acting (per-step tool-driven planning); ReAct enables flexible on-the-fly planning and tool usage.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper leverages a ReAct-style agent inside DataAgent to handle complex data-processing actions, highlighting ReAct's utility for tool-using, explainable, per-action reasoning, but provides no quantitative evaluation within the workflow experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ProAgent: From Robotic Process Automation to Agentic Process Automation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e787.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e787.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large language model from OpenAI used as the backbone LLM in PROAGENT for workflow generation, function-calling, and per-action reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Large pre-trained transformer used for code generation (producing Python workflow code and JSON schemas), for controlling the workflow-construction loop via Function Calling, and as the reasoning engine instantiated inside DataAgent and ControlAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used as a model for code and reasoning generation; not placed inside a classical partially-observable text benchmark in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>Used in conjunction with Function Calling to emit structured JSON/Python code and to direct tool calls within generated code; the system integrates GPT-4 with the n8n API surface.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Generated code (Python), generated JSON schemas, natural-language chain-of-thought comments/plans, decision outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>No explicit belief-state architecture described for GPT-4; ephemeral chain-of-thought comments are used during code/action generation but are not a persisted belief store.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>Programmatic plan generation (code-as-plan), augmented with chain-of-thought reasoning and function-level testing.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GPT-4 can be used to generate executable workflow programs and to instantiate agents (DataAgent/ControlAgent) that use external tools; the paper uses GPT-4 successfully for proof-of-concept workflow construction/execution but provides no numeric benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ProAgent: From Robotic Process Automation to Agentic Process Automation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>React: Synergizing reasoning and acting in language models <em>(Rating: 2)</em></li>
                <li>WebGPT: Browser-assisted question-answering with human feedback <em>(Rating: 2)</em></li>
                <li>Toolformer: Language models can teach themselves to use tools <em>(Rating: 2)</em></li>
                <li>Gorilla: Large language model connected with massive apis <em>(Rating: 2)</em></li>
                <li>Webshop: Towards scalable real-world web interaction with grounded language agents <em>(Rating: 1)</em></li>
                <li>Voyager: An open-ended embodied agent with large language models <em>(Rating: 1)</em></li>
                <li>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-787",
    "paper_id": "paper-265295561",
    "extraction_schema_id": "extraction-schema-21",
    "extracted_data": [
        {
            "name_short": "PROAGENT",
            "name_full": "PROAGENT (instantiation of Agentic Process Automation)",
            "brief_description": "An LLM-based agentic automation system that uses GPT-4 to autonomously construct and execute workflows (JSON for data flow, Python for control flow), and that orchestrates specialized sub-agents (DataAgent and ControlAgent) to handle dynamic decision-making and complex data processing inside workflows.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PROAGENT",
            "agent_description": "A system built on GPT-4 that treats workflow construction as code generation (Agentic Workflow Description Language: JSON for action I/O, Python for control flow). Key components: (1) GPT-4 backbone used with Function Calling to generate actions, I/O schemas, and mainWorkflow Python code; (2) Python executor that runs generated workflows; (3) DataAgent and ControlAgent primitives that are inserted as actions/decision nodes; (4) engineering techniques including Testing-on-Constructing, Chain-of-Thought comments/plans, and function-level testing to validate generated code prior to execution.",
            "environment_name": "n8n workflow platform / web-based app integration environment",
            "environment_description": "A web-integrations workflow environment where nodes correspond to apps/APIs (Google Sheets, Slack, Gmail, Webhooks, etc.). The environment is primarily text/API driven: inputs are webhook payloads and structured data, and outputs are API calls (messages, emails, etc.). Challenges arise from heterogeneous APIs, variable input schemas and the need for dynamic branching and data processing, but the paper does not treat this as a canonical partially-observable text benchmark.",
            "is_partially_observable": null,
            "external_tools_used": "n8n apps/APIs (Google Sheets, Slack, Gmail, Webhook triggers), Python interpreter (workflow executor), GPT-4 (LLM backbone). The paper also discusses general external tools agents can use (search engines, web browser, calculator, other APIs) in the Discussion but does not instantiate all of them in the experiment.",
            "tool_output_types": "Structured JSON (action input/output schemas and return values), text snippets (emails, Slack messages), API responses (success/failure, data rows), and Python function return values/logs.",
            "belief_state_mechanism": "No explicit probabilistic or persistent belief-state representation is described. State is handled by the workflow's dataflow: standardized JSON objects are passed as parameters and return values between actions and stored in variables within the generated Python control flow. Chain-of-thought comments/plans act as ephemeral reasoning traces during generation but are not described as a long-lived belief store.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "Tool outputs (action return JSON) are returned from action functions and are fed into subsequent actions via Python variables and JSON keys; ControlAgent receives current input data (which may include prior tool outputs) and chooses a branch; DataAgent returns JSON outputs that become new workflow data. Updates are procedural (assignment and passing of JSON objects) rather than explicit belief fusion or probabilistic updating.",
            "planning_approach": "LLM-based programmatic planning: PROAGENT generates an explicit workflow program (Python + JSON) constituting a plan. During execution, ReAct-style per-action reasoning is used inside DataAgent; chain-of-thought comments and Function Calling guide generation. Planning is therefore a combination of code-generation (high-level plan) and per-action LLM reasoning (local planning).",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": false,
            "key_findings": "PROAGENT demonstrates that an LLM (GPT-4) can autonomously generate executable workflows that integrate external tools/APIs, and that inserting specialized LLM-driven primitives (DataAgent for data processing and ControlAgent for branching) provides flexibility for dynamic decision-making; workflow state is managed by standardizing action I/O as JSON and by using Python control flow, but the system lacks an explicit belief-state model and quantitative evaluations of tool-enabled performance.",
            "uuid": "e787.0",
            "source_info": {
                "paper_title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "DataAgent",
            "name_full": "DataAgent (LLM-driven data-processing action)",
            "brief_description": "A workflow action implemented as an LLM-operated function that accepts a natural-language task description plus structured input and autonomously performs complex data processing, returning standardized JSON outputs so it can be seamlessly stitched into workflows.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "DataAgent",
            "agent_description": "An action primitive within PROAGENT implemented by an LLM (the paper says it initiates a ReACT-based agent) that receives task text and input_data (JSON), uses chain-of-thought reasoning and tool calls as needed to accomplish the data-processing subtask, and returns a JSON-structured result. Designed to encapsulate arbitrary complex transformations (e.g., writing an email, generating a report) that rule-based nodes cannot express.",
            "environment_name": "workflow action execution environment (n8n apps and Python executor)",
            "environment_description": "Operates as a single node inside a workflow that receives structured JSON and may call out to external APIs/tools; environment is API/text-based and task-specific rather than an explicit partially-observable text world benchmark.",
            "is_partially_observable": null,
            "external_tools_used": "Invokable external tools via a tool(...) interface in the generated code (implicitly: web APIs, python interpreter, and any configured APIs such as Gmail/Slack/Google Sheets); the paper states DataAgent initiates a ReACT-based agent able to use external tools but does not enumerate a fixed toolset for DataAgent.",
            "tool_output_types": "Textual outputs (emails, reports), structured JSON return objects to be consumed by subsequent workflow actions, and API response metadata.",
            "belief_state_mechanism": "No explicit persistent belief state; DataAgent uses the incoming JSON input_data as its local context and produces JSON outputs; chain-of-thought comments provide internal reasoning traces during execution but are not stored as a global belief.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "Tool outputs produced during DataAgent execution become the JSON return value of the action and are thus incorporated into the workflow's dataflow for later nodes. There is no described aggregation beyond overwriting/adding JSON fields in the workflow context.",
            "planning_approach": "Per-action ReAct-style reasoning (thought/action traces) and chain-of-thought inside the LLM to decide which sub-steps/tools to call to fulfill the data task.",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "DataAgent provides a modular way to delegate complex, hard-to-rule data-processing tasks to LLM reasoning and tool use while preserving workflow composability by returning structured JSON; enables handling of tasks (e.g., writing tailored emails) that static workflows cannot.",
            "uuid": "e787.1",
            "source_info": {
                "paper_title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ControlAgent",
            "name_full": "ControlAgent (LLM-driven control/branch decision primitive)",
            "brief_description": "A workflow primitive that uses an LLM to implement control-flow decisions: given a natural-language judgement criterion, input data, and candidate branches, the agent selects which branch to execute and returns the option to the workflow.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "ControlAgent",
            "agent_description": "A decision-action inserted into the generated Python control flow. It encapsulates an LLM prompt containing the decision task and candidate options; during execution the LLM evaluates the current input_data (JSON) against the judgment criterion and returns the selected branch option. Designed to replace brittle rule-based branching with flexible natural-language-anchored decisions.",
            "environment_name": "workflow control environment (generated Python mainWorkflow running n8n app actions)",
            "environment_description": "Operates inside the Python control flow of a workflow over structured JSON data; interacts with outputs of other actions (which may be results from external APIs). The environment is not defined as a partially-observable text world.",
            "is_partially_observable": null,
            "external_tools_used": "Primarily the LLM (GPT-4) for decision-making. Indirectly consumes outputs from other tools/actions in the workflow (Google Sheets, API nodes); paper mentions ReAct-based style but ControlAgent is described as an LLM decision oracle rather than a multi-tool planner.",
            "tool_output_types": "Chosen option string, sometimes accompanied by textual rationale (chain-of-thought stored as comments/plans during construction but not as persistent structured belief).",
            "belief_state_mechanism": "No explicit belief model; decisions are made based on the current JSON input_data passed into the ControlAgent; workflow variables serve as the de-facto state.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "The ControlAgent's returned option (a string or indicator) directs subsequent control flow in the Python workflow; this is how its decision updates the effective state of execution. No formal belief fusion is described.",
            "planning_approach": "Decision-time LLM reasoning (natural-language decision prompts) â€” effectively local planning/decision selection rather than multi-step global planning.",
            "uses_shortest_path_planning": false,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "ControlAgent enables dynamic control-flow branching by replacing rule-based conditionals with LLM-based judgments; it consumes action outputs (JSON) and returns a branch choice that alters subsequent workflow execution, increasing flexibility but without a described formal belief model.",
            "uuid": "e787.2",
            "source_info": {
                "paper_title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ReAct",
            "name_full": "ReAct (Reasoning and Acting framework)",
            "brief_description": "A framework that interleaves reasoning traces ('thoughts') and actions to make LLM-based agents both explainable and capable of tool use; cited and partially used as the execution model inside DataAgent.",
            "citation_title": "React: Synergizing reasoning and acting in language models",
            "mention_or_use": "use",
            "agent_name": "ReAct-style agent",
            "agent_description": "An agent framework where the model alternates between generating intermediate reasoning (thoughts) and invoking actions (tool calls), producing a transparent chain-of-thought + action trace that guides multi-step tasks and tool interactions.",
            "environment_name": null,
            "environment_description": "General text-and-tool interaction paradigm; the paper uses a ReAct-based agent as the internal executor for DataAgent, but does not place it in a canonical partially-observable text environment.",
            "is_partially_observable": null,
            "external_tools_used": "ReAct supports arbitrary external tools; the paper indicates DataAgent uses a ReAct-based agent to invoke tools (e.g., web APIs, Python) but does not list a fixed set for the ReAct instance beyond workflow APIs.",
            "tool_output_types": "Tool responses (text/JSON) and intermediate reasoning traces (text).",
            "belief_state_mechanism": "ReAct produces chain-of-thought traces which serve as ephemeral local reasoning state; ReAct itself does not prescribe a persistent belief-state representation in this paper.",
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": "Tool outputs are consumed at each ReAct step and influence subsequent thoughts/actions; the paper does not describe aggregation into a persistent belief store.",
            "planning_approach": "Interleaved reasoning + acting (per-step tool-driven planning); ReAct enables flexible on-the-fly planning and tool usage.",
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "The paper leverages a ReAct-style agent inside DataAgent to handle complex data-processing actions, highlighting ReAct's utility for tool-using, explainable, per-action reasoning, but provides no quantitative evaluation within the workflow experiments.",
            "uuid": "e787.3",
            "source_info": {
                "paper_title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large language model from OpenAI used as the backbone LLM in PROAGENT for workflow generation, function-calling, and per-action reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "GPT-4",
            "agent_description": "Large pre-trained transformer used for code generation (producing Python workflow code and JSON schemas), for controlling the workflow-construction loop via Function Calling, and as the reasoning engine instantiated inside DataAgent and ControlAgent.",
            "environment_name": null,
            "environment_description": "Used as a model for code and reasoning generation; not placed inside a classical partially-observable text benchmark in this paper.",
            "is_partially_observable": null,
            "external_tools_used": "Used in conjunction with Function Calling to emit structured JSON/Python code and to direct tool calls within generated code; the system integrates GPT-4 with the n8n API surface.",
            "tool_output_types": "Generated code (Python), generated JSON schemas, natural-language chain-of-thought comments/plans, decision outputs.",
            "belief_state_mechanism": "No explicit belief-state architecture described for GPT-4; ephemeral chain-of-thought comments are used during code/action generation but are not a persisted belief store.",
            "incorporates_tool_outputs_in_belief": null,
            "belief_update_description": null,
            "planning_approach": "Programmatic plan generation (code-as-plan), augmented with chain-of-thought reasoning and function-level testing.",
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": null,
            "key_findings": "GPT-4 can be used to generate executable workflow programs and to instantiate agents (DataAgent/ControlAgent) that use external tools; the paper uses GPT-4 successfully for proof-of-concept workflow construction/execution but provides no numeric benchmarks.",
            "uuid": "e787.4",
            "source_info": {
                "paper_title": "ProAgent: From Robotic Process Automation to Agentic Process Automation",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "React: Synergizing reasoning and acting in language models",
            "rating": 2,
            "sanitized_title": "react_synergizing_reasoning_and_acting_in_language_models"
        },
        {
            "paper_title": "WebGPT: Browser-assisted question-answering with human feedback",
            "rating": 2,
            "sanitized_title": "webgpt_browserassisted_questionanswering_with_human_feedback"
        },
        {
            "paper_title": "Toolformer: Language models can teach themselves to use tools",
            "rating": 2,
            "sanitized_title": "toolformer_language_models_can_teach_themselves_to_use_tools"
        },
        {
            "paper_title": "Gorilla: Large language model connected with massive apis",
            "rating": 2,
            "sanitized_title": "gorilla_large_language_model_connected_with_massive_apis"
        },
        {
            "paper_title": "Webshop: Towards scalable real-world web interaction with grounded language agents",
            "rating": 1,
            "sanitized_title": "webshop_towards_scalable_realworld_web_interaction_with_grounded_language_agents"
        },
        {
            "paper_title": "Voyager: An open-ended embodied agent with large language models",
            "rating": 1,
            "sanitized_title": "voyager_an_openended_embodied_agent_with_large_language_models"
        },
        {
            "paper_title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
            "rating": 1,
            "sanitized_title": "language_models_as_zeroshot_planners_extracting_actionable_knowledge_for_embodied_agents"
        }
    ],
    "cost": 0.014529,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Figure 1: The comparison between Robotic Process Automation and Agentic Process Automation</p>
<p>Indicates equal contribution</p>
<p>Figure 1: The comparison between Robotic Process Automation and Agentic Process Automation
37FF854CF4A330F87F4C360A7E04B47A</p>
<p>INTRODUCTION</p>
<p>Automation, aiming to reduce human intervention in processes and enhance efficiency, has undergone a series of evolutionary stages throughout history.From the waterwheel irrigation system in the early agricultural age to steam engines in the industrial age, the human race has continuously been pursuing to offload human labor to autonomous systems, liberating themselves from arduous processes.Entering the information age, marked by a rapid shift from traditional industry to 1 arXiv:2311.10751v2[cs.RO]  Table 1: A comparison between robotic process automation and agentic process automation in terms of efficiency and flexibility.</p>
<p>an economy primarily based on digital technology, software has been widely used as it serves as the foundation for the processing, storage, and communication of information.Robotic Process Automation (RPA) (IvanÄiÄ‡ et al., 2019;Wewerka &amp; Reichert, 2020;Agostinelli et al., 2020;Ferreira et al., 2020)), the de facto predominant automation technology, thus has been widely applied, which automates a process by orchestrating several software by manual-crafted rules into a solidified workflow for efficient execution (Zapier;n8n;unipath).Despite its strides, robotic process automation merely offloads simple and mechanical human labor, while processes requiring human intelligence still necessitate human labor.First, as Figure 1 shows, while RPA workflows can perform processes automatically, their construction still requires human intelligence for elaborate design.Second, many tasks performed by humans are characterized by their flexible and complex nature while workflows are limited to mechanistically replicating human behavioral processes, posing challenges in automating intricate processes that demand dynamic decision-making capabilities during execution.</p>
<p>With the rapid development of Large Language Models (LLMs) (OpenAI, 2022;2023), LLMs are emerging with intelligence that was previously exclusive to human beings (Wei et al., 2022).Recently, LLM-based agents have garnered significant attention from the research community (Xi et al., 2023;Wang et al., 2023b;Yao et al., 2022b;Shinn et al., 2023;Sumers et al., 2023;Qin et al., 2023c;Ye et al., 2023).LLM-based agents have demonstrated a certain level of human intelligence, being capable of using tools (Schick et al., 2023;Qin et al., 2023b;c), creating tools (Qian et al., 2023b;Cai et al., 2023), playing games (Wang et al., 2023a;Chen et al., 2023), browsing website (Nakano et al., 2021;Qin et al., 2023a;Yao et al., 2022a), developping software (Qian et al., 2023a) akin to humans.Consequently, a meaningful inquiry naturally emerges: Can LLM-based agents advance automation in processes necessitating human intelligence, further liberating human beings?</p>
<p>In this paper, we propose AGENTIC PROCESS AUTOMATION (APA), a novel process automation paradigm that overcomes the two aforementioned limitations of automation.(1) Agentic Workflow Construction: Upon receiving human requirements or instructions, LLM-based agents elaborately construct the corresponding workflows instead of humans.If a process involves dynamic decisionmaking, agents should recognize which part of this process needs the dynamic decision-making and then orchestrate agents into the workflow.(2) Agentic Workflow Execution: Workflows should be monitored by agents and once the workflow is executed in the dynamic part, agents would intervene to handle the dynamic decision-making.</p>
<p>To explore the feasibility of APA, we instantiate PROAGENT, an LLM-based agent that integrates the agentic workflow construction and agentic workflow execution in a unified framework.For agentic workflow construction, to make LLM-based agents understand and generate workflows, we design Agentic Workflow Description Language based on the JSON structure and Python code, stemming from the realization that LLMs are pretrained on coding corpus.Specifically, it adopts JSON structure to organize the input and output data for each software for data standardization and uses Python code to implement process control logic to orchestrate software (see in Figure 2).Upon receiving a specific task, PROAGENT is able to generate the corresponding workflow language to facilitate the construction of the requisite workflow.For agentic workflow execution, dynamic decision-making in workflows encompasses two aspects: (1) Data flow: complex data processing (e.g., writing data analysis reports) often exceed the capacity of rule-based systems and thus agents must intervene to effectively manage these intricate processes.(2) Control flow: complex tasks may involve intricate conditional branches and loops, which surpass the expression ability of rules.In such cases, agents need to function as controllers to dynamically determine the subsequent actions.Hence, we def action_0(input_data): """ input_data = { "key_1": int } """ return run(input_data["key_1"]) def action_1(input_data): ... def action_2(input_data): ... design two types of dynamic decision-making agents: DataAgent acts as a data processing to handle intricate data processes dynamically and ControlAgent functions as a condition expression that enables the dynamic determination of subsequent branches for execution.Confronted with complex tasks that need intelligence, PROAGENT can orchestrate these two agents into the workflows during construction and handle complex circumstances purposefully during execution, offloading the intelligent labor (see in Table 1).</p>
<p>To empirically validate our approach, we conduct proof-of-concept experiments to showcase that PROAGENT is able to construct workflows based on human instructions and handle the dynamic decision-making part of the process by utilizing agents in the workflow.We further discuss the relationship between PROAGENT with existing research areas, including Tool Learning (Qin et al., 2023b;c), Process Mining (Tiwari et al., 2008;Van Der Aalst, 2012;Turner et al., 2012), Safety (Cummings, 2004) and etc.Our contributions are listed as follows:</p>
<p>â€¢ We propose AGENTIC PROCESS AUTOMATION, a new process automation paradigm that integrates LLM-based agents to further offload the intelligent labor of humans.â€¢ We instantiate PROAGENT, in which Agentic Workflow Description Language is desgined for LLM-based agents to construct workflows and DataAgent and ControlAgent are orchestrated into workflows to handle the dynamic decision-making process part purposefully.â€¢ We demonstrate of feasibility of our PROAGENT through proof-of-concept case analyses and the exploration of potential and opportunities of AGENTIC PROCESS AUTOMATION across various research domains including tool learning, process mining, safety, etc.</p>
<p>METHODOLOGY</p>
<p>Workflow is widely-used in RPA to solidify the process by a software invocation graph, where nodes represent a software operation and edges signify topology of the process of execution.To achieve the solidification, a data flow and a control flow are involved to within the workflow.Data flow describes how data is passed and processed within a series of software and control flow describes the order of software to execute.In this section, we first introduce Agentic Workflow Description Language to express the data flow and control flow, and then we further detail how to integrate agents into workflows to bring flexibility into workflows.Finally, we detail the workflow construction and execution procedure about how PROAGENT works.</p>
<p>AGENTIC WORKFLOW DESCRIPTION LANGUAGE</p>
<p>As workflow is a graph-based representation approach for RPA to solidify the process, it is inadaptive to LLMs to understand and generate workflows.Thus, we we elaborately design Agentic Workflow Description Language for LLM-agents to conveniently solidify workflows based on the characteristics of coding pretraining.Specifically, we adopt JSON structure to describe data flow and Python code to describe control flow.Figure 2 gives the illustration of Agentic Workflow Description Language.</p>
<p>JSON Structure for Data Flow To solidify a workflow, the data format through software should be standardized to ensure the automatic data process, free from unnecessary agent interventions.We adapt the JSON structure to organize the input/output data of all actions in the workflow.As Figure 2 shows, the input data is formatted in a key-value-paired dictionary.Every data should be assigned a specific key, making it easy to parse and manipulate.When transferring data between different software, the JSON structure is convenient to index the specific data field.Only when the input and output of all software are strictly standardized, promoting consistency across different software of the workflow, thereby reducing the likelihood of data interpretation errors or discrepancies.</p>
<p>Python Code for Control Flow For complex tasks, the corresponding workflows usually involve complex control logic, including conditional branches, loops, or sub-workflow execution.Conventional RPA methods commonly design graph-based representations for human developers to describe the control flow (Zapier; n8n; unipath) but its expression ability for complex workflow is limited and it is also not suitable for LLM-based agents to understand and generate.As Python programming language supports complex control logic and more importantly and it is learned by LLMs during the pre-training phase, we use Python to describe the control flow.As a high-level programming language, Python offers a rich set of primitives and features, providing greater expressive capability to describe complex control logic.A workflow is composed of a Python file, with each software operation aligned to a Python function called action.The corresponding input/output data is mapped into the parameters and return values of the function.Thus, a series of actions (i.e., software) are described as sequential function callings in Python.The if-else statement and for/while statement in Python can be used to implement complex logic control flow.Finally, the workflow is encapsulated within a main Python function (i.e., mainWorkflow).Furthermore, as Python supports the nested function calling, different workflows can also be composed together by calling workflow function to construct a complex workflow.During workflow execution, we utilize a Python executor, starting from the main workflow function (mainWorkflow) as the entry point and execute each functions sequentially, ultimately completing the entire workflow execution.</p>
<p>AGENT-INTEGRATED WORKFLOW</p>
<p>As many real-world tasks with flexibility and complexity nature involve dynamic decision-making process, we devise DataAgent and ControlAgent which can be orchestrated into workflows to handle the dynamic part during execution.Figure 3 gives the illustration.</p>
<p>Action Define</p>
<p>Comment: ... Plan: ...</p>
<p>Not Implement Error</p>
<p>Testing-On-Constructing Function Calling</p>
<p>Chain-of-Thought def action_0(input_data):</p>
<p>""" comments: ... plan: ... """ raise NotImplementedError def mainWorkflow(trigger_input):</p>
<p>raise NotImplementedError</p>
<p>Action Implement</p>
<p>Comment: ... Plan: ...</p>
<p>Not Implement Error</p>
<p>def action_0(input_data):</p>
<p>""" comments: ... plan: ... """ params = { "key_0": int, } return tool(params,input_data) def mainWorkflow(trigger_input):</p>
<p>raise NotImplementedError</p>
<p>Testing-On-Constructing Chain-of-Thought Function Calling</p>
<p>Action Define</p>
<p>Comment: ... Plan: ... DataAgent To achieve complex data process, we devise DataAgent, which acts as an action that is operated by an LLM-based agent.As Figure 3 shows, it supports inputting a task description based on natural language and then accomplishing this task autonomously based on the intelligence of the agent.During execution, this function initiates a ReACT-based agent (Yao et al., 2022b) to fulfill the task.output â† DataAgent(task, input)</p>
<p>Not Implement Error</p>
<p>Although the function is actually operated by agents, its input/output data are still organized by JSON to make it can be orchestrated into existing workflows to connect with other actions.By incorporating the DataAgent, the workflow provides support for enhanced flexibility for data flow, enabling the handling of intricate data processing demands.</p>
<p>ControlAgent In addition to serving as the action, agents can be further involved in the control flow to schedule the execution logic.We introduce ControlAgent into the control flow, allowing it to substitute a selection expression.As Figure 3 shows, ControlAgent contains a pre-generated judgment criterion based on natural language and several execution branch candidates.
opt â† ControlAgent(task, input, [opt 1 , opt 2 , â€¢ â€¢ â€¢ , opt n ])(2)
During execution, the agent can make a decision based on the input data to decide which branch will be executed subsequently, influencing the control flow of the workflow.</p>
<p>WORKFLOW CONSTRUCTION</p>
<p>As the workflow is represented as JSON structure and Python code, the workflow construction is formulated as a code generation task.As Figure 4 demonstrates, the workflow construction procedure contains four iterative operations:</p>
<p>â€¢ action define: It determines which action is selected to add into the workflow.</p>
<p>â€¢ action implement: It first transforms the action into the Python function by determining its input/output data format in JSON structure and then implement the data process program in Python code.â€¢ workflow implement: As workflows are represented as mainWorkflow functions, this operation refers to providing an implementation for it to orchestrate the entire workflow.â€¢ task submit: It is used to denote the termination of the workflow construction.</p>
<p>Preprint</p>
<p>In practice, we employ OpenAI GPT-4 as the backbone of PROAGENT to generate the workflow language and further incorporated several techniques to enhance the workflow generation capabilities:</p>
<p>â€¢ Testing-on-Constructing: During the construction, PROAGENT tends to test each function or entire workflow, which ensures the validation of the constructed workflow before execution.â€¢ Function Calling: The aforementioned four operations are defined as function in GPT-4 to use Function Calling to explicitly control the whole construction procedure, benefiting controllable generation.â€¢ Chain-of-Thought: When implementing each function, PROAGENT requires to provide a comment (explaining the purpose of this function) and a plan (indicating what the subsequent operations should be done next), which aids in enhancing the workflow code generation performance.</p>
<p>WORKFLOW EXECUTION</p>
<p>The workflow execution procedure is based on Python interpreter.Given a workflow language, once this workflow is triggered, its corresponding mainWorkflow function is selected as the entry point to begin the execution procedure.The execution procedure follows the Python code execution rule, i.e., executing according to the line order sequentially.Once the mainWorkflow function returns, the workflow execution is finished successfully.</p>
<p>PROOF-OF-CONCEPT EXPERIMENT</p>
<p>To validate the feasibility of AGENTIC PROCESS AUTOMATION, we conduct proof-of-concept experiment based on n8n1 , an open-source workflow platform.Each APP (i.g., software) in the n8n platform is encapsulated as an action in the workflow and thus the core of the workflow construction is to orchestrate these APPs to achieve certain tasks.We implement our proposed PROAGENT based on GPT-4.We construct a case about the commercial scenario to explain how our PROAGENT works in detail.</p>
<p>TASK CONSTRUCTION Preprint</p>
<p>In practice, we employ OpenAI GPT-4 as the backbone of PROAGENT to generate the workflow language and further incorporated several techniques to enhance the workflow generation capabilities:</p>
<p>â€¢ Testing-on-Constructing: During the construction, PROAGENT tends to test each function or entire workflow, which ensures the validation of the constructed workflow before execution.â€¢ Function Calling: The aforementioned four operations are defined as function in GPT-4 to use Function Calling to explicitly control the whole construction procedure, benefiting controllable generation.â€¢ Chain-of-Thought: When implementing each function, PROAGENT requires to provide a comment (explaining the purpose of this function) and a plan (indicating what the subsequent operations should be done next), which aids in enhancing the workflow code generation performance.</p>
<p>WORKFLOW EXECUTION</p>
<p>The workflow execution procedure is based on Python interpreter.Given a workflow language, once this workflow is triggered, its corresponding mainWorkflow function is selected as the entry point to begin the execution procedure.The execution procedure follows the Python code execution rule, i.e., executing according to the line order sequentially.Once the mainWorkflow function returns, the workflow execution is finished successfully.</p>
<p>PROOF-OF-CONCEPT EXPERIMENT</p>
<p>To validate the feasibility of AGENTIC PROCESS AUTOMATION, we conduct proof-of-concept experiment based on n8n 1 , an open-source workflow platform.Each APP (i.g., software) in the n8n platform is encapsulated as an action in the workflow and thus the core of the workflow construction is to orchestrate these APPs to achieve certain tasks.We implement our proposed PROAGENT based on GPT-4.We construct a case about the commercial scenario to explain how our PROAGENT works in detail.</p>
<p>TASK CONSTRUCTION Task</p>
<p>When I send a worksheet of business lines through Web, deal with them according to which type of each business line belong to.</p>
<ol>
<li>
<p>To-Customer: Send a message to Slack to report the profits of business lines.</p>
</li>
<li>
<p>To-Business: Write a report which should analyze the data to give some suggestions and then send it to the Gmail of the corresponding managers.</p>
</li>
</ol>
<p>We present a typical commercial scenario where a business department manager seeks to extract diverse business line data from Google Sheets.Upon identifying a business line is To-Customer, a message is dispatched to the Slack channel.In the case of a business line as To-Business, an email is sent to the respective manager, encompassing an assessment of the business line and a concise overview of its profitability.This exemplifies the capabilities achievable through the integration of workflow and agent:</p>
<p>â€¢ Given the similar format of the content in Google Sheets, this task exhibits a high level of reusability, applicable to various business departments with analogous requirements.â€¢ Distinguishing whether a business line pertains To-Customer or To-Business based solely on its description is a complex task not easily handled through rule-based judgments.Agent integration becomes imperative for dynamic branching.â€¢ Generating corresponding emails for the relevant business lines is a dynamic requirement necessitating flexible agent-based data processing.</p>
<p>1 https://n8n.io6</p>
<p>We present a typical commercial scenario where a business department manager seeks to extract diverse business line data from Google Sheets.Upon identifying a business line is To-Customer, a message is dispatched to the Slack channel.In the case of a business line as To-Business, an email is sent to the respective manager, encompassing an assessment of the business line and a concise overview of its profitability.This exemplifies the capabilities achievable through the integration of workflow and agent:</p>
<p>â€¢ Given the similar format of the content in Google Sheets, this task exhibits a high level of reusability, applicable to various business departments with analogous requirements.â€¢ Distinguishing whether a business line pertains To-Customer or To-Business based solely on its description is a complex task not easily handled through rule-based judgments.Agent integration becomes imperative for dynamic branching.â€¢ Generating corresponding emails for the relevant business lines is a dynamic requirement necessitating flexible agent-based data processing.</p>
<p>Preprint</p>
<p>When I send a worksheet of business lines through web, split them by To-Business and To-Customer.</p>
<ol>
<li>Send slack of profits of To-Business lines 2. Write and send Gmail of To-Customer lines</li>
</ol>
<p>Action Define</p>
<p>Thought: I will first define a trigger and see the input schema, then add a Google Sheet node to read WebhookTrigger(Comments: check the trigger input schema)</p>
<p>def WebhookTrigger(input_data):</p>
<p>"""comments:</p>
<p>1.check the trigger input schema """ return def mainWorkflow(trigger_input): raise NotImplementedError</p>
<p>Action Implement</p>
<p>Thought: Since To-Customer or To-Business can be classified based on rules, I will use ControlAgent.</p>
<p>DecideBusinessLine("Decide whether the business line is toC or toB", ["toC", "toB"] )</p>
<p>def WebhookTrigger(input_data): ... def GoogleSheetRead(input_data):</p>
<p>... def DecideBusinessLine(line_data):</p>
<p>"""comments: ... """ task = "decide Whether the business line is toC or toB" options = ["toC", "toB"] return ControlAgent(task, options, line_data)</p>
<p>def mainWorkflow(trigger_input): ...</p>
<p>Not Implemented Error</p>
<p>Action Implement</p>
<p>Thought: All business line has to write a own email, I can only put an DataAgent.WriteEmail("Write a email of the business line of profit, together with your suggestion")</p>
<p>â€¢â€¢â€¢</p>
<p>def WebhookTrigger(input_data): ... def GoogleSheetRead(input_data):</p>
<p>... def DecideBusinessLine(line_data):</p>
<p>.
Preprint Google Sheets ControlAgent Business Line Data Webhook Trigger Send Email to Manager Slack To Customer Send Message to Slack Gmail DataAgent Loop Write Email Send Email
The business line's profit is 50,000$, which is comparable goodâ€¦ â€¦I will write the email as following:</p>
<p>"I hope this finds you well.â€¦" This business line is Enterprise resource planning service system, a typically To-Business service
Google Sheets ControlAgent Business Line Data Webhook Send Email to Manager Slack To Customer Send Message to Slack Gmail DataAgent Loop Write Email Send Email
This business line is about providing a range of products for users to purchase.It is a To-Customer service.</p>
<p>Trigger</p>
<p>ProAgent automatically routes different inputs of task into the workflow and handles them with different logic To-Business data in Google Sheets, PROAGENT further add a Loop in workflow to deal with these data iteratively.Finally, as the workflow is constructed completely, task submit is operated by PROAGENT to end the construction procedure.</p>
<p>WORKFLOW EXECUTION</p>
<p>Figure 6 illustrates two execution cases for the constructed workflow.These two cases demonstrate a To-Customer and a To-Business line respectively.It is obviously shown that the ControlAgent successfully distinguish which type of two business lines belong to.For the first one, the description of this business line is:
Preprint Google Sheets ControlAgent Business Line Data Webhook Trigger Send Email to Manager Slack To Customer Send Message to Slack Gmail DataAgent Loop Write Email Send Email
The business line's profit is 50,000$, which is comparable goodâ€¦ â€¦I will write the email as following:</p>
<p>"I hope this finds you well.â€¦" This business line is Enterprise resource planning service system, a typically To-Business service
Google Sheets ControlAgent Business Line Data Webhook Send Email to Manager Slack To Customer Send Message to Slack Gmail DataAgent Loop Write Email Send Email
This business line is about providing a range of products for users to purchase.It is a To-Customer service.</p>
<p>Trigger</p>
<p>ProAgent automatically routes different inputs of task into the workflow and handles them with different logic</p>
<p>WORKFLOW EXECUTION</p>
<p>Figure 6 illustrates two execution cases for the constructed workflow.These two cases demonstrate a To-Customer and a To-Business line respectively.It is obviously shown that the ControlAgent successfully distinguish which type of two business lines belong to.For the first one, the description of this business line is:</p>
<p>"Enterprise Resource Planning: organizations use to manage day-to-day business activities such as accounting, procurement, project management, and risk management, and supply chain operations."</p>
<p>ControlAgent distinguish that This business line is Enterprise resource planning system, a typically to-business service.After that, the DataAgent is executed to write an email to send:</p>
<p>"I hope this finds you well.I wanted to update you on our ERP product line's performance.The feedback has been overwhelmingly positive, especially from larger corporations integrating it into their daily operations.Remarkably, the ERP system generated a revenue of $50,000 this month alone."</p>
<p>8</p>
<p>ControlAgent distinguish that This business line is Enterprise resource planning system, a typically to-business service.After that, the DataAgent is executed to write an email to send: Preprint The business line's profit is 50,000$, which is comparable goodâ€¦ â€¦I will write the email as following:</p>
<p>"I hope this finds you well.â€¦" This business line is about providing a range of products for users to purchase.It is a To-Customer service.</p>
<p>Trigger</p>
<p>ProAgent automatically routes different inputs of task into the workflow and handles them with different logic To-Business data in Google Sheets, PROAGENT further add a Loop in workflow to deal with these data iteratively.Finally, as the workflow is constructed completely, task submit is operated by PROAGENT to end the construction procedure.</p>
<p>WORKFLOW EXECUTION</p>
<p>Figure 6 illustrates two execution cases for the constructed workflow.These two cases demonstrate a To-Customer and a To-Business line respectively.It is obviously shown that the ControlAgent successfully distinguish which type of two business lines belong to.For the first one, the description of this business line is:</p>
<p>"Enterprise Resource Planning: organizations use to manage day-to-day business activities such as accounting, procurement, project management, and risk management, and supply chain operations."</p>
<p>ControlAgent distinguish that This business line is Enterprise resource planning system, a typically to-business service.After that, the DataAgent is executed to write an email to send:</p>
<p>"I hope this finds you well.I wanted to update you on our ERP product line's performance.The feedback has been overwhelmingly positive, especially from larger corporations integrating it into their daily operations.Remarkably, the ERP system generated a revenue of $50,000 this month alone."</p>
<p>Preprint</p>
<p>For the second one, its description is:</p>
<p>Preprint For the second one, its description is:</p>
<p>"E-commerce Marketplace: Operating an online platform for consumers to purchase a wide range of products from various brands and sellers."</p>
<p>PROAGENT extracts some key words such as "products" and "purchase" to decide that this business line belongs to To-Customer type.Then, a simple message "The profit of the business line 9 is -3500$."to the Slack.</p>
<p>DISCUSSION</p>
<p>In this section, we discuss the relationship between APA and PROAGENT technologies and the field of tool learning, process mining, etc, along with potential research directions.Subsequently, we discuss the issue of automation bias that may arise from APA technologies and delve into the unique value humans should bring in the era of automation.</p>
<p>PROAGENT AS TOOLAGENT: INTEGRATING TOOL UTILIZATION AND TOOL CREATION</p>
<p>Existing work has shown that LLM-based agents own powerful capability to utilize external tools (e.g., search engine, web browser, calculator, python interpreter, etc) (IvanÄiÄ‡ et al., 2019;Wewerka &amp; Reichert, 2020;Agostinelli et al., 2020;Ferreira et al., 2020).By integrating the external tools, agents can extend its capability from text generation to manipulate tools to impact environments and even the real world.In addition to their adeptness in utilizing existing tools, recent research has showcased their capability to create novel tools for specific tasks (Qian et al., 2023b;Cai et al., 2023).In a workflow, a series of operations are involved, and when these operations involve invoking external tools, the execution process of this workflow can be viewed as the process of tool utilization (Nakano et al., 2021;Yao et al., 2022a;Schick et al., 2023;Qin et al., 2023b;c;Ye et al., 2023).In the context of workflow management, the execution of a series of operations through the invocation of external tools can be perceived as a process of tool utilization.Orchestrating multiple operations (i.e., tools) into a coherent workflow to address specific tasks can be viewed as the process of tool creation, i.e., combining multiple tools to form a new tool.In this context, PROAGENT can be understood as an autonomous process that seamlessly integrates tool creation and utilization.</p>
<p>PROCESS MINING: DISCOVER, ANALYZE, AND IMPROVE WORKFLOWS</p>
<p>In our PROAGENT, the workflow construction process is primarily driven by the agent solely, potentially yielding sub-optimal workflows.Integrating the principles of Process Mining (PM) (Tiwari et al., 2008;Van Der Aalst, 2012;Turner et al., 2012) into this framework can facilitate the discovery of valuable workflows from historical records.Process Mining is a data-driven technique used to discover, analyze, and improve existing workflows.It involves the extraction of insights and knowledge from historical records generated during the execution of various workflows.This method enables to gain a comprehensive understanding of workflows constructed by agents, identify inefficiencies, bottlenecks, and deviations from the intended workflow, and subsequently optimize their operations for better performance and efficiency.Moreover, optimized workflows can serve as effective training data to enhance the agent's workflow construction capabilities.</p>
<p>ETHICAL AND SAFETY CONCERNS: AGENT AGGRAVATES AUTOMATION BIAS</p>
<p>The advent of agent technology offers the potential for models to tackle complex tasks.However, on the flip side, it can also lead to an over-reliance on agents by humans.People might opt to trust agent decisions even when these decisions conflict with their own views, which is known as Automation Bias (Cummings, 2004) and has been observed in domains such as Clinical decision support systems (Goddard et al., 2012).Under LLM-based agent technologies, this problem becomes even more pronounced.Humans may shift their trust in the stability of traditional rule-based workflows to agents, mistakenly believing that the agent's decision-making processes are equally reliable, especially hallucination (Maynez et al., 2020;Zhang et al., 2023;Ji et al., 2023).Future research is</p>
<p>9</p>
<p>PROAGENT extracts some key words such as "products" and "purchase" to decide that this business line belongs to To-Customer type.Then, a simple message "The profit of the business line 9 is -3500$."to the Slack.</p>
<p>DISCUSSION</p>
<p>In this section, we discuss the relationship between APA and PROAGENT technologies and the field of tool learning, process mining, etc, along with potential research directions.Subsequently, we discuss the issue of automation bias that may arise from APA technologies and delve into the unique value humans should bring in the era of automation.</p>
<p>PROAGENT AS TOOLAGENT: INTEGRATING TOOL UTILIZATION AND TOOL CREATION</p>
<p>Existing work has shown that LLM-based agents own powerful capability to utilize external tools (e.g., search engine, web browser, calculator, python interpreter, etc) (IvanÄiÄ‡ et al., 2019;Wewerka &amp; Reichert, 2020;Agostinelli et al., 2020;Ferreira et al., 2020).By integrating the external tools, agents can extend its capability from text generation to manipulate tools to impact environments and even the real world.In addition to their adeptness in utilizing existing tools, recent research has showcased their capability to create novel tools for specific tasks (Qian et al., 2023b;Cai et al., 2023).In a workflow, a series of operations are involved, and when these operations involve invoking external tools, the execution process of this workflow can be viewed as the process of tool utilization (Nakano et al., 2021;Yao et al., 2022a;Schick et al., 2023;Qin et al., 2023b;c;Ye et al., 2023).In the context of workflow management, the execution of a series of operations through the invocation of external tools can be perceived as a process of tool utilization.Orchestrating multiple operations (i.e., tools) into a coherent workflow to address specific tasks can be viewed as the process of tool creation, i.e., combining multiple tools to form a new tool.In this context, PROAGENT can be understood as an autonomous process that seamlessly integrates tool creation and utilization.</p>
<p>PROCESS MINING: DISCOVER, ANALYZE, AND IMPROVE WORKFLOWS</p>
<p>In our PROAGENT, the workflow construction process is primarily driven by the agent solely, potentially yielding sub-optimal workflows.Integrating the principles of Process Mining (PM) (Tiwari et al., 2008;Van Der Aalst, 2012;Turner et al., 2012) into this framework can facilitate the discovery of valuable workflows from historical records.Process Mining is a data-driven technique used to discover, analyze, and improve existing workflows.It involves the extraction of insights and knowledge from historical records generated during the execution of various workflows.This method enables to gain a comprehensive understanding of workflows constructed by agents, identify inefficiencies, bottlenecks, and deviations from the intended workflow, and subsequently optimize their operations for better performance and efficiency.Moreover, optimized workflows can serve as effective training data to enhance the agent's workflow construction capabilities.</p>
<p>ETHICAL AND SAFETY CONCERNS: AGENT AGGRAVATES AUTOMATION BIAS</p>
<p>The advent of agent technology offers the potential for models to tackle complex tasks.However, on the flip side, it can also lead to an over-reliance on agents by humans.People might opt to trust agent decisions even when these decisions conflict with their own views, which is known as Automation Bias (Cummings, 2004) and has been observed in domains such as Clinical decision support systems (Goddard et al., 2012).Under LLM-based agent technologies, this problem becomes even more pronounced.Humans may shift their trust in the stability of traditional rule-based workflows to agents, mistakenly believing that the agent's decision-making processes are equally reliable, especially hallucination (Maynez et al., 2020;Zhang et al., 2023;Ji et al., 2023).Future research is Preprint necessary to prioritize the development of safer, more trustful, more interpretable agentic process automation.</p>
<p>HUMAN ADVANTAGE: RETHINKING THE MEANING OF HUMAN LABOR</p>
<p>APA introduces the intelligence of elaborate design in workflow construction and dynamic decisionmaking in workflow execution into process automation, which can offload the heavy human labor in RPA.Now, the more pertinent question is: "What tasks should remain human-driven?"There are processes that inherently benefit from human intuition, experience, and creativity.For these tasks, humans play a crucial role that can't be easily supplanted by machines.While automation might offer efficiency, it can't replicate the nuanced understanding and innovative solutions that a human brings to the table.The paradox of human involvement, where human intervention can improve outcomes, stands in contrast to the earlier mentioned pitfalls of automation bias.</p>
<p>The next frontier in APA involves discerning which processes can be wholly automated and which require human oversight or intervention.We must remember that the ultimate goal of automation is to amplify productivity, not to supplant humans entirely.The challenge lies in facilitating a symbiotic relationship between humans and machines, where neither is completely excluded in favor of the other.Drawing from the perspective of Steve Jobs, the future should see humans focusing on what they do best: applying their unique intelligence and creativity where it matters most.APA demands a recalibration, where automation serves humanity, and humans, in turn, elevate the capabilities of automation.</p>
<p>RELATED WORK</p>
<p>Robotic Process Automation Robotic process automation (RPA) (IvanÄiÄ‡ et al., 2019;Hofmann et al., 2020;Tiwari et al., 2008;Scheer et al., 2004), as the fashion automation paradigm, primarily employs software robots to either automate access to software APIs or simulate user GUI interactions to accomplish tasks through multiple software.Unlike traditional automation techniques, RPA emulates the way humans use software, directly tapping into existing software assets without the need for transformation or additional investment.Thus, RPA has gained substantial attention in recent years as an effective technology for automating repetitive and rule-based tasks typically performed by human workers (Zapier;n8n;unipath). RPA are primarily designed to automate repetitive tasks using predefined rules and workflow templates, which needs heavy human labor to design and implement workflows.Still, due to the workflows are driven by manual-crafted rules, it struggles to handle those complex tasks that needs dynamic decision-making.</p>
<p>Recently, there has been a growing interest in integrating RPA with AI technique, leading to various terminologies and definitions.For instance, Intelligent Process Automation (IPA) (Ferreira et al., 2020;Chakraborti et al., 2020b) and Cognitive Automation (or RPA 4.0) (Lacity &amp; Willcocks, 2018), aim to amalgamate AI techniques in the phases of RPA, e.g., data format transformation (Leno et al., 2020), workflow optimization (Chakraborti et al., 2020a), conversational assistant (Moiseeva et al., 2020), demonstration-to-process translation (Li et al., 2019), etc.Nevertheless, these work still utilizes traditional deep learning technique (e.g., RNN (Han et al., 2020)) or even machine learning technique (e.g., Monte Carlo Tree Search (Chen, 2020)) into RPA.More importantly, they just utilizes AI technique into some specific fragments of RPA (e.g., data format transformation (Leno et al., 2020)).In contrast, our work AGENTIC PROCESS AUTOMATION takes the lead to integrate the most intelligent AI model, large language models, into RPA.As a result, it is the inaugural exploration into agentic techniques in both the autonomous generation of workflows and Agent-driven workflow execution to endow them with intelligence.</p>
<p>LLM-based Agents Large language models (LLMs), as significant milestones of artificial intelligence, unveil the remarkable capability on a wide range of tasks (OpenAI, 2022;2023).Recently, LLM-based agents emerge to extend LLMs with external tools to interact with the environment to achieve real-world tasks.Early research work attempt to prompt LLMs to generate the action according to the observation of environment (Nakano et al., 2021;Huang et al., 2022;Ahn et al., 2022;Schick et al., 2023;Qian et al., 2023a;Chen et al., 2023).Such a manner tends to struggle when facing intricate tasks that need long-term planning and decision-making.To address this issue, ReAct (Yao et al., 2022b) proposed a dynamic task-solving approach that makes agents generate thought for each action to form a reasoning chain, enabling flexible reasoning-guided, trackable, and adjustable actions, resulting in notable improvements compared to act-only methodologies.Based on the dynamic task-solving manner, many agents are proposed subsequently to improve agent capability in different aspects, e.g., reflection (Shinn et al., 2023), planning (Yao et al., 2023;Hao et al., 2023;Besta et al., 2023;Sel et al., 2023), tool learning (Schick et al., 2023;Patil et al., 2023;Qin et al., 2023b;c;Qian et al., 2023b), multi-agents (Park et al., 2023;Qian et al., 2023a), etc.However, all the existing ReACT-based agent methods are restricted to linearly generate decisionmaking, resulting in lower operational efficiency.In this paper, we propose PROAGENT that explores to enhance the efficiency of the dynamic task-solving approach by recognizing which part of the workflow needs the intelligence involves and integrating agents to handle these parts purposefully.</p>
<p>CONCLUSION</p>
<p>In this research, we present a novel process automation paradigm, AGENTIC PROCESS AUTOMA-TION, to address the limitations of robotic process automation technologies in handling tasks requiring human intelligence by harnessing the capabilities of LLM-based agents to integrate them into the workflow construction and execution process.Through the instantiation of PROAGENT, we illustrated how LLM-based agents can feasibly manage complex decision-making processes, thereby offloading the burden of intelligent labor from humans.Our proof-of-concept experiment provided evidence of the feasibility of AGENTIC PROCESS AUTOMATION in achieving efficiency and flexibility in process automation.Our findings contribute to the growing body of research in the field of intelligent automation and underscore the significant role that LLM-based agents can play in enhancing the efficiency and flexibility of various industries.As the adoption of automation technologies continues to expand, we anticipate that the APA framework can serve as a catalyst for further advancements in the automation landscape, leading to increased efficiency, reduced human intervention, and ultimately, a more streamlined and intelligent workflow ecosystem.</p>
<p>Figure 2 :
2
Figure 2: Illustration of Agentic Workflow Description Language.</p>
<p>Figure 3 :
3
Figure 3: Illustration of Agentic Workflow Description Language with DataAgent and ControlAgent.</p>
<p>Figure 4 :
4
Figure 4: The Illustration of the workflow construction procedure of PROAGENT.</p>
<p>Figure 5 :
5
Figure 5: The Illustration of the workflow construction procedure of PROAGENT for case analysis.</p>
<p>Figure 6 :
6
Figure 6: The Illustration of the workflow execution procedure of PROAGENT for case analysis.</p>
<p>Figure 6 :
6
Figure 6: The Illustration of the workflow execution procedure of PROAGENT for case analysis.</p>
<p>Figure 6 :
6
Figure 6: The Illustration of the workflow execution procedure of PROAGENT for case analysis.</p>
<p>23 Nov 2023
PreprintParadigmEfficiency Data Flow Control Flow Data Flow Control Flow IntelligenceEfficiency Paradigm ShiftRPA ControlAgent DataAgent APA LLM-based Agentsâœ“ âœ— âœ“ âœ“ âœ“âœ“ âœ— âœ“ âœ“ âœ“âœ— âœ“ âœ“ âœ“ âœ—âœ— âœ“ âœ“ âœ— âœ“RPAIntelliegence Agent APA</p>
<p>This business line is Enterprise resource planning service system, a typically To-Business service
DataAgentSend Email to ManagerWrite EmailSend EmailBusiness Line DataControlAgentLoopGmailTo CustomerWebhookGoogle SheetsSend Messageto SlackSlack
https://n8n.io</p>
<p>Towards intelligent robotic process automation for bpmers. Simone Agostinelli, Andrea Marrella, Massimo Mecella, arXiv:2001.008042020arXiv preprint</p>
<p>Do as i can, not as i say: Grounding language in robotic affordances. Anthony Michael Ahn, Noah Brohan, Yevgen Brown, Omar Chebotar, Byron Cortes, Chelsea David, Keerthana Finn, Karol Gopalakrishnan, Alex Hausman, Herzog, abs/2204.01691ArXiv preprint. 2022</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, arXiv:2308.096872023arXiv preprint</p>
<p>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou, arXiv:2305.17126Large language models as tool makers. 2023arXiv preprint</p>
<p>D3ba: a tool for optimizing business processes using non-deterministic planning. Tathagata Chakraborti, Shubham Agarwal, Yasaman Khazaeni, Yara Rizk, Vatche Isahagian, Business Process Management Workshops: BPM 2020 International Workshops. Seville, SpainSpringerSeptember 13-18, 2020. 2020a18</p>
<p>From robotic process automation to intelligent process automation: -emerging trends. Tathagata Chakraborti, Vatche Isahagian, Rania Khalaf, Yasaman Khazaeni, Vinod Muthusamy, Yara Rizk, Merve Unuvar, Business Process Management: Blockchain and Robotic Process Automation Forum: BPM 2020 Blockchain and RPA Forum. Proceedings. Seville, SpainSpringerSeptember 13-18, 2020. 2020b18</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, arXiv:2308.10848Facilitating multi-agent collaboration and exploring emergent behaviors in agents. 2023arXiv preprint</p>
<p>Monte carlo tree search for generating interactive data analysis interfaces. Preprint Yiru, Chen , Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data. the 2020 ACM SIGMOD International Conference on Management of Data2020</p>
<p>Automation bias in intelligent time critical decision support systems. Mary Cummings, AIAA 1st intelligent systems technical conference. 20046313</p>
<p>On the evaluation of intelligent process automation. Deborah Ferreira, Julia Rozanova, Krishna Dubba, Dell Zhang, Andre Freitas, arXiv:2001.026392020arXiv preprint</p>
<p>Automation bias: a systematic review of frequency, effect mediators, and mitigators. Kate Goddard, Abdul Roudsari, Jeremy C Wyatt, Journal of the American Medical Informatics Association. 1912012</p>
<p>Automatic business process structure discovery using ordered neurons lstm: a preliminary study. Xue Han, Lianxue Hu, Yabin Dang, Shivali Agarwal, Lijun Mei, Shaochun Li, Xin Zhou, arXiv:2001.012432020arXiv preprint</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 2023arXiv preprint</p>
<p>Robotic process automation. Electronic markets. Peter Hofmann, Caroline Samp, Nils Urbach, 202030</p>
<p>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch, International Conference on Machine Learning, ICML 2022. Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba SzepesvÃ¡ri, Gang Niu, Sivan Sabato, Baltimore, Maryland, USAPMLR17-23 July 2022. 2022162of Proceedings of Machine Learning Research</p>
<p>Robotic process automation: systematic literature review. Lucija IvanÄiÄ‡, Dalia SuÅ¡a Vugec, Vesna Bosilj, VukÅ¡iÄ‡, Business Process Management: Blockchain and Central and Eastern Europe Forum: BPM 2019 Blockchain and CEE Forum. Proceedings. Vienna, AustriaSpringerSeptember 1-6, 2019. 201917</p>
<p>Survey of hallucination in natural language generation. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye , Jin Bang, Andrea Madotto, Pascale Fung, ACM Computing Surveys. 55122023</p>
<p>Robotic process and cognitive automation: the next phase. Mary Lacity, Leslie P Willcocks, 2018SB Publishing</p>
<p>Automated discovery of data transformations for robotic process automation. Volodymyr Leno, Marlon Dumas, Marcello La Rosa, Fabrizio Maria, Maggi , Artem Polyvyanyy, arXiv:2001.010072020arXiv preprint</p>
<p>Toby Jia-Jun Li, Marissa Radensky, Justin Jia, Kirielle Singarajah, Tom M Mitchell, Brad A Myers, arXiv:1909.00031Interactive task and concept learning from natural language instructions and gui demonstrations. 2019arXiv preprint</p>
<p>On faithfulness and factuality in abstractive summarization. Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan Mcdonald, arXiv:2005.006612020arXiv preprint</p>
<p>Multipurpose intelligent process automation via conversational assistant. Alena Moiseeva, Dietrich Trautmann, Michael Heimann, Hinrich SchÃ¼tze, arXiv:2001.022842020arXiv preprint</p>
<p>Webgpt: Browser-assisted question-answering with human feedback. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, abs/2112.09332ArXiv preprint. 2021</p>
<p>Preprint Openai, OpenAI: Introducing ChatGPT. 2022. 2023</p>
<p>Sung Joon, Park, C Joseph, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, arXiv:2304.03442Generative agents: Interactive simulacra of human behavior. 2023arXiv preprint</p>
<p>Tianjun Shishir G Patil, Xin Zhang, Joseph E Wang, Gonzalez, arXiv:2305.15334Gorilla: Large language model connected with massive apis. 2023arXiv preprint</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 2023aarXiv preprint</p>
<p>Creator: Disentangling abstract and concrete reasonings of large language models through tool creation. Chi Cheng Qian, Yi R Han, Yujia Fung, Zhiyuan Qin, Heng Liu, Ji, arXiv:2305.143182023barXiv preprint</p>
<p>Webcpm: Interactive web search for chinese long-form question answering. Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin, Xu Han, Ning Ding, Huadong Wang, arXiv:2305.068492023aarXiv preprint</p>
<p>Tool learning with foundation models. Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, arXiv:2304.083542023barXiv preprint</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, arXiv:2307.16789Facilitating large language models to master 16000+ real-world apis. 2023carXiv preprint</p>
<p>Business process automation. August-Wilhelm Scheer, Ferri Abolhassan, Wolfram Jost, Mathias Kirchmer, ARIS in practice. 2004</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, abs/2302.047612023ArXiv preprint</p>
<p>Algorithm of thoughts: Enhancing exploration of ideas in large language models. Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu Wang, Ruoxi Jia, Ming Jin, arXiv:2308.103792023arXiv preprint</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, 2023</p>
<p>Theodore Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L Griffiths, arXiv:2309.02427Cognitive architectures for language agents. 2023arXiv preprint</p>
<p>A review of business process mining: stateof-the-art and future trends. Ashutosh Tiwari, Chris J Turner, Basim Majeed, Business Process Management Journal. 1412008</p>
<p>Process mining: from theory to practice. Chris J Turner, Ashutosh Tiwari, Richard Olaiya, Yuchun Xu, The uipath business automation platform. 201218</p>
<p>Process mining: Overview and opportunities. Wil Van, Der Aalst, ACM Transactions on Management Information Systems (TMIS). 322012</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, arXiv:2305.162912023aarXiv preprint</p>
<p>Preprint Lei, Wang , Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, arXiv:2308.11432A survey on large language model based autonomous agents. 2023barXiv preprint</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022arXiv preprint</p>
<p>Robotic process automation-a systematic literature review and assessment framework. Judith Wewerka, Manfred Reichert, arXiv:2012.119512020arXiv preprint</p>
<p>Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023arXiv preprint</p>
<p>Webshop: Towards scalable real-world web interaction with grounded language agents. Shunyu Yao, Howard Chen, John Yang, Karthik Narasimhan, Advances in Neural Information Processing Systems. 2022a35</p>
<p>React: Synergizing reasoning and acting in language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, ; Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.10601Tree of thoughts: Deliberate problem solving with large language models. 2022b. 2023arXiv preprint</p>
<p>Large language model as autonomous decision maker. Yining Ye, Xin Cong, Yujia Qin, Yankai Lin, Zhiyuan Liu, Maosong Sun, arXiv:2308.125192023arXiv preprint</p>
<p>Zapier -automation makes you move forward. Zapier, </p>
<p>Siren's song in the ai ocean: A survey on hallucination in large language models. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, arXiv:2309.012192023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>