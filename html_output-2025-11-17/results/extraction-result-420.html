<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-420 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-420</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-420</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-227053875</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2011.09860v1.pdf" target="_blank">Neural Abstract Reasoner</a></p>
                <p><strong>Paper Abstract:</strong> Abstract reasoning and logic inference are difficult problems for neural networks, yet essential to their applicability in highly structured domains. In this work we demonstrate that a well known technique such as spectral regularization can significantly boost the capabilities of a neural learner. We introduce the Neural Abstract Reasoner (NAR), a memory augmented architecture capable of learning and using abstract rules. We show that, when trained with spectral regularization, NAR achieves $78.8\%$ accuracy on the Abstraction and Reasoning Corpus, improving performance 4 times over the best known human hand-crafted symbolic solvers. We provide some intuition for the effects of spectral regularization in the domain of abstract reasoning based on theoretical generalization bounds and Solomonoff's theory of inductive inference.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e420.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e420.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NAR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Abstract Reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-augmented neural architecture that learns abstract rules by separating instruction inference and program execution: a Differentiable Neural Computer (DNC) infers an instruction set ψ which a Transformer decoder uses to execute per-instance transformations; trained end-to-end with spectral regularization to favor algorithmically simpler solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Abstract Reasoner (NAR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NAR is a hybrid, memory-augmented neural system designed for abstract reasoning on the ARC dataset. It consists of (1) an encoder/decoder convolutional autoencoder that maps grids to latent embeddings, (2) a Differentiable Neural Computer (DNC) meta-learner M that processes example input/output embeddings and produces an instruction set ψ, and (3) a Transformer decoder T that self-attends to inputs and cross-attends to ψ to produce the output grid. The whole pipeline is trained end-to-end with ADAM and uses spectral norm regularization (annealed schedule) to bias solutions toward lower algorithmic complexity; at evaluation it uses a few small adaptation (gradient) steps on the Transformer/DNC parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Implicit instruction set ψ produced by the DNC acting as a learned, program-like symbolic representation of rules; the paper frames these inferred instructions as abstract rules/programs but they are represented as continuous vectors (latent, program-like tokens) rather than explicit symbolic logic.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural architectures and gradient-based learning: (i) Differentiable Neural Computer (memory-augmented RNN/meta-learner) to infer ψ, (ii) Transformer decoder to execute instructions and map inputs to outputs, (iii) convolutional encoder/decoder for grid embeddings; trained with ADAM and few-shot adaptation steps.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular hybrid: the DNC (instruction inference) and Transformer (execution) are distinct modules; the DNC outputs a learned instruction set ψ which the Transformer cross-attends to (cross-attention layers), effectively conditioning execution on inferred instructions. The whole system is trained end-to-end, and at evaluation a small number of gradient-based adaptation steps are applied (inner-loop adaptation). Spectral regularization is applied during training to bias both modules jointly toward simpler/low-rank solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>1) Ability to learn and reuse abstract 'instruction sets' across tasks (meta-learning / slow weights in DNC) while the Transformer adapts quickly per-instance; 2) Strong generalization to novel ARC tasks (claimed algorithmic rule learning rather than memorization); 3) Rapid test-time adaptation — small gradient updates on Transformer (and negligible change to DNC) suffice to solve new tasks; 4) Empirical emergence of algorithmically simpler solutions (lower stable ranks) when spectral regularization applied, improving compression/generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Abstraction and Reasoning Corpus (ARC) — grid-based abstract reasoning and transformation tasks (train/eval each 400 tasks; paper uses tasks with grid sizes ≤10×10).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>78.8% accuracy on ARC evaluation (reported after 3 adaptation steps; grids up to 10×10; metric: percent of tasks solved exactly pixel-wise).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Reported strong generalization across the held-out ARC tasks: spectral regularization reduces stable ranks and spectral norms leading to simpler functions (argument via Lipschitz bounds and polynomial approximation) and substantially better OOD task performance. Empirically, DNC behaves as a slow meta-learner with near-zero gradient change at adaptation (gradient norm < 1e-7) while Transformer undergoes small adjustments, enabling fast adaptation to novel tasks (3 gradient steps to reach high accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Partially interpretable: the DNC produces an instruction set ψ that the Transformer uses; the authors argue ψ corresponds to abstract, program-like rules, and spectral regularization biases toward simpler (lower-complexity) programs; however ψ is a learned continuous embedding (not an explicit symbolic language), so interpretability is limited compared to explicit symbolic programs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Preliminary results limited to grids ≤10×10; reliance on spectral regularization (other regularizers failed); model needs few adaptation steps at evaluation (without adaptation reported performance is very low), implying dependence on test-time gradient updates; the inferred instruction set is latent (not an explicit symbolic program) so full symbolic interpretability and formal guarantees are absent; training and evaluation reported as preliminary.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Combination of empirical spectral-regularization-based generalization analysis and algorithmic information theory: authors argue spectral norm regularization reduces Lipschitz constant and stable ranks, steering the model toward functions approximable by low-degree polynomials (algorithmically simpler programs), and relate this to Solomonoff/Occam-style principles and Kolmogorov complexity proxies; generalization bounds referenced via spectral norms and stable ranks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Abstract Reasoner', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e420.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e420.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ARC Symbolic Solver</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hand-crafted symbolic solver (ARC Kaggle winner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-engineered symbolic solution to ARC constraints implemented in ≈7k lines of C++ that uses explicit hand-coded rules and heuristics to solve a subset of ARC tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ARC hand-crafted symbolic solver (Kaggle winner)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A fully symbolic, hand-engineered solver created for the ARC Kaggle challenge; implemented as approx. 7k lines of C++ with task-specific handcrafted rules and heuristics to transform input grids to outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit hand-coded symbolic rules / program logic implemented in C++ (rule-based heuristic program).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Classical procedural code (C++ implementations of heuristics and transformations) — not learned via gradient descent.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Not a hybrid in the learned sense — purely symbolic/procedural hand-coded pipeline; no neural integration reported.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Interpretable rule-based behaviour for tasks it covers; human-understandable transformations for many specific patterns, but limited coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Abstraction and Reasoning Corpus (ARC).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td>~20% accuracy on ARC (best-known human hand-crafted symbolic solver as reported in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Limited generalization: despite being engineered to capture many patterns, it succeeds on only ≈20% of ARC evaluation tasks, indicating limited ability to generalize across the broad variety of ARC problems.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability because rules are hand-crafted and explicit; solutions can be inspected and reasoned about by humans.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Low coverage (20% of ARC), substantial engineering effort required (≈7k LOC), brittle to tasks outside the manually encoded heuristics, not data-driven, not adaptive.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Pure symbolic engineering; no formal theoretical framework for learning or generalization beyond heuristic rule design is provided in the paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Abstract Reasoner', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e420.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e420.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DreamCoder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic program induction system (DreamCoder) that learns libraries of reusable symbolic programs from data using wake-sleep style learning combining program search and neural recognition models; capable of learning rules from geometry, vector algebra, and physics and solving generative tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DreamCoder</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A hybrid program induction framework that alternates between synthesizing explicit symbolic programs (using program search and Bayesian priors) and training neural recognition models to propose programs; learns a library of primitives to grow interpretable, reusable symbolic abstractions.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Explicit symbolic programs and learned library of symbolic primitives (programmatic rules and DSL fragments).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural recognition models used to guide search and propose program sketches; wake-sleep learning pairs symbolic search with neural proposal networks.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Wake-sleep alternating loop: symbolic program synthesis/search generates candidate programs (declarative) while neural proposal/recognition models are trained to suggest promising program components (imperative); the two components bootstrap each other but the symbolic programs remain explicit.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Learned reusable symbolic abstractions and interpretable programs that can generalize to compositional tasks; emergence of a growing library that speeds future synthesis and enables interpretable solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Geometry/vector-algebra/physics style program synthesis tasks and scene generation/drawing tasks (as reported by Ellis et al. in the cited work); not evaluated on ARC within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Reported by originating authors to yield improved generalization via learned symbolic abstractions and library growth; the current paper only briefly cites it as a capable exception among neuro-symbolic methods but notes such methods often require large amounts of data.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability because final solutions are explicit symbolic programs and learned libraries are human-understandable primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>According to the citing paper: typically data-hungry (requires lots of examples) which contrasts with ARC's few-shot setting; no direct ARC results reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Bayesian program learning and program induction with a wake-sleep style training loop coupling symbolic search and neural proposal models; interpretable library growth as a form of inductive bias.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Abstract Reasoner', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e420.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e420.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DNC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Neural Computer / Memory-augmented neural network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-augmented neural network (Differentiable Neural Computer) used here as a meta-learner to extract task context and infer an instruction set ψ from example I/O pairs; used as the slow-learning declarative-like component in NAR.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hybrid computing using a neural network with dynamic external memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Differentiable Neural Computer (DNC) as used in NAR</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The DNC is used to process the embeddings of example input/output pairs and to produce a latent instruction set ψ that summarizes the relations in the provided examples; in NAR it functions as the slow meta-learning module whose outputs are attended by the Transformer executor.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>In this paper the DNC's outputs serve as learned, program-like instruction representations (continuous vectors) which act analogously to a declarative instruction set, though they are not explicit symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>The DNC itself is a neural, gradient-trained, memory-augmented recurrent architecture (imperative procedural neural component) that implements read/write attention over an external memory.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular integration: the DNC's final output ψ is provided to the Transformer via cross-attention; both modules are trained jointly end-to-end, and spectral regularization is applied across weights to encourage simpler solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>When used in NAR, the DNC acts as a slow meta-learner (negligible gradient updates at evaluation) that provides reusable task context/instructions enabling the Transformer to generalize and adapt quickly; empirically DNC gradients at evaluation are near-zero, indicating stable instruction representations.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used within NAR for Abstraction and Reasoning Corpus (ARC) tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>As part of NAR, contributes to meta-learning and cross-task generalization by providing stable task representations; the paper reports that DNC's parameters change negligibly during test-time adaptation implying its role as a slow, generalizable module.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Limited: ψ is a latent continuous vector output (not an explicit symbolic program), so interpretability is indirect — the paper interprets ψ as instruction-like but does not provide a procedure to decode it into human-readable rules.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>ψ is latent and not explicitly symbolic; reliance on DNC does not by itself guarantee symbolic interpretability; the approach is validated only on ARC tasks (≤10×10 grids) in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Used operationally as a memory-augmented meta-learner within the NAR architecture; theoretical discussion in the paper focuses on how spectral regularization and stable ranks influence the algorithmic simplicity of functions learned by neural modules including the DNC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Neural Abstract Reasoner', 'publication_date_yy_mm': '2020-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning <em>(Rating: 2)</em></li>
                <li>Hybrid computing using a neural network with dynamic external memory <em>(Rating: 2)</em></li>
                <li>Differentiable programs with neural libraries <em>(Rating: 2)</em></li>
                <li>Meta-learning with memory-augmented neural networks <em>(Rating: 2)</em></li>
                <li>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-420",
    "paper_id": "paper-227053875",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "NAR",
            "name_full": "Neural Abstract Reasoner",
            "brief_description": "A memory-augmented neural architecture that learns abstract rules by separating instruction inference and program execution: a Differentiable Neural Computer (DNC) infers an instruction set ψ which a Transformer decoder uses to execute per-instance transformations; trained end-to-end with spectral regularization to favor algorithmically simpler solutions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Neural Abstract Reasoner (NAR)",
            "system_description": "NAR is a hybrid, memory-augmented neural system designed for abstract reasoning on the ARC dataset. It consists of (1) an encoder/decoder convolutional autoencoder that maps grids to latent embeddings, (2) a Differentiable Neural Computer (DNC) meta-learner M that processes example input/output embeddings and produces an instruction set ψ, and (3) a Transformer decoder T that self-attends to inputs and cross-attends to ψ to produce the output grid. The whole pipeline is trained end-to-end with ADAM and uses spectral norm regularization (annealed schedule) to bias solutions toward lower algorithmic complexity; at evaluation it uses a few small adaptation (gradient) steps on the Transformer/DNC parameters.",
            "declarative_component": "Implicit instruction set ψ produced by the DNC acting as a learned, program-like symbolic representation of rules; the paper frames these inferred instructions as abstract rules/programs but they are represented as continuous vectors (latent, program-like tokens) rather than explicit symbolic logic.",
            "imperative_component": "Neural architectures and gradient-based learning: (i) Differentiable Neural Computer (memory-augmented RNN/meta-learner) to infer ψ, (ii) Transformer decoder to execute instructions and map inputs to outputs, (iii) convolutional encoder/decoder for grid embeddings; trained with ADAM and few-shot adaptation steps.",
            "integration_method": "Modular hybrid: the DNC (instruction inference) and Transformer (execution) are distinct modules; the DNC outputs a learned instruction set ψ which the Transformer cross-attends to (cross-attention layers), effectively conditioning execution on inferred instructions. The whole system is trained end-to-end, and at evaluation a small number of gradient-based adaptation steps are applied (inner-loop adaptation). Spectral regularization is applied during training to bias both modules jointly toward simpler/low-rank solutions.",
            "emergent_properties": "1) Ability to learn and reuse abstract 'instruction sets' across tasks (meta-learning / slow weights in DNC) while the Transformer adapts quickly per-instance; 2) Strong generalization to novel ARC tasks (claimed algorithmic rule learning rather than memorization); 3) Rapid test-time adaptation — small gradient updates on Transformer (and negligible change to DNC) suffice to solve new tasks; 4) Empirical emergence of algorithmically simpler solutions (lower stable ranks) when spectral regularization applied, improving compression/generalization.",
            "task_or_benchmark": "Abstraction and Reasoning Corpus (ARC) — grid-based abstract reasoning and transformation tasks (train/eval each 400 tasks; paper uses tasks with grid sizes ≤10×10).",
            "hybrid_performance": "78.8% accuracy on ARC evaluation (reported after 3 adaptation steps; grids up to 10×10; metric: percent of tasks solved exactly pixel-wise).",
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Reported strong generalization across the held-out ARC tasks: spectral regularization reduces stable ranks and spectral norms leading to simpler functions (argument via Lipschitz bounds and polynomial approximation) and substantially better OOD task performance. Empirically, DNC behaves as a slow meta-learner with near-zero gradient change at adaptation (gradient norm &lt; 1e-7) while Transformer undergoes small adjustments, enabling fast adaptation to novel tasks (3 gradient steps to reach high accuracy).",
            "interpretability_properties": "Partially interpretable: the DNC produces an instruction set ψ that the Transformer uses; the authors argue ψ corresponds to abstract, program-like rules, and spectral regularization biases toward simpler (lower-complexity) programs; however ψ is a learned continuous embedding (not an explicit symbolic language), so interpretability is limited compared to explicit symbolic programs.",
            "limitations_or_failures": "Preliminary results limited to grids ≤10×10; reliance on spectral regularization (other regularizers failed); model needs few adaptation steps at evaluation (without adaptation reported performance is very low), implying dependence on test-time gradient updates; the inferred instruction set is latent (not an explicit symbolic program) so full symbolic interpretability and formal guarantees are absent; training and evaluation reported as preliminary.",
            "theoretical_framework": "Combination of empirical spectral-regularization-based generalization analysis and algorithmic information theory: authors argue spectral norm regularization reduces Lipschitz constant and stable ranks, steering the model toward functions approximable by low-degree polynomials (algorithmically simpler programs), and relate this to Solomonoff/Occam-style principles and Kolmogorov complexity proxies; generalization bounds referenced via spectral norms and stable ranks.",
            "uuid": "e420.0",
            "source_info": {
                "paper_title": "Neural Abstract Reasoner",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "ARC Symbolic Solver",
            "name_full": "Hand-crafted symbolic solver (ARC Kaggle winner)",
            "brief_description": "A human-engineered symbolic solution to ARC constraints implemented in ≈7k lines of C++ that uses explicit hand-coded rules and heuristics to solve a subset of ARC tasks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "ARC hand-crafted symbolic solver (Kaggle winner)",
            "system_description": "A fully symbolic, hand-engineered solver created for the ARC Kaggle challenge; implemented as approx. 7k lines of C++ with task-specific handcrafted rules and heuristics to transform input grids to outputs.",
            "declarative_component": "Explicit hand-coded symbolic rules / program logic implemented in C++ (rule-based heuristic program).",
            "imperative_component": "Classical procedural code (C++ implementations of heuristics and transformations) — not learned via gradient descent.",
            "integration_method": "Not a hybrid in the learned sense — purely symbolic/procedural hand-coded pipeline; no neural integration reported.",
            "emergent_properties": "Interpretable rule-based behaviour for tasks it covers; human-understandable transformations for many specific patterns, but limited coverage.",
            "task_or_benchmark": "Abstraction and Reasoning Corpus (ARC).",
            "hybrid_performance": null,
            "declarative_only_performance": "~20% accuracy on ARC (best-known human hand-crafted symbolic solver as reported in the paper).",
            "imperative_only_performance": null,
            "has_comparative_results": true,
            "generalization_properties": "Limited generalization: despite being engineered to capture many patterns, it succeeds on only ≈20% of ARC evaluation tasks, indicating limited ability to generalize across the broad variety of ARC problems.",
            "interpretability_properties": "High interpretability because rules are hand-crafted and explicit; solutions can be inspected and reasoned about by humans.",
            "limitations_or_failures": "Low coverage (20% of ARC), substantial engineering effort required (≈7k LOC), brittle to tasks outside the manually encoded heuristics, not data-driven, not adaptive.",
            "theoretical_framework": "Pure symbolic engineering; no formal theoretical framework for learning or generalization beyond heuristic rule design is provided in the paper's discussion.",
            "uuid": "e420.1",
            "source_info": {
                "paper_title": "Neural Abstract Reasoner",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "DreamCoder",
            "name_full": "DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning",
            "brief_description": "A neuro-symbolic program induction system (DreamCoder) that learns libraries of reusable symbolic programs from data using wake-sleep style learning combining program search and neural recognition models; capable of learning rules from geometry, vector algebra, and physics and solving generative tasks.",
            "citation_title": "Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning",
            "mention_or_use": "mention",
            "system_name": "DreamCoder",
            "system_description": "A hybrid program induction framework that alternates between synthesizing explicit symbolic programs (using program search and Bayesian priors) and training neural recognition models to propose programs; learns a library of primitives to grow interpretable, reusable symbolic abstractions.",
            "declarative_component": "Explicit symbolic programs and learned library of symbolic primitives (programmatic rules and DSL fragments).",
            "imperative_component": "Neural recognition models used to guide search and propose program sketches; wake-sleep learning pairs symbolic search with neural proposal networks.",
            "integration_method": "Wake-sleep alternating loop: symbolic program synthesis/search generates candidate programs (declarative) while neural proposal/recognition models are trained to suggest promising program components (imperative); the two components bootstrap each other but the symbolic programs remain explicit.",
            "emergent_properties": "Learned reusable symbolic abstractions and interpretable programs that can generalize to compositional tasks; emergence of a growing library that speeds future synthesis and enables interpretable solutions.",
            "task_or_benchmark": "Geometry/vector-algebra/physics style program synthesis tasks and scene generation/drawing tasks (as reported by Ellis et al. in the cited work); not evaluated on ARC within this paper.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Reported by originating authors to yield improved generalization via learned symbolic abstractions and library growth; the current paper only briefly cites it as a capable exception among neuro-symbolic methods but notes such methods often require large amounts of data.",
            "interpretability_properties": "High interpretability because final solutions are explicit symbolic programs and learned libraries are human-understandable primitives.",
            "limitations_or_failures": "According to the citing paper: typically data-hungry (requires lots of examples) which contrasts with ARC's few-shot setting; no direct ARC results reported in this paper.",
            "theoretical_framework": "Bayesian program learning and program induction with a wake-sleep style training loop coupling symbolic search and neural proposal models; interpretable library growth as a form of inductive bias.",
            "uuid": "e420.2",
            "source_info": {
                "paper_title": "Neural Abstract Reasoner",
                "publication_date_yy_mm": "2020-11"
            }
        },
        {
            "name_short": "DNC",
            "name_full": "Differentiable Neural Computer / Memory-augmented neural network",
            "brief_description": "A memory-augmented neural network (Differentiable Neural Computer) used here as a meta-learner to extract task context and infer an instruction set ψ from example I/O pairs; used as the slow-learning declarative-like component in NAR.",
            "citation_title": "Hybrid computing using a neural network with dynamic external memory",
            "mention_or_use": "use",
            "system_name": "Differentiable Neural Computer (DNC) as used in NAR",
            "system_description": "The DNC is used to process the embeddings of example input/output pairs and to produce a latent instruction set ψ that summarizes the relations in the provided examples; in NAR it functions as the slow meta-learning module whose outputs are attended by the Transformer executor.",
            "declarative_component": "In this paper the DNC's outputs serve as learned, program-like instruction representations (continuous vectors) which act analogously to a declarative instruction set, though they are not explicit symbolic rules.",
            "imperative_component": "The DNC itself is a neural, gradient-trained, memory-augmented recurrent architecture (imperative procedural neural component) that implements read/write attention over an external memory.",
            "integration_method": "Modular integration: the DNC's final output ψ is provided to the Transformer via cross-attention; both modules are trained jointly end-to-end, and spectral regularization is applied across weights to encourage simpler solutions.",
            "emergent_properties": "When used in NAR, the DNC acts as a slow meta-learner (negligible gradient updates at evaluation) that provides reusable task context/instructions enabling the Transformer to generalize and adapt quickly; empirically DNC gradients at evaluation are near-zero, indicating stable instruction representations.",
            "task_or_benchmark": "Used within NAR for Abstraction and Reasoning Corpus (ARC) tasks.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "As part of NAR, contributes to meta-learning and cross-task generalization by providing stable task representations; the paper reports that DNC's parameters change negligibly during test-time adaptation implying its role as a slow, generalizable module.",
            "interpretability_properties": "Limited: ψ is a latent continuous vector output (not an explicit symbolic program), so interpretability is indirect — the paper interprets ψ as instruction-like but does not provide a procedure to decode it into human-readable rules.",
            "limitations_or_failures": "ψ is latent and not explicitly symbolic; reliance on DNC does not by itself guarantee symbolic interpretability; the approach is validated only on ARC tasks (≤10×10 grids) in this paper.",
            "theoretical_framework": "Used operationally as a memory-augmented meta-learner within the NAR architecture; theoretical discussion in the paper focuses on how spectral regularization and stable ranks influence the algorithmic simplicity of functions learned by neural modules including the DNC.",
            "uuid": "e420.3",
            "source_info": {
                "paper_title": "Neural Abstract Reasoner",
                "publication_date_yy_mm": "2020-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning",
            "rating": 2,
            "sanitized_title": "dreamcoder_growing_generalizable_interpretable_knowledge_with_wakesleep_bayesian_program_learning"
        },
        {
            "paper_title": "Hybrid computing using a neural network with dynamic external memory",
            "rating": 2,
            "sanitized_title": "hybrid_computing_using_a_neural_network_with_dynamic_external_memory"
        },
        {
            "paper_title": "Differentiable programs with neural libraries",
            "rating": 2,
            "sanitized_title": "differentiable_programs_with_neural_libraries"
        },
        {
            "paper_title": "Meta-learning with memory-augmented neural networks",
            "rating": 2,
            "sanitized_title": "metalearning_with_memoryaugmented_neural_networks"
        },
        {
            "paper_title": "The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision",
            "rating": 1,
            "sanitized_title": "the_neurosymbolic_concept_learner_interpreting_scenes_words_and_sentences_from_natural_supervision"
        }
    ],
    "cost": 0.01295375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Neural Abstract Reasoner</p>
<p>Victor Kolev victor.kolev@yahoo.com 
Bogdan Georgiev bogdan.m.georgiev@gmail.com 
Svetlin Penkov 
Svet@sciro Ai 
Neural Abstract Reasoner</p>
<p>reasoning and logic inference are difficult problems for neural networks, yet essential to their applicability in highly structured domains. In this work we demonstrate that a well known technique such as spectral regularization can significantly boost the capabilities of a neural learner. We introduce the Neural Abstract Reasoner (NAR), a memory augmented architecture capable of learning and using abstract rules. We show that, when trained with spectral regularization, NAR achieves 78.8% accuracy on the Abstraction and Reasoning Corpus, improving performance 4 times over the best known human hand-crafted symbolic solvers. We provide some intuition for the effects of spectral regularization in the domain of abstract reasoning based on theoretical generalization bounds and Solomonoff's theory of inductive inference.</p>
<p>Introduction</p>
<p>Extracting and reasoning with abstract concepts is a crucial ability for any learner that is to operate in combinatorially complex open worlds or domains with limited or structured data. It is well known that neural learners struggle to operate in such conditions due to their poor generalization capabilities in structured domains [6,17]. In this work, we demonstrate that spectral regularization provides neural networks with a strong inductive bias towards learning and utilizing abstract concepts akin to a symbolic learner.</p>
<p>For that purpose, we employ the Abstraction and Reasoning Corpus (ARC) [6] which contains tasks related to manipulating colored patterns in a grid. In order to successfully solve the tasks in the corpus an agent needs to be able to count, manipulate numbers, work with topological and geometric concepts as well as recognise the notion of objects. There are 400 training tasks and 400 (distinct) evaluation tasks. Each task has a small set of input-output example pairs (between 1 and 5) and a query input pattern. This is quite a challenging dataset due to the small amount of example data, large number of different tasks and their abstract nature. So far, the best known solution, with a success rate of 20%, is the winner of the ARC Kaggle challenge, and it is a carefully hand-crafted symbolic solver written in approx. 7k lines of C++ code. In this paper, we introduce the Neural Abstract Reasoner (NAR) which achieves an accuracy rate of 79% and so outperforming even the best symbolic solver created by a human. The NAR architecture contains a Differentiable Neural Computer (DNC) that learns general problem solving skills and a Transformer network responsible for solving particular task instances (see. Fig 2 in Chollet [6]). 7u Importantly, spectral regularization plays a fundamental role in the successful training of NAR. From a purely machine learning perspective, spectral regularization is known to reduce the effective number of parameters in the network, however we provide some additional theoretical intuition and demonstrate that spectral regularization also pushes the network towards finding algorithmically simpler solutions as recommended by Solomonoff's theory of inductive inference [14].</p>
<p>Related Work</p>
<p>Neuro-symbolic architectures Hybrid neuro-symbolic approaches enable agents to solve structured tasks from raw data, while learning faster and being more robust to noise [9,28,19,16]. However, the majority of methods proposed so far are designed with specific domains in mind, making them inapplicable to a broader range of tasks. A notable exception is the architecture proposed by Ellis et al. [7], which is capable of learning rules from geometry, vector algebra, and physics and solve tasks such as drawing pictures or building complete scenes. Importantly, these methods often require lots of data, which is in stark contrast with human capabilities.</p>
<p>The ARC dataset [6] is specially designed to push research towards data efficient learners, as there are hunderds of tasks, each of which is represented by no more than 5 input/output examples. To the best of our knowledge, the Neural Abstract Reasoner, presented in this paper, is the first architecture that achieves a performance rate of 79% on the ARC dataset, outperforming state-of-the-art hand-coded symoblic systems by a factor of 4. The NAR architecture is a composition of a slowly learning Differentiable Neural Computer and a fast adapting Transformer network creating an outer learning and inner executing loops, as suggested in [6].</p>
<p>Complexity and generalization The analysis of complexity and generalization metrics applied to neural networks has formed a central line of theoretical ML research with a variety of recent breakthroughs in terms of PAC-based and compression methods (cf. [2,3,11,23,29] and the references therein). In particular, many generalization approaches based on spectral norm analysis have been so far proposed and investigated [18,21]. However, to our knowledge the present work is the first to address the relationship between spectral norms' behaviour and abstract reasoning tasks, whereby a strong relationship between a classical spectral regularisation and the ability of a neural model towards learning abstract reasoning (concepts and rules) is demonstrated. As touched upon in Section 4, one could draw motivation from well-known algorithmic information theory concepts such as Solomonoff inference and program generation based on least complexity [14,4,22].</p>
<p>Methods</p>
<p>Description The ARC dataset consists of a train and evaluation portions D and D v , respectively. Each portion consists of 400 tasks (train tasks are augmented to ≈15000 through color permutations and rotations). The individual tasks T are grouped in tags τ based on the skills needed to solve them [5]. consists of up to five example input-output pairs and one query pair. A neural learner has to infer a logical rule π : i → o. All inputs and outputs are grids of variable sizes with 10 colors. A solution is correct only when all the pixels on the grid match.</p>
<p>First, we derive a latent representation of the grids with an InceptionNet-style [24] deterministic auto-encoder. Let G ∈ {0, . . . , 9} 10×10 be a grid, and E : G → R n , D : R n → G be the encoder and decoder, parametrized by θ. We train an embedding network by minimizing the standard autoencoder cross-entropy loss min θ : L e = G∈D H G, D(E(G))|θ .</p>
<p>Next, we consider all latent grid embeddings, and we train a Differentiable Neural Computer [10] M µ with parameters µ to infer an instruction set ψ. All inputs are processed by a Transformer Decoder Stack T [27] with parameters η, which self-attends to all inputs and cross-attends to ψ:
ψ = M µ [i e 1 , o e 1 ]; . . . ; [i e 5 , o e 5 ] , o j = T η i j |ψ; i k,k =j .
The whole model is then trained end-to-end via ADAM [12] to minimize the cross-entropy loss between the query target and the decoded test output prediction.
min µ,η : L = T ∈D H D(o q ), D( o q |µ, η)
We employ a two-stage curriculum during training, first training only a on a single tag τ , and then expanding to the whole train dataset D. Additionally, during the first stage of training, spectral regularization [30] with a larger λ value is applied, which is then annealed in the second stage. When evaluating the model, we apply additional optimization steps (similar to [8,13]), as described in Algorithm 1. See Appendix C for additional details.</p>
<p>Motivation We build on methods from Santoro et al. [20] and use a memory-augmented neural network (the Differentiable Neural Computer [10]) to derive context for the current task. The multiple read heads and attention mechanisms allow the DNC to relate the input and the output of a pair and compare them to the other input/output pairs that it has already processed. Unlike Santoro et al. [20], we leverage a Transformer to carry out the task execution based on the DNC context. This decouples the learning of the instruction set from the program execution itself, and allows us to use the input/output relations directly, rather than the more standard [i t , o t−1 ]. Lastly, the Transformer network relates the inputs to each other, thereby exploiting similarities within them.</p>
<p>Performance As this work is still in progress, these are preliminary results evaluated on grids up to 10×10. Nonetheless, we outperform all currently known solutions, including a hand-crafted symbolic solution (see Fig. 1). Spectral regularization proved instrumental for this, and other regularization methods did not yield any significant results (see Fig. 2).</p>
<p>Without any additional adaptation steps [8], evaluation performance remains low at 1%, while only after 3 steps, that number climbs up to 78.8%. Analyzing more closely the network changes made by the adaptation steps, the gradient norm of M is &lt; 1 × 10 −7 , which implies that the DNC is acting as a true meta-learner, and only the Transformer requires a small change [3 × 10 −4 , 7 × 10 −3 ] to execute the instructions flawlessly. We again attribute this generalization to spectral regularization. 
Algorithm 1: NAR evaluation cycle Given: D v evaluation dataset; E, D, M µ , T η ; Hyperparameters: α step size; k number of steps for Task T ∈ D v do µ 0 ← µ, η 0 ← η for step in 1:k do ψ = M µstep−1 [i e 1 , o e 1 ]; . . . ; [i e 5 , o e 5 ] [ o e 1 , . . . , o 5 e ] = T ηstep−1 [i e 1 , . . . , i e 5 , i q ]|ψ Evaluate L = 5 i=1 H D(o e i ), D( o e i ) Adjust parameters: µ step ← µ step−1 − α∇ µstep−1 L η step ← η step−1 − α∇ ηstep−1 L end ψ = M µ k [i e 1 ,</p>
<p>Effects of spectral regularization: stable ranks and complexity</p>
<p>The surprisingly significant effect of a simple spectral regularization strategy in the reasoning tasks suggests strong connections with generalization and the underlying model complexity estimates. On one hand, this motivates the analysis of spectral regularization in terms of some well-known generalization bounds (e.g. based on stable rank and spectral norms), however, we first discuss a perspective inspired by algorithmic information theory. Intuitively, abstract reasoning tasks are induced by a concise set of logic rules and combinatorial patterns, and, hence, it is natural to search for short programs producing these rules -in this regard, we give motivation as to why spectral regularization naturally shrinks the search space towards shorter programs.</p>
<p>Spectral regularization and polynomials as algorithmically simple programs. Classical methods from program inference and algorithmic information theory, such as Solomonoff inference and Occam's razor [14], suggest that "simpler" program models are preferable in terms of forming abstract concepts and generalization -a formal approach towards such issues is given, e.g., by Kolmogorov complexity theory [14,22]. Although the evaluation of algorithmic complexity is a demanding task (Kolmogorov complexity is theoretically uncomputable), one could attempt to devise various proxy metrics that capture the algorithmic complexity of a given function/program.</p>
<p>Here, in an attempt to evaluate and explain the algorithmic complexity of our models from a spectralregularization perspective, we consider approximations in terms of a simple but flexible class π n of programs computing rational-coefficient polynomials of maximal degree n ∈ N. Intuitively, approximating a model f in terms of π n for lower values of n corresponds to discovering programs of decreased algorithmic length (in terms of operations) that effectively compute f . In this direction, we bring forward some classical approximation theory results implying that lower spectral norms yield lower degrees of the approximation polynomial. To ease notation, here we discuss the 1-dimensional case, however, similar results hold for higher dimensions as well [26]: Since the Lipschitz constant of a neural model is bounded above by the spectral norms of the layers W i , spectral regularization gives control over L; moreover, a lower value of L implies that one can decrease the polynomial degree n and retain similar approximation qualities. These observations support our empirical results -introducing spectral regularization steers the model search space towards algorithmically simpler and more robust functions.</p>
<p>Generalization via spectral norms and stable ranks. We recall that the stable rank of a matrix A, rank s (A), is defined as the ratio A 2 F / A 2 2 and note that rank s (A) is at most the rank of A. The stable rank is intuitively understood as a continuous proxy to rank(A) and as a measure for the true parameter count of A. Now, let f be a deep neural model consisting of d layers whose corresponding weight matrices are denoted by W i , i = 1, . . . , d. Recent works (e.g. [18,2]) obtain generalization bounds on f , roughly speaking, in terms of the expression O
d i=1 W i 2 2 d i=1 rank s (W i ) ,
where W i 2 denotes the spectral norm of the matrix W i . A related stronger compression-based estimate in terms of so-called noise-cushions is obtained in [2]. In other words, the generalization error is influenced by the spectral norms as well as stable ranks of the layers.</p>
<p>In this direction, we evaluated our model and the effect of stable ranks. Interpreting Fig. 3, one observes that initially while the model adopts to the single task of pattern_expansion it increases and stabilizes a true parameter count ∼ 8000; afterwards, the model is introduced to the full task bundle where a significant decrease of the stable ranks is observed -according to the last expression this leads to better generalization, and further implies that at the end of training one actually deals with simpler models with better compression properties.  Sum of stable ranks during training Figure 3: Stable ranks vary drastically depending on the task distribution. With a larger pool of tasks, NN's stable ranks decrease rapidly, as it is optimized for greater generalization, as opposed to specialization to a particular task.</p>
<p>Conclusion and Acknowledgements</p>
<p>We have demonstrated the spectral regularization provides neural learners with a significant boost in performance on abstract reasoning tasks. We believe that studying the complexity of the underlying models in the context of powerful frameworks such as Kolmogorov complexity or Solomonoff's theory of inductive inference is a promising step towards closing the neuro-symbolic gap. We would like to thank Dimitar Vasilev (Microsoft Inc.) for the computational resources used in this work.</p>
<p>Appendix A Abstraction and Reasoning Corpus</p>
<p>The Abstraction and Reasoning Corpus (ARC) [6] is a dataset of grid-based pattern recognition and pattern manipulation tasks. A decision-making agent sees a small number of examples of input and output grids that illustrate the underlying logical relationship between them. It then has to infer this logical rule and apply it correctly on a test query.</p>
<p>In many ways, the benchmark is similar to the Bongard problems (view [15]) -relations are highly abstract and geometric. Moreover, only 3-5 examples are presented for each task, therefore, the benchmark tests the ability of an decision-making agent to (i) grasp abstract logic and (ii) adapt quickly to new tasks.</p>
<p>There are 400 training and 400 evaluation task examples, structured as follows:</p>
<p>• each task consists of a train and a test set;</p>
<p>• the train set includes 3-5 input/output pairs;</p>
<p>• the test set includes 1 input/output pair;</p>
<p>• an input/output pair is comprised of an input grid and an output grid, the relation between which follows a consistent logic throughout the task;</p>
<p>• grids are rectangular and are divided into 1 × 1 squares;</p>
<p>• grid patterns are drawn with 10 colors;</p>
<p>• grid sizes vary between 1 and 30 in length and width; input and output grid sizes are not necessarily equal.</p>
<p>No set of rules exists that can solve all tasks, and while some skills are useful for multiple of them, each task has its own unique principle. This makes trivial approaches like brute-force computation impractical.</p>
<p>If a human was approaching those tasks, they would easily be able to spot logical relations -we have developed the necessary priors to find similarities and infer logic. Therefore, ideally the neural network would derive this prior during training, and that would allow it to generalize well to the evaluation dataset.</p>
<p>For the current scope of our research we use all tasks with grids of size not larger than 10 × 10. For the train set, we augment the tasks to 15000 by permuting colors and by exploiting that the tasks are invariant to rotation and symmetry.</p>
<p>Abstraction and Reasoning Corpus</p>
<p>Training Evaluation  </p>
<p>Appendix B Grid Embedding</p>
<p>Prior to embedding, we zero-pad all grids to be 10 × 10, with the original grid in the center of the image. Additionally, colors in the grids are represented as one-hot vectors, making the final dimensionality of the grids 10 × 10 × 10 (10 colors).</p>
<p>The embedding is done with a convolutional neural network, comprised of an encoder and a decoder. The encoder consists of a basket of 10 convolutions of filter sizes equal to 1, . . . 10 (the C module, Fig. 5). Different filter sizes enable the network to capture both local and global patterns. The convolution outputs are flattened and passed to linear layers with hyperbolic tangent activation functions, which transform them into the desired dimensionality (n = 256). A second neural network R computes weights for summing the 10 resulting vectors. The decoder shares the same architecture with the encoder, but in reverse order -first linear layers, after that convolutions and then a weighted sum; finally a softmax over the color dimension.</p>
<p>Summing the convolutional outputs enables the embedding network to be agnostic to the order in which it receives them (as would be with an RNN for instance). The weighs reflect the fact that grid sizes vary and therefore not all filter sizes would be equally applicable or useful.</p>
<p>While training the Embedding network, we found that spectral regularization again proved to be instrumental for achieving 95% perfect reconstruction accuracy. In contrast, networks regularized by weight decay failed to climb above 6%.</p>
<p>What is more, tanh functions yielded a network that is 3 orders of magnitude more stable to Gaussian input noise than the same network, trained under the same conditions, with ReLU activations. We postulate that this is due to the fact that ReLU is unbounded for x &gt; 0, therefore random perturbations would have a greater impact.</p>
<p>Appendix C Architecture Details Figure 6 and 7 give greater detail about the architecture we devise, as well as the procedure for training it end-to-end.</p>
<p>Embedding Training</p>
<p>Single-task Training   : When we observed that stable ranks, a proxy of the number of parameters, were negatively correlated with generalization performance, we analyzed if an explicitly smaller model would improve performance without spectral regularization. While better performance and greater variance are observed, the model with spectral regularization remains unmatched.</p>
<p>A task T j = [i e 1 , o e 1 ]; . . . ; [i e 5 , o e 5 ]; [i q , o q ]</p>
<p>o e 1 Figure 1 :
11]; . . . ; [i e 5 , o e 5 ] [ o e 1 , . . . , o 5 e , o q ] = T η k [i e 1 , . . . , i e 5 , i q ]|ψ Compute accuracy of o q end We achieve 78.8% evaluation accuracy on the ARC dataset. The reported results are calculated for 100 unseen tasks from the corpus.</p>
<p>Proposition 1 .
1Let f : [0, 1] → R represent a model with Lipschitz constant L. Then, there exists a polynomial B n ∈ π n of degree n, so that f − B n L ∞ [0,1] ≤ 3L 2 √ n , where . L ∞ [0,1] denotes the usual sup-norm over the interval [0, 1].</p>
<p>Figure 2 :
2Performance on the pattern expansion task from the ARC dataset. The exact same models (DNC Transformer) were trained with and without spectral regularization.</p>
<p>Figure 4 :
4Structure of the Abstraction and Reasoning Corpus dataset.</p>
<p>Figure 5 :
5Structure of the Embedding network.</p>
<p>Figure 6 :Figure 7 :
67Order of procedures in training the model. Total runtime is ∼ 50 hours on a single K80 GPU. We use a memory-augmented neural network (DNC) to extract the context of the current task from example input-output pairs [i e 1 , o e 1 ], . . . , [i e n , o e n ]. The final DNC output is passed to the cross-attention layers of a Transformer Decoder, which processes all inputs (examples and query) and produces output predictions. Loss is calculated as by-pixel cross-entropy of the output predictions and the targets, and the model is trained end-to-end.</p>
<p>Figure 8
8Figure 8: When we observed that stable ranks, a proxy of the number of parameters, were negatively correlated with generalization performance, we analyzed if an explicitly smaller model would improve performance without spectral regularization. While better performance and greater variance are observed, the model with spectral regularization remains unmatched.
Appendix E HyperparamtersAppendix F Approximation via polynomial programsIn this Section we briefly elaborate on the polynomial approximation mentioned in the main text. In general, classical results in this direction are based, e.g. on Chebyshev, Legendre and Bersntein polynomial approximations. Here we discuss a 1-dimensional approximation via Bernstein polynomials, but similar estimates hold in higher dimensions as well as other polynomial schemes (e.g. Chebyshev). We refer to[1,26]for a thorough collection of results as well as further references.A well-known method of approximating one-dimensional continuous functions is by means of Bernstein polynomials. Let f : [0, 1] → R be continuous. The Bernstein polynomial Bn(f ; t) of order n corresponding to f is defined as:Theorem 1. The following estimate holds:where ω denotes the modulus of continuity defined asIn other words, ω measures the maximal jump |f (x) − f (y)| over points x, y which are no more than a distance δ apart.Note that whenever f has a Lipschitz constant L, the modulus of continuity ω(f, δ) is controlled above via Lδ. Applying this bound in the estimate of Theorem 1 yields the result mentioned in the text. As already mentioned, more technical high dimensional analogues of the estimates are also available [26, 1] -e.g. an analogues result for Chebyshev polynomials holds where the modulus of continuity ω is appropriately replaced by extrema over complex ellipsoids[25].
10.1007/978-3-540-30726-6_5Polynomial Approximation Theory. Berlin Heidelberg; Berlin, HeidelbergSpringerPolynomial Approximation Theory. Springer Berlin Heidelberg, Berlin, Heidelberg, 2006. ISBN 978-3-540-30726-6. doi: 10.1007/978-3-540-30726-6_5. URL https://doi.org/10.1007/ 978-3-540-30726-6_5.</p>
<p>Stronger generalization bounds for deep nets via a compression approach. Sanjeev Arora, Rong Ge, Behnam Neyshabur, Yi Zhang, 35th International Conference on Machine Learning, ICML 2018. 1ISBN 9781510867963Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep nets via a compression approach. In 35th International Conference on Machine Learning, ICML 2018, volume 1, pages 390-418, 2018. ISBN 9781510867963.</p>
<p>Spectrally-normalized margin bounds for neural networks. L Peter, Dylan J Bartlett, Matus Foster, Telgarsky, Advances in Neural Information Processing Systems. Peter L. Bartlett, Dylan J. Foster, and Matus Telgarsky. Spectrally-normalized margin bounds for neural networks. In Advances in Neural Information Processing Systems, 2017.</p>
<p>The description length of deep learning models. Léonard Blier, Yann Ollivier, ; S Bengio, H Wallach, H Larochelle, K Grauman, N Cesa-Bianchi, R Garnett, Advances in Neural Information Processing Systems. Curran Associates, Inc31Léonard Blier and Yann Ollivier. The description length of deep learning models. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 2216-2226. Curran Associates, Inc., 2018. URL http://papers.nips. cc/paper/7490-the-description-length-of-deep-learning-models.pdf.</p>
<p>Task tagging. Kaggle public notebook. Davide Bonin, Davide Bonin. Task tagging. Kaggle public notebook. URL https://www.kaggle.com/davidbnn92/ task-tagging. Accessed on 08.10.2020.</p>
<p>On the measure of intelligence. Francois Chollet, arXiv:1911.01547arXiv preprintFrancois Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547, 2019.</p>
<p>Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sable-Meyer, Luc Cary, Lucas Morales, Luke Hewitt, Armando Solar-Lezama, Joshua B Tenenbaum, arXiv:2006.08381Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning. arXiv preprintKevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sable-Meyer, Luc Cary, Lucas Morales, Luke Hewitt, Armando Solar-Lezama, and Joshua B Tenenbaum. Dreamcoder: Growing generalizable, interpretable knowledge with wake-sleep bayesian program learning. arXiv preprint arXiv:2006.08381, 2020.</p>
<p>Model-agnostic meta-learning for fast adaptation of deep networks. Chelsea Finn, Pieter Abbeel, Sergey Levine, arXiv:1703.03400arXiv preprintChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. arXiv preprint arXiv:1703.03400, 2017.</p>
<p>Differentiable programs with neural libraries. L Alexander, Marc Gaunt, Nate Brockschmidt, Daniel Kushman, Tarlow, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning70Alexander L Gaunt, Marc Brockschmidt, Nate Kushman, and Daniel Tarlow. Differentiable programs with neural libraries. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1213-1222, 2017.</p>
<p>Hybrid computing using a neural network with dynamic external memory. Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Nature. 5387626Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538(7626):471-476, 2016.</p>
<p>Fantastic generalization measures and where to find them. Yiding Jiang, * , Behnam Neyshabur, * , Hossein Mobahi, Dilip Krishnan, Samy Bengio, International Conference on Learning Representations. Yiding Jiang<em>, Behnam Neyshabur</em>, Hossein Mobahi, Dilip Krishnan, and Samy Bengio. Fantastic generalization measures and where to find them. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SJgIPJBFvH.</p>
<p>Adam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.</p>
<p>Dynamic evaluation of neural sequence models. Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals, International Conference on Machine Learning. Ben Krause, Emmanuel Kahembwe, Iain Murray, and Steve Renals. Dynamic evaluation of neural sequence models. In International Conference on Machine Learning, pages 2766-2775, 2018.</p>
<p>An Introduction to Kolmogorov Complexity and Its Applications. Ming Li, M B Paul, Vitanyi, Springer Publishing CompanyIncorporated, 3 edition. ISBN 0387339981Ming Li and Paul M.B. Vitanyi. An Introduction to Kolmogorov Complexity and Its Applications. Springer Publishing Company, Incorporated, 3 edition, 2008. ISBN 0387339981.</p>
<p>A glimpse at the metaphysics of bongard problems. Alexandre Linhares, Artificial Intelligence. 1211-2Alexandre Linhares. A glimpse at the metaphysics of bongard problems. Artificial Intelligence, 121(1-2): 251-270, 2000.</p>
<p>The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenenbaum, Jiajun Wu, International Conference on Learning Representations. Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenenbaum, and Jiajun Wu. The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. In International Conference on Learning Representations, 2018.</p>
<p>Gary Marcus, arXiv:1801.00631Deep learning: A critical appraisal. arXiv preprintGary Marcus. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018.</p>
<p>Exploring generalization in deep learning. Srinadh Behnam Neyshabur, David Bhojanapalli, Nathan Mcallester, Srebro, Advances in Neural Information Processing Systems. Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. Exploring generalization in deep learning. In Advances in Neural Information Processing Systems, 2017.</p>
<p>Learning programmatically structured representations with perceptor gradients. Svetlin Penkov, Subramanian Ramamoorthy, International Conference on Learning Representations. Svetlin Penkov and Subramanian Ramamoorthy. Learning programmatically structured representations with perceptor gradients. In International Conference on Learning Representations, 2018.</p>
<p>Metalearning with memory-augmented neural networks. Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap, International conference on machine learning. Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta- learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850, 2016.</p>
<p>Stable rank normalization for improved generalization in neural networks and gans. Amartya Sanyal, Philip H Torr, Puneet K Dokania, International Conference on Learning Representations. Amartya Sanyal, Philip H. Torr, and Puneet K. Dokania. Stable rank normalization for improved general- ization in neural networks and gans. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=H1enKkrFDB.</p>
<p>Discovering neural nets with low kolmogorov complexity and high generalization capability. Jürgen Schmidhuber, 10.1016/S0893-6080(96)00127-XNeural Netw. 105Jürgen Schmidhuber. Discovering neural nets with low kolmogorov complexity and high generalization capability. Neural Netw., 10(5):857-873, July 1997. ISSN 0893-6080. doi: 10.1016/S0893-6080(96) 00127-X. URL https://doi.org/10.1016/S0893-6080(96)00127-X.</p>
<p>Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network. Taiji Suzuki, Hiroshi Abe, Tomoaki Nishimura, International Conference on Learning Representations. Taiji Suzuki, Hiroshi Abe, and Tomoaki Nishimura. Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network. International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=ByeGzlrKwH.</p>
<p>Going deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionChristian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1-9, 2015.</p>
<p>Multivariate polynomial approximation in the hypercube. L Trefethen, Proceedings of the American Mathematical Society. 145L Trefethen. Multivariate polynomial approximation in the hypercube. Proceedings of the American Mathematical Society, 145:4837-4844, 2017.</p>
<p>Approximation Theory and Approximation Practice. Lloyd N Trefethen, SIAMLloyd N. Trefethen. Approximation Theory and Approximation Practice. SIAM, 2013.</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017.</p>
<p>Programmatically interpretable reinforcement learning. Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, Swarat Chaudhuri, International Conference on Machine Learning. Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri. Pro- grammatically interpretable reinforcement learning. In International Conference on Machine Learning, pages 5045-5054, 2018.</p>
<p>Data-dependent sample complexity of deep neural networks via lipschitz augmentation. Colin Wei, Tengyu Ma, Advances in Neural Information Processing Systems. Curran Associates, Inc32Colin Wei and Tengyu Ma. Data-dependent sample complexity of deep neural networks via lipschitz augmentation. In Advances in Neural Information Processing Systems 32, pages 9725-9736. Curran Associates, Inc., 2019.</p>
<p>Yuichi Yoshida, Takeru Miyato, arXiv:1705.10941Spectral norm regularization for improving the generalizability of deep learning. arXiv preprintYuichi Yoshida and Takeru Miyato. Spectral norm regularization for improving the generalizability of deep learning. arXiv preprint arXiv:1705.10941, 2017.</p>            </div>
        </div>

    </div>
</body>
</html>