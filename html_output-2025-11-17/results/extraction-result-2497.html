<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2497 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2497</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2497</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-240261316</p>
                <p><strong>Paper Title:</strong> Artificial intelligence: A powerful paradigm for scientific research</p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2497.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2497.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoML / NAS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automatic Machine Learning / Neural Architecture Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated methods that generate and optimize neural network architectures using algorithms such as reinforcement learning controllers and evolutionary algorithms to produce high-performing DNNs without manual architecture design.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoML / Neural Architecture Search (NAS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A family of automated model-design methods described in the paper: (1) RL-based NAS where an RNN controller generates network architectures token-by-token and uses validation accuracy as a reward to update the controller via policy gradient; (2) evolutionary NAS where populations of architectures undergo selection, crossover and mutation guided by fitness (accuracy) to evolve high-quality networks. The paper cites EfficientNet as an example of a state-of-the-art network discovered via NAS.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>neural-architecture-search (AutoML) — RL-based and evolutionary</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>information science / machine learning (general across domains)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate neural-network 'hypotheses' (architectures) via (a) an RNN controller trained with reinforcement learning that samples architecture descriptions and receives validation accuracy as reward; (b) population-based evolutionary operators (selection, crossover, mutation) that iteratively produce improved architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Implicit: novelty measured indirectly by improved validation performance relative to prior architectures (accuracy/fitness); no explicit novelty metric described in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Validation-set performance (accuracy) of trained candidate architectures used as primary plausibility/quality signal.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Not explicitly formalized; trade-off handled implicitly by optimization objective (maximize validation accuracy) and search constraints (search space design, regularization).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Validation-set accuracy (or task-specific validation metric) used as fitness/reward; paper cites overall accuracy gains (e.g., EfficientNet outperforming human-designed networks).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational validation via training candidate networks and measuring validation/test performance metrics (accuracy); selection based on these metrics prior to deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Not detailed in paper beyond standard ML evaluation (validation/test splits and reporting of benchmark results).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Standard ML benchmarks implied (image classification benchmarks used to evaluate discovered architectures such as those that produced EfficientNet) but not enumerated in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper cites that NAS-discovered models (example EfficientNet) outperform human-designed models; no unified numeric benchmark in this survey apart from references to literature (e.g., EfficientNet results in original NAS paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Survey states NAS-designed networks can surpass networks designed by AI experts (e.g., EfficientNet derived through NAS), but gives no detailed numerical comparisons within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>EfficientNet cited as an example of a high-performing architecture discovered via NAS (reference to original NAS work).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High computational cost for large-scale NAS; need for careful search-space design; potential lack of interpretability of resulting architectures; requirement of large validation datasets for reliable fitness measurement.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2497.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Doctor Watson</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>IBM Watson (Doctor Watson clinical decision support)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An NLP-driven clinical decision-support system that searches large corpora of medical history and literature to propose ranked treatment options and reports a confidence score for proposals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Doctor Watson (IBM Watson clinical support)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An application of the IBM Watson platform that leverages natural language processing (NLP) to ingest electronic medical records and literature, retrieve relevant prior cases and guidelines, rank candidate treatment proposals based on prior knowledge reserves and model ensembles, and output a final proposal with an associated confidence score.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>NLP-based retrieval + expert-system / ensemble ranking</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>medicine / clinical decision support</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate clinical treatment hypotheses by searching and retrieving similar historical patient cases and synthesizing recommendations from stored prior-knowledge models and literature; ranking provides top candidate interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Generates confidence estimates for proposed treatments based on internal model ensemble ranking and prior-knowledge matching; plausibility judged by matching to previous cases and literature.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Outputs a confidence score for each proposal; specific metric calculation not described in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Comparison/ranking against prior clinical cases and reference knowledge bases; the system presents confidence scores for clinician review (human-in-the-loop validation implied).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Not detailed in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Implicit reliance on literature and prior case bases to ground recommendations; no explicit hallucination-prevention protocol described.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Confidence scores for proposals (system-reported), but no methodological details provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey notes Doctor Watson provides proposals and confidence but also highlights limitations (domain bias due to training data from US hospitals); no numeric performance metrics provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>No quantitative comparison with human clinicians in this survey; the paper notes practical limitations such as region-specific training data affecting suitability elsewhere.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Dependence on region-specific training data and prior knowledge (may not generalize across healthcare systems); still considered a 'black box' by clinicians; potential mismatch between training data distribution and local practice.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2497.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold / AlphaFold2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold (DeepMind) / AlphaFold2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Deep learning systems for protein structure prediction that produce 3D structural hypotheses for proteins from sequence, validated by CASP competitions and large-scale proteome predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaFold / AlphaFold2</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DL-based protein structure predictors developed by DeepMind (AlphaFold and AlphaFold2). The paper summarizes AlphaFold's high accuracy in CASP competitions (AlphaFold won CASP13 entries) and states AlphaFold2 can accurately predict 3D structures for a very high fraction of human proteins; the architectures are deep neural networks trained on sequence and structural databases to map sequences to coordinates.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>deep-learning (DNN) sequence-to-structure predictor</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>life sciences / structural biology / protein folding</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates structural hypotheses for proteins by mapping amino-acid sequence inputs through a trained deep neural network to predict residue-residue distances/angles and final 3D coordinates (end-to-end learned mapping).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Model confidence estimates and CASP-style community evaluation (competition metrics) used; survey cites empirical validation against experimentally determined structures (CASP results) as plausibility evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Community structure-prediction metrics in CASP (e.g., GDT, RMSD) implicitly referenced; the paper quotes accuracy statistics (e.g., AlphaFold2 predicted 98.5% of human protein structures accurately as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validated computationally against held-out/external experimentally determined structures in CASP competitions and by large-scale proteome comparisons against known structures; prediction confidence metrics reported by the model.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Not detailed in the survey beyond community benchmarking in CASP and public release of predictions/databases in follow-up literature.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Model-provided confidence/accuracy estimators per protein prediction are referenced (survey notes AlphaFold reports confidence), no methodological detail in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>CASP benchmark datasets (community structure-prediction benchmarks) implied; Human proteome predictions referenced.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey claims AlphaFold succeeded at CASP (winning CASP13) and AlphaFold2 achieved very high accuracy (paper cites '98.5% of human proteins' accurate prediction, referencing Tunyasuvunakool et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared favorably to prior structure-prediction methods in CASP benchmark; specific numeric comparisons appear in cited literature but are not enumerated here.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Enabled large-scale proteome structure hypotheses (AlphaFold database) that accelerate downstream biology and drug discovery; survey highlights the practical impact rather than specific novel biochemical mechanisms discovered by the model itself.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Survey notes general issues with ML 'black box' behavior and distributional shifts; specific AlphaFold limitations (e.g., multi-protein complexes, dynamics) are not detailed in this survey.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2497.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GENTRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GENTRL (Insilico Medicine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular deep-learning based de novo molecular design system (GANs and other ML) used to generate candidate small-molecule inhibitors, with rapid in vitro/in vivo follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GENTRL (Insilico modular drug design platform)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A generative-model-based drug-design platform described as combining generative adversarial networks (GANs) and other machine-learning methods into a modular pipeline to propose de novo small-molecule candidates; the paper reports a case where GENTRL produced a DDR1 kinase inhibitor candidate, taking 46 days from target selection to an active candidate validated with in vivo data.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>generative-model-based (GANs + other ML)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>medicinal chemistry / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generative sampling of chemical structures using GANs and related deep generative models conditioned on target properties to propose novel molecule hypotheses (de novo design).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Implicit novelty via generated molecules not present in training data; novelty demonstrated by de novo candidate progression to experimental validation (case study). No explicit novelty metric detailed in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Computational scoring/prediction of activity (QSAR-like scoring) and selection followed by experimental assays (in vitro/in vivo) to assess plausibility and activity.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Balanced by using optimization/objectives that condition generation on desired drug-like properties and predicted activity, then prioritizing molecules for experimental validation — specific trade-off algorithm not detailed in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Practical success criterion: generation of molecules that show activity in biological assays; time-to-active-candidate metric (46 days) reported. Specific internal scoring metrics not described in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational prioritization followed by laboratory validation (in vitro and in vivo assays) confirming biological activity of generated molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Not detailed in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Case example: discovery of the first de novo active DDR1 kinase inhibitor and reported timeline of 46 days from target selection to an active candidate; no general performance table provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Survey contrasts accelerated timeline (46 days) with traditional longer discovery times, implying improved speed over baseline pipelines; no head-to-head quantitative baseline comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Discovery of a de novo DDR1 kinase inhibitor that was experimentally validated (in vivo) as reported in the cited Insilico work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Survey does not describe detailed failure modes; general limitations include dependence on quality of training data, potential for generated chemistry to be synthetically intractable, and the need for experimental validation to confirm computational predictions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2497.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exscientia / Centaur Chemist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exscientia Centaur Chemist AI platform (DSP-1181)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI-driven drug-design platform used by Exscientia (in collaboration with Sumitomo Dainippon Pharma) to design a clinical candidate (DSP-1181) that entered phase I trials within a notably short development time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Exscientia Centaur Chemist AI platform</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An industrial AI drug-design platform (combining ML-guided candidate generation, scoring and prioritization workflows) used to identify a novel drug candidate (DSP-1181) for obsessive-compulsive disorder; the survey reports end-to-phase-I timeline under 12 months for this candidate.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>industrial ML pipeline for molecule design and prioritization (generative + optimization + screening)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>medicinal chemistry / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generative and optimization-based proposal of candidate molecules conditioned on desired properties followed by computational prioritization and selection for experimental progression.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Computational scoring and prioritization, followed by experimental validation (preclinical and into phase I clinical trials) as plausibility proof; details not provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Survey emphasizes development timeline (<12 months to Phase I) as an operational metric; no internal scoring metrics described.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational selection followed by preclinical testing and progression to clinical phase I trials for the selected candidate (DSP-1181).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported practical outcome: DSP-1181 progressed to phase I clinical trials with a development timeline of less than 12 months from program initiation; no other numeric metrics provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Survey contrasts the rapid timeline (~<12 months) with conventional drug discovery timelines (4-5 years to comparable stage), implying substantial acceleration but without controlled baseline comparison statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Identification and progression of DSP-1181, a candidate entering phase I clinical trials.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Survey does not detail platform-specific limitations; general limitations include dependence on data quality, generalizability of models, and need for extensive experimental validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2497.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chematica</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chematica (computer-assisted synthesis planning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrosynthesis planning system (historically 'Chematica') that autonomously plans synthetic routes which have been demonstrated to work in laboratory settings, enabling automated synthesis workflows when combined with robotics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Chematica (automated retrosynthesis planner)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A rule- and data-driven retrosynthesis planning system that encodes chemical transformations and heuristics to propose multi-step synthetic routes for target molecules; survey notes that Chematica autonomously plans synthetic routes that have been experimentally validated.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>retrosynthesis planning (rule-based + data-driven)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>organic chemistry / synthetic chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates synthetic-route hypotheses by searching a reaction-transformation graph (encoded rules + data) to propose sequences of reactions from available precursors to the target molecule.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Chemical feasibility assessed via retrosynthesis heuristics and subsequently by experimental validation in the laboratory (some routes proven to work).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Quality ultimately judged by experimental success of proposed synthetic route; no formal numeric metrics provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Laboratory execution of proposed synthetic routes; the survey references work showing autonomous planning that is proven to work experimentally and integration with robotic synthesis platforms.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey references that Chematica-derived routes were executed successfully in the lab; no quantitative success-rate numbers provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Survey cites that AI-assisted retrosynthesis simplifies what was once considered an 'art', reducing manual labor and accelerating route planning versus traditional human-only planning; not quantified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Enables autonomous planning of synthetic routes that have been experimentally validated; when combined with robotics, enables end-to-end automated synthesis workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Survey does not detail algorithmic limitations; general caveats include reliance on encoded reaction knowledge and potential gaps for novel reaction types or rare transformations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2497.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2497.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian / Bayesian optimization (materials & physics examples)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian methods and Bayesian optimization (including DL Bayesian frameworks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Probabilistic approaches used in the surveyed literature to quantify uncertainty, guide search (active learning), and fit model hyperparameters (e.g., Bayesian optimization to fit Hubbard U or for attribute-driven inverse materials design).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian methods / Bayesian optimization / DL Bayesian frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Survey references Bayesian learning and Bayesian optimization techniques across domains: Bayesian learning as an AI tool, a DL Bayesian framework for attribute-driven inverse materials design (used to predict functional molecular materials), and Bayesian optimization applied to fit DFT+U Hubbard parameters; these are probabilistic frameworks that model posterior distributions or use acquisition functions to balance exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic Bayesian methods / active learning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, condensed-matter physics, machine learning (general)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Used to guide search and propose candidates (materials or model hyperparameters) by optimizing acquisition functions (e.g., expected improvement) over a probabilistic surrogate model (Gaussian process or Bayesian neural network), thereby generating candidate hypotheses with estimated uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Implicit via acquisition-driven exploration: acquisition functions reward novel regions with high expected improvement; exact novelty metrics not described in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Surrogate-model predictive mean and posterior variance are used to estimate plausibility and uncertainty; Bayesian optimization balances expected performance with uncertainty-driven exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Handled via acquisition functions that trade off exploitation (high predicted performance) and exploration (high uncertainty) — survey references this general mechanism without implementation specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Surrogate-model predictive mean, posterior variance, expected improvement (or similar acquisition values) are the working metrics; explicit definitions not provided in survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational evaluation via surrogate models, followed in some cited works by targeted experiments or higher-fidelity simulation (e.g., DFT) to validate selected candidates; example: fitting Hubbard U via Bayesian optimization compared to linear-response methods.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Bayesian posterior predictive distributions, surrogate-model variance, and acquisition-function-driven uncertainties mentioned in context (e.g., DL Bayesian framework, Bayesian optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey cites that Bayesian-optimized fitting of Hubbard U achieved improved efficiency and accuracy relative to some traditional methods (referenced literature), and that DL Bayesian frameworks enabled efficient inverse design in materials; no unified numeric performance table included in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Bayesian optimization and Bayesian frameworks are presented as improvements (efficiency/accuracy) over some conventional approaches (e.g., linear-response U fitting), but numeric comparisons are in cited references rather than this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Applied examples include attribute-driven inverse materials design and improved parameter fitting in DFT+U workflows (references cited); specific novel materials discoveries are reported in referenced work rather than detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Survey notes general challenges: need for high-quality data, computational cost for surrogate models at scale, and difficulty in high-dimensional spaces; specifics depend on referenced implementations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural Architecture Search with Reinforcement Learning <em>(Rating: 2)</em></li>
                <li>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks <em>(Rating: 2)</em></li>
                <li>Deep learning enables rapid identification of potent DDR1 kinase inhibitors <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction for the human proteome <em>(Rating: 2)</em></li>
                <li>Chematica: a story of computer code that started to think like a chemist <em>(Rating: 2)</em></li>
                <li>A robotic platform for flow synthesis of organic compounds informed by AI planning <em>(Rating: 2)</em></li>
                <li>Machine learning the Hubbard U parameter in DFT+U using Bayesian optimization <em>(Rating: 1)</em></li>
                <li>Attribute driven inverse materials design using deep learning Bayesian framework <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2497",
    "paper_id": "paper-240261316",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "AutoML / NAS",
            "name_full": "Automatic Machine Learning / Neural Architecture Search",
            "brief_description": "Automated methods that generate and optimize neural network architectures using algorithms such as reinforcement learning controllers and evolutionary algorithms to produce high-performing DNNs without manual architecture design.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AutoML / Neural Architecture Search (NAS)",
            "system_description": "A family of automated model-design methods described in the paper: (1) RL-based NAS where an RNN controller generates network architectures token-by-token and uses validation accuracy as a reward to update the controller via policy gradient; (2) evolutionary NAS where populations of architectures undergo selection, crossover and mutation guided by fitness (accuracy) to evolve high-quality networks. The paper cites EfficientNet as an example of a state-of-the-art network discovered via NAS.",
            "system_type": "neural-architecture-search (AutoML) — RL-based and evolutionary",
            "scientific_domain": "information science / machine learning (general across domains)",
            "hypothesis_generation_method": "Generates candidate neural-network 'hypotheses' (architectures) via (a) an RNN controller trained with reinforcement learning that samples architecture descriptions and receives validation accuracy as reward; (b) population-based evolutionary operators (selection, crossover, mutation) that iteratively produce improved architectures.",
            "novelty_assessment_method": "Implicit: novelty measured indirectly by improved validation performance relative to prior architectures (accuracy/fitness); no explicit novelty metric described in the paper.",
            "plausibility_assessment_method": "Validation-set performance (accuracy) of trained candidate architectures used as primary plausibility/quality signal.",
            "novelty_plausibility_balance": "Not explicitly formalized; trade-off handled implicitly by optimization objective (maximize validation accuracy) and search constraints (search space design, regularization).",
            "hypothesis_quality_metrics": "Validation-set accuracy (or task-specific validation metric) used as fitness/reward; paper cites overall accuracy gains (e.g., EfficientNet outperforming human-designed networks).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational validation via training candidate networks and measuring validation/test performance metrics (accuracy); selection based on these metrics prior to deployment.",
            "reproducibility_measures": "Not detailed in paper beyond standard ML evaluation (validation/test splits and reporting of benchmark results).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Standard ML benchmarks implied (image classification benchmarks used to evaluate discovered architectures such as those that produced EfficientNet) but not enumerated in paper.",
            "performance_metrics": "Paper cites that NAS-discovered models (example EfficientNet) outperform human-designed models; no unified numeric benchmark in this survey apart from references to literature (e.g., EfficientNet results in original NAS paper).",
            "comparison_with_baseline": "Survey states NAS-designed networks can surpass networks designed by AI experts (e.g., EfficientNet derived through NAS), but gives no detailed numerical comparisons within this paper.",
            "validated_on_real_science": true,
            "novel_discoveries": "EfficientNet cited as an example of a high-performing architecture discovered via NAS (reference to original NAS work).",
            "limitations": "High computational cost for large-scale NAS; need for careful search-space design; potential lack of interpretability of resulting architectures; requirement of large validation datasets for reliable fitness measurement.",
            "uuid": "e2497.0"
        },
        {
            "name_short": "Doctor Watson",
            "name_full": "IBM Watson (Doctor Watson clinical decision support)",
            "brief_description": "An NLP-driven clinical decision-support system that searches large corpora of medical history and literature to propose ranked treatment options and reports a confidence score for proposals.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Doctor Watson (IBM Watson clinical support)",
            "system_description": "An application of the IBM Watson platform that leverages natural language processing (NLP) to ingest electronic medical records and literature, retrieve relevant prior cases and guidelines, rank candidate treatment proposals based on prior knowledge reserves and model ensembles, and output a final proposal with an associated confidence score.",
            "system_type": "NLP-based retrieval + expert-system / ensemble ranking",
            "scientific_domain": "medicine / clinical decision support",
            "hypothesis_generation_method": "Generates candidate clinical treatment hypotheses by searching and retrieving similar historical patient cases and synthesizing recommendations from stored prior-knowledge models and literature; ranking provides top candidate interventions.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Generates confidence estimates for proposed treatments based on internal model ensemble ranking and prior-knowledge matching; plausibility judged by matching to previous cases and literature.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Outputs a confidence score for each proposal; specific metric calculation not described in the survey.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Comparison/ranking against prior clinical cases and reference knowledge bases; the system presents confidence scores for clinician review (human-in-the-loop validation implied).",
            "reproducibility_measures": "Not detailed in the survey.",
            "hallucination_prevention_method": "Implicit reliance on literature and prior case bases to ground recommendations; no explicit hallucination-prevention protocol described.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Confidence scores for proposals (system-reported), but no methodological details provided in survey.",
            "benchmark_dataset": null,
            "performance_metrics": "Survey notes Doctor Watson provides proposals and confidence but also highlights limitations (domain bias due to training data from US hospitals); no numeric performance metrics provided in this paper.",
            "comparison_with_baseline": "No quantitative comparison with human clinicians in this survey; the paper notes practical limitations such as region-specific training data affecting suitability elsewhere.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Dependence on region-specific training data and prior knowledge (may not generalize across healthcare systems); still considered a 'black box' by clinicians; potential mismatch between training data distribution and local practice.",
            "uuid": "e2497.1"
        },
        {
            "name_short": "AlphaFold / AlphaFold2",
            "name_full": "AlphaFold (DeepMind) / AlphaFold2",
            "brief_description": "Deep learning systems for protein structure prediction that produce 3D structural hypotheses for proteins from sequence, validated by CASP competitions and large-scale proteome predictions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AlphaFold / AlphaFold2",
            "system_description": "DL-based protein structure predictors developed by DeepMind (AlphaFold and AlphaFold2). The paper summarizes AlphaFold's high accuracy in CASP competitions (AlphaFold won CASP13 entries) and states AlphaFold2 can accurately predict 3D structures for a very high fraction of human proteins; the architectures are deep neural networks trained on sequence and structural databases to map sequences to coordinates.",
            "system_type": "deep-learning (DNN) sequence-to-structure predictor",
            "scientific_domain": "life sciences / structural biology / protein folding",
            "hypothesis_generation_method": "Generates structural hypotheses for proteins by mapping amino-acid sequence inputs through a trained deep neural network to predict residue-residue distances/angles and final 3D coordinates (end-to-end learned mapping).",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Model confidence estimates and CASP-style community evaluation (competition metrics) used; survey cites empirical validation against experimentally determined structures (CASP results) as plausibility evidence.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Community structure-prediction metrics in CASP (e.g., GDT, RMSD) implicitly referenced; the paper quotes accuracy statistics (e.g., AlphaFold2 predicted 98.5% of human protein structures accurately as reported).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Validated computationally against held-out/external experimentally determined structures in CASP competitions and by large-scale proteome comparisons against known structures; prediction confidence metrics reported by the model.",
            "reproducibility_measures": "Not detailed in the survey beyond community benchmarking in CASP and public release of predictions/databases in follow-up literature.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Model-provided confidence/accuracy estimators per protein prediction are referenced (survey notes AlphaFold reports confidence), no methodological detail in survey.",
            "benchmark_dataset": "CASP benchmark datasets (community structure-prediction benchmarks) implied; Human proteome predictions referenced.",
            "performance_metrics": "Survey claims AlphaFold succeeded at CASP (winning CASP13) and AlphaFold2 achieved very high accuracy (paper cites '98.5% of human proteins' accurate prediction, referencing Tunyasuvunakool et al.).",
            "comparison_with_baseline": "Compared favorably to prior structure-prediction methods in CASP benchmark; specific numeric comparisons appear in cited literature but are not enumerated here.",
            "validated_on_real_science": true,
            "novel_discoveries": "Enabled large-scale proteome structure hypotheses (AlphaFold database) that accelerate downstream biology and drug discovery; survey highlights the practical impact rather than specific novel biochemical mechanisms discovered by the model itself.",
            "limitations": "Survey notes general issues with ML 'black box' behavior and distributional shifts; specific AlphaFold limitations (e.g., multi-protein complexes, dynamics) are not detailed in this survey.",
            "uuid": "e2497.2"
        },
        {
            "name_short": "GENTRL",
            "name_full": "GENTRL (Insilico Medicine)",
            "brief_description": "A modular deep-learning based de novo molecular design system (GANs and other ML) used to generate candidate small-molecule inhibitors, with rapid in vitro/in vivo follow-up.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "GENTRL (Insilico modular drug design platform)",
            "system_description": "A generative-model-based drug-design platform described as combining generative adversarial networks (GANs) and other machine-learning methods into a modular pipeline to propose de novo small-molecule candidates; the paper reports a case where GENTRL produced a DDR1 kinase inhibitor candidate, taking 46 days from target selection to an active candidate validated with in vivo data.",
            "system_type": "generative-model-based (GANs + other ML)",
            "scientific_domain": "medicinal chemistry / drug discovery",
            "hypothesis_generation_method": "Generative sampling of chemical structures using GANs and related deep generative models conditioned on target properties to propose novel molecule hypotheses (de novo design).",
            "novelty_assessment_method": "Implicit novelty via generated molecules not present in training data; novelty demonstrated by de novo candidate progression to experimental validation (case study). No explicit novelty metric detailed in survey.",
            "plausibility_assessment_method": "Computational scoring/prediction of activity (QSAR-like scoring) and selection followed by experimental assays (in vitro/in vivo) to assess plausibility and activity.",
            "novelty_plausibility_balance": "Balanced by using optimization/objectives that condition generation on desired drug-like properties and predicted activity, then prioritizing molecules for experimental validation — specific trade-off algorithm not detailed in survey.",
            "hypothesis_quality_metrics": "Practical success criterion: generation of molecules that show activity in biological assays; time-to-active-candidate metric (46 days) reported. Specific internal scoring metrics not described in survey.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational prioritization followed by laboratory validation (in vitro and in vivo assays) confirming biological activity of generated molecules.",
            "reproducibility_measures": "Not detailed in the survey.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Case example: discovery of the first de novo active DDR1 kinase inhibitor and reported timeline of 46 days from target selection to an active candidate; no general performance table provided in survey.",
            "comparison_with_baseline": "Survey contrasts accelerated timeline (46 days) with traditional longer discovery times, implying improved speed over baseline pipelines; no head-to-head quantitative baseline comparison provided.",
            "validated_on_real_science": true,
            "novel_discoveries": "Discovery of a de novo DDR1 kinase inhibitor that was experimentally validated (in vivo) as reported in the cited Insilico work.",
            "limitations": "Survey does not describe detailed failure modes; general limitations include dependence on quality of training data, potential for generated chemistry to be synthetically intractable, and the need for experimental validation to confirm computational predictions.",
            "uuid": "e2497.3"
        },
        {
            "name_short": "Exscientia / Centaur Chemist",
            "name_full": "Exscientia Centaur Chemist AI platform (DSP-1181)",
            "brief_description": "An AI-driven drug-design platform used by Exscientia (in collaboration with Sumitomo Dainippon Pharma) to design a clinical candidate (DSP-1181) that entered phase I trials within a notably short development time.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Exscientia Centaur Chemist AI platform",
            "system_description": "An industrial AI drug-design platform (combining ML-guided candidate generation, scoring and prioritization workflows) used to identify a novel drug candidate (DSP-1181) for obsessive-compulsive disorder; the survey reports end-to-phase-I timeline under 12 months for this candidate.",
            "system_type": "industrial ML pipeline for molecule design and prioritization (generative + optimization + screening)",
            "scientific_domain": "medicinal chemistry / drug discovery",
            "hypothesis_generation_method": "Generative and optimization-based proposal of candidate molecules conditioned on desired properties followed by computational prioritization and selection for experimental progression.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Computational scoring and prioritization, followed by experimental validation (preclinical and into phase I clinical trials) as plausibility proof; details not provided in the survey.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Survey emphasizes development timeline (&lt;12 months to Phase I) as an operational metric; no internal scoring metrics described.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational selection followed by preclinical testing and progression to clinical phase I trials for the selected candidate (DSP-1181).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Reported practical outcome: DSP-1181 progressed to phase I clinical trials with a development timeline of less than 12 months from program initiation; no other numeric metrics provided in survey.",
            "comparison_with_baseline": "Survey contrasts the rapid timeline (~&lt;12 months) with conventional drug discovery timelines (4-5 years to comparable stage), implying substantial acceleration but without controlled baseline comparison statistics.",
            "validated_on_real_science": true,
            "novel_discoveries": "Identification and progression of DSP-1181, a candidate entering phase I clinical trials.",
            "limitations": "Survey does not detail platform-specific limitations; general limitations include dependence on data quality, generalizability of models, and need for extensive experimental validation.",
            "uuid": "e2497.4"
        },
        {
            "name_short": "Chematica",
            "name_full": "Chematica (computer-assisted synthesis planning)",
            "brief_description": "A retrosynthesis planning system (historically 'Chematica') that autonomously plans synthetic routes which have been demonstrated to work in laboratory settings, enabling automated synthesis workflows when combined with robotics.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Chematica (automated retrosynthesis planner)",
            "system_description": "A rule- and data-driven retrosynthesis planning system that encodes chemical transformations and heuristics to propose multi-step synthetic routes for target molecules; survey notes that Chematica autonomously plans synthetic routes that have been experimentally validated.",
            "system_type": "retrosynthesis planning (rule-based + data-driven)",
            "scientific_domain": "organic chemistry / synthetic chemistry",
            "hypothesis_generation_method": "Generates synthetic-route hypotheses by searching a reaction-transformation graph (encoded rules + data) to propose sequences of reactions from available precursors to the target molecule.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Chemical feasibility assessed via retrosynthesis heuristics and subsequently by experimental validation in the laboratory (some routes proven to work).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Quality ultimately judged by experimental success of proposed synthetic route; no formal numeric metrics provided in survey.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Laboratory execution of proposed synthetic routes; the survey references work showing autonomous planning that is proven to work experimentally and integration with robotic synthesis platforms.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Survey references that Chematica-derived routes were executed successfully in the lab; no quantitative success-rate numbers provided here.",
            "comparison_with_baseline": "Survey cites that AI-assisted retrosynthesis simplifies what was once considered an 'art', reducing manual labor and accelerating route planning versus traditional human-only planning; not quantified in this paper.",
            "validated_on_real_science": true,
            "novel_discoveries": "Enables autonomous planning of synthetic routes that have been experimentally validated; when combined with robotics, enables end-to-end automated synthesis workflows.",
            "limitations": "Survey does not detail algorithmic limitations; general caveats include reliance on encoded reaction knowledge and potential gaps for novel reaction types or rare transformations.",
            "uuid": "e2497.5"
        },
        {
            "name_short": "Bayesian / Bayesian optimization (materials & physics examples)",
            "name_full": "Bayesian methods and Bayesian optimization (including DL Bayesian frameworks)",
            "brief_description": "Probabilistic approaches used in the surveyed literature to quantify uncertainty, guide search (active learning), and fit model hyperparameters (e.g., Bayesian optimization to fit Hubbard U or for attribute-driven inverse materials design).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Bayesian methods / Bayesian optimization / DL Bayesian frameworks",
            "system_description": "Survey references Bayesian learning and Bayesian optimization techniques across domains: Bayesian learning as an AI tool, a DL Bayesian framework for attribute-driven inverse materials design (used to predict functional molecular materials), and Bayesian optimization applied to fit DFT+U Hubbard parameters; these are probabilistic frameworks that model posterior distributions or use acquisition functions to balance exploration/exploitation.",
            "system_type": "probabilistic Bayesian methods / active learning",
            "scientific_domain": "materials science, condensed-matter physics, machine learning (general)",
            "hypothesis_generation_method": "Used to guide search and propose candidates (materials or model hyperparameters) by optimizing acquisition functions (e.g., expected improvement) over a probabilistic surrogate model (Gaussian process or Bayesian neural network), thereby generating candidate hypotheses with estimated uncertainty.",
            "novelty_assessment_method": "Implicit via acquisition-driven exploration: acquisition functions reward novel regions with high expected improvement; exact novelty metrics not described in survey.",
            "plausibility_assessment_method": "Surrogate-model predictive mean and posterior variance are used to estimate plausibility and uncertainty; Bayesian optimization balances expected performance with uncertainty-driven exploration.",
            "novelty_plausibility_balance": "Handled via acquisition functions that trade off exploitation (high predicted performance) and exploration (high uncertainty) — survey references this general mechanism without implementation specifics.",
            "hypothesis_quality_metrics": "Surrogate-model predictive mean, posterior variance, expected improvement (or similar acquisition values) are the working metrics; explicit definitions not provided in survey text.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational evaluation via surrogate models, followed in some cited works by targeted experiments or higher-fidelity simulation (e.g., DFT) to validate selected candidates; example: fitting Hubbard U via Bayesian optimization compared to linear-response methods.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Bayesian posterior predictive distributions, surrogate-model variance, and acquisition-function-driven uncertainties mentioned in context (e.g., DL Bayesian framework, Bayesian optimization).",
            "benchmark_dataset": null,
            "performance_metrics": "Survey cites that Bayesian-optimized fitting of Hubbard U achieved improved efficiency and accuracy relative to some traditional methods (referenced literature), and that DL Bayesian frameworks enabled efficient inverse design in materials; no unified numeric performance table included in this paper.",
            "comparison_with_baseline": "Bayesian optimization and Bayesian frameworks are presented as improvements (efficiency/accuracy) over some conventional approaches (e.g., linear-response U fitting), but numeric comparisons are in cited references rather than this survey.",
            "validated_on_real_science": true,
            "novel_discoveries": "Applied examples include attribute-driven inverse materials design and improved parameter fitting in DFT+U workflows (references cited); specific novel materials discoveries are reported in referenced work rather than detailed here.",
            "limitations": "Survey notes general challenges: need for high-quality data, computational cost for surrogate models at scale, and difficulty in high-dimensional spaces; specifics depend on referenced implementations.",
            "uuid": "e2497.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural Architecture Search with Reinforcement Learning",
            "rating": 2,
            "sanitized_title": "neural_architecture_search_with_reinforcement_learning"
        },
        {
            "paper_title": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks",
            "rating": 2,
            "sanitized_title": "efficientnet_rethinking_model_scaling_for_convolutional_neural_networks"
        },
        {
            "paper_title": "Deep learning enables rapid identification of potent DDR1 kinase inhibitors",
            "rating": 2,
            "sanitized_title": "deep_learning_enables_rapid_identification_of_potent_ddr1_kinase_inhibitors"
        },
        {
            "paper_title": "Highly accurate protein structure prediction for the human proteome",
            "rating": 2,
            "sanitized_title": "highly_accurate_protein_structure_prediction_for_the_human_proteome"
        },
        {
            "paper_title": "Chematica: a story of computer code that started to think like a chemist",
            "rating": 2,
            "sanitized_title": "chematica_a_story_of_computer_code_that_started_to_think_like_a_chemist"
        },
        {
            "paper_title": "A robotic platform for flow synthesis of organic compounds informed by AI planning",
            "rating": 2,
            "sanitized_title": "a_robotic_platform_for_flow_synthesis_of_organic_compounds_informed_by_ai_planning"
        },
        {
            "paper_title": "Machine learning the Hubbard U parameter in DFT+U using Bayesian optimization",
            "rating": 1,
            "sanitized_title": "machine_learning_the_hubbard_u_parameter_in_dftu_using_bayesian_optimization"
        },
        {
            "paper_title": "Attribute driven inverse materials design using deep learning Bayesian framework",
            "rating": 1,
            "sanitized_title": "attribute_driven_inverse_materials_design_using_deep_learning_bayesian_framework"
        }
    ],
    "cost": 0.021123249999999996,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Artificial intelligence: A powerful paradigm for scientific research
October 28, 2021</p>
<p>Fengliang Dong 
National Center for Nanoscience and Technology
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>National Center for Nanoscience and Technology
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Cheng-Wei Qiu 
Department of Electrical and Computer Engineering
National University of Singapore
117583Singapore, Singapore</p>
<p>Department of Electrical and Computer Engineering
National University of Singapore
117583Singapore, Singapore</p>
<p>Junjun Qiu 
Department of Gynaecology, Obstetrics and Gynaecology Hospital
Fudan University
200011ShanghaiChina</p>
<p>Shanghai Key Laboratory of Female Reproductive Endocrine-Related Diseases
200011ShanghaiChina</p>
<p>Department of Gynaecology, Obstetrics and Gynaecology Hospital
Fudan University
200011ShanghaiChina</p>
<p>Shanghai Key Laboratory of Female Reproductive Endocrine-Related Diseases
200011ShanghaiChina</p>
<p>Keqin Hua 
Department of Gynaecology, Obstetrics and Gynaecology Hospital
Fudan University
200011ShanghaiChina</p>
<p>Shanghai Key Laboratory of Female Reproductive Endocrine-Related Diseases
200011ShanghaiChina</p>
<p>Department of Gynaecology, Obstetrics and Gynaecology Hospital
Fudan University
200011ShanghaiChina</p>
<p>Shanghai Key Laboratory of Female Reproductive Endocrine-Related Diseases
200011ShanghaiChina</p>
<p>Wentao Su 
School of Food Science and Technology
Dalian Polytechnic University
116034DalianChina</p>
<p>School of Food Science and Technology
Dalian Polytechnic University
116034DalianChina</p>
<p>Jian Wu 
School of Public Health
Second Affiliated Hospital School of Medicine
Zhejiang University
310058HangzhouChina</p>
<p>School of Public Health
Second Affiliated Hospital School of Medicine
Zhejiang University
310058HangzhouChina</p>
<p>Huiyu Xu 
Department of Obstetrics and Gynecology
Peking University Third Hospital
100191BeijingChina</p>
<p>Department of Obstetrics and Gynecology
Peking University Third Hospital
100191BeijingChina</p>
<p>Yong Han 
Zhejiang Provincial People's Hospital
310014HangzhouChina</p>
<p>Zhejiang Provincial People's Hospital
310014HangzhouChina</p>
<p>Chenguang Fu 
School of Materials Science and Engineering
Zhejiang University
310027HangzhouChina</p>
<p>School of Materials Science and Engineering
Zhejiang University
310027HangzhouChina</p>
<p>Zhigang Yin 
Structure of Matter
Fujian Institute of Research
Chinese Academy of Sciences
350002FuzhouChina</p>
<p>14 Medical Center
Radboud University
6500Nijmegenthe Netherlands</p>
<p>Structure of Matter
Fujian Institute of Research
Chinese Academy of Sciences
350002FuzhouChina</p>
<p>14 Medical Center
Radboud University
6500Nijmegenthe Netherlands</p>
<p>Miao Liu 
Institute of Physics
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Songshan Lake Materials Laboratory
523808DongguanGuangdongChina</p>
<p>Institute of Physics
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Songshan Lake Materials Laboratory
523808DongguanGuangdongChina</p>
<p>Ronald Roepman 
Sabine Dietmann 
Institute for Informatics
Washington University School of Medicine
63110St. LouisMOUSA</p>
<p>Institute for Informatics
Washington University School of Medicine
63110St. LouisMOUSA</p>
<p>Marko Virta 
Department of Microbiology
University of Helsinki
00014HelsinkiFinland</p>
<p>Department of Microbiology
University of Helsinki
00014HelsinkiFinland</p>
<p>Fredrick Kengara 
School of Pure and Applied Sciences
Bomet University College
20400BometKenya</p>
<p>School of Pure and Applied Sciences
Bomet University College
20400BometKenya</p>
<p>Ze Zhang 
Agriculture College of Shihezi University
832000XinjiangChina</p>
<p>Agriculture College of Shihezi University
832000XinjiangChina</p>
<p>Lifu Zhang 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Taolan Zhao 
Agriculture College of Shihezi University
832000XinjiangChina</p>
<p>Institute of Genetics and Developmental Biology
Chinese Academy of Sciences
100101BeijingChina</p>
<p>Agriculture College of Shihezi University
832000XinjiangChina</p>
<p>Institute of Genetics and Developmental Biology
Chinese Academy of Sciences
100101BeijingChina</p>
<p>Ji Dai 
The Brain Cognition and Brain Disease Institute
Shenzhen Institute of Advanced Technology
Chinese Academy of Sciences
518055ShenzhenChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions
518055ShenzhenChina</p>
<p>The Brain Cognition and Brain Disease Institute
Shenzhen Institute of Advanced Technology
Chinese Academy of Sciences
518055ShenzhenChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions
518055ShenzhenChina</p>
<p>Jialiang Yang 
Geneis (Beijing) Co
100102Ltd, BeijingChina</p>
<p>Geneis (Beijing) Co
100102Ltd, BeijingChina</p>
<p>Liang Lan 
Department of Communication Studies
Hong Kong Baptist University
Hong KongChina</p>
<p>Department of Communication Studies
Hong Kong Baptist University
Hong KongChina</p>
<p>Ming Luo 
South China Botanical Garden
Chinese Academy of Sciences
510650GuangzhouChina</p>
<p>Center of Economic Botany
Core Botanical Gardens
Chinese Academy of Sciences
510650GuangzhouChina</p>
<p>40 Zhejiang Lab
311121HangzhouChina</p>
<p>South China Botanical Garden
Chinese Academy of Sciences
510650GuangzhouChina</p>
<p>Center of Economic Botany
Core Botanical Gardens
Chinese Academy of Sciences
510650GuangzhouChina</p>
<p>40 Zhejiang Lab
311121HangzhouChina</p>
<p>Zhaofeng Liu 
Institute of High Energy Physics
Chinese Academy of Sciences
100049BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of High Energy Physics
Chinese Academy of Sciences
100049BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Tao An 
Shanghai Astronomical Observatory
Chinese Academy of Sciences
200030ShanghaiChina</p>
<p>Shanghai Astronomical Observatory
Chinese Academy of Sciences
200030ShanghaiChina</p>
<p>Bin Zhang 
Institute of Coal Chemistry
Chinese Academy of Sciences
030001TaiyuanChina</p>
<p>Institute of Coal Chemistry
Chinese Academy of Sciences
030001TaiyuanChina</p>
<p>Xiao He 
Institute of High Energy Physics
Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of High Energy Physics
Chinese Academy of Sciences
100049BeijingChina</p>
<p>Shan Cong 
Suzhou Institute of Nano-Tech and Nano-Bionics
Chinese Academy of Sciences
215123SuzhouChina</p>
<p>Suzhou Institute of Nano-Tech and Nano-Bionics
Chinese Academy of Sciences
215123SuzhouChina</p>
<p>Xiaohong Liu 
Chongqing Institute of Green and Intelligent Technology
Chinese Academy of Sciences
400714ChongqingChina</p>
<p>Chongqing Institute of Green and Intelligent Technology
Chinese Academy of Sciences
400714ChongqingChina</p>
<p>Wei Zhang 
Chongqing Institute of Green and Intelligent Technology
Chinese Academy of Sciences
400714ChongqingChina</p>
<p>Chongqing Institute of Green and Intelligent Technology
Chinese Academy of Sciences
400714ChongqingChina</p>
<p>James P Lewis 
Institute of Coal Chemistry
Chinese Academy of Sciences
030001TaiyuanChina</p>
<p>Institute of Coal Chemistry
Chinese Academy of Sciences
030001TaiyuanChina</p>
<p>James M Tiedje 
Center for Microbial Ecology
Department of Plant, Soil and Microbial Sciences
Michigan State University
48824East LansingMIUSA</p>
<p>Center for Microbial Ecology
Department of Plant, Soil and Microbial Sciences
Michigan State University
48824East LansingMIUSA</p>
<p>Qi Wang wangqi08@ict.ac.cn 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Zhulin An anzhulin@ict.ac.cn 
Fei Wang wangfei@ict.ac.cn 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Libo Zhang 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Institute of Software
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Tao Huang huangtao@sibs.ac.cn 
Shanghai Institute of Nutrition and Health
Chinese Academy of Sciences
200031ShanghaiChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Shanghai Institute of Nutrition and Health
Chinese Academy of Sciences
200031ShanghaiChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Chuan Lu 
Department of Computer Science
Aberystwyth University
SY23 3FLAberystwythCeredigionUK</p>
<p>Department of Computer Science
Aberystwyth University
SY23 3FLAberystwythCeredigionUK</p>
<p>Zhipeng Cai zcai@gsu.edu 
Department of Computer Science
Georgia State University
30303AtlantaGAUSA</p>
<p>Department of Computer Science
Georgia State University
30303AtlantaGAUSA</p>
<p>Fang Wang wangfang@issas.ac.cn 
Institute of Soil Science
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Jiabao Zhang jiabaozhang@issac.ac.cn 
Institute of Soil Science
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Soil Science
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Lifu Zhang 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Fei Wang 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Libo Zhang 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Institute of Software
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Fang Wang 
Institute of Soil Science
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Academy of Mathematics and Systems Science
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Zhongshan Hospital Institute of Clinical Science
Fudan University
200032ShanghaiChina</p>
<p>Artificial intelligence: A powerful paradigm for scientific research
October 28, 202174C9E5DE0D56FFB1879AC8A61C65984710.1016/j.xinn.2021.100179Received: August 29, 2021; Accepted: October 26, 2021; The Innovation 2, 100179, November 28, 2021 Received: August 29, 2021; Accepted: October 26, 2021;artificial intelligencemachine learningdeep learninginformation sciencemathematicsmedical sciencematerials sciencegeosciencelife sciencephysicschemistry
Can machines think?"The goal of artificial intelligence (AI) is to enable machines to mimic human thoughts and behaviors, including learning, reasoning, predicting, and so on.-"Can AI do fundamental research?"AI coupled with machine learning techniques is impacting a wide range of fundamental sciences, including mathematics, medical science, physics, etc.-"How does AI accelerate fundamental research?"New research and applications are emerging rapidly with the support by AI infrastructure, including data storage, computing power, AI algorithms, and frameworks.</p>
<p>INTRODUCTION</p>
<p>"Can machines think?"Alan Turing posed this question in his famous paper "Computing Machinery and Intelligence." 1 He believes that to answer this question, we need to define what thinking is.However, it is difficult to define thinking clearly, because thinking is a subjective behavior.Turing then introduced an indirect method to verify whether a machine can think, the Turing test, which examines a machine's ability to show intelligence indistinguishable from that of human beings.A machine that succeeds in the test is qualified to be labeled as artificial intelligence (AI).</p>
<p>AI refers to the simulation of human intelligence by a system or a machine.The goal of AI is to develop a machine that can think like humans and mimic human behaviors, including perceiving, reasoning, learning, planning, predicting, and so on.Intelligence is one of the main characteristics that distinguishes human beings from animals.With the interminable occurrence of industrial revolutions, an increasing number of types of machine types continuously replace human labor from all walks of life, and the imminent easier than to program it manually by predicting the desired response for all potential inputs.The following sections survey eight fundamental sciences, including information science (informatics), mathematics, medical science, materials science, geoscience, life science, physics, and chemistry, which develop or exploit AI techniques to promote the development of sciences and accelerate their applications to benefit human beings, society, and the world.</p>
<p>AI IN INFORMATION SCIENCE</p>
<p>AI aims to provide the abilities of perception, cognition, and decision-making for machines.At present, new research and applications in information science are emerging at an unprecedented rate, which is inseparable from the support by the AI infrastructure.As shown in Figure 2, the AI infrastructure layer includes data, storage and computing power, ML algorithms, and the AI framework.The perception layer enables machines have the basic ability of vision, hearing, etc.For instance, CV enables machines to "see" and identify objects, while speech recognition and synthesis helps machines to "hear" and recognize speech elements.The cognitive layer provides higher ability levels of induction, reasoning, and acquiring knowledge with the help of NLP, 6, knowledge graphs, 7, and continual learning. 8In the decision-making layer, AI is capable of making optimal decisions, such as automatic planning, expert systems, and decision-supporting systems.Numerous applications of AI have had a profound impact on fundamental sciences, industrial manufacturing, human life, social governance, and cyberspace.The following subsections provide an overview of the AI framework, automatic machine learning (AutoML) technology, and several state-of-the-art AI/ML applications in the information field.</p>
<p>The AI framework provides basic tools for AI algorithm implementation</p>
<p>In the past 10 years, applications based on AI algorithms have played a significant role in various fields and subjects, on the basis of which the prosperity of the DL framework and platform has been founded.AI frameworks and platforms reduce the requirement of accessing AI technology by integrating the overall process of algorithm development, which enables researchers from different areas to use it across other fields, allowing them to focus on designing the structure of neural networks, thus providing better solutions to problems in their fields.At the beginning of the 21st century, only a few tools, such as MATLAB, OpenNN, and Torch, were capable of describing and developing neural networks.However, these tools were not originally designed for AI models, and thus faced problems, such as complicated user API and lacking GPU support.During this period, using these frameworks demanded professional computer science knowledge and tedious work on model construction.As a solution, early frameworks of DL, such as Caffe, Chainer, and Theano, emerged, allowing users to conveniently construct complex deep neural networks (DNNs), such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and LSTM conveniently, and this significantly reduced the cost of applying AI models.Tech giants then joined the march in researching AI frameworks. 9,Google developed the famous open-source framework, TensorFlow, while Facebook's AI research team released another popular platform, PyTorch, which is based on Torch; Microsoft Research published CNTK, and Amazon announced MXNet.Among them, TensorFlow, also the most representative framework, referred to Theano's declarative programming style, offering a larger space for graph-based optimization, while PyTorch inherited the imperative programming style of Torch, which is intuitive, user friendly, more flexible, and easier to be traced.As modern AI frameworks and platforms are being widely applied, practitioners can now assemble models swiftly and conveniently by adopting various building block sets and languages specifically suitable for given fields.Polished over time, these platforms gradually developed a clearly defined user API, the ability for multi-GPU training and distributed training, as well as a variety of model zoos and tool kits for specific tasks. 10,Looking forward, there are a few trends that may become the mainstream of next-generation framework development.(1) Capability of super-scale model training.With the emergence of models derived from Transformer, such as BERT and GPT-3, the ability of training large models has become an ideal feature of the DL framework.It requires AI frameworks to train effectively under the scale of hundreds or even thousands of devices.(2) Unified API standard.The APIs of many frameworks are generally similar but slightly different at certain points.This leads to some difficulties and unnecessary learning efforts, when the user attempts to shift from one framework to another.The API of some frameworks, such as JAX, has already become compatible with Numpy standard, which is familiar to most practitioners.Therefore, a unified API standard for AI frameworks may gradually come into being in the future.(3) Universal operator optimization.At present, kernels of DL operator are implemented either manually or based on third-party libraries.Most third-party libraries are developed to suit certain hardware platforms, causing large unnecessary spending when models are trained or deployed on different hardware platforms.The development speed of new DL algorithms is usually much faster than the update rate of libraries, which often makes new algorithms to be beyond the range of libraries' support. 11o improve the implementation speed of AI algorithms, much research focuses on how to use hardware for acceleration.The DianNao family is one of the earliest research innovations on AI hardware accelerators. 12It includes DianNao, DaDianNao, ShiDianNao, and PuDianNao, which can be used to accelerate the inference speed of neural networks and other ML algorithms.Of these, the best performance of a 64-chip DaDianNao system can achieve a speed up of 450.653 over a GPU, and reduce the energy by 150.313.Prof. Chen and his team in the Institute of Computing Technology also designed an Instruction Set Architecture for a broad range of neural network accelerators, called Cambricon, which developed into a serial DL accelerator.After Cambricon, many AI-related companies, such as Apple, Google, HUAWEI, etc., developed their own DL accelerators, and AI accelerators became an important research field of AI.</p>
<p>AI for AI-AutoML</p>
<p>AutoML aims to study how to use evolutionary computing, reinforcement learning (RL), and other AI algorithms, to automatically generate specified AI algorithms.Research on the automatic generation of neural networks has existed before the emergence of DL, e.g., neural evolution. 13,The main purpose of neural evolution is to allow neural networks to evolve according to the principle of survival of the fittest in the biological world.Through selection, crossover, mutation, and other evolutionary operators, the individual quality in a population is continuously improved and, finally, the individual with the greatest fitness represents the best neural network.The biological inspiration in this field lies in the evolutionary process of human brain neurons.The human brain has such developed learning and memory functions that it cannot do without the complex neural network system in the brain.The whole neural network system of the human brain benefits from a long evolutionary process rather than gradient descent and back propagation.In the era of DL, the application of AI algorithms to automatically generate DNN has attracted more attention and, gradually, developed into an important direction of Au-toML research: neural architecture search.The implementation methods of neural architecture search are usually divided into the RL-based method and the evolutionary algorithm-based method.In the RL-based method, an RNN is used as a controller to generate a neural network structure layer by layer, and then the network is trained, and the accuracy of the verification set is used as the reward signal of the RNN to calculate the strategy gradient.During the iteration, the controller will give the neural network, with higher accuracy, a higher probability value, so as to ensure that the strategy function can output the optimal network structure. 14,The method of neural architecture search through evolution is similar to the neural evolution method, which is based on a population and iterates continuously according to the principle of survival of the fittest, so as to obtain a high-quality neural network. 15,rough the application of neural architecture search technology, the design of neural networks is more efficient and automated, and the accuracy of the network gradually outperforms that of the networks designed by AI experts.For example, Google's SOTA network EfficientNet was realized through the baseline network based on neural architecture search. 16</p>
<p>AI enabling networking design adaptive to complex network conditions</p>
<p>The application of DL in the networking field has received strong interest.Network design often relies on initial network conditions and/or theoretical assumptions to characterize real network environments.However, traditional network modeling and design, regulated by mathematical models, are unlikely to deal with complex scenarios with many imperfect and high dynamic network environments.Integrating DL into network research allows for a better representation of complex network environments.Furthermore, DL could be combined with the Markov decision process and evolve into the deep reinforcement learning (DRL) model, which finds an optimal policy based on the reward function and the states of the system.Taken together, these techniques could be used to make better decisions to guide proper network design, thereby improving the network quality of service and quality of experience.With regard to the aspect of different layers of the network protocol stack, DL/DRL can be adopted for network feature extraction, decision-making, etc.In the physical layer, DL can be used for interference alignment.It can also be used to classify the modulation modes, design efficient network coding 17, and error correction codes, etc.In the data link layer, DL can be used for resource (such as channels) allocation, medium access control, traffic prediction, 18, link quality evaluation, and so on.In the network (routing) layer, routing establishment and routing optimization 19 can help to obtain an optimal routing path.In higher layers (such as the application layer), enhanced data The Innovation compression and task allocation is used.Besides the above protocol stack, one critical area of using DL is network security.DL can be used to classify the packets into benign/malicious types, and how it can be integrated with other ML schemes, such as unsupervised clustering, to achieve a better anomaly detection effect.</p>
<p>1][22] The conventional design of such components involves generally forward modeling, i.e., solving Maxwell's equations based on empirical and intuitive nanostructures to find corresponding optical properties, as well as the inverse design of nanophotonic devices given an on-demand optical response.The trans-dimensional feature of macro-optical components consisting of complex nano-antennas makes the design process very time consuming, computationally expensive, and even numerically prohibitive, such as device size and complexity increase.DL is an efficient and automatic platform, enabling novel efficient approaches to designing nanophotonic devices with high-performance and versatile functions.Here, we present briefly the recent progress of DL-based nanophotonics and its wide-ranging applications.DL was exploited for forward modeling at first using a DNN. 23,The transmission or reflection coefficients can be well predicted after training on huge datasets.To improve the prediction accuracy of DNN in case of small datasets, transfer learning was introduced to migrate knowledge between different physical scenarios, which greatly reduced the relative error.Furthermore, a CNN and an RNN were developed for the prediction of optical properties from arbitrary structures using images. 24,The CNN-RNN combination successfully predicted the absorption spectra from the given input structural images.In inverse design of nanophotonic devices, there are three different paradigms of DL methods, i.e., supervised, unsupervised, and RL. 25, Supervised learning has been utilized to design structural parameters for the pre-defined geometries, such as tandem DNN and bidirectional DNNs.Unsupervised learning methods learn by themselves without a specific target, and thus are more accessible to discovering new and arbitrary patterns 26, in completely new data than supervised learning.A generative adversarial network (GAN)-based approach, combining conditional GANs and Wasserstein GANs, was proposed to design freeform all-dielectric multifunctional metasurfaces.RL, especially double-deep Q-learning, powers up the inverse design of high-performance nanophotonic devices. 27,DL has endowed nanophotonic devices with better performance and more emerging applications. 28,,29,For instance, an intelligent microwave cloak driven by DL exhibits millisecond and self-adaptive response to an ever-changing incident wave and background. 28,Another example is that a DL-augmented infrared nanoplasmonic metasurface is developed for monitoring dynamics between four major classes of bio-molecules, which could impact the fields of biology, bioanalytics, and pharmacology from fundamental research, to disease diagnostics, to drug development. 29The potential of DL in the wide arena of nanophotonics has been unfolding.Even end-users without optics and photonics background could exploit the DL as a black box toolkit to design powerful optical devices.Nevertheless, how to interpret/mediate the intermediate DL process and determine the most dominant factors in the search for optimal solutions, are worthy of being investigated in depth.We optimistically envisage that the advancements in DL algorithms and computation/optimization infrastructures would enable us to realize more efficient and reliable training approaches, more complex nanostructures with unprecedented shapes and sizes, and more intelligent and reconfigurable optic/optoelectronic systems.</p>
<p>AI in other fields of information science</p>
<p>We believe that AI has great potential in the following directions:</p>
<p>d AI-based risk control and management in utilities can prevent costly or hazardous equipment failures by using sensors that detect and send information regarding the machine's health to the manufac-turer, predicting possible issues that could occur so as to ensure timely maintenance or automated shutdown.d AI could be used to produce simulations of real-world objects, called digital twins.When applied to the field of engineering, digital twins allow engineers and technicians to analyze the performance of an equipment virtually, thus avoiding safety and budget issues associated with traditional testing methods.d Combined with AI, intelligent robots are playing an important role in industry and human life.Different from traditional robots working according to the procedures specified by humans, intelligent robots have the ability of perception, recognition, and even automatic planning and decision-making, based on changes in environmental conditions.d AI of things (AIoT) or AI-empowered IoT applications. 30</p>
<p>AI IN MATHEMATICS</p>
<p>Mathematics always plays a crucial and indispensable role in AI.Decades ago, quite a few classical AI-related approaches, such as k-nearest neighbor, 32, support vector machine, 33, and AdaBoost, 34, were proposed and developed after their rigorous mathematical formulations had been established.In recent years, with the rapid development of DL, 35, AI has been gaining more and more attention in the mathematical community.Equipped with the Markov process, minimax optimization, and Bayesian statistics, RL, 36, GANs, 37, and Bayesian learning 38 became the most favorable tools in many AI applications.Nevertheless, there still exist plenty of open problems in mathematics for ML, including the interpretability of neural networks, the optimization problems of parameter estimation, and the generalization ability of learning models.In the rest of this section, we discuss these three questions in turn.</p>
<p>The interpretability of neural networks</p>
<p>From a mathematical perspective, ML usually constructs nonlinear models, with neural networks as a typical case, to approximate certain functions.The well-known Universal Approximation Theorem suggests that, under very mild conditions, any continuous function can be uniformly approximated on compact domains by neural networks, 39, which serves a vital function in the interpretability of neural networks.However, in real applications, ML models seem to admit accurate approximations of many extremely complicated functions, sometimes even black boxes, which are far beyond the scope of continuous functions.To understand the effectiveness of ML models, many researchers have investigated the function spaces that can be well approximated by them, and the corresponding quantitative measures.This issue is closely related to the classical approximation theory, but the approximation scheme is distinct.For example, Bach 40, finds that the random feature model is naturally associated with the corresponding reproducing kernel Hilbert space.In the same way, the Barron space is identified as the natural function space associated with two-layer neural networks, and the approximation error is measured using the Barron norm. 41,The corresponding quantities of residual networks (ResNets) are defined for the flow-induced spaces.For multi-layer networks, the natural function spaces for the purposes of approximation theory are the tree-like function spaces introduced in Wojtowytsch. 42,There are several works revealing the relationship between neural networks and numerical algorithms for solving partial differential equations.For example, He and Xu 43 discovered that CNNs for image classification have a strong connection with multi-grid (MG) methods.In fact, the pooling operation and feature extraction in CNNs correspond directly to</p>
<p>The Innovation restriction operation and iterative smoothers in MG, respectively.Hence, various convolution and pooling operations used in CNNs can be better understood.</p>
<p>The optimization problems of parameter estimation</p>
<p>In general, the optimization problem of estimating parameters of certain DNNs is in practice highly nonconvex and often nonsmooth.Can the global minimizers be expected?What is the landscape of local minimizers?How does one handle the nonsmoothness?All these questions are nontrivial from an optimization perspective.Indeed, numerous works and experiments demonstrate that the optimization for parameter estimation in DL is itself a much nicer problem than once thought; see, e.g., Goodfellow et al. 44, As a consequence, the study on the solution landscape (Figure 3), also known as loss surface of neural networks, is no longer supposed to be inaccessible and can even in turn provide guidance for global optimization.Interested readers can refer to the survey paper (Sun et al. 45 ) for recent progress in this aspect.</p>
<p>Recent studies indicate that nonsmooth activation functions, e.g., rectified linear units, are better than smooth ones in finding sparse solutions.However, the chain rule does not work in the case that the activation functions are nonsmooth, which then makes the widely used stochastic gradient (SG)-based approaches not feasible in theory.Taking approximated gradients at nonsmooth iterates as a remedy ensures that SG-type methods are still in extensive use, but that the numerical evidence has also exposed their limitations.Also, the penalty-based approaches proposed by Cui et al. 46, and Liu et al. 47 provide a new direction to solve the nonsmooth optimization problems efficiently.</p>
<p>The generalization ability of learning models</p>
<p>A small training error does not always lead to a small test error.This gap is caused by the generalization ability of learning models.A key finding in statistical learning theory states that the generalization error is bounded by a quantity that grows with the increase of the model capacity, but shrinks as the number of training examples increases. 48,A common conjecture relating generalization to solution landscape is that flat and wide minima generalize better than sharp ones.Thus, regularization techniques, including the dropout approach, 49, have emerged to force the algorithms to bypass the sharp minima.However, the mechanism behind this has not been fully explored.Recently, some researchers have focused on the ResNet-type architecture, with dropout being inserted after the last convolutional layer of each modular building.They thus managed to explain the stochastic dropout training process and the ensuing dropout regularization effect from the perspective of optimal control. 50</p>
<p>AI IN MEDICAL SCIENCE</p>
<p>There is a great trend for AI technology to grow more and more significant in daily operations, including medical fields.With the growing needs of healthcare for patients, hospital needs are evolving from informationization networking to the Internet Hospital and eventually to the Smart Hospital.At the same time, AI tools and hardware performance are also growing rapidly with each passing day.Eventually, common AI algorithms, such as CV, NLP, and data mining, will begin to be embedded in the medical equipment market (Figure 4).</p>
<p>AI doctor based on electronic medical records</p>
<p>For medical history data, it is inevitable to mention Doctor Watson, developed by the Watson platform of IBM, and Modernizing Medicine, which aims to solve oncology, and is now adopted by CVS &amp; Walgreens in the US and various medical organizations in China as well.Doctor Watson takes advantage of the NLP performance of the IBM Watson platform, which already collected vast data of medical history, as well as prior knowledge in the literature for reference.After inputting the patients' case, Doctor Watson searches the medical history reserve and forms an elementary treatment proposal, which will be further ranked by prior knowledge reserves.With the multiple models stored, Doctor Watson gives the final proposal as well as the confidence of the proposal.However, there are still problems for such AI doctors because, 51 as they rely on prior experience from US hospitals, the proposal may not be suitable for other regions with different medical insurance AI can be used for public health purposes in many ways.One classical usage is to detect disease outbreaks using search engine query data or social media data, as Google did for prediction of influenza epidemics 52, and the Chinese Academy of Sciences did for modeling the COVID-19 outbreak through multi-source information fusion. 53,After the COVID-19 outbreak, a digital health Quick Response (QR) code system has been developed by China, first to detect potential contact with confirmed COVID-19 cases and, secondly, to indicate the person's health status using mobile big data. 54Different colors indicate different health status: green means healthy and is OK for daily life, orange means risky and requires quarantine, and red means confirmed COVID-19 patient.It is easy to use for the general public, and has been adopted by many other countries.The health QR code has made great contributions to the worldwide prevention and control of the COVID-19 pandemic.</p>
<p>Biomarker discovery with AI</p>
<p>High-dimensional data, including multi-omics data, patient characteristics, medical laboratory test data, etc., are often used for generating various predictive or prognostic models through DL or statistical modeling methods.For instance, the COVID-19 severity evaluation model was built through ML using proteomic and metabolomic profiling data of sera 55, ; using integrated genetic, clinical, and demographic data, Taliaz et al. built an ML model to predict patient response to antidepressant medications 56, ; prognostic models for multiple cancer types (such as liver cancer, lung cancer, breast cancer, gastric cancer, colorectal cancer, pancreatic cancer, prostate cancer, ovarian cancer, lymphoma, leukemia, sarcoma, melanoma, bladder cancer, renal cancer, thyroid cancer, head and neck cancer, etc.) were constructed through DL or statistical methods, such as least absolute shrinkage and selection operator (LASSO), combined with Cox proportional hazards regression model using genomic data. 57</p>
<p>Image-based medical AI</p>
<p>Medical image AI is one of the most developed mature areas as there are numerous models for classification, detection, and segmentation tasks in CV.For the clinical area, CV algorithms can also be used for computer-aided diagnosis and treatment with ECG, CT, eye fundus imaging, etc.As human doctors may be tired and prone to make mistakes after viewing hundreds and hundreds of images for diagnosis, AI doctors can outperform a human medical image viewer due to their specialty at repeated work without fatigue.The first medical AI product approved by FDA is IDx-DR, which uses an AI model to make predictions of diabetic retinopathy.The smartphone app SkinVision can accurately detect melanomas. 58It uses "fractal analysis" to identify moles and their surrounding skin, based on size, diameter, and many other parameters, and to detect abnormal growth trends.AI-ECG of LEPU Medical can automatically detect heart disease with ECG images.Lianying Medical takes advantage of their hardware equipment to produce real-time high-definition image-guided all-round radiotherapy technology, which successfully achieves precise treatment.</p>
<p>Wearable devices for surveillance and early warning</p>
<p>For wearable devices, AliveCor has developed an algorithm to automatically predict the presence of atrial fibrillation, which is an early warning sign of stroke and heart failure.The 23andMe company can also test saliva</p>
<p>Review</p>
<p>The Innovation samples at a small cost, and a customer can be provided with information based on their genes, including who their ancestors were or potential diseases they may be prone to later in life.It provides accurate health management solutions based on individual and family genetic data.In the 20-30 years of the near feature, we believe there are several directions for further research: (1) causal inference for real-time in-hospital risk prediction.Clinical doctors usually acquire reasonable explanations for certain medical decisions, but the current AI models nowadays are usually black box models.The casual inference will help doctors to explain certain AI decisions and even discover novel ground truths.(2) Devices, including wearable instruments for multi-dimensional health monitoring.The multi-modality model is now a trend for AI research.With various devices to collect multi-modality data and a central processor to fuse all these data, the model can monitor the user's overall real-time health condition and give precautions more precisely.</p>
<p>(3) Automatic discovery of clinical markers for diseases that are difficult to diagnose.Diseases, such as ALS, are still difficult for clinical doctors to diagnose because they lack any effective general marker.It may be possible for AI to discover common phenomena for these patients and find an effective marker for early diagnosis.</p>
<p>AI-aided drug discovery</p>
<p>Today we have come into the precision medicine era, and the new targeted drugs are the cornerstones for precision therapy.However, over the past decades, it takes an average of over one billion dollars and 10 years to bring a new drug into the market.How to accelerate the drug discovery process, and avoid late-stage failure, are key concerns for all the big and fiercely competitive pharmaceutical companies.The highlighted emerging role of AI, including ML, DL, expert systems, and artificial neural networks (ANNs), has brought new insights and high efficiency into the new drug discovery processes.AI has been adopted in many aspects of drug discovery, including de novo molecule design, structure-based modeling for proteins and ligands, quantitative structure-activity relationship research, and druggable property judgments.DL-based AI appliances demonstrate superior merits in addressing some challenging problems in drug discovery.Of course, prediction of chemical synthesis routes and chemical process optimization are also valuable in accelerating new drug discovery, as well as lowering production costs.</p>
<p>There has been notable progress in the AI-aided new drug discovery in recent years, for both new chemical entity discovery and the relating business area.Based on DNNs, DeepMind built the AlphaFold platform to predict 3D protein structures that outperformed other algorithms.As an illustration of great achievement, AlphaFold successfully and accurately predicted 25 scratch protein structures from a 43 protein panel without using previously built proteins models.Accordingly, AlphaFold won the CASP13 proteinfolding competition in December 2018. 59,Based on the GANs and other ML methods, Insilico constructed a modular drug design platform GENTRL system.In September 2019, they reported the discovery of the first de novo active DDR1 kinase inhibitor developed by the GENTRL system.It took the team only 46 days from target selection to get an active drug candidate using in vivo data. 60Exscientia and Sumitomo Dainippon Pharma developed a new drug candidate, DSP-1181, for the treatment of obsessivecompulsive disorder on the Centaur Chemist AI platform.In January 2020, DSP-1181 started its phase I clinical trials, which means that, from program initiation to phase I study, the comprehensive exploration took less than 12 months.In contrast, comparable drug discovery using traditional methods usually needs 4-5 years with traditional methods.</p>
<p>How AI transforms medical practice: A case study of cervical cancer</p>
<p>As the most common malignant tumor in women, cervical cancer is a disease that has a clear cause and can be prevented, and even treated, if detected early.Conventionally, the screening strategy for cervical cancer mainly adopts the "three-step" model of "cervical cytology-colposcopy-histopathology." 61,However, limited by the level of testing methods, the efficiency of cervical cancer screening is not high.In addition, owing to the lack of knowledge by doctors in some primary hospitals, patients cannot be provided with the best diagnosis and treatment decisions.In recent years, with the advent of the era of computer science and big data, AI has gradually begun to extend and blend into various fields.In particular, AI has been widely used in a variety of cancers as a new tool for data mining.For cervical cancer, a clinical database with millions of medical records and pathological data has been built, and an AI medical tool set has been developed. 62,Such an AI analysis algorithm supports doctors to access the ability of rapid iterative AI model training.In addition, a prognostic prediction model established by ML and a web-based prognostic result calculator have been developed, which can accurately predict the risk of postoperative recurrence and death in cervical cancer patients, and thereby better guide decision-making in postoperative adjuvant treatment. 63</p>
<p>AI IN MATERIALS SCIENCE</p>
<p>As the cornerstone of modern industry, materials have played a crucial role in the design of revolutionary forms of matter, with targeted properties for broad applications in energy, information, biomedicine, construction, transportation, national security, spaceflight, and so forth.Traditional strategies rely on the empirical trial and error experimental approaches as well as the theoretical simulation methods, e.g., density functional theory, thermodynamics, or molecular dynamics, to discover novel materials. 64These methods often face the challenges of long research cycles, high costs, and low success rates, and thus cannot meet the increasingly growing demands of current materials science.Accelerating the speed of discovery and deployment of advanced materials will therefore be essential in the coming era.</p>
<p>With the rapid development of data processing and powerful algorithms, AI-based methods, such as ML and DL, are emerging with good potentials in the search for and design of new materials prior to actually manufacturing them. 65,,66,By integrating material property data, such as the constituent element, lattice symmetry, atomic radius, valence, binding energy, electronegativity, magnetism, polarization, energy band, structure-property relation, and functionalities, the machine can be trained to "think" about how to improve material design and even predict the properties of new materials in a costeffective manner (Figure 5).</p>
<p>AI in discovery and design of new materials</p>
<p>Recently, AI techniques have made significant advances in rational design and accelerated discovery of various materials, such as piezoelectric materials with large electrostrains, 67, organic-inorganic perovskites for photovoltaics, 68, molecular emitters for efficient light-emitting diodes, 69, inorganic solid materials for thermoelectrics, 70, and organic electronic materials for renewable-energy applications. 66,,71,The power of data-driven computing and algorithmic optimization can promote comprehensive applications of simulation and ML (i.e., high-throughput virtual screening, inverse molecular design, Bayesian optimization, and supervised learning, etc.), in material discovery and property prediction in various fields. 72,For instance, using a DL Bayesian framework, the attribute-driven inverse materials design has been demonstrated for efficient and accurate prediction of functional molecular materials, with desired semiconducting properties or redox stability for applications in organic thin-film transistors, organic solar cells, or lithium-ion batteries. 73,It is meaningful to adopt automation tools for quick experimental testing of potential materials and utilize high-performance computing to calculate their bulk, interface, and defect-related properties. 74,The effective convergence of automation, computing, and ML can greatly speed up the discovery of materials.In the future, with the aid of AI techniques, it will be possible to accomplish the design of superconductors, metallic glasses, solder alloys, high-entropy alloys, high-temperature superalloys, thermoelectric materials, two-dimensional materials, magnetocaloric materials, polymeric bio-inspired materials, sensitive composite materials, and topological (electronic and phonon) materials, and so on.In the past decade, topological materials have ignited the research enthusiasm of condensed matter physicists, materials scientists, and chemists, as they exhibit exotic physical properties with potential applications in electronics, thermoelectrics, optics, catalysis, and energy-related fields.From the most recent predictions, more than a quarter of all inorganic materials in nature are topologically nontrivial.The establishment of topological electronic materials databases [75][76][77] and</p>
<p>The Innovation topological phononic materials databases 78, using high-throughput methods will help to accelerate the screening and experimental discovery of new topological materials for functional applications.It is recognized that large-scale high-quality datasets are required to practice AI.Great efforts have also been expended in building high-quality materials science databases.As one of the top-ranking databases of its kind, the "atomly.net"materials data infrastructure, 79, has calculated the properties of more than 180,000 inorganic compounds, including their equilibrium structures, electron energy bands, dielectric properties, simulated diffraction patterns, elasticity tensors, etc.As such, the atomly.netdatabase has set a solid foundation for extending AI into the area of materials science research.The X-ray diffraction (XRD)matcher model of atomly.netuses ML to match and classify the experimental XRD to the simulated patterns.Very recently, by using the dataset from atomly.net, an accurate AI model was built to rapidly predict the formation energy of almost any given compound to yield a fairly good predictive ability. 80</p>
<p>AI-powered Materials Genome Initiative</p>
<p>The Materials Genome Initiative (MGI) is a great plan for rational realization of new materials and related functions, and it aims to discover, manufacture, and deploy advanced materials efficiently, cost-effectively, and intelligently.The initiative creates policy, resources, and infrastructure for accelerating materials development at a high level.This is a new paradigm for the discovery and design of next-generation materials, and runs from a view point of fundamental building blocks toward general materials developments, and accelerates materials development through efforts in theory, computation, and experiment, in a highly integrated high-throughput manner.MGI raises an ultimately high goal and high level for materials development and materials science for humans in the future.The spirit of MGI is to design novel materials by using data pools and powerful computation once the requirements or aspirations of functional usages appear.The theory, computation, and algorithm are the primary and substantial factors in the establishment and implementation of MGI.Advances in theories, computations, and experiments in materials science and engineering provide the footstone to not only accelerate the speed at which new materials are realized but to also shorten the time needed to push new products into the market.These AI techniques bring a great promise to the developing MGI.The applications of new technologies, such as ML and DL, directly accelerate materials research and the establishment of MGI.The model construction and application to science and engineering, as well as the data infrastructure, are of central importance.When the AI-powered MGI approaches are coupled with the ongoing autonomy of manufacturing methods, the potential impact to society and the economy in the future is profound.We are now beginning to see that the AI-aided MGI, among other things, integrates experiments, computation, and theory, and facilitates access to materials data, equips the next generation of the materials workforce, and enables a paradigm shift in materials development.Furthermore, the AI-powdered MGI could also design operational procedures and control the equipment to execute experiments, and to further realize autonomous experimentation in future material research.</p>
<p>Advanced functional materials for generation upgrade of AI</p>
<p>The realization and application of AI techniques depend on the computational capability and computer hardware, and this bases physical functionality on the performance of computers or supercomputers.For our current technology, the electric currents or electric carriers for driving electric chips and devices consist of electrons with ordinary characteristics, such as heavy mass and low mobility.All chips and devices emit relatively remarkable heat levels, consuming too much energy and lowering the efficiency of information transmission.Benefiting from the rapid development of modern physics, a series of advanced materials with exotic functional effects have been discovered or designed, including superconductors, quantum anomalous Hall insulators, and topological fermions.In particular, the superconducting state or topologically nontrivial electrons will promote the next-generation AI techniques once the (near) room temperature applications of these states are realized and implanted in integrated circuits. 81In this case, the central processing units, signal circuits, and power channels will be driven based The Innovation on the electronic carriers that show massless, energy-diffusionless, ultra-high mobility, or chiral-protection characteristics.The ordinary electrons will be removed from the physical circuits of future-generation chips and devices, leaving superconducting and topological chiral electrons running in future AI chips and supercomputers.The efficiency of transmission, for information and logic computing will be improved on a vast scale and at a very low cost.</p>
<p>AI for materials and materials for AI</p>
<p>The coming decade will continue to witness the development of advanced ML algorithms, newly emerging data-driven AI methodologies, and integrated technologies for facilitating structure design and property prediction, as well as to accelerate the discovery, design, development, and deployment of advanced materials into existing and emerging industrial sectors.At this moment, we are facing challenges in achieving accelerated materials research through the integration of experiment, computation, and theory.The great MGI, proposed for high-level materials research, helps to promote this process, especially when it is assisted by AI techniques.Still, there is a long way to go for the usage of these advanced functional materials in future-generation electric chips and devices to be realized.More materials and functional effects need to be discovered or improved by the developing AI techniques.Meanwhile, it is worth noting that materials are the core components of devices and chips that are used for construction of computers or machines for advanced AI systems.The rapid development of new materials, especially the emergence of flexible, sensitive, and smart materials, is of great importance for a broad range of attractive technologies, such as flexible circuits, stretchable tactile sensors, multifunctional actuators, transistor-based artificial synapses, integrated networks of semiconductor/quantum devices, intelligent robotics, human-machine interactions, simulated muscles, biomimetic prostheses, etc.These promising materials, devices, and integrated technologies will greatly promote the advancement of AI systems toward wide applications in human life.Once the physical circuits are upgraded by advanced functional or smart materials, AI techniques will largely promote the developments and applications of all disciplines.</p>
<p>AI IN GEOSCIENCE AI technologies involved in a large range of geoscience fields</p>
<p>Momentous challenges threatening current society require solutions to problems that belong to geoscience, such as evaluating the effects of climate change, assessing air quality, forecasting the effects of disaster incidences on infrastructure, by calculating the incoming consumption and availability of food, water, and soil resources, and identifying factors that are indicators for potential volcanic eruptions, tsunamis, floods, and earthquakes. 82,,83,It has become possible, with the emergence of advanced technology products (e.g., deep sea drilling vessels and remote sensing satellites), for enhancements in computational infrastructure that allow for processing large-scale, wide-range simulations of multiple models in geoscience, and internet-based data analysis that facilitates collection, processing, and storage of data in distributed and crowd-sourced environments. 84,The growing availability of massive geoscience data provides unlimited possibilities for AI-which has popularized all aspects of our daily life (e.g., entertainment, transportation, and commerce)-to significantly contribute to geoscience problems of great societal relevance.As geoscience enters the era of massive data, AI, which has been extensively successful in different fields, offers immense opportunities for settling a series of problems in Earth systems. 85,,86,Accompanied by diversified data, AI-enabled technologies, such as smart sensors, image visualization, and intelligent inversion, are being actively examined in a large range of geoscience fields, such as marine geoscience, rock physics, geology, ecology, seismicity, environment, hydrology, remote sensing, Arc GIS, and planetary science. 87</p>
<p>Multiple challenges in the development of geoscience</p>
<p>9][90] Amorphous bound-aries generally exist in geoscience objects between space and time that are not as well defined as objects in other fields.Geoscience phenomena are also significantly multivariate, obey nonlinear relationships, and exhibit spatiotemporal structure and non-stationary characteristics.Except for the inherent challenges of geoscience observations, the massive data at multiple dimensions of time and space, with different levels of incompleteness, noise, and uncertainties, disturb processes in geoscience.For supervised learning approaches, there are other difficulties owing to the lack of gold standard ground truth and the "small size" of samples (e.g., a small amount of historical data with sufficient observations) in geoscience applications.</p>
<p>Usage of AI technologies as efficient approaches to promote the geoscience processes</p>
<p>Geoscientists continually make every effort to develop better techniques for simulating the present status of the Earth system (e.g., how much greenhouse gases are released into the atmosphere), and the connections between and within its subsystems (e.g., how does the elevated temperature influence the ocean ecosystem).Viewed from the perspective of geoscience, newly emerging approaches, with the aid of AI, are a perfect combination for these issues in the application of geoscience: (1) characterizing objects and events 91, ; (2) estimating geoscience variables from observations 92, ; (3) forecasting geoscience variables according to long-term observations 85, ; (4) exploring geoscience data relationships 93, ; and (5) causal discovery and causal attribution. 94While characterizing geoscience objects and events using traditional methods are primarily rooted in hand-coded features, algorithms can automatically detect the data by improving the performance with pattern-mining techniques.However, due to spatiotemporal targets with vague boundaries and the related uncertainties, it can be necessary to advance pattern-mining methods that can explain the temporal and spatial characteristics of geoscience data when characterizing different events and objects.To address the non-stationary issue of geoscience data, AI-aided algorithms have been expanded to integrate the holistic results of professional predictors and engender robust estimations of climate variables (e.g., humidity and temperature).Furthermore, forecasting long-term trends of the current situation in the Earth system using AI-enabled technologies can simulate future scenarios and formulate early resource planning and adaptation policies.Mining geoscience data relationships can help us seize vital signs of the Earth system and promote our understanding of geoscience developments.Of great interest is the advancement of AI-decision methodology with uncertain prediction probabilities, engendering vague risks with poorly resolved tails, signifying the most extreme, transient, and rare events formulated by model sets, which supports various cases to improve accuracy and effectiveness.</p>
<p>AI technologies for optimizing the resource management in geoscience</p>
<p>Currently, AI can perform better than humans in some well-defined tasks.For example, AI techniques have been used in urban water resource planning, mainly due to their remarkable capacity for modeling, flexibility, reasoning, and forecasting the water demand and capacity.Design and application of an Adaptive Intelligent Dynamic Water Resource Planning system, the subset of AI for sustainable water resource management in urban regions, largely prompted the optimization of water resource allocation, will finally minimize the operation costs and improve the sustainability of environmental management 95, (Figure 6).Also, meteorology requires collecting tremendous amounts of data on many different variables, such as humidity, altitude, and temperature; however, dealing with such a huge dataset is a big challenge. 96,An AI-based technique is being utilized to analyze shallow-water reef images, recognize the coral color-to track the effects of climate change, and to collect humidity, temperature, and CO 2 data-to grasp the health of our ecological environment. 97,Beyond AI's capabilities for meteorology, it can also play a critical role in decreasing greenhouse gas emissions originating from the electric-power sector.Comprised of production, transportation, allocation, and consumption of electricity, many opportunities exist in the electric-power sector for Al applications, including speeding up the development of new clean energy, enhancing system optimization and management, improving electricity-demand forecasts and distribution, and advancing system monitoring. 98,New materials may even be found, with the auxiliary of AI, for batteries to store energy or materials and absorb CO 2 from the atmosphere. 99,Although traditional fossil fuel operations have been widely used for thousands of years, AI techniques are being used to help explore the development of more potential sustainable energy sources for the development (e.g., fusion technology). 100n addition to the adjustment of energy structures due to climate change (a core part of geoscience systems), a second, less-obvious step could also be taken to reduce greenhouse gas emission: using AI to target inefficiencies.A related statistical report by the Lawrence Livermore National Laboratory pointed out that around 68% of energy produced in the US could be better used for purposeful activities, such as electricity generation or transportation, but is instead contributing to environmental burdens. 101,AI is primed to reduce these inefficiencies of current nuclear power plants and fossil fuel operations, as well as improve the efficiency of renewable grid resources. 102,For example, AI can be instrumental in the operation and optimization of solar and wind farms to make these utility-scale renewable-energy systems far more efficient in the production of electricity. 103,AI can also assist in reducing energy losses in electricity transportation and allocation. 104,A distribution system operator in Europe used AI to analyze load, voltage, and network distribution data, to help "operators assess available capacity on the system and plan for future needs." 105AI allowed the distribution system operator to employ existing and new resources to make the distribution of energy assets more readily available and flexible.The International Energy Agency has proposed that energy efficiency is core to the reform of energy systems and will play a key role in reducing the growth of global energy demand to one-third of the current level by 2040.</p>
<p>AI as a building block to promote development in geoscience</p>
<p>The Earth's system is of significant scientific interest, and affects all aspects of life. 106The challenges, problems, and promising directions provided by AI are definitely not exhaustive, but rather, serve to illustrate that there is great potential for future AI research in this important field.Prosperity, development, and popularization of AI approaches in the geosciences is commonly driven by a posed scientific question, and the best way to succeed is that AI researchers work closely with geoscientists at all stages of research.That is because the geoscientists can better understand which scientific question is important and novel, which sample collection process can reasonably exhibit the inherent strengths, which datasets and parameters can be used to answer that question, and which pre-processing operations are conducted, such as removing seasonal cycles or smoothing.Similarly, AI researchers are better suited to decide which data analysis approaches are appropriate and available for the data, the advantages and disadvantages of these approaches, and what the approaches actually acquire.Interpretability is also an important goal in geoscience because, if we can understand the basic reasoning behind the models, patterns, or relationships extracted from the data, they can be used as building blocks in scientific knowledge discovery.Hence, frequent communication between the researchers avoids long detours and ensures that analysis results are indeed beneficial to both geoscientists and AI researchers.</p>
<p>AI IN THE LIFE SCIENCES</p>
<p>The developments of AI and the life sciences are intertwined.The ultimate goal of AI is to achieve human-like intelligence, as the human brain is capable of multi-tasking, learning with minimal supervision, and generalizing learned skills, all accomplished with high efficiency and low energy cost. 107The Innovation</p>
<p>Mutual inspiration between AI and neuroscience</p>
<p>In the past decades, neuroscience concepts have been introduced into ML algorithms and played critical roles in triggering several important advances in AI.For example, the origins of DL methods lie directly in neuroscience, 5, which further stimulated the emergence of the field of RL. 108, The current state-of-the-art CNNs incorporate several hallmarks of neural computation, including nonlinear transduction, divisive normalization, and maximum-based pooling of inputs, 109, which were directly inspired by the unique processing of visual input in the mammalian visual cortex. 110,By introducing the brain's attentional mechanisms, a novel network has been shown to produce enhanced accuracy and computational efficiency at difficult multi-object recognition tasks than conventional CNNs. 111,Other neuroscience findings, including the mechanisms underlying working memory, episodic memory, and neural plasticity, have inspired the development of AI algorithms that address several challenges in deep networks. 108These algorithms can be directly implemented in the design and refinement of the brain-machine interface and neuroprostheses.</p>
<p>On the other hand, insights from AI research have the potential to offer new perspectives on the basics of intelligence in the brains of humans and other species.Unlike traditional neuroscientists, AI researchers can formalize the concepts of neural mechanisms in a quantitative language to extract their necessity and sufficiency for intelligent behavior.An important illustration of such exchange is the development of the temporal-difference (TD) methods in RL models and the resemblance of TD-form learning in the brain. 112,Therefore, the China Brain Project covers both basic research on cognition and translational research for brain disease and brain-inspired intelligence technology. 113</p>
<p>AI for omics big data analysis</p>
<p>Currently, AI can perform better than humans in some well-defined tasks, such as omics data analysis and smart agriculture.In the big data era, 114 there are many types of data (variety), the volume of data is big, and the generation of data (velocity) is fast.The high variety, big volume, and fast velocity of data makes having it a matter of big value, but also makes it difficult to analyze the data.Unlike traditional statistics-based methods, AI can easily handle big data and reveal hidden associations.</p>
<p>In genetics studies, there are many successful applications of AI. 115, One of the key questions is to determine whether a single amino acid polymorphism is deleterious. 116,There have been sequence conservation-based SIFT 117, and network-based SySAP, 118, but all these methods have met bottlenecks and cannot be further improved.Sundaram et al. developed Prima-teAI, which can predict the clinical outcome of mutation based on DNN. 119,nother problem is how to call copy-number variations, which play important roles in various cancers. 120,,121,Glessner et al. proposed a DL-based tool DeepCNV, in which the area under the receiver operating characteristic (ROC) curve was 0.909, much higher than other ML methods. 122,In epigenetic studies, m6A modification is one of the most important mechanisms. 123,Zhang et al. developed an ensemble DL predictor (EDLm6APred) for mRNA m6A site prediction. 124,The area under the ROC curve of EDL-m6APred was 86.6%, higher than existing m6A methylation site prediction models.There are many other DL-based omics tools, such as DeepCpG 125, for methylation, DeepPep 126, for proteomics, AtacWorks 127, for assay for transposase-accessible chromatin with high-throughput sequencing, and deepTCR 128 for T cell receptor sequencing.</p>
<p>Another emerging application is DL for single-cell sequencing data.Unlike bulk data, in which the sample size is usually much smaller than the number of features, the sample size of cells in single-cell data could also be big compared with the number of genes.That makes the DL algorithm applicable for most single-cell data.Since the single-cell data are sparse and have many unmeasured missing values, DeepImpute can accurately impute these missing values in the big gene 3 cell matrix. 129,During the quality control of single-cell data, it is important to remove the doublet solo embedded cells, using autoencoder, and then build a feedforward neural network to identify the doublet. 130,Potential energy underlying single-cell gradients used gener-ative modeling to learn the underlying differentiation landscape from time series single-cell RNA sequencing data. 131n protein structure prediction, the DL-based AIphaFold2 can accurately predict the 3D structures of 98.5% of human proteins, and will predict the structures of 130 million proteins of other organisms in the next few months. 132,It is even considered to be the second-largest breakthrough in life sciences after the human genome project 133 and will facilitate drug development among other things.</p>
<p>AI makes modern agriculture smart</p>
<p>Agriculture is entering a fourth revolution, termed agriculture 4.0 or smart agriculture, benefiting from the arrival of the big data era as well as the rapid progress of lots of advanced technologies, in particular ML, modern information, and communication technologies. 134,,135Applications of DL, information, and sensing technologies in agriculture cover the whole stages of agricultural production, including breeding, cultivation, and harvesting.</p>
<p>Traditional breeding usually exploits genetic variations by searching natural variation or artificial mutagenesis.However, it is hard for either method to expose the whole mutation spectrum.Using DL models trained on the existing variants, predictions can be made on multiple unidentified gene loci. 136,For example, an ML method, multi-criteria rice reproductive gene predictor, was developed and applied to predict coding and lincRNA genes associated with reproductive processes in rice. 137,Moreover, models trained in species with well-studied genomic data (such as Arabidopsis and rice) can also be applied to other species with limited genome information (such as wild strawberry and soybean). 138,In most cases, the links between genotypes and phenotypes are more complicated than we expected.One gene can usually respond to multiple phenotypes, and one trait is generally the product of the synergism between multi-genes and multi-development.For this reason, multi-traits DL models were developed and enabled genomic editing in plant breeding. 139,,140t is well known that dynamic and accurate monitoring of crops during the whole growth period is vitally important to precision agriculture.In the new stage of agriculture, both remote sensing and DL play indispensable roles.Specifically, remote sensing (including proximal sensing) could produce agricultural big data from ground, air-borne, to space-borne platforms, which have a unique potential to offer an economical approach for non-destructive, timely, objective, synoptic, long-term, and multi-scale information for crop monitoring and management, thereby greatly assisting in precision decisions regarding irrigation, nutrients, disease, pests, and yield. 141,,142,DL makes it possible to simply, efficiently, and accurately discover knowledge from massive and complicated data, especially for remote sensing big data that are characterized with multiple spatial-temporal-spectral information, owing to its strong capability for feature representation and superiority in capturing the essential relation between observation data and agronomy parameters or crop traits. 135,,143,Integration of DL and big data for agriculture has demonstrated the most disruptive force, as big as the green revolution.As shown in Figure 7, for possible application a scenario of smart agriculture, multi-source satellite remote sensing data with various geo-and radio-metric information, as well as abundance of spectral information from UV, visible, and shortwave infrared to microwave regions, can be collected.In addition, advanced aircraft systems, such as unmanned aerial vehicles with multi/hyper-spectral cameras on board, and smartphonebased portable devices, will be used to obtain multi/hyper-spectral data in specific fields.All types of data can be integrated by DL-based fusion techniques for different purposes, and then shared for all users for cloud computing.On the cloud computing platform, different agriculture remote sensing models developed by a combination of data-driven ML methods and physical models, will be deployed and applied to acquire a range of biophysical and biochemical parameters of crops, which will be further analyzed by a decision-making and prediction system to obtain the current water/nutrient stress, growth status, and to predict future development.As a result, an automatic or interactive user service platform can be accessible to make the correct decisions for appropriate actions through an integrated irrigation and fertilization system.Furthermore, DL presents unique advantages in specific agricultural applications, such as for dense scenes, that increase the difficulty of artificial planting and harvesting.It is reported that CNNs and Autoencoder models, trained with image data, are being used increasingly for phenotyping and yield estimation, 144 such as counting fruits in orchards, grain recognition and classification, disease diagnosis, etc. [145][146][147] Consequently, this may greatly liberate the labor force.</p>
<p>The application of DL in agriculture is just beginning.There are still many problems and challenges for the future development of DL technology.We believe, with the continuous acquisition of massive data and the optimization of algorithms, DL will have a better prospect in agricultural production.</p>
<p>AI IN PHYSICS</p>
<p>The scale of modern physics ranges from the size of a neutron to the size of the Universe (Figure 8).According to the scale, physics can be divided into four categories: particle physics on the scale of neutrons, nuclear physics on the scale of atoms, condensed matter physics on the scale of molecules, and cosmic physics on the scale of the Universe.AI, also called ML, plays an important role in all physics in different scales, since the use of the AI algorithm will be the main trend in data analyses, such as the reconstruction and analysis of images.</p>
<p>Speeding up simulations and identifications of particles with AI</p>
<p>There are many applications or explorations of applications of AI in particle physics.We cannot cover all of them here, but only use lattice quantum chromodynamics (LQCD) and the experiments on the Beijing spectrometer (BES) and the large hadron collider (LHC) to illustrate the power of ML in both theoretical and experimental particle physics.</p>
<p>LQCD studies the nonperturbative properties of QCD by using Monte Carlo simulations on supercomputers to help us understand the strong interaction that binds quarks together to form nucleons.Markov chain Monte Carlo simulations commonly used in LQCD suffer from topological freezing and critical slowing down as the simulations approach the real situation of the actual world.New algorithms with the help of DL are being proposed and tested to overcome those difficulties. 148,,149,Physical observables are extracted from LQCD data, whose signal-to-noise ratio deteriorates exponentially.For non-Abelian gauge theories, such as QCD, complicated contour deformations can be optimized by using ML to reduce the variance of LQCD data.Proof-of-principle applications in two dimensions have been studied. 150,ML can also be used to reduce the time cost of generating LQCD data. 151n the experimental side, particle identification (PID) plays an important role.Recently, a few PID algorithms on BES-III were developed, and the ANN 152, is one of them.Also, extreme gradient boosting has been used for multi-dimensional distribution reweighting, muon identification, and cluster reconstruction, and can improve the muon identification.U-Net is a convolutional network for pixel-level semantic segmentation, which is widely used in CV.It has been applied on BES-III to solve the problem of multi-turn curling track finding for the main drift chamber.The average efficiency and purity for the first turn's hits is about 91%, at the threshold of 0.85.Current (and future) particle physics experiments are producing a huge amount of data.Machine leaning can be used to discriminate between signal and overwhelming background events.Examples of data analyses on LHC, using supervised ML, can be found in a 2018 collaboration. 153,To take the potential advantage of quantum computers forward, quantum ML methods are also being investigated, see, for example, Wu et al., 154 and references therein, for proof-of-concept studies.The Innovation</p>
<p>AI makes nuclear physics powerful</p>
<p>Cosmic ray muon tomography (Muography) 155 is an imaging graphe technology using natural cosmic ray muon radiation rather than artificial radiation to reduce the dangers.As an advantage, this technology can detect high-Z materials without destruction, as muon is sensitive to high-Z materials.The Classification Model Algorithm (CMA) algorithm is based on the classification in the supervised learning and gray system theory, and generates a binary classifier designing and decision function with the input of the muon track, and the output indicates whether the material exists at the location.The AI helps the user to improve the efficiency of the scanning time with muons.</p>
<p>AIso, for nuclear detection, the Cs 2 LiYCl 6 :Ce (CLYC) signal can react to both electrons and neutrons to create a pulse signal, and can therefore be applied to detect both neutrons and electrons, 156 but needs identification of the two particles by analyzing the shapes of the waves, that is n-g ID.The traditional method has been the PSD (pulse shape discrimination) method, which is used to separate the waves of two particles by analyzing the distribution of the pulse information-such as amplitude, width, raise time, fall time, and the two particles that can be separated when the distribution has two separated Gaussian distributions.The traditional PSD can only analyze single-pulse waves, rather than multipulse waves, when two particles react with CLYC closely.But it can be solved by using an ANN method for classification of the six categories (n,g,n + n,n + g,g + n,g).Also, there are several parameters that could be used by AI to improve the reconstruction algorithm with high efficiency and less error.</p>
<p>AI-aided condensed matter physics</p>
<p>AI opens up a new avenue for physical science, especially when a trove of data is available.Recent works demonstrate that ML provides useful insights to improve the density functional theory (DFT), in which the singleelectron picture of the Kohn-Sham scheme has the difficulty of taking care of the exchange and correlation effects of many-body systems.Yu et al. proposed a Bayesian optimization algorithm to fit the Hubbard U parameter, and the new method can find the optimal Hubbard U through a self-consistent process with good efficiency compared with the linear response method, 157, and boost the accuracy to the near-hybrid-functional-level.Snyder et al. developed an ML density functional for a 1D non-interacting non-spin-polarized fermion system to obtain significantly improved kinetic energy.This method enabled a direct approximation of the kinetic energy of a quantum system and can be utilized in orbital-free DFT modeling, and can even bypass the solving of the Kohn-Sham equation-while maintaining the precision to the quantum chemical level when a strong correlation term is included.Recently, FermiNet showed that the many-body quantum mechanics equations can be solved via AI.AI models also show advantages of capturing the interatom force field.In 2010, the Gaussian approximation potential (GAP) 158, was introduced as a powerful interatomic force field to describe the interactions between atoms.GAP uses kernel regression and invariant many-body representations, and performs quite well.For instance, it can simulate crystallization of amorphous crystals under high pressure fairly accurately.By employing the smooth overlap of the atomic position kernel (SOAP), 159 the accuracy of the potential can be further enhanced and, therefore, the SOAP-GAP can be viewed as a field-leading method for AI molecular dynamic simulation.There are also several other well-developed AI interatomic potentials out there, e.g., crystal graph CNNs provide a widely applicable way of vectorizing crystalline materials; SchNet embeds the continuous-filter convolutional layers into its DNNs for easing molecular dynamic as the potentials are space continuous; DimeNet constructs the directional message passing neural network by adding not only the bond length between atoms but also the bond angle, the dihedral angle, and the interactions between unconnected atoms into the model to obtain good accuracy.</p>
<p>AI helps explore the Universe</p>
<p>AI is one of the newest technologies, while astronomy is one of the oldest sciences.When the two meet, new opportunities for scientific breakthroughs are often triggered.Observations and data analysis play a central role in The Innovation astronomy.The amount of data collected by modern telescopes has reached unprecedented levels, even the most basic task of constructing a catalog has become challenging with traditional source-finding tools. 160,Astronomers have developed automated and intelligent source-finding tools based on DL, which not only offer significant advantages in operational speed but also facilitate a comprehensive understanding of the Universe by identifying particular forms of objects that cannot be detected by traditional software and visual inspection. 160,,161ore than a decade ago, a citizen science project called "Galaxy Zoo" was proposed to help label one million images of galaxies collected by the Sloan Digital Sky Survey (SDSS) by posting images online and recruiting volunteers. 162,Larger optical telescopes, in operation or under construction, produce data several orders of magnitude higher than SDSS.Even with volunteers involved, there is no way to analyze the vast amount of data received.The advantages of ML are not limited to source-finding and galaxy classification.In fact, it has a much wider range of applications.For example, CNN plays an important role in detecting and decoding gravitational wave signals in real time, reconstructing all parameters within 2 ms, while traditional algorithms take several days to accomplish the same task. 163Such DL systems have also been used to automatically generate alerts for transients and track asteroids and other fast-moving near-Earth objects, improving detection efficiency by several orders of magnitude.In addition, astrophysicists are exploring the use of neural networks to measure galaxy clusters and study the evolution of the Universe.</p>
<p>In addition to the amazing speed, neural networks seem to have a deeper understanding of the data than expected and can recognize more complex patterns, indicating that the "machine" is evolving rather than just learning the characteristics of the input data.</p>
<p>AI IN CHEMISTRY</p>
<p>Chemistry plays an important "central" role in other sciences 164, because it is the investigation of the structure and properties of matter, and identifies the chemical reactions that convert substances into to other substances.Accordingly, chemistry is a data-rich branch of science containing complex information resulting from centuries of experiments and, more recently, decades of computational analysis.This vast treasure trove of data is most apparent within the Chemical Abstract Services, which has collected more than 183 million unique organic and inorganic substances, including alloys, coordination compounds, minerals, mixtures, polymers, and salts, and is expanding by addition of thousands of additional new substances daily. 165,The unlimited complexity in the variety of material compounds explains why chemistry research is still a labor-intensive task.The level of complexity and vast amounts of data within chemistry provides a prime opportunity to achieve significant breakthroughs with the application of AI.First, the type of molecules that can be constructed from atoms are almost unlimited, which leads to unlimited chemical space 166, ; the interconnection of these molecules with all possible combinations of factors, such as temperature, substrates, and solvents, are overwhelmingly large, giving rise to unlimited reaction space. 167,Exploration of the unlimited chemical space and reaction space, and navigating to the optimum ones with the desired properties, is thus practically impossible solely from human efforts.Secondly, in chemistry, the huge assortment of molecules and the interplay of them with the external environments brings a new level of complexity, which cannot be simply predicted using physical laws.While many concepts, rules, and theories have been generalized from centuries of experience from studying trivial (i.e., single component) systems, nontrivial complexities are more likely as we discover that "more is different" in the words of Philip Warren Anderson, American physicist and Nobel Laureate. 168Nontrivial complexities will occur when the scale changes, and the breaking of symmetry in larger, increasingly complex systems, and the rules will shift from quantitative to qualitative.Due to lack of systematic and analytical theory toward the structures, properties, and transformations of macroscopic substances, chemistry research is thus, incorrectly, guided by heuristics and fragmental rules accumulated over the previous centuries, yielding progress that only proceeds through trial and error.ML will recognize patterns from large amounts of data; thereby of-fering an unprecedented way of dealing with complexity, and reshaping chemistry research by revolutionizing the way in which data are used.Every sub-field of chemistry, currently, has utilized some form of AI, including tools for chemistry research and data generation, such as analytical chemistry and computational chemistry, as well as application to organic chemistry, catalysis, and medical chemistry, which we discuss herein.</p>
<p>AI breaks the limitations of manual feature selection methods</p>
<p>In analytical chemistry, the extraction of information has traditionally relied heavily on the feature selection techniques, which are based on prior human experiences.Unfortunately, this approach is inefficient, incomplete, and often biased.Automated data analysis based on AI will break the limitations of manual variable selection methods by learning from large amounts of data.Feature selection through DL algorithms enables information extraction from the datasets in NMR, chromatography, spectroscopy, and other analytical tools, 169, thereby improving the model prediction accuracy for analysis.These ML approaches will greatly accelerate the analysis of materials, leading to the rapid discovery of new molecules or materials.Raman scattering, for instance, since its discovery in the 1920s, has been widely employed as a powerful vibrational spectroscopy technology, capable of providing vibrational fingerprints intrinsic to analytes, thus enabling identification of molecules. 170,Recently, ML methods have been trained to recognize features in Raman (or SERS) spectra for the identity of an analyte by applying DL networks, including ANN, CNN, and fully convolutional network for feature engineering. 171,For example, Leong et al. designed a machine-learning-driven "SERS taster" to simultaneously harness useful vibrational information from multiple receptors for enhanced multiplex profiling of five wine flavor molecules at ppm levels.Principal-component analysis is employed for the discrimination of alcohols with varying degrees of substitution, and supported with vector machine discriminant analysis, is used to quantitatively classify all flavors with 100% accuracy. 172Overall, AI techniques provide the first glimmer of hope for a universal method for spectral data analysis, which is fast, accurate, objective and definitive and with attractive advantages in a wide range of applications.</p>
<p>AI improves the accuracy and efficiency for various levels of computational theory</p>
<p>Complementary to analytical tools, computational chemistry has proven a powerful approach for using simulations to understand chemical properties; however, it is faced with an accuracy-versus-efficiency dilemma.This dilemma greatly limits the application of computational chemistry to realworld chemistry problems.To overcome this dilemma, ML and other AI methods are being applied to improve the accuracy and efficiency for various levels of theory used to describe the effects arising at different time and length scales, in the multi-scaling of chemical reactions. 173,Many of the open challenges in computational chemistry can be solved by ML approaches, for example, solving Schrödinger's equation, 174, developing atomistic 175, or coarse graining 176, potentials, constructing reaction coordinates, 177, developing reaction kinetics models, 178, and identifying key descriptors for computable properties. 179In addition to analytical chemistry and computational chemistry, several disciplines of chemistry have incorporated AI technology to chemical problems.We discuss the areas of organic chemistry, catalysis, and medical chemistry as examples of where ML has made a significant impact.Many examples exist in literature for other subfields of chemistry and AI will continue to demonstrate breakthroughs in a wide range of chemical applications.</p>
<p>AI enables robotics capable of automating the synthesis of molecules</p>
<p>Organic chemistry studies the structure, property, and reaction of carbonbased molecules.The complexity of the chemical and reaction space, for a given property, presents an unlimited number of potential molecules that can be synthesized by chemists.Further complications are added when faced with the problems of how to synthesize a particular molecule, given that the process relies much on heuristics and laborious testing.Challenges have been addressed by researchers using AI.Given enough data, any</p>
<p>Review</p>
<p>The Innovation properties of interest of a molecule can be predicted by mapping the molecular structure to the corresponding property using supervised learning, without resorting to physical laws.In addition to known molecules, new molecules can be designed by sampling the chemical space 180, using methods, such as autoencoders and CNNs, with the molecules coded as sequences or graphs.Retrosynthesis, the planning of synthetic routes, which was once considered an art, has now become much simpler with the help of ML algorithms.The Chemetica system, 181, for instance, is now capable of autonomous planning of synthetic routes that are subsequently proven to work in the laboratory.Once target molecules and the route of synthesis are determined, suitable reaction conditions can be predicted or optimized using ML techniques. 182he integration of these AI-based approaches with robotics has enabled fully AI-guided robotics capable of automating the synthesis of small organic molecules without human intervention Figure 9. 183,,184 AI helps to search through vast catalyst design spaces Catalytic chemistry originates from catalyst technologies in the chemical industry for efficient and sustainable production of chemicals and fuels.Thus far, it is still a challenging endeavor to make novel heterogeneous catalysts with good performance (i.e., stable, active, and selective) because a catalyst's performance depends on many properties: composition, support, surface termination, particle size, particle morphology, atomic coordination environment, porous structure, and reactor during the reaction.The inherent complexity of catalysis makes discovering and developing catalysts with desired properties more dependent on intuition and experiment, which is costly and time consuming.AI technologies, such as ML, when combined with experimental and in silico high-throughput screening of combinatorial catalyst libraries, can aid catalyst discovery by helping to search through vast design spaces.With a well-defined structure and standardized data, including reaction results and in situ characterization results, the complex association between catalytic structure and catalytic performance will be revealed by AI. 185,,186 An accurate descriptor of the effect of molecules, molecular aggregation states, and molecular transport, on catalysts, could also be predicted.With this approach, researchers can build virtual laboratories to develop new catalysts and catalytic processes.</p>
<p>AI enables screening of chemicals in toxicology with minimum ethical concerns</p>
<p>A more complicated sub-field of chemistry is medical chemistry, which is a challenging field due to the complex interactions between the exotic substances and the inherent chemistry within a living system.Toxicology, for instance, as a broad field, seeks to predict and eliminate substances (e.g., pharmaceuticals, natural products, food products, and environmental substances), which may cause harm to a living organism.Living organisms are already complex, nearly any known substance can cause toxicity at a high enough exposure because of the already inherent complexity within living organisms.Moreover, toxicity is dependent on an array of other factors, including organism size, species, age, sex, genetics, diet, combination with other chemicals, overall health, and/or environmental context.Given the scale and complexity of toxicity problems, AI is likely to be the only realistic approach to meet regulatory body requirements for screening, prioritization, and risk assessment of chemicals (including mixtures), therefore revolutionizing the landscape in toxicology. 187In summary, AI is turning chemistry from a labor-intensive branch of science to a highly intelligent, standardized, and automated field, and much more can be achieved compared with the limitation of human labor.Underlying knowledge with new concepts, rules, and theories is expected to advance with the application of AI algorithms.A large portion of new chemistry knowledge leading to significant breakthroughs is expected to be generated from AI-based chemistry research in the decades to come.</p>
<p>CONCLUSIONS</p>
<p>This paper carries out a comprehensive survey on the development and application of AI across a broad range of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry.Despite the fact that AI has been pervasively used in a wide range of applications, there still exist ML security risks on data and ML models as attack targets during both training and execution phases.Firstly, since the performance of an ML system is highly dependent on the data used to train it, these input data are crucial for the security of the ML system.For instance, adversarial example attacks 188 providing malicious input data often lead the ML system into making false judgments (predictions or categorizations) with small perturbations that are imperceptible to humans; data poisoning by intentionally manipulating raw, training, or testing data can result in a decrease in model accuracy or lead to other error-specific attack purposes.Secondly, ML model attacks include backdoor attacks on DL, CNN, and federated learning that manipulate the model's parameters directly, as well as model stealing attack, model inversion attack, and membership inference attack, which can steal the model parameters or leak the sensitive training data.While a number of defense techniques against these security threats have been proposed, new attack models that target ML systems are constantly emerging.Thus, it is necessary to address the problem of ML security and develop robust ML systems that remain effective under malicious attacks.</p>
<p>Due to the data-driven character of the ML method, features of the training and testing data must be drawn from the same distribution, which is difficult to guarantee in practice.This is because, in practical application, the data source might be different from that in the training dataset.In addition, the data feature distribution may drift over time, which leads to a decline of the performance of the model.Moreover, if the model is trained with only new data, it will lead to catastrophic "forgetting" of the model, which means the model only remembers the new features and forgets the previously learned features.To solve this problem, more and more scholars pay attention on how to make the model have the ability of lifelong learning, that is, a change in the computing paradigm from "offline learning + online reasoning" to "online continuous learning," and thus give the model have the ability of lifelong learning, just like a human being.</p>
<p>The Innovation</p>
<p>Figure 1 .
1
Figure 1.The general framework of AI</p>
<p>Figure 2 .
2
Figure 2. The knowledge graph of the AI framework</p>
<p>Figure 3 .
3
Figure 3. AI in mathematics</p>
<p>Figure 4 .
4
Figure 4. AI in medical science</p>
<p>Figure 5 .
5
Figure 5. AI is expected to power the development of materials science</p>
<p>Figure 6 .
6
Figure 6.Applications of AI in hydraulic resource management</p>
<p>Figure 7 .
7
Figure 7. Integration of AI and remote sensing in smart agriculture</p>
<p>Figure 8 .
8
Figure 8. Scale of the physics</p>
<p>Figure 9 .
9
Figure 9.A closed loop workflow to enable automatic and intelligent design, synthesis, and assay of molecules in organic chemistry by AI</p>
<p>The Innovation 2, 100179, November 28, 2021 www.cell.com/the-innovation
The Innovation 2, 100179, November 28, 2021 www.cell.com/the-innovationThe Innovation
The Innovation 2, 100179, November 28, 2021   www.cell.com/the-innovationThe InnovationThe Innovation 2, 100179, November 28, 2021 www.cell.com/the-innovationThe InnovationACKNOWLEDGMENTSThis work was partially supported by the National Key R&amp;D Program of China (2018YFA0404603, 2019YFA0704900, 2020YFC1807000, and 2020YFB1313700), the Youth Innovation Promotion Association CAS (2011225, 2012006, 2013002, 2015316, 2016275,  2017017, 2017086, 2017120, 2017204, 2017300, 2017399, 2018356, 2020111, 2020179, Y201664, Y201822, and Y201911), NSFC (nos.11971466, 12075253, 52173241, and 61902376), the Foundation of State Key Laboratory of Particle Detection and Electronics (SKLPDE-ZZ-201902), the Program of Science &amp; Technology Service Network of CAS (KFJ-STS-QYZX-050), the Fundamental Science Center of the National Nature Science Foundation of China (nos.52088101 and 11971466), the Scientific Instrument Developing Project of CAS (ZDKYYQ20210003), the Strategic Priority Research Program (B) of CAS (XDB33000000), the National Science Foundation of Fujian Province for Distinguished Young Scholars (2019J06023), the Key Research Program of Frontier Sciences, CAS (nos.ZDBS-LY-7022 and ZDBS-LY-DQC012), the CAS Project for Young Scientists in Basic Research (no.YSBR-005).The study is dedicated to the 10th anniversary of the Youth Innovation Promotion Association of the Chinese Academy of Sciences.The Innovation AUTHOR CONTRIBUTIONS Y.X., Q.W., Z.A., Fei W., C.L., Z.C., J.M.T., and J.Z. conceived and designed the research.Z.A., Q.W., Fei W., Libo.Z., Y.W., F.D., and C.W.-Q.wrote the "AI in information science" section.Xin.L. wrote the "AI in mathematics" section.J.Q., K.H., W.S., J.W., H.X., Y.H., and X.C. wrote the "AI in medical science" section.E.L., C.F., Z.Y., and M.L. wrote the "AI in materials science" section.Fang W., R.R., S.D., M.V., and F.K. wrote the "AI in geoscience" section.C.H., Z.Z., L.Z., T.Z., J.D., J.Y., L.L., M.L., and T.H. wrote the "AI in life sciences" section.Z.L., S.Q., and T.A. wrote the "AI in physics" section.X.L., B.Z., X.H., S.C., X.L., W.Z., and J.P.L. wrote the "AI in chemistry" section.Y.X., Q.W., and Z.A. wrote the "Abstract," "introduction," "history of AI," and "conclusions" sections.DECLARATION OF INTERESTSThe authors declare no competing interests.
A Turing, Computing Machinery and Intelligence. American Association for Artificial Intelligence1995</p>
<p>P Mccorduck, Machines Who Think. 2004Second Edition (W.h.freeman &amp; Company</p>
<p>A fast learning algorithm deep belief nets. G E Hinton, S Osindero, Y.-W Teh, Neural Comput. 182006</p>
<p>Reducing the dimensionality of data with neural networks. G E Hinton, R R Salakhutdinov, Science. 3132006</p>
<p>Y Lecun, Y Bengio, G Hinton, Deep learning. 2015521</p>
<p>P M Nadkarni, L Ohno-Machado, W Chapman, Natural Language Processing: An Introduction. 201118</p>
<p>A survey on knowledge graphs: representation, acquisition, and applications. S Ji, S Pan, E Cambria, IEEE Trans. Neural Networks Learn. Syst. 2021</p>
<p>G I Parisi, R Kemker, J L Part, Continual Lifelong Learning with Neural Networks: A Review, 113 (Neural Networks). 2019</p>
<p>Tensorflow: a system for large-scale machine learning. M Abadi, P Barham, J Chen, 10.1109/TNNLS.2021.307084312th USENIX Symposium on Operating Systems Design and Implementation. 201616</p>
<p>Pytorch: an imperative style, high-performance deep learning library. A Paszke, S Gross, F Massa, Adv. Neural Inf. Process. Syst. 322019</p>
<p>Array programming with NumPy. C R Harris, K J Millman, S J Van Der Walt, Nature. 5852020</p>
<p>DianNao family: energy-efficient hardware accelerators for machine learning. Y Chen, T Chen, Z Xu, Commun. ACM. 592016</p>
<p>Evolving neural networks through augmenting topologies. K O Stanley, R Miikkulainen, Evol. Comput. 102002</p>
<p>Neural Architecture Search with Reinforcement Learning. B Zoph, Q V Le, Science of the Total Environment. 2016</p>
<p>Large-scale evolution of image classifiers. E Real, S Moore, A Selle, International Conference on Machine Learning (PMLR). 2017</p>
<p>Efficientnet: rethinking model scaling for convolutional neural networks. M Tan, Q Le, International Conference on Machine Learning (PMLR). 2019</p>
<p>INCdeep: intelligent network coding with deep reinforcement learning. Q Wang, J Liu, K Jaffrès-Runser, IEEE INFOCOM 2021-IEEE Conference on Computer Communications. IEEE2021</p>
<p>Spatiotemporal modeling and prediction in cellular networks: a big data enabled deep learning approach. J Wang, J Tang, Z Xu, IEEE INFOCOM. 2017</p>
<p>QMR: Q-learning based multi-objective optimization routing protocol for flying ad hoc networks. J Liu, Q Wang, C He, Comput. Commun. 1502020</p>
<p>Light propagation with phase discontinuities: generalized laws of reflection and refraction. N Yu, P Genevet, M A Kats, Science. 3342011</p>
<p>Multichannel-independent information encoding optical metasurfaces. F Dong, W J A M Chu, Adv. Mater. 3118049212019</p>
<p>Z Xuan, J Li, Q Liu, Artificial structural colors and applications. Innovation 2. 2019100081</p>
<p>AIl-optical machine learning using diffractive deep neural networks. X Lin, Y Rivenson, N T Yardimci, Science. 3612018</p>
<p>Finding the optical properties of plasmonic structures by image processing using a combination of convolutional neural networks and recurrent neural networks. I Sajedian, J Kim, J J M Rho, Microsyst. Nanoeng. 52019</p>
<p>Deep learning enabled inverse design in nanophotonics. S So, T Badloe, J Noh, Nanophotonics. 92020</p>
<p>Multifunctional metasurface design with a generative adversarial network. S An, B Zheng, H Tang, Adv. Opt. Mater. 92021. 2001433</p>
<p>Optimisation of colour generation from dielectric nanostructures using reinforcement learning. I Sajedian, T Badloe, J J Rho, Opt. Express. 272019</p>
<p>Deep-learning-enabled self-adaptive microwave cloak without human intervention. C Qian, B Zheng, Y Shen, Nat. Photon. 142020</p>
<p>Infrared metasurface augmented by deep learning for monitoring dynamics between all major classes of biomolecules. A John-Herpin, D Kavungal, L Altug, H J , Adv. Mater. 332021. 2006054</p>
<p>Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things. J Zhang, D J Tao, IEEE Internet Things J. 82020</p>
<p>LAMANCO: a lightweight anonymous mutual authentication scheme for N-Times computing offloading in IoT. F Wang, Y Xu, L Zhu, IEEE Internet Things J. 62018</p>
<p>Nearest neighbor pattern classification. T Cover, P J Hart, IEEE Trans. Inf. Theory. 131967</p>
<p>Support-vector networks. C Cortes, V J Vapnik, Mach. Learn. 201995</p>
<p>Y Freund, R E Schapire, Experiments with a New Boosting Algorithm (ICML). 1996</p>
<p>A logical calculus of the ideas immanent in nervous activity. W S Mcculloch, W J Pitts, Bull. Math. Biophys. 51943</p>
<p>Playing atari with deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, arXiv, 1312.56022013</p>
<p>Generative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza, Adv. Neural Inf. Process. Syst. 272014</p>
<p>Some Bayesian learning processes. E H Shuford, United States. Air force. Systems command. Electron. Syst. Division. 861963Technical documentary report</p>
<p>Approximation by superpositions of a sigmoidal function. G Cybenko, Math. Control Signals Syst. 21989</p>
<p>On the equivalence between kernel quadrature rules and random feature expansions. F Bach, J. Mach. Learn. Res. 182017</p>
<p>A priori estimates of the population risk for two-layer neural networks. M C Ew, L Wu, Commun. Math. Sci. 172019</p>
<p>On the banach spaces associated with multi-layer relu networks: Function representation, approximation theory and gradient descent dynamics. arXiv. S Wojtowytsch, 10.4208/csiam-am.20-2212020. 2007.15623</p>
<p>MgNet: a unified framework of multigrid and convolutional neural network. J He, J Xu, Sci. China Math. 622019</p>
<p>I J Goodfellow, O Vinyals, A M Saxe, arXiv, 1412.6544Qualitatively characterizing neural network optimization problems. 2014</p>
<p>The global landscape of neural networks: an overview. R Sun, D Li, S Liang, IEEE Signal. Process. Mag. 372020</p>
<p>MultiComposite nonconvex optimization for training deep neural networks. Y Cui, Z He, J.-S Pang, SIAM J. Optimization. 302020</p>
<p>W Liu, X Liu, X Chen, arXiv, 2103.16232Linearly-constrained nonsmooth optimization for training autoencoders. 2021</p>
<p>On the uniform convergence of relative frequencies of events to their probabilities. V N Vapnik, A Y Chervonenkis, Measures of Complexity. Springer2015</p>
<p>Dropout: a simple way to prevent neural networks from overfitting. N Srivastava, G Hinton, A Krizhevsky, J. Mach. Learn. Res. 152014</p>
<p>Q Sun, Y Tao, Q Du, arXiv, 1812.00174Stochastic training of residual networks: a differential equation viewpoint. 2018</p>
<p>Artificial intelligence in oncology: path to implementation. I S Chua, M Gaziel-Yablowitz, Z T Korach, Cancer Med. 102021</p>
<p>Detecting influenza epidemics using search engine query data. J Ginsberg, M H Mohebbi, R S Patel, Nature. 4572009</p>
<p>Modeling the COVID-19 outbreak in China through multi-source information fusion. Innovation 1. L Wu, L Wang, N Li, 10.1016/j.xinn.2020.1000332020100033</p>
<p>Measures undertaken in China to avoid COVID-19 infection: internet-based, cross-sectional survey study. Y Huang, Q Wu, P Wang, J. Med. Internet Res. 222020. e18718</p>
<p>Proteomic and metabolomic characterization of COVID-19 patient sera. B Shen, X Yi, Y Sun, Cell. 1822020e15</p>
<p>Optimizing prediction of response to antidepressant medications using machine learning and integrated genetic, clinical, and demographic data. D Taliaz, A Spinrad, R Barzilay, Transl. psychiatry. 112021</p>
<p>An integrated TCGA pan-cancer clinical data resource to drive high-quality survival outcome analytics. J Liu, T Lichtenberg, K A Hoadley, Cell. 1732018e411</p>
<p>Algorithm based smartphone apps to assess risk of skin cancer in adults: systematic review of diagnostic accuracy studies. K Freeman, J Dinnes, N Chuchu, BMJ. 3681272020</p>
<p>AlphaFold at CASP13. M Alquraishi, Bioinformatics. 352019</p>
<p>Deep learning enables rapid identification of potent DDR1 kinase inhibitors. A Zhavoronkov, Y A Ivanenkov, A Aliper, Nat. Biotechnol. 372019</p>
<p>Cytopathology, histopathology, and colposcopy in the management of cervical neoplasia. B H Thompson, J D Woodruff, H J Davis, Am. J. Obstet. Gynecol. 1141972</p>
<p>The artificial intelligence-assisted cytology diagnostic system in large-scale cervical cancer screening: a population-based cohort study of 0.7 million women. H Bao, X Sun, Y Zhang, Cancer Med. 92020</p>
<p>OScc: an online survival analysis web server to evaluate the prognostic value of biomarkers in cervical cancer. Q Wang, L Zhang, Z Yan, Future Oncol. 152019</p>
<p>. J Wei, X Chu, X Y Sun, Machine learning in materials science. InfoMat. 12019</p>
<p>Toward design of novel materials for organic electronics. P Friederich, A Fediai, S Kaiser, Adv. Mater. 312019. 1808256</p>
<p>Machine learning for high performance organic solar cells: current scenario and future prospects. A Mahmood, J.-L Wang, Energy Environ. Sci. 142021</p>
<p>Accelerated discovery of large electrostrains in BaTiO3-based piezoelectrics using active learning. R Yuan, Z Liu, P V Balachandran, Adv. Mater. 302018. 1702884</p>
<p>Accelerated discovery of stable leadfree hybrid organic-inorganic perovskites via machine learning. S Lu, Q Zhou, Y Ouyang, Nat. Commun. 92018</p>
<p>Computer aided design of stable and efficient OLEDs. L Paterson, F May, D Andrienko, J. Appl. Phys. 1281609012020</p>
<p>Computationally guided discovery of thermoelectric materials. P Gorai, V Stevanovi C, E S Toberer, Nat. Rev. Mater. 22017</p>
<p>Integrating computational and experimental workflows for accelerated organic materials discovery. R L Greenaway, K E Jelfs, Adv. Mater. 332021. 2004831</p>
<p>Data-driven strategies for accelerated materials design. R Pollice, G Dos Passos Gomes, M Aldeghi, Acc. Chem. Res. 542021</p>
<p>Attribute driven inverse materials design using deep learning Bayesian framework. P M Tagade, S P Adiga, S Pandian, Comput. Mater. 52019</p>
<p>Accelerating materials development via automation, machine learning, and high-performance computing. J.-P Correa-Baena, K Hippalgaonkar, J Van Duren, 20182</p>
<p>Catalogue of topological electronic materials. T Zhang, Y Jiang, Z Song, Nature. 5662019</p>
<p>A complete catalogue of high-quality topological materials. M Vergniory, L Elcoro, C Felser, Nature. 5662019</p>
<p>Comprehensive search for topological materials using symmetry indicators. F Tang, H C Po, A Vishwanath, Wan , X , Nature. 5662019</p>
<p>Topological phononic materials: computation and data. Innovation 2. X.-Q Chen, J Liu, J Li, 10.1016/j.xinn.2021.1001342021100134</p>
<p>A universal model for the formation energy prediction of inorganic compounds. Y Liang, M Chen, Y Wang, arXiv, 2108.003492021</p>
<p>Zero-field dissipationless chiral edge transport and the nature of dissipation in the quantum anomalous Hall state. C.-Z Chang, W Zhao, D Y Kim, Phys. Rev. Lett. 115572062015</p>
<p>R W Kates, W C Clark, R Corell, Sustainability science. 2001292</p>
<p>Earth science and society. F Press, Nature. 4512008</p>
<p>Geospatial sensor web: a cyber-physical infrastructure for geoscience research and application. X Zhang, N Chen, Z Chen, Earth Sci. Rev. 1852018</p>
<p>Machine learning for the geosciences: challenges and opportunities. A Karpatne, I Ebert-Uphoff, S Ravela, IEEE Trans. Knowledge Data Eng. 312018</p>
<p>Machine learning in geosciences and remote sensing. D J Lary, A H Alavi, A H Gandomi, A L Walker, Geosci. Front. 72016</p>
<p>P Imperatore, D Riccio, Geoscience and Remote Sensing: New Achievements. BoD-Books on Demand2010</p>
<p>High-resolution X-ray computed tomography in geosciences: a review of the current technology and applications. V Cnudde, M N Boone, Earth Sci. Rev. 1232013</p>
<p>Review of smartphone applications for geoscience: current status, limitations, and future perspectives. S Lee, J Suh, Y Choi, Earth Sci. Inform. 112018</p>
<p>Physically interpretable neural networks for the geosciences: applications to earth system variability. B A Toms, E A Barnes, I Ebert-Uphoff, J. Adv. Model. Earth Syst. 122020</p>
<p>Global observations of large oceanic eddies. D B Chelton, M G Schlax, R M Samelson, R A De Szoeke, 10.1029/2007GL030812Geophys. Res. Lett. 342007</p>
<p>Reconstructing time series and their uncertainty from observations with universal noise. M Sambridge, J. Geophys. Res. Solid Earth. 1212016</p>
<p>Geoscience keyphrase extraction algorithm using enhanced word embedding. Q Qiu, Z Xie, L Wu, W Li, Expert Syst. Appl. 1252019</p>
<p>Causal inference in geoscience and remote sensing from observational data. A Pérez-Suay, G Camps-Valls, IEEE Trans. Geosci. Remote Sensing. 572018</p>
<p>Urban water resource management for sustainable environment planning using artificial intelligence techniques. X Xiang, Q Li, S Khan, O I Khalaf, Environ. Impact Assess. Rev. 861065152021</p>
<p>Applying big data beyond small problems in climate research. B Kn€ Usel, M Zumwald, C Baumberger, Nat. Clim. Change. 92019</p>
<p>A review of computational intelligence techniques in coral reef-related applications. S Salcedo-Sanz, L Cuadra, M J Vermeij, Ecol. Inform. 322016</p>
<p>Tackling climate change with machine learning. D Rolnick, P L Donti, L H Kaack, 2019. 19065433arXiv</p>
<p>Applied artificial intelligence and trustthe case of autonomous vehicles and medical assistance devices. M Hengstler, E Enkel, S Duelli, Technol. Forecast. Soc. Change. 1052016</p>
<p>The carbon impact of artificial intelligence. P Dhar, Nat. Mach. Intell. 22020</p>
<p>Charting the Complex Relationships Among Energy, Water, and Carbon. 2018Lawrence Livermore National Laboratory</p>
<p>AI-guided reasoning-based operator support system for the nuclear power plant management. B Hanna, T C Son, N Dinh, Ann. Nucl. Energy. 1541080792021</p>
<p>Modeling and application of wind-solar energy hybrid power generation system based on multi-agent technology. J Chang, S.-Y Jia, 2009 International Conference on Machine Learning and Cybernetics. IEEE20093</p>
<p>Artificial intelligence: the next digital frontier?. J Bughin, E Hazan, S Ramaswamy, 2017Information Security and Communications Privacy</p>
<p>J Wei, S Sanborn, A Slaughter, Digital Innovation. Creating the Utility of the Future. 2019</p>
<p>The emergence and evolution of earth system science. W Steffen, K Richardson, J Rockström, Nat. Rev. Earth Environ. 12020</p>
<p>Towards Brain-Inspired Artificial Intelligence. M.-M Poo, 2018Oxford University Press</p>
<p>Neuroscienceinspired artificial intelligence. D Hassabis, D Kumaran, C Summerfield, M Botvinick, Neuron. 952017</p>
<p>Using goal-driven deep learning models to understand sensory cortex. D L Yamins, J J Dicarlo, Nat. Neurosci. 192016</p>
<p>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. D H Hubel, T N Wiesel, J. Physiol. 1601962</p>
<p>Multiple object recognition with visual attention. J Ba, V Mnih, K Kavukcuoglu, arXiv, 1412.77552014</p>
<p>Temporal difference models and reward-related learning in the human brain. J P O'doherty, P Dayan, K Friston, Neuron. 382003</p>
<p>China brain project: basic neuroscience, brain diseases, and brain-inspired computing. M Poo, -M, J.-L Du, N Y Ip, Neuron. 922016</p>
<p>Promises and challenges of big data computing in health sciences. T Huang, L Lan, X Fang, Big Data Res. 22015</p>
<p>Deep learning: new computational modelling techniques for genomics. G Eraslan, Z Avsec, J Gagneur, F J Theis, Nat. Rev. Genet. 202019</p>
<p>Deep learning of genomic variation and regulatory network data. A Telenti, C Lippert, P.-C Chang, M Depristo, Hum. Mol. Genet. 272018</p>
<p>SIFT: predicting amino acid changes that affect protein function. P C Ng, S Henikoff, Nucleic Acids Res. 312003</p>
<p>SySAP: a system-level predictor of deleterious single amino acid polymorphisms. T Huang, C Wang, G Zhang, Protein Cell. 32012</p>
<p>Predicting the clinical impact of human mutation with deep neural networks. L Sundaram, H Gao, S R Padigepati, Nat. Genet. 502018</p>
<p>Copy number variation pattern for discriminating MACROD2 states of colorectal cancer subtypes. S Zhang, X Pan, T Zeng, Front. Bioeng. Biotechnol. 74072019</p>
<p>Identification of the copy number variant biomarkers for breast cancer subtypes. X Pan, X Hu, Y.-H Zhang, Mol. Genet. Genomics. 2942019</p>
<p>DeepCNV: a deep learning approach for authenticating copy number variations. J T Glessner, X Hou, C Zhong, Brief. Bioinform. 223812021</p>
<p>RNA m6A modification in cancers: molecular mechanisms and potential clinical applications. Innovation 1. C Gu, X Shi, C Dai, 10.1016/j.xinn.2020.1000662020100066</p>
<p>EDLm6APred: ensemble deep learning approach for mRNA m6A site prediction. L Zhang, G Li, X Li, BMC Bioinformatics. 222021</p>
<p>DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning. C Angermueller, H J Lee, W Reik, O Stegle, Genome Biol. 182017</p>
<p>DeepPep: deep proteome inference from peptide profiles. M Kim, A Eetemadi, I Tagkopoulos, PLoS Comput. Biol. 13e10056612017</p>
<p>Deep learning-based enhancement of epigenomics data with AtacWorks. A Lal, Z D Chiang, N Yakovenko, Nat. Commun. 122021</p>
<p>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires. J.-W Sidhom, H B Larman, D M Pardoll, A S Baras, Nat. Commun. 122021</p>
<p>DeepImpute: an accurate, fast, and scalable deep neural network method to impute single-cell RNA-seq data. C Arisdakessian, O Poirion, B Yunits, Genome Biol. 202019</p>
<p>Solo: doublet identification in singlecell RNA-Seq via semi-supervised deep learning. N J Bernstein, N L Fong, I Lam, Cell Syst. 11e1052020</p>
<p>Generative modeling of singlecell time series with PRESCIENT enables prediction of cell trajectories with interventions. G H T Yeo, S D Saksena, D K Gifford, Nat. Commun. 122021</p>
<p>Highly accurate protein structure prediction for the human proteome. K Tunyasuvunakool, J Adler, Z Wu, Nature. 5962021</p>
<p>On the ultimate finishing line of the Human Genome Project. Innovation 2. Y Jun, H Songnian, 10.1016/j.xinn.2021.1001332021100133</p>
<p>Opinion: smart farming is key to developing sustainable agriculture. A Walter, R Finger, R Huber, N Buchmann, Proc. Natl. Acad. Sci. U S A. 1142017</p>
<p>Deep learning in environmental remote sensing: achievements and challenges. Q Yuan, H Shen, T Li, 2020Remote Sensing Environ. 241, 111716</p>
<p>Deep learning for plant genomics and crop improvement. H Wang, E Cimen, N Singh, E Buckler, Curr. Opin. Plant Biol. 542020</p>
<p>MCRiceRepGP: a framework for the identification of genes associated with sexual reproduction in rice. A A Golicz, P L Bhalla, M B Singh, Plant J. 962018</p>
<p>Harnessing current knowledge of DNA N6-methyladenosine from model plants for non-model crops. S Chachar, J Liu, P Zhang, 10.3389/fgene.2021.668317Front. Genet. 122021</p>
<p>Multi-trait, multi-environment deep learning modeling for genomic-enabled prediction of plant traits. O A Montesinos-López, A Montesinos-López, J Crossa, Bethesda). 32018</p>
<p>New deep learning genomic-based prediction model for multiple traits with binary, ordinal, and continuous phenotypes. O A Montesinos-López, J Martín-Vallejo, J Crossa, G3 (Bethesda). 92019</p>
<p>Advances in remote sensing of agriculture: context description, existing operational monitoring systems and major information needs. C Atzberger, 20135Remote Sensing</p>
<p>Twenty five years of remote sensing in precision agriculture: key advances and remaining knowledge gaps. D J Mulla, Biosyst. Eng. 1142013</p>
<p>Deep learning and process understanding for data-driven Earth system science. M Reichstein, G Camps-Valls, B Stevens, Nature. 5662019</p>
<p>Applications of deep learning for dense scenes analysis in agriculture: a review. Q Zhang, Y Liu, C Gong, Sensors. 2015202020</p>
<p>Tomato fruit detection and counting in greenhouses using deep learning. M Afonso, H Fonteijn, F S Fiorentin, Front. Plant Sci. 1117592020</p>
<p>Image analysis-based recognition and quantification of grain number per panicle in rice. W Wu, T Liu, P Zhou, Plant Methods. 152019</p>
<p>Plant disease detection and classification by deep learning. M H Saleem, J Potgieter, K M Arif, 20198468</p>
<p>S Foreman, X.-Y Jin, J C Osborn, arXiv, 2105.03418Deep learning Hamiltonian Monte Carlo. 2021</p>
<p>Equivariant flow-based sampling for lattice gauge theory. G Kanwar, M S Albergo, D Boyda, Phys. Rev. Lett. 1251216012020</p>
<p>Path integral contour deformations for observables in S U (N) gauge theory. W Detmold, G Kanwar, H Lamm, Phys. Rev. D. 103945172021</p>
<p>Machine-learning prediction for quasiparton distribution function matrix elements. R Zhang, Z Fan, R Li, Phys. Rev. D. 101345162020</p>
<p>Particle identification using artificial neural networks at BES. L.-L Wang, S.-P Wen, L.-H Wu, 10.1088/1674-1137/32/1/001Chin. Phys. C. 322008</p>
<p>Observation of ttH production. A M Sirunyan, A Tumasyan, W Adam, Phys. Rev. Lett. 1202318012018</p>
<p>Application of quantum machine learning using the quantum kernel algorithm on high energy physics analysis at the LHC. S L Wu, S Sun, W Guan, 10.1103/PhysRevResearch.3.033221arXiv2021</p>
<p>Pilot study of eruption forecasting with muography using convolutional neural network. Y Nomura, M Nemoto, N Hayashi, Sci. Rep. 102020</p>
<p>Understanding phase equilibria and segregation in Bridgman growth of Cs2LiYCl6 scintillator. F L Ruta, S Swider, S Lam, R S Feigelson, J. Mater. Res. 322017</p>
<p>Machine learning the Hubbard U parameter in DFT+ U using Bayesian optimization. M Yu, S Yang, C Wu, N Marom, Comput. Mater. 62020</p>
<p>Gaussian approximation potentials: the accuracy of quantum mechanics, without the electrons. A P Bartók, M C Payne, R Kondor, G Csányi, Phys. Rev. Lett. 1041364032010</p>
<p>On representing chemical environments. A P Bartók, R Kondor, G Csányi, Phys. Rev. B. 871841152013</p>
<p>Artificial intelligence for celestial object census: the latest technology meets the oldest science. B Lao, T An, A Wang, Sci. Bull. 662021</p>
<p>Radio Galaxy Zoo: CLARAN-a deep learning classifier for radio morphologies. C Wu, O I Wong, L Rudnick, MNRAS. 4822019</p>
<p>Galaxy zoo: exploring the motivations of citizen science volunteers. M J Raddick, G Bracey, P L Gay, Astron. Educ. Rev. 9101032010</p>
<p>Deep neural networks to enable real-time multimessenger astrophysics. D George, E Huerta, Phys. Rev. D. 97440392018</p>
<p>T L Brown, H E Lemay, B E Bursten, L S Brunauer, Chemistry: The Central Science. Prentice Hall1997Thirteenth Edition</p>
<p>. Cas Registry, 2021</p>
<p>Exploration of the chemical space and its three historical regimes. E J Llanos, W Leal, D H Luu, Proc. Natl. Acad. Sci. U S A. 1162019</p>
<p>Chapter 14 the reaction space. 10.1016/S0922-3487(08)70261-2S0922-3487(08) 70261-2Data Handling in Science and Technology. R Carlson, Ed , Elsevier1992</p>
<p>More is different. P W Anderson, Science. 1771972</p>
<p>Taking the leap between analytical chemistry and artificial intelligence: a tutorial review. L B Ayres, F J Gomez, J R Linton, Anal. Chim. Acta. 11613384032021</p>
<p>Surface enhanced Raman scattering revealed by interfacial charge-transfer transitions. Innovation 1. S Cong, X Liu, Y Jiang, 10.1016/j.xinn.2020.1000512020100051</p>
<p>Deep learning networks for the recognition and quantitation of surface-enhanced Raman spectroscopy. S Weng, H Yuan, X Zhang, Analyst. 1452020</p>
<p>Surface-enhanced Raman scattering (SERS) taster: a machine-learning-driven multireceptor platform for multiplex profiling of wine flavors. Y X Leong, Y H Lee, C S L Koh, Nano Lett. 212021</p>
<p>Perspective on integrating machine learning into computational chemistry and materials science. J Westermayr, M Gastegger, K T Sch€ Utt, R J Maurer, J. Chem. Phys. 1542309032021</p>
<p>Deep-neural-network solution of the electronic Schrödinger equation. J Hermann, Z Sch€ Atzle, F Noé, Nat. Chem. 122020</p>
<p>Machine learning force fields. O T Unke, S Chmiela, H E Sauceda, Chem. Rev. 1212021</p>
<p>Machine learning of coarse-grained molecular dynamics force fields. J Wang, S Olsson, C Wehmeyer, ACS Cent. Sci. 52019</p>
<p>A machine-driven hunt for global reaction coordinates of azobenzene photoisomerization. P Tavadze, G Avendaneo Franco, P Ren, J. Am. Chem. Soc. 1402018</p>
<p>Artificial intelligence in the modeling of chemical reactions kinetics. M Staszak, Theoretical and Computational Chemistry. De Gruyter2021</p>
<p>A graph-convolutional neural network model for the prediction of chemical reactivity. C W Coley, W Jin, L Rogers, Chem. Sci. 102019</p>
<p>Exploring chemical compound space with quantum-based machine learning. O A Von Lilienfeld, K.-R M€ Uller, A Tkatchenko, Nat. Rev. Chem. 42020</p>
<p>Chematica: a story of computer code that started to think like a chemist. B A Grzybowski, S Szymku C, E P Gajewska, 20184</p>
<p>Using machine learning to predict suitable conditions for organic reactions. H Gao, T J Struble, C W Coley, ACS Cent. Sci. 42018</p>
<p>A robotic platform for flow synthesis of organic compounds informed by AI planning. C W Coley, D A Thomas, J A Lummiss, Science. 3652019. eaax1566</p>
<p>Organic synthesis in a modular robotic system driven by a chemical programming language. S Steiner, J Wolf, S Glatzel, Science. 36322112019</p>
<p>A mobile robotic chemist. B Burger, P M Maffettone, V V Gusev, Nature. 5832020</p>
<p>Enabling catalyst discovery through machine learning and high-throughput experimentation. T Williams, K Mccullough, J A Lauterbach, Chem. Mater. 322019</p>
<p>Machine learning in predictive toxicology: recent applications and future directions for classification models. M W Wang, J M Goodman, T E Allen, Chem. Res. Toxicol. 342020</p>
<p>C Szegedy, W Zaremba, I Sutskever, arXiv, 1312.6199Intriguing properties of neural networks. 2013</p>            </div>
        </div>

    </div>
</body>
</html>