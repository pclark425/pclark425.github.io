<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5733 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5733</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5733</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-34f721457b92155a5f5ccaf5201c1a9f0f6f99be</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/34f721457b92155a5f5ccaf5201c1a9f0f6f99be" target="_blank">An Assessment of ChatGPT on Log Data</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> The findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues.</p>
                <p><strong>Paper Abstract:</strong> Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5733.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5733.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (OpenAI gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors used the gpt-3.5-turbo ChatGPT model (snapshot March 2023) in a prompt-based, zero-shot fashion to analyze system logs and to attempt anomaly detection over sequences of raw log messages.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An Assessment of ChatGPT on Log Data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer-based large language model from OpenAI (GPT-3.5 family) accessed via the ChatGPT API; trained on large internet text corpora and used here via prompts (no fine-tuning). The authors used a snapshot of gpt-3.5-turbo from March 2023.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Prompt-based, zero-shot anomaly detection: raw/semi-structured log messages (up to ~190–200 entries per prompt) were appended to a natural-language prompt ('Detect the anomalies...') and the model was asked to list/analyze anomalies; no fine-tuning or supervised training was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential system logs (unstructured / semi-structured text log lines from Loghub benchmark).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic/operational anomalies and security-related anomalies (examples in paper: repeated authentication failures, multiple failures from same IP, abnormal process exit / 'ALERT exited abnormally with [1]'). In general the model flags suspicious or abnormal log events rather than numeric outlier scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Loghub benchmark (Loghub) [34] (200 log entries appended in anomaly experiment).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No quantitative anomaly-detection metrics (e.g., precision/recall/F1/AUROC) were reported. Evaluation was qualitative: the paper shows example outputs (Fig. 9) where ChatGPT identifies several authentication failures and an abnormal 'logrotate' exit. The authors report that ChatGPT 'tries' to identify anomalies but do not provide systematic accuracy numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>No direct empirical comparison to traditional anomaly detection methods or established baselines is reported for the anomaly-detection experiment. The paper discusses traditional and deep-learning log-analysis work in related work but does not benchmark ChatGPT against them for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported limitations include: need for context (anomaly detection requires contextual understanding), inconsistent responses, lack of quantitative evaluation, scalability/token limits (authors could only append ~190–200 log messages per prompt), high latency as input size grows, and zero-shot setup may underperform compared to tuned/few-shot approaches. The paper notes ChatGPT 'tries' to identify anomalies but performance is limited and not systematically measured; potential failure cases include missed anomalies, inconsistent detection across runs, and inability to handle large continuous streams due to token and latency limits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Assessment of ChatGPT on Log Data', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5733.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5733.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pre-trained LMs for log representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pre-trained language models used to represent log data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites prior work that leverages pre-trained language models to represent log messages for downstream tasks (e.g., analytic tasks including anomaly detection), but notes those approaches generally require fine-tuning or training on labeled data and so may be impractical due to compute and labeling costs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified pre-trained language models (general reference)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generic reference to pre-trained language models used in literature to create representations of log text; details (architecture, size) are not specified in this paper. The authors note such approaches exist in recent studies.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Representation learning followed by task-specific training/tuning (the paper states these approaches either train models from scratch or fine-tune pre-trained LMs with labeled data), not prompt-based in the cited descriptions within the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log messages / system logs (textual sequences); representations are used for downstream detection/classification tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Not explicitly specified in this paper for these methods; generally used for log-analytics tasks including anomaly detection, error identification, and root-cause analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>The paper does not report metrics for these referenced methods in this work; it only comments qualitatively that they require training or tuning and may be impractical due to compute/labeled-data requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>No comparisons are provided in this paper between pre-trained-LM-based methods and traditional anomaly detection approaches; the authors only comment that prior methods require training/tuning which can be a practical obstacle.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes that pre-trained-LM-based methods typically require either training from scratch or fine-tuning with labeled data, which may be impractical because of computing-resource and labeled-data constraints; no empirical failure cases are presented here for those methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Assessment of ChatGPT on Log Data', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning <em>(Rating: 2)</em></li>
                <li>Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs. <em>(Rating: 2)</em></li>
                <li>Log-Based Anomaly Detection without Log Parsing <em>(Rating: 2)</em></li>
                <li>Robust Log-Based Anomaly Detection on Unstable Log Data <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5733",
    "paper_id": "paper-34f721457b92155a5f5ccaf5201c1a9f0f6f99be",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "ChatGPT (gpt-3.5-turbo)",
            "name_full": "ChatGPT (OpenAI gpt-3.5-turbo)",
            "brief_description": "The authors used the gpt-3.5-turbo ChatGPT model (snapshot March 2023) in a prompt-based, zero-shot fashion to analyze system logs and to attempt anomaly detection over sequences of raw log messages.",
            "citation_title": "An Assessment of ChatGPT on Log Data",
            "mention_or_use": "use",
            "model_name": "gpt-3.5-turbo (ChatGPT)",
            "model_description": "A transformer-based large language model from OpenAI (GPT-3.5 family) accessed via the ChatGPT API; trained on large internet text corpora and used here via prompts (no fine-tuning). The authors used a snapshot of gpt-3.5-turbo from March 2023.",
            "model_size": null,
            "anomaly_detection_method": "Prompt-based, zero-shot anomaly detection: raw/semi-structured log messages (up to ~190–200 entries per prompt) were appended to a natural-language prompt ('Detect the anomalies...') and the model was asked to list/analyze anomalies; no fine-tuning or supervised training was performed.",
            "data_type": "Sequential system logs (unstructured / semi-structured text log lines from Loghub benchmark).",
            "anomaly_type": "Semantic/operational anomalies and security-related anomalies (examples in paper: repeated authentication failures, multiple failures from same IP, abnormal process exit / 'ALERT exited abnormally with [1]'). In general the model flags suspicious or abnormal log events rather than numeric outlier scoring.",
            "dataset_name": "Loghub benchmark (Loghub) [34] (200 log entries appended in anomaly experiment).",
            "performance_metrics": "No quantitative anomaly-detection metrics (e.g., precision/recall/F1/AUROC) were reported. Evaluation was qualitative: the paper shows example outputs (Fig. 9) where ChatGPT identifies several authentication failures and an abnormal 'logrotate' exit. The authors report that ChatGPT 'tries' to identify anomalies but do not provide systematic accuracy numbers.",
            "baseline_comparison": "No direct empirical comparison to traditional anomaly detection methods or established baselines is reported for the anomaly-detection experiment. The paper discusses traditional and deep-learning log-analysis work in related work but does not benchmark ChatGPT against them for anomaly detection.",
            "limitations_or_failure_cases": "Reported limitations include: need for context (anomaly detection requires contextual understanding), inconsistent responses, lack of quantitative evaluation, scalability/token limits (authors could only append ~190–200 log messages per prompt), high latency as input size grows, and zero-shot setup may underperform compared to tuned/few-shot approaches. The paper notes ChatGPT 'tries' to identify anomalies but performance is limited and not systematically measured; potential failure cases include missed anomalies, inconsistent detection across runs, and inability to handle large continuous streams due to token and latency limits.",
            "uuid": "e5733.0",
            "source_info": {
                "paper_title": "An Assessment of ChatGPT on Log Data",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Pre-trained LMs for log representation",
            "name_full": "Pre-trained language models used to represent log data",
            "brief_description": "The paper cites prior work that leverages pre-trained language models to represent log messages for downstream tasks (e.g., analytic tasks including anomaly detection), but notes those approaches generally require fine-tuning or training on labeled data and so may be impractical due to compute and labeling costs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified pre-trained language models (general reference)",
            "model_description": "Generic reference to pre-trained language models used in literature to create representations of log text; details (architecture, size) are not specified in this paper. The authors note such approaches exist in recent studies.",
            "model_size": null,
            "anomaly_detection_method": "Representation learning followed by task-specific training/tuning (the paper states these approaches either train models from scratch or fine-tune pre-trained LMs with labeled data), not prompt-based in the cited descriptions within the paper.",
            "data_type": "Log messages / system logs (textual sequences); representations are used for downstream detection/classification tasks.",
            "anomaly_type": "Not explicitly specified in this paper for these methods; generally used for log-analytics tasks including anomaly detection, error identification, and root-cause analysis.",
            "dataset_name": null,
            "performance_metrics": "The paper does not report metrics for these referenced methods in this work; it only comments qualitatively that they require training or tuning and may be impractical due to compute/labeled-data requirements.",
            "baseline_comparison": "No comparisons are provided in this paper between pre-trained-LM-based methods and traditional anomaly detection approaches; the authors only comment that prior methods require training/tuning which can be a practical obstacle.",
            "limitations_or_failure_cases": "Paper notes that pre-trained-LM-based methods typically require either training from scratch or fine-tuning with labeled data, which may be impractical because of computing-resource and labeled-data constraints; no empirical failure cases are presented here for those methods.",
            "uuid": "e5733.1",
            "source_info": {
                "paper_title": "An Assessment of ChatGPT on Log Data",
                "publication_date_yy_mm": "2023-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning",
            "rating": 2
        },
        {
            "paper_title": "Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs.",
            "rating": 2
        },
        {
            "paper_title": "Log-Based Anomaly Detection without Log Parsing",
            "rating": 2
        },
        {
            "paper_title": "Robust Log-Based Anomaly Detection on Unstable Log Data",
            "rating": 1
        }
    ],
    "cost": 0.011263249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>An Assessment of ChatGPT on Log Data</h1>
<p>Priyanka Mudgal<em> and Rita Wouhaybi</em><br>Intel Corporation, Hillsboro OR 97124, USA,<br><em>priyanka.mudgal@intel.com,<br></em>rita.h.wouhaybi@intel.com</p>
<h4>Abstract</h4>
<p>Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues.</p>
<p>Keywords: log data, log analysis, log processing, ChatGPT, log analysis using LLM, large language model, deep learning, machine learning</p>
<h2>1 Introduction</h2>
<p>In recent years, the emergence of generative AI and large language models (LLMs) such as OpenAI's ChatGPT have led to significant advancements in NLP. Many of these models provide the ability to be fine-tuned on custom datasets [1], [2], [3] and achieve the state-of-the-art (SOTA) performance across various tasks. A few of the LLMs such as GPT-3 [4] have demonstrated in-context-learning capability without requiring any fine-tuning on task-specific data. The impressive performance of ChatGPT and other LLMs [81|5|6|7|8|9] in zero-shot and few-shot learning scenarios is a major finding as this helps LLMs to be more efficient [80|79|78|77|76]. With such learning methodologies, the LLMs can be used as a service [10] to empower a set of new real-world applications.</p>
<p>Despite the impressive capability of ChatGPT in performing a wide range of challenging tasks, there remain some major concerns about it in solving realworld problems like log analysis [95]. Log analysis is a vast area, and much</p>
<p>research has been done. It mainly comprises three major categories, namely, log parsing, log analytics, and log summarization. Log parsing is an important initial step of system diagnostic tasks. Through log parsing, the raw log messages are converted into a structured format while extracting the template [14|13|12|11]. Log analytics can be used to identify the system events and dynamic runtime information, which can help the subject matter experts to understand system behavior and perform system diagnostic tasks, such as anomaly detection [18|17|16|15], log classification [19], error prediction [21|20], and root cause analysis [22|23]. Log analytics can further be used to perform advanced operations e.g., identify user activities, and security analysis e.g., detect loggedin users, API/service calls, malicious URLs, etc. As logs are huge in volume, log summarization enables the operators to provide a gist of the overall activities in logs and empowers the subject matter experts to read and/or understand logs faster. Recent studies leverage pre-trained language models [17|25|24] for representing log data. However, these methods still require either training the models from scratch [26] or tuning a pre-trained language model with labeled data [17|24], which could be impractical due to the lack of computing resources and labeled data.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: An example of log code, log message, and structured log from [34]</p>
<p>More recently, LLMs such as ChatGPT [95] have been applied to a variety of software engineering tasks and achieved satisfactory performance [27|28]. With a lack of studies to analyze ChatGPT's capabilities on log processing, it is unclear whether it can be performed well on the logs. Although many papers have performed the evaluation of ChatGPT on software engineering tasks [29|30|33], specific research is required to investigate its capabilities in system log area. We are aware that the LLMs are fast evolving, with new models, versions, and tools being released frequently, and each one is improved over the previous ones. However, our goal is to assess the current situation and to provide a set of experiments that can enable the researchers to identify possible shortcomings of the current version for analyzing logs and provide a variety of specific tasks to measure the improvement of future versions. Hence, in this paper, we conduct an initial level of evaluation of ChatGPT on log data. Specifically, we divide</p>
<p>the log processing [32] into three subsections: log parsing, log analytics, and log summarization. We design appropriate prompts for each of these tasks and analyze ChatGPT's capabilities in these areas. Our analysis shows that ChatGPT achieves promising results in some areas, but limited outcomes in others and contains several real-world challenges in terms of scalability. In summary, the major contributions of our work are as follows:</p>
<ul>
<li>To the best of our knowledge, we are the first to study and analyze ChatGPT's ability to analyze the log data in multiple detailed aspects.</li>
<li>We design the prompts for multiple scenarios in log processing and record ChatGPT's response.</li>
<li>Based on the findings, we outline several challenges and prospects for ChatGPT-based log processing.</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: left;">Prompt 1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">You will be provided with a log message. Please extract the log template and</td>
</tr>
<tr>
<td style="text-align: left;">variables from this log message:</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
<tr>
<td style="text-align: left;">Prompt 3</td>
</tr>
<tr>
<td style="text-align: left;">Summarize the errors and warning from these log messages and identify the root</td>
</tr>
<tr>
<td style="text-align: left;">cause:</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
<tr>
<td style="text-align: left;">Prompt 5</td>
</tr>
<tr>
<td style="text-align: left;">Detect the anomalies from the following log messages.</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
<tr>
<td style="text-align: left;">Prompt 7</td>
</tr>
<tr>
<td style="text-align: left;">Summarize the log message.</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">Prompt 2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Show the APIs called most with count from these log messages:</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
<tr>
<td style="text-align: left;">Prompt 4</td>
</tr>
<tr>
<td style="text-align: left;">Act there any malicious users, urls, ips, and connection status from these log</td>
</tr>
<tr>
<td style="text-align: left;">messages?</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
<tr>
<td style="text-align: left;">Prompt 6</td>
</tr>
<tr>
<td style="text-align: left;">Predict the next 10 log events based on these log messages.</td>
</tr>
<tr>
<td style="text-align: left;">$\left[\right.$ LUG]</td>
</tr>
</tbody>
</table>
<p>Fig. 2: Various prompt designs to address the research questions.</p>
<h1>2 Related Work</h1>
<h3>2.1 Log data</h3>
<p>With the increasing scale of software systems, it is complex to manage and maintain them. To tackle this challenge, engineers enhance the system observability $[31,101]$ with logs.</p>
<p>Logs capture multiple system run-time information such as events, transactions, and messages. A typical piece of log message is a time-stamped record that captures the activity that happened over time (e.g., software update events or received messages). Logs are usually generated when a system executes the corresponding logging code snippets. An example of the code snippet and generated code is shown in Fig. 1. A system with mature logs essentially facilitates the system behavior understanding, health monitoring, failure diagnosis, etc. Generally, there are three standard log formats, i.e., structured, semi-structured, and</p>
<p>unstructured logs [74]. These formats share the same components: a timestamp and a payload content.</p>
<p>Structured logs usually keep a consistent format within the log data and are easy to manage. Specifically, the well-structured format allows easy storing, indexing, searching, and aggregation in a relational database. The unstructured log data achieves its high flexibility at the expense of the ease of machine processing. The characteristic of free-form text becomes a major obstacle for efficient query and analysis on unstructured or semi-structured logs. For instance, to count how often an API version appears in unstructured logs, engineers need to design a complex query with ad-hoc regular expressions to extract the desired information. The manual process takes lots of time and effort and is not scalable.</p>
<h1>2.2 Log Processing</h1>
<p>Logs have been widely adopted in software system development and maintenance. In industry, it is a common practice to record detailed software runtime information into logs, allowing developers and support engineers to track system behaviors and perform postmortem analysis. On a high level, log processing can be categorized in three types as discussed below.</p>
<p>Log Parsing Log parsing is generally the first step toward automated log analytics. It aims at parsing each log message into a specific log event/template and extracting the corresponding parameters. Although there are many traditional regular expression-based log parsers, but, they require a predefined knowledge about the log template. To achieve better performance in comparison to traditional log parsers, many data-driven [41|42|40|39|38|37|12] and deep learning based approaches [24|26] have been proposed to automatically distinguish template and parameter parts.</p>
<p>Log Analytics Modern software development and operations rely on log monitoring to understand how systems behave in production. There is an increasing trend to adopt artificial intelligence to automate operations. Gartner [99] refers to this movement as AIOps. The research community, including practitioners, has been actively working to address the challenges related to extracting insights from log data also being referred to as "Log Analysis" [98]. Various insights that can be gained are in terms of log mining [87], error detection and root cause analysis, security and privacy, anomaly detection, and event prediction.</p>
<p>Log Mining Log mining seeks to support understanding and analysis utilizing abstraction and extracting useful insights. However, building such models is a challenging and expensive task. In our study, we confine ourselves to posing specific questions in terms of most API/service calls that can be extracted out of raw log messages. This area is well studied from a deep learning aspect and most of those approaches [50|56|53|57|51|54|55|52] require to first parse the logs and then process them to extract the detailed level of knowledge.</p>
<p>Error Detection and Root Cause Analysis Automatic error detection from logs is an important part of monitoring solutions. Maintainers need to investigate what caused that unexpected behavior. Several studies 494847464443] attempt to provide their useful contribution to root cause analysis, accurate error identification, and impact analysis.</p>
<p>Security and Privacy Logs can be leveraged for security purposes, such as malicious behaviour and attack detection, URLs, and IP detection, logged-in user detection, etc. Several researchers have worked towards detecting earlystage malware and advanced persistence threat infections to identify malicious activities based on log data 5862596061.</p>
<p>Anomaly Detection Anomaly detection techniques addresses to identify the anomalous or undesired patterns in logs. The manual analysis of logs is time-consuming, error-prone, and unfeasible in many cases. Researchers have been trying several different techniques for automated anomaly detection, such as deep learning [66634465] and data mining, statistical learning methods, and machine learning 73727170696867.</p>
<p>Event Prediction The knowledge about the correlation of multiple events, when combined to predict the critical or interesting event is useful in preventive maintenance or predictive analytics that can reduce the unexpected system downtime and result in cost saving 848283 . Thus, the event prediction method is highly valuable in real-time applications. In recent years, many rule-based and deep learning based approaches 949392919085 have evolved and performing significantly.</p>
<p>Log Summarization Log statements are inserted in the source code to capture normal and abnormal behaviors. However, with the growing volume of logs, it becomes a time-consuming task to summarize the logs. There are multiple deep learning-based approaches 459810019] that perform the summarization, but they require time and compute resources for training the models.</p>
<h1>2.3 ChatGPT</h1>
<p>ChatGPT is a large language model which is developed by OpenAI 9596. ChatGPT is trained on a huge dataset containing massive amount of internet text. It offeres the capability to generate text responses in natural language that are based on a wide range of topics. The fundamental of ChatGPT is generative pre-training transformer (GPT) architecture. GPT architecture is highly effective for natural language processing tasks such as translation in multiple languages, summarization, and question answering ( $\mathrm{Q} \&amp; \mathrm{~A}$ ). It offers the capability to be fine-tuned on specific tasks with a smaller dataset with specific examples. ChatGPT can be adopted in a variety of use cases including chatbots, language translation, and language understanding. It is a powerful tool and possesses the potential to be used across wide range of industries and applications.</p>
<h1>2.4 ChatGPT Evaluation</h1>
<p>Several recent works on ChatGPT evaluation have been done, but most of the papers target the evaluations on general tasks [75,33], code generation [27], deep learning-based program repair [28], benchmark datasets from various domains [29], software modeling tasks [30], information extraction [89], sentiment analysis of social media and research papers [86] or even assessment of evaluation methods [88]. The closest to our work is [35], but they focus only on log parsing.</p>
<p>We believe that the log processing area is huge and a large-level evaluation of ChatGPT on log data would be useful for the research community. Hence, in our work, we focus on evaluating ChatGPT by conducting an in-depth and wider analysis of log data in terms of log parsing, log analytics, and log summarization.</p>
<h2>3 Context</h2>
<p>In this paper, our primary focus is to assess the capability of ChatGPT on log data. In line with this, we aim to answer several research questions through experimental evaluation.</p>
<h3>3.1 Research Questions</h3>
<p>Log Parsing RQ1. How does ChatGPT perform on log parsing?</p>
<p>Log Analytics RQ2. Can ChatGPT extract the errors and identify the root cause from raw log messages?</p>
<p>RQ3. How does ChatGPT perform on advanced analytics tasks e.g., most called APIs/services?</p>
<p>RQ4. Can ChatGPT be used to extract security information from log messages?</p>
<p>RQ5. Is ChatGPT able to detect anomalies from log data?
RQ6. Can ChatGPT predict the next events based on previous log messages?</p>
<p>Log Summarization RQ7. Can ChatGPT summarize a single raw log messages?</p>
<p>RQ8. Can ChatGPT summarize multiple log messages?</p>
<p>General RQ9. Can ChatGPT process bulk log messages?
RQ10. What length of log messages can ChatGPT process at once?
To examine the effectiveness of ChatGPT in answering the research questions, we design specific prompts as shown in Fig 2. We append the log messages in each of the prompts (in place of the slot ' $[\mathrm{LOG}]^{\prime}$ ').</p>
<h1>3.2 Dataset</h1>
<p>To perform our experiments, we use the datasets provided from the Loghub benchmark [13|34]. This benchmark covers log data from various systems, including, windows and linux operating systems, distributed systems, mobile systems, server applications, and standalone software. Each system dataset contains 2,000 manually labeled and raw log messages.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 3: Flow Diagram.</p>
<h3>3.3 Experimental Setup</h3>
<p>For our experiments, we are using the ChatGPT API based on the gpt-3.5turbo model to generate the responses for different prompts [95]. As shown in Fig. 3, we send the prompts appended with log messages to ChatGPT from our system with Intel ${ }^{\circledR}$ Xeon ${ }^{\circledR}$ E3-1200 v5 processor and Intel ${ }^{\circledR}$ Xeon ${ }^{\circledR}$ E3-1500 v5 processor and receive the response. To avoid bias from model updates, we use a snapshot of gpt3.5-turbo from March 2023 [97].</p>
<h3>3.4 Evaluation Metrics</h3>
<p>As our study demands a detailed evaluation and in some cases, there was no state-of-the-art tool, we evaluated the output by our manual evaluation.</p>
<h2>4 Experiments and Results</h2>
<p>Each of the subsections below describes the individual evaluation of ChatGPT in different areas of log processing.</p>
<h3>4.1 Log Parsing</h3>
<p>In this experiment, we assess the capability of ChatGPT in parsing a raw log message and a preprocessed log message and find the answer to RQ1. For the first experiment, we provide a single raw log message from each of the sixteen publicly available datasets [34] and ask ChatGPT to extract the log template. We refer to it as first-level log parsing. ChatGPT performs well in extracting the specific parts of log messages for all sixteen log messages. One of the examples of ChatGPT's response for first-level log parsing is shown in Fig. 4. Next, we</p>
<div class="codehilite"><pre><span></span><code><span class="n">Prompt</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">provided</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="n">message</span><span class="o">.</span><span class="w"> </span><span class="n">Please</span><span class="w"> </span><span class="n">extract</span><span class="w"> </span><span class="n">the</span>
<span class="n">log</span><span class="w"> </span><span class="n">template</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">variables</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="k">this</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="n">message</span><span class="o">:</span>
<span class="mi">03</span><span class="o">-</span><span class="mi">17</span><span class="w"> </span><span class="mi">16</span><span class="o">:</span><span class="mi">13</span><span class="o">:</span><span class="mf">38.819</span><span class="w"> </span><span class="mi">1702</span><span class="w"> </span><span class="mi">8671</span><span class="w"> </span><span class="n">D</span><span class="w"> </span><span class="n">PowerManagerService</span><span class="o">:</span><span class="w"> </span><span class="n">acquire</span>
<span class="n">lock</span><span class="o">=</span><span class="mi">233570404</span><span class="o">,</span><span class="w"> </span><span class="n">flags</span><span class="o">=</span><span class="mh">0x1</span><span class="o">,</span><span class="w"> </span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;View Lock&quot;</span><span class="o">,</span><span class="w"> </span><span class="n">name</span><span class="o">=</span><span class="n">com</span><span class="o">.</span><span class="na">android</span><span class="o">.</span><span class="na">systemui</span><span class="o">,</span>
<span class="n">ws</span><span class="o">=</span><span class="kc">null</span><span class="o">,</span><span class="w"> </span><span class="n">uid</span><span class="o">=</span><span class="mi">10037</span><span class="o">,</span><span class="w"> </span><span class="n">pid</span><span class="o">=</span><span class="mi">2227</span>
<span class="n">ChatGPT</span><span class="w"> </span><span class="n">Response</span><span class="o">:</span>
<span class="n">Log</span><span class="w"> </span><span class="n">Template</span><span class="o">:</span><span class="w"> </span><span class="o">{</span><span class="n">timestamp</span><span class="o">}</span><span class="w"> </span><span class="o">{</span><span class="n">process_id</span><span class="o">}</span><span class="w"> </span><span class="o">{</span><span class="n">thread_id</span><span class="o">}</span><span class="w"> </span><span class="o">{</span><span class="n">log_level</span><span class="o">}</span><span class="w"> </span><span class="o">{</span><span class="n">tag</span><span class="o">}:</span>
<span class="o">{</span><span class="n">message</span><span class="o">}</span>
<span class="n">Variables</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">timestamp</span><span class="o">:</span><span class="w"> </span><span class="mi">03</span><span class="o">-</span><span class="mi">17</span><span class="w"> </span><span class="mi">16</span><span class="o">:</span><span class="mi">13</span><span class="o">:</span><span class="mf">38.819</span>
<span class="o">-</span><span class="w"> </span><span class="n">process_id</span><span class="o">:</span><span class="w"> </span><span class="mi">1702</span>
<span class="o">-</span><span class="w"> </span><span class="n">thread_id</span><span class="o">:</span><span class="w"> </span><span class="mi">8671</span>
<span class="o">-</span><span class="w"> </span><span class="n">log_level</span><span class="o">:</span><span class="w"> </span><span class="n">D</span>
<span class="o">-</span><span class="w"> </span><span class="n">tag</span><span class="o">:</span><span class="w"> </span><span class="n">PowerManagerService</span>
<span class="o">-</span><span class="w"> </span><span class="n">message</span><span class="o">:</span><span class="w"> </span><span class="n">acquire</span><span class="w"> </span><span class="n">lock</span><span class="o">=</span><span class="mi">233570404</span><span class="o">,</span><span class="w"> </span><span class="n">flags</span><span class="o">=</span><span class="mh">0x1</span><span class="o">,</span><span class="w"> </span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;View Lock&quot;</span><span class="o">,</span>
<span class="w">    </span><span class="n">name</span><span class="o">=</span><span class="n">com</span><span class="o">.</span><span class="na">android</span><span class="o">.</span><span class="na">systemui</span><span class="o">,</span><span class="w"> </span><span class="n">ws</span><span class="o">=</span><span class="kc">null</span><span class="o">,</span><span class="w"> </span><span class="n">uid</span><span class="o">=</span><span class="mi">10037</span><span class="o">,</span><span class="w"> </span><span class="n">pid</span><span class="o">=</span><span class="mi">2227</span>
</code></pre></div>

<p>Fig. 4: Log parsing of raw log message.
preprocess the log message, extract the content, and ask chatGPT to further extract the template from the log message. ChatGPT can extract the template and variables from the log message successfully on all sixteen log messages with a simple prompt. One of the examples of ChatGPT's response is shown in Fig. 5 .</p>
<h1>4.2 Log Analytics</h1>
<p>To evaluate ChatGPT's capability in log analytics, we perform several experiments in each of the categories described in section 2.2 .</p>
<p>Log Mining In this experiment, we are seeking the answer of RQ2 by investigating if ChatGPT can skim out the knowledge from raw logs without building an explicit parsing pipeline. We perform our experiments in several parts. We provide a subset of log messages containing 5, 10, 20, and 50 log messages from Loghub benchmark [34] and ask ChatGPT to identify the APIs. Fig 6 shows an example of ChatGPT response when a smaller set of log messages were passed. We notice that ChatGPT consistently missed identifying some APIs from the log messages irrespective of the count of log messages, but still shows $75 \%$ or more accuracy in all cases. Results are reported in Table 1.</p>
<h1>Prompt: You will be provided with a log message. Please extract the log template and variables from this log message:</h1>
<p>PowerManagerService: acquire lock=233570404, flags=0x1, tag="View Lock", ChatGPT Response:</p>
<p>Log Template: PowerManagerService: acquire lock={lock}, flags={flags}, tag $=$ " ${\mathrm{tag}}$ ", name $={$ name $}, \mathrm{ws}={\mathrm{ws}}$, uid $={\mathrm{uid}}, \mathrm{pid}={\mathrm{pid}}$
Variables:</p>
<ul>
<li>lock: 233570404</li>
<li>flags: $0 \times 1$</li>
<li>tag: "View Lock"</li>
<li>name: com.android.systemui</li>
<li>ws: null</li>
<li>uid: 10037</li>
<li>pid: 2227</li>
</ul>
<p>Fig. 5: Log parsing of preprocessed log message.
Table 1: ChatGPT's performance to identify the APIs, errors and root cause from Loghub dataset [34].</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Log <br> Message <br> Count</th>
<th style="text-align: center;">API <br> Count</th>
<th style="text-align: center;">API <br> captured</th>
<th style="text-align: center;">API <br> Accuracy (\%)</th>
<th style="text-align: center;">API <br> Response <br> Time (s)</th>
<th style="text-align: center;">Error <br> Count</th>
<th style="text-align: center;">Error <br> captured</th>
<th style="text-align: center;">Error <br> Accuracy <br> (\%)</th>
<th style="text-align: center;">Error <br> Response <br> time (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">2.48</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">18.49</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">3.96</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">27.61</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">6.44</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;">36.38</td>
</tr>
<tr>
<td style="text-align: center;">50</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">46</td>
<td style="text-align: center;">92</td>
<td style="text-align: center;">5.66</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">38.46</td>
<td style="text-align: center;">46.46</td>
</tr>
</tbody>
</table>
<p>Error Detection and Root Cause Analysis In this experiment, we explicitly ask ChatGPT [97] to identify the errors, warnings, and possible root causes of those in the provided log messages and address RQ3. Aligning towards our study structure, we first provide five log messages from the Loghub dataset [34] and later increase the size of log messages to ten, twenty, and fifty. Fig 7 shows the identified errors from five log messages and a detailed report for all the combinations with their response time is being reported in Table 1. It is evident from Table 1 that ChatGPT successfully identifies the errors and warnings on a smaller set of log messages than a larger set.</p>
<p>Security and privacy In this experiment, we focus on addressing RQ4 and investigate if ChatGPT can identify the URLs, IPs, and logged users from the logs and extract knowledge about malicious activities. We use the open source dataset from Loghub [102] and follow the same approach of sending the set of</p>
<h1>Prompt: Show the APIs called most with count from these log messages:</h1>
<p>03-17 16:13:46.671 170217633 I NotificationManager:
onNotificationVisibilityChanged called
03-17 16:13:46.672 22272318 I PhoneStatusBar:
logNotificationVisibilityChanges runInThread over
03-17 16:13:46.764 22272794 E KeyguardUpdateMonitor: isSimPinSecure mSimDatas is null or empty
03-17 16:13:46.765 22272794 W KeyguardUpdateMonitor: registerCallback</p>
<h2>ChatGPT Response:</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">API Name</th>
<th style="text-align: left;">Count</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">NotificationManager</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">PhoneStatusBar</td>
<td style="text-align: left;">1</td>
</tr>
<tr>
<td style="text-align: left;">KeyguardUpdateMonitor</td>
<td style="text-align: left;">2</td>
</tr>
</tbody>
</table>
<p>Fig. 6: ChatGPT response to extract the APIs from log messages.
five, ten, twenty, and fifty log messages to chatGPT to detect the URLs, IPs, and users from them. We use the 'Prompt 4' from Fig. 2 to ask if there are any malicious activities present in the logs. As shown in Table 2, ChatGPT extracts out the IPs and logged-in users with high accuracy irrespective of the length of log messages. An example of ChatGPT's response is shown in Fig. 8. The detailed report is shown in Table. 2.
Table 2: ChatGPT performance to extract urls, IPs, and users from the log messages from Loghub dataset [34].</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Log <br> Message <br> Count</th>
<th style="text-align: center;">URLs <br> Count</th>
<th style="text-align: center;">URLs <br> captured</th>
<th style="text-align: center;">URL <br> Accuracy <br> $(\%)$</th>
<th style="text-align: center;">User <br> Count</th>
<th style="text-align: center;">User <br> captured</th>
<th style="text-align: center;">User <br> Accuracy <br> $(\%)$</th>
<th style="text-align: center;">Response <br> time (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">13.77</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">46.41</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">112.14</td>
</tr>
<tr>
<td style="text-align: center;">50</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">83.33</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">87.5</td>
<td style="text-align: center;">163.76</td>
</tr>
</tbody>
</table>
<h2>Anomaly Detection</h2>
<p>To evaluate ChatGPT's capability to detect anomalies in logs and to address RQ5, we use 'Prompt 5' from Fig. 2. As detecting anomalies through log messages would require context, we append 200 log message entries and ask ChatGPT to detect anomalies from it. Without showing any examples to ChatGPT of how an anomaly might look like, it still tries to identify the possible anomalies and provide its analysis in the end. One of the examples is shown in Fig. 9.</p>
<h2>Event Prediction</h2>
<p>It is interesting to evaluate ChatGPT's performance in predicting future events in log messages. Typically, for future event prediction, a context of past</p>
<h1>Prompt: Summarize the errors and warning from these log messages and identify the root cause.</h1>
<p>[Sun Dec 04 04:52:49 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 04:52:49 2005] [notice] workerEnv.init() ok /etc/httpd/conf/workers2.properties
[Sun Dec 04 04:52:52 2005] [error] mod_jk child workerEnv in error state 7</p>
<h2>ChatGPT Response:</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Date</th>
<th style="text-align: left;">Log Message</th>
<th style="text-align: left;">Tag</th>
<th style="text-align: left;">Root Cause</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Sun Dec 04 <br> 04:52:49 2005</td>
<td style="text-align: left;">workerEnv.init() ok <br> /etc/httpd/conf/workers2.properties</td>
<td style="text-align: left;">Notice</td>
<td style="text-align: left;">N/A</td>
</tr>
<tr>
<td style="text-align: left;">Sun Dec 04 <br> 04:52:52 2005</td>
<td style="text-align: left;">workerEnv.init() ok <br> /etc/httpd/conf/workers2.properties</td>
<td style="text-align: left;">Notice</td>
<td style="text-align: left;">N/A</td>
</tr>
<tr>
<td style="text-align: left;">Sun Dec 04 <br> 04:52:52 2005</td>
<td style="text-align: left;">mod_jk child workerEnv in error <br> state 7</td>
<td style="text-align: left;">Error</td>
<td style="text-align: left;">Issue with child <br> workerEnv</td>
</tr>
<tr>
<td style="text-align: left;">Sun Dec 04 <br> 04:52:52 2005</td>
<td style="text-align: left;">mod_jk child workerEnv in error <br> state 6</td>
<td style="text-align: left;">Error</td>
<td style="text-align: left;">Issue with child <br> workerEnv</td>
</tr>
<tr>
<td style="text-align: left;">Sun Dec 04 <br> 04:53:05 2005</td>
<td style="text-align: left;">jk2_init() Found child 6750 in <br> scoreboard slot 7</td>
<td style="text-align: left;">Notice</td>
<td style="text-align: left;">N/A</td>
</tr>
</tbody>
</table>
<p>Root Cause: There is an issue with the child workerEnv which is causing it to be in an error state (state 7 or state 6).</p>
<p>Fig. 7: ChatGPT response to identify the errors and root cause from set of 5 log messages from Loghub dataset [34].
event is required, hence, we append 200 log messages to 'Prompt 6' from Fig. 2 and ask ChatGPT to predict the next 10 messages for simplicity. This experiment addresses the RQ6. While ChatGPT predicts the next 10 events in log format, it fails to predict even a single log message correctly when compared with the ground truth. ChatGPT's response is shown in Fig. 10.</p>
<h3>4.3 Log Summarization</h3>
<p>This experiment is designed to understand if ChatGPT could succinctly summarize logs. We perform this study in two steps. First, To address the RQ7, we provide a single log message from each of the sixteen datasets of opensource benchmark [34] to ChatGPT to understand its mechanics. This is useful to understand the log message in natural language. Fig. 11 shows one of the log messages from the Android subset of the Loghub dataset [34] and ChatGPT response. It is evident from the response that ChatGPT provides a detailed explanation of the log message. Next, to address the RQ8, we provide a set of ten log messages from each of the sixteen subsets of the Loghub dataset [34] to ChatGPT and ask to</p>
<h1>Prompt: Are there any malicious users, urls, ips, and connection status from these log messages.</h1>
<p>Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 14 15:16:02 combo sshd(pam_unix)[19937]: check pass; user unknown Jun 14 15:16:02 combo sshd(pam_unix)[19937]: authentication failure;</p>
<h2>ChatGPT Response:</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Date</th>
<th style="text-align: left;">Time</th>
<th style="text-align: left;">User</th>
<th style="text-align: left;">IP</th>
<th style="text-align: left;">Connection Status</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Jun 14</td>
<td style="text-align: left;">$15: 16: 01$</td>
<td style="text-align: left;">Unknown</td>
<td style="text-align: left;">218.188 .2 .4</td>
<td style="text-align: left;">Authentication Failure</td>
</tr>
<tr>
<td style="text-align: left;">Jun 14</td>
<td style="text-align: left;">$15: 16: 02$</td>
<td style="text-align: left;">Unknown</td>
<td style="text-align: left;">218.188 .2 .4</td>
<td style="text-align: left;">Authentication Failure</td>
</tr>
<tr>
<td style="text-align: left;">Jun 15</td>
<td style="text-align: left;">$02: 04: 59$</td>
<td style="text-align: left;">root</td>
<td style="text-align: left;">220.135 .151 .1</td>
<td style="text-align: left;">Authentication Failure</td>
</tr>
<tr>
<td style="text-align: left;">Jun 15</td>
<td style="text-align: left;">$02: 04: 59$</td>
<td style="text-align: left;">root</td>
<td style="text-align: left;">220.135 .151 .1</td>
<td style="text-align: left;">Authentication Failure</td>
</tr>
<tr>
<td style="text-align: left;">Based on the log messages provided, there are no indicators of malicious <br> activities. However, the repeated authentication failures from different IP <br> addresses may suggest potential unauthorized access attempts. It is <br> recommended to monitor and investigate any further unusual activities.</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Fig. 8: ChatGPT response to extract urls, IPs, and users from set of 5 log messages from Loghub dataset [102].
summarize the logs. ChatGPT generates a concrete summary collectively from the provided log messages as shown in Fig. 12. In Fig. 12, we only show a few log messages for visual clarity. ChatGPT generates an understandable summary for all the sixteen subsets.</p>
<h2>5 Discussion</h2>
<p>Based on our study, we highlight a few challenges and prospects for ChatGPT on log data analysis.</p>
<h3>5.1 Handling unstructured $\log$ data</h3>
<p>For our experiments, we send the unstructured raw log messages to ChatGPT to analyze its capabilities on various log-specific tasks. Our study indicates that ChatGPT shows promising performance in processing the raw log messages. It is excellent in log parsing and identifying security and privacy information, but encounters difficulty in case of API detection, event prediction, and summarizing. It misses out on several APIs and events from raw log messages.</p>
<h1>Prompt: Detect the anomalies from the following log messages.</h1>
<p>Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 14 15:16:02 combo sshd(pam_unix)[19937]: check pass; user unknown Jun 14 15:16:02 combo sshd(pam_unix)[19937]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 15 02:04:59 combo sshd(pam_unix)[20882]: authentication failure;</p>
<h2>ChatGPT Response:</h2>
<p>Anomalies detected in the log messages are as follows:
Jun 15 04:06:20 combo logrotate: ALERT exited abnormally with [1] This indicates an abnormal exit of logrotate process.</p>
<p>Jun 15 12:12:34 combo sshd(pam_unix)[23397]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 15 12:12:34 combo sshd(pam_unix)[23395]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</p>
<p>These log messages indicate multiple authentication failures from the same IP address (rhost). This could signify a security threat or unauthorized access attempts.</p>
<p>Fig. 9: ChatGPT response for anomaly detection for a sample from Loghub dataset $[34]$.</p>
<h3>5.2 Performance with zero-shot learning</h3>
<p>We perform our experiments with zero-shot learning. Our experimental results show that ChatGPT exhibits good performance in the areas of log parsing, security, and privacy, and average performance in the case of API detection, incident detection, and root cause identification. As ChatGPT supports few-shot learning, it remains an important future work to select important guidelines to set effective examples and evaluate ChatGPT's performance with them.</p>
<h3>5.3 Scalability - Message Cap For GPT</h3>
<p>Most of the intelligent knowledge extraction from logs depends on processing a large amount of the logs in a short period. As ChatGPT 3.5 can only process limited tokens at once, it poses a major limitation in feeding the bigger chunk of log data. For our experiments, we could only send 190 to 200 log messages appended (addressing RQ9 and RQ10) with the appropriate prompt at once. As most of</p>
<h1>Prompt: Predict the next 10 log events based on these log messages.</h1>
<p>Jun 14 15:16:01 combo sshd(pam_unix)[19939]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 14 15:16:02 combo sshd(pam_unix)[19937]: check pass; user unknown Jun 14 15:16:02 combo sshd(pam_unix)[19937]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$ Jun 15 02:04:59 combo sshd(pam_unix)[20882]: authentication failure; logname $=$ uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=220-135-151-1$.hinetip.hinet.net user $=$ root</p>
<h2>ChatGPT Response:</h2>
<p>Based on the given log messages, the next 10 log events could be:</p>
<ol>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28324]: check pass; user unknown</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28324]: authentication failure; logname= uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28322]: check pass; user unknown</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28322]: authentication failure; logname= uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28329]: check pass; user unknown</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28329]: authentication failure; logname= uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28325]: check pass; user unknown</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28325]: authentication failure; logname= uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</li>
<li>Jun 17 04:08:47 combo sshd(pam_unix)[28328]: check pass; user unknown
10.Jun 17 04:08:47 combo sshd(pam_unix)[28328]: authentication failure; logname= uid $=0$ euid $=0$ tty $=$ NODEVssh ruser $=$ rhost $=218.188 .2 .4$</li>
</ol>
<p>Fig. 10: ChatGPT response for event prediction from Loghub dataset [34].
the real-time applications would require to continuously send larger chunks of log messages to a system for processing, this limitation of ChatGPT 3.5 may pose a major hindrance in terms of scalability making them less suitable for tasks that require up-to-date knowledge or rapid adaptation to changing contexts. With the newer versions of ChatGPT, the number of tokens may be increased which would make it more suitable for its application in the log processing area.</p>
<h3>5.4 Latency</h3>
<p>The response time of ChatGPT ranges from a few seconds to minutes when the number of log messages is increased in the prompt. The details about response time are shown in Table 1 and 2. Most of the intelligent knowledge extraction from logs depends on the processing time of the large amount of the logs. With the current state of response time, ChatGPT would face a major challenge in real-time applications, where a response is required in a shorter period. As currently, we have to call openAI API to get ChatGPT's response, with the newer</p>
<div class="codehilite"><pre><span></span><code><span class="n">Prompt</span><span class="o">:</span><span class="w"> </span><span class="n">Summarize</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="n">message</span><span class="o">.</span>
<span class="n">PowerManagerService</span><span class="o">:</span><span class="w"> </span><span class="n">acquire</span><span class="w"> </span><span class="n">lock</span><span class="o">=</span><span class="mi">233570404</span><span class="o">,</span><span class="w"> </span><span class="n">flags</span><span class="o">=</span><span class="mh">0x1</span><span class="o">,</span><span class="w"> </span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;View Lock&quot;</span><span class="o">,</span>
<span class="n">name</span><span class="o">=</span><span class="n">com</span><span class="o">.</span><span class="na">android</span><span class="o">.</span><span class="na">systemui</span><span class="o">,</span><span class="w"> </span><span class="n">ws</span><span class="o">=</span><span class="kc">null</span><span class="o">,</span><span class="w"> </span><span class="n">uid</span><span class="o">=</span><span class="mi">10037</span><span class="o">,</span><span class="w"> </span><span class="n">pid</span><span class="o">=</span><span class="mi">2227</span>
<span class="n">ChatGPT</span><span class="w"> </span><span class="n">Response</span><span class="o">:</span>
<span class="n">On</span><span class="w"> </span><span class="n">March</span><span class="w"> </span><span class="mi">17</span><span class="n">th</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="mi">16</span><span class="o">:</span><span class="mi">13</span><span class="o">:</span><span class="mf">38.819</span><span class="o">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">PowerManagerService</span><span class="w"> </span><span class="n">acquired</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lock</span><span class="w"> </span><span class="k">with</span>
<span class="n">certain</span><span class="w"> </span><span class="n">flags</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">attributes</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">tag</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="k">this</span><span class="w"> </span><span class="n">lock</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="s2">&quot;View Lock&quot;</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">it</span>
<span class="n">belonged</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="kd">package</span><span class="w"> </span><span class="s2">&quot;com.android.systemui&quot;</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">lock</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">associated</span><span class="w"> </span><span class="k">with</span>
<span class="n">a</span><span class="w"> </span><span class="n">specific</span><span class="w"> </span><span class="n">process</span><span class="w"> </span><span class="n">ID</span><span class="w"> </span><span class="o">(</span><span class="n">PID</span><span class="o">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">user</span><span class="w"> </span><span class="n">ID</span><span class="w"> </span><span class="o">(</span><span class="n">UID</span><span class="o">).</span>
</code></pre></div>

<p>Fig. 11: Summary generated by ChatGPT for single log message from Loghub dataset [34].
versions of ChatGPT, it may be possible to deploy these models close to applications and reduce the latency significantly.</p>
<h1>5.5 Privacy</h1>
<p>Log data often contains sensitive information that requires protection. It is crucial to ensure that log data is stored and processed securely to safeguard sensitive information. It is also important to consider appropriate measures to mitigate any potential risks.</p>
<h2>6 Conclusion</h2>
<p>This paper presents the first evaluation to give a comprehensive overview of ChatGPT's capability on log data from three major areas: log parsing, log analytics and log summarization. We have designed specific prompts for ChatGPT to reveal its capabilities in the area of log processing. Our evaluations reveal that the current state of ChatGPT exhibits excellent performance in the areas of log parsing, but poses certain limitations in other areas i.e., API detection, anomaly detection, log summarization, etc. We identify several grand challenges and opportunities that future research should address to improve the current capabilities of ChatGPT.</p>
<h2>7 Disclaimer</h2>
<p>The goal of this paper is mainly to summarize and discuss existing evaluation efforts on ChatGPT along with some limitations. The only intention is to foster a better understanding of the existing framework. Additionally, due to the swift</p>
<h1>Prompt: Summarize the log messages.</h1>
<p>03-17 16:13:38.811 17022395 D WindowManager: printFreezingDisplayLogsopening app wtoken = AppWindowToken{9f4ef63 token=Token{a64f992 ActivityRecord{de9231d u0 com.tencent.qt.qtl/.activity.info.NewsDetailXmlActivity t761}}), allDrawn= false, startingDisplayed $=$ false, startingMoved $=$ false, isRelaunching $=$ false 03-17 16:13:38.819 17028671 D PowerManagerService: acquire lock=233570404, flags $=0 \times 1$, tag="View Lock", name=com.android.systemui, ws=null, uid=10037, pid=2227 03-17 16:13:38.820 17028671 D PowerManagerService: ready=true, policy=3,wakefulness=1,wksummary=0x23,uasummary=0x1,bootcompleted= true,boostinprogress=false,waitmodeenable=false,mode=false,manual=38,auto=-</p>
<h2>ChatGPT Response:</h2>
<p>The log message shows various activities and operations happening in the system. These include the opening of an app window token, acquisition of a lock by the PowerManagerService, and manipulation of TextView visibility.</p>
<p>Fig. 12: Collective summary generated by ChatGPT for ten log messages from Loghub dataset [34].
evolution of LLMs especially ChatGPT, they would likely become more robust, and some of their limitations described in this paper are remediated. We encourage interested readers to take this survey as a reference for future research and conduct real experiments in current systems when performing evaluations. Finally, with continuous evaluation of LLMs, we may miss some new papers or benchmarks. We welcome all constructive feedback and suggestions to help make this evaluation better.</p>
<h2>References</h2>
<ol>
<li>Wang, A., Singh, A., Michael, J., Hill, F., Levy, O. \&amp; Bowman, S. GLUE: A MultiTask Benchmark and Analysis Platform for Natural Language Understanding. Proceedings Of The 2018 EMNLP Workshop BlackboxNLP: Analyzing And Interpreting Neural Networks For NLP. pp. 353-355 (2018,11), https://aclanthology.org/W185446</li>
<li>Wang, B. Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX.</li>
<li>Wang, B. \&amp; Komatsuzaki, A. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.</li>
<li>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I. \&amp; Amodei, D. Language Models are Few-Shot Learners. (2020)</li>
<li>
<p>Tay, Y., Dehghani, M., Tran, V., Garcia, X., Wei, J., Wang, X., Chung, H., Shakeri, S., Bahri, D., Schuster, T., Zheng, H., Zhou, D., Houlsby, N. \&amp; Metzler, D. UL2: Unifying Language Learning Paradigms. (2023)</p>
</li>
<li>
<p>Thoppilan, R., Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H., Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J., Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhao, V., Zhou, Y., Chang, C., Krivokon, I., Rusch, W., Pickett, M., Srinivasan, P., Man, L., Meier-Hellstern, K., Morris, M., Doshi, T., Santos, R., Duke, T., Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson, B., Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R., Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R., Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E. \&amp; Le, Q. LaMDA: Language Models for Dialog Applications. (2022)</p>
</li>
<li>Fedus, W., Zoph, B. \&amp; Shazeer, N. Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity. (2022)</li>
<li>Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Las Casas, D., Hendricks, L., Welbl, J., Clark, A., Hennigan, T., Noland, E., Millican, K., Driessche, G., Damoc, B., Guy, A., Osindero, S., Simonyan, K., Elsen, E., Rae, J., Vinyals, O. \&amp; Sifre, L. Training Compute-Optimal Large Language Models. (2022)</li>
<li>Zeng, A., Liu, X., Du, Z., Wang, Z., Lai, H., Ding, M., Yang, Z., Xu, Y., Zheng, W., Xia, X., Tam, W., Ma, Z., Xue, Y., Zhai, J., Chen, W., Zhang, P., Dong, Y. \&amp; Tang, J. GLM-130B: An Open Bilingual Pre-trained Model. (2022)</li>
<li>Sun, T., Shao, Y., Qian, H., Huang, X. \&amp; Qiu, X. Black-Box Tuning for Language-Model-as-a-Service. (2022)</li>
<li>Du, M. \&amp; Li, F. Spell: Streaming Parsing of System Event Logs. 2016 IEEE 16th International Conference On Data Mining (ICDM). pp. 859-864 (2016), https://api.semanticscholar.org/CorpusID:206784678</li>
<li>He, P., Zhu, J., Zheng, Z. \&amp; Lyu, M. Drain: An Online Log Parsing Approach with Fixed Depth Tree. 2017 IEEE International Conference On Web Services (ICWS). pp. 33-40 (2017)</li>
<li>Zhu, J., He, S., Liu, J., He, P., Xie, Q., Zheng, Z. \&amp; Lyu, M. Tools and Benchmarks for Automated Log Parsing. (2019)</li>
<li>Khan, Z., Shin, D., Bianculli, D. \&amp; Briand, L. Guidelines for Assessing the Accuracy of Log Message Template Identification Techniques. Proceedings Of The 44th International Conference On Software Engineering. pp. 1095-1106 (2022), https://doi.org/10.1145/3510003.3510101</li>
<li>Du, M., Li, F., Zheng, G. \&amp; Srikumar, V. DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning. Proceedings Of The 2017 ACM SIGSAC Conference On Computer And Communications Security. pp. 1285-1298 (2017), https://doi.org/10.1145/3133956.3134015</li>
<li>Zhang, X., Xu, Y., Lin, Q., Qiao, B., Zhang, H., Dang, Y., Xie, C., Yang, X., Cheng, Q., Li, Z., Chen, J., He, X., Yao, R., Lou, J., Chintalapati, M., Shen, F. \&amp; Zhang, D. Robust Log-Based Anomaly Detection on Unstable Log Data. Proceedings Of The 2019 27th ACM Joint Meeting On European Software Engineering Conference And Symposium On The Foundations Of Software Engineering. pp. 807-817 (2019), https://doi.org/10.1145/3338906.3338931</li>
<li>Le, V. \&amp; Zhang, H. Log-Based Anomaly Detection without Log Parsing. Proceedings Of The 36th IEEE/ACM International Conference On Automated Software Engineering. pp. 492-504 (2022), https://doi.org/10.1109/ASE51524.2021.9678773</li>
<li>
<p>Zhang, B., Zhang, H., Le, V., Moscato, P. \&amp; Zhang, A. Semi-Supervised and Unsupervised Anomaly Detection by Mining Numerical Workflow Relations from System Logs. Automated Software Engg.. 30 (2022,12), https://doi.org/10.1007/s10515-022-00370-w</p>
</li>
<li>
<p>Ramachandran, S., Agrahari, R., Mudgal, P., Bhilwaria, H., Long, G. \&amp; Kumar, A. Automated Log Classification Using Deep Learning. Procedia Computer Science. 218 pp. 1722-1732 (2023), https://www.sciencedirect.com/science/article/pii/S1877050923001503, International Conference on Machine Learning and Data Engineering</p>
</li>
<li>Das, A., Mueller, F., Siegel, C. \&amp; Vishnu, A. Desh: Deep Learning for System Health Prediction of Lead Times to Failure in HPC. Proceedings Of The 27th International Symposium On High-Performance Parallel And Distributed Computing. pp. 40-51 (2018), https://doi.org/10.1145/3208040.3208051</li>
<li>Russo, B., Succi, G. \&amp; Pedrycz, W. Mining system logs to learn error predictors: a case study of a telemetry system. Empirical Software Engineering. 20 pp. 879-927 (2015), https://api.semanticscholar.org/CorpusID:19032755</li>
<li>Gurumdimma, N., Jhumka, A., Liakata, M., Chuah, E. \&amp; Browne, J. CRUDE: Combining Resource Usage Data and Error Logs for Accurate Error Detection in Large-Scale Distributed Systems. 2016 IEEE 35th Symposium On Reliable Distributed Systems (SRDS). pp. 51-60 (2016)</li>
<li>Lu, S., Rao, B., Wei, X., Tak, B., Wang, L. \&amp; Wang, L. Log-based Abnormal Task Detection and Root Cause Analysis for Spark. 2017 IEEE International Conference On Web Services (ICWS). pp. 389-396 (2017)</li>
<li>Le, V. \&amp; Zhang, H. Log Parsing with Prompt-based Few-shot Learning. (2023)</li>
<li>Tao, S., Meng, W., Chen, Y., Zhu, Y., Du, Y., Han, T., Zhao, Y., Wang, X. \&amp; Yang, H. LogStamp: Automatic Online Log Parsing Based on Sequence Labelling. (2022)</li>
<li>Liu, Y., Zhang, X., He, S., Zhang, H., Li, L., Kang, Y., Xu, Y., Ma, M., Lin, Q., Dang, Y., Rajmohan, S. \&amp; Zhang, D. UniParser: A Unified Log Parser for Heterogeneous Log Data. Proceedings Of The ACM Web Conference 2022. (2022,4), https://doi.org/10.1145</li>
<li>Feng, Y., Vanam, S., Cherukupally, M., Zheng, W., Qiu, M. \&amp; Chen, H. Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data. 2023 IEEE 47th Annual Computers, Software, And Applications Conference (COMPSAC). pp. 876-885 (2023)</li>
<li>Cao, J., Li, M., Wen, M. \&amp; Shing-Cheung A study on Prompt Design, Advantages and Limitations of ChatGPT for Deep Learning Program Repair. (2023)</li>
<li>Laskar, M., Bari, M., Rahman, M., Bhuiyan, M., Joty, S. \&amp; Huang, J. A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (2023)</li>
<li>Cámara, J., Troya, J., Burgueño, L. \&amp; Vallecillo, A. On the Assessment of Generative AI in Modeling Tasks: An Experience Report with ChatGPT and UML. Softw. Syst. Model.. 22, 781-793 (2023,5), https://doi.org/10.1007/s10270-023-01105-5</li>
<li>Sridharan, C. Distributed Systems Observability: : A Guide to Building Robust Systems. (O'Reilly Media, Inc.,2018)</li>
<li>He, S., Zhang, X., He, P., Xu, Y., Li, L., Kang, Y., Ma, M., Wei, Y., Dang, Y., Rajmohan, S. \&amp; Others An empirical study of log analysis at Microsoft. Proceedings Of The 30th ACM Joint European Software Engineering Conference And Symposium On The Foundations Of Software Engineering. pp. 1465-1476 (2022)</li>
<li>Sridhara, G., G., R. \&amp; Mazumdar, S. ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks. (2023)</li>
<li>He, S., Zhu, J., He, P. \&amp; Lyu, M. Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics. (2020)</li>
<li>
<p>Le, V. \&amp; Zhang, H. An Evaluation of Log Parsing with ChatGPT. (2023)</p>
</li>
<li>
<p>Fu, Q., Lou, J., Wang, Y. \&amp; Li, J. Execution Anomaly Detection in Distributed Systems through Unstructured Log Analysis. 2009 Ninth IEEE International Conference On Data Mining. pp. 149-158 (2009)</p>
</li>
<li>Tang, L., Li, T. \&amp; Perng, C. LogSig: Generating System Events from Raw Textual Logs. Proceedings Of The 20th ACM International Conference On Information And Knowledge Management. pp. 785-794 (2011), https://doi.org/10.1145/2063576.2063690</li>
<li>Shima, K. Length Matters: Clustering System Log Messages using Length of Words. ArXiv. abs/1611.03213 (2016), https://api.semanticscholar.org/CorpusID:16326353</li>
<li>Dai, H., Li, H., Shang, W., Chen, T. \&amp; Chen, C. Logram: Efficient Log Parsing Using n-Gram Dictionaries. (2020)</li>
<li>Nagappan, M. \&amp; Vouk, M. Abstracting log lines to log event types for mining software system logs. 2010 7th IEEE Working Conference On Mining Software Repositories (MSR 2010). pp. 114-117 (2010)</li>
<li>Vaarandi, R. A data clustering algorithm for mining patterns from event logs. Proceedings Of The 3rd IEEE Workshop On IP Operations $\mathcal{E}$ Management (IPOM 2003) (IEEE Cat. No.03EX764). pp. 119-126 (2003)</li>
<li>Wang, X., Zhang, X., Li, L., He, S., Zhang, H., Liu, Y., Zheng, L., Kang, Y., Lin, Q., Dang, Y., Rajmohan, S. \&amp; Zhang, D. SPINE: A Scalable Log Parser with Feedback Guidance. Proceedings Of The 30th ACM Joint European Software Engineering Conference And Symposium On The Foundations Of Software Engineering. pp. 1198-1208 (2022), https://doi.org/10.1145/3540250.3549176</li>
<li>Gurumdimma, N., Jhumka, A., Liakata, M., Chuah, E. \&amp; Browne, J. Crude: Combining resource usage data and error logs for accurate error detection in large-scale distributed systems. 2016 IEEE 35th Symposium On Reliable Distributed Systems (SRDS). pp. 51-60 (2016)</li>
<li>Zheng, Z., Yu, L., Tang, W., Lan, Z., Gupta, R., Desai, N., Coghlan, S. \&amp; Buettner, D. Co-analysis of RAS log and job log on Blue Gene/P. 2011 IEEE International Parallel $\mathcal{E}$ Distributed Processing Symposium. pp. 840-851 (2011)</li>
<li>Meng, W., Zaiter, F., Huang, Y., Liu, Y., Zhang, S., Zhang, Y., Zhu, Y., Zhang, T., Wang, E., Ren, Z., Wang, F., Tao, S. \&amp; Pei, D. Summarizing Unstructured Logs in Online Services. (2020)</li>
<li>Chuah, E., Jhumka, A., Narasimhamurthy, S., Hammond, J., Browne, J. \&amp; Barth, B. Linking resource usage anomalies with system failures from cluster log data. 2013 IEEE 32nd International Symposium On Reliable Distributed Systems. pp. 111-120 (2013)</li>
<li>Pi, A., Chen, W., Zhou, X. \&amp; Ji, M. Profiling distributed systems in lightweight virtualized environments with logs and resource metrics. Proceedings Of The 27th International Symposium On High-Performance Parallel And Distributed Computing. pp. 168-179 (2018)</li>
<li>Ren, Z., Liu, C., Xiao, X., Jiang, H. \&amp; Xie, T. Root cause localization for unreproducible builds via causality analysis over system call tracing. 2019 34th IEEE/ACM International Conference On Automated Software Engineering (ASE). pp. 527-538 (2019)</li>
<li>
<p>Kimura, T., Ishibashi, K., Mori, T., Sawada, H., Toyono, T., Nishimatsu, K., Watanabe, A., Shimoda, A. \&amp; Shiomoto, K. Spatio-temporal factorization of log data for understanding network events. IEEE INFOCOM 2014-IEEE Conference On Computer Communications. pp. 610-618 (2014)</p>
</li>
<li>
<p>Steinle, M., Aberer, K., Girdzijauskas, S. \&amp; Lovis, C. Mapping moving landscapes by mining mountains of logs: novel techniques for dependency model generation. VLDB. 6 pp. 1093-1102 (2006)</p>
</li>
<li>Lou, J., Fu, Q., Yang, S., Xu, Y. \&amp; Li, J. Mining invariants from console logs for system problem detection. 2010 USENIX Annual Technical Conference (USENIX ATC 10). (2010)</li>
<li>Kc, K. \&amp; Gu, X. ELT: Efficient log-based troubleshooting system for cloud computing infrastructures. 2011 IEEE 30th International Symposium On Reliable Distributed Systems. pp. 11-20 (2011)</li>
<li>Awad, M. \&amp; Menascé, D. Performance model derivation of operational systems through log analysis. 2016 IEEE 24th International Symposium On Modeling, Analysis And Simulation Of Computer And Telecommunication Systems (MASCOTS). pp. 159-168 (2016)</li>
<li>Tan, J., Kavulya, S., Gandhi, R. \&amp; Narasimhan, P. Visual, log-based causal tracing for performance debugging of mapreduce systems. 2010 IEEE 30th International Conference On Distributed Computing Systems. pp. 795-806 (2010)</li>
<li>Beschastnikh, I., Brun, Y., Ernst, M. \&amp; Krishnamurthy, A. Inferring models of concurrent systems from logs of their behavior with CSight. Proceedings Of The 36th International Conference On Software Engineering. pp. 468-479 (2014)</li>
<li>Mariani, L. \&amp; Pastore, F. Automated Identification of Failure Causes in System Logs. 2008 19th International Symposium On Software Reliability Engineering (ISSRE). pp. 117-126 (2008)</li>
<li>Ulrich, A., Hallal, H., Petrenko, A. \&amp; Boroday, S. Verifying trustworthiness requirements in distributed systems with formal log-file analysis. 36th Annual Hawaii International Conference On System Sciences, 2003. Proceedings Of The. pp. 10 pp.- (2003)</li>
<li>Oprea, A., Li, Z., Yen, T., Chin, S. \&amp; Alrwais, S. Detection of early-stage enterprise infection by mining large-scale log data. 2015 45th Annual IEEE/IFIP International Conference On Dependable Systems And Networks. pp. 45-56 (2015)</li>
<li>Balzarotti, D., Stolfo, S. \&amp; Cova, M. Research in Attacks, Intrusions and Defenses: 15th International Symposium, RAID 2012, Amsterdam, The Netherlands, September 12-14, 2012, Proceedings. (Springer,2012)</li>
<li>Yoon, E. \&amp; Squicciarini, A. Toward detecting compromised mapreduce workers through log analysis. 2014 14th IEEE/ACM International Symposium On Cluster, Cloud And Grid Computing. pp. 41-50 (2014)</li>
<li>Yen, T., Oprea, A., Onarlioglu, K., Leetham, T., Robertson, W., Juels, A. \&amp; Kirda, E. Beehive: Large-scale log analysis for detecting suspicious activity in enterprise networks. Proceedings Of The 29th Annual Computer Security Applications Conference. pp. 199-208 (2013)</li>
<li>Gonçalves, D., Bota, J. \&amp; Correia, M. Big data analytics for detecting host misbehavior in large logs. 2015 IEEE Trustcom/BigDataSE/ISPA. 1 pp. 238-245 (2015)</li>
<li>Du, M., Li, F., Zheng, G. \&amp; Srikumar, V. Deeplog: Anomaly detection and diagnosis from system logs through deep learning. Proceedings Of The 2017 ACM SIGSAC Conference On Computer And Communications Security. pp. 1285-1298 (2017)</li>
<li>Bertero, C., Roy, M., Sauvanaud, C. \&amp; Trédan, G. Experience report: Log mining using natural language processing and application to anomaly detection. 2017 IEEE 28th International Symposium On Software Reliability Engineering (ISSRE). pp. $351-360(2017)$</li>
<li>
<p>Meng, W., Liu, Y., Zhu, Y., Zhang, S., Pei, D., Liu, Y., Chen, Y., Zhang, R., Tao, S., Sun, P. \&amp; Others Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs.. IJCAI. 19, 4739-4745 (2019)</p>
</li>
<li>
<p>Zhang, X., Xu, Y., Lin, Q., Qiao, B., Zhang, H., Dang, Y., Xie, C., Yang, X., Cheng, Q., Li, Z. \&amp; Others Robust log-based anomaly detection on unstable log data. Proceedings Of The 2019 27th ACM Joint Meeting On European Software Engineering Conference And Symposium On The Foundations Of Software Engineering. pp. 807-817 (2019)</p>
</li>
<li>Lu, S., Rao, B., Wei, X., Tak, B., Wang, L. \&amp; Wang, L. Log-based abnormal task detection and root cause analysis for spark. 2017 IEEE International Conference On Web Services (ICWS). pp. 389-396 (2017)</li>
<li>He, S., Zhu, J., He, P. \&amp; Lyu, M. Experience report: System log analysis for anomaly detection. 2016 IEEE 27th International Symposium On Software Reliability Engineering (ISSRE). pp. 207-218 (2016)</li>
<li>Cândido, J., Aniche, M. \&amp; Deursen, A. Log-based software monitoring.</li>
<li>Tang, D. \&amp; Iyer, R. Analysis of the VAX/VMS error logs in multicomputer environments-a case study of software dependability. Proceedings Third International Symposium On Software Reliability Engineering. pp. 216-217 (1992)</li>
<li>Lim, C., Singh, N. \&amp; Yajnik, S. A log mining approach to failure analysis of enterprise telephony systems. 2008 IEEE International Conference On Dependable Systems And Networks With FTCS And DCC (DSN). pp. 398-403 (2008)</li>
<li>Xu, W., Huang, L., Fox, A., Patterson, D. \&amp; Jordan, M. Detecting large-scale system problems by mining console logs. Proceedings Of The ACM SIGOPS 22nd Symposium On Operating Systems Principles. pp. 117-132 (2009)</li>
<li>Xu, W., Huang, L., Fox, A., Patterson, D. \&amp; Jordan, M. Online system problem detection by mining patterns of console logs. 2009 Ninth IEEE International Conference On Data Mining. pp. 588-597 (2009)</li>
<li>Gandomi, A. \&amp; Haider, M. Beyond the hype: Big data concepts, methods, and analytics. International Journal Of Information Management. 35, 137-144 (2015), https://www.sciencedirect.com/science/article/pii/S0268401214001066</li>
<li>Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi, X., Wang, C., Wang, Y., Ye, W., Zhang, Y., Chang, Y., Yu, P., Yang, Q. \&amp; Xie, X. A Survey on Evaluation of Large Language Models. (2023)</li>
<li>Chang, M., Ratinov, L., Roth, D. \&amp; Srikumar, V. Importance of Semantic Representation: Dataless Classification. Proceedings Of The 23rd National Conference On Artificial Intelligence - Volume 2. pp. 830-835 (2008)</li>
<li>Larochelle, H., Erhan, D. \&amp; Bengio, Y. Zero-Data Learning of New Tasks. Proceedings Of The 23rd National Conference On Artificial Intelligence - Volume 2. pp. $646-651(2008)$</li>
<li>Palatucci, M., Pomerleau, D., Hinton, G. \&amp; Mitchell, T. Zero-Shot Learning with Semantic Output Codes. Proceedings Of The 22nd International Conference On Neural Information Processing Systems. pp. 1410-1418 (2009)</li>
<li>Lampert, C., Nickisch, H. \&amp; Harmeling, S. Learning to detect unseen object classes by between-class attribute transfer. 2009 IEEE Conference On Computer Vision And Pattern Recognition. pp. 951-958 (2009), https://api.semanticscholar.org/CorpusID:10301835</li>
<li>Miller, E., Matsakis, N. \&amp; Viola, P. Learning from one example through shared densities on transforms. Proceedings IEEE Conference On Computer Vision And Pattern Recognition. CVPR 2000 (Cat. No.PR00662). 1 pp. 464-471 vol. 1 (2000)</li>
<li>Workshop, B., :, Scao, T. et al. BLOOM: A 176B-Parameter Open-Access Multilingual Language Model. (2023)</li>
<li>Fu, X., Ren, R., Zhan, J., Zhou, W., Jia, Z. \&amp; Lu, G. LogMaster: Mining Event Correlations in Logs of Large-Scale Cluster Systems. 2012 IEEE 31st Symposium On Reliable Distributed Systems. pp. 71-80 (2012)</li>
</ol>            </div>
        </div>

    </div>
</body>
</html>