<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5623 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5623</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5623</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-265067109</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.05462v2.pdf" target="_blank">ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</a></p>
                <p><strong>Paper Abstract:</strong> Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies. Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations. This paper proposes large language models (LLM), e.g., ChatGPT, for the cybersecurity of IEC 61850-based digital substation communications. Multicast messages such as generic object oriented system event (GOOSE) and sampled value (SV) are used for case studies. The proposed LLM-based cybersecurity framework includes, for the first time, data pre-processing of communication systems and human-in-the-loop (HITL) training (considering the cybersecurity guidelines recommended by humans). The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs. A hardware-in-the-loop (HIL) testbed is used to generate and extract dataset of IEC 61850 communications.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5623.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5623.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT 4.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT 4.0 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proprietary large language model (LLM) used in this paper as an IDS by ingesting textualized packet features and human recommendations to detect anomalies in IEC 61850 GOOSE and SV communications; evaluated at three human-in-the-loop training levels (without, partial, full).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4.0</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A generative pre-trained large language model (transformer-based). The paper treats it as a black-box LLM used via textual prompts and HITL training; no architecture or parameter counts are specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Packet-level features and IDS rules are converted to text and presented to the LLM; detection is performed via prompt-based/textual classification with a human-in-the-loop (HITL) training process at three levels (no recommendations, partial recommendations for DI and DoS, full recommendations). No model fine-tuning is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/tabular features extracted from packet captures (.pcap) of sequence/time-series protocol messages (IEC 61850 GOOSE and SV); essentially structured, time-ordered message logs.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Data injection (DI) anomalies (e.g., invalid/stalled sqNum, incorrect data1/data2/stNum behavior), denial-of-service (DoS) timing anomalies (packet bursts, abnormal heartbeat intervals), system problems (missing packets within allowed interval), replay (RE) attacks (duplicated or stale messages).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Metrics reported: True Positive Rate (TPR / recall), False Positive Rate (FPR), False Negative Rate (FNR), Precision, F1-score. Results from Table I: GOOSE — without: TPR 78.18%, FPR 48%, FNR 21.82%, Precision 78.18%, F1 78.18%; partial: TPR 85.45%, FPR 32%, FNR 14.55%, Precision 85.45%, F1 85.45%; full: TPR 98.18%, FPR 4%, FNR 1.82%, Precision 98.18%, F1 98.18%. SV — without: TPR 70%, FPR 50%, FNR 30%, Precision 80.77%, F1 75%; partial: TPR 95%, FPR 15%, FNR 5%, Precision 95%, F1 95%; full: TPR 96.67%, FPR 0%, FNR 3.33%, Precision 100%, F1 98.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against two other LLMs (Anthropic Claude 2 and Google Bard/PaLM 2) in the same HITL setup; ChatGPT 4.0 achieved higher TPR and lower FPR/FNR across GOOSE and SV at all training levels. The paper qualitatively contrasts LLMs with traditional ML/rule-based IDS: ML models require frequent re-training for new attack patterns, whereas LLMs (as used here) are claimed to adapt via contextual understanding and HITL without full re-training; rule-based systems can be superior for known threats but LLMs can detect novel/unexpected attacks. No direct quantitative comparison to classical ML models is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper-reported limitations include: privacy and confidentiality concerns when using LLMs on critical-infrastructure data; computational and latency constraints (authors focus on online detection rather than real-time due to LLM limitations); possibility of false positives/negatives depending on training level; reliance on human recommendations (HITL) and need for task-oriented dialogues (ToD) or fine-tuning for improved accuracy; potential for LLMs to disclose confidential info or show limited contextual discernment for complex cyber-physical anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5623.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5623.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude 2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anthropic Claude 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial LLM evaluated in the paper as an IDS for IEC 61850 GOOSE and SV datasets using the same text-conversion and HITL approach as for other LLMs; performance reported at three training levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Anthropic Claude 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A generative large language model (transformer family); treated as a black-box LLM in experiments. The paper does not provide architecture or parameter counts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Textualized packet-feature prompts and IDS rule descriptions presented to the model; human-in-the-loop guidance used to create partial and full recommendation training; prompt-based classification rather than reported fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/tabular (feature columns) derived from GOOSE and SV packet captures; time-ordered message logs.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Data injection (DI), denial-of-service (DoS), system problems, and replay (RE) attacks; specific protocol anomalies like sequence number and sample count violations and heartbeat timing anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Metrics reported: TPR, FPR, FNR, Precision, F1-score. Results from Table I: GOOSE — without: TPR 78.18%, FPR 56%, FNR 21.82%, Precision 75.43%, F1 76.78%; partial: TPR 83.64%, FPR 44%, FNR 16.36%, Precision 80.7%, F1 82.3%; full: TPR 89.09%, FPR 32%, FNR 10.91%, Precision 85.96%, F1 87.5%. SV — without: TPR 50%, FPR 50%, FNR 50%, Precision 75%, F1 60%; partial: TPR 70%, FPR 20%, FNR 30%, Precision 91.3%, F1 79.2%; full: TPR 88.3%, FPR 0%, FNR 11.67%, Precision 100%, F1 93.8%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared directly to ChatGPT 4.0 and Google Bard in the same HITL experimental setup; Claude 2 shows generally lower TPR (especially for SV without training) than ChatGPT 4.0 but achieves perfect precision at full SV training level. The paper provides qualitative comparison to rule-based and ML methods (LLMs are portrayed as more adaptable, reducing need for retraining) but offers no quantitative comparison to classical ML baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same general limitations noted: potential for privacy leaks, computational speed limitations (not real-time), dependence on quality of human recommendations, risk of FPs/FNs especially at lower training levels, and need for ToD/fine-tuning to improve task-specific performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5623.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5623.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Google Bard / PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Bard / PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's LLM (PaLM 2 accessible via Bard) evaluated in the paper under the same HITL prompt-based detection pipeline for IEC 61850 GOOSE and SV packet-derived features; performance is reported for no, partial, and full human recommendation training levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Google Bard / PaLM 2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A generative large language model by Google (PaLM 2 used via Bard); treated as a black-box LLM in the experiments with no architecture/parameter details provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Textualization of IDS rules and packet feature logs presented as prompts; HITL training at three levels (without, partial, full); detection performed via prompt-based classification/interpretation rather than fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/tabular features extracted from network packet captures (.pcap) of IEC 61850 GOOSE and SV messages (time-ordered message logs).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Data injection (DI), denial-of-service (DoS), system problem, and replay (RE) anomalies, including sequence number/sample count violations and heartbeat/timing irregularities.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Metrics reported: TPR, FPR, FNR, Precision, F1-score. Results from Table I: GOOSE — without: TPR 74.5%, FPR 56%, FNR 25.5%, Precision 74.5%, F1 74.5%; partial: TPR 81.8%, FPR 40%, FNR 18.18%, Precision 81.8%, F1 81.8%; full: TPR 89.1%, FPR 20%, FNR 10.9%, Precision 90.7%, F1 90.7%. SV — without: TPR 50%, FPR 50%, FNR 50%, Precision 75%, F1 60%; partial: TPR 63.3%, FPR 40%, FNR 36.6%, Precision 82.6%, F1 71.7%; full: TPR 81.6%, FPR 25%, FNR 18.34%, Precision 91.7%, F1 85.9%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Directly compared to ChatGPT 4.0 and Claude 2 within the paper — Bard/PaLM 2 underperforms ChatGPT 4.0 across most metrics and training levels but achieves reasonably high precision at full training. The authors argue qualitatively that LLMs (including Bard) can reduce retraining needs compared with classical ML IDS, but the paper contains no quantitative comparison to traditional ML or statistical anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same limitations as for other LLMs: privacy concerns, computational/latency constraints preventing real-time use in the paper, dependence on HITL quality, potential FPR/FNR issues particularly at lower training levels, and need for ToD/fine-tuning to improve detection robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unsupervised learning based intrusion detection for GOOSE messages in digital substation <em>(Rating: 2)</em></li>
                <li>Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids <em>(Rating: 2)</em></li>
                <li>A deep learning-based cyberattack detection system for transmission protective relays <em>(Rating: 2)</em></li>
                <li>Anomaly detection for cybersecurity of the substations <em>(Rating: 2)</em></li>
                <li>Automated cybersecurity tester for IEC 61850-based digital substations <em>(Rating: 2)</em></li>
                <li>From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5623",
    "paper_id": "paper-265067109",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "ChatGPT 4.0",
            "name_full": "ChatGPT 4.0 (OpenAI)",
            "brief_description": "A proprietary large language model (LLM) used in this paper as an IDS by ingesting textualized packet features and human recommendations to detect anomalies in IEC 61850 GOOSE and SV communications; evaluated at three human-in-the-loop training levels (without, partial, full).",
            "citation_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
            "mention_or_use": "use",
            "model_name": "ChatGPT 4.0",
            "model_description": "A generative pre-trained large language model (transformer-based). The paper treats it as a black-box LLM used via textual prompts and HITL training; no architecture or parameter counts are specified in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Packet-level features and IDS rules are converted to text and presented to the LLM; detection is performed via prompt-based/textual classification with a human-in-the-loop (HITL) training process at three levels (no recommendations, partial recommendations for DI and DoS, full recommendations). No model fine-tuning is reported.",
            "data_type": "Structured/tabular features extracted from packet captures (.pcap) of sequence/time-series protocol messages (IEC 61850 GOOSE and SV); essentially structured, time-ordered message logs.",
            "anomaly_type": "Data injection (DI) anomalies (e.g., invalid/stalled sqNum, incorrect data1/data2/stNum behavior), denial-of-service (DoS) timing anomalies (packet bursts, abnormal heartbeat intervals), system problems (missing packets within allowed interval), replay (RE) attacks (duplicated or stale messages).",
            "dataset_name": "GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)",
            "performance_metrics": "Metrics reported: True Positive Rate (TPR / recall), False Positive Rate (FPR), False Negative Rate (FNR), Precision, F1-score. Results from Table I: GOOSE — without: TPR 78.18%, FPR 48%, FNR 21.82%, Precision 78.18%, F1 78.18%; partial: TPR 85.45%, FPR 32%, FNR 14.55%, Precision 85.45%, F1 85.45%; full: TPR 98.18%, FPR 4%, FNR 1.82%, Precision 98.18%, F1 98.18%. SV — without: TPR 70%, FPR 50%, FNR 30%, Precision 80.77%, F1 75%; partial: TPR 95%, FPR 15%, FNR 5%, Precision 95%, F1 95%; full: TPR 96.67%, FPR 0%, FNR 3.33%, Precision 100%, F1 98.3%.",
            "baseline_comparison": "Compared against two other LLMs (Anthropic Claude 2 and Google Bard/PaLM 2) in the same HITL setup; ChatGPT 4.0 achieved higher TPR and lower FPR/FNR across GOOSE and SV at all training levels. The paper qualitatively contrasts LLMs with traditional ML/rule-based IDS: ML models require frequent re-training for new attack patterns, whereas LLMs (as used here) are claimed to adapt via contextual understanding and HITL without full re-training; rule-based systems can be superior for known threats but LLMs can detect novel/unexpected attacks. No direct quantitative comparison to classical ML models is provided.",
            "limitations_or_failure_cases": "Paper-reported limitations include: privacy and confidentiality concerns when using LLMs on critical-infrastructure data; computational and latency constraints (authors focus on online detection rather than real-time due to LLM limitations); possibility of false positives/negatives depending on training level; reliance on human recommendations (HITL) and need for task-oriented dialogues (ToD) or fine-tuning for improved accuracy; potential for LLMs to disclose confidential info or show limited contextual discernment for complex cyber-physical anomalies.",
            "uuid": "e5623.0",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Claude 2",
            "name_full": "Anthropic Claude 2",
            "brief_description": "A commercial LLM evaluated in the paper as an IDS for IEC 61850 GOOSE and SV datasets using the same text-conversion and HITL approach as for other LLMs; performance reported at three training levels.",
            "citation_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
            "mention_or_use": "use",
            "model_name": "Anthropic Claude 2",
            "model_description": "A generative large language model (transformer family); treated as a black-box LLM in experiments. The paper does not provide architecture or parameter counts.",
            "model_size": null,
            "anomaly_detection_method": "Textualized packet-feature prompts and IDS rule descriptions presented to the model; human-in-the-loop guidance used to create partial and full recommendation training; prompt-based classification rather than reported fine-tuning.",
            "data_type": "Structured/tabular (feature columns) derived from GOOSE and SV packet captures; time-ordered message logs.",
            "anomaly_type": "Data injection (DI), denial-of-service (DoS), system problems, and replay (RE) attacks; specific protocol anomalies like sequence number and sample count violations and heartbeat timing anomalies.",
            "dataset_name": "GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)",
            "performance_metrics": "Metrics reported: TPR, FPR, FNR, Precision, F1-score. Results from Table I: GOOSE — without: TPR 78.18%, FPR 56%, FNR 21.82%, Precision 75.43%, F1 76.78%; partial: TPR 83.64%, FPR 44%, FNR 16.36%, Precision 80.7%, F1 82.3%; full: TPR 89.09%, FPR 32%, FNR 10.91%, Precision 85.96%, F1 87.5%. SV — without: TPR 50%, FPR 50%, FNR 50%, Precision 75%, F1 60%; partial: TPR 70%, FPR 20%, FNR 30%, Precision 91.3%, F1 79.2%; full: TPR 88.3%, FPR 0%, FNR 11.67%, Precision 100%, F1 93.8%.",
            "baseline_comparison": "Compared directly to ChatGPT 4.0 and Google Bard in the same HITL experimental setup; Claude 2 shows generally lower TPR (especially for SV without training) than ChatGPT 4.0 but achieves perfect precision at full SV training level. The paper provides qualitative comparison to rule-based and ML methods (LLMs are portrayed as more adaptable, reducing need for retraining) but offers no quantitative comparison to classical ML baselines.",
            "limitations_or_failure_cases": "Same general limitations noted: potential for privacy leaks, computational speed limitations (not real-time), dependence on quality of human recommendations, risk of FPs/FNs especially at lower training levels, and need for ToD/fine-tuning to improve task-specific performance.",
            "uuid": "e5623.1",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Google Bard / PaLM 2",
            "name_full": "Google Bard / PaLM 2",
            "brief_description": "Google's LLM (PaLM 2 accessible via Bard) evaluated in the paper under the same HITL prompt-based detection pipeline for IEC 61850 GOOSE and SV packet-derived features; performance is reported for no, partial, and full human recommendation training levels.",
            "citation_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
            "mention_or_use": "use",
            "model_name": "Google Bard / PaLM 2",
            "model_description": "A generative large language model by Google (PaLM 2 used via Bard); treated as a black-box LLM in the experiments with no architecture/parameter details provided in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Textualization of IDS rules and packet feature logs presented as prompts; HITL training at three levels (without, partial, full); detection performed via prompt-based classification/interpretation rather than fine-tuning.",
            "data_type": "Structured/tabular features extracted from network packet captures (.pcap) of IEC 61850 GOOSE and SV messages (time-ordered message logs).",
            "anomaly_type": "Data injection (DI), denial-of-service (DoS), system problem, and replay (RE) anomalies, including sequence number/sample count violations and heartbeat/timing irregularities.",
            "dataset_name": "GOOSE and SV datasets extracted from a hardware-in-the-loop (HIL) IEC 61850 testbed (packet captures, .pcap)",
            "performance_metrics": "Metrics reported: TPR, FPR, FNR, Precision, F1-score. Results from Table I: GOOSE — without: TPR 74.5%, FPR 56%, FNR 25.5%, Precision 74.5%, F1 74.5%; partial: TPR 81.8%, FPR 40%, FNR 18.18%, Precision 81.8%, F1 81.8%; full: TPR 89.1%, FPR 20%, FNR 10.9%, Precision 90.7%, F1 90.7%. SV — without: TPR 50%, FPR 50%, FNR 50%, Precision 75%, F1 60%; partial: TPR 63.3%, FPR 40%, FNR 36.6%, Precision 82.6%, F1 71.7%; full: TPR 81.6%, FPR 25%, FNR 18.34%, Precision 91.7%, F1 85.9%.",
            "baseline_comparison": "Directly compared to ChatGPT 4.0 and Claude 2 within the paper — Bard/PaLM 2 underperforms ChatGPT 4.0 across most metrics and training levels but achieves reasonably high precision at full training. The authors argue qualitatively that LLMs (including Bard) can reduce retraining needs compared with classical ML IDS, but the paper contains no quantitative comparison to traditional ML or statistical anomaly detectors.",
            "limitations_or_failure_cases": "Same limitations as for other LLMs: privacy concerns, computational/latency constraints preventing real-time use in the paper, dependence on HITL quality, potential FPR/FNR issues particularly at lower training levels, and need for ToD/fine-tuning to improve detection robustness.",
            "uuid": "e5623.2",
            "source_info": {
                "paper_title": "ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unsupervised learning based intrusion detection for GOOSE messages in digital substation",
            "rating": 2,
            "sanitized_title": "unsupervised_learning_based_intrusion_detection_for_goose_messages_in_digital_substation"
        },
        {
            "paper_title": "Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids",
            "rating": 2,
            "sanitized_title": "ereno_a_framework_for_generating_realistic_iec61850_intrusion_detection_datasets_for_smart_grids"
        },
        {
            "paper_title": "A deep learning-based cyberattack detection system for transmission protective relays",
            "rating": 2,
            "sanitized_title": "a_deep_learningbased_cyberattack_detection_system_for_transmission_protective_relays"
        },
        {
            "paper_title": "Anomaly detection for cybersecurity of the substations",
            "rating": 2,
            "sanitized_title": "anomaly_detection_for_cybersecurity_of_the_substations"
        },
        {
            "paper_title": "Automated cybersecurity tester for IEC 61850-based digital substations",
            "rating": 2,
            "sanitized_title": "automated_cybersecurity_tester_for_iec_61850based_digital_substations"
        },
        {
            "paper_title": "From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy",
            "rating": 1,
            "sanitized_title": "from_chatgpt_to_threatgpt_impact_of_generative_ai_in_cybersecurity_and_privacy"
        }
    ],
    "cost": 0.01260625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications</p>
<p>Graduate Student Member, IEEEAydin Zaboli 
Member, IEEESeong Lok Choi 
Member, IEEETai-Jin Song 
Senior Member, IEEEJunho Hong </p>
<p>Department of Electrical and Computer Engineering
University of Michigan -Dearborn
48128DearbornMIUSA</p>
<p>Power Systems Engineering Center
National Renewable Energy Laboratory (NREL)
80401GoldenCOUSA</p>
<p>Department of Urban Engineering
Chungbuk National University
28644CheongjuSouth Korea</p>
<p>ChatGPT and Other Large Language Models for Cybersecurity of Smart Grid Applications
9D19C63013D83CAEC93F46B603C0E479
Cybersecurity breaches targeting electrical substations constitute a significant threat to the integrity of the power grid, necessitating comprehensive defense and mitigation strategies.Any anomaly in information and communication technology (ICT) should be detected for secure communications between devices in digital substations.This paper proposes large language models (LLMs), e.g., ChatGPT, for the cybersecurity of IEC 61850-based communications.Multi-cast messages such as generic object oriented system events (GOOSE) and sampled values (SV) are used for case studies.The proposed LLMbased cybersecurity framework includes, for the first time, data pre-processing of communication systems and human-in-theloop (HITL) training (considering the cybersecurity guidelines recommended by humans).The results show a comparative analysis of detected anomaly data carried out based on the performance evaluation metrics for different LLMs.A hardwarein-the-loop (HIL) testbed is used to generate and extract dataset of IEC 61850 communications.Index Terms-Cybersecurity, generic object oriented system event (GOOSE), ChatGPT, human-in-the-loop (HITL), large language model (LLM), sampled value (SV), substations.</p>
<p>I. INTRODUCTION</p>
<p>Digital substations serve as crucial elements within modern power systems, characterized by their escalating complexity and integration.GOOSE and SV are instrumental in facilitating rapid and dependable communication in the context of digital substations.Nevertheless, the open architecture intrinsic to these protocols makes them vulnerable to cyberattacks.The focal point of scholarly endeavors is the refinement and implementation of complex algorithms tailored for the contemporaneous oversight and scrutiny of network traffic [1].</p>
<p>Intrusion detection system (IDS)-based machine learning (ML) methods have been the foundation for detecting and mitigating anomalies in GOOSE and SV messages.While these methods offer precision and are data-driven, they come with a significant challenge.Every time a new attack pattern emerges, the models need to be re-trained.This necessity for re-training consumes time and resources and leaves the system vulnerable during the interim periods when the new threats are not yet incorporated into the model's knowledge base [2].On the other hand, LLMs such as ChatGPT 4.0 offer a more dynamic and adaptable approach.Unlike ML models, LLMs are designed to understand context, allowing them to recognize and respond to novel threats even if they have not been explicitly trained in them.This contextual understanding minimizes the efforts required in the face of evolving cyber threats.Instead of frequent re-training sessions, LLMs can interpret and adapt to new information, providing a more resilient and efficient solution for anomaly detection in digital substations [3], [4].In the area of cybersecurity for digital substations, LLMs can play a pivotal role in anomaly detection, enhancing the security layers.These models can analyze vast datasets, identify patterns, and detect anomalies indicative of potential cyberattacks.These models are designed to investigate through extensive data, including GOOSE and SV messages, to effectively distinguish regular patterns from irregularities [5].The incorporation of artificial intelligence (AI) aids into real-time monitoring is crucial to accelerate responses to security breaches.A unique deep learning-based system tailored for detecting cyberattacks on protective relays was developed based on extensive real-world datasets [6].GOOSE and SV messages are vulnerable to replay and message injection attacks, involving the re-transmission of unaltered messages or the transmission of fake, malicious ones.These attacks disrupt system operations either by replaying old messages or by injecting new, deceptive messages that mimic legitimate behavior [7], [8].However, the diversity and complexity of cyberattacks necessitate advanced detection mechanisms.Also, balancing the model's sensitivity to detect minor anomalies while avoiding false positives (FPs) is crucial.In [9], a novel unsupervised learning approach for an IDS of GOOSE messages is suggested based on a combination of autoencoders and clustering techniques for efficient detection.According to literature surveys, challenges in the applicability of ML models in IDSs can include ensuring the reliability and robustness of the model in real-time power grids considering new cyberattacks, a trade-off between complexity and accuracy due to large datasets, and the adaptability of the ML model to evolving cyberattacks and changing the substation infrastructure.Furthermore, a re-training process is required for new cyberattacks; however, LLMs can handle these challenges effectively and reduce the processing time.</p>
<p>This paper proposes for the first time the employment of LLMs based on HITL interactions to detect anomalies in GOOSE and SV datasets for cybersecurity considerations in substations.Hence, this paper focuses on the cybersecurity of multicast messages, and we will focus on other protocols in substations in the future.This paper suggests human recommendations for data pre-processing for these communication arXiv:2311.05462v2[cs.CR] 25 Feb 2024 protocols.This process minimizes efforts (unlike applying ML methods) when encountering new cyberattacks (or anomalies).It does not affect the model's complexity/precision and is faster to implement.Moreover, this paper makes a comparison between LLMs (i.e., ChatGPT 4.0 [10], Anthropic's Claude 2 [11], and Google Bard/PaLM 2 [12]) to evaluate their performance.The actual datasets for GOOSE and SV packets are extracted from the HIL testbed.The main contributions of this paper can be summarized as follows:</p>
<p>• This paper proposes the usage of different LLMs in the cybersecurity of digital substations in terms of performance evaluation metrics.• LLM-based HITL is considered an IDS to detect abnormal data in IEC 61850 communication protocols.• A conversion of the IDS algorithm to text is employed for training datasets to detect anomalies in LLMs.The remainder of the paper is organized as follows: Section II states a representation of the cybersecurity of digital substations using LLMs.The proposed HITL technique, along with the feature extraction and analysis of datasets, are mentioned in Section III.Section IV presents the results and discussion of the evaluation metrics according to different levels of training.Finally, this paper is deduced in Section V.</p>
<p>II. CYBERSECURITY OF DIGITAL SUBSTATIONS USING LARGE LANGUAGE MODELS</p>
<p>A. Cybersecurity of Digital Substations</p>
<p>A cyber-physical power system testbed serves as an instrumental platform for studying the causal relationships associated with cyber intrusions, the robustness of power systems, and the dependability of applications in a realistic environment.Within such a real-time HIL testbed, all constituent elements, encompassing hardware, software, communication mechanisms, and emulators, are coordinated in alignment with the global positioning system (GPS).The real-time dynamics pertinent to communication and information processing become imperative in the context of analyzing cyber intrusions, detection mechanisms, and mitigation strategies [13].As seen in Fig. 1, the testbed consists of protective intelligent electronic devices (IEDs), software-defined networking (SDN) switches, a satellite-synchronized clock, a merging unit, a supervisory control and data acquisition (SCADA) system, a real-time digital simulator, and the amplifier.The distributed management system (DMS) SCADA system can get measurements and issue a control command via DNP3 communication.Various IEDs are implemented, including the merging unit IED and protective IEDs.These IEDs possess the proficiency to transmit control commands (e.g., GOOSE messages) pertinent to a circuit breaker (CB).Conversely, a CB IED (modeled in a real-time simulator) is specifically configured to subscribe to GOOSE messages and publish the status (open or closed) to protective IEDs.The merging unit IED has the ability to forward digital current and voltage values (i.e., SV), taking into account the amplifier from the digital simulator, to the protective IED.Furthermore, the proposed HITL LLM-based IDS is engineered to identify anomalies and potential security threats within the substation automation framework and maintains a connection to SDN switches [13].The purpose of this paper is to demonstrate an IDS considering the LLMbased HITL process.Hence, the GOOSE and SV packets are extracted from the HIL testbed for further analysis in different LLMs considering the human recommendations that are described in the subsequent section.</p>
<p>B. Large Language Model-Based Human-in-the-loop Process</p>
<p>Generative AI (GenAI) models, constructed through deep neural network methods, are designed to discern patterns and structures from extensive training datasets, subsequently producing similar content.The capabilities of GenAI encompass the creation of diverse content types, ranging from text and images to sounds and various data forms.The introduction of ChatGPT has markedly influenced the broader AI/ML domain, exemplifying GenAI's potential to resonate with the wider populace and altering prevailing conceptions of AI/ML.The technological sector is actively pursuing the refinement of advanced LLMs aimed at simulating authentic human interactions, as evidenced by innovations (e.g., Microsoft's GPT and Google Bard/PaLM 2).Over the past year, GenAI has strengthened its presence as a prevalent online tool [5].</p>
<p>LLMs and GenAI systems present considerable opportunities to augment productivity and operational efficiency.However, their application, especially in sectors characterized by high risk and stringent regulations, brings about notable challenges.A potential strategy to mitigate risks is adopting the HITL process, as illustrated in Fig. 1 by the HITL LLM box.Incorporating human interactions during training, validation, and testing stages can expedite the learning process and improve the confidence level of outputs.Initially, individuals can explain the execution of specific tasks and subsequently offer insights into the model's efficacy.This involvement can be manifested in modifying the model's results.Drawing insights from a fusion of human demonstrations and assessments has proven to surpass the efficiency and speed of ML methods.The HITL paradigm becomes indispensable when confronted with constraints (e.g., when data presents anomalies or lacks comprehensiveness), leading to uncertainties about the model's capability to address all scenarios.Moreover, consistent human oversight and verification are useful, especially when inaccuracies in model predictions could have severe consequences [14].In the proposed model, there are human recommendations to improve the model efficiency based on GOOSE and SV message features.Thus, this method is helpful in minimizing the trials by entering new data into the normal dataset and avoiding the re-training process.Also, the adaptability and robustness of models can be improved quickly.</p>
<p>Allowing a language model unrestricted access to data pertaining to critical infrastructure necessitates meticulous study, given the significant security and privacy implications.Implementing accurate access controls and encryption and authentication protocols is imperative to mitigate unauthorized data access.It is vital for human specialists to exercise continuous supervision and assess the outputs of the model, ensuring the validity and dependability of AI-facilitated cybersecurity methodologies.In addition, there exists the potential for LLMs to unintentionally disclose confidential information during engagements, especially if they lack appropriate training or protection [5].The cybersecurity of LLMs is out of scope for this research, and the purpose is solely to employ LLMs as tools for detecting anomalies in communication messages.</p>
<p>III. IEC 61850-BASED COMMUNICATION DATASETS AND HUMAN RECOMMENDATIONS PROCESS</p>
<p>A. GOOSE and SV Datasets</p>
<p>The GOOSE and SV packets are extracted from the HIL testbed.The ".pcap" means that these packets are captured using Wireshark (a network packet analyzer), as seen in Fig. 2. As shown, there are 10 data points for GOOSE packets based on the extracted features.The SV datasets follow the same procedures, with the 7 most important features as dataset columns."Time" shows the time at which the packet is actually sent, and the format of this feature is based on hour, minute, and second (including microsecond level).The features "DM" and "SM" refer to the destination and source media access control (MAC) addresses, respectively.This specific "DM" address (01 00 03) of GOOSE messages shows the target devices (sent to the device that subscribes to this MAC address).Also, the "SM" address of GOOSE messages is 27 34 31 which shows the sender's IED.The indicators for GOOSE and SV are shown as "type," which is 88 b8 and 88 ba, respectively.The "APPID" values for GOOSE and SV communications are 3 and 40, respectively.Also, "datSet" and "goID" are assigned based on "DM" and indicate the dataset name and GOOSE identification, respectively.Based on Fig. 2, there is a GOOSE block reference ("gocbRef") that indicates the name of the GOOSE in the "goosePdu.""stNum" and "sqNum" express the state and sequence numbers in GOOSE communications, respectively.Furthermore, two data types ("data1" and "data2") are considered based on GOOSE packets.In the SV dataset, there are "svID" and "smpCnt" in the "savPdu," which indicate SV identification and sample count number.A large number of datasets have been used to train the GOOSE and SV communications to check the performance evaluation of LLMs.</p>
<p>B. Human Recommendations for Intrusion Detection Systems</p>
<p>According to the given datasets, a series of human recommendations based on the violations in the GOOSE and SV datasets can be described.Some different attacks and errors were considered, such as the data injection (DI) attack, the denial-of-service (DoS) attack, the system problem, and the replay (RE) attack for GOOSE and SV communications.These attacks can be described as follows.A failure to satisfy at least one recommendation leads to the relevant attack.Regarding the DoS attack for SV, the sample/cycle is 80 and the frequency is 60 Hz, so there are a total of 4, 800 samples per second.If 1/4800 is calculated, 208 microseconds can be achieved.Hence, the normal time for a DoS attack should be around this time.The process can be done for GOOSE messages as well.The "heartbeat" of GOOSE packets refers to a regular, periodic message sent over the network to indicate the status of the system.The heartbeat (e.g., 2 seconds) ensures continuous monitoring and quick detection of any changes or failures in the system.The frequency of these heartbeat messages can vary depending on the configuration and requirements of the specific substation system.Typically, GOOSE messages are sent at intervals ranging from a few milliseconds to several seconds.Regarding SV packets, a heartbeat indicates the operational status or health of a system.The exact frequency or interval of the heartbeat for SV packets can vary depending on the specific implementation and requirements of the digital substation system.</p>
<p>• Attacks/errors on GOOSE datasets -DI: If data has the same "DM" and "SM," "sqNum" should be increased every time.</p>
<p>-DI: If there is any change in "data1" or "data2," "stNum" should be increased by 1 and "sqNum" should be reset to 0.</p>
<p>-DI: If data has the same "DM" and "SM," once "stNum" is increased, it cannot go back to smaller numbers.</p>
<p>-DoS: There are up to 10 packets (rows) within 10 ms.</p>
<p>-System Problem: There should be a packet (dataset) within 10 s.</p>
<p>-RE: If there is any change in "data1" or "data2," "stNum" should be increased 1 and "sqNum" should be reset to 0.</p>
<p>• Attacks/errors on SV datasets -DI: The range of "smpCnt" is from 0 to 4799.</p>
<p>-DI: Once the "smpCnt" is increased, it should be increased up to 4799 and then reset to 0.</p>
<p>-DI: "smpCnt" cannot be decreased until it reaches 4799 and resets to 0.</p>
<p>-DoS: A normal time interval should be around 208 ms.</p>
<p>-DoS: There are up to 12 packets within 2.083 ms.</p>
<p>-System Problem: "smpCnt" should be increased every time by 1.The recommended considerations are applied to datasets to train LLMs.This helps to improve the accuracy of the pretrained model based on the ML model, even though there is new data.The purpose is to show the performance evaluation based on datasets generated at three different levels, including a dataset without training (without human recommendations), with partial training (recommendations of DI and DoS attacks), and with full training.Then, the performance evaluation metrics of different LLMs are compared.This process assists in minimizing the trials for re-training ML models and the adaptability of the model in cases where there is new data.The next section presents the performance evaluation results, considering the HITL process in different LLMs.</p>
<p>IV. RESULTS AND DISCUSSION</p>
<p>This section presents a comparison of results between LLMs at different levels.Precision is a preferable performance metric, denoting the rate at which an IDS correctly detects anomalies.However, relying solely on precision metric might be misleading when evaluating anomaly detection techniques, especially in scenarios characterized by significant differences between FPs and false negatives (FNs).Therefore, this section presents the performance analysis of different LLMs considering the HITL for the GOOSE and SV datasets.The fundamental performance metrics for anomaly detection analysis are described and discussed in this section.A description of evaluation metrics based on the detection of anomaly data in GOOSE and SV communication protocols, along with the results based on case studies, is shown in Table I.Due to the limitations of LLMs and computational speed, this paper focuses on online detection, not real-time intrusion detection.</p>
<p>A. Case Studies: GOOSE and SV Anomaly Detection</p>
<p>This section presents the results of the performance evaluation metrics for different LLMs based on the training levels.The formulations of the performance assessment are given in the previous part, including true positive rate (TPR), false positive rate (FPR), false negative rate (FNR), precision, and F1-score metrics.A comparison of anomaly detection results considering the different LLMs (i.e., ChatGPT 4.0, Anthropic's Claude 2, and Google Bard/PaLM 2) with the HITL process is presented in this table.The results show that ChatGPT 4.0 outperforms the two other LLMs in both case studies for anomaly detection as an IDS.A higher TPR indicates a better model, as it is able to identify more of the actual positives.It also shows the detection rate of anomalies, where ChatGPT 4.0 has values of 98.18% and 96.67% for detection of anomalies in GOOSE and SV messages, respectively.These percentages are the highest rates in comparison with other LLMs at full training levels.It happened for all other training levels as well.Lower FPR and FNR indicate a superior model, as it is less possible to misclassify positive and negative values, respectively.It occurs for ChatGPT 4.0 considering FPR and FNR in both communications.At full training levels, these values are less than 4% which represents a good performance of this LLM.Also, Claude 2 shows great performance in the detection of normal SV data that was wrongly detected as anomalies.The precision metric represents the accuracy of anomalies detection in GOOSE and SV communications.The precision values for ChatGPT 4.0 and Claude 2 are 100% in comparison with Google Bard (91.7%) in the SV dataset.F1-score is a harmonic mean of precision and recall, which means that it gives equal importance to both the ability of the algorithm to identify true anomalies and its ability to avoid FPs.This metric shows the highest value based on ChatGPT 4.0.The impact of the HITL process can be observed at different training levels in Table I.A portion of the human recommendations are considered for the partial training.Therefore, better performance at different rates, precisions, and F1-scores can be perceived by applying the HITL process.All human recommendations based on the defined attacks/errors are considered at the full training level.</p>
<p>To recap, ChatGPT 4.0 served as the best LLM in comparison with Anthropic's Claude 2 and Google Bard/PaLM 2 in all rates and measurements.However, there are challenges in using LLMs based on the HITL process in cybersecurity studies on digital substations.Cybersecurity anomalies entail a level of complexity that may exceed AI's contextual discernment capabilities.The necessity for LLMs to process sensitive data introduces data privacy and security considerations.AI's enhancement in cybersecurity is hindered by the need for continuous data input, reflecting the dynamic nature of the field.The integrity of anomaly detection in AI is dependent on its training data, with potential inaccuracies manifesting as FPs or FNs.Hence, task-oriented dialogues (ToD) and fine-tuning are posited to enhance anomaly detection accuracy through the provision of structured interactive patterns that augment LLMs' effectiveness in cybersecurity-specific responses.They enable more targeted and context-aware queries, thereby refining the decision-making process.Additionally, they promote an improved feedback mechanism where human experts can iteratively refine AI performance on designated tasks, thereby optimizing its learning trajectory over time.Rule-based detection systems, known for their effectiveness in identifying known threats, often demonstrate superior results in specific scenarios.However, LLMs bring a unique advantage to the field of anomaly detection.Unlike rule-based systems that rely on predefined criteria, LLMs possess the capability to identify unexpected or novel attacks, a critical feature in the constantly evolving landscape of cybersecurity threats.This ability to detect anomalies that deviate from known patterns or behaviors allows LLMs to address a broader range of potential attacks.Consequently, integrating LLMs into anomaly detection efforts can significantly reduce the manual labor and complexity involved in continuously updating and maintaining rule-based systems, especially in environments where new and unforeseen attack vectors are a constant challenge.</p>
<p>V. CONCLUSION</p>
<p>This paper proposes the use of LLMs based on the HITL process for cybersecurity in substations, as evaluated by various performance metrics.LLMs are employed as IDSs to identify anomalies in communication protocols.An IDS algorithm is converted to text to train datasets for anomaly detection.In comparison, ChatGPT 4.0 outperformed the two other LLMs in all metrics.This LLM demonstrated better precision and performance at different levels of training.These models have privacy issues regarding confidential data.Thus, using the ToD and fine-tuning are necessary to enhance the accuracy of LLMs.In the future, it will be the intention to consider other LLMs with ToD and fine-tuning processes with more attacks and errors to improve the LLMs' efficiency, along with analyses on all multicast messages in digital substations.</p>
<p>Fig. 1 .
1
Fig. 1.HIL Testbed considering the IDS with human recommendations.</p>
<p>Fig. 2 .
2
Fig. 2. A pre-processing step based on the feature extraction for a log of GOOSE message (actual data from an HIL testbed).</p>
<p>TABLE I A
I
COMPARISON OF DETECTION RESULTS (WITHOUT, PARTIAL AND FULL TERMS SHOW THE LEVELS OF TRAINING PROCESS).
IEC 61850-based CommunicationGOOSELLMsChatGPT 4.0Anthropic's Claude 2Google Bard/PaLM 2MetricsDescriptionwithoutpartialfullwithoutpartialfullwithoutpartialfullTPRA ratio of correct GOOSE anomalies that were correctly identified (also, named recall).78.18%85.45%98.18%78.18%83.64%89.09%74.5%81.8%89.1%FPRA ratio of normal GOOSE data that were wrongly identified as anomalies.48%32%4%56%44%32%56%40%20%FNRA ratio of correct GOOSE anomalies that the system failed to detect.21.82%14.55%1.82%21.82%16.36%10.91%25.5%18.18%10.9%PrecisionMeasures accuracy of detected GOOSE anomalies.78.18%85.45%98.18%75.43%80.7%85.96%74.5%81.8%90.7%F1-ScoreProvides a trade-off between precision and recall.78.18%85.45%98.18%76.78%82.3%87.5%74.5%81.8%90.7%IEC 61850-based CommunicationSVLLMsChatGPT 4.0Anthropic's Claude 2Google Bard/PaLM 2MetricsDescriptionwithoutpartialfullwithoutpartialfullwithoutpartialfullTPRA ratio of correct SV anomalies that were correctly identified (also, named recall).70%95%96.67%50%70%88.3%50%63.3%81.6%FPRA ratio of normal SV data that were wrongly identified as anomalies.50%15%0%50%20%0%50%40%25%FNRA ratio of correct SV anomalies that the system failed to detect.30%5%3.33%50%30%11.67%50%36.6%18.34%PrecisionMeasures accuracy of detected SV anomalies.80.77%95%100%75%91.3%100%75%82.6%91.7%F1-ScoreProvides a trade-off between precision and recall.75%95%98.3%60%79.2%93.8%60%71.7%85.9%</p>
<p>A novel hybrid methodology to secure GOOSE messages against cyberattacks in smart grids. S Hussain, A Iqbal, S S Hussain, S Zanero, A Shikfa, E Ragaini, I Khan, R Alammari, Scientific Reports. 13118572023</p>
<p>Automated cybersecurity tester for IEC 61850-based digital substations. J Hong, T.-J Song, H Lee, A Zaboli, Energies. 152178332022</p>
<p>ChatGPT: Vision and challenges. S S Gill, R Kaur, Internet of Things and Cyber-Physical Systems. 32023</p>
<p>Anomaly detection for cybersecurity of the substations. C.-W Ten, J Hong, C.-C Liu, IEEE Transactions on Smart Grid. 242011</p>
<p>From ChatGPT to ThreatGPT: Impact of Generative AI in cybersecurity and privacy. M Gupta, C Akiri, K Aryal, E Parker, L Praharaj, IEEE Access. 2023</p>
<p>A deep learning-based cyberattack detection system for transmission protective relays. Y M Khaw, A A Jahromi, M F Arani, S Sanner, D Kundur, M Kassouf, IEEE Transactions on Smart Grid. 1232020</p>
<p>Ereno: A framework for generating realistic iec-61850 intrusion detection datasets for smart grids. S E Quincozes, C Albuquerque, D Passos, D Mossé, IEEE Transactions on Dependable and Secure Computing. 2023</p>
<p>Cyber attacks on power grids: Causes and propagation of cascading failures. V S Rajkumar, A ¸tefanov, A Presekal, P Palensky, J L R Torres, IEEE Access. 112023</p>
<p>Unsupervised learning based intrusion detection for GOOSE messages in digital substation. D Jay, H Goyel, U Manickam, G Khare, 2022 22nd National Power Systems Conference (NPSC). IEEE2022</p>
<p>. Openai -Introducing Chatgpt, </p>
<p>. Anthropic -Claude, </p>
<p>Cyber-physical security testbed for substations in a power grid. J Hong, Y Chen, C.-C Liu, M Govindarasu, 2015Cyber Physical Systems Approach to Smart Electric Power Grid</p>            </div>
        </div>

    </div>
</body>
</html>