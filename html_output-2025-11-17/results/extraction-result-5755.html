<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5755 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5755</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5755</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-1a205b0e91393d3f1837ce54fb2e44b56f12169a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1a205b0e91393d3f1837ce54fb2e44b56f12169a" target="_blank">CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model</a></p>
                <p><strong>Paper Venue:</strong> ACS/IEEE International Conference on Computer Systems and Applications</p>
                <p><strong>Paper TL;DR:</strong> It is shown that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the “masked language model” unsupervised training objective, and outperforms state-of-the-art approaches.</p>
                <p><strong>Paper Abstract:</strong> Due to the rising number of sophisticated customer functionalities, electronic control units (ECUs) are increasingly integrated into modern automotive systems. However, the high connectivity between the in-vehicle and the external networks paves the way for hackers who could exploit in-vehicle network protocols' vulnerabilities. Among these protocols, the Controller Area Network (CAN), known as the most widely used in-vehicle networking technology, lacks encryption and authentication mechanisms, making the communications delivered by distributed ECUs insecure. Inspired by the outstanding performance of bidirectional encoder representations from transformers (BERT) for improving many natural language processing tasks, we propose in this paper “CAN-BERT”, a deep learning based network intrusion detection system, to detect cyber attacks on CAN bus protocol. We show that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the “masked language model” unsupervised training objective. The experimental results on the “Car Hacking: Attack & Defense Challenge 2020” dataset show that “CAN-BERT” outperforms state-of-the-art approaches. In addition to being able to identify in-vehicle intrusions in real-time within 0.8 ms to 3 ms w.r.t CAN ID sequence length, it can also detect a wide variety of cyberattacks with an F1-score of between 0.81 and 0.99.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5755.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5755.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAN-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAN-BERT (BERT-based Controller Area Network Intrusion Detection System)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-derived self-supervised intrusion detection model that models ordered CAN arbitration identifier sequences with a masked-language-model objective to detect injected/abnormal CAN IDs in sequence windows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (Transformer encoder) fine-tuned as CAN-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multi-layer bidirectional transformer encoder (CAN-specific instantiation): 4 encoder layers, d_model=256, d_ff=512, single attention head (h=1) reported as sufficient; identifier linear input embedding + sinusoidal positional embeddings; projection head to vocabulary size M and trained with masked language modeling (MLM). Implementation in PyTorch; uses Adam optimizer, dropout=0.1, early stopping.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈3M parameters (reported per-vehicle models: 2,937,422; 3,149,291; 3,163,142)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Self-supervised masked language modeling: during training ~45% of CAN ID tokens are masked (m=0.45) and the model learns to predict masked IDs; at inference the model computes softmax probabilities for masked positions and a sequence is flagged abnormal if the true CAN ID is not within the top-k predicted candidates (paper uses #Candidates=5).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Ordered discrete sequences (sliding windows) of CAN arbitration identifiers (CAN IDs); window lengths T in {16,32,64,128,256}; slide size 1.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Sequence/semantic anomalies caused by message injection: Flooding (mass injection of ID 0x000), Fuzzy (random IDs and payloads), Malfunction (repeated injection of a vehicle-specific functional ID); anomalies manifest as unexpected tokens or disrupted token-order patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Car Hacking: Attack & Defense Challenge 2020 (In-Vehicle Network Intrusion Detection Challenge dataset) — datasets from Chevrolet Spark, Hyundai Sonata, KIA Soul (includes labeled normal and Flooding, Fuzzy, Malfunction attacks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score (precision & recall combined) is the primary metric. Reported CAN-BERT performance: F1 in [0.81, 0.99] across attacks and vehicles (paper highlights ~0.85–0.99 for T >= 32; on very short windows T=16 performance drops to ~0.6–0.9). Also reports inference latency (0.8–3.8 ms per sequence depending on T and vehicle) and model size on disk (20–70 MB).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to PCA, Isolation Forest, and autoencoder baselines (LSTM-AE, BiLSTM-AE), CAN-BERT substantially outperforms traditional ML and AE approaches across most window sizes, especially for medium-to-long sequences (T >= 32). Traditional methods performed poorly and were largely insensitive to sequence length, while AE and CAN-BERT both beat them but CAN-BERT yields the highest F1.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance degrades on very short windows (T=16). Requires normal-only training (unsupervised/one-class setup). Hyperparameter sensitivity: mask ratio m needs tuning (performance dropped when m increased beyond ~0.45 to 0.65). Resource footprint (20–70 MB, ~3M params) requires capable ECUs or cloud deployment. Detection logic (true token not in top-k) depends on chosen k; may produce false positives/negatives if attack resembles normal high-likelihood candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5755.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5755.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Encoder Representations from Transformers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained deep bidirectional transformer encoder that uses masked language modeling to learn representations by conditioning on both left and right context; used here as the architectural and methodological basis for CAN-BERT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bert: Pre-training of deep bidirectional transformers for language understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (bidirectional transformer encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Original BERT is a multi-layer transformer encoder trained with the masked language model (MLM) and next-sentence prediction objectives; in this paper BERT's MLM idea and bidirectional encoder architecture are adapted into a compact CAN-specific model (4 layers, d=256 in CAN-BERT).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified for original BERT in this paper; CAN-specific instantiation ≈3M params</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>MLM-based scoring: mask tokens and predict them; anomalies are identified when the model's predicted high-likelihood tokens do not include the actual token (used as a likelihood/scoring mechanism for sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential discrete data — here applied to CAN ID sequences; the paper also cites prior applications to logs/time-series.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Sequential/semantic anomalies arising from unexpected/misaligned tokens in context.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>This paper leverages BERT methodology; specific numeric performance relates to the CAN-BERT instantiation. Other cited works (refs cited in paper) report F1/AUROC etc., but numbers are not reproduced here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Paper argues BERT's bidirectional conditioning provides better contextual modeling than unidirectional autoregressive models (GPT, RNNs) and shallow bidirectional concatenations, implying fewer false alarms for sequence anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires sufficiently long context to leverage bidirectionality (short windows hurt performance); needs normal training data and careful hyperparameter choices (mask ratio, top-k); computational cost higher than very small classical models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5755.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5755.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autoregressive models (GPT/RNN/Bi-GPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autoregressive sequence models (e.g., GPT, RNNs, Bi-GPT concatenations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Unidirectional next-token-prediction models previously used to model CAN ID sequences by predicting future IDs from past context; the paper discusses their limitations relative to BERT-style bidirectional models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT / RNN (autoregressive) and Bi-GPT concatenations</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Models that predict next token(s) from left context only (RNNs, LSTMs, GPT-style transformers); Bi-GPT and Bi-RNN are shallow concatenations of left-to-right and right-to-left autoregressive models to approximate bidirectionality.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Next-token prediction / autoregressive likelihood scoring: anomalies detected by large prediction error for the next token or breached correlation between successive tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of CAN IDs (time-ordered identifiers).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Sequence anomalies where token-order correlations are broken or unexpected future tokens appear; susceptible to false positives when correlations are legitimately breached.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No numeric results provided in this paper for these models; they are discussed qualitatively. The paper reports that autoregressive models have limitations and have been used in prior works.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Paper claims autoregressive models focus mostly on left context and therefore may miss anomalies that require full (left+right) context; concatenated bidirectional autoregressive approaches (Bi-GPT) are described as weaker than true bidirectional MLM like BERT.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Unidirectional context limitation (access only to left context) can lead to missed anomalies or false alarms; shallow concatenation (Bi-GPT) less effective than true bidirectional models; these models may overemphasize local correlations and thus flag anomalies when correlations change legitimately.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5755.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5755.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT-based anomaly detection (logs/time-series references)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogBERT / LAnoBERT / TS-BERT and related BERT adaptations for anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of referenced works that adapt BERT's masked-language-modeling objective to detect anomalies in structured logs and time series by masking tokens/entries and scoring model surprise to flag anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT variants adapted for logs/time-series (LogBERT, LAnoBERT, TS-BERT, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Adaptations of BERT to domain-specific discrete/temporal data: examples include LogBERT (log anomaly detection via BERT), LAnoBERT (system log anomaly detection with MLM), TS-BERT (pretraining BERT for time series anomaly detection), and layerwise surprise metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Masked token prediction / layerwise surprise scoring / pretraining followed by anomaly scoring on masked positions; often no log parsing or using light preprocessing.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Structured/semi-structured logs, system logs, and time-series sequences (discrete event sequences).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Log/event anomalies, temporal anomalies, unexpected or rare tokens/events in sequence context.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper (cited works report F1, precision/recall, AUROC in their respective evaluations).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>These cited works are given as prior evidence that BERT-style models are effective for sequence anomaly detection; this paper does not re-evaluate them but positions CAN-BERT in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed here; generalized limitations include sensitivity to mask ratio, need for domain-specific tokenization/embedding of discrete events, and computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>How is BERT surprised? Layerwise detection of linguistic anomalies. <em>(Rating: 2)</em></li>
                <li>Logbert: Log anomaly detection via bert. <em>(Rating: 2)</em></li>
                <li>LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model. <em>(Rating: 2)</em></li>
                <li>TS-Bert: Time Series Anomaly Detection via Pretraining Model Bert. <em>(Rating: 2)</em></li>
                <li>Intrusion detection method using bi-directional GPT for in-vehicle controller area networks. <em>(Rating: 2)</em></li>
                <li>Log-based anomaly detection without log parsing. <em>(Rating: 1)</em></li>
                <li>Securing critical infrastructures: Deep-LearningBased threat detection in IIoT. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5755",
    "paper_id": "paper-1a205b0e91393d3f1837ce54fb2e44b56f12169a",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "CAN-BERT",
            "name_full": "CAN-BERT (BERT-based Controller Area Network Intrusion Detection System)",
            "brief_description": "A BERT-derived self-supervised intrusion detection model that models ordered CAN arbitration identifier sequences with a masked-language-model objective to detect injected/abnormal CAN IDs in sequence windows.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BERT (Transformer encoder) fine-tuned as CAN-BERT",
            "model_description": "Multi-layer bidirectional transformer encoder (CAN-specific instantiation): 4 encoder layers, d_model=256, d_ff=512, single attention head (h=1) reported as sufficient; identifier linear input embedding + sinusoidal positional embeddings; projection head to vocabulary size M and trained with masked language modeling (MLM). Implementation in PyTorch; uses Adam optimizer, dropout=0.1, early stopping.",
            "model_size": "≈3M parameters (reported per-vehicle models: 2,937,422; 3,149,291; 3,163,142)",
            "anomaly_detection_method": "Self-supervised masked language modeling: during training ~45% of CAN ID tokens are masked (m=0.45) and the model learns to predict masked IDs; at inference the model computes softmax probabilities for masked positions and a sequence is flagged abnormal if the true CAN ID is not within the top-k predicted candidates (paper uses #Candidates=5).",
            "data_type": "Ordered discrete sequences (sliding windows) of CAN arbitration identifiers (CAN IDs); window lengths T in {16,32,64,128,256}; slide size 1.",
            "anomaly_type": "Sequence/semantic anomalies caused by message injection: Flooding (mass injection of ID 0x000), Fuzzy (random IDs and payloads), Malfunction (repeated injection of a vehicle-specific functional ID); anomalies manifest as unexpected tokens or disrupted token-order patterns.",
            "dataset_name": "Car Hacking: Attack & Defense Challenge 2020 (In-Vehicle Network Intrusion Detection Challenge dataset) — datasets from Chevrolet Spark, Hyundai Sonata, KIA Soul (includes labeled normal and Flooding, Fuzzy, Malfunction attacks).",
            "performance_metrics": "F1-score (precision & recall combined) is the primary metric. Reported CAN-BERT performance: F1 in [0.81, 0.99] across attacks and vehicles (paper highlights ~0.85–0.99 for T &gt;= 32; on very short windows T=16 performance drops to ~0.6–0.9). Also reports inference latency (0.8–3.8 ms per sequence depending on T and vehicle) and model size on disk (20–70 MB).",
            "baseline_comparison": "Compared to PCA, Isolation Forest, and autoencoder baselines (LSTM-AE, BiLSTM-AE), CAN-BERT substantially outperforms traditional ML and AE approaches across most window sizes, especially for medium-to-long sequences (T &gt;= 32). Traditional methods performed poorly and were largely insensitive to sequence length, while AE and CAN-BERT both beat them but CAN-BERT yields the highest F1.",
            "limitations_or_failure_cases": "Performance degrades on very short windows (T=16). Requires normal-only training (unsupervised/one-class setup). Hyperparameter sensitivity: mask ratio m needs tuning (performance dropped when m increased beyond ~0.45 to 0.65). Resource footprint (20–70 MB, ~3M params) requires capable ECUs or cloud deployment. Detection logic (true token not in top-k) depends on chosen k; may produce false positives/negatives if attack resembles normal high-likelihood candidates.",
            "uuid": "e5755.0",
            "source_info": {
                "paper_title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "BERT (general)",
            "name_full": "Bidirectional Encoder Representations from Transformers",
            "brief_description": "A pretrained deep bidirectional transformer encoder that uses masked language modeling to learn representations by conditioning on both left and right context; used here as the architectural and methodological basis for CAN-BERT.",
            "citation_title": "Bert: Pre-training of deep bidirectional transformers for language understanding.",
            "mention_or_use": "use",
            "model_name": "BERT (bidirectional transformer encoder)",
            "model_description": "Original BERT is a multi-layer transformer encoder trained with the masked language model (MLM) and next-sentence prediction objectives; in this paper BERT's MLM idea and bidirectional encoder architecture are adapted into a compact CAN-specific model (4 layers, d=256 in CAN-BERT).",
            "model_size": "not specified for original BERT in this paper; CAN-specific instantiation ≈3M params",
            "anomaly_detection_method": "MLM-based scoring: mask tokens and predict them; anomalies are identified when the model's predicted high-likelihood tokens do not include the actual token (used as a likelihood/scoring mechanism for sequences).",
            "data_type": "Sequential discrete data — here applied to CAN ID sequences; the paper also cites prior applications to logs/time-series.",
            "anomaly_type": "Sequential/semantic anomalies arising from unexpected/misaligned tokens in context.",
            "dataset_name": null,
            "performance_metrics": "This paper leverages BERT methodology; specific numeric performance relates to the CAN-BERT instantiation. Other cited works (refs cited in paper) report F1/AUROC etc., but numbers are not reproduced here.",
            "baseline_comparison": "Paper argues BERT's bidirectional conditioning provides better contextual modeling than unidirectional autoregressive models (GPT, RNNs) and shallow bidirectional concatenations, implying fewer false alarms for sequence anomalies.",
            "limitations_or_failure_cases": "Requires sufficiently long context to leverage bidirectionality (short windows hurt performance); needs normal training data and careful hyperparameter choices (mask ratio, top-k); computational cost higher than very small classical models.",
            "uuid": "e5755.1",
            "source_info": {
                "paper_title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Autoregressive models (GPT/RNN/Bi-GPT)",
            "name_full": "Autoregressive sequence models (e.g., GPT, RNNs, Bi-GPT concatenations)",
            "brief_description": "Unidirectional next-token-prediction models previously used to model CAN ID sequences by predicting future IDs from past context; the paper discusses their limitations relative to BERT-style bidirectional models.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT / RNN (autoregressive) and Bi-GPT concatenations",
            "model_description": "Models that predict next token(s) from left context only (RNNs, LSTMs, GPT-style transformers); Bi-GPT and Bi-RNN are shallow concatenations of left-to-right and right-to-left autoregressive models to approximate bidirectionality.",
            "model_size": null,
            "anomaly_detection_method": "Next-token prediction / autoregressive likelihood scoring: anomalies detected by large prediction error for the next token or breached correlation between successive tokens.",
            "data_type": "Sequences of CAN IDs (time-ordered identifiers).",
            "anomaly_type": "Sequence anomalies where token-order correlations are broken or unexpected future tokens appear; susceptible to false positives when correlations are legitimately breached.",
            "dataset_name": null,
            "performance_metrics": "No numeric results provided in this paper for these models; they are discussed qualitatively. The paper reports that autoregressive models have limitations and have been used in prior works.",
            "baseline_comparison": "Paper claims autoregressive models focus mostly on left context and therefore may miss anomalies that require full (left+right) context; concatenated bidirectional autoregressive approaches (Bi-GPT) are described as weaker than true bidirectional MLM like BERT.",
            "limitations_or_failure_cases": "Unidirectional context limitation (access only to left context) can lead to missed anomalies or false alarms; shallow concatenation (Bi-GPT) less effective than true bidirectional models; these models may overemphasize local correlations and thus flag anomalies when correlations change legitimately.",
            "uuid": "e5755.2",
            "source_info": {
                "paper_title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "BERT-based anomaly detection (logs/time-series references)",
            "name_full": "LogBERT / LAnoBERT / TS-BERT and related BERT adaptations for anomaly detection",
            "brief_description": "A set of referenced works that adapt BERT's masked-language-modeling objective to detect anomalies in structured logs and time series by masking tokens/entries and scoring model surprise to flag anomalies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "BERT variants adapted for logs/time-series (LogBERT, LAnoBERT, TS-BERT, etc.)",
            "model_description": "Adaptations of BERT to domain-specific discrete/temporal data: examples include LogBERT (log anomaly detection via BERT), LAnoBERT (system log anomaly detection with MLM), TS-BERT (pretraining BERT for time series anomaly detection), and layerwise surprise metrics.",
            "model_size": null,
            "anomaly_detection_method": "Masked token prediction / layerwise surprise scoring / pretraining followed by anomaly scoring on masked positions; often no log parsing or using light preprocessing.",
            "data_type": "Structured/semi-structured logs, system logs, and time-series sequences (discrete event sequences).",
            "anomaly_type": "Log/event anomalies, temporal anomalies, unexpected or rare tokens/events in sequence context.",
            "dataset_name": null,
            "performance_metrics": "Not reported in this paper (cited works report F1, precision/recall, AUROC in their respective evaluations).",
            "baseline_comparison": "These cited works are given as prior evidence that BERT-style models are effective for sequence anomaly detection; this paper does not re-evaluate them but positions CAN-BERT in this context.",
            "limitations_or_failure_cases": "Not detailed here; generalized limitations include sensitivity to mask ratio, need for domain-specific tokenization/embedding of discrete events, and computational cost.",
            "uuid": "e5755.3",
            "source_info": {
                "paper_title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model",
                "publication_date_yy_mm": "2022-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "How is BERT surprised? Layerwise detection of linguistic anomalies.",
            "rating": 2
        },
        {
            "paper_title": "Logbert: Log anomaly detection via bert.",
            "rating": 2
        },
        {
            "paper_title": "LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model.",
            "rating": 2
        },
        {
            "paper_title": "TS-Bert: Time Series Anomaly Detection via Pretraining Model Bert.",
            "rating": 2
        },
        {
            "paper_title": "Intrusion detection method using bi-directional GPT for in-vehicle controller area networks.",
            "rating": 2
        },
        {
            "paper_title": "Log-based anomaly detection without log parsing.",
            "rating": 1
        },
        {
            "paper_title": "Securing critical infrastructures: Deep-LearningBased threat detection in IIoT.",
            "rating": 1
        }
    ],
    "cost": 0.01425625,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model</h1>
<p>Natasha Alkhatib, Maria Mushtaq, Hadi Ghauch, Jean-Luc Danger<br>Télécom Paris, IP Paris, Palaiseau, France<br>{natasha.alkhatib, maria.mushtaq, hadi.ghauch, jean-luc.danger}@telecom-paris.fr</p>
<h4>Abstract</h4>
<p>Due to the rising number of sophisticated customer functionalities, electronic control units (ECUs) are increasingly integrated into modern automotive systems. However, the high connectivity between the in-vehicle and the external networks paves the way for hackers who could exploit in-vehicle network protocols' vulnerabilities. Among these protocols, the Controller Area Network (CAN), known as the most widely used invehicle networking technology, lacks encryption and authentication mechanisms, making the communications delivered by distributed ECUs insecure. Inspired by the outstanding performance of bidirectional encoder representations from transformers (BERT) for improving many natural language processing tasks, we propose in this paper "CAN-BERT", a deep learning based network intrusion detection system, to detect cyber attacks on CAN bus protocol. We show that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the "masked language model" unsupervised training objective. The experimental results on the "Car Hacking: Attack \&amp; Defense Challenge 2020" dataset show that "CAN-BERT" outperforms state-of-the-art approaches. In addition to being able to identify in-vehicle intrusions in realtime within 0.8 ms to 3 ms w.r.t CAN ID sequence length, it can also detect a wide variety of cyberattacks with an F1-score of between 0.81 and 0.99 .</p>
<p>Index Terms-controller area network, CAN, Intrusion Detection, bidirectional encoder representations from transformers, BERT, in-vehicle network, cyberattacks.</p>
<h2>I. InTRODUCTION</h2>
<p>To fulfill automotive features, the Controller Area Network (CAN) bus is widely used as the de-facto standard for message communication between different electronic control units (ECUs) in today's vehicles. It is sometimes referred to as a "message-based" system, since it focuses on the transmission of diagnostic, informative and controlling data through messages, also known as CAN data frames. In fact, while developing a vehicle, all conceivable CAN bus messages and their respective priority, encoded into an identifier called "CAN ID", must be determined beforehand. Due to the lack of authentication, any device can connect physically or wirelessly to the CAN bus, broadcast CAN data frames, and all the participants on the CAN bus can receive it without verifying its source. Consequently, since CAN security was not a design priority, many message injection attacks have become widely implemented. These attacks can interfere with the desired function of the system, shut down some connected nodes,
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. A CAN bus network exploited by attackers through different physical and wireless interfaces.
and make the vehicle behave abnormally, putting at risk the safety of the driver and the passengers. To address these security flaws, researchers have proposed intrusion detection as a supplementary layer of protection to specialized security solutions. By monitoring the communication between different ECUs within a CAN bus system, a network intrusion detection system (N-IDS) can detect deviations from the normal message exchange behavior and, thereby, identify both anticipated and novel cyberattacks. The adoption of deep neural networks for in-vehicle intrusion detection have lately proliferated, with impressive results. Since a message injection attack can alter the normal order of occurence of several CAN IDs, researchers have deployed deep learning based sequential models, to model the CAN ID sequences. Some studies have proposed the use of autoregressive models that are trained to capture the patterns of regular CAN ID sequences by predicting the future CAN ID sequence based on the preceding one, such as recurrent neural network (RNN) models and its variants and the generative pretrained transformer (GPT). However, these models identify malicious network intrusions on CAN ID traffic by focusing primarily on the exchange of CAN ID messages from earlier steps rather than integrating the left and right context of a CAN ID sequence, limiting the model's capacity to grasp the whole context information representation. Additionally, these algorithms focus largely on the correlation</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. CAN packet structure.</p>
<p>between CAN ID messages in normal sequences, which would result in false alarms for intrusion detection whenever the correlation is breached. Hence, due to these limitations, the autoregressive models do not adequately depict the natural communication behavior between the various ECUs.</p>
<p>To address these challenges, we propose CAN-BERT, an intrusion detection system based on a language representation model called Bidirectional Encoder Representations from Transformers (BERT). CAN-BERT, in contrast to autoregressive models, is a self-supervised model which can successfully depict deep bidirectional representations from CAN ID sequences by conditioning on both left and right context in its various layers. By using the "masked language model" unsupervised training objective, CAN-BERT model masks some of the CAN IDs in the input at random, with the goal of predicting the conventional ID of the masked word based on its left and right context.</p>
<p>We evaluate our approach using the recently published "Car Hacking: Attack &amp; Defense Challenge 2020" collected from three different cars, Chevrolet Spark, Hyundai Sonata and Kia Soul and which contains diverse types of message injection attacks.</p>
<p>Our contributions are summarized below:</p>
<ul>
<li>Inspired by the outstanding performance of BERT model for improving many natural language processing tasks, we propose "CAN-BERT", a novel BERT-based intrusion detection system architecture which can detect known and unprecedented cyberattacks in CAN ID sequences.</li>
<li>We evaluate the performance of our approach with the recently published "Car Hacking: Attack &amp; Defense Challenge 2020" collected from three different cars, Chevrolet Spark, Hyundai Sonata and KIA Soul and which contains diverse types of message injection attacks. We also compare our model with other baseline models.</li>
</ul>
<p>Towards this end, our paper is organized into six sections. In Section III, we present an overview of the Controller Area Network (CAN) and the Bidirectional Encoder Representations from Transformers model (BERT). In Section IV, we present an overview of our proposed framework "CAN-BERT". Section V discusses the launched experiments with the corresponding dataset and the proposed metrics for IDS' evaluation. In Section VI, we discuss the obtained results showing the proposed model accuracy and complexity. Finally, we conclude our paper with future work direction.</p>
<h2>II. RELATED WORK</h2>
<p>Intrusion Detection systems (IDSs) have been widely used to detect intrusions on the Controller Area Network (CAN). Intrusions can be detected either by inspecting the content or the signals transmitted by CAN data frames [19], or by examining the order by which different CAN data frames' identifiers are exchanged between the ECUs [20].</p>
<h2>III. PRELIMINARIES</h2>
<h3>A. Controller Area Network</h3>
<p>The Controller Area Network (CAN), created by BOSCH in 1983, is a potent networking technology essential for the development of useful automotive features. Due to its robustness represented by its ability to allow various ECUs to be connected in almost all areas of a car, it still prevails in vehicles today. As seen in Figure, it is a bus system, meaning that all Electronic Control Units (ECUs) share the same wiring.</p>
<p>It is a "message-based" system in which messages, also known as CAN data frames, are transmitted between various ECUs. As depicted in Figure. 2, each CAN data frame is composed of the following elements: Start of frame (SOF), identifier (ID), Remote frame transmission field (RTR), control field, data, cyclic redundancy check (CRC), delimiters (DEL) and acknowledgment fields (ACK), and end of frame fields. Each CAN bus message has a priority that is represented by the arbitration identifier field (ID) that can either be composed of 11 or 29 bits, depending on the car manufacturer and which will be mainly used in our work for detecting in-vehicle intrusions.</p>
<p>To avoid contention between multiple ECUs willing to transmit CAN messages in the medium, CAN employs a priority-based mechanism which allows the ECU with the highest priority/lowest value identifier to transmit before others. The procedure is termed "arbitration" because the message with the highest priority wins out over competing messages with a lower priority at the time of transmission.</p>
<p>1) Security Weaknesses: CAN does not prohibit several ECUs from sharing the same IDs. Moreover, CAN messages are broadcast and do not contain any sender's address. Consequently, any device linked to the CAN bus can use any predefined ID, communicate its message without authentication or encryption, and all associated ECUs can receive it. The receiver defines whether or not a message identification causes the receiving ECU to retain and process the given data. Consequently, an attacker is able to broadcast spoofed CAN messages, eavesdrop on all the CAN traffic and collect detailed</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. ECU devices connected through CAN bus, source [1].</p>
<p>information about it, resulting in Fuzzing and Malfunction attacks.</p>
<p>Additionally, as previously mentioned, the CAN bus leverages the arbitration method which discerns between "dominant" (0) and "recessive" (1) bits in the message identifiers. Therefore, if several ECUs begin transmitting simultaneously, the ECU whose message begins with a greater number of dominant "0" bits will take over the CAN bus. As soon as a unit detects that the message on the bus is no longer the message it is transmitting, it halts its transmission, waits for the real transmission to conclude, then waits for the interframe gap to expire and retransmits its message. This phenomenon carries the risk that a message with a lower priority will never be delivered if the network is very congested and can be exploited by attackers to launch denial of service (DoS)/flooding attacks.</p>
<h2><em>B. BERT</em></h2>
<p>Bidirectional Encoder Representations from Transformers (BERT), proposed by Devlin et al. [2], is a state-of-the-art language representation model which is designed to pretrain bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. Regarding its architecture, it is a multi-layer bidirectional transformer encoder based on the original implementation proposed by Vaswani et al. [3].</p>
<p>Inspired by its outstanding performance in modeling sequential data, BERT is recently employed for sequence anomaly detection [6] [7] [8] [9] [10]. To the best of our knowledge, none of the previous works have evaluated the performance of the BERT model for in-vehicle intrusion detection on CAN protocol.</p>
<p>In order to detect anomalies in sequences, it's crucial to incorporate context from both left and right directions of the sequence. Sequential anomalies may be misdetected by traditional unidirectional models, such as OpenAI GPT and RNNs, where every token can only attend to context to its left. To solve this significant constraint, some researchers have proposed a shallow concatenation of both left-to-right and right-to-left architecture of the autoregressive models, such as Bi-RNN and Bi-GPT [5]. However, these approaches aren't as powerful as BERT which adopts a "masked language model" (MLM) training objective, in which input sequence tokens are randomly masked and the goal is to predict the original vocabulary id of the masked word based on its context. In contrast to denoising auto-encoders, BERT predicts the masked words instead of reconstructing the whole sequence [12].</p>
<h2>IV. PROPOSED FRAMEWORK: CAN-BERT</h2>
<p>We propose "CAN-BERT", a pattern-based anomaly detection algorithm, which leverages a BERT-based architecture to detect message injection intrusions in the CAN bus. As seen in Figure. 4, our model is composed of a multi-layer bidirectional transformer encoder and is trained using the "masked language model" self-supervised task to model normal CAN ID sequences. The following subsections elaborately describe the suggested framework.</p>
<h3><em>A. Model description</em></h3>
<p>Note that $$S = [id_1, ..., id_t, ..., id_T]$$ is an observed sequence of <em>T</em> CAN identifiers, arranged in their order of transmission in the CAN bus network, where an identifier $$id_t \in \mathbb{ID}$$ is an M-dimensional vector which denotes the CAN ID transmitted at time <em>t</em> by an ECU, $$\mathbb{ID}$$ indicates the set of CAN IDs extracted from CAN messages, and M is the size of the $$\mathbb{ID}$$ set.</p>
<p>Since anomaly detection is an unsupervised learning-based technique in which only normal data are used for training, a collection of <em>N</em> CAN ID sequences, represented as $$\mathbb{D}<em j="j">{training} = {S_1, ..., S</em>}$$, is solely used as a training dataset.}, ..., S_{N</p>
<p>Identifier Embeddings To feed the appropriate input to the BERT model, each identifier $$id_i^j$$ with size (M,1) in a CAN sequence $$S^j$$ is firstly projected into a <em>d</em>-dimensional space using a single linear layer, i.e.:</p>
<p>$$e_i^j = W^e id_i^j + b^e, \forall i \in {1..T}, \forall j \in {1..N} \tag{1}$$</p>
<p>where $$e_i^j$$ represents the identifier embedding with size (<em>d</em>,1), $$W^e \in \mathbb{R}^d \times M$$ is the input embedding weight matrix, and $$b^e \in \mathbb{R}^d$$ denotes the bias. Both $$W^e$$ and $$b^e$$ are trainable parameters.</p>
<p>Subsequently, the identifier's position is encoded into a <em>d</em>-dimensional positional embedding $$p_i^j$$ using a sinusoidal function. To this end, the CAN ID, fed into the CAN-BERT model, is a summation of both the positional encoding and the input embedding:</p>
<p>$$x_i^j = e_i^j + p_i^j \tag{2}$$</p>
<p>where $$x_i^j$$ is the total embedding <em>j</em>-th identifier in the <em>t</em>-th CAN ID sequence $$id_i^j$$, thereby the convergence of the input sequence $$S^j$$ into $$X^j = [x_1^j, ..., x_T^j] T$$ with $$X^j$$ a matrix with size <em>T</em> × <em>d</em>.</p>
<p>Transformer Encoder The encoded input $$X^j$$ is then delivered into a stack of <em>L</em> transformer encoder layers, each of which has two sub-layers: a multi-head self-attention mechanism and a position-wise feed-forward network [3]. A residual connection is employed around each of these two sub-layers, followed by layer normalization [4], as follows:</p>
<p>$$\begin{gathered} \mathbf{E}^{(j,l)} = g(\mathbf{X}^{(j,l)}) + f(\mathbf{X}^{(j,l)} + g(\mathbf{X}^{(j,l)})) \ \mathbf{H}^{(j,l)} = z(\mathbf{E}^{(j,l)}) + f(\mathbf{E}^{(j,l)} + z(\mathbf{E}^{(j,l)})) \ \mathbf{X}^{(j,l+1)} = \mathbf{H}^{(j,l)}, \forall l &lt; L \end{gathered} \tag{3}$$</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. CAN-BERT model architecture</p>
<p>where <strong>E</strong><sup>(j,l)</sup> represents the output of the first sublayer for the l-th transformer encoder layer with size T×d, <strong>H</strong><sup>(j,l)</sup> represents the output of the second sublayer for the l-th transformer encoder layer with size T×d, g is the multi-head attention function, z is the position wise feed forward function, and f is the layer normalization function.</p>
<p><strong>Attention</strong> We use the scaled dot-product attention proposed by [3], requiring query <strong>Q</strong><sup>(j,l)</sup>, key <strong>K</strong><sup>(j,l)</sup>, and value <strong>V</strong><sup>(j,l)</sup> representations, and which are projections of the embedded sequence <strong>X</strong><sup>(j,l)</sup> ∈ <strong>R</strong><sup>T×d</sup>. In fact, we leverage the dot-product similarity to compare the query representation of a given CAN identifier to all other keys. Hence, if the query and key are comparable have a high attention weight, the matching value is deemed to be relevant. The output is therefore computed as a weighted sum of the values <strong>V</strong>:</p>
<p>$$
\text{Attn}(\mathbf{Q}^{(j,l)}, \mathbf{K}^{(j,l)}, \mathbf{V}^{(j,l)}) = \sigma(\frac{\mathbf{Q}^{(j,l)}\mathbf{K}^{(j,l)T}}{\sqrt{d}}) \mathbf{V}^{(j,l)}
\tag
$$</p>
<p>Attn( <strong>Q</strong><sup>(j,l)</sup>, <strong>K</strong><sup>(j,l)</sup>, <strong>V</strong><sup>(j,l)</sup>) = <strong>AV</strong><sup>(j,l)</sup></p>
<p>where σ is the softmax function, <strong>A</strong> ∈ <strong>R</strong><sup>T×T</sup> denotes the attention weight matrix containing attention weights, and d is the dimension of the <strong>Q</strong><sup>(j,l)</sup>, <strong>K</strong><sup>(j,l)</sup>, <strong>V</strong><sup>(j,l)</sup> vectors.</p>
<p>As described by [3], the multiple heads of attention allows the model to concurrently capture diverse aspects of data at distinct CAN IDs. Hence, we adopt a multi-head attention (MHA) mechanism in which the d-dimensional CAN identifiers are projected into subspaces calculated by different attention heads n ∈ {1, .., H}:</p>
<p>$$
\begin{aligned}
\mathbf{Q}^{(j,n,l)} &amp;= \mathbf{X}^{(j,l)} \mathbf{W}^{(Q,n)}, \mathbf{Q}^{(j,n,l)} \in \mathbb{R}^{T \times F} \
\mathbf{K}^{(j,n,l)} &amp;= \mathbf{X}^{(j,l)} \mathbf{W}^{(K,n)}, \mathbf{K}^{(j,n,l)} \in \mathbb{R}^{T \times F} \
\mathbf{V}^{(j,n,l)} &amp;= \mathbf{X}^{(j,l)} \mathbf{W}^{(V,n)}, \mathbf{V}^{(j,n,l)} \in \mathbb{R}^{T \times F}
\end{aligned}
\tag
$$</p>
<p>where <strong>Q</strong><sup>(j,n,l)</sup>, <strong>K</strong><sup>(j,n,l)</sup> and <strong>V</strong><sup>(j,n,l)</sup> are the query, key and value vectors, respectively of the j-th CAN ID sequence for the l-th transformer encoder layer and which are calculated using the n-th attention head. The <strong>W</strong><sup>(Q,n)</sup>, <strong>W</strong><sup>(K,n)</sup> and <strong>W</strong><sup>(V,n)</sup> are their corresponding trainable weight matrices ∈ <strong>R</strong><sup>d×F</sup>, and F is set to D/H. The results are then concatenated and projected back into representation space using the weight matrix <strong>W</strong><sup>o</sup> ∈ <strong>R</strong><sup>HF×D</sup> as follows:</p>
<p>$$
\text{head}_{n}^{(j,l)} = \text{Attn}(\mathbf{Q}^{(j,n,l)}, \mathbf{K}^{(j,n,l)}, \mathbf{V}^{(j,n,l)})
\tag
$$</p>
<p>$$
\overline{\mathbf{X}}^{(j,l)} = [\text{head}<em n="n">{1}^{(j,l)}, ..\text{head}</em>^O
\tag
$$}^{(j,l)}, .., \text{head}_{H}^{(j,l)}] \mathbf{W</p>
<p>where <strong>X</strong><sup>(j,l)</sup> ∈ <strong>R</strong><sup>(T,d)</sup>.</p>
<p><strong>Position-wise feed-forward</strong> A position-wise feed-forward network with a ReLU activation is thereby applied to each representation in each of the layers of our encoder, in addition to attention sub-layers, using the following equation:</p>
<p>$$
z(\mathbf{E}^{(j,l)}) = [\mathbf{W}<em>1 \mathbf{E}^{(j,l)}]</em>+ \circ \mathbf{W}_2
\tag
$$</p>
<p>where <strong>E</strong><sup>(j,l)</sup> is previously defined in (3), <strong>W</strong><sup>1</sup> and <strong>W</strong><sup>2</sup> are trainable projection matrices, where ○ is the hadarmard product, and ||<sup>+</sup> is the element-wise maximum.</p>
<p>After passing through different transformer layers, the L-th contextual embedding vectors of the CAN IDs, denoted as <strong>h</strong><sup>(j,L)</sup><sub>i</sub> with size (d, 1) ∈ <strong>H</strong><sup>(j,L)</sup> = [<strong>h</strong><sup>(j,L)</sup><sub>i</sub>, .., <strong>h</strong><sup>(j,L)</sup><sub>T</sub>]<sup>T</sup>, are fed into a single linear layer which projects them back to the M-dimensional layer, as follows:</p>
<p>$$
\mathbf{m}_1^l = \mathbf{W}^m \mathbf{h}_i^{(j,L)} + \mathbf{b}^m, \forall i \in {1..T}, \forall j \in {1..N}
\tag
$$</p>
<p>where <strong>m</strong><sup>1</sup><sub>i</sub> represents the projected output with size (M, 1), <strong>W</strong><sup>m</sup> ∈ <strong>R</strong><sup>M×d</sup> is the input embedding weight matrix, and <strong>b</strong><sup>e</sup> ∈ <strong>R</strong><sup>M</sup> denotes the bias. Both <strong>W</strong><sup>m</sup> and <strong>b</strong><sup>m</sup> are trainable parameters.</p>
<h4><em>B. Training and Inference</em></h4>
<p>We use the masked language model training method to train the CAN-BERT model on capturing the patterns of normal CAN ID sequences. Hence, CAN sequences with random</p>
<p>mask as inputs, where we randomly replace a ratio of CAN IDs in a sequence with a specific MASK token, are fed into CAN-BERT. The purpose of training is to reliably anticipate the CAN IDs that have been randomly masked.</p>
<p>To achieve that, we feed the contextual embedding vector of the $u$-th MASK in the j-th CAN ID sequence $\mathbf{m}<em u="u">{MASK</em>$:}}^{j}$ to a softmax function, which will return a probability distribution for the whole set of CAN IDs $\mathbb{ID</p>
<p>$\hat{\mathbf{y}}<em u="u">{[MASK</em>}]}^{j}=\sigma(\mathbf{W}^{c}\mathbf{m<em u="u">{[MASK</em>)$}]}^{j}+\mathbf{b}^{c</p>
<p>where $\hat{\mathbf{y}}<em u="u">{[MASK</em>}]}^{j}$ is an $m$-dimensional vector, $\sigma$ is the softmax function, $\mathbf{m<em u="u">{[MASK</em>$ are trainable parameters.}]}^{j}$ and $\mathbf{b}^{c</p>
<p>CAN-BERT is trained to minimize the cross entropy loss over a batch of $I$ sequences ( with $I\leq N$), for masked CAN ID prediction, which is defined as:</p>
<p>$\mathcal{L}<em j="1">{MASK}=-\frac{1}{IR}\sum</em>}^{N}\sum_{u=1}^{R}\mathbf{y<em u="u">{[MASK</em>}]}^{j}log\hat{\mathbf{y}<em u="u">{[MASK</em>$}]}^{j</p>
<p>where the ground-truth $u$-th CAN ID in the $j$-th sequence is denoted as $\mathbf{y}<em u="u">{[MASK</em>$, $R$ is the total number of masked tokens in the $j$-th sequence, and $N$ is the number of training samples.}]}^{j</p>
<p>By modeling the normal exchange of messages through CAN bus using CAN-BERT, our model is expected, after training, to predict a candidate set with the normal CAN IDs having the highest likelihood for each masked token. Hence, for a randomly masked testing sequence, we calculate the probability distribution represented in (10), for each masked CAN ID. Therefore, if the actual CAN ID is among the anticipated candidates, the corresponding CAN ID sequence is considered as normal. Otherwise, it is deemed abnormal.</p>
<h2>V. EXPERIMENTAL SETTINGS</h2>
<h3>V-A. Dataset</h3>
<p>To assess the proposed CAN-BERT, we leverage the “In-Vehicle Network Intrusion Detection Challenge” dataset [13] (presented in Table I), which was used at the “In-vehicle Network Intrusion Detection track” of ‘Information Security R&amp;D Data Challenge 2019. It includes normal and abnormal in-vehicle network traffic data of HYUNDAI Sonata, KIA Soul, and CHEVROLET Spark vehicles collected during their stationary state. We have mainly used its preliminary dataset, which includes three types of attacks (Flooding, Fuzzy, and Malfunction). The dataset is labeled and each sample is represented by the following features: “Timestamp” representing the logging time, “CAN ID” representing the CAN Identifier, “DLC” indicating the Data length code, and the Payload indicating the “CAN data” field.</p>
<h4>V-A1) Attacks</h4>
<p>The dataset contains the following attacks:</p>
<ul>
<li>Flooding Attack The flooding attack was carried out by injecting many messages with the CAN ID set to 0x000 into the CAN network. Consequently, an ECU that transmits CAN data frames with such CAN ID dominates the CAN bus, which could restrict the communications among the ECU nodes and impair normal in-vehicle functions.</li>
<li>Fuzzy Attack To implement fuzzy attacks, the attacker injected every 0.0003 seconds random CAN packets, for both the ID field and the Data field. This process lead to abnormal automotive functionalities behavior such as short beeping sound repeatedly occurring, the heater turning on, etc.</li>
<li>Malfunction Attack The malfunction attack was carried out by injecting messages with a specified CAN ID from among the extractable CAN IDs of a particular vehicle in order to disable relevant automotive functions, such as IDs 0×316, 0×153 and 0×18E for the HYUNDAI YF Sonata, KIA Soul, and CHEVROLET Spark vehicles, respectively.</li>
</ul>
<p>TABLE I
IN-VEHICLE NETWORK INTRUSION DETECTION DATASET</p>
<table>
<thead>
<tr>
<th>Vehicle</th>
<th>Dataset</th>
<th># Normal packets</th>
<th># Abnormal packets</th>
<th>Size (MB)</th>
</tr>
</thead>
<tbody>
<tr>
<td>CHEVROLET Spark</td>
<td>Attack Free</td>
<td>136,933</td>
<td>N/A</td>
<td>6.2</td>
</tr>
<tr>
<td></td>
<td>Flooding</td>
<td>70,001</td>
<td>14,999</td>
<td>4.2</td>
</tr>
<tr>
<td></td>
<td>Fuzzy</td>
<td>37,957</td>
<td>3,043</td>
<td>2.0</td>
</tr>
<tr>
<td></td>
<td>Malfunction</td>
<td>47,005</td>
<td>3,995</td>
<td>2.5</td>
</tr>
<tr>
<td>HYUNDAI Sonata</td>
<td>Attack Free</td>
<td>117,172</td>
<td>N/A</td>
<td>5.8</td>
</tr>
<tr>
<td></td>
<td>Flooding</td>
<td>78,907</td>
<td>17,093</td>
<td>4.9</td>
</tr>
<tr>
<td></td>
<td>Fuzzy</td>
<td>78,905</td>
<td>9,095</td>
<td>4.5</td>
</tr>
<tr>
<td></td>
<td>Malfunction</td>
<td>78,798</td>
<td>8,202</td>
<td>4.5</td>
</tr>
<tr>
<td>KIA Soul</td>
<td>Attack Free</td>
<td>192,515</td>
<td>N/A</td>
<td>9.3</td>
</tr>
<tr>
<td></td>
<td>Flooding</td>
<td>103,928</td>
<td>16,072</td>
<td>6.2</td>
</tr>
<tr>
<td></td>
<td>Fuzzy</td>
<td>122,387</td>
<td>21,613</td>
<td>7.4</td>
</tr>
<tr>
<td></td>
<td>Malfunction</td>
<td>108,230</td>
<td>4,770</td>
<td>5.8</td>
</tr>
</tbody>
</table>
<p>As mentioned in Section IV, we aim to detect if a sequence of ordered CAN ID contains injected messages. Hence, in order to represent CAN ID sequences, we use the Feature-based Sliding Window (FSW) to group CAN IDs which belong to the dataset into subsequences with fixed window size $\mathbf{T}$, where $\mathbf{T}\in{16,32,64,128,256}$ and the slide size is 1. Moreover, each CAN ID sequence $\mathbf{S}=[\mathbf{i}\mathbf{d}<em t="t">{1},...,\mathbf{i}\mathbf{d}</em>},...,\mathbf{i}\mathbf{d<em 1="1">{T}]$ has its corresponding labels represented by $\mathbf{Y}=[\mathbf{y}</em>},...,\mathbf{y<em T="T">{t},...,\mathbf{y}</em>}]$ wherein each identifier $\mathbf{i}\mathbf{d<em t="t">{t}\in\mathbf{S}$ is labeled as $\mathbf{y}</em>}=1$ if $\mathbf{i}\mathbf{d<em t="t">{t}$ is an injected identifier in $\mathbf{S}$ or as $\mathbf{y}</em>=0$ otherwise. However, to identify the state of each sequence, we have used the following criteria:</p>
<p>[ z=\begin{cases}1\text{ (abnormal)} &amp; \text{if }\exists\mathbf{y}_{t}=1,\forall t\in{1,..,T} \0\text{ (normal)} &amp; \text{otherwise }\end{cases} ]</p>
<p>where $z$ is the CAN ID sequence’s label.</p>
<h3>V-B. Benchmark Models</h3>
<p>The benchmark models for evaluating the performance of different CAN ID sequence anomaly detection algorithms with CAN-BERT on the chosen dataset, are detailed in this section.</p>
<ul>
<li>Principal Component Analysis (PCA): PCA [14] is a feature selection model which can be used to reduce data features from $m$ dimensions to $n$. Inverting the PCA transform does not retrieve the data lost during the application of the transform. The essence of PCA-based anomaly identification is that an anomalous sample</li>
</ul>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. Hyperparameter tuning the mask ratio m and the number of attention heads h on the "CHEVROLET Spark" dataset for T=32. We have obtained similar behavior pattern for the results w.r.t other sequence length and car types.</p>
<p>should have more loss or reconstruction error than a normal sample. In other words, the loss sustained when an anomalous sample is processed by a PCA algorithm and projected back to its dimension using PCA also should be greater than when the same procedure is performed on a normal sample.</p>
<ul>
<li><strong>Isolation Forest (iForest):</strong> Isolation forest (IF), proposed by Liu at al. [15], detects anomalies using isolation rather than modelling the normal points. In fact, this technique presents a novel approach for isolating anomalies using binary trees, providing a new prospect for a speedier anomaly detector that directly targets abnormalities rather than profiling all regular instances.</li>
<li><strong>Autoencoder (AE):</strong> The autoencoder, introduced by Rumelhart et al. [16], is a deep learning based algorithm which seeks to learn a low-dimensional feature representation space suitable for reconstructing the provided data instances. During the encoding process, the encoder maps the original data onto low-dimensional feature space, while the decoder tries to retrieve the original data from the projected low-dimensional space. Reconstruction loss functions are used to learn the parameters of the encoder and decoder networks. Its reconstruction error value must be minimized during the training of normal instances and therefore used during testing as an anomaly score. In other words, compared to the typical data reconstruction error, anomalies that differ from the majority of the data have a large data reconstruction error. In our experiments, we have tested Long short-term based memory (LSTM) and Bidirectional LSTM (BiLSTM) models with different network hyperparameters: BiLSTM-AE-4 (with 4 layers), LSTM-AE-4 (with 4 layers), and LSTM-AE-8 (with 8 layers).</li>
</ul>
<h2><em>C. Evaluation metrics</em></h2>
<p>For measuring the performance of different anomaly-based IDS, we use the F1-score metric, a weighted average result of both metrics precision and recall and which is specifically used when the dataset is imbalanced. The model has a large predictive power if the F1-score is near 1.0.</p>
<p>Precision is the ratio of correctly classified predicted abnormal observations of all the observations in the predicted class.</p>
<p>$$Precision = \frac{TP}{TP + FP} \tag{12}$$</p>
<p>Recall is the ratio of correctly predicted abnormal observations of all observations in the actual class.</p>
<p>$$Recall = \frac{TP}{TP + FN} \tag{13}$$</p>
<p>Hence, the F1-score is calculated using the following equation:</p>
<p>$$F1 - score = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} \tag{14}$$</p>
<p>Where: TP= True Positive; FP=False Positive; TN= True Negative; FN=False Negative.</p>
<h2>VI. RESULTS</h2>
<p>To evaluate our model, we leverage the Python deep learning framework Pytorch [17]. We train and evaluate them on NVIDIA® Tesla® V100S with 32 GB HBM2 memory.</p>
<h3><em>A. Model Configuration &amp; Hyperparameter tuning</em></h3>
<p>As presented in Table II, for CAN-BERT, we have chosen the total number of transformer encoder layers as 4. In each transformer layer, the position-wise feed forward network is composed of two dense layers where the first one projects d=256 dimensional CAN identifier embedding into d<sub>ff</sub>=512 dimensional space, followed by a ReLU activation. The second dense layer maps back the 512-dimensional vector into the d-dimensional space. For training, we use a batch size of 32, a learning rate of 0.001 and the Adam optimizer [18] with its default parameters β<sub>1</sub> = 0.9 and β<sub>2</sub> = 0.999. To avoid overfitting, we employ the same dropout of P<sub>drop</sub>=0.1 for all dropout layers in our network. Moreover, we apply early stopping for a total number of 200 epochs and a patience of 10 epochs as a form of regularization used to avoid overfitting.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Comparision of the CAN-BERT model with other anomaly detection baselines using the F1-score percentage metric, for different message injection attacks applied on different car models w.r.t sequence length $T$.</p>
<p>TABLE II
CAN-BERT MODEL CONFIGURATION</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$N$</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: center;">$d_{\text {model }}$</td>
<td style="text-align: center;">256</td>
</tr>
<tr>
<td style="text-align: center;">$d_{f f}$</td>
<td style="text-align: center;">512</td>
</tr>
<tr>
<td style="text-align: center;">$k$</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">$P_{\text {drop }}$</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: center;">$m$</td>
<td style="text-align: center;">0.45</td>
</tr>
<tr>
<td style="text-align: center;">$#$ Candidates</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">Optimizer</td>
<td style="text-align: center;">Adam</td>
</tr>
<tr>
<td style="text-align: center;">Adam $\beta_{1}$</td>
<td style="text-align: center;">0.9</td>
</tr>
<tr>
<td style="text-align: center;">Adam $\beta_{2}$</td>
<td style="text-align: center;">0.999</td>
</tr>
<tr>
<td style="text-align: center;">Learning rate</td>
<td style="text-align: center;">0.001</td>
</tr>
<tr>
<td style="text-align: center;">Batch size</td>
<td style="text-align: center;">32</td>
</tr>
<tr>
<td style="text-align: center;"># Epochs</td>
<td style="text-align: center;">200</td>
</tr>
<tr>
<td style="text-align: center;">Patience</td>
<td style="text-align: center;">10</td>
</tr>
</tbody>
</table>
<p>The hyperparameters, including the ratio of masked CAN IDs in a sequence $m$, and $h$ the number of attention heads are
tuned based on a validation set for the three car types and the different message injection attacks. As seen in Figure 5, raising the ratios of masked CAN IDs in the sequences from 0.1 to 0.45 somewhat improves F1 scores, however increasing the ratios further degrades performance, as is the case for $m=0.65$. Furthermore, the model performance is relatively stable by setting different attention head $h \in{1,2,4,8}$ values for each mask ratio $m \in{0.15,0.3,0.45,0.6}$. Therefore, in our invehicle intrusion detection use case, a single attention head is sufficiant to detect different types of intrusions. Note that, in our experiments, we use the same ratio of masked CAN IDS $m=0.45$ and $h=1$ for both training and inference phases.</p>
<h2>B. Model Accuracy</h2>
<p>As seen in Figure 6, we compare performance of the CANBERT model with other baselines approaches for different sequence length $T$ using the F1-score metric. In fact, we varied the sequence length among values of $16,32,64,128$</p>
<p>and 256 CAN IDs per sequence in the experiments. If our approaches could identify a message injection attack in a shorter sequence length, it would be more advantageous in a practical situation. The traditional machine learning algorithms such as Isolation Forest (iForest), and Principal Component Analysis (PCA) perform poorly and maintain the same F1-score metric w.r.t sequence length. Because these models presume small datasets with a limited number of features, they fail to discover abnormalities in high-dimensional datasets. Because of this, a significant fraction of irrelevant features may effectively disguise the underlying abnormalities in the input data, resulting in poor anomaly identification performance when dealing with large input dimensions. Meanwhile, both deep learning based models autoencoder (AE) and CAN-BERT outperformed the traditional anomaly detection models over different window sizes. However, when the length of the CAN ID sequence is increased, both models performed oppositely. In contrast to the baseline models, our suggested model, CAN-BERT, significantly outperforms them by huge margins and obtains respectable F1 scores $\in[0.85,0.99]$, demonstrating the usefulness of using BERT-based models to capture the patterns of CAN ID sequences when $T \geq 32$. However, on short sequence length as is the case for $T=16$, the model performs modestly with F1-score $\in[0.6,0.9]$ for different kind of attacks. These experiments, therefore, reveal that by using self-supervised training tasks, CAN-BERT can effectively model medium to long normal CAN ID sequences and accurately detect anomalous sequences.</p>
<h2>C. Model Complexity</h2>
<p>From a practical point of view, we must assess not only the classification performance but also the model complexity to check if the model's ability for real-time in-vehicle intrusion detection in CAN networks. Therefore, we assessed the inference time per sample as well as the number of parameters for the CAN-BERT model w.r.t different car types. As depicted in</p>
<p>TABLE III
CAN-BERT MODEL COMPLEXITY</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Vehicle</th>
<th style="text-align: center;">Features</th>
<th style="text-align: center;">Values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Number of Parameters</td>
<td style="text-align: center;">$2,937,422$</td>
</tr>
<tr>
<td style="text-align: center;">CHEVROLET Spark</td>
<td style="text-align: center;">Model Size (MB)</td>
<td style="text-align: center;">$[20,70]$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Inference Time (ms)</td>
<td style="text-align: center;">$[0.8,3.1]$</td>
</tr>
<tr>
<td style="text-align: center;">HYUNDAI Sonata</td>
<td style="text-align: center;">Number of Parameters</td>
<td style="text-align: center;">$3,149,291$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Model Size (MB)</td>
<td style="text-align: center;">$[20,70]$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Inference Time (ms)</td>
<td style="text-align: center;">$[0.8,3.5]$</td>
</tr>
<tr>
<td style="text-align: center;">KIA Soul</td>
<td style="text-align: center;">Number of Parameters</td>
<td style="text-align: center;">$3,163,142$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Model Size (MB)</td>
<td style="text-align: center;">$[20,70]$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Inference Time (ms)</td>
<td style="text-align: center;">$[0.8,3.8]$</td>
</tr>
</tbody>
</table>
<p>Table III, the intrusion detection inference time varies between 0.8 and 3.1 ms w.r.t CAN ID sequence length. Hence, when considering a sequence length of 32 CAN IDs, our model detects an intrusion in 0.9 to 1 ms , which is suitable for realtime detection. Furthermore, having a size between 20MB and 70 MB and a number of parameters ranging between 2 to 3 millions, our model can be either deployed in performant ECU or even on a cloud server wirelessly connected to the vehicle.</p>
<h2>VII. CONCLUSION</h2>
<p>Identification of intrusions within the vehicle is critical for defending it against malicious cyberattacks. In this paper, we suggest CAN-BERT, a self-supervised intrusion detection system based on BERT model, for in-vehicle intrusion detection. Experimental results on benchmark datasets for different CAN ID sequence length have shown that CAN-BERT surpasses state-of-the-art techniques for CAN ID sequence anomaly detection with an F1-score ranging between 0.81 and 0.99 for different type of attacks and is appropriate for real-time detection with an inference time ranging between 0.8 and 3 ms w.r.t CAN ID sequence length. For future work, we aim to deploy our model on embedded electronic control units (ECU) and test the model efficiency in a real vehicle environment.</p>
<h2>REFERENCES</h2>
<p>[1] Matheus, Kirsten, and Thomas Königseder. Automotive ethernet. Cambridge University Press, 2021.
[2] Devlin, Jacob, et al. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018).
[3] Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems 30 (2017).
[4] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. "Layer normalization." arXiv preprint arXiv:1607.06450 (2016).
[5] Nam, Minki, Seungyoung Park, and Duk Soo Kim. "Intrusion detection method using bi-directional GPT for in-vehicle controller area networks." IEEE Access 9 (2021): 124931-124944.
[6] Li, Bai, et al. "How is BERT surprised? Layerwise detection of linguistic anomalies." arXiv preprint arXiv:2105.07452 (2021).
[7] Guo, Haixuan, Shuhan Yuan, and Xintao Wu. "Logbert: Log anomaly detection via bert." 2021 International Joint Conference on Neural Networks (IJCNN). IEEE, 2021.
[8] Lee, Yukyung, Jina Kim, and Pilsung Kang. "LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model." arXiv preprint arXiv:2111.09564 (2021).
[9] Le, Van-Hoang, and Hongyu Zhang. "Log-based anomaly detection without log parsing." 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021.
[10] Yu, Keping, et al. "Securing critical infrastructures: Deep-LearningBased threat detection in IIoT." IEEE Communications Magazine 59.10 (2021): 76-82.
[11] Dang, Weixia, et al. "TS-Bert: Time Series Anomaly Detection via Pretraining Model Bert." International Conference on Computational Science. Springer, Cham, 2021.
[12] Vincent, Pascal, et al. "Extracting and composing robust features with denoising autoencoders." Proceedings of the 25th international conference on Machine learning. 2008.
[13] Hyunjae Kang, Byung Il Kwak, Young Hun Lee, Haneol Lee, Hwejae Lee, Huy Kang Kim, February 3, 2021, "Car Hacking: Attack \&amp; Defense Challenge 2020 Dataset", IEEE Dataport, doi: https://dx.doi.org/10.21227/ qvr7-n418
[14] Abdi, Hervé, and Lynne J. Williams. "Principal component analysis." Wiley interdisciplinary reviews: computational statistics 2.4 (2010): 433459.
[15] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. "Isolation-based anomaly detection." ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): 3.
[16] Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. "Learning representations by back-propagating errors." nature 323.6088 (1986): 533-536.
[17] Pytorch framework. https://pytorch.org/.
[18] Kingma, Diederik P., and Jimmy Ba. "Adam: A method for stochastic optimization." arXiv preprint arXiv:1412.6980 (2014).
[19] Hanselmann, Markus, et al. "CANet: An unsupervised intrusion detection system for high dimensional CAN bus data." Ieee Access 8 (2020): 58194-58205.
[20] Song, Hyun Min, Jiyoung Woo, and Huy Kang Kim. "In-vehicle network intrusion detection using deep convolutional neural network." Vehicular Communications 21 (2020): 100198.</p>            </div>
        </div>

    </div>
</body>
</html>