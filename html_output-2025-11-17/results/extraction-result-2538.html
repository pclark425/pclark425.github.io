<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2538 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2538</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2538</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-c06e4e187f4dddb3b67ba4932ef2b096f146c20f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c06e4e187f4dddb3b67ba4932ef2b096f146c20f" target="_blank">GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper introduces the"GPT-in-the-loop" approach, a novel method combining the advanced reasoning capabilities of Large Language Models like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems, and employs GPT-4 for enhanced problem-solving and explanation skills.</p>
                <p><strong>Paper Abstract:</strong> This paper introduces the"GPT-in-the-loop"approach, a novel method combining the advanced reasoning capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems. Venturing beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 for enhanced problem-solving and explanation skills. Our experimental backdrop is the smart streetlight Internet of Things (IoT) application. Here, agents use sensors, actuators, and neural networks to create an energy-efficient lighting system. By integrating GPT-4, these agents achieve superior decision-making and adaptability without the need for extensive training. We compare this approach with both traditional neuroevolutionary methods and solutions provided by software engineers, underlining the potential of GPT-driven multiagent systems in IoT. Structurally, the paper outlines the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), introduces our proposed GPT-in-the-loop approach, presents comparative results in the IoT context, and concludes with insights and future directions.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2538.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2538.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-in-the-loop</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-in-the-loop (LLM-in-the-loop) approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that integrates a Large Language Model (GPT-4) into the decision-making/adaptation loop of multi-agent systems to generate or refine agent controllers via iterative prompts that incorporate environmental feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-in-the-loop (Interactive MAS mode)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A hybrid approach in which GPT-4 is used to produce and iteratively refine agent decision-making controllers (e.g., if-else code) based on environment feedback. Modes described include Active MAS (GPT explains outcomes), Interactive MAS (GPT shapes agent controllers in a bidirectional loop with the MAS), and MAS Teaching (GPT directs adaptation). In the interactive mode implemented, GPT receives environment metrics (fitness, energy, trip times), generates controller code for agents, the controllers are deployed in the MAS, environment performance is measured, and those measurements are fed back into GPT for further refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (one agent per streetlight; exact count not specified)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>No new agent types beyond existing FIoT roles were invented; specialization is at the role level: (1) Agent controllers produced by GPT run on AdaptiveAgents (per-device controllers implementing sensing->decision->actuation); (2) ObserverAgent role remains responsible for evaluating candidate controllers and providing aggregated environment feedback to GPT.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>implementation (code/controller synthesis), execution (running synthesized controllers in the environment), and evaluation (iterative fitness evaluation and refinement). The approach also covers explainability/interpretation since GPT produces rationale alongside controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Decentralized runtime coordination among agents via local controller logic (per-agent if-else controllers) and local wireless interactions; the higher-level coordination of controller design is centralized/sequential with GPT producing controllers in iterative cycles (human/GPT-guided design loop).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Two levels: (1) inter-agent runtime protocol: lightweight local wireless flags (e.g., wirelessTransmit and wirelessReceiver boolean/float signals indicating motion detection or anticipatory alerts); (2) agent-to-GPT protocol: batched environment metrics and textual prompts (human-readable prompt incorporating evaluation metrics) used to request updated controller code from GPT (text/code as output).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative fitness-driven refinement: ObserverAgent or experimental harness evaluates energy consumption, people finishing routes, and total trip time to compute a fitness score; these evaluation outputs are included in GPT prompts so GPT generates improved controllers. Additionally, GPT provides textual rationales explaining decisions which guide subsequent iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Two timescales: (1) runtime agent-to-agent: on-demand event-driven messages (e.g., transmit on motion detection; listeningDecision may default to always listening or be adapted), and (2) design-time GPT loop: discrete iterations (in the experiment three design iterations were performed; feedback is provided between iterations).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>IoT multi-agent control (smart streetlight control) as an exemplar; proposed for broader MAS and evolutionary robotics domains.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics are Energy (unitless simulation energy metric), People (percentage of people reaching destination), TotalFTrip (cumulative travel time), and aggregated Fitness (composite score). Example results (Scenario 1): GPT iter1: Energy=4.03, People=66.66, TotalFTrip=59.25, Fitness=29.49; GPT iter2: Energy=15.02, People=100, TotalFTrip=54.62, Fitness=61.2; GPT iter3: Energy=11.92, People=100, TotalFTrip=54.62, Fitness=62.44. (Scenario 2): GPT iter1 Fitness=36.72; iter2 Fitness=70.81; iter3 Fitness=71.42. Metrics reported as in paper tables.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared experimentally to a neuroevolutionary approach (three-layer neural network evolved via genetic algorithm) and to human software engineer solutions. Results: GPT reached high fitness in three iterations whereas neuroevolution required 200 generations × 50 interactions; GPT iter3 outperformed the best neuroevolution solution in both scenarios (Scenario1: GPT iter3 Fitness=62.44 vs neuroevolution best 59.53; Scenario2: GPT iter3 Fitness=71.42 vs neuroevolution best 68.83). Against best human participant: Scenario1 best participant had Fitness=62.88 (slightly higher than GPT iter3), but that participant solution failed to generalize to Scenario2 where GPT outperformed human.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Faster synthesis and iteration of controllers (target fitness achieved in 3 GPT iterations vs lengthy neuroevolutionary runs), explainability (GPT emits human-readable if-else code and rationales), and effective decentralized runtime coordination via simple local signaling (motion alerts) produced efficient anticipatory lighting behavior; quantitative improvements include GPT iter3 outperforming best neuroevolution solution (Scenario1: +2.91 fitness points; Scenario2: +2.59 fitness points) and achieving generalization across scenarios where some human solutions failed.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Computational cost and practicality of running large LLMs for real-time per-agent decision-making (authors note heavy computational needs and propose cloud-hosted GPT as future work); opacity of proprietary LLMs (black-box concerns) despite textual explanations; no measured communication overhead numbers provided; potential reliance on centralized GPT for controller generation introduces a single point of failure / latency if used at runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported. The paper does not include ablation experiments removing communication or feedback components; comparisons are only between full GPT-in-the-loop, neuroevolutionary solution, and human solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>No empirically-validated optimal configurations reported. Authors suggest possible favorable configurations: Interactive MAS mode (bidirectional GPT-MAS loop) and per-agent personalized GPT instances as promising directions, but these are presented as proposals rather than validated settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2538.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2538.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FIoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Framework for the Internet of Things (FIoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A software framework for building self-adaptive IoT multi-agent systems that supports interchangeable decision-making controllers (if-else, state machines, neural networks) and adaptation methods (evolutionary algorithms, reinforcement learning), with built-in agent roles (AdaptiveAgent, ObserverAgent) and a MAPE-K-based architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fiot: An agent-based framework for self-adaptive and self-organizing applications based on the internet of things.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FIoT framework</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>FIoT is a Java-based framework that supplies components for recognizing devices, assigning control, creating software agents, collecting device data, and enabling agent-device interactions. It exposes flexible points: Controller (decision engine), Controller Adaptation method, and Making Evaluation. The framework includes AdaptiveAgent (per-device controller following a MAPE-K loop) and ObserverAgent (global evaluator/adaptor). The paper extends FIoT to accept GPT-generated controllers or to have GPT guide the ObserverAgent adaptation process.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (framework supports arbitrary numbers of agents; experiment instantiated one agent per streetlight)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>AdaptiveAgent: per-device controller that perceives sensors, executes controller (if-else or neural network), and acts; ObserverAgent: evaluates collective performance (fitness) and can adapt or request new controllers; agents in application (streetlight agents) implement AdaptiveAgent functionality with sensors/actuators.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>implementation (controller integration), execution (deploying controllers in simulation), and evaluation (observer-based fitness evaluation). Also supports adaptation/training phases (e.g., evolutionary runs) when used with neuroevolution.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Framework-level coordination is flexible: supports decentralized per-agent controllers with local communication and centralized adaptation via ObserverAgent which can replace or reconfigure controllers. In experiments, coordination is decentralized at runtime (local wireless signaling) with centralized evaluation by ObserverAgent.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Framework is agnostic to specific message formats; in experiment, inter-agent communication implemented as simple wireless transmit/receive boolean/float signals; framework supports passing controller inputs/outputs via method signatures (consistent class signatures).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>ObserverAgent collects per-agent and global metrics (energy, people completion, trip time) to compute fitness and can trigger adaptation (neuroevolution or GPT-in-the-loop) by providing these metrics as feedback to the adaptation engine.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Framework leaves frequency to controller design; in the streetlight experiment, inter-agent messages sent on events (motion detection) and ObserverAgent performs evaluation after full simulation runs (batch evaluation per candidate controller).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General self-adaptive IoT multiagent control; demonstrated on smart streetlight control.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same experimental metrics as above when FIoT is used: Energy, People, TotalFTrip, Fitness. FIoT enabled the comparison of neuroevolutionary and GPT-generated controllers using these metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>FIoT was the execution platform for comparing controller generation approaches: neuroevolution (evolutionary controller adaptation implemented within FIoT), human-designed controllers, and GPT-generated controllers. Results as reported in GPT-in-the-loop entry.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Provides modular hooks to swap controller/adaptation methods enabling rapid experimentation (e.g., plug-in GPT-produced controllers), and central ObserverAgent makes collective evaluation straightforward. Benefit demonstrated by enabling the fast iterative GPT loop and comparison with neuroevolution.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Noted limitations are inherited from chosen controllers/adaptation methods (e.g., neuroevolution is time-consuming; LLM integration introduces computation/latency concerns). Framework consistency constraints (class signature requirements) must be maintained for runtime replacement of controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported for framework components in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper does not prescribe optimal FIoT configurations; recommended use is to exploit its flexible points to try different controller/adaptation combinations (e.g., use GPT for controller generation or to guide ObserverAgent's adaptation).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2538.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2538.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Smart Streetlight MAS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Smart Streetlight Multi-Agent System (streetlight control scenario)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulated multi-agent system of autonomous streetlight agents (each with sensors, actuators and a controller) coordinating via local wireless signaling to balance energy consumption and pedestrian safety; used as the experimental domain to evaluate GPT-in-the-loop vs neuroevolution and human solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward human-in-the-loop collaboration between software engineers and machine learning algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Smart Streetlight MAS (streetlight control case study)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Each streetlight agent senses ambient light and motion, may listen to neighbor posts (wirelessReceiver) and transmit events (wirelessTransmit). Controllers decide light intensity, transmission, and listening decisions. The collective objective is minimizing energy while ensuring people complete routes and minimizing travel time; global fitness is computed from energy, number of people finishing routes, and total trip time. Communication happens locally between adjacent poles; controller logic was supplied either by evolved neural networks, human-written code, or GPT-generated if-else controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>unspecified (multiple streetlight agents forming paths in simulation; exact count not stated in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Homogeneous streetlight agents (each performs sensing, local decision-making, actuation, and limited wireless messaging). Additionally the system includes an ObserverAgent for global evaluation in the experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Implementation (controller code synthesized and deployed), execution (simulation runs collecting energy/people/trip-time), and evaluation (fitness calculation); also used for generalization tests (controllers designed in one scenario tested in expanded scenario).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Event-driven decentralized coordination: agents transmit a simple signal when they detect motion; neighboring agents that are listening may pre-emptively light to prepare path. The design-time coordination for controller creation is iterative centralized (GPT receives batch fitness feedback and produces new controllers).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Runtime inter-agent messaging via simple wireless transmit/receive boolean or float flags (e.g., wirelessTransmit=1.0 indicates motion detected; wirelessReceiver>0.0 used as condition); no higher-level structured message format reported. Controller generation/feedback uses text prompts and numerical environment metrics to/from GPT.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Simulation-based collective fitness evaluation (energy, people completion, total trip time) supplied back to the GPT prompt between design iterations. Within runtime, agents implicitly provide feedback via their state changes (motion detection) and through the ObserverAgent's aggregated metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Runtime: mostly on-demand/event-driven (transmit when motion detected); some controllers default to always listening (listeningDecision=1.0) but optimized controllers reduced transmissions. Design-time: discrete iterative rounds (experiment used three GPT iterations).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>IoT/smart city control (smart streetlight coordination); exemplar for multi-agent adaptation research and robotics/evolutionary robotics transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same as above: Energy, People (% reaching destination), TotalFTrip (total trip time), Fitness (composite). Example numeric outcomes listed in the paper tables (see GPT-in-the-loop entry).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Direct comparisons performed between GPT-generated controllers, neuroevolution-evolved controllers (three-layer neural network), and human participant solutions. GPT iter3 outperformed the best neuroevolution solution in both scenarios and generalized better across scenarios than some human solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Event-driven local coordination enabled anticipatory lighting that conserves energy while maintaining safety; GPT-driven controller synthesis accelerated design iterations and yielded controllers that generalized to a more complex scenario where many human solutions failed. Quantitatively: GPT iter2/iter3 achieved large fitness improvements (e.g., Scenario2 iter2=70.81, iter3=71.42) compared to iter1.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Design-time reliance on GPT requires repeated simulation evaluations and human-crafted prompts; runtime application of LLMs per agent is computationally heavy and not implemented (authors discuss possible cloud-hosted GPT but note cost/latency concerns). Exact agent counts and network-scale communications effects were not explored.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported specifically for runtime communication (e.g., no experiments disabling wirelessTransmit/listening to measure impact).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Empirical results suggest controllers that reduce redundant transmissions (transmit once on initial motion detection) and condition listening on prior state and ambient light improve fitness; however, no comprehensive search or formal optimal configuration was provided—these are emergent from the GPT iterations rather than globally optimized recommendations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fiot: An agent-based framework for self-adaptive and self-organizing applications based on the internet of things. <em>(Rating: 2)</em></li>
                <li>Toward human-in-the-loop collaboration between software engineers and machine learning algorithms. <em>(Rating: 2)</em></li>
                <li>Human-in-the-loop machine learning: A state of the art. <em>(Rating: 1)</em></li>
                <li>Progress and challenges in adaptive robotics. <em>(Rating: 1)</em></li>
                <li>Towards the Neuroevolution of Low-level artificial general intelligence. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2538",
    "paper_id": "paper-c06e4e187f4dddb3b67ba4932ef2b096f146c20f",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "GPT-in-the-loop",
            "name_full": "GPT-in-the-loop (LLM-in-the-loop) approach",
            "brief_description": "An approach that integrates a Large Language Model (GPT-4) into the decision-making/adaptation loop of multi-agent systems to generate or refine agent controllers via iterative prompts that incorporate environmental feedback.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GPT-in-the-loop (Interactive MAS mode)",
            "system_description": "A hybrid approach in which GPT-4 is used to produce and iteratively refine agent decision-making controllers (e.g., if-else code) based on environment feedback. Modes described include Active MAS (GPT explains outcomes), Interactive MAS (GPT shapes agent controllers in a bidirectional loop with the MAS), and MAS Teaching (GPT directs adaptation). In the interactive mode implemented, GPT receives environment metrics (fitness, energy, trip times), generates controller code for agents, the controllers are deployed in the MAS, environment performance is measured, and those measurements are fed back into GPT for further refinement.",
            "number_of_agents": "variable (one agent per streetlight; exact count not specified)",
            "agent_specializations": "No new agent types beyond existing FIoT roles were invented; specialization is at the role level: (1) Agent controllers produced by GPT run on AdaptiveAgents (per-device controllers implementing sensing-&gt;decision-&gt;actuation); (2) ObserverAgent role remains responsible for evaluating candidate controllers and providing aggregated environment feedback to GPT.",
            "research_phases_covered": "implementation (code/controller synthesis), execution (running synthesized controllers in the environment), and evaluation (iterative fitness evaluation and refinement). The approach also covers explainability/interpretation since GPT produces rationale alongside controllers.",
            "coordination_mechanism": "Decentralized runtime coordination among agents via local controller logic (per-agent if-else controllers) and local wireless interactions; the higher-level coordination of controller design is centralized/sequential with GPT producing controllers in iterative cycles (human/GPT-guided design loop).",
            "communication_protocol": "Two levels: (1) inter-agent runtime protocol: lightweight local wireless flags (e.g., wirelessTransmit and wirelessReceiver boolean/float signals indicating motion detection or anticipatory alerts); (2) agent-to-GPT protocol: batched environment metrics and textual prompts (human-readable prompt incorporating evaluation metrics) used to request updated controller code from GPT (text/code as output).",
            "feedback_mechanism": "Iterative fitness-driven refinement: ObserverAgent or experimental harness evaluates energy consumption, people finishing routes, and total trip time to compute a fitness score; these evaluation outputs are included in GPT prompts so GPT generates improved controllers. Additionally, GPT provides textual rationales explaining decisions which guide subsequent iterations.",
            "communication_frequency": "Two timescales: (1) runtime agent-to-agent: on-demand event-driven messages (e.g., transmit on motion detection; listeningDecision may default to always listening or be adapted), and (2) design-time GPT loop: discrete iterations (in the experiment three design iterations were performed; feedback is provided between iterations).",
            "task_domain": "IoT multi-agent control (smart streetlight control) as an exemplar; proposed for broader MAS and evolutionary robotics domains.",
            "performance_metrics": "Reported metrics are Energy (unitless simulation energy metric), People (percentage of people reaching destination), TotalFTrip (cumulative travel time), and aggregated Fitness (composite score). Example results (Scenario 1): GPT iter1: Energy=4.03, People=66.66, TotalFTrip=59.25, Fitness=29.49; GPT iter2: Energy=15.02, People=100, TotalFTrip=54.62, Fitness=61.2; GPT iter3: Energy=11.92, People=100, TotalFTrip=54.62, Fitness=62.44. (Scenario 2): GPT iter1 Fitness=36.72; iter2 Fitness=70.81; iter3 Fitness=71.42. Metrics reported as in paper tables.",
            "baseline_comparison": "Compared experimentally to a neuroevolutionary approach (three-layer neural network evolved via genetic algorithm) and to human software engineer solutions. Results: GPT reached high fitness in three iterations whereas neuroevolution required 200 generations × 50 interactions; GPT iter3 outperformed the best neuroevolution solution in both scenarios (Scenario1: GPT iter3 Fitness=62.44 vs neuroevolution best 59.53; Scenario2: GPT iter3 Fitness=71.42 vs neuroevolution best 68.83). Against best human participant: Scenario1 best participant had Fitness=62.88 (slightly higher than GPT iter3), but that participant solution failed to generalize to Scenario2 where GPT outperformed human.",
            "coordination_benefits": "Faster synthesis and iteration of controllers (target fitness achieved in 3 GPT iterations vs lengthy neuroevolutionary runs), explainability (GPT emits human-readable if-else code and rationales), and effective decentralized runtime coordination via simple local signaling (motion alerts) produced efficient anticipatory lighting behavior; quantitative improvements include GPT iter3 outperforming best neuroevolution solution (Scenario1: +2.91 fitness points; Scenario2: +2.59 fitness points) and achieving generalization across scenarios where some human solutions failed.",
            "coordination_challenges": "Computational cost and practicality of running large LLMs for real-time per-agent decision-making (authors note heavy computational needs and propose cloud-hosted GPT as future work); opacity of proprietary LLMs (black-box concerns) despite textual explanations; no measured communication overhead numbers provided; potential reliance on centralized GPT for controller generation introduces a single point of failure / latency if used at runtime.",
            "ablation_studies": "None reported. The paper does not include ablation experiments removing communication or feedback components; comparisons are only between full GPT-in-the-loop, neuroevolutionary solution, and human solutions.",
            "optimal_configurations": "No empirically-validated optimal configurations reported. Authors suggest possible favorable configurations: Interactive MAS mode (bidirectional GPT-MAS loop) and per-agent personalized GPT instances as promising directions, but these are presented as proposals rather than validated settings.",
            "uuid": "e2538.0",
            "source_info": {
                "paper_title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "FIoT",
            "name_full": "Framework for the Internet of Things (FIoT)",
            "brief_description": "A software framework for building self-adaptive IoT multi-agent systems that supports interchangeable decision-making controllers (if-else, state machines, neural networks) and adaptation methods (evolutionary algorithms, reinforcement learning), with built-in agent roles (AdaptiveAgent, ObserverAgent) and a MAPE-K-based architecture.",
            "citation_title": "Fiot: An agent-based framework for self-adaptive and self-organizing applications based on the internet of things.",
            "mention_or_use": "use",
            "system_name": "FIoT framework",
            "system_description": "FIoT is a Java-based framework that supplies components for recognizing devices, assigning control, creating software agents, collecting device data, and enabling agent-device interactions. It exposes flexible points: Controller (decision engine), Controller Adaptation method, and Making Evaluation. The framework includes AdaptiveAgent (per-device controller following a MAPE-K loop) and ObserverAgent (global evaluator/adaptor). The paper extends FIoT to accept GPT-generated controllers or to have GPT guide the ObserverAgent adaptation process.",
            "number_of_agents": "variable (framework supports arbitrary numbers of agents; experiment instantiated one agent per streetlight)",
            "agent_specializations": "AdaptiveAgent: per-device controller that perceives sensors, executes controller (if-else or neural network), and acts; ObserverAgent: evaluates collective performance (fitness) and can adapt or request new controllers; agents in application (streetlight agents) implement AdaptiveAgent functionality with sensors/actuators.",
            "research_phases_covered": "implementation (controller integration), execution (deploying controllers in simulation), and evaluation (observer-based fitness evaluation). Also supports adaptation/training phases (e.g., evolutionary runs) when used with neuroevolution.",
            "coordination_mechanism": "Framework-level coordination is flexible: supports decentralized per-agent controllers with local communication and centralized adaptation via ObserverAgent which can replace or reconfigure controllers. In experiments, coordination is decentralized at runtime (local wireless signaling) with centralized evaluation by ObserverAgent.",
            "communication_protocol": "Framework is agnostic to specific message formats; in experiment, inter-agent communication implemented as simple wireless transmit/receive boolean/float signals; framework supports passing controller inputs/outputs via method signatures (consistent class signatures).",
            "feedback_mechanism": "ObserverAgent collects per-agent and global metrics (energy, people completion, trip time) to compute fitness and can trigger adaptation (neuroevolution or GPT-in-the-loop) by providing these metrics as feedback to the adaptation engine.",
            "communication_frequency": "Framework leaves frequency to controller design; in the streetlight experiment, inter-agent messages sent on events (motion detection) and ObserverAgent performs evaluation after full simulation runs (batch evaluation per candidate controller).",
            "task_domain": "General self-adaptive IoT multiagent control; demonstrated on smart streetlight control.",
            "performance_metrics": "Same experimental metrics as above when FIoT is used: Energy, People, TotalFTrip, Fitness. FIoT enabled the comparison of neuroevolutionary and GPT-generated controllers using these metrics.",
            "baseline_comparison": "FIoT was the execution platform for comparing controller generation approaches: neuroevolution (evolutionary controller adaptation implemented within FIoT), human-designed controllers, and GPT-generated controllers. Results as reported in GPT-in-the-loop entry.",
            "coordination_benefits": "Provides modular hooks to swap controller/adaptation methods enabling rapid experimentation (e.g., plug-in GPT-produced controllers), and central ObserverAgent makes collective evaluation straightforward. Benefit demonstrated by enabling the fast iterative GPT loop and comparison with neuroevolution.",
            "coordination_challenges": "Noted limitations are inherited from chosen controllers/adaptation methods (e.g., neuroevolution is time-consuming; LLM integration introduces computation/latency concerns). Framework consistency constraints (class signature requirements) must be maintained for runtime replacement of controllers.",
            "ablation_studies": "None reported for framework components in this paper.",
            "optimal_configurations": "Paper does not prescribe optimal FIoT configurations; recommended use is to exploit its flexible points to try different controller/adaptation combinations (e.g., use GPT for controller generation or to guide ObserverAgent's adaptation).",
            "uuid": "e2538.1",
            "source_info": {
                "paper_title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Smart Streetlight MAS",
            "name_full": "Smart Streetlight Multi-Agent System (streetlight control scenario)",
            "brief_description": "A simulated multi-agent system of autonomous streetlight agents (each with sensors, actuators and a controller) coordinating via local wireless signaling to balance energy consumption and pedestrian safety; used as the experimental domain to evaluate GPT-in-the-loop vs neuroevolution and human solutions.",
            "citation_title": "Toward human-in-the-loop collaboration between software engineers and machine learning algorithms.",
            "mention_or_use": "use",
            "system_name": "Smart Streetlight MAS (streetlight control case study)",
            "system_description": "Each streetlight agent senses ambient light and motion, may listen to neighbor posts (wirelessReceiver) and transmit events (wirelessTransmit). Controllers decide light intensity, transmission, and listening decisions. The collective objective is minimizing energy while ensuring people complete routes and minimizing travel time; global fitness is computed from energy, number of people finishing routes, and total trip time. Communication happens locally between adjacent poles; controller logic was supplied either by evolved neural networks, human-written code, or GPT-generated if-else controllers.",
            "number_of_agents": "unspecified (multiple streetlight agents forming paths in simulation; exact count not stated in paper)",
            "agent_specializations": "Homogeneous streetlight agents (each performs sensing, local decision-making, actuation, and limited wireless messaging). Additionally the system includes an ObserverAgent for global evaluation in the experimental setup.",
            "research_phases_covered": "Implementation (controller code synthesized and deployed), execution (simulation runs collecting energy/people/trip-time), and evaluation (fitness calculation); also used for generalization tests (controllers designed in one scenario tested in expanded scenario).",
            "coordination_mechanism": "Event-driven decentralized coordination: agents transmit a simple signal when they detect motion; neighboring agents that are listening may pre-emptively light to prepare path. The design-time coordination for controller creation is iterative centralized (GPT receives batch fitness feedback and produces new controllers).",
            "communication_protocol": "Runtime inter-agent messaging via simple wireless transmit/receive boolean or float flags (e.g., wirelessTransmit=1.0 indicates motion detected; wirelessReceiver&gt;0.0 used as condition); no higher-level structured message format reported. Controller generation/feedback uses text prompts and numerical environment metrics to/from GPT.",
            "feedback_mechanism": "Simulation-based collective fitness evaluation (energy, people completion, total trip time) supplied back to the GPT prompt between design iterations. Within runtime, agents implicitly provide feedback via their state changes (motion detection) and through the ObserverAgent's aggregated metrics.",
            "communication_frequency": "Runtime: mostly on-demand/event-driven (transmit when motion detected); some controllers default to always listening (listeningDecision=1.0) but optimized controllers reduced transmissions. Design-time: discrete iterative rounds (experiment used three GPT iterations).",
            "task_domain": "IoT/smart city control (smart streetlight coordination); exemplar for multi-agent adaptation research and robotics/evolutionary robotics transfer.",
            "performance_metrics": "Same as above: Energy, People (% reaching destination), TotalFTrip (total trip time), Fitness (composite). Example numeric outcomes listed in the paper tables (see GPT-in-the-loop entry).",
            "baseline_comparison": "Direct comparisons performed between GPT-generated controllers, neuroevolution-evolved controllers (three-layer neural network), and human participant solutions. GPT iter3 outperformed the best neuroevolution solution in both scenarios and generalized better across scenarios than some human solutions.",
            "coordination_benefits": "Event-driven local coordination enabled anticipatory lighting that conserves energy while maintaining safety; GPT-driven controller synthesis accelerated design iterations and yielded controllers that generalized to a more complex scenario where many human solutions failed. Quantitatively: GPT iter2/iter3 achieved large fitness improvements (e.g., Scenario2 iter2=70.81, iter3=71.42) compared to iter1.",
            "coordination_challenges": "Design-time reliance on GPT requires repeated simulation evaluations and human-crafted prompts; runtime application of LLMs per agent is computationally heavy and not implemented (authors discuss possible cloud-hosted GPT but note cost/latency concerns). Exact agent counts and network-scale communications effects were not explored.",
            "ablation_studies": "None reported specifically for runtime communication (e.g., no experiments disabling wirelessTransmit/listening to measure impact).",
            "optimal_configurations": "Empirical results suggest controllers that reduce redundant transmissions (transmit once on initial motion detection) and condition listening on prior state and ambient light improve fitness; however, no comprehensive search or formal optimal configuration was provided—these are emergent from the GPT iterations rather than globally optimized recommendations.",
            "uuid": "e2538.2",
            "source_info": {
                "paper_title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fiot: An agent-based framework for self-adaptive and self-organizing applications based on the internet of things.",
            "rating": 2
        },
        {
            "paper_title": "Toward human-in-the-loop collaboration between software engineers and machine learning algorithms.",
            "rating": 2
        },
        {
            "paper_title": "Human-in-the-loop machine learning: A state of the art.",
            "rating": 1
        },
        {
            "paper_title": "Progress and challenges in adaptive robotics.",
            "rating": 1
        },
        {
            "paper_title": "Towards the Neuroevolution of Low-level artificial general intelligence.",
            "rating": 1
        }
    ],
    "cost": 0.011696749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems</h1>
<p>Nathalia Nascimento, Paulo Alencar, Donald Cowan<br>David R. Cheriton School of Computer Science<br>University of Waterloo (UW)<br>Waterloo, Canada<br>{nmoraesd, palencar, dcowan} @uwaterloo.ca</p>
<h4>Abstract</h4>
<p>This paper introduces the "GPT-in-the-loop" approach, a novel method combining the advanced reasoning capabilities of Large Language Models (LLMs) like Generative Pretrained Transformers (GPT) with multiagent (MAS) systems. Venturing beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 for enhanced problem-solving and explanation skills. Our experimental backdrop is the smart streetlight Internet of Things (IoT) application. Here, agents use sensors, actuators, and neural networks to create an energy-efficient lighting system. By integrating GPT-4, these agents achieve superior decision-making and adaptability without the need for extensive training. We compare this approach with both traditional neuroevolutionary methods and solutions provided by software engineers, underlining the potential of GPT-driven multiagent systems in IoT. Structurally, the paper outlines the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), introduces our proposed GPT-in-the-loop approach, presents comparative results in the IoT context, and concludes with insights and future directions.</p>
<p>Keywords: GPT-in-the-loop, LLM-in-the-loop, Multiagent system (MAS), self-adaptation, Generative pre-trained transformer (GPT).</p>
<h2>Introduction</h2>
<p>Exploratory investigations are currently underway to harness the reasoning capabilities of Generative Pre-trained Transformers (GPT) for practical applications. Recent studies (Richardson and Sabharwal 2022) (Webb, Holyoak, and Lu 2023) (Wei et al. 2022) (Huang and Chang 2023) indicate that large language models, especially those exceeding 100 billion parameters, are showcasing emergent reasoning abilities. Webb et al. (Webb, Holyoak, and Lu 2023) demonstrated that models like GPT-3 might match or even outdo human reasoning in certain tasks-a trajectory GPT-4 seems set to follow. Further supporting this, (Wei et al. 2022) reveals that a "chain of thought" approach can significantly enhance reasoning in these models, suggesting new methods to utilize their reasoning prowess in real-world scenarios.</p>
<p>Conversely, in the multiagent domain, developing autonomous systems, especially agents that autonomously develop their skills through environment interactions, is an</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>ambitious scientific endeavor (Nolfi 2022). These agents aim to expand their behavioral repertoire in an open-ended manner. A major thrust is enabling them to employ world models, using common sense knowledge akin to humans, to enhance their performance (Nolfi 2022). Such knowledge can be gleaned via self-supervised learning, allowing agents to mentally plan and reason. While neuroevolutionary approaches offer potential solutions (Almansoori, Alkilabi, and Tuci 2023; do Nascimento and de Lucena 2017; Lan, Chen, and Eiben 2019), refining neural networks for performance enhancement is time-intensive, costly, and complex, especially in real-time settings with physical agents. In addition to problem-solving skills, the agents should also offer an explanation for their decisions (Sado et al. 2023).</p>
<p>Bridging these two domains, the concept of "GPT-in-the-loop" emerges as a promising approach. By leveraging the advanced reasoning capabilities of GPT models within the loop of agent decision-making, there's potential to address the challenges in multiagent systems more efficiently. This fusion could harness GPT's inherent adaptability and reasoning prowess, potentially reducing reliance on long training processes that are usual to adaptive approaches (Nolfi 2022). Inspired by human-in-the-loop approaches (Mosqueira-Rey et al. 2023), our proposal defines novel GPT and multiagent system interactions.</p>
<p>Building upon the FIoT framework for adaptable Internet of Things (IoT) applications (do Nascimento and de Lucena 2017), we incorporate the "GPT-in-the-loop" methodology. To create self-adaptive IoT agents, FIoT supports the use of different decision-making engines, like neural networks, state machines, and if-else statement; as the use of different adaptative processes, like evolutionary algorithms, backpropagation, and reinforcement learning. FIoT's flexibility in decision-making engines and adaptive processes make it conducive for GPT integration. This flexibility paves the way for GPT to augment reasoning or adaptive functions. For instance, within an interactive MAS setup, GPT can amplify decision-making, aiding agents in outputs and interactions. In MAS teaching, GPT might guide the adaptive process or even dictate the decision-making engine entirely, adjusting agent behaviors based on environmental feedback.</p>
<p>Furthermore, we have applied the GPT-in-the-loop model to smart streetlights, a benchmark IoT application (Nascimento et al. 2018). In this scenario, agents, equipped with</p>
<p>sensors, actuators, and a neural network, evolve to develop a communication system and behavior that optimizes energy while ensuring adequate lighting. As this study (Nascimento et al. 2018) also assessed 14 software engineers’ solutions to the same challenge, it allows us to perform a direct comparison between the neuroevolutionary approach, the engineers’ solutions, and our GPT-in-the-loop method.</p>
<p>The paper is structured as follows: Section 2 delves into the GPT and FIoT background. Section 3 details our primary contribution, the GPT-in-the-loop approach. Section 4 offers performance results and comparisons within the IoT scenario. We conclude in Section 5.</p>
<h2>Background</h2>
<h3>LLM and GPT</h3>
<p>Large Language Models (LLMs) and Generative Pre-trained Transformers (GPT) are integral parts of AI’s Natural Language Processing (NLP) realm. While LLM is a broad category encompassing models that predict word sequences and can be used for various tasks such as text generation and translation, GPT, developed by OpenAI (OpenAI 2023), is a specific LLM type. GPT, renowned for generating text akin to human writing, undergoes extensive pre-training before fine-tuning for specialized tasks. In essence, GPT is a subclass of LLMs, but not all LLMs are GPT models. Other prominent LLM examples include BERT, RoBERTa, and XLNet.</p>
<p>GPT (Generative Pre-trained Transformer) is rooted in the Transformer neural network design (Vaswani et al. 2017; Brown et al. 2020). Representing breakthroughs in natural language processing, GPT, especially in its advanced iterations like GPT-4, utilizes a deep architecture of many layers of these transformers. A GPT solution comprises several key components, such as a pre-trained neural network model, a fine-tuning component to improve the model for specific tasks, an inference engine that uses the fine-tuned GPT model to generate responses or predictions (i.e. the inference engine feeds input data into the model and processes the model’s output), and data pipeline that handles the flow of data in and out of the model (Brown et al. 2020).</p>
<h3>FIoT: Framework for Self-Adaptive IoT Multiagent Systems</h3>
<p>The Framework for the Internet of Things (FIoT) (do Nascimento and de Lucena 2017; Nascimento 2023) is a software framework designed for building control systems for self-operating agents through learning or rule-based methods. Utilizing FIoT results in a Java software element pre-loaded with features for recognizing autonomous entities, assigning control, developing software agents, collecting device data, and ensuring agent-device interactions.</p>
<p>FIoT’s features can be customized based on the application’s needs. These include: 1) a control unit, ranging from basic if-else conditions to neural networks or preset state machines; 2) a controller adaptation method using techniques like reinforcement learning or genetic algorithms; and 3) a mechanism to evaluate decision-making processes in controlled devices.</p>
<p>There are two primary agents in FIoT: AdaptiveAgent and ObserverAgent. The former oversees IoT devices and uses the controller for decision-making. Its foundation is the MAPE-K loop (Redbooks and Organization 2004), an esteemed model for enhancing system autonomy. It perceives, acts, and reasons, tailoring outputs based on the chosen decision system. Meanwhile, the ObserverAgent gauges overall agent activity and can refine the control system adopted by IoT agents.</p>
<h2>Approach: GPT-in-the-loop</h2>
<p>Drawing inspiration from human-in-the-loop methodologies (Mosqueira-Rey et al. 2023), our proposition delineates novel interactions between GPT and multiagent systems. We propose three main interaction modes:</p>
<ul>
<li>Active MAS: Traditional algorithms drive agents while GPT clarifies outcomes.</li>
<li>Interactive MAS: This encourages a more integrated collaboration between the GPT’s reasoning and the MAS, which has been our primary focus in this work as depicted in Figure 1.</li>
<li>MAS Teaching: Here, the GPT directs the MAS adaptation.</li>
</ul>
<p>In the interactive MAS model, GPT shapes the decision-making engine of the agent. This engine processes inputs, generates outcomes, and influences the manner in which the agent engages with its environment, which in turn impacts application performance. Feedback from these engagements can re-engage the GPT, leading to refinements in agent behaviors.</p>
<p>Figure 1: GPT-in-the-loop: GPT crafts the decision-making engine for the agent, drawing from environmental feedback.</p>
<p>While the interactive MAS mode stands at the heart of our research, we chose to integrate GPT with FIoT. This framework paves the way for probing diverse interaction forms. It permits a complete overhaul of the IoT agents’ decision-making engine or, alternatively, steers the evolution/training process orchestrated by the ObserverAgent.</p>
<p>Figures 2 and 3 illustrate the seamless extension of FIoT to accommodate the GPT-in-the-loop model, tapping</p>
<p>into both the AdaptiveAgent’s controller and the ObserverAgent’s adaptation process. Notably, both the decision-making controller and the adaptive procedure are flexible points at the framework. This allows for varied runtime implementations, so long as class signatures (parameters, inputs, and outputs) remain consistent. For instance, environmental feedback can prompt GPT to craft a new controller for agents.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: Augmenting FIoT to empower agents with decision-making abilities using GPT-crafted code.</p>
<h2>Application Scenario: Smart Streetlights</h2>
<p>In our experiment, we replicated the streetlight scenario from Nascimento et al. (Nascimento et al. 2018) using the FIoT framework. The goal was to create autonomous streetlights balancing energy conservation with effective illumination, ensuring individuals could navigate their paths seamlessly. These streetlights, equipped with sensors and communicative tools, had three core functions: data collection, decision-making, and action execution. The focus of this experiment was on the decision-making aspect.</p>
<p>The original study utilized a three-layer neural network, evolved through a genetic algorithm, to automate the streetlights' decision rules. Software engineers also tackled the challenge, developing decision-making solutions. They were presented with the same simulated scenario, facilitating a comparison of human-devised solutions with the automated neural network method. Subsequently, these solutions were tested in an expanded environment. This second phase aimed to assess whether the decision-making module, originally designed for the first scenario, could be effectively reused in a different environment.</p>
<p>Incorporating the GPT-in-the-loop methodology, and paralleling the strategy in Nascimento et al. (Nascimento et al. 2018), GPT engaged with the primary scenario until it derived a solution surpassing a fitness score of 62 (we set it based on the best fitness value presented in Nascimento et al. (Nascimento et al. 2018)). This derived decision mechanism was then trialed in the expansive environment. Conclusively, we set the GPT-in-the-loop results as a benchmark, juxtaposing them against the top solutions from the neuroevolutionary algorithm, the best software engineer participant, and GPT's own solution.</p>
<p>To facilitate a clear comparison between the two methods, Table 1 showcases the application of the Streetlight Control case study using a neuroevolutionary approach, highlighting the flexible points of the FIoT framework. Conversely, Table 2 delineates the implementation of the Streetlight Control application through the GPT-in-the-loop-based approach, capitalizing on the adaptability of the FIoT framework. Both tables aim to provide a foundation for evaluating the efficacy of each solution within the same application context.</p>
<p>Table 1: Implementing FIoT flexible points to synthesize streetlight controllers using an ML-based approach (Nascimento et al. 2018).</p>
<table>
<thead>
<tr>
<th>FIoT Framework</th>
<th>Light Control Application</th>
</tr>
</thead>
<tbody>
<tr>
<td>Controller</td>
<td>Three Layer Neural Network</td>
</tr>
<tr>
<td>Making Evaluation</td>
<td>Collective Fitness Evaluation: the solution is evaluated based on the energy consumption, the number of people that finished their routes after the simulation ends, and the total time spent by people to move during their trip</td>
</tr>
<tr>
<td>Controller Adaptation</td>
<td>Evolutionary Algorithm: Generate a pool of candidates to represent the neural network parameters</td>
</tr>
</tbody>
</table>
<h2>Results and Discussion</h2>
<p>The GPT-in-the-loop approach required three iterations to reach a fitness score of 62 in the first scenario. Comparatively, the original evolutionary approach underwent 200 generations, with each generation undergoing 50 interactions with the environment. This section details the solutions GPT proposed for the streetlight controllers in each iteration, elucidating the adaptive changes influenced by GPT's explanations. Ultimately, we compared the outcomes of this innovative method against those of neuroevolution and human-generated solutions.</p>
<p>In the initial iteration, the problem description presented to the software engineers in Nascimento et al. (Nascimento et al. 2018) served as the prompt. For every iteration, GPT generated an 'if-else statement' controller accompanied by a rationale for the decision.</p>
<p>The code, as shown in Figure 4, emerged from the first iteration. The foundational idea behind this solution was: 1) Ambient Light Detection: It's the sole strategy highlighting that poles will perpetually be in "listening" mode, regardless of external lighting conditions; 2) Wireless Communication: Stresses the significance of interaction with the pre-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Elevating FIoT to incorporate GPT as a potential adaptive strategy for the Observer Agent.</p>
<p>Table 2: Detailed implementation of FIoT flexible points to synthesize streetlight controllers using the GPT-in-the-loop approach.</p>
<table>
<thead>
<tr>
<th>FIoT Framework</th>
<th>Light Control Application</th>
</tr>
</thead>
<tbody>
<tr>
<td>Controller</td>
<td>GPT-based Decision Engine:</td>
</tr>
<tr>
<td></td>
<td>Use if-else statement controllers</td>
</tr>
<tr>
<td></td>
<td>optimized for the given</td>
</tr>
<tr>
<td></td>
<td>scenario's constraints and goals</td>
</tr>
<tr>
<td>Making Evaluation</td>
<td>Iterative Fitness Evaluation:</td>
</tr>
<tr>
<td></td>
<td>the solution iterates until it</td>
</tr>
<tr>
<td></td>
<td>exceeds a fitness score of 62,</td>
</tr>
<tr>
<td></td>
<td>evaluating based on energy</td>
</tr>
<tr>
<td></td>
<td>consumption, the number of</td>
</tr>
<tr>
<td></td>
<td>people that complete routes,</td>
</tr>
<tr>
<td></td>
<td>and the cumulative time of</td>
</tr>
<tr>
<td></td>
<td>people's journeys</td>
</tr>
<tr>
<td>Controller Adaptation</td>
<td>GPT-in-the-loop:</td>
</tr>
<tr>
<td></td>
<td>GPT engages in</td>
</tr>
<tr>
<td></td>
<td>interactive loops, refining</td>
</tr>
<tr>
<td></td>
<td>its if-else controllers based on</td>
</tr>
<tr>
<td></td>
<td>environment feedback until</td>
</tr>
<tr>
<td></td>
<td>the desired fitness</td>
</tr>
<tr>
<td></td>
<td>level is reached</td>
</tr>
</tbody>
</table>
<p>ceding pole and adjusting illumination based on that communication; 3) Energy Conservation: Sets a distinct condition whereby, in the absence of motion detection for a predetermined cycle count, the light's intensity diminishes.</p>
<p>The first iteration resulted in an average fitness of 29.49. Given its inadequacy, GPT was re-engaged to produce an enhanced solution. For the second iteration, the environment's outputs, such as energy consumption and trip time, were in-</p>
<p>Figure 4: GPT's decision-making engine from the first iteration.</p>
<div class="codehilite"><pre><span></span><code><span class="err">@</span><span class="n">Override</span>
<span class="n">public</span><span class="w"> </span><span class="n">double</span><span class="p">[]</span><span class="w"> </span><span class="n">getOutput</span><span class="p">(</span><span class="n">double</span><span class="p">[]</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">Input</span><span class="w"> </span><span class="n">variables</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">lightingSensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="o">.</span><span class="n">getLightingSensor</span><span class="p">();</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">motionSensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="o">.</span><span class="n">getMotionSensor</span><span class="p">();</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">wirelessReceiver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">this</span><span class="o">.</span>
<span class="w">        </span><span class="n">getPreviousListeningDecision</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">?</span><span class="w"> </span><span class="n">this</span><span class="o">.</span>
<span class="w">        </span><span class="n">getWirelessReceiver</span><span class="p">()</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">listening</span><span class="p">,</span>
<span class="w">        </span><span class="n">ignore</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">value</span><span class="o">.</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">Decision</span><span class="w"> </span><span class="n">variables</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">By</span><span class="w"> </span><span class="n">default</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">keep</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">off</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">By</span><span class="w"> </span><span class="n">default</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">don</span><span class="s1">&#39;t</span>
<span class="w">        </span><span class="n">transmit</span><span class="w"> </span><span class="n">anything</span>
<span class="w">    </span><span class="n">double</span><span class="w"> </span><span class="n">listeningDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">By</span><span class="w"> </span><span class="n">default</span><span class="p">,</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">always</span>
<span class="w">        </span><span class="n">listen</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">surrounding</span><span class="w"> </span><span class="n">posts</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">it</span><span class="s1">&#39;s day, we keep the light off</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">lightingSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="o">//</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">detect</span><span class="w"> </span><span class="n">movement</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">motionSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">            </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">alert</span><span class="w"> </span><span class="n">the</span>
<span class="w">                </span><span class="n">surrounding</span><span class="w"> </span><span class="n">posts</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">detected</span><span class="w"> </span><span class="n">movement</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">If</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">neighboring</span><span class="w"> </span><span class="n">post</span><span class="w"> </span><span class="n">detected</span><span class="w"> </span><span class="n">movement</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">are</span>
<span class="w">        </span><span class="n">listening</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wirelessReceiver</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">partially</span><span class="w"> </span><span class="n">light</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">to</span>
<span class="w">        </span><span class="n">prepare</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">path</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
<span class="o">//</span><span class="w"> </span><span class="n">Action</span><span class="w"> </span><span class="n">decisions</span>
<span class="n">this</span><span class="o">.</span><span class="n">setLightDecision</span><span class="p">(</span><span class="n">lightDecision</span><span class="p">);</span>
<span class="n">this</span><span class="o">.</span><span class="n">setWirelessTransmitter</span><span class="p">(</span><span class="n">wirelessTransmit</span><span class="p">);</span>
<span class="n">this</span><span class="o">.</span><span class="n">setListeningDecision</span><span class="p">(</span><span class="n">listeningDecision</span><span class="p">);</span>
<span class="k">return</span><span class="w"> </span><span class="n">this</span><span class="o">.</span><span class="n">actuador</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>

<p>corporated into the GPT prompt. The code from the second iteration is showcased in Figure 5. Contrary to the first solution, which emphasized persistent ambient light listening, previous pole communication, and energy preservation, the second solution accentuates anticipatory lighting influenced</p>
<p>by adjacent movements and subdued illumination during extreme darkness.</p>
<p>Figure 5: GPT's decision-making engine from the second iteration (input and output settings excluded).</p>
<div class="codehilite"><pre><span></span><code><span class="nv">@Override</span>
<span class="k">public</span><span class="w"> </span><span class="k">double</span><span class="err">[]</span><span class="w"> </span><span class="n">getOutput</span><span class="p">(</span><span class="k">double</span><span class="err">[]</span><span class="w"> </span><span class="k">input</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="cm">/*...*/</span>
<span class="w">    </span><span class="k">double</span><span class="w"> </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">double</span><span class="w"> </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">double</span><span class="w"> </span><span class="n">listeningDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Always</span>
<span class="w">        </span><span class="n">listening</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">optimize</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">person</span><span class="err">’</span><span class="n">s</span><span class="w"> </span><span class="k">path</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="n">motion</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">detected</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">motionSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Turn</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">fully</span><span class="w"> </span><span class="k">for</span>
<span class="w">            </span><span class="n">the</span><span class="w"> </span><span class="n">passerby</span>
<span class="w">            </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Notify</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">nearby</span>
<span class="w">                </span><span class="n">posts</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">prepare</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">path</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="k">If</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">neighboring</span><span class="w"> </span><span class="n">post</span><span class="w"> </span><span class="n">reports</span><span class="w"> </span><span class="n">movement</span>
<span class="w">    </span><span class="err">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wirelessReceiver</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Partially</span><span class="w"> </span><span class="n">light</span><span class="w"> </span><span class="n">up</span>
<span class="w">            </span><span class="k">to</span><span class="w"> </span><span class="n">anticipate</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">passerby</span><span class="err">’</span><span class="n">s</span><span class="w"> </span><span class="n">arrival</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">Energy</span><span class="w"> </span><span class="n">saving</span><span class="w"> </span><span class="k">without</span><span class="w"> </span><span class="n">compromising</span><span class="w"> </span><span class="n">safety</span>
<span class="w">    </span><span class="err">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">lightingSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Keep</span><span class="w"> </span><span class="n">partially</span><span class="w"> </span><span class="n">lit</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">it</span><span class="err">’</span><span class="n">s</span><span class="w"> </span><span class="n">too</span><span class="w"> </span><span class="n">dark</span><span class="p">,</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">ensure</span><span class="w"> </span><span class="ow">some</span><span class="w"> </span><span class="k">level</span>
<span class="w">            </span><span class="k">of</span><span class="w"> </span><span class="n">safety</span>
<span class="w">    </span><span class="err">}</span>
<span class="w">    </span><span class="cm">/*...*/</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">this</span><span class="p">.</span><span class="n">actuador</span><span class="p">;</span>
<span class="err">}</span>
</code></pre></div>

<p>The second iteration notably improved the fitness value, achieving 61.2. However, since this score remained below the target, GPT produced another controller, depicted in Figure 6. Unlike the solution from the second iteration, this new approach concentrates on curtailing data transmissions by sending signals exclusively upon initial motion detection, determining listening necessity based on present light status, and integrating adaptive dimming.</p>
<p>The integration of environmental feedback into successive GPT iterations consistently led to performance improvements. Table 3 displays the fitness outcomes across three iterations for scenario 1, whereas Table 4 presents the outcomes when the decision algorithms were implemented in a more intricate environment for scenario 2. In both scenarios, the third solution proposed by GPT outperformed its predecessors. When juxtaposed with the optimal outcome derived from the neuroevolution method, the solution offered by GPT achieved a superior fitness score in both scenarios. In scenario 1, one participant managed to devise a solution with a slightly better fitness score than that of GPT's. However, this solution faltered in the second scenario. Evaluating GPT's performance against the most successful participantdriven solutions in the second scenario, GPT's solution was unrivaled.</p>
<p>In the quest for optimized streetlight controllers, GPT's iterative approach showcased notable adaptability and improvement. The model's ability to integrate environment feedback between iterations culminated in solutions compet-</p>
<p>Figure 6: GPT's decision-making engine from the third iteration (input and output settings excluded).</p>
<div class="codehilite"><pre><span></span><code><span class="nv">@Override</span>
<span class="w">    </span><span class="k">public</span><span class="w"> </span><span class="k">double</span><span class="err">[]</span><span class="w"> </span><span class="n">getOutput</span><span class="p">(</span><span class="k">double</span><span class="err">[]</span><span class="w"> </span><span class="k">input</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="cm">/*...*/</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">motionSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">this</span><span class="p">.</span><span class="n">getPreviousListeningDecision</span><span class="p">()</span>
<span class="w">                </span><span class="o">!=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">                    </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Transmit</span>
<span class="w">                        </span><span class="n">motion</span><span class="w"> </span><span class="n">detection</span><span class="w"> </span><span class="n">once</span>
<span class="w">                    </span><span class="n">listeningDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="k">No</span><span class="w"> </span><span class="n">need</span>
<span class="w">                        </span><span class="k">to</span><span class="w"> </span><span class="n">listen</span><span class="w"> </span><span class="k">when</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">already</span><span class="w"> </span><span class="n">detect</span>
<span class="w">                            </span><span class="n">motion</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">    </span><span class="err">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">wirelessReceiver</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">this</span><span class="p">.</span><span class="n">getPreviousListeningDecision</span><span class="p">()</span>
<span class="w">            </span><span class="o">!=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="n">wirelessTransmit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Inform</span>
<span class="w">                </span><span class="n">neighbors</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">anticipatory</span>
<span class="w">                </span><span class="n">lighting</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">    </span><span class="err">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">lightingSensor</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0.0</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">lightDecision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>
<span class="w">    </span><span class="err">}</span>
<span class="w">    </span><span class="cm">/*...*/</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">this</span><span class="p">.</span><span class="n">actuador</span><span class="p">;</span>
<span class="err">}</span>
</code></pre></div>

<p>itive with human and neuroevolution strategies. Moreover, GPT's intrinsic explainability, as evident in its generated 'ifelse statements' and accompanying rationale, offers valuable insights for users, bridging the gap between automation and human understanding.</p>
<h2>Conclusion and Future Horizons</h2>
<p>The synergy between Large Language Models (LLMs) like GPT-4 and multiagent systems promises to redefine the boundaries of autonomous interactions and adaptability. Our research underscores the compelling advantages of this integration. The GPT-in-the-loop methodology exemplifies how problem-solving abilities can be significantly enhanced in a dynamic setting. When LLMs are incorporated into agents, it catalyzes a two-fold benefit: a supercharged reasoning mechanism for each agent and a more efficient communication process across a diverse multi-agent landscape.</p>
<p>Furthermore, GPT's unique ability to elucidate its decision-making process brings a new dimension of transparency. This clarity not only strengthens confidence in the system's actions but also paves the way for a deeper understanding of intricate decisions.</p>
<p>Nonetheless, this promising integration is met with inherent challenges. From the substantial computational needs of LLMs to the subtleties surrounding their decisions and looming ethical considerations, there's a clear call for meticulous evaluation. The forward-looking vision of agents dynamically leveraging a cloud-hosted GPT to optimize their actions in real-time is undeniably ambitious. To fully mate-</p>
<p>Table 3: Performance comparison of GPT iterations, best neuroevolution solution, and best participant’s solution in the first scenario.</p>
<table>
<thead>
<tr>
<th>Solution</th>
<th>Energy</th>
<th>People</th>
<th>TotalFTrip</th>
<th>Fitness</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT (iteration 1)</td>
<td>4.03</td>
<td>66.66</td>
<td>59.25</td>
<td>29.49</td>
</tr>
<tr>
<td>GPT (iteration 2)</td>
<td>15.02</td>
<td>100</td>
<td>54.62</td>
<td>61.2</td>
</tr>
<tr>
<td>GPT (iteration 3)</td>
<td>11.92</td>
<td>100</td>
<td>54.62</td>
<td>62.44</td>
</tr>
<tr>
<td>Best neuroevolution’s solution</td>
<td>8.1</td>
<td>100</td>
<td>62.03</td>
<td>59.53</td>
</tr>
<tr>
<td>Best participant’s solution</td>
<td>9.46</td>
<td>100</td>
<td>55.55</td>
<td>62.88</td>
</tr>
</tbody>
</table>
<p>Table 4: Performance comparison of GPT iterations, best neuroevolution solution, and best participant’s solution in the second scenario.</p>
<table>
<thead>
<tr>
<th>Solution</th>
<th>Energy</th>
<th>People</th>
<th>TotalFTrip</th>
<th>Fitness</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT (iteration 1)</td>
<td>2.08</td>
<td>66.66</td>
<td>48.51</td>
<td>36.72</td>
</tr>
<tr>
<td>GPT (iteration 2)</td>
<td>11.29</td>
<td>100</td>
<td>41.10</td>
<td>70.81</td>
</tr>
<tr>
<td>GPT (iteration 3)</td>
<td>9.76</td>
<td>100</td>
<td>41.10</td>
<td>71.42</td>
</tr>
<tr>
<td>Best neuroevolution’s solution</td>
<td>8.46</td>
<td>100</td>
<td>46.29</td>
<td>68.83</td>
</tr>
<tr>
<td>Best participant’s solution</td>
<td>50.52</td>
<td>100</td>
<td>38.14</td>
<td>56.9</td>
</tr>
</tbody>
</table>
<p>rialize this vision, further research and exploration are essential, especially in leveraging GPT-in-the-loop to enhance diverse GPT-Multiagent interactions.</p>
<h2>Exploring Further Configurations for the GPT-in-the-loop</h2>
<p>The premise of “GPT-in-the-loop” holds tremendous potential in the realm of multiagent systems, leveraging the sophisticated reasoning capabilities of GPT models directly into agent decision-making processes. Given the inspiration drawn from the human-in-the-loop approaches (Mosqueira-Rey et al. 2023), our roadmap defines diverse GPT and multiagent system interactions, which can be expanded in several directions:</p>
<ol>
<li>Active MAS Involvement: A scenario wherein traditional algorithms guide the multiagent systems, and GPT steps in to provide clarity and interpretation of results. This interaction mode mainly draws on GPT’s unparalleled explainability prowess, making complex decisions more transparent and comprehensible.</li>
</ol>
<p>(a) GPT as a Decentralized Decision Engine: A promising direction is to use GPT as the primary decision-maker for each agent. Instead of one general reasoning mechanism for all agents, envision each agent having its personalized GPT. This approach allows agents to make context-specific decisions in real-time, drawing from GPT’s vast knowledge to address their unique situations.
2. Interactive MAS Integration: This model envisions a more intimate alliance between GPT’s reasoning faculties and the multiagent system. Here, there’s a bidirectional flow of information and decisions, ensuring that both GPT and MAS evolve and adapt symbiotically.
3. MAS Teaching: GPT’s role as a tutor or mentor to multiagent systems. GPT could oversee, instruct, and guide the adaptation process of MAS.</p>
<h2>Enhancing Human Engagement in the Loop</h2>
<p>While the human element remains foundational, especially in shaping the initial system prompt or documentation, the potential for a more intertwined human-machine partnership exists.</p>
<ol>
<li>Direct Influence: Encouraging humans to directly shape agent behaviors is key. An intuitive interface could enable users to propose behaviors, pinpoint overarching goals, or lay out specific parameters. This merges human intuition with technological prowess, targeting the best results for agents.</li>
<li>Feedback Mechanism: It’s beneficial when agents offer clear summaries of their decisions, from data analysis to behavioral tweaks. Such transparency strengthens trust, offers clarity, and provides avenues for system enhancements based on human feedback.</li>
<li>Making Sense of Complexity: Even though adaptive systems are complex by design, demystifying their workings is essential. Translating intricate operations into comprehensible language paves the way for enhanced human-machine interactions.</li>
</ol>
<h2>Diversifying Application Scenarios:</h2>
<p>Venturing beyond our preliminary framework, our ambition is to validate the GPT-in-the-loop approach in a spectrum of applications, especially when integrated with realistic robotics frameworks like Evorobot (Nolfi 2020) and Webots (Michel 2004). Such platforms enable the deployment of neural networks sculpted by evolutionary techniques.</p>
<p>The domain of evolutionary robotics unravels complex challenges, a notable one being the food foraging task (Pontes-Filho et al. 2022). Here, agents are tasked with distinguishing nourishing food sources from harmful ones, adeptly navigating environmental intricacies for optimal survival. In this setup, agents traverse a dynamic landscape, reliant on a singular light sensor, to ascertain the edibility of</p>
<p>proximate food. Represented in alternating colors of black and white, the safety of the food keeps shifting, mandating constant adaptability. Agents face a binary choice: to consume or avoid the food, within a given time frame.</p>
<p>Figure 7 depicts our conceptualization of GPT-in-the-loop within a distinct application setting, accounting for an alternative MAS interaction paradigm. Here, the graphic portrays a MAS teaching interaction: while agents predominantly adhere to a conventional evolutionary path, GPT plays a supportive role in their evolution.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 7: GPT-in-the-loop: GPT supporting the evolutionary process.</p>
<p><strong>Evolutionary GPT Engagement:</strong> Embedding GPT within the evolutionary paradigm offers captivating prospects. GPT, transcending its observational role, can proactively shape the evolutionary trajectory. This encompasses guiding individual selection, fine-tuning genetic algorithms, and pinpointing ideal neural network configurations. Incorporating GPT's analytical prowess with evolutionary strategies could potentially evolve solutions that are not only optimal but also explainable.</p>
<p>Integrating LLMs into such narratives exhibits significant potential. With the GPT-in-the-loop approach, we're amplifying agent adaptability and delving deep into the multifaceted GPT-MAS interactions delineated in subsection . This synergy might herald a transformative shift in the adaptability and prowess of future robotic agents.</p>
<h3>Diversifying LLM Choices:</h3>
<p>While we centered on GPT-4, many other LLMs exist with unique capabilities. Exploring these options and creating clear evaluation standards might lead to even more effective multiagent strategies.</p>
<h3>Addressing the Black-Box Concern:</h3>
<p>GPT-4 remains proprietary and opaque despite its explanatory capabilities. To ensure trust and safety, there's imperative to decode its operational logic, facilitating rigorous testing and risk-mitigation strategies.</p>
<h3>Acknowledgment</h3>
<p>This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC), and the Centre for Community Mapping (COMAP).</p>
<h3>References</h3>
<p>Almansoori, A.; Alkilabi, M.; and Tuci, E. 2023. On the evolution of mechanisms for three-option collective decision-making in a swarm of simulated robots. In <em>Proceedings of the Genetic and Evolutionary Computation Conference</em>, 4–12.</p>
<p>Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020. Language models are few-shot learners. <em>Advances in neural information processing systems</em>, 33: 1877–1901.</p>
<p>do Nascimento, N. M.; and de Lucena, C. J. P. 2017. Fiot: An agent-based framework for self-adaptive and self-organizing applications based on the internet of things. <em>Information Sciences</em>, 378: 161–176.</p>
<p>Huang, J.; and Chang, K. C.-C. 2023. Towards Reasoning in Large Language Models: A Survey. arXiv:2212.10403.</p>
<p>Lan, G.; Chen, J.; and Eiben, A. 2019. Evolutionary predator-prey robot systems: From simulation to real world. In <em>Proceedings of the genetic and evolutionary computation conference companion</em>, 123–124.</p>
<p>Michel, O. 2004. Cyberbotics ltd. webots™: professional mobile robot simulation. <em>International Journal of Advanced Robotic Systems</em>, 1(1): 5.</p>
<p>Mosqueira-Rey, E.; Hernández-Pereira, E.; Alonso-Ríos, D.; Bobes-Bascarán, J.; and Fernández-Leal, Á. 2023. Human-in-the-loop machine learning: A state of the art. <em>Artificial Intelligence Review</em>, 56(4): 3005–3054.</p>
<p>Nascimento, N. 2023. A software framework for developing self-adaptive IoT agents. https://github.com/nathyecomp/fiot.</p>
<p>Nascimento, N.; Alencar, P.; Lucena, C.; and Cowan, D. 2018. Toward human-in-the-loop collaboration between software engineers and machine learning algorithms. In <em>2018 IEEE International Conference on Big Data (Big Data)</em>, 3534–3540. IEEE.</p>
<p>Nolfi, S. 2020. A tool for training robots through evolutionary and reinforcement learning methods. https://github.com/snolfi/evorobotpy2.</p>
<p>Nolfi, S. 2022. Progress and challenges in adaptive robotics. <em>Frontiers in Robotics and AI</em>, 9: 1020462.</p>
<p>OpenAI. 2023. GPT Models API. Accessed: 2023-08-07.</p>
<p>Pontes-Filho, S.; Olsen, K.; Yazidi, A.; Riegler, M. A.; Halvorsen, P.; and Michele, S. 2022. Towards the Neuroevolution of Low-level artificial general intelligence. <em>Frontiers in Robotics and AI</em>, 9: 1007547.</p>
<p>Redbooks, I.; and Organization, I. B. M. C. I. T. S. 2004. <em>A Practical Guide to the IBM Autonomic Computing Toolkit</em>. IBM redbooks. IBM, International Support Organization. ISBN 9780738498058.</p>
<p>Richardson, K.; and Sabharwal, A. 2022. Pushing the limits of rule reasoning in transformers through natural language satisfiability. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, 11209-11219.
Sado, F.; Loo, C. K.; Liew, W. S.; Kerzel, M.; and Wermter, S. 2023. Explainable Goal-Driven Agents and Robots - A Comprehensive Review. ACM Comput. Surv., 55(10).
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is all you need. Advances in neural information processing systems, 30.
Webb, T.; Holyoak, K. J.; and Lu, H. 2023. Emergent analogical reasoning in large language models. Nature Human Behaviour, 1-16.
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.; Le, Q. V.; Zhou, D.; et al. 2022. Chain-ofthought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35: $24824-24837$.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Copyright © 2024. All rights reserved.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>