<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4482 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4482</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4482</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-97.html">extraction-schema-97</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <p><strong>Paper ID:</strong> paper-d8be118ba41df62ca92e49b1f757d53404393529</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d8be118ba41df62ca92e49b1f757d53404393529" target="_blank">The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research.</p>
                <p><strong>Paper Abstract:</strong> In recent years, groundbreaking advancements in natural language processing have culminated in the emergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a vast array of domains, including the understanding, generation, and translation of natural language, and even tasks that extend beyond language processing. In this report, we delve into the performance of LLMs within the context of scientific discovery, focusing on GPT-4, the state-of-the-art language model. Our investigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational chemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial differential equations (PDE). Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research. Our exploration methodology primarily consists of expert-driven case assessments, which offer qualitative insights into the model's comprehension of intricate scientific concepts and relationships, and occasionally benchmark testing, which quantitatively evaluates the model's capacity to solve well-defined domain-specific problems. Our preliminary exploration indicates that GPT-4 exhibits promising potential for a variety of scientific applications, demonstrating its aptitude for handling complex problem-solving and knowledge integration tasks. Broadly speaking, we evaluate GPT-4's knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4482.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4482.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art large language model (LLM) used in this study to interpret scientific text, answer domain questions, perform case studies, and attempt quantitative prediction tasks (e.g., drug-target affinity, molecular property regression, PDE guidance) via prompt-based interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Prompt-driven GPT-4 analysis pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper uses GPT-4 via the Azure OpenAI Service in interactive, prompt-driven experiments. Methodology combines expert-driven qualitative case studies and quantitative benchmark tests. Prompts include system messages (e.g., 'You are a drug assistant'), zero-shot, few-shot, and similarity-based prompting; inputs provided are natural-language descriptions, SMILES strings, FASTA sequences, and dataset records. For some quantitative tasks (drug-target affinity) GPT-4 was given dataset samples (BindingDB, DAVIS) and asked to estimate affinity; temperature was set (reported 0.7) and multiple model versions (v0314, occasional 0613) were used. The pipeline is entirely LLM-centric (no docking or external simulation was actually executed), with outputs compared to ground-truth dataset labels for validation where applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Azure OpenAI Service)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Drug discovery (chemistry, biology), computational chemistry, materials design, partial differential equations (applied mathematics)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Empirical/quantitative relationships and predictive mappings (e.g., drug-target binding affinity regression, molecular property prediction), plus restatement/extraction of established empirical heuristics (e.g., Lipinski's Rule of Five); not formal derivation of new physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Examples discussed in the paper include: (1) Lipinski's Rule of Five restated as inequalities: molecular weight < 500 Da; logP ≤ 5; H-bond donors ≤ 5; H-bond acceptors ≤ 10; (2) predicted drug-target affinity values (regression outputs) such as a produced docking-like score '-7.2 kcal/mol' in a qualitative example (GPT-4 fabricated such a score without running docking); (3) molecular property numeric estimates (e.g., XLogP3, TPSA) returned by GPT-4 in cases though with occasional counting errors.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Prompt-based text mining and direct question-answering: GPT-4 was given chemical names, SMILES, FASTA sequences, or dataset rows and asked to extract, summarize, or predict numerical relationships; for benchmarks, model was fed sample inputs and asked to produce numerical affinity/property values. Extraction relied on GPT-4's internal knowledge and pattern completion rather than explicit parsing of equations from PDF images or running external simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Quantitative evaluation on public benchmark datasets (BindingDB and DAVIS) with a random selection of 1,000 samples for testing; comparison of GPT-4 outputs to ground-truth affinity labels where possible; additional qualitative case checks against authoritative databases (e.g., PubChem, DrugBank) and expert inspection. The paper notes fabricated numeric outputs (e.g., emulated docking scores) requiring verification.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Specific numeric performance metrics (e.g., RMSE, Pearson r) are not reported in the provided excerpt; the paper reports qualitative observations that GPT-4 can produce plausible-sounding numeric predictions but may be inaccurate and prone to fabrication for computationally-derived quantities.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not quantified in the excerpt; the authors report mixed success: accurate high-level conceptual extractions (e.g., Lipinski rules, target descriptions), reasonable but error-prone numeric/property outputs, frequent failures for precise sequence-to-structure SMILES generation and fabricated numerical predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Major failure modes reported: (1) GPT-4 fabricates precise numerical results when asked to emulate simulations (e.g., docking) without actually running them; (2) difficulty reliably generating or handling SMILES and atom counts due to tokenization and representation issues; (3) errors in counting-based properties (heavy atom counts, stereochemistry); (4) limited precision on quantitative regression tasks unless integrated with domain-specific tools or fine-tuning; (5) reliance on prompt engineering and iterative guidance for correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No rigorous baseline model comparisons are provided in the excerpt; authors reference domain tools (e.g., AutoDock Vina) and datasets (BindingDB, DAVIS) used as ground-truth, but GPT-4 outputs were not consistently benchmarked against standard cheminformatics or docking pipelines in the presented text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4482.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4482.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM orchestration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based orchestration/controllers for coordinating models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concept and practice where LLMs act as controllers or orchestrators to coordinate other machine-learning models and tools to perform complex tasks, e.g., chaining retrieval, models, and domain tools to produce integrated outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM orchestration paradigm (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper cites prior work using LLMs as controllers/orchestrators to coordinate other ML models and tools [numerous citations]. The described paradigm has the LLM manage task flow: select sub-tasks, call specialized models or software (e.g., docking, property calculators), aggregate outputs, and produce a coherent final answer. The current study mentions this as an important integration avenue but does not implement a full orchestrated pipeline in the experiments (focus is on intrinsic GPT-4 capabilities).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General across domains (chemistry, biology, materials science, computational workflows)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Facilitation of empirical relationship extraction and multi-model pipelines rather than a single law type; enables combining model outputs (e.g., docking scores + ML predictions) to produce quantitative inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>No concrete new laws presented; cited as an approach to enable extraction/discovery workflows (e.g., orchestrate a docking tool + ML regressor to produce binding-affinity relationships).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Orchestration: LLM selects and sequences calls to specialized models/tools and aggregates their numeric outputs; extraction would be via downstream models/tooling rather than the LLM alone.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Not applied/validated in this paper's experiments; referenced as prior-art and suggested future direction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes integration with specialized tools can greatly enhance capabilities but was largely out of scope for this report; challenges include reliability of tool invocation, verification of numeric outputs, and fail-safe handling when tools are unavailable or outputs conflict.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No direct comparisons provided in the excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4482.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4482.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI/ML for knowledge discovery</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Artificial intelligence and machine learning for data integration and knowledge discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generic reference to AI/ML techniques (including LLMs and other models) that integrate heterogeneous data sources (literature, experimental data, clinical records) to uncover hypotheses, hidden relationships, and quantitative patterns in drug-target-disease spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI/ML knowledge-discovery approaches (as discussed)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper discusses how AI/ML can be applied to multiple drug-discovery challenges: target identification, virtual screening, QSAR (quantitative structure–activity relationships), ADMET prediction, de novo design, and drug repurposing. These approaches typically combine curated datasets, statistical/ML regression models, generative models, and (optionally) LLM-driven literature synthesis to extract quantitative relationships between molecular structure and properties.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Drug discovery, bioinformatics, cheminformatics</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Empirical QSAR relationships, predictive statistical/regression mappings (structure → activity/property), correlations between multi-omic signals and phenotypes.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>The paper lists use-cases (QSAR, ADMET models) but does not present new formulas; example classical relationships include QSAR-style regression mappings (activity ≈ f(structural descriptors)), though no explicit equations are reported in the excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Integration of literature mining, dataset-driven ML modeling, and predictive model training to distill correlations and quantitative predictive relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Described generally: benchmark datasets, cross-validation, and expert evaluation are suggested; no concrete validation numbers given in excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>General limitations noted include difficulty of predictive accuracy, high false-positive/false-discovery rates, dependence on data quality, and the need for domain-specific tools and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not specified in the excerpt; suggestions to combine LLMs with domain-specific models imply baselines would be specialized tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4482.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4482.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs or AI systems being used to extract, discover, or distill quantitative laws, relationships, or patterns from scientific papers or literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 for PDEs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 assistance for Partial Differential Equations (PDE) research</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of GPT-4 to understand PDE concepts, recommend analytical/numerical solution methods, provide proof approaches, and generate code to solve PDEs, with limited capacity for independently discovering novel mathematical theories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Prompt-driven PDE assistance using GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The authors used GPT-4 to probe understanding of PDE fundamentals, to request analytical solutions, numerical methods, and to generate code for solving PDEs; GPT-4 provides conceptual mappings between PDE types and solution approaches, suggests numerical discretizations and solvers, and produces example implementations in common programming languages. Interaction is prompt-based; the model is not claimed to autonomously discover new PDE laws but to assist in deriving or summarizing existing relationships and solution strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (Azure OpenAI Service)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Applied mathematics, computational physics, engineering</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Mathematical relationships and solution forms (analytical solutions, theorem-proof approaches, relationships between PDE forms and solution techniques); not new physical laws but distillation/explication of known relationships and numerical methods.</td>
                        </tr>
                        <tr>
                            <td><strong>law_examples</strong></td>
                            <td>Examples include mapping PDE types to recommended solution methods (e.g., 'use separation of variables for linear homogeneous PDEs with separable domains', 'use finite difference/finite element methods for numerical solution'), and example analytic solution approaches; no novel closed-form PDE laws are claimed.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_method</strong></td>
                            <td>Textual question-answering and code generation from prompts describing PDEs; extraction consists of retrieving and reorganizing known mathematical relationships from GPT-4's internal training.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approach</strong></td>
                            <td>Qualitative evaluation by experts in the paper; some code-generation outputs were run/inspected, but the excerpt notes GPT-4's theorem-proving and novel-theory discovery capacity remains limited.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not quantified; authors report GPT-4 is useful for conceptual guidance and code scaffolding but limited for rigorous theorem-proving and independent discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include lack of rigor for novel mathematical discovery, occasional incorrect derivations or proofs, and the need for expert verification of generated solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No formal baseline comparisons provided in excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AutoGPT <em>(Rating: 2)</em></li>
                <li>ChemCrow <em>(Rating: 2)</em></li>
                <li>BindingDB <em>(Rating: 2)</em></li>
                <li>DAVIS <em>(Rating: 2)</em></li>
                <li>AutoDock Vina <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4482",
    "paper_id": "paper-d8be118ba41df62ca92e49b1f757d53404393529",
    "extraction_schema_id": "extraction-schema-97",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A state-of-the-art large language model (LLM) used in this study to interpret scientific text, answer domain questions, perform case studies, and attempt quantitative prediction tasks (e.g., drug-target affinity, molecular property regression, PDE guidance) via prompt-based interaction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Prompt-driven GPT-4 analysis pipeline",
            "system_description": "The paper uses GPT-4 via the Azure OpenAI Service in interactive, prompt-driven experiments. Methodology combines expert-driven qualitative case studies and quantitative benchmark tests. Prompts include system messages (e.g., 'You are a drug assistant'), zero-shot, few-shot, and similarity-based prompting; inputs provided are natural-language descriptions, SMILES strings, FASTA sequences, and dataset records. For some quantitative tasks (drug-target affinity) GPT-4 was given dataset samples (BindingDB, DAVIS) and asked to estimate affinity; temperature was set (reported 0.7) and multiple model versions (v0314, occasional 0613) were used. The pipeline is entirely LLM-centric (no docking or external simulation was actually executed), with outputs compared to ground-truth dataset labels for validation where applicable.",
            "model_name": "GPT-4 (Azure OpenAI Service)",
            "model_size": null,
            "scientific_domain": "Drug discovery (chemistry, biology), computational chemistry, materials design, partial differential equations (applied mathematics)",
            "number_of_papers": null,
            "law_type": "Empirical/quantitative relationships and predictive mappings (e.g., drug-target binding affinity regression, molecular property prediction), plus restatement/extraction of established empirical heuristics (e.g., Lipinski's Rule of Five); not formal derivation of new physical laws.",
            "law_examples": "Examples discussed in the paper include: (1) Lipinski's Rule of Five restated as inequalities: molecular weight &lt; 500 Da; logP ≤ 5; H-bond donors ≤ 5; H-bond acceptors ≤ 10; (2) predicted drug-target affinity values (regression outputs) such as a produced docking-like score '-7.2 kcal/mol' in a qualitative example (GPT-4 fabricated such a score without running docking); (3) molecular property numeric estimates (e.g., XLogP3, TPSA) returned by GPT-4 in cases though with occasional counting errors.",
            "extraction_method": "Prompt-based text mining and direct question-answering: GPT-4 was given chemical names, SMILES, FASTA sequences, or dataset rows and asked to extract, summarize, or predict numerical relationships; for benchmarks, model was fed sample inputs and asked to produce numerical affinity/property values. Extraction relied on GPT-4's internal knowledge and pattern completion rather than explicit parsing of equations from PDF images or running external simulators.",
            "validation_approach": "Quantitative evaluation on public benchmark datasets (BindingDB and DAVIS) with a random selection of 1,000 samples for testing; comparison of GPT-4 outputs to ground-truth affinity labels where possible; additional qualitative case checks against authoritative databases (e.g., PubChem, DrugBank) and expert inspection. The paper notes fabricated numeric outputs (e.g., emulated docking scores) requiring verification.",
            "performance_metrics": "Specific numeric performance metrics (e.g., RMSE, Pearson r) are not reported in the provided excerpt; the paper reports qualitative observations that GPT-4 can produce plausible-sounding numeric predictions but may be inaccurate and prone to fabrication for computationally-derived quantities.",
            "success_rate": "Not quantified in the excerpt; the authors report mixed success: accurate high-level conceptual extractions (e.g., Lipinski rules, target descriptions), reasonable but error-prone numeric/property outputs, frequent failures for precise sequence-to-structure SMILES generation and fabricated numerical predictions.",
            "challenges_limitations": "Major failure modes reported: (1) GPT-4 fabricates precise numerical results when asked to emulate simulations (e.g., docking) without actually running them; (2) difficulty reliably generating or handling SMILES and atom counts due to tokenization and representation issues; (3) errors in counting-based properties (heavy atom counts, stereochemistry); (4) limited precision on quantitative regression tasks unless integrated with domain-specific tools or fine-tuning; (5) reliance on prompt engineering and iterative guidance for correctness.",
            "comparison_baseline": "No rigorous baseline model comparisons are provided in the excerpt; authors reference domain tools (e.g., AutoDock Vina) and datasets (BindingDB, DAVIS) used as ground-truth, but GPT-4 outputs were not consistently benchmarked against standard cheminformatics or docking pipelines in the presented text.",
            "uuid": "e4482.0",
            "source_info": {
                "paper_title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LLM orchestration",
            "name_full": "LLM-based orchestration/controllers for coordinating models",
            "brief_description": "Concept and practice where LLMs act as controllers or orchestrators to coordinate other machine-learning models and tools to perform complex tasks, e.g., chaining retrieval, models, and domain tools to produce integrated outputs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "LLM orchestration paradigm (as cited)",
            "system_description": "The paper cites prior work using LLMs as controllers/orchestrators to coordinate other ML models and tools [numerous citations]. The described paradigm has the LLM manage task flow: select sub-tasks, call specialized models or software (e.g., docking, property calculators), aggregate outputs, and produce a coherent final answer. The current study mentions this as an important integration avenue but does not implement a full orchestrated pipeline in the experiments (focus is on intrinsic GPT-4 capabilities).",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "General across domains (chemistry, biology, materials science, computational workflows)",
            "number_of_papers": null,
            "law_type": "Facilitation of empirical relationship extraction and multi-model pipelines rather than a single law type; enables combining model outputs (e.g., docking scores + ML predictions) to produce quantitative inferences.",
            "law_examples": "No concrete new laws presented; cited as an approach to enable extraction/discovery workflows (e.g., orchestrate a docking tool + ML regressor to produce binding-affinity relationships).",
            "extraction_method": "Orchestration: LLM selects and sequences calls to specialized models/tools and aggregates their numeric outputs; extraction would be via downstream models/tooling rather than the LLM alone.",
            "validation_approach": "Not applied/validated in this paper's experiments; referenced as prior-art and suggested future direction.",
            "performance_metrics": "Not reported in this paper.",
            "success_rate": "Not reported.",
            "challenges_limitations": "Paper notes integration with specialized tools can greatly enhance capabilities but was largely out of scope for this report; challenges include reliability of tool invocation, verification of numeric outputs, and fail-safe handling when tools are unavailable or outputs conflict.",
            "comparison_baseline": "No direct comparisons provided in the excerpt.",
            "uuid": "e4482.1",
            "source_info": {
                "paper_title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "AI/ML for knowledge discovery",
            "name_full": "Artificial intelligence and machine learning for data integration and knowledge discovery",
            "brief_description": "Generic reference to AI/ML techniques (including LLMs and other models) that integrate heterogeneous data sources (literature, experimental data, clinical records) to uncover hypotheses, hidden relationships, and quantitative patterns in drug-target-disease spaces.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AI/ML knowledge-discovery approaches (as discussed)",
            "system_description": "The paper discusses how AI/ML can be applied to multiple drug-discovery challenges: target identification, virtual screening, QSAR (quantitative structure–activity relationships), ADMET prediction, de novo design, and drug repurposing. These approaches typically combine curated datasets, statistical/ML regression models, generative models, and (optionally) LLM-driven literature synthesis to extract quantitative relationships between molecular structure and properties.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Drug discovery, bioinformatics, cheminformatics",
            "number_of_papers": null,
            "law_type": "Empirical QSAR relationships, predictive statistical/regression mappings (structure → activity/property), correlations between multi-omic signals and phenotypes.",
            "law_examples": "The paper lists use-cases (QSAR, ADMET models) but does not present new formulas; example classical relationships include QSAR-style regression mappings (activity ≈ f(structural descriptors)), though no explicit equations are reported in the excerpt.",
            "extraction_method": "Integration of literature mining, dataset-driven ML modeling, and predictive model training to distill correlations and quantitative predictive relationships.",
            "validation_approach": "Described generally: benchmark datasets, cross-validation, and expert evaluation are suggested; no concrete validation numbers given in excerpt.",
            "performance_metrics": "Not reported here.",
            "success_rate": "Not reported.",
            "challenges_limitations": "General limitations noted include difficulty of predictive accuracy, high false-positive/false-discovery rates, dependence on data quality, and the need for domain-specific tools and verification.",
            "comparison_baseline": "Not specified in the excerpt; suggestions to combine LLMs with domain-specific models imply baselines would be specialized tools.",
            "uuid": "e4482.2",
            "source_info": {
                "paper_title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "GPT-4 for PDEs",
            "name_full": "GPT-4 assistance for Partial Differential Equations (PDE) research",
            "brief_description": "Use of GPT-4 to understand PDE concepts, recommend analytical/numerical solution methods, provide proof approaches, and generate code to solve PDEs, with limited capacity for independently discovering novel mathematical theories.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Prompt-driven PDE assistance using GPT-4",
            "system_description": "The authors used GPT-4 to probe understanding of PDE fundamentals, to request analytical solutions, numerical methods, and to generate code for solving PDEs; GPT-4 provides conceptual mappings between PDE types and solution approaches, suggests numerical discretizations and solvers, and produces example implementations in common programming languages. Interaction is prompt-based; the model is not claimed to autonomously discover new PDE laws but to assist in deriving or summarizing existing relationships and solution strategies.",
            "model_name": "GPT-4 (Azure OpenAI Service)",
            "model_size": null,
            "scientific_domain": "Applied mathematics, computational physics, engineering",
            "number_of_papers": null,
            "law_type": "Mathematical relationships and solution forms (analytical solutions, theorem-proof approaches, relationships between PDE forms and solution techniques); not new physical laws but distillation/explication of known relationships and numerical methods.",
            "law_examples": "Examples include mapping PDE types to recommended solution methods (e.g., 'use separation of variables for linear homogeneous PDEs with separable domains', 'use finite difference/finite element methods for numerical solution'), and example analytic solution approaches; no novel closed-form PDE laws are claimed.",
            "extraction_method": "Textual question-answering and code generation from prompts describing PDEs; extraction consists of retrieving and reorganizing known mathematical relationships from GPT-4's internal training.",
            "validation_approach": "Qualitative evaluation by experts in the paper; some code-generation outputs were run/inspected, but the excerpt notes GPT-4's theorem-proving and novel-theory discovery capacity remains limited.",
            "performance_metrics": "Not provided in excerpt.",
            "success_rate": "Not quantified; authors report GPT-4 is useful for conceptual guidance and code scaffolding but limited for rigorous theorem-proving and independent discovery.",
            "challenges_limitations": "Limitations include lack of rigor for novel mathematical discovery, occasional incorrect derivations or proofs, and the need for expert verification of generated solutions.",
            "comparison_baseline": "No formal baseline comparisons provided in excerpt.",
            "uuid": "e4482.3",
            "source_info": {
                "paper_title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AutoGPT",
            "rating": 2
        },
        {
            "paper_title": "ChemCrow",
            "rating": 2
        },
        {
            "paper_title": "BindingDB",
            "rating": 2
        },
        {
            "paper_title": "DAVIS",
            "rating": 2
        },
        {
            "paper_title": "AutoDock Vina",
            "rating": 1
        }
    ],
    "cost": 0.01521825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4</h1>
<p>Microsoft Research AI4Science<br>Microsoft Azure Quantum<br>llm4sciencediscovery@microsoft.com<br>November, 2023</p>
<h4>Abstract</h4>
<p>In recent years, groundbreaking advancements in natural language processing have culminated in the emergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a vast array of domains, including the understanding, generation, and translation of natural language, and even tasks that extend beyond language processing. In this report, we delve into the performance of LLMs within the context of scientific discovery/research, focusing on GPT-4, the state-of-the-art language model. Our investigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational chemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial differential equations (PDE).</p>
<p>Evaluating GPT-4 on scientific tasks is crucial for uncovering its potential across various research domains, validating its domain-specific expertise, accelerating scientific progress, optimizing resource allocation, guiding future model development, and fostering interdisciplinary research. Our exploration methodology primarily consists of expert-driven case assessments, which offer qualitative insights into the model's comprehension of intricate scientific concepts and relationships, and occasionally benchmark testing, which quantitatively evaluates the model's capacity to solve well-defined domain-specific problems.</p>
<p>Our preliminary exploration indicates that GPT-4 exhibits promising potential for a variety of scientific applications, demonstrating its aptitude for handling complex problem-solving and knowledge integration tasks. We present an analysis of GPT-4's performance in the aforementioned domains (e.g., drug discovery, biology, computational chemistry, materials design, etc.), emphasizing its strengths and limitations. Broadly speaking, we evaluate GPT-4's knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilities.</p>
<p>In biology and materials design, GPT-4 possesses extensive domain knowledge that can help address specific requirements. In other fields, like drug discovery, GPT-4 displays a strong ability to predict properties. However, in research areas like computational chemistry and PDE, while GPT-4 shows promise for aiding researchers with predictions and calculations, further efforts are required to enhance its accuracy. Despite its impressive capabilities, GPT-4 can be improved for quantitative calculation tasks, e.g., fine-tuning is needed to achieve better accuracy. ${ }^{1}$</p>
<p>We hope this report serves as a valuable resource for researchers and practitioners seeking to harness the power of LLMs for scientific research and applications, as well as for those interested in advancing natural language processing for domain-specific scientific tasks. It's important to emphasize that the field of LLMs and large-scale machine learning is progressing rapidly, and future generations of this technology may possess additional capabilities beyond those highlighted in this report. Notably, the integration of LLMs with specialized scientific tools and models, along with the development of foundational scientific models, represent two promising avenues for exploration.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>Contents</h1>
<p>1 Introduction ..... 4
1.1 Scientific areas ..... 4
1.2 Capabilities to evaluate ..... 5
1.3 Our methodologies ..... 6
1.4 Our observations ..... 6
1.5 Limitations of this study ..... 7
2 Drug Discovery ..... 9
2.1 Summary ..... 9
2.2 Understanding key concepts in drug discovery ..... 10
2.2.1 Entity translation ..... 10
2.2.2 Knowledge/information memorization ..... 12
2.2.3 Molecule manipulation ..... 15
2.2.4 Macroscopic questions about drug discovery ..... 18
2.3 Drug-target binding ..... 21
2.3.1 Drug-target affinity prediction ..... 21
2.3.2 Drug-target interaction prediction ..... 26
2.4 Molecular property prediction ..... 29
2.5 Retrosynthesis ..... 31
2.5.1 Understanding chemical reactions ..... 31
2.5.2 Predicting retrosynthesis ..... 32
2.6 Novel molecule generation ..... 37
2.7 Coding assistance for data processing ..... 39
3 Biology ..... 42
3.1 Summary ..... 42
3.2 Understanding biological sequences ..... 42
3.2.1 Sequence notations vs. text notations ..... 43
3.2.2 Performing sequence-related tasks with GPT-4 ..... 44
3.2.3 Processing files in domain-specific formats ..... 49
3.2.4 Pitfalls with biological sequence handling ..... 53
3.3 Reasoning with built-in biological knowledge ..... 55
3.3.1 Predicting protein-protein interactions (PPI) ..... 55
3.3.2 Understanding gene regulation and signaling pathways ..... 57
3.3.3 Understanding concepts of evolution ..... 61
3.4 Designing biomolecules and bio-experiments ..... 63
3.4.1 Designing DNA sequences for biological tasks ..... 63
3.4.2 Designing biological experiments ..... 66
4 Computational Chemistry ..... 68
4.1 Summary ..... 68
4.2 Electronic structure: theories and practices ..... 69
4.2.1 Understanding of quantum chemistry and physics ..... 69
4.2.2 Quantitative calculation ..... 73
4.2.3 Simulation and implementation assistant ..... 75
4.3 Molecular dynamics simulation ..... 84
4.3.1 Fundamental knowledge of concepts and methods ..... 85
4.3.2 Assistance with simulation protocol design and MD software usage ..... 91
4.3.3 Development of new computational chemistry methods ..... 95
4.3.4 Chemical reaction optimization ..... 103
4.3.5 Sampling bypass MD simulation ..... 108
4.4 Practical examples with GPT-4 evaluations from different chemistry perspectives ..... 118
4.4.1 NMR spectrum modeling for Tamiflu ..... 119
4.4.2 Polymerization reaction kinetics determination of Tetramethyl Orthosilicate (TMOS) ..... 122</p>
<p>5 Materials Design ..... 126
5.1 Summary ..... 126
5.2 Knowledge memorization and designing principle summarization ..... 126
5.3 Candidate proposal ..... 129
5.4 Structure generation ..... 132
5.5 Property prediction ..... 134
5.5.1 MatBench evaluation ..... 134
5.5.2 Polymer property ..... 136
5.6 Synthesis planning ..... 140
5.6.1 Synthesis of known materials ..... 140
5.6.2 Synthesis of new materials ..... 142
5.7 Coding assistance ..... 143
6 Partial Differential Equations ..... 145
6.1 Summary ..... 145
6.2 Knowing basic concepts about PDEs ..... 145
6.3 Solving PDEs ..... 152
6.3.1 Analytical solutions ..... 152
6.3.2 Numerical solutions ..... 158
6.4 AI for PDEs ..... 163
7 Looking Forward ..... 170
7.1 Improving LLMs ..... 170
7.2 New directions ..... 171
7.2.1 Integration of LLMs and scientific tools ..... 171
7.2.2 Building a unified scientific foundation model ..... 172
A Appendix of Drug Discovery ..... 182
B Appendix of Computational Chemistry ..... 183
C Appendix of Materials Design ..... 192
C. 1 Knowledge memorization for materials with negative Poisson Ratio ..... 192
C. 2 Knowledge memorization and design principle summarization for polymers ..... 193
C. 3 Candidate proposal for inorganic compounds ..... 196
C. 4 Representing polymer structures with BigSMILES ..... 198
C. 5 Evaluating the capability of generating atomic coordinates and predicting structures using a novel crystal identified by crystal structure prediction. ..... 201
C. 6 Property prediction for polymers ..... 205
C. 7 Evaluation of GPT-4 's capability on synthesis planning for novel inorganic materials ..... 207
C. 8 Polymer synthesis ..... 209
C. 9 Plotting stress vs. strain for several materials ..... 213
C. 10 Prompts and evaluation pipelines of synthesizing route prediction of known inorganic materials ..... 220
C. 11 Evaluating candidate proposal for Metal-Organic frameworks (MOFs) ..... 224</p>
<h1>1 Introduction</h1>
<p>The rapid development of artificial intelligence (AI) has led to the emergence of sophisticated large language models (LLMs), such as GPT-4 [62] from OpenAI, PaLM 2 [4] from Google, Claude from Anthropic, LLaMA 2 [85] from Meta, etc. LLMs are capable of transforming the way we generate and process information across various domains and have demonstrated exceptional performance in a wide array of tasks, including abstraction, comprehension [23], vision [29, 89], coding [66], mathematics [97], law [41], understanding of human motives and emotions, and more. In addition to the prowess in the realm of text, they have also been successfully integrated into other domains, such as image processing [114], speech recognition [38], and even reinforcement learning, showcasing its adaptability and potential for a broad range of applications. Furthermore, LLMs have been used as controllers/orchestrators $[76,83,94,106,34,48]$ to coordinate other machine learning models for complex tasks.</p>
<p>Among these LLMs, GPT-4 has gained substantial attention for its remarkable capabilities. A recent paper has even indicated that GPT-4 may be exhibiting early indications of artificial general intelligence (AGI) [11]. Because of its extraordinary capabilities in general AI tasks, GPT-4 is also garnering significant attention in the scientific community [71], especially in domains such as medicine [45, 87], healthcare [61, 91], engineering $[67,66]$, and social sciences $[28,5]$.</p>
<p>In this study, our primary goal is to examine the capabilities of LLMs within the context of natural science research. Due to the extensive scope of the natural sciences, covering all sub-disciplines is infeasible; as such, we focus on a select set of areas, including drug discovery, biology, computational chemistry, materials design, and partial differential equations (PDE). Our aim is to provide a broad overview of LLMs' performance and their potential applicability in these specific scientific fields, with GPT-4, the state-of-the-art LLM, as our central focus. A summary of this report can be found in Fig. 1.1.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1.1: Overview of this report.</p>
<h3>1.1 Scientific areas</h3>
<p>Natural science is dedicated to understanding the natural world through systematic observation, experimentation, and the formulation of testable hypotheses. These strive to uncover the fundamental principles and</p>
<p>laws governing the universe, spanning from the smallest subatomic particles to the largest galaxies and beyond. Natural science is an incredibly diverse field, encompassing a wide array of disciplines, including both physical sciences, which focus on non-living systems, and life sciences, which investigate living organisms. In this study, we have opted to concentrate on a subset of natural science areas, selected from both physical and life sciences. It is important to note that these areas are not mutually exclusive; for example, drug discovery substantially overlaps with biology, and they do not all fall within the same hierarchical level in the taxonomy of natural science.</p>
<p>Drug discovery is the process by which new candidate medications are identified and developed to treat or prevent specific diseases and medical conditions. This complex and multifaceted field aims to improve human health and well-being by creating safe, effective, and targeted therapeutic agents. In this report, we explore how GPT-4 can help drug discovery research (Sec. 2) and study several key tasks in drug discovery: knowledge understanding (Sec. 2.2), molecular property prediction (Sec. 2.4), molecular manipulation (Sec. 2.2.3), drugtarget binding prediction (Sec. 2.3), and retrosynthesis (Sec. 2.5).</p>
<p>Biology is a branch of life sciences that studies life and living organisms, including their structure, function, growth, origin, evolution, distribution, and taxonomy. As a broad and diverse field, biology encompasses various sub-disciplines that focus on specific aspects of life, such as genetics, ecology, anatomy, physiology, and molecular biology, among others. In this report, we explore how LLMs can help biology research (Sec. 3), mainly understanding biological sequences (Sec. 3.2), reasoning with built-in biological knowledge (Sec. 3.3), and designing biomolecules and bio-experiments (Sec. 3.4).</p>
<p>Computational chemistry is a branch of chemistry (and also physical sciences) that uses computer simulations and mathematical models to study the structure, properties, and behavior of molecules, as well as their interactions and reactions. By leveraging the power of computational techniques, this field aims to enhance our understanding of chemical processes, predict the behavior of molecular systems, and assist in the design of new materials and drugs. In this report, we explore how LLMs can help research in computational chemistry (Sec. 4), mainly focusing on electronic structure modeling (Sec. 4.2) and molecular dynamics simulation (Sec. 4.3).</p>
<p>Materials design is an interdisciplinary field that investigates (1) the relationship between the structure, properties, processing, and performance of materials, and (2) the discovery of new materials. It combines elements of physics, chemistry, and engineering. This field encompasses a wide range of natural and synthetic materials, including metals, ceramics, polymers, composites, and biomaterials. The primary goal of materials design is to understand how the atomic and molecular arrangement of a material affects its properties and to develop new materials with tailored characteristics for various applications. In this report, we explore how GPT-4 can help research in materials design (Sec. 5), e.g., understanding materials knowledge (Sec. 5.2), proposing candidate compositions (Sec. 5.3), generating materials structure (Sec. 5.4), predicting materials properties (Sec. 5.5), planning synthesis routes (Sec. 5.6), and assisting code development (Sec. 5.7).</p>
<p>Partial Differential Equations (PDEs) represent a category of mathematical equations that delineate the relationship between an unknown function and its partial derivatives concerning multiple independent variables. PDEs have applications in modeling significant phenomena across various fields such as physics, engineering, biology, economics, and finance. Examples of these applications include fluid dynamics, electromagnetism, acoustics, heat transfer, diffusion, financial models, population dynamics, reaction-diffusion systems, and more. In this study, we investigate how GPT-4 can contribute to PDE research (Sec. 6), emphasizing its understanding of fundamental concepts and AI techniques related to PDEs, theorem-proof capabilities, and PDE-solving abilities.</p>
<h1>1.2 Capabilities to evaluate</h1>
<p>We aim to understand how GPT-4 can help natural science research and its potential limitations in scientific domains. In particular, we study the following capabilities:</p>
<ul>
<li>Accessing and analyzing scientific literature. Can GPT-4 suggest relevant research papers, extract key information, and summarize insights for researchers?</li>
<li>Concept clarification. Is GPT-4 capable of explaining and providing definitions for scientific terms, concepts, and principles, helping researchers better understand the subject matter?</li>
<li>
<p>Data analysis. Can GPT-4 process, analyze, and visualize large datasets from experiments, simulations, and field observations, and uncover non-obvious trends and relationships in complex data?</p>
</li>
<li>
<p>Theoretical modeling. Can GPT-4 assist in developing mathematical/computational models of physical systems, which would be useful for fields like physics, chemistry, climatology, systems biology, etc.?</p>
</li>
<li>Methodology guidance. Could GPT-4 help researchers choose the right experimental/computational methods and statistical tests for their research by analyzing prior literature or running simulations on synthetic data?</li>
<li>Prediction. Is GPT-4 able to analyze prior experimental data to make predictions on new hypothetical scenarios and experiments (e.g., in-context few-shot learning), allowing for a focus on the most promising avenues?</li>
<li>Experimental design. Can GPT-4 leverage knowledge in the field to suggest useful experimental parameters, setups, and techniques that researchers may not have considered, thereby improving experimental efficiency?</li>
<li>Code development. Could GPT-4 assist in developing code for data analysis, simulations, and machine learning across a wide range of scientific applications by generating code from natural language descriptions or suggesting code snippets from a library of prior code?</li>
<li>Hypothesis generation. By connecting disparate pieces of information across subfields, can GPT-4 come up with novel hypotheses (e.g., compounds, proteins, materials, etc.) for researchers to test in their lab, expanding the scope of their research?</li>
</ul>
<h1>1.3 Our methodologies</h1>
<p>In this report, we choose the best LLM to date, GPT-4, to study and evaluate the capabilities of LLMs across scientific domains. We use the GPT-4 model ${ }^{2}$ available through the Azure OpenAI Service. ${ }^{3}$.</p>
<p>We employ a combination of qualitative ${ }^{4}$ and quantitative approaches, ensuring a good understanding of its proficiency in scientific research.</p>
<p>In the case of most capabilities, we primarily adopt a qualitative approach, carefully designing tasks and questions that not only showcase GPT-4's capabilities in terms of its scientific expertise but also address the fundamental inquiry: the extent of GPT-4's proficiency in scientific research. Our objective is to elucidate the depth and flexibility of its understanding of diverse concepts, skills, and fields, thereby demonstrating its versatility and potential as a powerful tool in scientific research. Moreover, we scrutinize GPT-4's responses and actions, evaluating their consistency, coherence, and accuracy, while simultaneously identifying potential limitations and biases. This examination allows us to gain a deeper understanding of the system's potential weaknesses, paving the way for future improvements and refinements. Throughout our study, we present numerous intriguing cases spanning each scientific domain, illustrating the diverse capabilities of GPT-4 in areas such as concept capture, knowledge comprehension, and task assistance.</p>
<p>For certain capabilities, particularly predictive ones, we also employ a quantitative approach, utilizing public benchmark datasets to evaluate GPT-4's performance on well-defined tasks, in addition to presenting a wide array of case studies. By incorporating quantitative evaluations, we can objectively assess the model's performance in specific tasks, allowing for a more robust and reliable understanding of its strengths and limitations in scientific research applications.</p>
<p>In summary, our methodologies for investigating GPT-4's performance in scientific domains involve a blend of qualitative and quantitative approaches, offering a holistic and systematic understanding of its capabilities and limitations.</p>
<h3>1.4 Our observations</h3>
<p>GPT-4 demonstrates considerable potential in various scientific domains, including drug discovery, biology, computational chemistry, materials design, and PDEs. Its capabilities span a wide range of tasks and it exhibits an impressive understanding of key concepts in each domain.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>In drug discovery, GPT-4 shows a comprehensive grasp of the field, enabling it to provide useful insights and suggestions across a wide range of tasks. It is helpful in predicting drug-target binding affinity, molecular properties, and retrosynthesis routes. It also has the potential to generate novel molecules with desired properties, which can lead to the discovery of new drug candidates with the potential to address unmet medical needs. However, it is important to be aware of GPT-4's limitations, such as challenges in processing SMILES sequences and limitations in quantitative tasks.</p>
<p>In the field of biology, GPT-4 exhibits substantial potential in understanding and processing complex biological language, executing bioinformatics tasks, and serving as a scientific assistant for biology design. Its extensive grasp of biological concepts and its ability to perform various tasks, such as processing specialized files, predicting signaling peptides, and reasoning about plausible mechanisms from observations, benefit it to be a valuable tool in advancing biological research. However, GPT-4 has limitations when it comes to processing biological sequences (e.g., DNA and FASTA sequences) and its performance on tasks related to under-studied entities.</p>
<p>In computational chemistry, GPT-4 demonstrates remarkable potential across various subdomains, including electronic structure methods and molecular dynamics simulations. It is able to retrieve information, suggest design principles, recommend suitable computational methods and software packages, generate code for various programming languages, and propose further research directions or potential extensions. However, GPT-4 may struggle with generating accurate atomic coordinates of complex molecules, handling raw atomic coordinates, and performing precise calculations.</p>
<p>In materials design, GPT-4 shows promise in aiding materials design tasks by retrieving information, suggesting design principles, generating novel and feasible chemical compositions, recommending analytical and numerical methods, and generating code for different programming languages. However, it encounters challenges in representing and proposing more complex structures, e.g., organic polymers and MOFs, generating accurate atomic coordinates, and providing precise quantitative predictions.</p>
<p>In the realm of PDEs, GPT-4 exhibits its ability to understand the fundamental concepts, discern relationships between concepts, and provide accurate proof approaches. It is able to recommend appropriate analytical and numerical methods for addressing various types of PDEs and generate code in different programming languages to numerically solve PDEs. However, GPT-4's proficiency in mathematical theorem proving still has room for growth, and its capacity for independently discovering and validating novel mathematical theories remains limited in scope.</p>
<p>In summary, GPT-4 exhibits both significant potential and certain limitations for scientific discovery. To better leverage GPT-4, researchers should be cautious and verify the model's outputs, experiment with different prompts, and combine its capabilities with dedicated AI models or computational tools to ensure reliable conclusions and optimal performance in their respective research domains:</p>
<ul>
<li>Interpretability and Trust: It is crucial to maintain a healthy skepticism when interpreting GPT-4's output. Researchers should always critically assess the generated results and cross-check them with existing knowledge or expert opinions to ensure the validity of the conclusions.</li>
<li>Iterative Questioning and Refinement: GPT-4's performance can be improved by asking questions in an iterative manner or providing additional context. If the initial response from GPT-4 is not satisfactory, researchers can refine their questions or provide more information to guide the model toward a more accurate and relevant answer.</li>
<li>Combining GPT-4 with Domain-Specific Tools: In many cases, it may be beneficial to combine GPT-4's capabilities with more specialized tools and models designed specifically for scientific discovery tasks, such as molecular docking software, or protein folding algorithms. This combination can help researchers leverage the strengths of both GPT-4 and domain-specific tools to achieve more reliable and accurate results. Although we do not extensively investigate the integration of LLMs and domain-specific tools/models in this report, a few examples are briefly discussed in Section 7.2.1.</li>
</ul>
<h1>1.5 Limitations of this study</h1>
<p>First, a large part of our assessment of GPT-4's capabilities utilizes case studies. We acknowledge that this approach is somewhat subjective, informal, and lacking in rigor per formal scientific standards. However, we believe that this report is useful and helpful for researchers interested in leveraging LLMs for scientific discovery. We look forward to the development of more formal and comprehensive methods for testing and analyzing LLMs and potentially more complex AI systems in the future for scientific intelligence.</p>
<p>Second, in this study, we primarily focus on the scientific intelligence of GPT-4 and its applications in various scientific domains. There are several important aspects, mainly responsible AI, beyond the scope of this work that warrant further exploration for GPT-4 and all LLMs:</p>
<ul>
<li>Safety Concerns: Our analysis does not address the ability of GPT-4 to safely respond to hazardous chemistry or drug-related situations. Future studies should investigate whether these models provide appropriate safety warnings and precautions when suggesting potentially dangerous chemical reactions, laboratory practices, or drug interactions. This could involve evaluating the accuracy and relevance of safety information generated by LLMs and determining if they account for the risks and hazards associated with specific scientific procedures.</li>
<li>Malicious Usage: Our research does not assess the potential for GPT-4 to be manipulated for malicious purposes. It is crucial to examine whether it has built-in filters or content-monitoring mechanisms that prevent it from disclosing harmful information, even when explicitly requested. Future research should explore the potential vulnerabilities of LLMs to misuse and develop strategies to mitigate risks, such as generating false or dangerous information.</li>
<li>Data Privacy and Security: We do not investigate the data privacy and security implications of using GPT-4 in scientific research. Future studies should address potential risks, such as the unintentional leakage of sensitive information, data breaches, or unauthorized access to proprietary research data.</li>
<li>Bias and Fairness: Our research does not examine the potential biases present in LLM-generated content or the fairness of their outputs. It is essential to assess whether these models perpetuate existing biases, stereotypes, or inaccuracies in scientific knowledge and develop strategies to mitigate such issues.</li>
<li>Impact on the Scientific Workforce: We do not analyze the potential effects of LLMs on employment and job opportunities within the scientific community. Further research should consider how the widespread adoption of LLMs may impact the demand for various scientific roles and explore strategies for workforce development, training, and skill-building in the context of AI-driven research.</li>
<li>Ethics and Legal Compliance: We do not test the extent to which LLMs adhere to ethical guidelines and legal compliance requirements related to scientific use. Further investigation is needed to determine if LLM-generated content complies with established ethical standards, data privacy regulations, and intellectual property laws. This may involve evaluating the transparency, accountability, and fairness of LLMs and examining their potential biases or discriminatory outputs in scientific research contexts.
By addressing these concerns in future studies, we can develop a more holistic understanding of the potential benefits, challenges, and implications of LLMs in the scientific domain, paving the way for more responsible and effective use of these advanced AI technologies.</li>
</ul>
<h1>2 Drug Discovery</h1>
<h3>2.1 Summary</h3>
<p>Drug discovery is the process by which new candidate medications are identified and developed to treat or prevent specific diseases and medical conditions. This complex and multifaceted field aims to improve human health and well-being by creating safe, effective, and targeted therapeutic agents. The importance of drug discovery lies in its ability to identify and develop new therapeutics for treating diseases, alleviating suffering, and improving human health [72]. It is a vital part of the pharmaceutical industry and plays a crucial role in advancing medical science [64]. Drug discovery involves a complex and multidisciplinary process, including target identification, lead optimization, and preclinical testing, ultimately leading to the development of safe and effective drugs [35].</p>
<p>Assessing GPT-4's capabilities in drug discovery has significant potential, such as accelerating the discovery process [86], reducing the search and design cost [73], enhancing creativity, and so on. In this chapter, we first study GPT-4's knowledge about drug discovery through qualitative tests (Sec. 2.2), and then study its predictive capabilities through quantitative tests on multiple crucial tasks, including drug-target interaction/binding affinity prediction (Sec. 2.3), molecular property prediction (Sec. 2.4), and retrosynthesis prediction (Sec. 2.5).</p>
<p>We observe the considerable potential of GPT-4 for drug discovery: ${ }^{5}$</p>
<ul>
<li>Broad Knowledge: GPT-4 demonstrates a wide-ranging understanding of key concepts in drug discovery, including individual drugs (Fig. 2.4), target proteins (Fig. 2.6), general principles for small-molecule drugs (Fig. 2.8), and the challenges faced in various stages of the drug discovery process (Fig. 2.9). This broad knowledge base allows GPT-4 to provide useful insights and suggestions across a wide range of drug discovery tasks.</li>
<li>Versatility in Key Tasks: LLMs, such as GPT-4, can help in several essential tasks in drug discovery, including:</li>
<li>Molecule Manipulation: GPT-4 is able to generate new molecular structures by modifying existing ones (Fig. 2.7), potentially leading to the discovery of novel drug candidates.</li>
<li>Drug-Target Binding Prediction: GPT-4 is able to predict the interaction between of a molecule to a target protein (Table 4), which can help in identifying promising drug candidates and optimizing their binding properties.</li>
<li>Molecule Property Prediction: GPT-4 is able to predict various physicochemical and biological properties of molecules (Table 5), which can guide the selection and optimization of drug candidates.</li>
<li>Retrosynthesis Prediction: GPT-4 is able to predict synthetic routes for target molecules, helping chemists design efficient and cost-effective strategies for the synthesis of potential drug candidates (Fig. 2.23).</li>
<li>Novel Molecule Generation: GPT-4 can be used to generate novel molecules following text instruction. This de novo molecule generation capability can be a valuable tool for identifying new drug candidates with the potential to address unmet medical needs (Sec. 2.6).</li>
<li>Coding capability: GPT-4 can provide help in coding for drug discovery, offering large benefits in data downloading, processing, and so on (Fig. 2.27, Fig 2.28). The strong coding capability of GPT-4 can greatly ease human efforts in the future.
While GPT-4 is a useful tool for assisting research in drug discovery, it's important to be aware of its limitations and potential errors. To better leverage GPT-4, we provide several tips for researchers:</li>
<li>SMILES Sequence Processing Challenges: GPT-4 may struggle with directly processing SMILES sequences. To improve the model's understanding and output, it is better to provide the names of drug molecules along with their descriptions, if possible. This will give the model more context and improve its ability to generate relevant and accurate responses.</li>
<li>Limitations in Quantitative Tasks: While GPT-4 excels in qualitative tasks and questions, it may face limitations when it comes to quantitative tasks, such as predicting numerical values for molecular</li>
</ul>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>properties and drug-target binding in our evaluated datasets. Researchers are advised to take GPT-4's output as a reference in these cases and perform verification using dedicated AI models or scientific computational tools to ensure reliable conclusions.</p>
<ul>
<li>Double-Check Generated Molecules: When generating novel molecules with GPT-4, it is essential to verify the validity and chemical properties of the generated structures.</li>
</ul>
<h1>2.2 Understanding key concepts in drug discovery</h1>
<p>Understanding fundamental and important concepts in drug discovery is the first step to testing GPT-4's intelligence in this domain. In this subsection, we ask questions from different perspectives to test GPT-4's knowledge. The system message is set as in Fig. 2.1, which is added to each prompt.</p>
<h2>GPT-4</h2>
<h2>System message:</h2>
<p>You are a drug assistant and should be able to help with drug discovery tasks.</p>
<p>Figure 2.1: System message used in all the prompts in Sec. 2.2.</p>
<h3>2.2.1 Entity translation</h3>
<p>In this subsection, we focus on evaluating the performance of GPT-4 in translating drug names, IUPAC nomenclature, chemical formula, and SMILES representations.</p>
<p>Drug names, IUPAC nomenclature, chemical formula, and SMILES strings serve as crucial building blocks for understanding and conveying chemical structures and properties for drug molecules. These representations are essential for researchers to communicate, search, and analyze chemical compounds effectively. Several examples are shown in Fig. 2.2 and Fig. 2.3.</p>
<p>The first example is to generate the chemical formula, IUPAC name, and the SMILES for a given drug name, which is the translation between names and other representations of drugs. We take Afatinib as the input drug. As shown in Fig. 2.2, GPT-4 correctly outputs the chemical formula as $\mathrm{C}<em 25="25">{24} \mathrm{H}</em>} \mathrm{ClFN<em 3="3">{5} \mathrm{O}</em>$, and the IUPAC name is also right, which means GPT-4 is aware of drug Afatinib. However, the SMILES is not correct. Therefore, we give guidance and let GPT-4 generate SMILES again. Unfortunately, as shown in the figure, though we explicitly ask GPT-4 to "pay attention to the number of atoms of each atom type" and generate based on the correct IUPAC and chemical formula, the generated SMILES sequences in several trials are still not correct.</p>
<p>In Fig. 2.3, we ask GPT-4 to translate between the IUPAC name and the SMILES sequence and output the chemical formula. As presented in the figure, the translation from the SMILES sequence to the IUPAC name is correct, but the other direction is incorrect. Besides, the generated chemical formulas in both translation directions are incorrect. From these two cases, we can see that IUPAC looks to be much easier for GPT-4 to understand and generate while generating SMILES faces some challenges. We suspect one possible reason may be the tokenization method used in GPT-4 since it is based on the subword representation, which may not be easy for the SMILES representation where each character has its specific meaning for a drug molecule. This hypothesis can also explain the situation in that the generated chemical formula is not always correct (as shown in Fig. 2.3) since the formula is based on the count of each atom type.</p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>What's the chemical formula, IUPAC name, and the SMILES of Afatinib?</p>
<h2>GPT-4:</h2>
<p>Afatinib is a tyrosine kinase inhibitor used for the treatment of non-small cell lung cancer.
Chemical formula: $\mathrm{C}<em 25="25">{24} \mathrm{H}</em>} \mathrm{ClFN<em 3="3">{5} \mathrm{O}</em>$
IUPAC name: N-[4-[(3-chloro-4-fluorophenyl)amino]-7-[[(3S)-tetrahydro-3-furanyl]oxy]-6-quinazolinyl]-4-(dimethylamino)-2-butenamide</p>
<p>SMILES: $\mathrm{CN}(\mathrm{C}) \mathrm{C}=\mathrm{C}\backslash \mathrm{C}(=\mathrm{O}) \mathrm{NC} 1=\mathrm{C}(\mathrm{C}=\mathrm{CC}(=\mathrm{N} 1) \mathrm{NC} 2=\mathrm{C}(\mathrm{C}=\mathrm{C}(\mathrm{C}=\mathrm{C} 2) \mathrm{F}) \mathrm{Cl}) \mathrm{OC}[\mathrm{C} 0 \oplus \mathrm{H}] 3 \mathrm{CCCO} 3$</p>
<h2>Prompt:</h2>
<p>The SMILES is wrong. Show me the canonical SMILES.</p>
<h2>GPT-4:</h2>
<p>Apologies for the confusion earlier. Here is the correct canonical SMILES for Afatinib:
Canonical SMILES: $\mathrm{CC}(\mathrm{C}=\mathrm{C} \backslash \mathrm{C}(=\mathrm{O}) \mathrm{Nc} 1 \mathrm{cc} 2 \mathrm{c}(\mathrm{cc} 1 \mathrm{OC} 3 \mathrm{CCCO} 3) \mathrm{ncnc} 2 \mathrm{Nc} 4 \mathrm{ccc}(\mathrm{c}(\mathrm{c} 4) \mathrm{Cl}) \mathrm{F}) \mathrm{N}(\mathrm{C}) \mathrm{C}$
Please note that this SMILES notation does not include the stereochemistry information.</p>
<h2>Prompt:</h2>
<p>The SMILES is still wrong. Pay attention to the number of atoms of each atom type and show me the correct SMILES. GPT-4:
I apologize for my previous mistakes. Here is the correct SMILES notation for Afatinib:
SMILES: $\mathrm{COC} 1=\mathrm{CC}=\mathrm{CC} 2=\mathrm{C} 1 \mathrm{C}(\mathrm{NC} 3=\mathrm{CC}(=\mathrm{C}(\mathrm{C}=\mathrm{C} 3 \mathrm{P}) \mathrm{Cl}) \mathrm{NC}=\mathrm{C} 4 \mathrm{CCCCO} 4)=\mathrm{NC}=\mathrm{N} 2$
Again, I apologize for the confusion and appreciate your patience.</p>
<h2>Prompt:</h2>
<p>The chemical formula and the IUPAC name are correct, but the SMILES is wrong. Generate SMILES based on the chemical formula and the IUPAC name.</p>
<h2>GPT-4:</h2>
<p>My apologies for the confusion earlier. Based on the chemical formula and the IUPAC name, the correct SMILES notation for Afatinib should be:
SMILES: $\mathrm{CN}(\mathrm{C}) \mathrm{C}=\mathrm{C} / \mathrm{C}(=\mathrm{O}) \mathrm{Nc} 1 \mathrm{cc} 2 \mathrm{c}(\mathrm{cc} 1 \mathrm{OC}[\mathrm{C} 0 \oplus \mathrm{H}] 1 \mathrm{CCCO} 1) \mathrm{ncnc} 2 \mathrm{Nc} 1 \mathrm{cc}(\mathrm{c}(\mathrm{cc} 1) \mathrm{Cl}) \mathrm{F}$
Please note that this SMILES notation includes the stereochemistry information as well.</p>
<p>Figure 2.2: Example of entity translation. Given a drug name, generate its chemical formula, IUPAC name, and the SMILES. The first molecular graph is the ground-truth 2D structure of Afatinib, while the latter four graphs are converted from the SMILES sequences generated by GPT-4.</p>
<h1>Prompt:</h1>
<p>Given the IUPAC name "(2E)-N-4-[(3-chloro-4-fluorophenyl)amino]-7-[(3S)-oxolan-3-yloxy]quinazolin-6-yl-4-(dimethylamino)but-2-enamide" of a compound, generate its SMILES sequence.</p>
<h2>GPT-4:</h2>
<p>The compound's IUPAC name "(2E)-N-4-[(3-chloro-4-fluorophenyl)amino]-7-[(3S)-oxolan-3-yloxy]quinazolin-6-yl-4-(dimethylamino)but-2-enamide" corresponds to the SMILES sequence
"COC1=CC2=C(N=C1)N=CN=C2NCC $\backslash \mathrm{C}=\mathrm{C}(/ \mathrm{C}(=\mathrm{O}) \mathrm{N}) \mathrm{N}(\mathrm{C}) \mathrm{C}$ " and the chemical formula $\mathrm{C}<em 22="22">{22} \mathrm{H}</em>} \mathrm{ClFN<em 2="2">{4} \mathrm{O}</em>$.</p>
<h2>Prompt:</h2>
<p>Given the SMILES ${ }^{\prime} \mathrm{CN}(\mathrm{C}) \mathrm{C} \backslash \mathrm{C}=\mathrm{C} \backslash \mathrm{C}(=\mathrm{O}) \mathrm{NC} 1=\mathrm{C}(\mathrm{O}[\mathrm{C} @ \mathrm{H}] 2 \mathrm{CCOC} 2) \mathrm{C}=\mathrm{C} 2 \mathrm{~N}=\mathrm{CN}=\mathrm{C}(\mathrm{NC} 3=\mathrm{CC}(\mathrm{Cl})=\mathrm{C}(\mathrm{F}) \mathrm{C}=\mathrm{C} 3) \mathrm{C} 2=\mathrm{C} 1$ " of a compound, generate its IUPAC name and chemical formula.</p>
<h2>GPT-4:</h2>
<p>The compound's SMILES ${ }^{\prime} \mathrm{CN}(\mathrm{C}) \mathrm{C} \backslash \mathrm{C}=\mathrm{C} \backslash \mathrm{C}(=\mathrm{O}) \mathrm{NC} 1=\mathrm{C}(\mathrm{O}[\mathrm{C} @ \mathrm{H}] 2 \mathrm{CCOC} 2) \mathrm{C}=\mathrm{C} 2 \mathrm{~N}=\mathrm{CN}=\mathrm{C}(\mathrm{NC} 3=\mathrm{CC}(\mathrm{Cl})=\mathrm{C}(\mathrm{F}) \mathrm{C}=\mathrm{C} 3) \mathrm{C} 2=\mathrm{C} 1$ " corresponds to the IUPAC name (6R)-6-((5-chloro-2-fluorophenyl)amino)-3-methyl-5-(3-methylimidazo[1,2-a]pyridin-2-yl)-3,6-dihydro-2H-pyridin-2-one 2-oxide and the chemical formula $\mathrm{C}<em 16="16">{19} \mathrm{H}</em>} \mathrm{ClEN<em 2="2">{4} \mathrm{O}</em>$.</p>
<p>Figure 2.3: Translation between IUPAC name and SMILES.</p>
<h3>2.2.2 Knowledge/information memorization</h3>
<p>We evaluate GPT-4's capability of knowledge and information memorization for drug discovery in this subsection.</p>
<p>The drug we choose is still Afatinib and the cases are presented in Fig. 2.4. We first ask GPT-4 to give an introduction to the drug Afatinib, GPT-4 replies with multiple pieces of information, covering the molecule type, its target receptor, the FDA-proved time, the function, pathway, side effects, and so on. With checking from Pubchem and DrugBank, the information given by GPT-4 is clear and correct, which demonstrates that GPT-4 has knowledge about Afatinib. Then, we further ask more about the chemical properties of Afatinib, which is crucial to truly understand a molecule drug. In Fig. 2.5, GPT-4 answers a variety of properties about Afatinib, such as the molecular weight, solubility, XLogP3, hydrogen bond acceptor count, etc. (1) Most of the introduced properties are correct. (2) Some properties are not correct, especially for counting related results such as the number of heavy atoms. (3) Interestingly, the generated SMILES notation for Afatinib is wrong again, which aligns well with the observation in the previous subsection and suggests that generating SMILES still remains a challenge for GPT-4.</p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>Please give an introduction to the drug Afatinib.</p>
<h2>GPT-4:</h2>
<p>Afatinib is a small molecule, tyrosine kinase inhibitor (TKI) that is designed to selectively and irreversibly block the epidermal growth factor receptor (EGFR) family. It specifically targets the human EGFR (HER) family of receptor tyrosine kinases, which includes EGFR (ErbB1), HER2 (ErbB2), HER3 (ErbB3), and HER4 (ErbB4). These receptors play a crucial role in the growth, survival, and spread of cancer cells.</p>
<p>Afatinib was developed by Boehringer Ingelheim and is marketed under the brand name Gilotrif or Giotrif. It was first approved by the U.S. Food and Drug Administration (FDA) in July 2013 for the treatment of metastatic non-small cell lung cancer (NSCLC) with EGFR exon 19 deletions or exon 21 (L858R) substitution mutations as detected by an FDA-approved test.</p>
<p>In addition to NSCLC, Afatinib has been studied in various types of solid tumors, including breast, head and neck, and colorectal cancers. It has shown efficacy in tumors that overexpress or have mutations in the EGFR family, which contributes to the development and progression of the disease.</p>
<p>Afatinib works by inhibiting the intracellular signaling pathways involved in cell proliferation and survival, thereby blocking the growth and spread of cancer cells. Its mechanism of action is distinct from other EGFR inhibitors, as it forms a covalent bond with the target receptor, resulting in irreversible inhibition.</p>
<p>The most common side effects associated with Afatinib include diarrhea, rash, acne, dry skin, and mouth sores. Additionally, serious side effects such as interstitial lung disease, liver toxicity, and gastrointestinal perforation have been reported. It is essential for patients to be closely monitored by their healthcare providers while on Afatinib treatment to manage any potential side effects.</p>
<p>In summary, Afatinib is a targeted therapy that specifically inhibits the EGFR family of receptor tyrosine kinases, providing a treatment option for patients with certain types of EGFR-mutated NSCLC and other solid tumors.</p>
<h2>Prompt:</h2>
<p>Give an introduction to the drug Afatinib and focus on its chemical information such as formula, SMILES, properties, molecular weight, and so on.</p>
<h2>GPT-4:</h2>
<p>Afatinib is a small molecule, tyrosine kinase inhibitor (TKI) that specifically targets the human EGFR (HER) family of receptor tyrosine kinases. Chemically, Afatinib is known as N-[4-[(3-chloro-4-fluorophenyl)amino]-7-[[(3S)-tetrahydro-3-furanyl]oxy]-6-quinazolinyll-4-(dimethylamino)-2-butenamide.</p>
<p>Here are some key chemical properties of Afatinib:</p>
<ul>
<li>Molecular Formula: $\mathrm{C}<em 25="25">{24} \mathrm{H}</em>} \mathrm{ClFN<em 3="3">{5} \mathrm{O}</em>$</li>
<li>Molecular Weight: $485.94 \mathrm{~g} / \mathrm{mol}$</li>
<li>SMILES notation: $\mathrm{CN}(\mathrm{C}) \mathrm{C} / \mathrm{C}=\mathrm{C} / \mathrm{C}(=\mathrm{O}) \mathrm{Nc1cc2c(cc1Cl)ncnc2O[C} @ @ \mathrm{H}] 3 \mathrm{COCC} 3$</li>
<li>IUPAC Name: N-[4-[(3-chloro-4-fluorophenyl)amino]-7-[[(3S)-tetrahydro-3-furanyl]oxy]-6-quinazolinyll-4-(dimethylamino)-2butenamide</li>
<li>Appearance: Afatinib is a white to yellowish powder</li>
<li>Solubility: It is sparingly soluble in water and moderately soluble in organic solvents such as methanol and DMSO.</li>
</ul>
<p>Afatinib's chemical structure features a quinazoline core, which is essential for its pharmacological activity. The molecule forms a covalent bond with the target receptor, leading to irreversible inhibition of the EGFR family. This distinguishes it from other reversible EGFR inhibitors and contributes to its unique mechanism of action in treating certain types of EGFR-mutated cancers.</p>
<p>It is important to note that Afatinib is a chiral molecule, and the approved drug is a single enantiomer with the (S)-configuration at the tetrahydrofuran ring. This enantiomeric purity is essential for its pharmacological activity and selectivity.</p>
<p>Figure 2.4: Retrieve general and chemical information about the drug Afatinib from GPT-4. Most of the knowledge about Afatinib is correct.</p>
<h1>GPT-4 (continue)</h1>
<h2>Prompt:</h2>
<p>Can you introduce more properties about Afatinib, such as XLogP3, Hydrogen bond donor count, topological polar surface area, and so on?</p>
<h2>GPT-4:</h2>
<p>Certainly! Here are some additional physicochemical properties of Afatinib:</p>
<ul>
<li>XLogP3: XLogP3 is a measure of the lipophilicity of a compound, which can affect its absorption, distribution, metabolism, and excretion (ADME) properties. Afatinib has an XLogP3 value of 4.2, indicating moderate lipophilicity.</li>
<li>Hydrogen Bond Donor Count: Afatinib has 2 hydrogen bond donor groups. These are the amide nitrogen and the secondary amine nitrogen in the quinazoline core.</li>
<li>Hydrogen Bond Acceptor Count: Afatinib has 9 hydrogen bond acceptor groups. These include oxygen atoms in the tetrahydrofuran ring, amide carbonyl, and quinazoline core, as well as nitrogen atoms in the quinazoline core and dimethylamino group.</li>
<li>Topological Polar Surface Area (TPSA): TPSA is a measure of the molecular surface area that is occupied by polar atoms (oxygen, nitrogen, and their attached hydrogen atoms).</li>
<li>It is a useful parameter for predicting drug transport properties, such as permeability and solubility. Afatinib has a TPSA value of $78.63 \AA^{2}$, which indicates a moderate polar surface area.</li>
<li>Rotatable Bond Count: Afatinib has 8 rotatable bonds. These are the single bonds that allow for conformational flexibility in the molecule and can influence its pharmacokinetic properties.</li>
<li>Heavy Atom Count: Afatinib contains 33 heavy atoms (non-hydrogen atoms).</li>
</ul>
<p>These physicochemical properties play a role in determining Afatinib's pharmacokinetic profile, including its absorption, distribution, metabolism, and excretion in the body. It is crucial to consider these properties when designing and optimizing drug candidates to improve their efficacy and safety.</p>
<p>Figure 2.5: Retrieve molecular property information about the drug Afatinib from GPT-4.</p>
<p>In addition to evaluating drug knowledge, we also assess GPT-4's understanding of target proteins. We use SARS-CoV-2 as the target disease and request GPT-4 to provide information on the target protein 3CLpro, including its protein sequence in FASTA format and the active binding sites on this target protein. As illustrated in Fig. 2.6, GPT-4 recognizes 3CLpro and attempts to provide the protein sequence and binding sites. Interestingly, although GPT-4 correctly states that the target protein sequence should consist of 306 amino acids, it presents a protein sequence with over 1000 amino acids. After informing GPT-4 of the incorrect length and prompting it to provide the 306 amino acids, GPT-4 successfully delivers the correct protein sequence ${ }^{6}$. This case and other cases we do not include in this report demonstrate that GPT-4 possesses knowledge about target proteins, although errors may occasionally occur with specific protein sequences.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>For 3CLpro, please give me the protein sequences and identify the binding sites.</p>
<h2>GPT-4:</h2>
<p>3CLpro, also known as the main protease (Mpro) or non-structural protein 5 (nsp5), is a key enzyme in the life cycle of coronaviruses, including SARS-CoV-2, which causes COVID-19. It is essential for the processing of viral polyproteins, making it an attractive target for drug development against coronaviruses. The protein sequence of SARS-CoV-2 3CLpro (Mpro) is as follows:</p>
<p>SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGH SMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGYYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCY MHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYE PLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQSAVKRTIKGTHHWLLL KGFCDLKGKYVQIPTTCANDPVGFTLKNTVCTVCGMWKGYGCSCDQLREPMLQSADAQSFLNGFAV</p>
<p>The length of the protein sequence is 306 amino acids.
The binding site of 3CLpro is located at its active site, which consists of a Cys-His catalytic dyad. The critical amino acids involved in the binding site are:</p>
<ul>
<li>Cysteine 145 (Cys145 or C145)</li>
<li>Histidine 41 (His41 or H41)</li>
</ul>
<p>These residues are essential for the proteolytic activity of the enzyme. Inhibitors that target this active site could potentially block the enzyme's activity and disrupt the replication of the virus. Therefore, it is crucial to consider the binding site's structural and chemical properties when designing drugs targeting 3CLpro.</p>
<h2>Prompt:</h2>
<p>The length of the 3CLpro you gave is not 306, show me the 306 amino acids of 3CLpro.</p>
<h2>GPT-4:</h2>
<p>I apologize for the confusion in my previous responses. The correct length of the SARS-CoV-2 3CLpro (Mpro) protein sequence provided is 306 amino acids. Here is the corrected sequence:</p>
<p>SGFRKMAFPSGKVEGCMVQVTCGTTTLNGLWLDDVVYCPRHVICTSEDMLNPNYEDLLIRKSNHNFLVQAGNVQLRVIGH SMQNCVLKLKVDTANPKTPKYKFVRIQPGQTFSVLACYNGSPSGYYQCAMRPNFTIKGSFLNGSCGSVGFNIDYDCVSFCY MHHMELPTGVHAGTDLEGNFYGPFVDRQTAQAAGTDTTITVNVLAWLYAAVINGDRWFLNRFTTTLNDFNLVAMKYNYE PLTQDHVDILGPLSAQTGIAVLDMCASLKELLQNGMNGRTILGSALLEDEFTPFDVVRQCSGVTFQ</p>
<p>The length of this corrected protein sequence is 306 amino acids.
The binding site of 3CLpro is located at its active site, which consists of a Cys-His catalytic dyad. The critical amino acids involved in the binding site are:</p>
<ul>
<li>Cysteine 145 (Cys145 or C145)</li>
<li>Histidine 41 (His41 or H41)</li>
</ul>
<p>These residues are essential for the proteolytic activity of the enzyme. Inhibitors that target this active site could potentially block the enzyme's activity and disrupt the replication of the virus. Therefore, it is crucial to consider the binding site's structural and chemical properties when designing drugs targeting 3CLpro.</p>
<p>Figure 2.6: 3CLPro target protein information of SARS-Cov-2 retrieved by GPT-4.</p>
<h3>2.2.3 Molecule manipulation</h3>
<p>Molecule manipulation involves modifying the structure of a molecule to achieve desired properties or functions. In the pharmaceutical industry, molecule manipulation enables researchers to optimize drug candidates to enhance efficacy, reduce side effects, and improve pharmacokinetic properties which is crucial for designing potent and safe therapeutic agents.</p>
<p>In Fig. 2.7, we present one case in GPT-4 is asked to help with drug molecule manipulation. Specifically, Asciminib, a first-in-class allosteric inhibitor of BCR::ABL1 kinase activity, is recently approved for the</p>
<p>treatment of patients with chronic-phase chronic myeloid leukemia who failed 2 lines of therapy or in patients with the T315I mutation. We first ask GPT-4 to modify Asciminib by replacing the chlorine ( Cl ) with the element on the row below in the periodic table, which is actually bromine ( Br ), GPT-4 knows the element and makes a successful replacement. When we further ask GPT-4 to replace pyrrolidine with a 6 -membered ring and change the alcohol to a fluoride, GPT-4 gives the correct process, but interestingly, the result is wrong. After multiple rounds of guidance and correction, GPT-4 finally gives the right modification of the desired molecule. Therefore, we can find that GPT-4 has strong knowledge, but without specific user feedback and the step-by-step check, GPT-4 may fail into errors in large possibility. Another case can be found in Appendix Fig. A.1, which shows that GPT-4 often generates invalid SMILES.</p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>Can you modify ascimnib $\mathrm{O}=\mathrm{C}(\mathrm{Nc} 1 \mathrm{ccc}(\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Cl}) \mathrm{cc} 1) \mathrm{c} 1 \mathrm{cnc}(\mathrm{N} 2 \mathrm{CC}<a href="\mathrm{O}">\mathrm{C} @ @ \mathrm{H}</a> \mathrm{C} 2) \mathrm{c}(-c 2 \mathrm{ccn}[\mathrm{nH}] 2) \mathrm{c} 1$ and replace the chlorine with the element on row below in the periodic table?</p>
<h2>GPT-4:</h2>
<p>Sure! To replace the chlorine atom with the element in the row below it in the periodic table, you need to replace chlorine $(\mathrm{Cl})$ with bromine $(\mathrm{Br})$. Here's the modified structure of ascimnib with the chlorine replaced by bromine:
$\mathrm{O}=\mathrm{C}(\mathrm{Nc} 1 \mathrm{ccc}(\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Br}) \mathrm{cc} 1) \mathrm{c} 1 \mathrm{cnc}(\mathrm{N} 2 \mathrm{CCC}(\mathrm{O}) \mathrm{C} 2) \mathrm{c}(-c 2 \mathrm{ccn}[\mathrm{nH}] 2) \mathrm{c} 1$
In this modified structure, the $\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{CI}$ fragment has been replaced with $\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Br}$.</p>
<h2>Prompt:</h2>
<p>Can you replace the pyrrolidine with a 6 membered ring and change the alcohol to a fluoride?</p>
<h2>GPT-4:</h2>
<p>To modify the original structure of ascimnib by replacing the pyrrolidine with a 6 -membered ring and changing the alcohol group to a fluoride, follow these steps:</p>
<ol>
<li>Replace the pyrrolidine ring ( $\mathrm{N} 2 \mathrm{CCC}(\mathrm{O}) \mathrm{C} 2$ ) with a 6-membered ring (piperidine). The piperidine ring can be represented as N2CCCCC2.</li>
<li>Change the alcohol group $(\mathrm{O})$ to a fluoride $(\mathrm{F})$.</li>
</ol>
<p>Here's the modified structure of ascimnib with the requested changes:
$\mathrm{O}=\mathrm{C}(\mathrm{Nc} 1 \mathrm{ccc}(\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Cl}) \mathrm{cc} 1) \mathrm{c} 1 \mathrm{cnc}(\mathrm{N} 2 \mathrm{CCCCC} 2) \mathrm{c}(-c 2 \mathrm{ccn}[\mathrm{nH}] 2) \mathrm{c} 1$
In this modified structure, the $\mathrm{N} 2 \mathrm{CCC}(\mathrm{O}) \mathrm{C} 2$ fragment has been replaced with $\mathrm{N} 2 \mathrm{CCCCC} 2$ and the alcohol group $(\mathrm{O})$ has been replaced with a fluoride $(\mathrm{F})$.</p>
<h2>Prompt:</h2>
<p>Where is the flourine?</p>
<h2>GPT-4:</h2>
<p>Apologies for the confusion in my previous response. I misunderstood your request. Here's the correct modified structure of ascimnib with the pyrrolidine replaced with a 6-membered ring (piperidine) and the alcohol group changed to a fluoride:
$\mathrm{O}=\mathrm{C}(\mathrm{Nc} 1 \mathrm{ccc}(\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Cl}) \mathrm{cc} 1) \mathrm{c} 1 \mathrm{cnc}(\mathrm{N} 2 \mathrm{CCCCC}(\mathrm{F}) \mathrm{C} 2) \mathrm{c}(-c 2 \mathrm{ccn}[\mathrm{nH}] 2) \mathrm{c} 1$
In this modified structure, the $\mathrm{N} 2 \mathrm{CCC}(\mathrm{O}) \mathrm{C} 2$ fragment has been replaced with $\mathrm{N} 2 \mathrm{CCCCC}(\mathrm{F}) \mathrm{C} 2$, where the alcohol group $(\mathrm{O})$ is now replaced with a fluoride $(\mathrm{F})$.</p>
<h2>Prompt:</h2>
<p>Now the ring has 7 members. I would prefer 6 .</p>
<h2>GPT-4:</h2>
<p>Apologies for the error in my previous response. Here's the correct modified structure of ascimnib with the pyrrolidine replaced with a 6-membered ring (piperidine) and the alcohol group changed to a fluoride: $\mathrm{O}=\mathrm{C}(\mathrm{Nc} 1 \mathrm{ccc}(\mathrm{OC}(\mathrm{F})(\mathrm{F}) \mathrm{Cl}) \mathrm{cc} 1) \mathrm{c} 1 \mathrm{cnc}(\mathrm{N} 2 \mathrm{CCCC}(\mathrm{F}) \mathrm{C} 2) \mathrm{c}(-c 2 \mathrm{ccn}[\mathrm{nH}] 2) \mathrm{c} 1$
In this modified structure, the $\mathrm{N} 2 \mathrm{CCC}(\mathrm{O}) \mathrm{C} 2$ fragment has been replaced with $\mathrm{N} 2 \mathrm{CCCC}(\mathrm{F}) \mathrm{C} 2$, where the alcohol group $(\mathrm{O})$ is now replaced with a fluoride $(\mathrm{F})$, and the ring has a total of 6 members.</p>
<p>Figure 2.7: Manipulation of Asciminib. GPT-4 tries to make the modification by following the instructions but the manipulated result is not correct. With multiple rounds of guidance, GPT-4 finally gives the correct modification.</p>
<h1>2.2.4 Macroscopic questions about drug discovery</h1>
<p>The above evaluations focus more on individual drugs/molecules. Here we further test GPT-4 on macroscopic questions about drug discovery.</p>
<p>In Fig. 2.8, we first ask a basic question about Lipinski's Rule of Five, which is very basic and perhaps the most popular knowledge in drug discovery. GPT-4 provides a correct answer and gives reasonable explanations in helping assess the drug-likeness of a chemical compound. In Fig. 2.9, GPT-4 is asked to introduce the main challenges in drug discovery. This is a general and broad question with no standard answers. GPT-4's answer is meaningful, which implies that GPT-4 has this kind of macroscopic knowledge about drug discovery. The last case in Fig. 2.10 is about how AI and machine learning can help in drug discovery. GPT-4's answer is good and substantial, covering different aspects that AI can potentially help such as benefiting property prediction (ADMET), drug design (generative model), and knowledge discovery.</p>
<p>Overall speaking, GPT-4 has knowledge about the whole process and individual steps in drug discovery.</p>
<h2>GPT-4</h2>
<h2>Prompt:</h2>
<p>What is Lipinski's Rule of Five and how does it help in assessing the drug-likeness of a chemical compound?
GPT-4:
Lipinski's Rule of Five is a set of guidelines proposed by Christopher Lipinski in 1997 to help predict whether a chemical compound has the potential to be an orally active drug in humans. The rule is based on the observation that most orally active drugs possess certain common physicochemical properties related to their absorption, distribution, metabolism, and excretion (ADME) characteristics.</p>
<p>The Rule of Five consists of the following criteria:</p>
<ol>
<li>Molecular weight (MW) should be less than 500 Da .</li>
<li>The octanol-water partition coefficient $(\log \mathrm{P})$ should not be greater than 5 .</li>
<li>The number of hydrogen bond donors (sum of OH and NH groups) should not exceed 5 .</li>
<li>The number of hydrogen bond acceptors (sum of N and O atoms) should not exceed 10 .</li>
</ol>
<p>A chemical compound that violates more than one of these rules is less likely to be an orally active drug. The Rule of Five helps researchers in the early stages of drug discovery to quickly assess the drug-likeness of a compound, prioritize compound libraries for screening, and guide the optimization of lead compounds. It is important to note that the Rule of Five is not a strict rule, but rather a guideline. There are exceptions, and some drugs may violate one or more of these rules and still be orally active. However, the Rule of Five has been widely adopted in the drug discovery process as a useful tool for predicting drug-likeness and filtering out compounds with unfavorable ADME properties.</p>
<p>Figure 2.8: About Lipinski's Rule of Five.</p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>What are the main challenges faced during the drug discovery process?
GPT-4:
The drug discovery process is complex and time-consuming, with several challenges that researchers must overcome to successfully develop new therapeutics. Some of the main challenges include:</p>
<ol>
<li>Target identification and validation: Selecting the right biological target is crucial for successful drug development. Identifying a target that is both relevant to the disease and 'druggable' can be difficult. Furthermore, validating the target's role in the disease and demonstrating that its modulation leads to therapeutic effects can be challenging and resource-intensive.</li>
<li>High attrition rate: The drug development process has a high failure rate, with many potential drug candidates failing during preclinical or clinical development due to issues related to efficacy, safety, or pharmacokinetic properties. This leads to significant time and financial investment in projects that ultimately do not result in approved drugs.</li>
<li>Hit identification and optimization: Finding compounds that selectively bind to the target and exhibit the desired biological activity is challenging. Even after initial hits are identified, optimizing their potency, selectivity, and pharmacokinetic properties can be a complex and iterative process.</li>
<li>Predicting safety and efficacy: Preclinical models, such as cell lines and animal models, do not always accurately predict how a drug candidate will perform in humans. As a result, compounds that appear promising in preclinical studies may still fail in clinical trials due to unforeseen safety or efficacy issues.</li>
<li>Long development timelines: The drug discovery process typically takes 10-15 years from target identification to regulatory approval. This lengthy timeline increases the risk of failure and the financial burden associated with drug development.</li>
<li>High costs: Drug development is an expensive endeavor, with costs often exceeding one billion dollars for a single approved drug. The high costs, combined with the high failure rate, make drug discovery a risky and resource-intensive process.</li>
<li>Regulatory hurdles: Navigating the complex regulatory landscape, including securing approval for clinical trials and eventual marketing, can be challenging and time-consuming. Ensuring compliance with the requirements of regulatory agencies, such as the FDA, adds additional complexity to the drug discovery process.</li>
<li>Competition and intellectual property: Protecting intellectual property rights and staying ahead of competitors in a rapidly evolving scientific landscape can be challenging, especially in highly competitive therapeutic areas.</li>
<li>Personalized medicine and complex diseases: The increasing focus on personalized medicine and understanding the genetic basis of diseases adds complexity to target identification and validation. Additionally, complex diseases with multiple contributing factors, such as Alzheimer's or cancer, make it difficult to identify effective treatments that work for a broad patient population.</li>
</ol>
<p>Figure 2.9: About main challenges in drug discovery.</p>
<h1>GPT-4</h1>
<h2>Prompt:</h2>
<p>How can artificial intelligence and machine learning techniques be applied to the main challenges in drug discovery to accelerate the process?
GPT-4:
Artificial intelligence (AI) and machine learning (ML) techniques have the potential to address many of the main challenges in drug discovery and significantly accelerate the process. Some of the key applications include:</p>
<ol>
<li>Target identification and validation: AI and ML can help analyze large-scale genomic, proteomic, and transcriptomic data to identify and prioritize potential drug targets. They can also predict the functions of unknown proteins and assess the relevance of known targets in various diseases.</li>
<li>De novo drug design: ML algorithms, such as deep generative models, can generate novel chemical structures with desired properties, effectively exploring the vast chemical space for potential drug candidates.</li>
<li>Virtual screening: AI-powered algorithms can be used to screen large compound libraries, ranking and prioritizing compounds based on their predicted affinity to the target, reducing the number of compounds that need to be experimentally tested.</li>
<li>Quantitative structure-activity relationship (QSAR) modeling: ML models can predict the activity of compounds based on their chemical structure, aiding in the optimization of lead compounds.</li>
<li>ADMET prediction: AI models can predict the absorption, distribution, metabolism, excretion, and toxicity (ADMET) properties of compounds, enabling researchers to prioritize compounds with favorable pharmacokinetic profiles and minimize potential safety issues.</li>
<li>Drug repurposing: AI techniques can help identify new therapeutic applications for existing drugs by analyzing large-scale data and identifying patterns in drug-target-disease relationships.</li>
<li>Biomarker discovery: ML algorithms can analyze complex biological data to identify biomarkers for disease diagnosis, prognosis, and response to treatment, which can facilitate patient stratification and personalized medicine.</li>
<li>Clinical trial optimization: AI can assist in the design of clinical trials by predicting patient responses, identifying potential risks, and optimizing patient recruitment and stratification strategies.</li>
<li>Data integration and knowledge discovery: AI and ML can integrate and analyze heterogeneous data sources, such as literature, experimental data, and patient records, to generate new hypotheses and uncover hidden relationships between drugs, targets, and diseases.</li>
</ol>
<p>By automating and streamlining these aspects of the drug discovery process, AI and ML can help reduce the time and cost associated with bringing new drugs to market. Moreover, these techniques can improve the success rate of drug discovery efforts by providing deeper insights into complex biological systems and guiding more informed decision-making.</p>
<p>Figure 2.10: Suggestions about AI for drug discovery.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2.11: The label distributions for BindingDB $K_{i}$ and DAVIS datasets are illustrated. The xaxis represents the processed log version of the affinity value, while the y-axis displays the frequency ratio corresponding to each affinity value.</p>
<h1>2.3 Drug-target binding</h1>
<p>Drug-target binding, a fundamental concept in the field of pharmacology and drug discovery, refers to the specific interaction between a drug molecule and its intended target, usually a protein or receptor, within the body. Understanding drug-target binding is essential for designing effective and safe drugs. The strength of the interaction, known as binding affinity, is a critical factor in determining a drug's potency and efficacy. Higher binding affinity generally translates to a stronger effect on the target and, consequently, a more significant therapeutic impact. Accurately predicting the binding affinity between drugs and their targets can significantly expedite the drug discovery pipeline, reducing the time and cost required to bring new treatments to market.</p>
<p>In this subsection, we investigate the capability of GPT-4 in predicting drug-target interaction (DTI) and affinity scores. We employ a series of benchmark datasets, representing a diverse range of drug candidates and target proteins, for quantitative evaluation, as well as case studies for qualitative evaluation.</p>
<h3>2.3.1 Drug-target affinity prediction</h3>
<p>As a regression problem, drug-target affinity (DTA) prediction seeks to estimate an affinity score, which quantifies the binding strength between a drug candidate and its target protein.</p>
<p>Settings BindingDB [50] and DAVIS [22] are two prominent datasets for affinity prediction, exhibiting distinct data distributions as depicted in Fig. 2.11. We adopt the data processing approach utilized in previous works [63, 65]. Due to API call limitations, we randomly select 1,000 samples for our test set. We set the temperature for GPT-4 at 0.7 . We examine three different settings: zero-shot, few-shot, and similarity-based.</p>
<p>Zero-shot evaluation For zero-shot evaluation, we mainly test the capability of the GPT-4 to understand important concepts of affinity prediction, as shown in Fig. 2.12 to 2.13.</p>
<ul>
<li>In Fig.2.12, when prompted to estimate the affinity between a drug and a target, GPT-4 does not directly perform the calculation. Instead, it offers step-by-step guidance on estimating the binding affinity and provides additional information about the drug and target.</li>
<li>Fig.2.13 presents an intriguing case where GPT-4 appears to "directly" calculate affinity prediction. When provided with the SMILES of a drug and the FASTA sequence of a target, GPT-4 seemingly emulates the execution of AutoDock Vina (a docking software) and returns an affinity score of -7.2 $\mathrm{kcal} / \mathrm{mol}$. However, it does not genuinely run AutoDock Vina and merely fabricates a score. As a result, it is crucial to verify the accuracy of such numerical outcomes generated by GPT-4.</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://www.rcsb.org/fasta/entry/6M2Q/display&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>