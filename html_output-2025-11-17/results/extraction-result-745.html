<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-745 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-745</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-745</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-249395481</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2206.02063v2.pdf" target="_blank">Active Bayesian Causal Inference</a></p>
                <p><strong>Paper Abstract:</strong> Causal discovery and causal reasoning are classically treated as separate and consecutive tasks: one first infers the causal graph, and then uses it to estimate causal effects of interventions. However, such a two-stage approach is uneconomical, especially in terms of actively collected interventional data, since the causal query of interest may not require a fully-specified causal model. From a Bayesian perspective, it is also unnatural, since a causal query (e.g., the causal graph or some causal effect) can be viewed as a latent quantity subject to posterior inference -- other unobserved quantities that are not of direct interest (e.g., the full causal model) ought to be marginalized out in this process and contribute to our epistemic uncertainty. In this work, we propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian active learning framework for integrated causal discovery and reasoning, which jointly infers a posterior over causal models and queries of interest. In our approach to ABCI, we focus on the class of causally-sufficient, nonlinear additive noise models, which we model using Gaussian processes. We sequentially design experiments that are maximally informative about our target causal query, collect the corresponding interventional data, and update our beliefs to choose the next experiment. Through simulations, we demonstrate that our approach is more data-efficient than several baselines that only focus on learning the full causal graph. This allows us to accurately learn downstream causal queries from fewer samples while providing well-calibrated uncertainty estimates for the quantities of interest.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e745.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e745.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active Bayesian Causal Inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully-Bayesian active learning framework that jointly infers a posterior over structural causal models and arbitrary target causal queries, and sequentially selects interventions that maximise expected information gain about the query.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Active Bayesian Causal Inference (ABCI)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Place a Bayesian prior p(M) over SCMs M=(G,f,σ^2) and define a target query Y=q(M). Compute the query posterior p(Y|D)=E_{M|D}[p(Y|M)] by marginalising nuisance model parts, and design experiments myopically by maximising mutual information I(Y;X_t|data). For tractable instantiation ABCI uses (i) Gaussian processes for non-root mechanisms, (ii) MAP estimation for GP-hyperparameters, (iii) DiBS (continuous latent graph representation + SVGD) to approximate the graph posterior, and (iv) Bayesian optimisation to find informative continuous intervention values; utilities U_CD/U_CML/U_CR implement information-gain objectives for different queries.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic structural causal model simulations (interactive interventional simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Simulated SCMs over continuous variables (nonlinear additive Gaussian noise) where the agent can perform hard interventions do(X_i = x_i) on a subset of actionable variables and receive batches of i.i.d. samples from the resulting interventional distribution. The environment is interactive and allows sequential, adaptive experiment selection but is a synthetic lab (not open-ended).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit: Bayesian marginalisation over the model ensemble and query-targeted experimental design reduce emphasis on irrelevant model components (i.e., the method avoids spending data to learn parts of the model unrelated to the query), but no explicit distractor-detection algorithm is proposed.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Explicit refutation of spurious associations is achieved operationally by selecting interventions that maximise information gain about the query and then observing interventional outcomes; models (or edges) whose predictions are incompatible with observed interventional data receive reduced posterior weight.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Myopic mutual-information maximisation: choose intervention a to maximise I(Y; X_t | data). Candidate interventions are single-node hard interventions; intervention values are optimised with Bayesian optimisation; the utility is estimated with nested Monte Carlo over sampled graphs from DiBS and GP predictive posteriors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative empirical results on simulated scale-free SCMs (d=20) show ABCI objectives (U_CD, U_CML, U_CR) are more data-efficient than observational or random baselines: U_CD achieves faster graph identification (lower ESHD and higher AUPRC), U_CML gives good SCM-level performance across metrics, and U_CR attains substantially lower Query KLD when the target is an interventional distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines that do not perform informed experimentation (OBS, RAND FIXED) perform notably worse across metrics; a stronger random baseline (RAND) that randomises intervention values can perform competitively in some settings but on average is outperformed by ABCI objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ABCI provides a principled way to focus experimental effort on the causal query of interest, yielding substantially better query estimates (lower Query KLD) with fewer interventional samples than baselines; by marginalising nuisance parts of the model and selecting high-information interventions, ABCI implicitly avoids wasting data on irrelevant/distracting variables, but the framework assumes causal sufficiency (no hidden confounders) and does not include an explicit algorithmic module dedicated to detecting or removing distractor variables.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e745.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e745.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP-DiBS-ABCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GP-DiBS-ABCI (GP + DiBS instantiation of ABCI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A concrete, tractable implementation of ABCI for nonlinear additive Gaussian noise SCMs that uses Gaussian processes for mechanisms and DiBS for approximate Bayesian structure learning, together with MAP hyperparameter estimation and Bayesian optimisation for intervention choice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>GP-DiBS-ABCI</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Model non-root node mechanisms f_j with Gaussian processes (rational-quadratic kernel) and place priors on GP hyperparameters and noise variances; compute GP marginal likelihoods analytically conditional on hyperparameters and use MAP estimates for (σ^2, κ). Represent graph posterior via DiBS latent variables Z and approximate p(Z|data) with SVGD; sample graphs p(G|Z) to approximate expectations. Estimate the information-gain utility with nested Monte Carlo over sampled graphs and GP predictive posteriors; optimise continuous intervention values via Bayesian optimisation (GP-UCB). Shared priors and caching of marginal likelihoods reduce computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic interactive SCM simulator (same as ABCI experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Simulated SCMs (nonlinear additive GPs) with actionable variables; allows sequential, batched interventions and sampling from induced interventional distributions; experiments conducted on scale-free and Erdős–Rényi graph topologies.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit: like ABCI, GP-DiBS-ABCI downweights irrelevant model components via Bayesian marginalisation and by selecting interventions aimed at reducing uncertainty about the query; there is no explicit statistical test or regulariser targeted at distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventional testing: interventions selected by the information-gain utility are executed and observed outcomes used to reduce posterior mass on graphs/mechanisms inconsistent with the data, thereby refuting spurious dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Nested Monte-Carlo estimation of information-gain utilities using samples from the DiBS graph posterior and GP predictive distributions, combined with Bayesian optimisation (GP-UCB) to find informative continuous intervention values; single-node interventions considered for simplicity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Empirically, GP-DiBS-ABCI variants (U_CD, U_CML, U_CR) outperform uninformed baselines on graph recovery (ESHD, AUPRC), average interventional KLD, and query KLD on scale-free SCMs; U_CR excels at learning a specific interventional distribution while U_CD is best for full graph identification.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Uninformed strategies (OBS, RAND FIXED) produce significantly worse ESHD/AUPRC and higher KLDs; RAND (randomising values) is a relatively strong baseline but typically inferior to GP-DiBS-ABCI in targeted query performance.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This instantiation makes ABCI practical for moderately sized problems (d up to 20 in experiments) and demonstrates that combining GPs, DiBS, and information-gain-based experimentation yields data-efficient learning of queries; computational cost and the assumption of causal sufficiency are limitations—no explicit distractor-detection mechanisms are integrated.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e745.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e745.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DiBS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DiBS: Differentiable Bayesian Structure Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A continuous-latent-variable approach for Bayesian structure learning that represents distributions over DAGs via a latent variable Z and enables gradient-based approximate posterior inference (e.g., SVGD) while enforcing acyclicity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DiBS: Differentiable Bayesian Structure Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DiBS (Differentiable Bayesian Structure Learning)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Introduce continuous latent particles Z with an edge-wise generative model p(G|Z) and a prior p(Z) that penalises cycles; perform approximate inference in latent space with Stein Variational Gradient Descent (SVGD) to obtain particles approximating p(Z|data). Expectations over graphs are computed by sampling G~p(G|Z) for each particle, enabling efficient approximation of E_{G|data}[φ(G)].</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Used inside GP-DiBS-ABCI on synthetic SCM experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Provides approximate graph posteriors used to compute information-gain utilities and ultimately to choose experiments in an interactive simulated SCM environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Used to produce a sample-based approximation to the graph posterior which is required by the mutual-information-based experiment selection; DiBS itself is not an active-learning policy but a posterior inference tool used within ABCI.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DiBS enables scalable, differentiable approximate Bayesian structure learning that integrates well with ABCI's nested Monte Carlo estimators and information-gain objectives; it provides efficient graph posterior samples but does not itself address hidden confounding or explicit spurious-variable detection.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e745.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e745.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>U_CR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Reasoning Information-Gain Utility (U_CR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-gain utility specialised to learning target interventional distributions: it selects interventions that maximally reduce uncertainty about a specified interventional query (e.g., p_{do(Xi=ψ)}(X_j)).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>U_CR (Causal Reasoning utility)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Define the query Y as an interventional distribution (possibly for a distribution over intervention values ψ). The utility U_CR(a)=I(Y;X_t|data) is derived and computed via nested expectations over the graph posterior and GP predictive distributions; Monte-Carlo samples of graphs (from DiBS), simulated experiment outcomes and sampled ψ values are used to estimate the utility; optimisation over intervention values is done with Bayesian optimisation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic SCM experiments for learning interventional distributions</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive simulated SCM where the policy may or may not be able to intervene directly on the treatment variable; U_CR designs interventions (possibly on other variables) to best reduce posterior uncertainty about the interventional distribution of interest.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Query-targeted experimental design plus Bayesian marginalisation: the method focuses data collection and inference only on model aspects relevant to the target interventional distribution, thereby effectively downweighting irrelevant variables and spurious associations that do not affect the query.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables / spurious associations arising from limited observational data or model misspecification (no explicit treatment of hidden confounding since causal sufficiency is assumed).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Implicit detection via expected information gain: candidates whose interventions yield little information about the query reveal variables unlikely to be causally relevant to the query; posterior predictive inconsistency with interventional outcomes signals spurious model structure.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Bayesian marginalisation combined with targeted interventions: models/edges that do not predict observed interventional outcomes for the query receive reduced posterior weight, effectively downweighting spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Active refutation by executing interventions chosen to be maximally informative about the query and observing outcomes that invalidate models encoding spurious dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Maximise I(Y;X_t|data) for the chosen query Y; estimate utility with MC over DiBS graph samples and GP predictions; optimise intervention values with Bayesian optimisation; supports single-node hard interventions and sampling ψ from a prior over intervention values.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Empirically delivers substantially lower Query KLD compared to baselines (OBS, RAND, RAND FIXED) on simulated SCMs; when the treatment variable is not directly actionable, U_CR still outperforms alternatives after a modest number of experiments (≥10).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baselines that are not query-targeted (OBS, RAND FIXED) show higher Query KLD; UCML (full SCM utility) performs second-best in many settings but is less efficient than U_CR for focused interventional queries.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Targeting the information gain specifically at the interventional distribution of interest is more sample-efficient for that query than trying to learn the full SCM first; U_CR effectively ignores irrelevant parts of the model, so it achieves better query estimates (lower Query KLD) while sometimes yielding worse full-graph metrics (ESHD, Avg I-KLD).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e745.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e745.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active Invariant Causal Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active invariant causal prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A related active experiment selection approach that leverages invariance/stability to select experiments which help identify causal relationships that are invariant across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Active invariant causal prediction: Experiment selection through stability</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Active Invariant Causal Prediction (AICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mentioned in related work as an approach that selects experiments based on stability/invariance criteria to identify causal predictors robust to distribution shifts; not used in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as prior work on experiment selection that relates to finding interventions robust to spurious correlations via invariance/stability; the paper references it but does not evaluate or integrate it.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e745.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e745.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sparse Mechanism Shift</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A line of work (cited) that addresses causal discovery under distributional shifts by assuming only a sparse subset of mechanisms change across environments, enabling identification of robust causal relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Sparse Mechanism Shift approaches</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mentioned in related work: methods that exploit heterogeneity across environments under the assumption that only a small number of causal mechanisms change, using stability to identify causal structure resilient to spurious, environment-specific associations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as relevant work for detecting robust causal relations under environmental heterogeneity; not implemented in the paper's experiments but pointed out as related direction for handling spurious correlations arising from nonstationarity.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Active invariant causal prediction: Experiment selection through stability <em>(Rating: 2)</em></li>
                <li>Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis <em>(Rating: 2)</em></li>
                <li>ABCD-strategy: Budgeted experimental design for targeted causal structure discovery <em>(Rating: 2)</em></li>
                <li>Interventions, Where and How? Experimental Design for Causal Models at Scale <em>(Rating: 2)</em></li>
                <li>Learning neural causal models with active interventions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-745",
    "paper_id": "paper-249395481",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "ABCI",
            "name_full": "Active Bayesian Causal Inference",
            "brief_description": "A fully-Bayesian active learning framework that jointly infers a posterior over structural causal models and arbitrary target causal queries, and sequentially selects interventions that maximise expected information gain about the query.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Active Bayesian Causal Inference (ABCI)",
            "method_description": "Place a Bayesian prior p(M) over SCMs M=(G,f,σ^2) and define a target query Y=q(M). Compute the query posterior p(Y|D)=E_{M|D}[p(Y|M)] by marginalising nuisance model parts, and design experiments myopically by maximising mutual information I(Y;X_t|data). For tractable instantiation ABCI uses (i) Gaussian processes for non-root mechanisms, (ii) MAP estimation for GP-hyperparameters, (iii) DiBS (continuous latent graph representation + SVGD) to approximate the graph posterior, and (iv) Bayesian optimisation to find informative continuous intervention values; utilities U_CD/U_CML/U_CR implement information-gain objectives for different queries.",
            "environment_name": "Synthetic structural causal model simulations (interactive interventional simulator)",
            "environment_description": "Simulated SCMs over continuous variables (nonlinear additive Gaussian noise) where the agent can perform hard interventions do(X_i = x_i) on a subset of actionable variables and receive batches of i.i.d. samples from the resulting interventional distribution. The environment is interactive and allows sequential, adaptive experiment selection but is a synthetic lab (not open-ended).",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": "Implicit: Bayesian marginalisation over the model ensemble and query-targeted experimental design reduce emphasis on irrelevant model components (i.e., the method avoids spending data to learn parts of the model unrelated to the query), but no explicit distractor-detection algorithm is proposed.",
            "refutation_method": "Explicit refutation of spurious associations is achieved operationally by selecting interventions that maximise information gain about the query and then observing interventional outcomes; models (or edges) whose predictions are incompatible with observed interventional data receive reduced posterior weight.",
            "uses_active_learning": true,
            "inquiry_strategy": "Myopic mutual-information maximisation: choose intervention a to maximise I(Y; X_t | data). Candidate interventions are single-node hard interventions; intervention values are optimised with Bayesian optimisation; the utility is estimated with nested Monte Carlo over sampled graphs from DiBS and GP predictive posteriors.",
            "performance_with_robustness": "Qualitative empirical results on simulated scale-free SCMs (d=20) show ABCI objectives (U_CD, U_CML, U_CR) are more data-efficient than observational or random baselines: U_CD achieves faster graph identification (lower ESHD and higher AUPRC), U_CML gives good SCM-level performance across metrics, and U_CR attains substantially lower Query KLD when the target is an interventional distribution.",
            "performance_without_robustness": "Baselines that do not perform informed experimentation (OBS, RAND FIXED) perform notably worse across metrics; a stronger random baseline (RAND) that randomises intervention values can perform competitively in some settings but on average is outperformed by ABCI objectives.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "ABCI provides a principled way to focus experimental effort on the causal query of interest, yielding substantially better query estimates (lower Query KLD) with fewer interventional samples than baselines; by marginalising nuisance parts of the model and selecting high-information interventions, ABCI implicitly avoids wasting data on irrelevant/distracting variables, but the framework assumes causal sufficiency (no hidden confounders) and does not include an explicit algorithmic module dedicated to detecting or removing distractor variables.",
            "uuid": "e745.0"
        },
        {
            "name_short": "GP-DiBS-ABCI",
            "name_full": "GP-DiBS-ABCI (GP + DiBS instantiation of ABCI)",
            "brief_description": "A concrete, tractable implementation of ABCI for nonlinear additive Gaussian noise SCMs that uses Gaussian processes for mechanisms and DiBS for approximate Bayesian structure learning, together with MAP hyperparameter estimation and Bayesian optimisation for intervention choice.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "GP-DiBS-ABCI",
            "method_description": "Model non-root node mechanisms f_j with Gaussian processes (rational-quadratic kernel) and place priors on GP hyperparameters and noise variances; compute GP marginal likelihoods analytically conditional on hyperparameters and use MAP estimates for (σ^2, κ). Represent graph posterior via DiBS latent variables Z and approximate p(Z|data) with SVGD; sample graphs p(G|Z) to approximate expectations. Estimate the information-gain utility with nested Monte Carlo over sampled graphs and GP predictive posteriors; optimise continuous intervention values via Bayesian optimisation (GP-UCB). Shared priors and caching of marginal likelihoods reduce computational cost.",
            "environment_name": "Synthetic interactive SCM simulator (same as ABCI experiments)",
            "environment_description": "Simulated SCMs (nonlinear additive GPs) with actionable variables; allows sequential, batched interventions and sampling from induced interventional distributions; experiments conducted on scale-free and Erdős–Rényi graph topologies.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": "Implicit: like ABCI, GP-DiBS-ABCI downweights irrelevant model components via Bayesian marginalisation and by selecting interventions aimed at reducing uncertainty about the query; there is no explicit statistical test or regulariser targeted at distractors.",
            "refutation_method": "Interventional testing: interventions selected by the information-gain utility are executed and observed outcomes used to reduce posterior mass on graphs/mechanisms inconsistent with the data, thereby refuting spurious dependencies.",
            "uses_active_learning": true,
            "inquiry_strategy": "Nested Monte-Carlo estimation of information-gain utilities using samples from the DiBS graph posterior and GP predictive distributions, combined with Bayesian optimisation (GP-UCB) to find informative continuous intervention values; single-node interventions considered for simplicity.",
            "performance_with_robustness": "Empirically, GP-DiBS-ABCI variants (U_CD, U_CML, U_CR) outperform uninformed baselines on graph recovery (ESHD, AUPRC), average interventional KLD, and query KLD on scale-free SCMs; U_CR excels at learning a specific interventional distribution while U_CD is best for full graph identification.",
            "performance_without_robustness": "Uninformed strategies (OBS, RAND FIXED) produce significantly worse ESHD/AUPRC and higher KLDs; RAND (randomising values) is a relatively strong baseline but typically inferior to GP-DiBS-ABCI in targeted query performance.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "This instantiation makes ABCI practical for moderately sized problems (d up to 20 in experiments) and demonstrates that combining GPs, DiBS, and information-gain-based experimentation yields data-efficient learning of queries; computational cost and the assumption of causal sufficiency are limitations—no explicit distractor-detection mechanisms are integrated.",
            "uuid": "e745.1"
        },
        {
            "name_short": "DiBS",
            "name_full": "DiBS: Differentiable Bayesian Structure Learning",
            "brief_description": "A continuous-latent-variable approach for Bayesian structure learning that represents distributions over DAGs via a latent variable Z and enables gradient-based approximate posterior inference (e.g., SVGD) while enforcing acyclicity.",
            "citation_title": "DiBS: Differentiable Bayesian Structure Learning",
            "mention_or_use": "use",
            "method_name": "DiBS (Differentiable Bayesian Structure Learning)",
            "method_description": "Introduce continuous latent particles Z with an edge-wise generative model p(G|Z) and a prior p(Z) that penalises cycles; perform approximate inference in latent space with Stein Variational Gradient Descent (SVGD) to obtain particles approximating p(Z|data). Expectations over graphs are computed by sampling G~p(G|Z) for each particle, enabling efficient approximation of E_{G|data}[φ(G)].",
            "environment_name": "Used inside GP-DiBS-ABCI on synthetic SCM experiments",
            "environment_description": "Provides approximate graph posteriors used to compute information-gain utilities and ultimately to choose experiments in an interactive simulated SCM environment.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": true,
            "inquiry_strategy": "Used to produce a sample-based approximation to the graph posterior which is required by the mutual-information-based experiment selection; DiBS itself is not an active-learning policy but a posterior inference tool used within ABCI.",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "DiBS enables scalable, differentiable approximate Bayesian structure learning that integrates well with ABCI's nested Monte Carlo estimators and information-gain objectives; it provides efficient graph posterior samples but does not itself address hidden confounding or explicit spurious-variable detection.",
            "uuid": "e745.2"
        },
        {
            "name_short": "U_CR",
            "name_full": "Causal Reasoning Information-Gain Utility (U_CR)",
            "brief_description": "An information-gain utility specialised to learning target interventional distributions: it selects interventions that maximally reduce uncertainty about a specified interventional query (e.g., p_{do(Xi=ψ)}(X_j)).",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "U_CR (Causal Reasoning utility)",
            "method_description": "Define the query Y as an interventional distribution (possibly for a distribution over intervention values ψ). The utility U_CR(a)=I(Y;X_t|data) is derived and computed via nested expectations over the graph posterior and GP predictive distributions; Monte-Carlo samples of graphs (from DiBS), simulated experiment outcomes and sampled ψ values are used to estimate the utility; optimisation over intervention values is done with Bayesian optimisation.",
            "environment_name": "Synthetic SCM experiments for learning interventional distributions",
            "environment_description": "Interactive simulated SCM where the policy may or may not be able to intervene directly on the treatment variable; U_CR designs interventions (possibly on other variables) to best reduce posterior uncertainty about the interventional distribution of interest.",
            "handles_distractors": true,
            "distractor_handling_technique": "Query-targeted experimental design plus Bayesian marginalisation: the method focuses data collection and inference only on model aspects relevant to the target interventional distribution, thereby effectively downweighting irrelevant variables and spurious associations that do not affect the query.",
            "spurious_signal_types": "Irrelevant variables / spurious associations arising from limited observational data or model misspecification (no explicit treatment of hidden confounding since causal sufficiency is assumed).",
            "detection_method": "Implicit detection via expected information gain: candidates whose interventions yield little information about the query reveal variables unlikely to be causally relevant to the query; posterior predictive inconsistency with interventional outcomes signals spurious model structure.",
            "downweighting_method": "Bayesian marginalisation combined with targeted interventions: models/edges that do not predict observed interventional outcomes for the query receive reduced posterior weight, effectively downweighting spurious signals.",
            "refutation_method": "Active refutation by executing interventions chosen to be maximally informative about the query and observing outcomes that invalidate models encoding spurious dependencies.",
            "uses_active_learning": true,
            "inquiry_strategy": "Maximise I(Y;X_t|data) for the chosen query Y; estimate utility with MC over DiBS graph samples and GP predictions; optimise intervention values with Bayesian optimisation; supports single-node hard interventions and sampling ψ from a prior over intervention values.",
            "performance_with_robustness": "Empirically delivers substantially lower Query KLD compared to baselines (OBS, RAND, RAND FIXED) on simulated SCMs; when the treatment variable is not directly actionable, U_CR still outperforms alternatives after a modest number of experiments (≥10).",
            "performance_without_robustness": "Baselines that are not query-targeted (OBS, RAND FIXED) show higher Query KLD; UCML (full SCM utility) performs second-best in many settings but is less efficient than U_CR for focused interventional queries.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Targeting the information gain specifically at the interventional distribution of interest is more sample-efficient for that query than trying to learn the full SCM first; U_CR effectively ignores irrelevant parts of the model, so it achieves better query estimates (lower Query KLD) while sometimes yielding worse full-graph metrics (ESHD, Avg I-KLD).",
            "uuid": "e745.3"
        },
        {
            "name_short": "Active Invariant Causal Prediction",
            "name_full": "Active invariant causal prediction",
            "brief_description": "A related active experiment selection approach that leverages invariance/stability to select experiments which help identify causal relationships that are invariant across environments.",
            "citation_title": "Active invariant causal prediction: Experiment selection through stability",
            "mention_or_use": "mention",
            "method_name": "Active Invariant Causal Prediction (AICP)",
            "method_description": "Mentioned in related work as an approach that selects experiments based on stability/invariance criteria to identify causal predictors robust to distribution shifts; not used in this paper's experiments.",
            "environment_name": null,
            "environment_description": null,
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as prior work on experiment selection that relates to finding interventions robust to spurious correlations via invariance/stability; the paper references it but does not evaluate or integrate it.",
            "uuid": "e745.4"
        },
        {
            "name_short": "Sparse Mechanism Shift",
            "name_full": "Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis",
            "brief_description": "A line of work (cited) that addresses causal discovery under distributional shifts by assuming only a sparse subset of mechanisms change across environments, enabling identification of robust causal relations.",
            "citation_title": "Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis",
            "mention_or_use": "mention",
            "method_name": "Sparse Mechanism Shift approaches",
            "method_description": "Mentioned in related work: methods that exploit heterogeneity across environments under the assumption that only a small number of causal mechanisms change, using stability to identify causal structure resilient to spurious, environment-specific associations.",
            "environment_name": null,
            "environment_description": null,
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as relevant work for detecting robust causal relations under environmental heterogeneity; not implemented in the paper's experiments but pointed out as related direction for handling spurious correlations arising from nonstationarity.",
            "uuid": "e745.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Active invariant causal prediction: Experiment selection through stability",
            "rating": 2,
            "sanitized_title": "active_invariant_causal_prediction_experiment_selection_through_stability"
        },
        {
            "paper_title": "Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis",
            "rating": 2,
            "sanitized_title": "causal_discovery_in_heterogeneous_environments_under_the_sparse_mechanism_shift_hypothesis"
        },
        {
            "paper_title": "ABCD-strategy: Budgeted experimental design for targeted causal structure discovery",
            "rating": 2,
            "sanitized_title": "abcdstrategy_budgeted_experimental_design_for_targeted_causal_structure_discovery"
        },
        {
            "paper_title": "Interventions, Where and How? Experimental Design for Causal Models at Scale",
            "rating": 2,
            "sanitized_title": "interventions_where_and_how_experimental_design_for_causal_models_at_scale"
        },
        {
            "paper_title": "Learning neural causal models with active interventions",
            "rating": 1,
            "sanitized_title": "learning_neural_causal_models_with_active_interventions"
        }
    ],
    "cost": 0.0229525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Active Bayesian Causal Inference</p>
<p>Christian Toth 
Lars Lorch 
Eth Zürich 
Christian Knoll 
T U Graz 
Andreas Krause 
Eth Zürich 
Franz Pernkopf 
Robert Peharz 
T U Graz 
Julius Von Kügelgen </p>
<p>MPI for Intelligent Systems
TU Graz
Graz</p>
<p>Tübingen University of Cambridge</p>
<p>Active Bayesian Causal Inference</p>
<p>Causal discovery and causal reasoning are classically treated as separate and consecutive tasks: one first infers the causal graph, and then uses it to estimate causal effects of interventions. However, such a two-stage approach is uneconomical, especially in terms of actively collected interventional data, since the causal query of interest may not require a fully-specified causal model. From a Bayesian perspective, it is also unnatural, since a causal query (e.g., the causal graph or some causal effect) can be viewed as a latent quantity subject to posterior inferenceother unobserved quantities that are not of direct interest (e.g., the full causal model) ought to be marginalized out in this process and contribute to our epistemic uncertainty. In this work, we propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian active learning framework for integrated causal discovery and reasoning, which jointly infers a posterior over causal models and queries of interest. In our approach to ABCI, we focus on the class of causally-sufficient, nonlinear additive noise models, which we model using Gaussian processes. We sequentially design experiments that are maximally informative about our target causal query, collect the corresponding interventional data, and update our beliefs to choose the next experiment. Through simulations, we demonstrate that our approach is more data-efficient than several baselines that only focus on learning the full causal graph. This allows us to accurately learn downstream causal queries from fewer samples while providing well-calibrated uncertainty estimates for the quantities of interest.In this section, we first introduce the ABCI framework in generality and formalize its main concepts and distributional components, which are illustrated inFig. 1. In § 4, we then describe our particular instantiation of ABCI for the class of causally sufficient nonlinear additive Gaussian noise models.Notation. We use upper-case X and lower-case x to denote random variables and their realizations, respectively. Sets and vectors are written in bold face, X and x. We use p(·) to denote different distributions, or densities, which are distinguished by their arguments.Causal Model. To treat causality in a rigorous way, we first need to postulate a mathematically well-defined causal model. Historically hard questions about causality can then be reduced to epistemic questions, that is, what and how much is known about the causal model. A prominent type of causal model is the structural causal model (SCM) [56]. From a Bayesian perspective, an SCM can be viewed as a hierarchical data-generating process involving latent random variables. Definition 1 (SCM). An SCM M over observed endogenous variables X = {X 1 , . . . , X d } and unobserved exogenous variables U = {U 1 , . . . , U d } consists of structural equations, or mechanisms,. . , d}, (3.1) which assign the value of each X i as a deterministic function f i of its direct causes, or causal parents, Pa i ⊆ X \ {X i } and U i ; and a joint distribution p(U) over the exogenous variables.Associated with each SCM is a directed causal graph G with vertices X and edges X j → X i if and only if X j ∈ Pa i , which we assume to be acyclic. Any acyclic SCM then induces a unique observational distribution p(X | M) over the endogenous variables X, which is obtained as the pushforward measure of p(U ) through the causal mechanisms in Eq. (3.1).Interventions.A crucial aspect of causal models such as SCMs is that they also model the effect of interventions-external manipulations to one or more of the causal mechanisms in Eq. (3.1)-which,</p>
<p>Introduction</p>
<p>Causal reasoning, that is, answering causal queries such as the effect of a particular intervention, is a fundamental scientific quest [3,36,39,49]. A rigorous treatment of this quest requires a reference causal model, typically consisting at least of (i) a causal diagram, or directed acyclic graph (DAG), capturing the qualitative causal structure between a system's variables [55] and (ii) a joint distribution that is Markovian w.r.t. this causal graph [75]. Other frameworks additionally model (iii) the functional dependence of each variable on its causal parents in the graph [56,83]. If the graph is not known from domain expertise, causal discovery aims to infer it from data [48,75]. However, given only passively-collected observational data and no assumptions on the data-generating process, causal discovery is limited to recovering the Markov equivalence class (MEC) of DAGs implying the conditional independences present in the data [75]. Additional assumptions like linearity can render the graph identifiable [37, 61,71,86] but are often hard to falsify, thus leading to risk of misspecification. These shortcomings motivate learning from experimental (interventional) data, which enables recovering the true causal structure [16,17,31]. Since obtaining interventional data is costly in practice, we study the active learning setting, in which we sequentially design and perform interventions that are most informative for the target causal query [1,26,31,32,50,79].</p>
<p>Classically, causal discovery and reasoning are treated as separate, consecutive tasks that are studied by different communities. Prior work on experimental design has thus focused either purely on causal reasoning-that is, how to best design experimental studies if the causal graph is known?-or purely on causal discovery, whenever the graph is unknown [35,61]. In the present work, we consider the more general setting in which we are interested in performing causal reasoning but do not have access to a reference causal model a priori. In this case, causal discovery can be seen as a means to an end rather than as the main objective. Focusing on actively learning the full causal model to enable subsequent causal reasoning can thus be disadvantageous for two reasons. First, wasting samples on learning the full causal graph is suboptimal if we are only interested in specific aspects of the causal model. Second, causal discovery from small amounts of data entails significant epistemic uncertainty-for example, incurred by low statistical test power or multiple highly-scoring DAGs-which is not taken into account when selecting a single reference causal model [2,21].</p>
<p>In this work, we propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian framework for integrated causal discovery and reasoning with experimental design. The basic approach is to put a Bayesian prior over the causal model class of choice, and to cast the learning problem as Bayesian inference over the model posterior. Given the unobserved causal model, we formalize causal reasoning by introducing the target causal query, a function of the causal model that specifies the set of causal quantities we are interested in. The model posterior together with the query function induce a query posterior, which represents the result of our Bayesian learning procedure. It can be used, e.g., in downstream decision tasks or to derive a MAP solution or suitable expectation. To learn the query posterior, we follow the Bayesian optimal experimental design approach [10,42] and sequentially choose admissible interventions on the true causal model that are most informative about our target query w.r.t. our current beliefs. Given the observed data, we then update our beliefs by computing the posterior over causal models and queries and use them to design the next experiment.</p>
<p>Since inference in the general ABCI framework is computationally highly challenging, we instantiate our approach for the class of causally-sufficient, nonlinear additive Gaussian noise models [37], which we model using Gaussian processes (GPs) [22,82]. To perform efficient posterior inference in the combinatorial space of causal graphs, we use a recently proposed framework for differentiable Bayesian structure learning (DiBS) [45] that employs a continuous latent probabilistic graph representation. To efficiently maximise the information gain in the experiment design loop, we rely on Bayesian optimisation [46,47,73]. Overall, we highlight the following contributions:</p>
<p>• We propose ABCI as a flexible Bayesian active learning framework for efficiently inferring arbitrary sets of causal queries, subsuming causal discovery and reasoning as special cases ( § 3).</p>
<p>• We provide a fully Bayesian treatment for the flexible class of nonlinear additive Gaussian noise models by leveraging GPs, continuous graph parametrisations, and Bayesian optimisation ( § 4).</p>
<p>• We demonstrate that our approach scales to relevant problem sizes and compares favourably to baselines in terms of efficiently learning the graph, full SCM, and interventional distributions ( § 5).</p>
<p>Related Work</p>
<p>Causal discovery and reasoning have been widely studied in machine learning and statistics [27,35,61,81]. Given an already collected set of observations, there is a large body of literature on learning causal structure, both in the form of a point estimate [9,30,43,59,60,71,75] and a Bayesian posterior [2,4,12,14,21,33,45]. Given a known causal graph, previous work studies how to estimate treatment effects or counterfactuals [56, 67,69]. When interventional data is yet to be collected, existing work primarily focuses on the specific task of structure learning-without its downstream use. The concept of (Bayesian) active causal discovery was first considered in discrete [50,79] or linear [11,53] models with closed-form marginal likelihoods and later extended to nonlinear causal mechanisms [78,80], multi-target interventions [77], and general models by using hypothesis testing [23] or heuristics [68]. Graph theoretic works give insights on the interventions required for partial or full identifiability [15-17, 31, 38, 40, 70, 84]. use Bayesian experimental design based on our current beliefs to choose a maximally informative intervention at to perform. We then collect a finite data sample from the interventional distribution induced by the environment, which we assume to be described by an unknown structural causal model (SCM) M over a set of observable variables X. Given the interventional data x 1:t collected from the true SCM M and a prior distribution over the model class of consideration, we infer the posterior over a target causal query Y = q(M) that can be expressed as a function of the causal model. For example, we may be interested in the graph (causal discovery), the presence of certain edges (partial causal discovery), the full SCM (causal model learning), a collection of interventional distributions or treatment effects (causal reasoning), or any combination thereof.</p>
<p>Beyond learning the complete causal graph, few prior works have studied active causal inference. Concurrent work of Tigas et al.</p>
<p>[78] considers experimental design for learning a full SCM parameterised by neural networks. There are significant differences to our approach. In particular, our framework ( § 3) is not limited to the information gain over the full model and provides a fully Bayesian treatment of the functions and their epistemic uncertainty ( § 4). Agrawal et al. [1] consider actively learning a function of the causal graph under budget constraints, though not of the causal mechanisms and only for linear Gaussian models. Conversely, Rubenstein et al. [66] perform experimental design for learning the causal mechanisms after the causal graph has been inferred. Thus, while prior work considers causal discovery and reasoning as separate tasks, ABCI forms an integrated Bayesian approach for learning causal queries through interventions, reducing to previously studied settings in special cases. We further discuss related work in Appx. A. in general, are denoted using Pearl's do-operator [56] as do ({X i 
=f i (Pa i , U i )} i∈I ) with I ⊆ [d]
and suitably chosenf i (·). An intervention leads to a new SCM, the so-called interventional SCM, in which the relevant structural equations in Eq. (3.1) have been replaced by the new, manipulated ones. The interventional SCM thus induces a new distribution over the observed variables, the so-called interventional distribution, which is denoted by p do(a) (X | M) with a denoting the (set of) intervention(s) {X i =f i (Pa i , U i )} i∈I . Causal effects, that is, expressions like E[X j |do(X i = 3)], can then be derived from the corresponding interventional distribution via standard probabilistic inference.</p>
<p>Being Bayesian with Respect to Causal Models. The main epistemic challenge for causal reasoning stems from the fact that the true causal model M is not or not completely known. The canonical response to such epistemic challenges is a Bayesian approach: place a prior p(M) over causal models, collect data D from the true model M , and compute the posterior via Bayes rule:
p(M | D) = p(D | M) p(M) p(D) = p(D | M) p(M) p(D | M) p(M) dM . (3.2)
A full Bayesian treatment over M is computationally delicate, to say the least. We require a way to parameterise the class of models M while being able to perform posterior inference over this model class.</p>
<p>In this paper, we present a fully Bayesian approach for flexibly modelling nonlinear relationships ( § 4).</p>
<p>Bayesian Causal Inference. In the causal inference literature, the tasks of causal discovery and causal reasoning are typically considered separate problems. The former aims to learn (parts of) the causal model M , typically the causal graph G , while the latter assumes that the relevant parts of M are already known and aims to identify and estimate some query of interest, typically using only observational data. This separation suggests a two-stage approach of first performing causal discovery and then fixing the model for subsequent causal reasoning. From the perspective of uncertainty quantification and active learning, however, this distinction is unnatural because intermediate, unobserved quantities like the causal model do not contribute to the epistemic uncertainty in the final quantities of interest. Instead, we define a causal query function q, which specifies a target causal query Y = q(M) as a function of the causal model M. This view thus subsumes and generalises causal discovery and reasoning into a unified framework. For example, possible causal queries are:</p>
<p>Causal Discovery: Y = q CD (M) = G, that is, learning the full causal graph G;</p>
<p>Partial Causal Discovery:
Y = q PCD (M) = φ(G)
, that is, learning some feature φ of the graph, such as the presence of a particular (set of) edge(s); Causal Model Learning: Y = q CML (M) = M, that is, learning the full SCM M;</p>
<p>Causal Reasoning:
Y = q CR (M) = {X do(X I(j) =ψj ) j
} j∈J , that is, learning a set of interventional variables X j induced by M under do(X I(j) = ψ j ). 2 Given a causal query, Bayesian inference naturally extends to our learning goal, the query posterior:
p(Y | D) = p(Y | M) p(M | D) dM = E M | D [ p(Y | M)] . (3.3)
Evidently, computing Eq. (3.3) constitutes a hard computational problem in general, as we need to marginalise out the causal model. In § 4, we introduce a practical implementation for a restricted causal model class, informed by this challenge.</p>
<p>Identifiability of causal models and queries. A crucial concept is that of identifiability of a model class, which refers to the ability to uniquely recover the true model in the limit of infinitely many observations from it [25]. 3 In the context of our setting, if the class of causal models M is identifiable, the model posterior p(M | D) in Eq. (3.2) and hence, assuming q(·) is deterministic, 2 The return value of q is a set of realisations of the respective random variables. In principle, the set J can be uncountable, subsuming interventional distributions for a continuous set of intervention values, possibly on different variables. However, instead of having an uncountable set J for a continuous set of intervention values, it may be more practical to have a finite set J for intervention targets and to assume a distribution over intervention values ψj ∼ pj(ψ) as we do in § 4.2 and § 5. 3 It is worth pointing out that the term "identifiability" is sometimes used differently in the causal inference literature: within causal discovery, it typically refers to structure identifiability, that is, recovering only the causal graph; in the context of causal reasoning, on the other hand, it typically refers to whether an interventional (or counterfactual) query can be expressed in terms of known quantities, usually involving only the observational distribution. Here, we will use the term in its (original) statistical sense to refer to identifiability of models. also the query posterior p(Y | D) in Eq. (3.3) will collapse and converge to a point mass on their respective true values M and q(M ), given infinite data and provided the true model has non-zero mass under our prior, p(M ) &gt; 0. Given only observational data, causal models are notoriously unidentifiable in general: without further assumptions on p(U) and the structural form of Eq. (3.1), neither the graph nor the mechanisms can be recovered. In this case, p(M | D) may only converge to an equivalence class of models that cannot be further distinguished. Note, however, that even in this case, p(Y | D) may still sometimes collapse, for example, if the Markov equivalence class (MEC) of graphs is identifiable (under causal sufficiency) and our query concerns the presence of a particular edge which is shared by all graphs in the MEC.</p>
<p>Active Learning with Sequential Interventions. Rather than collect a large observational dataset, we seek to leverage experimental data, which can help resolve some of the aforementioned identifiability issues and facilitate learning our target causal query more quickly, even if the model is identifiable. Since obtaining experimental data is costly in practice, we study the active learning setting in which we sequentially design experiments in the form of interventions a t . 4 At each time step t, the outcome of this experiment a t is a batch x t of N t i.i.d. observations from the true interventional distribution:
x t = {x t,n } Nt n=1 , x t,n i.i.d. ∼ p do(at) (X | M ) (3.4)
Crucially, we design the experiment a t to be maximally informative about our target causal query Y . In our Bayesian setting, this is naturally formulated as maximising the myopic information gain from the next intervention, that is, the mutual information between Y and the outcome X t [10,42]:
max at I(Y ; X t | x 1:t−1 ) (3.5)
where X t follows the predictive interventional distribution of the Bayesian causal model ensemble at time t − 1 under intervention a t , which is given by
X t ∼ p do(at) (X | x 1:t−1 ) ∝ p do(at) (X | M) p(M | x 1:t−1 ) dM. (3.6)
By maximising Eq. (3.5), we collect experimental data and infer our target causal query Y in a highly efficient, goal-directed manner.</p>
<p>Tractable ABCI for Nonlinear Additive Noise Models</p>
<p>Having described the general ABCI framework and its conceptual components, we now detail how to instantiate ABCI for a flexible model class that still allows for tractable, approximate inference. This requires us to specify (i) the class of causal models we consider in Eq. Model Class and Parametrisation. In the following, we consider nonlinear additive Gaussian noise models [37] of the form
X i := f i (Pa i ) + U i , with U i ∼ N (0, σ 2 i ) for i ∈ {1, . . . , d},(4.1)
where the f i 's are smooth, nonlinear functions and the U i 's are assumed to be mutually independent. The latter corresponds to the assumption of causal sufficiency, or no hidden confounding. Interventional Likelihood. We support the realistic setting where only a subset W ⊆ X of all variables are actionable, that is, can be intervened upon. 5 We consider hard interventions of the form do(a t ) = do(X I = x I ) that fix a subset X I ⊆ W to a constant x I . Due to causal sufficiency, the interventional likelihood under such hard interventions a t factorises over the causal graph G and is given by the g-formula [64] or truncated factorisation [75]:
p do(at) (X | G, f , σ 2 ) = I{X I = x I } j ∈I p(X j | f j (Pa G j ), σ 2 j ). (4.2)
The last term in Eq. (4.2) is given by N (X j | f j (Pa G j ), σ 2 j ), due to the Gaussian noise assumption. Let x 1:t be the entire dataset, collected up to time t. The likelihood of x 1:t is then given by
p(x 1:t | G, f , σ 2 ) = t τ =1 p do(aτ ) (x τ | G, f , σ 2 ) = t τ =1 Nt n=1 p do(aτ ) (x τ,n | G, f , σ 2 ). (4.3)
Structured Model Prior. To specify our prior, we distinguish between root nodes X i , for which Pa i = ∅ and thus f i = const, and non-root nodes X j . For a given causal graph G, we denote the index set of root nodes by R(G) = {i ∈ [d] : Pa G i = ∅} and that of non-root nodes by NR(G) = [d] \ R(G). We then place the following structured prior over SCMs M = (G, f , σ 2 ):
p(M) = p(G) p(f , σ 2 | G) = p(G) i∈R(G) p(f i , σ 2 i | G) j∈NR(G) p(f j | G)p(σ 2 j | G) . (4.4)
Here, p(G) is a prior over graphs and p(f , σ 2 | G) is a prior over the functions and noise variances. We factorise our prior conditional on G as in Eq. (4.4) not only to allow for a separate treatment of root vs. non-root nodes, but also to share priors across similar graphs. Whenever Pa G1
i = Pa G2 i , we set p(f i , σ 2 i | G 1 ) = p(f i , σ 2 i | G 2 )
. As a consequence, the posteriors are also shared, which substantially reduces the computational cost in practice (see Appx. E.2 for details). Our prior also encodes the beliefs that
{f i , σ 2 i } ⊥ ⊥ {f i , σ 2 i } | G for i = i ∈ [d]
and that f j ⊥ ⊥ σ 2 j | G for j ∈ NR(G) which is motivated by the principle of independent causal mechanisms [61] and the causal sufficiency assumption. Our specific choices for the different factors on the RHS of Eq. (4.4) are guided by ensuring tractable inference and described in more detail below.</p>
<p>Model Posterior. Given collected data x 1:t , we can update our beliefs and quantify our uncertainty in M by inferring the posterior p(M | x 1:t ) over SCMs M = (G, f , σ 2 ), which can be written as 6
p(M | x 1:t ) = p(G | x 1:t ) i∈R(G) p(f i , σ 2 i | x 1:t , G) j∈NR(G) p(f j , σ 2 j | x 1:t , G) . (4.5)
For root nodes i ∈ R(G), posterior inference given the graph is straightforward. We have f i = const, so f i can be viewed as the mean of U i . We thus place conjugate normal-inverse-gamma
N-Γ −1 (µ i , λ i , α R i , β R i ) priors on p(f i , σ 2 i | G)
, which allows us to analytically compute the root node posteriors p(f i , σ 2 i | x 1:t , G) in Eq. (4.5) given the hyperparameters (µ, λ, α R , β R ) [51]. The posteriors over graphs and non-root nodes j ∈ NR(G) are given by
p(G | x 1:t ) = p(x 1:t | G) p(G) p(x 1:t ) , p(f j , σ 2 j | x 1:t , G) = p(x 1:t | G, f j , σ 2 j ) p(f j , σ 2 j | G) p(x 1:t | G) . (4.6)
Computing these posteriors is more involved and discussed in the following.</p>
<p>Addressing Challenges for Posterior Inference with GPs and DiBS</p>
<p>The posterior distributions in Eq. (4.6) are intractable to compute in general due to the marginal likelihood and evidence terms p(x 1:t | G) and p(x 1:t ), respectively. In the following, we will address these challenges by means of appropriate prior choices and approximations.</p>
<p>Challenge 1: Marginalising out the Functions. The marginal likelihood p(x 1:t | G) reads
p(x 1:t | G) = p(x 1:t | G, f j , σ 2 j ) p(f j | G) p(σ 2 j | G) df j dσ 2 j (4.7)
and requires evaluating integrals over the function domain. We use Gaussian processes (GPs) [82] as an elegant way to solve this problem, as GPs flexibly model nonlinear functions while offering convenient analytical properties. Specifically, we place a GP(0, k G j (·, ·)) prior on p(f j |G), where k G j (·, ·) is a covariance function over the parents of X j with kernel parameters κ j . As is common, we refer to (κ j , σ 2 j ) as the GP-hyperparameters. In addition, we place Gamma(α σ j , β σ j ) and Gamma (α κ j , β κ j ) priors on p(σ 2 i | G) and p(κ i | G) and collect their parameters in (α GP , β GP ). Figure 2: Graphical model of GP-DiBS-ABCI.
G Z fi σ 2 i x τ,n (µ, λ, α R , β R ) do(aτ ) fj σ 2 j κj (α GP , β GP ) NR(G) Nτ R(G) t
The graphical model underlying all variables and hyperparameters is shown in Fig. 2. For our model class, GPs provide closed-form expressions for the GP-marginal likelihood p(x 1:t | G, σ 2 j , κ j ), as well as for the GP posteriors p(f j | x 1:t , G, σ 2 j , κ j ) and the predictive posteriors over observations p(X | x 1:t , G, σ 2 , κ) [82], see Appx. B for details.</p>
<p>Challenge 2:</p>
<p>Marginalising out the GP-Hyperparameters. While GPs allow for exact posterior inference conditional on a fixed instance of (σ 2 j , κ j ), evaluating expressions such as p(f j | x 1:t , G) requires marginalising out these GP-hyperparameters from the GP-posterior. In general, this is intractable to do exactly, as there is no analytical expression for p(σ 2 j , κ j | x 1:t , G). To tackle this, we approximate such terms using a maximum a posteriori (MAP) point estimate (σ 2 j ,κ j ) obtained by performing gradient ascent on the unnormalised log posterior
∇ log p(σ 2 j , κ j | x 1:t , G) = ∇ log p(x 1:t | G, σ 2 j , κ j ) + ∇ log p(σ 2 j , κ j | G) (4.8)
according to a predefined update schedule, see Alg. 1. More specifically,
p(f j | x 1:t , G) = p(f j | x 1:t , G, σ 2 j , κ j )p(σ 2 j , κ j | x 1:t , G) dσ 2 j dκ j ≈ p(f j | x 1:t , G,σ 2 j ,κ j )
Challenge 3: Marginalising out the Causal Graph. The evidence p(x 1:t ) is given by
p(x 1:t ) = G p(x 1:t | G) p(G) (4.9)
and involves a summation over all possible DAGs G. This becomes intractable for d ≥ 5 variables as the number of DAGs grows super-exponentially in the number of variables [65]. To address this challenge, we employ the recently proposed DiBS framework [45]. By introducing a continuous prior p(Z) that models G via p(G | Z) and simultaneously enforces acyclicity of G, Lorch et al. [45] show that we can efficiently infer the discrete posterior p(G | x 1:t ) via p(Z | x 1:t ) as
E G | x 1:t [φ(G)] = E Z | x 1:t E G | Z [ p(x 1:t | G) φ(G)] E G | Z [ p(x 1:t | G)] (4.10)
where φ is some function of the graph. Since p(Z | x 1:t ) is a continuous density with tractable gradient estimators, we can leverage efficient variational inference methods such as Stein Variational Gradient Descent (SVGD) for approximate inference [44]. Additional details on DiBS are given in Appx. D.</p>
<p>Approximate Bayesian Experimental Design with Bayesian Optimisation</p>
<p>Following § 3, our goal is to perform experiments a t that are maximally informative about our target query Y = q(M) by maximising the information gain from Eq. (3.5) given our hitherto collected data D := x 1:t−1 . In Appx. C, we show that this is equivalent to maximising the following utility function:
U (a) = H(X t | D) + E M | D E X t ,Y | M log E M | D p(X t , Y | M ) ,(4.11)
where
H(X t | D) = E M | D E X t | M log E M | D p(X t | M )
denotes the differential entropy of the experiment outcome which depends on a and is distributed as in Eq. (3.6). This surrogate objective can be estimated using a nested Monte Carlo estimator as long as we can sample from and compute p(Y | M), or alternatively, p(Y | X t , G, D). Refer to Appx. C for further details. For example, for q CR (M) = X do(Xi=ψ) j with ψ ∼ p(ψ) a distribution over intervention values, we obtain: 
U CR (a) = E G | D E X t | G,D − log E G | D p(X t | D, G ) (4.12) + E ψ E do(Xi=ψ) Xj | X t ,G,D log E G | D p(X t | D, G) p do(Xi=ψ) (X j | X t , G, D) .z 0 ∼ p(Z) sample initial particles; Eq. (D.12) for t = 1 to T do a t ← arg max a=(I,x I ) U (a, x 1:t−1 ) design experiment; Eq. (4.11) x t ← {x (t,n) ∼ p do(at) (X | M )} Nt n=1 perform experiment; Eq. (3.4) z t ← z t−1 if r t then z t ← resample_particles (z t ) see Appx.E end repeat G ← {G (k,m) ∼ p(G | z t m )} K k=1 M m=1 sample graphs; Eq. (D.11) κ κ κ, σ σ σ 2 ← estimate_hyperparameters(x 1:st , G) see Eq. (4.8) z t ← svgd_step(z t , x 1:t , G, κ κ κ, σ σ σ 2 ) update latent particles until svgd_convergence z t now approximate p(Z | x 1:t ) end
Importantly, for specific instances of the query function q(·) discussed in § 3, we can derive simpler utility functions than Eq. (4.11). For example, for q CD (M) = G and q CML (M) = M, we arrive at
U CD (a) = E G | D E X t | G,D log p(X t | D, G) − log E G | D p(X t | D, G ) , (4.13) U CML (a) = E M | D E X t | M log p(X t | M) − log E G | D p(X t | D, G ) , (4.14)
where the entropy
E X t | M [log p(X t | M)]
can again be efficiently computed given our modelling choices. For brevity, we defer derivations and estimation details to Appxs. C and D.</p>
<p>Finding the optimal experiment a * t = (I * , x * I ) requires jointly optimising the utility function corresponding to our query with respect to (i) the set of intervention targets I and (ii) the corresponding intervention values x I . This lends itself naturally to a nested, bi-level optimisation scheme [80]:
I * ∈ arg max I U (I, x * I ) , where ∀I : x * I ∈ arg max x I U (I, x I ) ,
(4.15) In the above, we first estimate the optimal intervention values for all candidate intervention targets I and then select the intervention target that yields the highest utility. The intervention target I may contain multiple variables, which would yield a combinatorial problem. For simplicity, we consider only single-node interventions, |I| = 1. To find x * I , we employ Bayesian optimisation [46, 47, 73] to efficiently estimate the most informative intervention value x * I , see Appx. D.</p>
<p>Experiments</p>
<p>Setup. We evaluate ABCI by inferring the query posterior on synthetic ground-truth SCMs using several different experiment selection strategies. Specifically, we design experiments w.r.t. U CD (causal discovery), U CML (causal model learning), and U CR (causal reasoning); see § 4.2. We compare against baselines which (i) only sample from the observational distribution (OBS) or (ii) pick an intervention target j uniformly at random from [d] ∪ {∅} and set X j = 0 (RAND FIXED, a weak random baseline used in prior work) or draw X j ∼ U(−7, 7) (RAND) if X j = ∅. All methods follow our Bayesian GP-DiBS-ABCI approach from § 4. We sample ground truth SCMs over random scale-free graphs [6] of size d = 20, with mechanisms and noise variances drawn from our model prior in Eq. (4.4). In Appx. G, we report additional results for both scale-free and Erdős Renyi random graphs over d = 10 resp. d = 20 variables. For specific prior choices and simulation details, see Appx. D.</p>
<p>Metrics. As ABCI infers a posterior over the target query Y , a natural evaluation metric is the Kullback-Leibler divergence (KLD) between the true query distribution and the inferred query posterior, KL(p(Y | M )|| p(Y | x 1:t )). We report Query KLD, a KLD estimate for target interventional distributions (q CR ). As a proxy for the KLD of the SCM posterior (q CML ), 7 we report 7 The SCM KLD is either zero, if the SCM posterior collapses onto the true SCM, or infinite, otherwise.  the average KLD across all single node interventional distributions
{p do(Xi=ψ) (X)} d i=1 , with ψ ∼ U(−7, 7) (Average I-KLD).
We also report the expected structural Hamming distance [13],
ESHD = E G | x 1:t [SHD(G, G )]
, a commonly used causal discovery metric, and the area under the precision recall curve (AUPRC). See Appx. F for further details.</p>
<p>Causal Discovery and SCM Learning (Fig. 3). In our first experiment, we find that all ABCI-based methods are able to meaningfully learn from small amounts of data, which validates our Bayesian approach. Moreover, performing targeted interventions using experimental design indeed improves performance compared to uninformed experimentation (OBS, RAND FIXED, RAND). Notably, the stronger random baseline (RAND), which also randomises over intervention values, performs well in the considered setting. As expected by the theoretical grounding of the information gain utilities, U CD identifies the true graph the fastest (as measured by ESHD), whereas U CML exhibits good scores across all metrics. Further details are given in the caption of Fig. 3.</p>
<p>Learning Interventional Distributions (Fig. 4). In our second experiment, we investigate ABCI's causal reasoning capabilities by randomly sampling ground-truth SCMs as described above over the fixed graph shown in Fig. 4 (right), which is not known to the methods. Our target query is the set of interventional random variables, or "distributional treatment effects", X do(X3=ψ) 5 for treatments ψ ∼ U [2,5]. The results show that our informed experiment selection strategies significantly outperform the baselines at causal reasoning as measured by the Query KLD. In accordance with the results from Fig. 3 and considering that, once we know the true SCM, we can compute any causal quantity of interest, U CML seems to provide a reasonable experimental strategy in case the causal query of interest is not known a priori. However, our results indicate that if we do know our query of interest, then U CR provides a more efficient experiment design strategy for its estimation, even when the treatment variable of interest is not directly intervenable. In this case, the task is indeed more difficult, as highlighted by the larger Query KLD values across all considered methods.</p>
<p>Discussion</p>
<p>Assumptions, Limitations, and Extensions. In § 4, we have made several assumptions to facilitate tractable inference and showcase the ABCI framework in a relatively simple data-generating process. In particular, our assumptions exclude heteroscedastic noise, unobserved confounding, and cyclic relationships. On the experimental design side, we only considered hard interventions, but for some applications soft interventions [18] are more plausible. On the query side, we only considered interventional distributions. However, SCMs also naturally lend themselves to counterfactual reasoning, so one could also consider counterfactual queries such as the effect of the treatment on the treated [34,72]. In principle, the ABCI framework as presented in § 3 extends directly to such generalisations. In practice, however, these can be non-trivial to implement, especially with regard to model parametrisation and tractable inference. Since actively performed interventions allow for causal learning even under causal sufficiency violations, we consider this a promising avenue for future work and believe the ABCI framework to be particularly well-suited for exploring it.</p>
<p>Reflections on the ABCI Framework. The main conceptual advantages of the ABCI framework are that it is flexible and principled. By considering general target causal queries, we can precisely specify what aspects of the causal model we are interested in. This conceptual framework offers a fresh perspective on the classical divide between causal discovery and reasoning: sometimes, the main objective may be to foster scientific understanding by uncovering the qualitative causal structure underlying real-world systems; other times, causal discovery may only be a means to an end to support causal reasoning. Of particular interest in the context of actively selecting interventions is the setting in which we cannot directly intervene on variables whose causal effect on others we are interested in (see Fig. 4), which connects to concepts such as transportability and external validity [7,57]. ABCI is also flexible in that it easily allows for incorporating available domain knowledge: if we know some aspects of the model a priori (as assumed in conventional causal reasoning) [53] or have access to a large observational sample (from which we can infer the MEC of DAGs) [1], we can encode this in our prior and only optimise over a smaller model class. The principled Bayesian nature of ABCI comes at a significant computational cost: most integrals are intractable and approximating them with Monte-Carlo sampling is computationally expensive and can introduce bias when resources are limited, though cf.</p>
<p>[85] for recent efforts to address such intractability. We discuss the computational complexity of our implementation in more detail in Appx. E.3. On the other hand, in many real-world applications, such as in the context of biological networks, active interventions are possible but only at a significant cost [11,53]. In such cases in particular, a careful and computationally-heavy experimental design approach as presented in the present work is warranted and could be easily amortised.</p>
<p>[18] Eberhardt Summarising the abstract/introduction we claim (i) to introduce a principled fully-Bayesian active learning framework for integrated causal discovery and reasoning and to (ii) show the practicality of our approach through simulations. We lay out the former concisely in § 3 and § 4. We report the empirical evaluation in § 5. In this section, we further discuss the most closely related prior works, which also consider a Bayesian active learning approach for causal discovery. These methods are summarised and contrasted with ABCI in Tab. 1. Similar to our approach, they also all assume acyclicity and causal sufficiency. The setting with continuous variables was not explored from an active Bayesian causal discovery perspective until the work of Cho et al. [11], who consider the linear Gaussian case in the context of biological networks. Cho et al. [11] similarly use an inverse-Gamma prior to enable closed-form posterior inference. In these approaches, experiment selection targets the full causal graph. Agrawal et al. [1] extend the work of Cho et al. [11] by enabling the active learning of some function of the causal graph and handling interventional budget constraints.</p>
<p>Similarly to our approach, the concurrent work by Tigas et al.</p>
<p>[78] models nonlinear causal relationships with additive Gaussian noise in the active learning setting. However, they are limited to targeting the full SCM for experiment design, which corresponds to our q CML objective. In addition, their approach does not quantify the uncertainty in the functions conditional on a causal graph sampled from the graph posterior. In contrast, our nonparametric approach both directly models the epistemic uncertainty in the functions and mitigates the risk of model misspecification by jointly learning the kernel hyperparameters. Moreover, our method is Bayesian over the unknown noise variances, which are usually unknown in practice. Other related work by Shanmugam et al. [70] considers the problem of finding the minimal number of perfectly informative (w.r.t. conditional independences induced by the true underlying graph) multi-target interventions to fully identify the true causal graph. In contrast, we assume that only finitely many data points are available per experiment/intervention. Thus, we try to perform at each time step (possibly repeating) interventions to maximally reduce our uncertainty in the target causal query (which may be the causal graph). As another point of difference, we also optimise for the actual intervention value, whereas Shanmugam et al. [70] only optimise for the intervention targets.</p>
<p>B Background on Gaussian processes</p>
<p>We use Gaussian Processes (GPs) to model mechanisms of non-root nodes X i , i.e., we place a GP prior on p(f i | G). In the following, we give some background on GPs and how to compute probabilistic quantities thereof relevant to this work. For further information on GPs we refer the reader to Williams and Rasmussen [82].</p>
<p>A GP(m i (·), k G i (·, ·)) is a collection of random variables, any finite number of which have a joint Gaussian distribution, and is fully determined by its mean function m i (·) and covariance function (or
kernel) k G i (·, ·), where m(x) = E[f (x)], and k(x, x ) = E[(f (x) − m(x))(f (x ) − m(x ))]. (B.1)
In our experiments, we choose the mean function m i (x) ≡ 0 to be zero and a rational quadratic kernel
k RQ (x, x ) = κ o i · 1 + 1 2α (x − x ) κ l i (x − x ) −α (B.2)
as our covariance function. Here, α denotes a weighting parameter, κ o i denotes an output scale parameter and κ l i denotes a length scale parameter. For the weighting parameter, we use a default value of α = log 2 ≈ 0.693. For κ l i and κ o i we choose priors according to Appx. D.4. In Section 4.1 we summarise both parameters as κ i = (κ o i , κ l i ). In this work, we consider Gaussian additive noise models (see Eq. (4.1)). Hence, for a given non-root node X i in some graph G, we have
p(X i | pa G i , f i , σ 2 i , G) = N (X i | f i (pa G i ), σ 2 i ) (B.3)
where pa G i denotes the parents of X i in G. For some batch of collected data x = {x n } N n=1 , let
x i = (x 1 i , . . . x N i ) T , pa G i = (pa G,1 i , . . . , pa G,N i ), and K the Gram matrix with entries K m,n = k RQ (pa G,m i , pa G,n i
). Then, we can compute the prior marginal log-likelihood, which is needed to compute p(x 1:t | G), in closed form as
log p(x i | pa G i , σ 2 i , G) = log E fi | G p(x i | pa G i , f i , σ 2 i , G) (B.4) = − 1 2 x T i (K + σ 2 I) −1 x i − 1 2 log |K + σ 2 I| − N 2 log 2π. (B.5)
To predict the function values f i ( pa ). Then, the predictive posterior is multivariate Gaussian
p(f i ( pa G i ) | pa G i , x, σ 2 i , G) = N (µ f , Σ f ) (B.6)
with mean
µ f = K † K + σ 2 i I −1 x i (B.7) and covariance Σ f =K − K † K + σ 2 i I −1 K † . (B.8)
Finally, the marginal posterior over observationsX i , which is needed to sample and evaluate candidate experiments in the experimental design process, is given by
p(X i | pa G i , x, σ 2 i , G) = N (µ Xi , Σ Xi ) (B.9)
with mean µ Xi = µ f (B.10) and covariance
Σ Xi = Σ f + σ 2 i I. (B.11)</p>
<p>C Derivation of the Information Gain Utility Functions</p>
<p>In the following, we provide the derivations for the expressions presented in Section 4.2.</p>
<p>C.1 Information Gain for General Queries</p>
<p>We show that arg max
at I(Y ; X t | x 1:t−1 ) = arg max at U (a t ) (C.1)
for U (a t ) given in Eq. (4.11).</p>
<p>Proof. We write the mutual information in the following form
I(Y ; X t | x 1:t−1 ) = H(Y | x 1:t−1 ) + H(X t | x 1:t−1 ) − H(Y, X t | x 1:t−1 ). (C.2)
In the above, we expand the joint entropy of experiment outcome and query as
H(Y, X t | x 1:t−1 ) = −E Y, X t | x 1:t−1 log p(Y, X t | x 1:t−1 ) (C.3) = −E M | x 1:t−1 E Y, X t | M log p(Y, X t | x 1:t−1 ) (C.4) = −E M | x 1:t−1 E Y, X t | M log E M | x 1:t−1 p(Y | M ) · p(X t | M ) (C.5)
for any query such that query and experiment outcome are conditionally independent given an SCM. This holds true, e.g., whenever Y is a deterministic function of M such as Y = q CD (M) = G.</p>
<p>The marginal entropy of the experiment outcome given previously observed data is
H(X t | x 1:t−1 ) = −E X t | x 1:t−1 log p(X t | x 1:t−1 ) (C.6) = −E M | x 1:t−1 E X t | M log p(X t | x 1:t−1 ) (C.7) = −E M | x 1:t−1 E X t | M log E M | x 1:t−1 p(X t | M ) (C.8) = −E M | x 1:t−1 E X t | M log E f ,σ 2 ,G | x 1:t−1 p(X t | f , σ 2 , G ) (C.9) = −E M | x 1:t−1 E X t | M log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.10) = −E f ,σ 2 ,G | x 1:t−1 E X t | f ,σ 2 ,G log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.11) = −E G | x 1:t−1 E X t | G,x 1:t−1 log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.12)
Finally, since the query posterior entropy H(Y | x 1:t−1 ) does not depend on the candidate experiment a t , we obtain
arg max at I(Y ; X t | x 1:t−1 ) = arg max at H(Y | x 1:t−1 ) + H(X t | x 1:t−1 ) − H(Y, X t | x 1:t−1 ) = arg max at H(X t | x 1:t−1 ) − H(Y, X t | x 1:t−1 ) (C.13)
which, together with Eqs. (C.5) and (C.8), completes the proof.</p>
<p>C.2 Derivation of the Causal Discovery Utility Function</p>
<p>To derive U CD (a), we note that Y = q CD (M) = G, and hence the joint entropy of experiment outcome and query in Eq. (C.3) becomes
H(G, X t | x 1:t−1 ) = −E G, X t | x 1:t−1 log p(G, X t | x 1:t−1 ) (C.14) = −E G, X t | x 1:t−1 log p(X t | G, x 1:t−1 ) + log p(G | x 1:t−1 ) (C.15) = −E G, X t | x 1:t−1 log p(X t | G, x 1:t−1 ) + H(G | x 1:t−1 ) (C.16) = −E G | x 1:t−1 E X t | G,x 1:t−1 log p(X t | G, x 1:t−1 ) + H(G | x 1:t−1 ). (C.17)
Substituting this into Eq. (C.2) yields
I(G; X t | x 1:t−1 ) (C.18) = H(X t | x 1:t−1 ) + E G | x 1:t−1 E X t | G,x 1:t−1 log p(X t | G, x 1:t−1 ) . (C.19)
By Eq. (C.12), we have
= E G | x 1:t−1 E X t | G,x 1:t−1 log p(X t | G, x 1:t−1 ) − log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.20)
which recovers the utility function U CD (a) from Eq. (4.13).</p>
<p>C.3 Derivation of the Causal Model Learning Utility Function</p>
<p>To derive U CML (a) given Y = q CML (M) = M, the joint entropy of experiment outcome and query in Eq. (C.3) are given by
H(M, X t | x 1:t−1 ) = −E M, X t | x 1:t−1 log p(M, X t | x 1:t−1 ) (C.21) = −E M, X t | x 1:t−1 log p(X t | M, x 1:t−1 ) + log p(M | x 1:t−1 ) (C.22) = −E M, X t | x 1:t−1 log p(X t | M) + H(M | x 1:t−1 ) (C.23) = −E M | x 1:t−1 E X t | M log p(X t | M) + H(M | x 1:t−1 ). (C.24)
As previously, substituting this into Eq. (C.2) yields
I(G; X t | x 1:t−1 ) = H(X t | x 1:t−1 ) + E M | x 1:t−1 E X t | M log p(X t | M, ) (C.25)
and by Eq. (C.10), we have
= E M | x 1:t−1 E X t | M log p(X t | M) − log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.26)
which recovers the utility U CML (a) from Eq. (4.14).</p>
<p>For our concrete modeling choices we can further simplify this utility. Let Anc M i and Pa M i denote the ancestor and parent sets of node X i in M. Then,
E M | x 1:t−1 E X t | M log p(X t | M) (C.27) = E M | x 1:t−1   E X t | M   log i ∈I t p do(at) (X t i | pa M i , M)     (C.28) = E M | x 1:t−1   E X t | M   i ∈I t log p do(at) (X t i | pa M i , M)     (C.29) = E M | x 1:t−1   i ∈I t E X t | M log p do(at) (X t i | pa M i , M)   (C.30) = E M | x 1:t−1   i ∈I t E Anc M i | do(at),M E X t i | pa M i ,do(at),M log p do(at) (X t i | pa M i , M)   .
(C.31)</p>
<p>Since our root nodes and GPs assume an additive Gaussian noise model, the innermost expectation amounts to the negative entropy the Gaussian noise variable, i.e.,
E X t i | pa M i ,do(at),M log p do(at) (X t i | pa M i , M) = − N t 2 log(2πσ 2 i e).
(C.32)</p>
<p>As we further assume a homoscedastic noise model for our GPs, Eq. (C.31) reduces to
E M | x 1:t−1   i ∈I t − N t 2 log(2πσ 2 i e)   (C.33) = −E f ,σ 2 ,G | x 1:t−1   i ∈I t N t 2 log(2πσ 2 i e)   (C.34) = −E G | x 1:t−1   E σ 2 | G,x 1:t−1   i ∈I t N t 2 log(2πσ 2 i e)     (C.35) = −E G | x 1:t−1   i ∈I t E σ 2 i | G,x 1:t−1 N t 2 log(2πσ 2 i e)   , (C.36)
which can be approximated by nested Monte Carlo estimation. For non-root nodes we approximate the inner expectation with a single point estimate (cf. Section 4.1). For root nodes we can compute the inner expectation in closed form as
E σ 2 i | G,x 1:t−1 N t 2 log(2πσ 2 i e) = N t 2 log(2πe) − ψ(α t i ) + log β t i (C.37)
where α t i , β t i are the parameters of the inverse-gamma noise posterior
σ 2 i ∼ Γ −1 (σ 2 i | α t i , β t i ) (see Appx. D.3) and ψ(·) is the digamma function.
Proof (adapted from [74]). We need to show that
E σ 2 log(σ 2 ) = −ψ(α) + log β (C.38)
where the noise variance σ 2 follows an inverse-gamma density
σ 2 ∼ Γ −1 (σ 2 | α, β) = β α Γ(α) · (σ 2 ) −α−1 · e − β σ 2 . (C.39)
By substituting y = log σ 2 we get
y ∼ p(y | α, β) = β α Γ(α) · e −αy · e −βe −y . (C.40) Now note that ∞ −∞ p(y | α, β)dy = 1 (C.41)
and hence
Γ(α) β α = ∞ −∞ e −αy · e −βe −y dy. (C.42)
By differentiating the latter integrand w.r.t. α we get d dα e −αy · e −βe −y = (−y)e −αy · e −βe −y = (−y) · p(y | α, β) · Γ(α) β α . (C.43)</p>
<p>Bringing the parts together we obtain
E σ 2 log(σ 2 ) = E y [y] (C.44) = ∞ −∞ y · p(y | α, β)dy (C.45) Eq. (C.43) = − β α Γ(α) ∞ −∞ d dα e −αy · e −βe −y dy (C.46) = − β α Γ(α) d dα ∞ −∞ e −αy · e −βe −y dy (C.47) Eq. (C.42) = − β α Γ(α) d dα Γ(α) β α (C.48) = − β α Γ(α) β −α · d dα Γ(α) − Γ(α) · β −α · log β (C.49) = − ψ(α) + log β, (C.50)
which completes the proof.</p>
<p>In summary, in our instance of GP-DIBS-ABCI we estimate the causal model learning utility as
U CML (a t ) = −E G | x 1:t−1 i∈R(G)\I t N t 2 log(2πe) − ψ(α t i ) + log β t i + i∈NR(G)\I t E σ 2 i | G,x 1:t−1 N t 2 log(2πσ 2 i e) + E X t | G,x 1:t−1 log E G | x 1:t−1 p(X t | G , x 1:t−1 ) (C.51)</p>
<p>C.4 Derivation of the Causal Reasoning Utility Function</p>
<p>We derive the utility function U CR (a) in Eq. (4.12) for the query Y = X do(Xi=ψ) j with ψ ∼ p(ψ) a distribution over intervention values. Starting with the joint entropy in Eq. (C.3) we marginalise over graphs (instead of SCMs) to exploit that we can sample from and evaluate p(X | G, x 1:t−1 ) in closed form by using GPs:
−H(Y, X t | x 1:t−1 ) = E Y, X t | x 1:t−1 log p(Y, X t | x 1:t−1 ) (C.52) = E G | x 1:t−1 E Y,X t | G,x 1:t−1 log E G | x 1:t−1 p(Y, X t | G , x 1:t−1 ) (C.53) = E G | x 1:t−1 E X t | G,x 1:t−1 E Y | X t ,G,x 1:t−1 log E G | x 1:t−1 p(Y | X t , G , x 1:t−1 ) · p(X t | G , x 1:t−1 ) (C.54) To estimate E Y | X t ,G,x 1:t−1 [·]
we first sample intervention values ψ ∼ p(ψ) and then sample from the respective interventional densities p do(Xi=ψ) (X j | X t , G, x 1:t−1 ) induced by candidate SCMs with graph G. Thus, the expectation becomes E ψ E do(Xi=ψ)</p>
<p>Xj | X t ,G,x 1:t−1 [·] . To evaluate p(Y | X t , G , x 1:t−1 ) we estimate p do(Xi=ψ) (X j | X t , G , x 1:t−1 ) as described in Appx. D.1. The joint entropy therefore becomes
−H(Y, X t | x 1:t−1 ) =E G | x 1:t−1 E X t | G,x 1:t−1 E ψ E do(Xi=ψ) Xj | X t ,G,x 1:t−1 (C.55) log E G | x 1:t−1 p do(Xi=ψ) (X j | X t , G , x 1:t−1 ) · p(X t | G , x 1:t−1 )
By substituting Eqs. (C.13) and (D.1) into Eq. (C.12) we obtain the causal reasoning utility in Eq. (4.12).</p>
<p>D Approximate Inference and Experimental Details</p>
<p>In this section, we provide details about our approximate inference and estimation procedures, including the estimation of the marginal interventional likelihoods in Section D.1 and prior choices in Sections D.2 -D.4. We also provide details on DiBS for approximate graph posterior inference in Section D.5, the estimation of the information gain utilities in Section D.6, and our use of Bayesian Optimisation for experimental design in Section D.7.</p>
<p>D.1 Estimating Posterior Marginal Interventional Likelihoods</p>
<p>In the following, we show how we estimate (posterior) marginal interventional likelihoods p do(xj ) (x i | x 1:t ). Let Anc G i and Pa G i denote the ancestor and parent sets of node X i in G. Then, the marginal interventional likelihood is given by
p do(xj ) (x i | x 1:t ) = E M | x 1:t p do(xj ) (x i | M) (D.1) = E f ,σ 2 ,G | x 1:t p do(xj ) (x i | f , σ 2 , G) (D.2) = E f ,σ 2 ,G | x 1:t E Anc G i | do(xj ),f ,σ 2 ,G p do(xj ) (x i | anc G i , f , σ 2 , G) . (D.3)
Given that X i is independent of it's non-descendants given its parents, we obtain
= E f ,σ 2 ,G | x 1:t E Anc G i | do(xj ),f ,σ 2 ,G p do(xj ) (x i | pa G i , f i , σ 2 i , G) (D.4) = E G | x 1:t E f ,σ 2 | G,x 1:t E Anc G i | do(xj ),f ,σ 2 ,G p do(xj ) (x i | pa G i , f i , σ 2 i , G) . (D.5)
Given that p(f , σ 2 | G, x 1:t ) factorises and Anc G i are independent of mechanisms and noise variances f , σ 2 of the non-ancestors of X i , we have
= E G | x 1:t E f Anc G i ,σ 2 Anc G i | G,x 1:t E Anc G i | do(xj ),f Anc G i ,σ 2 Anc G i ,G E fi,σ 2 i | G,x 1:t p do(xj ) (x i | pa G i , f i , σ 2 i , G) . (D.6)
Finally, marginalising out the functions and noise variances, we obtain
= E G | x 1:t E f Anc G i ,σ 2 Anc G i | G,x 1:t E Anc G i | do(xj ),f Anc G i ,σ 2 Anc G i ,G p do(xj ) (x i | pa G i , G) (D.7) = E G | x 1:t E Anc G i | do(xj ),G p do(xj ) (x i | pa G i , G) (D.8) = E G | x 1:t E Anc G i | do(xj ),G p(x i | pa G i , G) Xj =xj . (D.9)
We use Monte Carlo estimation to approximate the outer expectation of this quantity according to Eq. (4.10). To approximate the inner expectation by performing ancestral sampling from the interventional density p do(xj ) (X | G), where we use 50 samples when estimating the U CR utility in Equation Eq. (4.12) and 200 samples when estimating the metrics described in Appx. F.</p>
<p>D.2 Sampling Ground Truth Graphs</p>
<p>When generating ground truth SCMs for evaluation, we sample causal graphs according to two random graph models. First, we sample scale-free graphs using the preferential attachment process presented by Barabási and Albert [6]. We use the networkx.generators.barabasi_albert_graph implementation provided in the NetworkX [29] Python package and interpret the returned, undirected graph as a DAG by only considering the upper-triangular part of its adjacency matrix. Before permuting the node labels, we generate graphs with in-degree 2 for nodes {X i } d i=3 whereas X 1 and X 2 are always root nodes. In addition, we consider Erdös-Renyi random graphs [20], where edges are sampled independently with probability p = 4 d−1 . After sampling edges, we choose a random ordering and discard any edges that disobey this ordering to obtain a DAG. Our choice of p yields an expected degree of 2. Unlike Lorch et al.</p>
<p>[45], we do not provide our model with any kind of prior information on the graph structure.</p>
<p>D.3 Normal-Inverse-Gamma Prior for Root Nodes</p>
<p>We use a conjugate normal-inverse-gamma (N-Γ −1 ) prior
p(f i , σ 2 i | G) = N-Γ −1 (µ i , λ i , α R i , β R i ) (D.10)
as the joint prior over functions and noise parameters for root nodes in G (see Section 4 and Fig. 2).</p>
<p>In our experiments, we use µ i = 0, λ i = 0.1, α R i = 50 and β R i = 25. When generating ground truth SCMs, we draw one sample for (f i , σ 2, i ) from this prior for all i and leave it fixed thereafter. Closed-form expressions for the (posterior) marginal likelihood can be found, e.g., in [51].</p>
<p>D.4 Gamma Priors for GP Hyperparameters of Non-Root Nodes</p>
<p>We model non-root node mechanisms with GPs (see Section 4.1), where each GP has a set of hyperparameters (κ i , σ 2 i ) where κ i = (κ l i , κ o i ) includes a length scale and output scale parameter, respectively, and where σ 2 i denotes the variance of the Gaussian noise variable U i . In our experiments, we use p(σ 2 i | G) = Gamma(α = 50, β = 500), p(κ o i | G) = Gamma(α = 100, β = 10) and p(κ l i | G) = Gamma(α = 30 · |Pa G i |, β = 30), where |Pa G i | denotes the size of the parent set of X i in G.</p>
<p>D.5 DiBS for Approximate Posterior Graph Inference</p>
<p>DiBS [45] introduces a probabilistic latent space representation for DAGs to allow for efficient posterior inference in continuous space. Specifically, given some latent particle z ∈ R d×d×2 we can define an edge-wise generative model
p(G | z) = d i=1 d j=1 j =i p(G i,j | z) (D.11)
where G i,j ∈ {0, 1} indicates the absence/presence of an edge from X i to X j in G, and a prior distribution
p(Z) ∝ exp(−β E G | Z [h(G)]) i,j,k N (z i,j,k | 0, 1) (D.12)
where h(G) is a scoring function quantifying the "degree of cyclicity" of G. β is a temperature parameter weighting the influence of the expected cyclicity in the prior. Lorch et al. [45] propose to use Stein Variational Gradient Descent [44] for approximate inference of p(Z | x 1:t ). SVGD maintains a fixed set of particles z = {z m } M m=1 and updates them using the posterior score ∇ log p(z | x 1:t ) = ∇ log p(z) + ∇ log p(x 1:t | z). In our experiments, we use K = 5 latent particles. For the estimation of expectations as in Eq. (4.10), we use K = 40 MC graph samples unless otherwise stated, hence, a total of M · K = 200 graphs, and we use the DiBS+ particle weighting. In contrast to the original DiBS version, we do not use the annealing parameter α to force the mass of p(G|z) onto a single graph during training. For further details on the method and its implementation, we refer to the original publication [45] and the provided code.</p>
<p>D.6 Estimation of the Information Gain Utility Functions</p>
<p>When estimating the information gain utilities (see § 4.2 and Appx. C), we keep the set of Monte Carlo samples from the SCM posterior p(M | x 1:t ) fixed for all evaluations of the chosen utility during a given experiment design phase at time t, i.e., during the optimisation for all candidate intervention sets and intervention targets. In our experiments, for the U CD and U CML utilities we sample 5 and 30 graphs to approximate the outer and inner expectations w.r.t. the posterior graphs, respectively. We sample 100 hypothetical experiment outcomes with given batch size from p(X t | G, x 1:t ) to approximate the expectation E X t | G,x 1:t [·].</p>
<p>For the U CR utility we sample 3 and 9 graphs to approximate the outer and inner expectations w.r.t. the posterior graphs, respectively. We sample 50 hypothetical experiment outcomes with given batch size from p(X t | G, x 1:t ) to approximate expectations of the form E X t | G,x 1:t [·]. To approximate
the expectations E ψ E do(Xi=ψ)
Xj | X t ,G,D [·] we sample 5 intervention values from p(ψ) and draw 3 samples from p do(Xi=ψ) (X j | X t , G, D) for each intervention value.</p>
<p>D.7 Bayesian Optimisation for Experimental Design</p>
<p>In order to find the optimal experiment a t = (I , x I ) at time t, we compute the optimal intervention value x I ∈ arg max x U (I, x) for each candidate intervention target set I (see Eq. (4.15)). As the evaluation of our proposed utility functions U (a) is expensive, we require an efficient approach for finding optimal intervention values using as few function evaluations as possible. 
x k+1 = arg max x µ k (x) + γσ k (x) , (D.13)
where µ k (x) and σ k (x) correspond to the mean and standard deviation of the GP predictive distribution p(U (I, x) | D BO ) (see Appx. B). We then evaluate U (I, x k+1 ) at the selected x k+1 and repeat. The scalar factor γ trades off exploitation with exploration. In our experiments, we set γ = 1 and run the GP-UCB algorithm 8 times for each candidate set of intervention targets.</p>
<p>simplicity we ignore that not all d mechanisms are modelled by GPs as some are root nodes, so this is not a tight bound). Thus, in the worst case, estimating p(x 1:t |z) = E G|z [p(x 1:t |G)] with K graph samples would yield a complexity of O(K · d · N 3 ). By caching the marginal likelihoods as outlined above we can rewrite the complexity O(K · d · N 3 ) as O(L · N 3 ) where L ≤ K · d denotes the number of unique mechanisms entailed by the set of K graph samples. Although this does not reduce the worst case complexity it nevertheless greatly alleviates the computational demand in practice.</p>
<p>The benefit of caching becomes even more pronounced as p(G | z) concentrates is mass on a small set of similar graphs as a result of the inference process. In particular, when updating the latent particles using SVGD we do not need to recompute p(x 1:t | G) after we have once before sampled G, which greatly speeds up the gradient estimation of the particle posterior.</p>
<p>E.3 Computational Complexity</p>
<p>There are two main phases in our algorithm (disregarding the computation of metrics for evaluation), (i) the inference phase where we (approximately) infer the posterior over SCMs p(M|x 1:t ) after collecting new experimental data, and (ii) the experimental design phase.</p>
<p>The inference phase has worst-case complexity in O(
T SV GD · (T HP · M · K · d · N 3 + M 2 · d 2 ))
where T SV GD is the number of SVGD update steps, T HP is the number of GP hyperparameter update steps, M is the number of latent z particles, K is the number of graph samples per latent z particle, d is the number of nodes in the network, and N is the number of collected experimental samples in x 1:t . The computation of the GP marginal likelihood dominates the complexity of the inference phase. To improve scalability we make use of shared priors and caching. Additionally, we update the GP hyperparameters according to a predefined schedule instead of doing so after each performed experiment. In our experiments, both measures reduce the factor T HP · M · K · d significantly. For example, running inference with 5 freshly initialized z particles with 40 graph samples each on a scale-free SCM with 20 nodes updates the hyperparameters of (2970, 964, 177) GPs during SVGD update steps (1,5,10), and of less than 15 GPs after 20 SVGD update steps. Compared to M · K · d = 4000 in this example, the benefit is evident.</p>
<p>In the experimental design phase we parallelize finding the optimal intervention value for each candidate target node, so the complexity is basically the number of Bayesian optimization (BO) steps times the complexity of the utility we want to optimize for. For a general query (cf. Eq. (4.11)) we have complexity in O(T BO · M · K outer · S · Q · M · K inner · (O(p(y|M) + d · N 3 ))) where T BO is the number of Bayesian optimization iterations, M is the number of latent z particles, K outer is the number of graph samples in the outer SCM expectation in, S is the number of simulated experiments per SCM, Q is the number of simulated queries, K inner is the number of graph samples in the inner SCM expectation, O( p(y|M) ) is the complexity of evaluating the query likelihood and d · N 3 is the complexity of evaluating the GP predictive posteriors for the simulated experiments. For the causal discovery and model learning utilities the complexity reduces to O(T BO · M · K outer · S · M · K inner · d · N 3 ).</p>
<p>In summary, the complexity of our ABCI implementation is dominated the experimental design phase from a high-level perspective. On a lower level, the cubic scaling of GP inference is the major computational issue that we alleviate by caching the (posterior) marginal log-likelihoods (see Appx. E.2 for details). However, in a small data regime where experimental data is costly to obtain, GPs are not a prohibitive element in our inference chain. Furthermore, GP scaling issues could be alleviated, e.g., by using sparse GP approximation or any other kind of scalable Bayesian mechanism model. Disregarding issues of GP scaling, the estimation of the information gain utilities is still costly, simply because it requires many levels of nested sampling and too few Monte-Carlo samples will yield too noisy, in the worst case unusable utility estimates. We believe that in follow-up work much can be gained in terms of scalability as well as performance by incorporating recent advances in nested Monte-Carlo/information gain estimation techniques(e.g., [8,28,63]).</p>
<p>Finally, consider that a single estimation of the causal discovery utility for an SCM with 20 nodes with N = 500 previously collected experimental samples takes approximately 2 minutes on an off-the-shelf laptop. Thus, for 10 BO iterations we can do the experimental design phase in 20 minutes (assuming we parallelize the utility optimization for each node). In a practical application scenario one might be very willing to invest hours or days for the design phase before conducting a costly experiment.</p>
<p>E.4 Implementation and Computing Resources</p>
<p>Our  [5] packages, which greatly eased our implementation efforts. All of our experiments were run on CPUs. We parallelise the experiment design by running the optimisation process for each candidate intervention set on a separate core.</p>
<p>F Evaluation Metrics</p>
<p>In this section, we provide details on the metrics used to evaluate our method in Section 5 and Appx. G.</p>
<p>In our experiments, we use (nested) Monte Carlo estimators to approximate intractable expectations.</p>
<p>Kullback-Leibler Divergence. We evaluate the inferred posterior over queries given observed data, p(Y | x 1:t ), to the true query distribution p(Y | M ) using the Kullback-Leibler Divergence (KLD), i.e.,
KL(p(Y | M )|| p(Y | x 1:t )) = E Y | M log p(Y | M ) − log p(Y | x 1:t ) (F.1) = E Y | M log p(Y | M ) − log E M | x 1:t [p(Y | M)] . (F.2) Query KLD. For Y = X do(X3=ψ) 5
with ψ ∼ p(ψ) we have
Query KLD = E ψ KL(p do(X3=ψ) (X 5 | M )|| p do(X3=ψ) (X 5 | x 1:t )) (F.3) = E ψ E X5 | do(X3=ψ),M log p do(X3=ψ) (X 5 | M ) − log p do(X3=ψ) (X 5 | x 1:t ) . (F.4)
To approximate the outer two expectations, we keep a fixed set of samples for each ground truth SCM to enhance comparability between different ABCI runs. For p do(X3=ψ) (X 5 | x 1:t ), we use the estimator described in Section D.1. Average Interventional KLD. Computing the KLD for Y = q CML (M) = M is not useful for evaluation, since it vanishes when the SCM posterior p(M | x 1:t ) collapses onto the true SCM M and is infinite otherwise. For this reason, we report the average interventional KLD as a proxy metric, which we define as
SCM KLD. For Y = q CML (M) = M, we have SCM KLD = KL(p(M | M )|| p(M | x 1:t )) (F.5) = E M | M log p(M | M ) − log p(M | x 1:t ) (F.6) = 0 − log p(M | x 1:t ) (F.7) = − log E M | x 1:t [p(M | M)] (F.8) = − log E G,f ,σ 2 | x 1:t p(G , f , σ 2, | G, f , σ 2 ) (F.9) = − log E G,f ,σ 2 | x 1:t p(G | G) p(f | f ) p(σ 2, | σ 2 ) .Avg. I-KLD = 1 d d i=1 E ψ KL(p do(Xi=ψ) (X | M )|| p do(Xi=ψ) (X | x 1:t )) (F.11) = 1 d d i=1 E ψ E X | do(Xi=ψ),M log p do(Xi=ψ) (X | M ) − log p do(Xi=ψ) (X | x 1:t ) (F.12) = 1 d d i=1 E ψ E X | do(Xi=ψ),M log p do(Xi=ψ) (X | M ) (F.13) − log E M | x 1:t p do(Xi=ψ) (X | M) .
As with the Query KLD, we keep a fixed set of MC samples per ground truth SCM to approximate the two outer expectations to enhance comparability between different ABCI runs.</p>
<p>Expected Structural Hamming Distance. The Structural Hamming Distance (SHD)
SHD(G, G ) = {(i, j) ∈ G : (i, j) ∈ G } + {(i, j) ∈ G : (i, j) ∈ G} (F.14)
denotes the simple graph edit distance, i.e., it counts the number of edges (i, j) that are present in the prediction graph G and not present in the reference graph G and vice versa. We report the expected SHD w.r.t. our posterior over graphs as ESHD(G, G ) = E G | x 1:t [SHD(G, G )] (F. 15) AUPRC. Following previous work [19, 21, 45, 78], we report the area under the precision recall curve (AUPRC) by casting graph learning as a binary edge prediction problem given our inferred posterior edge probabilities p(G i,j | x 1:t ). Refer to e.g. Murphy [52] for further information on this quantity. </p>
<p>G Extended Experimental Results</p>
<p>Causal Discovery and SCM Learning for SCMs with d = 10 Variables. We report results on ground truth SCMs with d = 10 variables and scale-free graphs in Fig. 5. We initialise all methods with 5 observational samples and perform experiments with a batch size of 3. All other parameters are chosen as described in Appx. D.</p>
<p>Causal Discovery and SCM Learning for SCMs with d = 20 Variables. To demonstrate the scalability of our framework, we report results on ground truth SCMs with d = 20 variables and scale-free or Erdős-Renyi graphs in Fig. 6 and Fig. 7, respectively. We initialise all methods with 50 observational samples and perform experiments with a batch size of 5. All other parameters are chosen as described in Appx. D.</p>
<p>While ABCI shows clear benefits when scale-free causal graphs underlie the SCMs, we find that the advantage of ABCI diminishes on SCMs with unstructured Erdős-Renyi graphs, which appear to pose a harder graph identification problem. Moreover, we expect performance of our inference machinery, especially together with the informed action selection, to increase when investing more computational power to improve the quality of our estimates, e.g., by increasing the number of Monte Carlo samples used in our estimators and increasing the number of evaluations during the Bayesian optimisation phase.</p>
<p>Finally, in Fig. 8 we show that using a simple linear model (GP model with a linear kernel) is not able to reasonably capture the characteristics of the ground truth model (non-linear GP model) due to the model mismatch.</p>
<p>Learning Interventional Distributions vs. Causal Discovery and SCM Learning. We report additional metrics for our causal reasoning experiment as described in § 5 in Figs. 9 and 10. The key result here is that U CR yields a significantly lower Query KLD while exhibiting a worse ESHD and Average I-KLD scores, which indicates that, indeed, the U CR learns only those parts of the model that are relevant to reducing the uncertainty in our target query. This is more data efficient than trying to learn the entire model first and then answering the causal query of interest.  Fig. 3 with additional confidence intervals for OBS and RAND FIXED.) Comparison of the experimental design strategy for causal discovery (UCD) with random and observational baselines on simulated ground truth models with 20 nodes. Lines and shaded areas show means and 95% confidence intervals (CIs) across 15 runs (5 randomly sampled ground-truth SCMs with 3 restarts per SCM). The UCD objective significantly outperforms the observational and random baselines on all metrics.  Figure 7: Causal Discovery and SCM Learning on Erdős-Renyi Graphs with 20 Variables. Comparison of experimental design strategies for causal discovery (UCD) and causal model learning (UCML) with random and observational baselines on simulated ground truth models with 20 nodes. Lines and shaded areas show means and 95% confidence intervals (CIs) across 15 runs (5 randomly sampled ground-truth SCMs with 3 restarts per SCM). The UCD and UCML strategies perform approx. equal to the strong random baseline (RAND) on all metrics, however, all three are significantly better than the weak random (RAND FIXED) and observational baselines. We expect that improving the quality of the UCD and UCML estimates (e.g., by scaling up computational resources invested in the MC estimates) yield similar benefits of the experimental design utilities as apparent in Fig. 6.  random and observational baselines. Lines and shaded areas show means and 95% confidence intervals (CIs) across 30 runs (10 randomly sampled ground-truth SCMs with 3 restarts per SCM). UCD, UCML and UCR perform best w.r.t. the ESHD, Avg. I-KLD and Query KLD metrics respectively, which is expected.</p>
<p>Figure 1 :
1x t ∼ p do(a t ) (X | M ) Overview of the Active Bayesian Causal Inference (ABCI) framework. At each time step t, we</p>
<p>(3.1), (ii) the types of interventions a t we consider at each step and the corresponding interventional likelihood in Eq. (3.4), (iii) our prior distribution p(M) over models, (iv) how to perform tractable inference of the model posterior in Eq. (3.2), and finally (v) how to maximise the information gain in Eq. (3.5) for experimental design.</p>
<p>Any model M in this model class can be parametrised as a triple M = (G, f , σ 2 ), where G is a causal DAG, f = (f 1 , . . . , f d ) is a vector of functions defined over the parent sets implied by G, and σ 2 = (σ 2 1 , . . . , σ 2 d ) contains the Gaussian noise variances. Provided that the f i are nonlinear and not constant in any of their arguments, the model is identifiable almost surely [37, 62].</p>
<p>Figure 3 :
3Causal Discovery and SCM Learning. Comparison of experimental design strategies for causal discovery (UCD) and causal model learning (UCML) with random and observational baselines on simulated ground truth models with 20 nodes. We initialise all methods with 50 observational samples, and then perform experiments with a batch size of Nt = 5. Lines and shaded areas show means and 95% confidence intervals (CIs) across 15 runs (5 randomly sampled ground-truth SCMs with 3 restarts per SCM). CIs for OBS and RAND FIXED baselines are not shown to aid readability; see Fig. 6 in Appx. G for the full figure. (a) ESHD. Both our objectives significantly outperform the observational and random baselines. (b) Average I-KLD. UCD significantly outperforms the baselines, whereas UCML performs only marginally better than RAND. (c) AUPRC. Both our strategies perform consistently better than the uninformed selection strategies.</p>
<p>Figure 4 :
4Learning Interventional Distributions. (left) Comparison of different methods w.r.t. learning a set of interventional distributions p do(X 3 =ψ) (X5 | M) with ψ ∼ U[2, 5] on simulated ground truth models with fixed causal graph (right). We initialise all methods with 5 observational samples, and then perform experiments with a batch size of Nt = 3. Lines and shaded areas show means and 95% confidence intervals (CIs) across 30 runs (10 randomly sampled ground truth SCMs with 3 restarts each). CIs for OBS and RAND FIXED baselines are not shown to aid readability; see Figs. 9 and 10 in Appx. G for the full figure. (a) All nodes actionable. UCR significantly outperforms all other methods as expected. UCML performs second best which, in conjunction with the results from Fig. 3, suggests that UCML yields a solid base model for performing downstream causal inference tasks. (b) X3 not actionable. In this setting, where we cannot directly intervene on the treatment variable of interest, UCR clearly outperforms all other methods for ≥ 10 experiments.</p>
<p>C 29 F
29(b) Did you describe the limitations of your work? [Yes] See discussion in § 6. (c) Did you discuss any potential negative societal impacts of your work? [N/A] (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] 2. If you are including theoretical results... (a) Did you state the full set of assumptions of all theoretical results? [Yes] We give a concise and rigorous treatment when formulating the general framework in § 3, as well as our approach and model specifics in § 4. (b) Did you include complete proofs of all theoretical results? [Yes] We provide the derivation of our utility functions in Appx. C. 3. If you ran experiments... (a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] Python code and instructions are provided in the supplement as source_code.zip (b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] We give a minimal set of details in § 5 and provide full information about our experiments in Appxs. D to F. (c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes] See Figs. 3 and 4 (d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] We give a brief summary in Appendix E. 4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... (a) If your work uses existing assets, did you cite the creators? [Yes] We do not use external models or data. We use a set of Python packages that we list in Appendix E. (b) Did you mention the license of the assets? [N/A] (c) Did you include any new assets either in the supplemental material or as a URL? [Yes] Our code base is available on Github at https://www.github.com/chritoth/active-bayesian-causalinference. We provide this link on the first page of the main paper and in Appx. E. (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A] (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A] 5. If you used crowdsourcing or conducted research with human subjects... (a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A] (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Derivation of the Information Gain Utility Functions 20 C.1 Information Gain for General Queries . . . . . . . . . . . . . . . . . . . . . . . 20 C.2 Derivation of the Causal Discovery Utility Function . . . . . . . . . . . . . . . 20 C.3 Derivation of the Causal Model Learning Utility Function . . . . . . . . . . . . 21 C.4 Derivation of the Causal Reasoning Utility Function . . . . . . . . . . . . . . . 23 D Approximate Inference and Experimental Details 24 D.1 Estimating Posterior Marginal Interventional Likelihoods . . . . . . . . . . . . 24 D.2 Sampling Ground Truth Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 24 D.3 Normal-Inverse-Gamma Prior for Root Nodes . . . . . . . . . . . . . . . . . . 25 D.4 Gamma Priors for GP Hyperparameters of Non-Root Nodes . . . . . . . . . . . 25 D.5 DiBS for Approximate Posterior Graph Inference . . . . . . . . . . . . . . . . . 25 D.6 Estimation of the Information Gain Utility Functions . . . . . . . . . . . . . . . 25 D.7 Bayesian Optimisation for Experimental Design . . . . . . . . . . . . . . . . . 26 E Implementation Details 27 E.1 Particle Resampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 E.2 Shared Priors and Caching of Marginal Likelihoods . . . . . . . . . . . . . . . 27 E.3 Computational Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 E.4 Implementation and Computing Resources . . . . . . . . . . . . . . . . . . . .</p>
<p>)
previously observed data x, let K † be the (Ñ × N ) covariance matrix with entries K † m,n = k RQ ( pa andK be the (Ñ ×Ñ ) covariance matrix with entriesK m,n = k RQ ( pa</p>
<p>Following von Kügelgen et al. [80], we employ Bayesian optimisation (BO) [46, 47] for this task and model our uncertainty in U (I, x) given previous evaluations D BO = {(x l , U (I, x l ))} k l=1 with a GP. We select a new candidate solution according to the GP-UCB acquisition function [76],</p>
<p>that p(G | G) = 1 if G = G and 0 otherwise, p(f | f ) = δ(f −f ), and p(σ 2, | σ 2 ) = δ(σ 2, − σ 2 ). Hence, the SCM KLD vanishes iff the SCM posterior p(M | x 1:t ) collapses onto the true SCM M , and is infinite otherwise.</p>
<p>Figure 5 :
5Causal Discovery and SCM Learning on Scale-free Graphs with 10 Variables. Comparison of the experimental design strategies with random and observational baselines on simulated ground truth models with 10 nodes. Lines and shaded areas show means and 95% confidence intervals (CIs) across 50 runs (10 randomly sampled ground-truth SCMs with 5 restarts per SCM). The UCD and UCML objectives perform on par with each other. Both clearly outperform the observational and random baselines on all metrics.</p>
<p>Figure 6 :
6Causal Discovery and SCM Learning on Scale-free Graphs with 20 Variables. (Same figure as in</p>
<p>Figure 8 :
8Causal Discovery and SCM Learning on Scale-free Graphs with 20 Variables. Comparison of non-linear GP model with a linear model (linear GP kernel) for UCD an RAND on simulated ground truth models with 20 nodes. Lines and shaded areas show means and 95% confidence intervals (CIs) across 15 runs (5 randomly sampled ground-truth SCMs with 3 restarts per SCM). Clearly, the model mismatch in the linear model prohibits the identification of the ground-truth graph.</p>
<p>Figure 9 :Figure 10 :
910Learning Interventional Distributions. Comparison of the experimental design strategies with random and observational baselines. Lines and shaded areas show means and 95% confidence intervals (CIs) across 30 runs (10 randomly sampled ground-truth SCMs with 3 restarts per SCM). UCD, UCML and UCR perform best w.r.t. the ESHD, Avg. I-KLD and Query KLD metrics respectively, which is expected. Learning Interventional Distributions. Comparison of the experimental design strategies with</p>
<p>Algorithm 1: GP-DiBS-ABCI for nonlinear additive Gaussian noise models Input: # of experiments T , batch sizes {N t } T t=1 , # of latent particles M , # of MC samples K, particle resampling schedule {r t } T t=1 , hyperparameter update schedule {s t } T Output: Posterior over target causal query p(Y | x 1:T )t=1 </p>
<p>, F. and Scheines, R. (2007). Interventions and causal inference. Philosophy of Science, 74(5):981-995. 10 [19] Ellis, B. and Wong, W. H. (2008). Learning causal bayesian network structures from experimental data. Journal of the American Statistical Association, 103(482):778-789. 31 [20] Erdös, P. and Rényi, A. (1959). On random graphs i. Ghassami, A., Salehkaleybar, S., Kiyavash, N., and Bareinboim, E. (2018). Budgeted Experiment Design for Causal Structure Learning. In Dy, J. and Krause, A., editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 1724-1733. PMLR. 2 [27] Glymour, C., Zhang, K., and Spirtes, P. (2019). Review of Causal Discovery Methods Based on Graphical Models. Frontiers in Genetics, 10. 2 Zhang, K. and Hyvärinen, A. (2009). On the identifiability of the post-nonlinear causal model. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, pages 647-655. AUAI Press. 1Publicationes Mathematicae Debrecen, 
6:290. 25 </p>
<p>[21] Friedman, N. and Koller, D. (2003). Being Bayesian about network structure. a Bayesian 
approach to structure discovery in Bayesian networks. Machine learning, 50(1):95-125. 2, 31 </p>
<p>[22] Friedman, N. and Nachman, I. (2000). Gaussian process networks. In Proceedings of the 
Sixteenth Conference on Uncertainty in Artificial Intelligence, pages 211-219. Morgan Kaufmann 
Publishers Inc. 2 </p>
<p>[23] Gamella, J. L. and Heinze-Deml, C. (2020). Active invariant causal prediction: Experiment 
selection through stability. Advances in Neural Information Processing Systems, 33:15464-15475. 
2 </p>
<p>[24] Gardner, J. R., Pleiss, G., Bindel, D., Weinberger, K. Q., and Wilson, A. G. (2018). Gpytorch: 
Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances in Neural 
Information Processing Systems. 29 </p>
<p>[25] George Casella, R. L. B. (2002). Statistical Inference, volume 2. Duxbury. 4 </p>
<p>[26] [28] Goda, T., Hironaka, T., and Iwamoto, T. (2020). Multilevel Monte Carlo estimation of expected 
information gains. Stochastic Analysis and Applications, 38. 28 </p>
<p>[29] Hagberg, A. A., Schult, D. A., and Swart, P. J. (2008). Exploring Network Structure, Dynamics, 
and Function using NetworkX. Proceedings of the 7th Python in Science Conference, pages 11-15. 
24, 29 </p>
<p>[30] Hauser, A. and Bühlmann, P. (2012). Characterization and greedy learning of interventional 
markov equivalence classes of directed acyclic graphs. The Journal of Machine Learning Research, 
13(1):2409-2464. 2 </p>
<p>[31] Hauser, A. and Bühlmann, P. (2014). Two optimal strategies for active learning of causal models 
from interventional data. International Journal of Approximate Reasoning, 55(4):926-939. 2 </p>
<p>[32] He, Y.-B. and Geng, Z. (2008). Active learning of causal networks with intervention experiments 
and optimal designs. Journal of Machine Learning Research, 9(Nov):2523-2547. 2 </p>
<p>[33] Heckerman, D. (1995). A Bayesian approach to learning causal networks. In Proceedings of the 
Eleventh Conference on Uncertainty in Artificial Intelligence, pages 285-295. Morgan Kaufmann 
Publishers Inc. 2 </p>
<p>[34] Heckman, J. J. (1992). Policy evaluation. Evaluating welfare and training programs, page 201. 
10 </p>
<p>[35] Heinze-Deml, C., Maathuis, M. H., and Meinshausen, N. (2018). Causal structure learning. 
Annual Review of Statistics and Its Application, 5:371-391. 2 </p>
<p>[36] Hernán, M. A. and Robins, J. M. (2020). Causal Inference: What If. Boca Raton: Chapman &amp; 
Hall/CRC. 1 
[37] Hoyer, P. O., Janzing, D., Mooij, J. M., Peters, J., and Schölkopf, B. (2009). Nonlinear causal 
discovery with additive noise models. In Advances in neural information processing systems, 
pages 689-696. 1, 2, 5 </p>
<p>[38] Hyttinen, A., Eberhardt, F., and Hoyer, P. O. (2013). Experiment selection for causal discovery. 
The Journal of Machine Learning Research, 14(1):3041-3071. 2 </p>
<p>[39] Imbens, G. W. and Rubin, D. B. (2015). Causal inference in statistics, social, and biomedical 
sciences. Cambridge University Press. 1 </p>
<p>[40] Jaber, A., Kocaoglu, M., Shanmugam, K., and Bareinboim, E. (2020). Causal discovery from 
soft interventions with unknown targets: Characterization and learning. Advances in neural 
information processing systems, 33:9551-9561. 2 </p>
<p>[41] Kalainathan, D., Goudet, O., and Dutta, R. (2020). Causal discovery toolbox: Uncovering 
causal relationships in python. Journal of Machine Learning Research, 21(37). 29 </p>
<p>[42] Lindley, D. V. et al. (1956). On a measure of the information provided by an experiment. The 
Annals of Mathematical Statistics, 27(4):986-1005. 2, 5 </p>
<p>[43] Lippe, P., Cohen, T., and Gavves, E. (2021). Efficient neural causal discovery without acyclicity 
constraints. In International Conference on Learning Representations. 2 </p>
<p>[44] Liu, Q. and Wang, D. (2016). Stein variational gradient descent: A general purpose Bayesian 
inference algorithm. In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R., editors, 
Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc. 7, 25 </p>
<p>[45] Lorch, L., Rothfuss, J., Schölkopf, B., and Krause, A. (2021). DiBS: Differentiable Bayesian 
Structure Learning. Advances in Neural Information Processing Systems, 34. 2, 7, 25, 31 </p>
<p>[46] Mockus, J. (1975). On Bayesian methods for seeking the extremum. In Optimization Techniques 
IFIP Technical Conference, pages 400-404. Springer. 2, 8, 26 </p>
<p>[47] Mockus, J. (2012). Bayesian Approach to Global Optimization: Theory and Applications, 
volume 37. Springer Science &amp; Business Media. 2, 8, 26 </p>
<p>[48] Mooij, J. M., Peters, J., Janzing, D., Zscheischler, J., and Schölkopf, B. (2016). Distinguishing 
cause from effect using observational data: methods and benchmarks. The Journal of Machine 
Learning Research, 17(1):1103-1204. 1 </p>
<p>[49] Morgan, S. L. and Winship, C. (2014). Counterfactuals and Causal Inference: Methods and 
Principles for Social Research. Cambridge University Press. 1 </p>
<p>[50] Murphy, K. P. (2001). Active learning of causal Bayes net structure. Technical report, Depart-
ment of Computer Science, U.C. Berkeley. 2, 18 </p>
<p>[51] Murphy, K. P. (2007). Conjugate Bayesian analysis of the gaussian distribution. Technical 
report, University of British Columbia. 6, 25 </p>
<p>[52] Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective. The MIT Press. 31 </p>
<p>[53] Ness, R. O., Sachs, K., Mallick, P., and Vitek, O. (2017). A Bayesian active learning exper-
imental design for inferring signaling networks. In International Conference on Research in 
Computational Molecular Biology, pages 134-156. Springer. 2, 10 </p>
<p>[54] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., 
Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., 
Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. (2019). Pytorch: An imperative 
style, high-performance deep learning library. In Wallach, H., Larochelle, H., Beygelzimer, A., 
d'Alché-Buc, F., Fox, E., and Garnett, R., editors, Advances in Neural Information Processing 
Systems 32, pages 8024-8035. Curran Associates, Inc. 29 </p>
<p>[55] Pearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4):669-688. 1 </p>
<p>[56] Pearl, J. (2009). Causality. Cambridge University Press, 2nd edition. 1, 2, 3, 4 
[74] Soch, J., Faulkenberry, Thomas Petrykowski, J., Allefeld, C., and McInerney, C. D. (2022). The 
Book of Statistical Proofs. Zenodo. 22 </p>
<p>[75] Spirtes, P., Glymour, C. N., and Scheines, R. (2000). Causation, prediction, and search. MIT 
press, 2nd edition. 1, 2, 5 </p>
<p>[76] Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. (2010). Gaussian process optimization 
in the bandit setting: No regret and experimental design. In International Conference on Machine 
Learning. 26 </p>
<p>[77] Sussex, S., Uhler, C., and Krause, A. (2021). Near-optimal multi-perturbation experimental 
design for causal structure learning. Advances in Neural Information Processing Systems, 34. 2 </p>
<p>[78] Tigas, P., Annadani, Y., Jesson, A., Schölkopf, B., Gal, Y., and Bauer, S. (2022). Inter-
ventions, Where and How? Experimental Design for Causal Models at Scale. arXiv preprint 
arXiv:2203.02016. 2, 3, 18, 31 </p>
<p>[79] Tong, S. and Koller, D. (2001). Active learning for structure in Bayesian networks. In 
International Joint Conference on Artificial Intelligence, volume 17, pages 863-869. 2, 18 </p>
<p>[80] von Kügelgen, J., Rubenstein, P. K., Schölkopf, B., and Weller, A. (2019). Optimal experimental 
design via Bayesian optimization: active causal structure learning for Gaussian process networks. 
In NeurIPS 2019 Workshop "Do the right thing": machine learning and causal inference for 
improved decision making. arXiv:1910.03962. 2, 8, 10, 26 </p>
<p>[81] Vowels, M. J., Camgoz, N. C., and Bowden, R. (2022). D'ya Like DAGs? A Survey on Structure 
Learning and Causal Discovery. ACM Computing Surveys. 2 </p>
<p>[82] Williams, C. K. and Rasmussen, C. E. (2006). Gaussian Processes for Machine Learning, 
volume 2. MIT Press Cambridge, MA. 2, 6, 7, 19 </p>
<p>[83] Wright, S. (1934). The method of path coefficients. The Annals of Mathematical Statistics, 
5(3):161-215. 1 </p>
<p>[84] Yang, K., Katcoff, A., and Uhler, C. (2018). Characterizing and learning equivalence classes 
of causal dags under interventions. In International Conference on Machine Learning, pages 
5541-5550. PMLR. 2 </p>
<p>[85] Zemplenyi, M. and Miller, J. W. (2022). Bayesian optimal experimental design for inferring 
causal structure. Bayesian Analysis, 1(1):1-28. 10 </p>
<p>[86] Checklist </p>
<ol>
<li>For all authors... 
(a) Do the main claims made in the abstract and introduction accurately reflect the paper's con-
tributions and scope? [Yes] </li>
</ol>
<p>Table 1 :
1Comparison of ABCI with closely related active Bayesian causal discovery methods in terms of the learning objective, that is, the causal target query, and the considered model class.Additive Gaussian noise with nonparametric functions f i modeled by GPsThe early experimental design work by Tong and Koller [79] and Murphy [50] already investigated active causal discovery from a Bayesian perspective. They focused on the case in which all variables are multinomial to allow for tractable, closed-form posterior inference with a conjugate Dirichlet prior.Work 
Target Query 
Model Class </p>
<p>Tong and Koller [79], 
Murphy [50] </p>
<p>causal graph G 
Conjugate Dirichlet-Multinomial </p>
<p>Cho et al. [11] 
causal graph G 
Conjugate linear Gaussian-inverse-Gamma </p>
<p>Agrawal et al. [1] 
some function φ(G) of the 
causal graph G </p>
<p>Linear Gaussian </p>
<p>Tigas et al. [78] 
causal graph G and param-
eters of f i </p>
<p>Additive Gaussian noise with parametric 
neural network functions f i </p>
<p>GP-DiBS-ABCI 
(ours) </p>
<p>some function q(M) of the 
full SCM M </p>
<p>Python implementation uses the PyTorch [54], GPyTorch [24], CDT [41], SKLearn [58], Net-workX [29] and BoTorch
Note that restricting to at = ∅ amounts to learning from observational data as a special case.5 In principle, the set of actionable variables might even change over time, in which case they are denoted Wt.
To avoid further complicating the notation, we write all posteriors and likelihoods in terms of the full data x 1:t . However, only observations of Xi and Xj | Pa G j matter for i ∈ R(G) and j ∈ NR(G).
20 30 40 50 60 70 80 90
Acknowledgments and Disclosure of FundingWe thank Paul K Rubenstein, Adrian Weller, and Bernhard Schölkopf for contributions to an early version of this work [80], and the anonymous reviewers for helpful feedback.Algorithm 2: Particle ResamplingInput: set of latent particles z = {z k } K k=1 Output: set of resampled latent particlesz = {z k } K k=1 z ← ∅ initialise set of resampled particles N max ← K 4 max. number of particles to keepE Implementation DetailsIn this section, we give details about our implementation, including our particle resampling procedure in Section E.1, the sharing and caching of priors in Section E.2, a discussion of the computational complexity of our implementation in Section E.3, and finally some information on our code framework and computing resources in Section E.4. Our implementation is available at https://www.github.com/chritoth/active-bayesian-causal-inference.E.1 Particle ResamplingAs described in Alg. 1, we resample latent particles z = {z k } K k=1 according to a predefined schedule instead of sampling new particles from the particle prior p(Z) after each epoch. Although sampling new particles would allow for higher diversity in the graph Monte Carlo samples and their respective mechanisms, it also entails a higher computational burden as the caching of mechanism marginal loglikelihoods is not as effective anymore. On the other hand, keeping a subset of the inferred particles is efficient, because once we have inferred a "good" particle z k that supposedly has a high posterior density p(z k | x 1:t ) it would be wasteful to discard the particle only to infer a similar particle again. Empirically, we found that keeping particles depending on their unnormalized posterior densities according to Alg. 2 does not diminish inference quality while increasing computational efficiency. In our experiments, we chose the following resampling schedule:E.2 Shared Priors and Caching of Marginal LikelihoodsWe share priors for mechanisms and noise p(f i , σ i | G), as well as for GP hyperparameters p(κ i | G), across all graphs G that induce the same parent set Pa G i . Consequently, not only the posteriors p(f i , σ i | G, x 1:t ) and p(κ i | G, x 1:t ), but also the GP marginal likelihoods p(x 1:t i | G) and GP predictive marginal likelihoods p(x t+1 i | G, x 1:t ) can be shared across graphs with identical parent sets for node X i . By caching the values of the computed GP (posterior) marginal likelihoods, we substantially save on computational cost when computing expectations of the form E G | z p(x 1:t | G) φ(G) and E G | z p(x t+1 | G, x 1:t ) φ(G) where φ(G) is some quantity depending the graph.Specifically, consider that p(x 1:t |G) = i p(x 1:t i |G) factorizes into the GP marginal likelihoods of the individual mechanisms, so for d nodes in the graph and N samples in x 1:t (counted over all time steps) the complexity of computing p(x 1:t |G) is O(d · N 3 ) for a fixed set of GP hyperparameters (for
ABCD-strategy: Budgeted experimental design for targeted causal structure discovery. R Agrawal, C Squires, K Yang, K Shanmugam, C Uhler, The 22nd International Conference on Artificial Intelligence and Statistics. 1018PMLR. 2, 3Agrawal, R., Squires, C., Yang, K., Shanmugam, K., and Uhler, C. (2019). ABCD-strategy: Budgeted experimental design for targeted causal structure discovery. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 3400-3409. PMLR. 2, 3, 10, 18</p>
<p>Minimal I-MAP MCMC for scalable structure discovery in causal DAG models. R Agrawal, C Uhler, T Broderick, PMLR. 2International Conference on Machine Learning. Agrawal, R., Uhler, C., and Broderick, T. (2018). Minimal I-MAP MCMC for scalable structure discovery in causal DAG models. In International Conference on Machine Learning, pages 89-98. PMLR. 2</p>
<p>J D Angrist, J.-S Pischke, Mostly Harmless Econometrics. Princeton University PressAngrist, J. D. and Pischke, J.-S. (2008). Mostly Harmless Econometrics. Princeton University Press. 1</p>
<p>Y Annadani, J Rothfuss, A Lacoste, N Scherrer, A Goyal, Y Bengio, S Bauer, arXiv:2106.07635.2Variational causal networks: Approximate bayesian inference over causal structures. arXiv preprintAnnadani, Y., Rothfuss, J., Lacoste, A., Scherrer, N., Goyal, A., Bengio, Y., and Bauer, S. (2021). Variational causal networks: Approximate bayesian inference over causal structures. arXiv preprint arXiv:2106.07635. 2</p>
<p>BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. M Balandat, B Karrer, D R Jiang, S Daulton, B Letham, A G Wilson, E Bakshy, Advances in Neural Information Processing Systems. 3329Balandat, M., Karrer, B., Jiang, D. R., Daulton, S., Letham, B., Wilson, A. G., and Bakshy, E. (2020). BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In Advances in Neural Information Processing Systems 33. 29</p>
<p>Emergence of scaling in random networks. A.-L Barabási, R Albert, Science. 286543924Barabási, A.-L. and Albert, R. (1999). Emergence of scaling in random networks. Science, 286(5439):509-512. 8, 24</p>
<p>Causal inference and the data-fusion problem. E Bareinboim, J Pearl, Proceedings of the National Academy of Sciences. 11327Bareinboim, E. and Pearl, J. (2016). Causal inference and the data-fusion problem. Proceedings of the National Academy of Sciences, 113(27):7345-7352. 10</p>
<p>Fast Bayesian experimental design: Laplace-based importance sampling for the expected information gain. J Beck, B M Dia, L F Espath, Q Long, R Tempone, Computer Methods in Applied Mechanics and Engineering. 33428Beck, J., Dia, B. M., Espath, L. F., Long, Q., and Tempone, R. (2018). Fast Bayesian experimental design: Laplace-based importance sampling for the expected information gain. Computer Methods in Applied Mechanics and Engineering, 334. 28</p>
<p>Differentiable Causal Discovery from Interventional Data. P Brouillard, S Lachapelle, A Lacoste, S Lacoste-Julien, A Drouin, H Larochelle, M Ranzato, R Hadsell, M F Balcan, Lin , H , Advances in Neural Information Processing Systems. Curran Associates, Inc33Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, S., and Drouin, A. (2020). Differ- entiable Causal Discovery from Interventional Data. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 21865-21877. Curran Associates, Inc. 2</p>
<p>Bayesian experimental design: A review. K Chaloner, I Verdinelli, Statistical Science. 25Chaloner, K. and Verdinelli, I. (1995). Bayesian experimental design: A review. Statistical Science, pages 273-304. 2, 5</p>
<p>Reconstructing causal biological networks through active learning. H Cho, B Berger, J Peng, e0150611. 2PloS one. 11318Cho, H., Berger, B., and Peng, J. (2016). Reconstructing causal biological networks through active learning. PloS one, 11(3):e0150611. 2, 10, 18</p>
<p>BCD nets: Scalable variational approaches for Bayesian causal discovery. C Cundy, A Grover, S Ermon, Advances in Neural Information Processing Systems. 34Cundy, C., Grover, A., and Ermon, S. (2021). BCD nets: Scalable variational approaches for Bayesian causal discovery. Advances in Neural Information Processing Systems, 34. 2</p>
<p>A comparison of structural distance measures for causal bayesian network models. Recent Advances in Intelligent Information Systems, Challenging Problems of Science. M De Jongh, M J Druzdzel, Computer Science series. 9de Jongh, M. and Druzdzel, M. J. (2009). A comparison of structural distance measures for causal bayesian network models. Recent Advances in Intelligent Information Systems, Challenging Problems of Science, Computer Science series, pages 443-456. 9</p>
<p>Bayesian structure learning with generative flow networks. T Deleu, A Góis, C C Emezue, M Rankawat, S Lacoste-Julien, S Bauer, Y Bengio, The 38th Conference on Uncertainty in Artificial Intelligence. 2Deleu, T., Góis, A., Emezue, C. C., Rankawat, M., Lacoste-Julien, S., Bauer, S., and Bengio, Y. (2022). Bayesian structure learning with generative flow networks. In The 38th Conference on Uncertainty in Artificial Intelligence. 2</p>
<p>Almost optimal intervention sets for causal discovery. F Eberhardt, Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence. the Twenty-Fourth Conference on Uncertainty in Artificial IntelligenceAUAI PressEberhardt, F. (2008). Almost optimal intervention sets for causal discovery. In Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence, pages 161-168. AUAI Press. 2</p>
<p>On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables. F Eberhardt, C Glymour, R Scheines, Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence. the 21st Conference on Uncertainty in Artificial Intelligence2Eberhardt, F., Glymour, C., and Scheines, R. (2005). On the number of experiments sufficient and in the worst case necessary to identify all causal relations among n variables. In Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence. 2</p>
<p>N-1 experiments suffice to determine the causal relations among n variables. F Eberhardt, C Glymour, R Scheines, Innovations in machine learning. SpringerEberhardt, F., Glymour, C., and Scheines, R. (2006). N-1 experiments suffice to determine the causal relations among n variables. In Innovations in machine learning, pages 97-112. Springer. 2</p>
<p>External validity: From do-calculus to transportability across populations. J Pearl, E Bareinboim, Statistical Science. 294Pearl, J. and Bareinboim, E. (2014). External validity: From do-calculus to transportability across populations. Statistical Science, 29(4):579-595. 10</p>
<p>Scikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, E Duchesnay, Journal of Machine Learning Research. 12Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830. 29</p>
<p>Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis. R Perry, J Von Kügelgen, B Schölkopf, Advances in Neural Information Processing Systems. 35Perry, R., von Kügelgen, J., and Schölkopf, B. (2022). Causal discovery in heterogeneous environments under the sparse mechanism shift hypothesis. Advances in Neural Information Processing Systems, 35. 2</p>
<p>Causal inference by using invariant prediction: identification and confidence intervals. J Peters, P Bühlmann, N Meinshausen, Journal of the Royal Statistical Society: Series B (Statistical Methodology). 785Peters, J., Bühlmann, P., and Meinshausen, N. (2016). Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947-1012. 2</p>
<p>Elements of Causal Inference -Foundations and Learning Algorithms. J Peters, D Janzing, B Schölkopf, The MIT PressCambridge, MA, USA. 1, 2, 6Adaptive Computation and Machine Learning SeriesPeters, J., Janzing, D., and Schölkopf, B. (2017). Elements of Causal Inference -Foundations and Learning Algorithms. Adaptive Computation and Machine Learning Series. The MIT Press, Cambridge, MA, USA. 1, 2, 6</p>
<p>Causal discovery with continuous additive noise models. J Peters, J M Mooij, D Janzing, B Schölkopf, The Journal of Machine Learning Research. 151Peters, J., Mooij, J. M., Janzing, D., and Schölkopf, B. (2014). Causal discovery with continuous additive noise models. The Journal of Machine Learning Research, 15(1):2009-2053. 5</p>
<p>On nesting Monte Carlo estimators. T Rainforth, R Cornish, H Yang, A Warrington, F Wood, 35th International Conference on Machine Learning. 1028Rainforth, T., Cornish, R., Yang, H., Warrington, A., and Wood, F. (2018). On nesting Monte Carlo estimators. 35th International Conference on Machine Learning, ICML 2018, 10. 28</p>
<p>A new approach to causal inference in mortality studies with a sustained exposure period-application to control of the healthy worker survivor effect. J Robins, Mathematical modelling. 79Robins, J. (1986). A new approach to causal inference in mortality studies with a sustained exposure period-application to control of the healthy worker survivor effect. Mathematical modelling, 7(9-12):1393-1512. 5</p>
<p>Counting labeled acyclic digraphs. New Directions in the Theory of Graphs. R W Robinson, Robinson, R. W. (1973). Counting labeled acyclic digraphs. New Directions in the Theory of Graphs, pages 239-273. 7</p>
<p>P K Rubenstein, I Tolstikhin, P Hennig, B Schölkopf, arXiv:1706.10234.3Probabilistic active learning of functions in structural causal models. arXiv preprintRubenstein, P. K., Tolstikhin, I., Hennig, P., and Schölkopf, B. (2017). Probabilistic active learning of functions in structural causal models. arXiv preprint arXiv:1706.10234. 3</p>
<p>Causal inference using potential outcomes: Design, modeling, decisions. D B Rubin, Journal of the American Statistical Association. 100469Rubin, D. B. (2005). Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469):322-331. 2</p>
<p>N Scherrer, O Bilaniuk, Y Annadani, A Goyal, P Schwab, B Schölkopf, M C Mozer, Y Bengio, S Bauer, N R Ke, arXiv:2109.02429.2Learning neural causal models with active interventions. arXiv preprintScherrer, N., Bilaniuk, O., Annadani, Y., Goyal, A., Schwab, P., Schölkopf, B., Mozer, M. C., Bengio, Y., Bauer, S., and Ke, N. R. (2021). Learning neural causal models with active interven- tions. arXiv preprint arXiv:2109.02429. 2</p>
<p>Estimating individual treatment effect: generalization bounds and algorithms. U Shalit, F D Johansson, D Sontag, PMLR. 2International Conference on Machine Learning. Shalit, U., Johansson, F. D., and Sontag, D. (2017). Estimating individual treatment effect: generalization bounds and algorithms. In International Conference on Machine Learning, pages 3076-3085. PMLR. 2</p>
<p>Learning Causal Graphs with Small Interventions. K Shanmugam, M Kocaoglu, A G Dimakis, S Vishwanath, N Lawrence, D Lee, M Sugiyama, R Garnett, Advances in Neural Information Processing Systems. Cortes, C.,Curran Associates, Inc2818Shanmugam, K., Kocaoglu, M., Dimakis, A. G., and Vishwanath, S. (2015). Learning Causal Graphs with Small Interventions. In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R., editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc. 2, 18</p>
<p>A linear non-gaussian acyclic model for causal discovery. S Shimizu, P O Hoyer, A Hyvärinen, A Kerminen, Jordan , M , Journal of Machine Learning Research. 710Shimizu, S., Hoyer, P. O., Hyvärinen, A., Kerminen, A., and Jordan, M. (2006). A linear non-gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10). 1, 2</p>
<p>Effects of treatment on the treated: Identification and generalization. I Shpitser, J Pearl, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI 2009. the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI 2009AUAI Press10Shpitser, I. and Pearl, J. (2009). Effects of treatment on the treated: Identification and general- ization. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI 2009, pages 514-521. AUAI Press. 10</p>
<p>Practical Bayesian optimization of machine learning algorithms. J Snoek, H Larochelle, R P Adams, Advances in neural information processing systems. 2Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, pages 2951-2959. 2, 8</p>            </div>
        </div>

    </div>
</body>
</html>