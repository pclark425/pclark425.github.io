<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2565 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2565</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2565</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-703035b483c181953de1b55b5fd59cd4cd4cf211</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/703035b483c181953de1b55b5fd59cd4cd4cf211" target="_blank">MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> MetaGPT is introduced, an innovative framework that incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration and leverages the assembly line paradigm to assign diverse roles to various agents, thereby establishing a framework that can effectively and cohesively deconstruct complex multi- agent collaborative problems.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2565.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2565.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-programming multi-agent framework that models a software company using specialized LLM-based agents following Standard Operating Procedures (SOPs), structured communications, and executable feedback to generate, run, debug and iteratively improve code.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MetaGPT is a meta-programming framework that composes multiple LLM-based agents into a simulated software company. Agents are instantiated with role profiles (name, goal, constraints, skills) and follow SOP-derived workflows to decompose user requests into PRDs, system designs, task lists, code artifacts, tests, and final deliverables. Communication is structured (documents, diagrams, and structured message schemas) and mediated via a global shared message pool with subscription-based access. An executable feedback loop allows engineers to run unit tests, capture runtime errors, consult memory/messages, and iteratively debug up to a configurable retry limit.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>5 (default roles: Product Manager, Architect, Project Manager, Engineer, QA Engineer) — variable depending on configuration</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Product Manager: requirement analysis, PRD generation, user stories, competitive analysis, web search; Architect: system/interface design, file lists, data structures, sequence diagrams; Project Manager: task decomposition and assignment; Engineer: code generation, execution, unit tests, debugging; QA Engineer: test-case generation and quality assurance. Each agent has a role profile with skills and constraints (e.g., Engineer can execute code).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Requirement analysis (PRD), system design, implementation (code generation), execution (unit test running / precompilation execution), evaluation (QA/tests), iterative debugging/refinement, and limited long-term self-improvement (handover summaries updating role constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Hierarchical/sequential SOP-driven pipeline (assembly-line paradigm): roles form a sequential workflow (Product Manager -> Architect -> Project Manager -> Engineers -> QA), coordinated via a centralized global message pool and publish-subscribe mechanism; agents follow React-style behavior to monitor messages and trigger actions when prerequisites are met.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Structured communication: agents publish structured documents (PRDs, system designs, interface specs, file lists, sequence diagrams) into a shared message pool; messages follow schemas/formats specific to roles rather than free-form chat. Agents subscribe to role-relevant messages based on profile interests and retrieve published structured outputs on-demand.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Executable feedback (runtime self-correction): Engineer agents write unit tests, execute code, obtain test results and runtime errors, consult historical execution/debugging memory and message pool, then iteratively debug up to a configured maximum retries (default: 3). Additionally, a handover feedback/self-improvement mechanism summarizes past project feedback into constraint-prompt updates for agents' long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand and event-driven: agents monitor the shared pool continuously but act after receiving prerequisite dependencies (effectively 'after each required step' in the SOP pipeline); publish-subscribe semantics means communications occur at phase transitions or when role-specific outputs are published.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development / automatic programming (benchmarked on code-generation tasks: HumanEval, MBPP) — generalizable meta-programming tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>HumanEval Pass@1 85.9% (with GPT-4 collaboration), MBPP Pass@1 87.7% (reported SoTA); SoftwareDev executability 3.75/4.0, running time 503 s (MetaGPT w/o feedback 503s, with feedback 541s in Table 1), token usage 31,255, total code lines 251.4, productivity 124.3 tokens per code line; human revision cost 0.83 edits on average.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against AutoGPT, LangChain (+REPL), AgentVerse, ChatDev and various LLM code models (AlphaCode, Incoder, CodeGeeX, CodeGen, CodeX, CodeT, PaLM, GPT-4). MetaGPT outperforms prior multi-agent frameworks on SoftwareDev metrics and achieves higher Pass@1 on HumanEval and MBPP relative to prior reported baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Structured SOPs + publish-subscribe + executable feedback reduce cascading hallucinations and idle chit-chat, improve code coherency and executability, and reduce human revision effort; quantitative gains include +4.2% Pass@1 (HumanEval) and +5.4% Pass@1 (MBPP) from adding executable feedback, higher executability (3.75 vs 2.25 ChatDev), lower human revision cost (0.83 vs 2.5 ChatDev), and improved productivity (124.3 tokens/line vs 248.9 for ChatDev).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Potential information overload if everything is published to all agents (mitigated via subscription); LLM hallucinations and cascading errors remain a risk (paper reports earlier versions overlooked errors), assistant repeated instructions and infinite message loops are known challenges in multi-agent systems; self-improvement currently limited to constraint updates (not yet applied to structured communication schemas).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Role ablation (Table 3): adding roles improves executability and reduces human revisions (e.g., Engineer-only: executability 1.0 with 10 revisions; adding Product, Architect, Project roles progressively improved executability up to 4.0 with 4 agents and reduced revisions to 2.5). Executable feedback ablation: including executable feedback yields +4.2% (HumanEval) and +5.4% (MBPP) Pass@1 improvements; improves executability from 3.67 to 3.75 and reduces human revision cost from 2.25 to 0.83 (Table 1 & text).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper suggests SOP-driven pipelines with role specialization and the executable feedback loop as effective configurations; ablation indicates multi-role teams (Product + Architect + Project + Engineer) produce best executability (4.0 in Table 3). Use of structured outputs + publish-subscribe and including executable feedback are recommended as optimal components.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2565.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDev (Communicative Agents for Software Development)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent role-play framework for software development that uses conversational agents to coordinate programming tasks; used as a comparative baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A multi-agent system where agents assume software development roles and interact (role-based conversations) to generate code. In the present paper ChatDev is used as a baseline for comparison on the SoftwareDev benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (role-based team in prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Role-based software development agents (prior work): likely Product-like, Engineer-like, QA-like agents (paper references role-play paradigm), exact specialization details are from the cited ChatDev work.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Software engineering phases via role-play communication (requirements, design, coding, review) as described in cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Dialogue-driven role-play (chat-based multi-agent communication) rather than structured document handovers (as described in this paper about ChatDev).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Unconstrained natural language dialogues between role agents (contrast: MetaGPT uses structured documents).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Non-executable code review/self-reflection (as used in prior chat-based frameworks); lacks MetaGPT's executable feedback mechanism (per authors' comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Continual dialogue/message exchanges as agents converse.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development / code generation (used as baseline in SoftwareDev experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported in MetaGPT comparison: ChatDev executability 2.25, running time 762 s, token usage 19,292, productivity 248.9 tokens/line, human revision cost 2.5 (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared directly to MetaGPT in SoftwareDev; ChatDev is outperformed by MetaGPT on executability, running time, code statistics, and human revision cost.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>ChatDev demonstrates multi-agent role-play can produce code, but less structured outputs lead to lower executability and higher revision cost relative to SOP-driven structured workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Tends to produce more unproductive collaboration and idle chit-chat; more prone to hallucinations and lower executability versus structured SOP-based coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2565.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autonomous multi-step agent framework built on LLMs for automating tasks via chains of actions and tool use; used as a baseline in this paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Auto-gpt</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An autonomous agent framework that chains LLM outputs into sequences of actions (planning, tool use, and iteration). In this paper it is included as a baseline for comparison on software development tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable / typically single autonomous agent orchestrating sub-actions (not structured as specialized team in the cited repo)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not explicitly role-specialized in the paper's comparison; AutoGPT typically operates as a goal-driven autonomous agent that decomposes tasks itself.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Task planning, decomposition, execution via tools; applied here as a baseline on software development tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Auto-chaining of actions by a single autonomous agent rather than a multi-role SOP pipeline (per MetaGPT's description and baseline usage).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>LLM prompt-response sequences and tool APIs, not structured multi-agent publish-subscribe.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iteration via repeated planning/execution cycles; not the same executable-feedback/unit-test loop described for MetaGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Sequential planning and action loops; on-demand per step.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous task automation and software development (baseline in this work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Included as a comparative baseline; MetaGPT reported to outperform general autonomous frameworks like AutoGPT on structured software engineering tasks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>AutoGPT demonstrates autonomous task decomposition and tool use but lacks SOP-structured multi-agent cooperation benefits according to authors.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Less structured role specialization and lack of SOPs can lead to inefficiencies and inconsistent intermediate outputs (as argued by the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2565.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LangChain</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LangChain</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A popular toolkit for building applications with LLMs, often employed to orchestrate chains of LLM calls and tool usage; used here with a Python REPL baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LangChain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LangChain (+ REPL)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A developer framework for composing LLMs, chains, and tools; in the paper it is used as a baseline combined with a Python REPL tool to emulate code generation workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>Not a multi-agent system per se; used as a tooling baseline (single orchestrator invoking tools/LLMs).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>N/A (tooling/orchestration rather than role-specialized agents in the paper's baseline usage).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Code generation and execution when configured with REPL tools; used for baseline comparisons on SoftwareDev tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Chain-of-call orchestration via a controlling program; not role-based multi-agent SOP pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>API/tool calls and prompt-response exchanges; not structured role documents/publish-subscribe.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Depends on how tool chains are constructed; not described as using MetaGPT's executable-feedback loop in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Sequential tool/chain calls as configured by developer.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development / code generation (baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used as a baseline; MetaGPT claims superiority for complex software engineering tasks due to SOPs and structured communication.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Flexible tool orchestration; widely used for prototyping LLM-based workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Lacks built-in SOP, role specialization, and structured publish-subscribe coordination described as beneficial in MetaGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2565.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentVerse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent platform for facilitating collaboration and exploring emergent behaviors among LLM-based agents; included as a baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A platform/framework that facilitates interaction among multiple agents to explore emergent behaviors; used in this paper as a comparative baseline for multi-agent collaboration performance.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (platform supports many agents; exact number dependent on experiments in cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>AgentVerse supports heterogeneous agent roles and skills as described in its own work; in this paper it is referenced as a baseline without detailed re-description.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General multi-agent collaboration tasks; used as baseline for software engineering comparisons in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Platform-level coordination enabling multi-agent interactions and emergent behaviors (details in the AgentVerse paper).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Agent-to-agent messages within the AgentVerse platform (not detailed here).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Platform-dependent interactions and iterations; not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Depends on AgentVerse experimental setup; not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-agent collaboration; used here as a baseline for software development tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Included in baseline list; MetaGPT claims broader functionality and better handling of software complexity compared to AgentVerse for this domain.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>AgentVerse demonstrates emergent multi-agent collaboration useful for exploration of behaviors; cited as relevant related work.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not detailed in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2565.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent simulation creating a 'town' of agents to study language interaction, social understanding, and collective memory; cited as an example of multi-agent LLM research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Generative Agents (Park et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A simulated environment of 25 agents (a 'town') designed to study emergent social behaviors, language interaction, collective memory and social understanding among LLM agents.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>25 (as reported in this paper's related work section)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Heterogeneous personas representing human-like roles with memory and social behaviors (details in Park et al., 2023).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Behavioral simulation, interactive language behaviors, social memory — not focused on software engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Open-world simulation where agents interact via language to produce collective memory and social behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language interactions and memory-based recall mechanisms (simulated dialogues).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Collective memory updates and interaction-driven behavior adjustments (per cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Continuous/dialogue-driven in-simulation interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Open-world human behavior simulation and social language interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Useful for studying emergent social phenomena, collective memory, and language-driven interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Noted as open-world simulation; not optimized for structured task-oriented engineering workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2565.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLSOM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Natural Language-Based Society of Mind (NLSOM) / Mindstorms in natural language-based societies of mind</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent approach where agents with different functions interact in rounds of 'mindstorms' to solve complex tasks; cited as related work motivating MetaGPT's SOP approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mindstorms in natural language-based societies of mind</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NLSOM (Natural Language-Based Society of Mind)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A society-of-minds style framework where heterogeneous agents interact through multiple rounds of brainstorming ('mindstorms') to collaboratively solve complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (societies of many specialized agents as per cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Functionally heterogeneous agents each with specialized roles contributing during iterative 'mindstorm' interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Complex problem-solving through iterative multi-agent reasoning and planning (idea generation and collaborative reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Iterative multi-round interactions ('mindstorms') among agents to converge on solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural language interactions across agents facilitating multi-round debate/brainstorming.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Multi-round discussion and consensus formation; details in cited NLSOM work.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Multiple rounds of interactions; iterative.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Complex task solving and collaborative reasoning; conceptual foundation for MetaGPT's multi-agent ideas.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrates how multiple specialized agents can interact iteratively to solve complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Open interaction dynamics may suffer from inconsistency/hallucination without structured SOPs (motivates MetaGPT's design).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2565.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting paradigm combining chain-of-thought reasoning with actions (tool calls) to produce reasoning traces and action plans; referenced as related work underlying agent behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReAct prompting paradigm</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ReAct instructs agents to produce interleaved reasoning traces (chain-of-thought) and actions, enabling LLM-based agents to plan and act; MetaGPT agents follow React-style behavior as described in Yao et al. (2022).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>N/A (prompting paradigm used by agents)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Used as an internal behavioral pattern (reasoning+action) for MetaGPT agents rather than a separate multi-agent system.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Reasoning and action planning during task execution.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Individual agent behavior pattern (interleaving thought and action) rather than multi-agent coordination per se.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Chain-of-thought style internal traces and tool calls; not a publish-subscribe multi-agent protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Provides intermediate reasoning/action traces which can be used for debugging and feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Interleaved within agent internal steps.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General reasoning and acting tasks; foundational technique for agent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Enables agents to plan and act coherently by exposing intermediate reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Chain-of-thought traces are susceptible to hallucination; MetaGPT mitigates with structured outputs and SOPs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2565.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion: An autonomous agent with dynamic memory and self-reflection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autonomous agent methodology that augments agents with dynamic memory and self-reflection to iteratively improve; cited as related work on self-improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: an autonomous agent with dynamic memory and self-reflection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Reflexion augments agents with the ability to reflect on past failures and maintain dynamic memory to self-improve behavior; referenced as related prior work informing MetaGPT's self-improvement design.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>N/A (single-agent self-reflection paradigm) as described in cited work</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not role-based in the referenced work; mechanism focuses on single-agent dynamic memory and reflection to improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Self-evaluation and iterative improvement of agent outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Self-reflection loops and dynamic memory updates (single-agent focus).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Internal memory and reflection prompts rather than inter-agent message pools.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Self-reflection-based correction using stored experiences and dynamic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Iteration-driven; invoked upon failures or periodically.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous agent tasks and self-improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Shows utility of reflection and memory for improving agent outputs; MetaGPT integrates related ideas in its handover feedback/self-improvement mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Limited to single-agent improvement; multi-agent coordination adds complexities addressed by MetaGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2565.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Voyager: An open-ended embodied agent with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embodied agent leveraging LLMs in a Minecraft sandbox to perform open-ended tasks and learn from interaction; cited as related work on long-lived agent teams/simulated environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Voyager: An open-ended embodied agent with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An LLM-driven embodied agent that interacts with a sandbox environment (Minecraft) to perform tasks and learn long-term skills; cited analogously to MetaGPT's simulated company concept.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>Single long-lived agent in cited work, though compared conceptually to simulated teams/towns.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Embodied agent roles and tool use for open-ended tasks in a simulated environment (details in cited Voyager paper).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Open-ended task execution, long-term learning and skill acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Environment-driven interactions and iterative learning within sandbox; not a multi-role SOP pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Tool calls and environment interactions rather than inter-agent structured message pools.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Environment feedback and iterative learning from interaction traces.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Continuous interaction with environment.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Embodied open-ended tasks (Minecraft sandbox); motivational example for long-lived agent teams.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrates long-term autonomous improvement and environment-driven learning.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Different focus from structured multi-agent SOP workflows; integration into team-based software workflows not explored here.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2565.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2565.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentStore</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentStore (DeepWisdom platform)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A platform (AgentStore) for creating, managing, and monetizing agents; integrates with MetaGPT to enable credit-assigned multi-agent economies and plug-and-play agent capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentStore (DeepWisdom)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A platform for hosting heterogeneous agents with listed services and costs; users and agents can purchase services, subscribe to agents, and upgrade capabilities. The paper positions AgentStore as compatible with MetaGPT and with credit-assignment multi-agent economy concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>platform supports many agents (variable, community-driven)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Marketplace of agents with varied skills, personalities and capabilities; developers can add new agents and services.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Agent provisioning, service composition, and collaborative execution of complex tasks when combined into teams (integration with MetaGPT).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Market-style credit assignment (Economy of Minds) and service purchase semantics; platform-driven composition rather than fixed SOPs.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>APIs for purchasing/using services, subscribing to agents; agents integrated under MetaGPT's communication protocols when used together.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Monetary/credit assignment to agents for contributions; upgrades and subscriptions enable iterative capability improvement (conceptual, per Appendix A).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand (service purchases, subscriptions) and usage-driven.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Agent development and deployment marketplace; supports collaborative multi-agent projects (including software development under MetaGPT).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Enables modular plug-and-play agent composition and credit assignment to manage contribution and incentivize specialized services.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Economic mechanisms and dynamic SOP adaptation introduce complexity; platform details are implementation-specific and not deeply evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MetaGPT: Meta Programming for Multi-Agent Collaborative Framework', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Mindstorms in natural language-based societies of mind <em>(Rating: 2)</em></li>
                <li>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents <em>(Rating: 2)</em></li>
                <li>React: Synergizing reasoning and acting in language models <em>(Rating: 2)</em></li>
                <li>Reflexion: an autonomous agent with dynamic memory and self-reflection <em>(Rating: 2)</em></li>
                <li>Voyager: An open-ended embodied agent with large language models <em>(Rating: 1)</em></li>
                <li>Communicative agents for software development <em>(Rating: 2)</em></li>
                <li>Auto-gpt <em>(Rating: 1)</em></li>
                <li>LangChain <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2565",
    "paper_id": "paper-703035b483c181953de1b55b5fd59cd4cd4cf211",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "MetaGPT",
            "name_full": "MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework",
            "brief_description": "A meta-programming multi-agent framework that models a software company using specialized LLM-based agents following Standard Operating Procedures (SOPs), structured communications, and executable feedback to generate, run, debug and iteratively improve code.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "MetaGPT",
            "system_description": "MetaGPT is a meta-programming framework that composes multiple LLM-based agents into a simulated software company. Agents are instantiated with role profiles (name, goal, constraints, skills) and follow SOP-derived workflows to decompose user requests into PRDs, system designs, task lists, code artifacts, tests, and final deliverables. Communication is structured (documents, diagrams, and structured message schemas) and mediated via a global shared message pool with subscription-based access. An executable feedback loop allows engineers to run unit tests, capture runtime errors, consult memory/messages, and iteratively debug up to a configurable retry limit.",
            "number_of_agents": "5 (default roles: Product Manager, Architect, Project Manager, Engineer, QA Engineer) — variable depending on configuration",
            "agent_specializations": "Product Manager: requirement analysis, PRD generation, user stories, competitive analysis, web search; Architect: system/interface design, file lists, data structures, sequence diagrams; Project Manager: task decomposition and assignment; Engineer: code generation, execution, unit tests, debugging; QA Engineer: test-case generation and quality assurance. Each agent has a role profile with skills and constraints (e.g., Engineer can execute code).",
            "research_phases_covered": "Requirement analysis (PRD), system design, implementation (code generation), execution (unit test running / precompilation execution), evaluation (QA/tests), iterative debugging/refinement, and limited long-term self-improvement (handover summaries updating role constraints).",
            "coordination_mechanism": "Hierarchical/sequential SOP-driven pipeline (assembly-line paradigm): roles form a sequential workflow (Product Manager -&gt; Architect -&gt; Project Manager -&gt; Engineers -&gt; QA), coordinated via a centralized global message pool and publish-subscribe mechanism; agents follow React-style behavior to monitor messages and trigger actions when prerequisites are met.",
            "communication_protocol": "Structured communication: agents publish structured documents (PRDs, system designs, interface specs, file lists, sequence diagrams) into a shared message pool; messages follow schemas/formats specific to roles rather than free-form chat. Agents subscribe to role-relevant messages based on profile interests and retrieve published structured outputs on-demand.",
            "feedback_mechanism": "Executable feedback (runtime self-correction): Engineer agents write unit tests, execute code, obtain test results and runtime errors, consult historical execution/debugging memory and message pool, then iteratively debug up to a configured maximum retries (default: 3). Additionally, a handover feedback/self-improvement mechanism summarizes past project feedback into constraint-prompt updates for agents' long-term memory.",
            "communication_frequency": "On-demand and event-driven: agents monitor the shared pool continuously but act after receiving prerequisite dependencies (effectively 'after each required step' in the SOP pipeline); publish-subscribe semantics means communications occur at phase transitions or when role-specific outputs are published.",
            "task_domain": "Software development / automatic programming (benchmarked on code-generation tasks: HumanEval, MBPP) — generalizable meta-programming tasks.",
            "performance_metrics": "HumanEval Pass@1 85.9% (with GPT-4 collaboration), MBPP Pass@1 87.7% (reported SoTA); SoftwareDev executability 3.75/4.0, running time 503 s (MetaGPT w/o feedback 503s, with feedback 541s in Table 1), token usage 31,255, total code lines 251.4, productivity 124.3 tokens per code line; human revision cost 0.83 edits on average.",
            "baseline_comparison": "Compared against AutoGPT, LangChain (+REPL), AgentVerse, ChatDev and various LLM code models (AlphaCode, Incoder, CodeGeeX, CodeGen, CodeX, CodeT, PaLM, GPT-4). MetaGPT outperforms prior multi-agent frameworks on SoftwareDev metrics and achieves higher Pass@1 on HumanEval and MBPP relative to prior reported baselines.",
            "coordination_benefits": "Structured SOPs + publish-subscribe + executable feedback reduce cascading hallucinations and idle chit-chat, improve code coherency and executability, and reduce human revision effort; quantitative gains include +4.2% Pass@1 (HumanEval) and +5.4% Pass@1 (MBPP) from adding executable feedback, higher executability (3.75 vs 2.25 ChatDev), lower human revision cost (0.83 vs 2.5 ChatDev), and improved productivity (124.3 tokens/line vs 248.9 for ChatDev).",
            "coordination_challenges": "Potential information overload if everything is published to all agents (mitigated via subscription); LLM hallucinations and cascading errors remain a risk (paper reports earlier versions overlooked errors), assistant repeated instructions and infinite message loops are known challenges in multi-agent systems; self-improvement currently limited to constraint updates (not yet applied to structured communication schemas).",
            "ablation_studies": "Role ablation (Table 3): adding roles improves executability and reduces human revisions (e.g., Engineer-only: executability 1.0 with 10 revisions; adding Product, Architect, Project roles progressively improved executability up to 4.0 with 4 agents and reduced revisions to 2.5). Executable feedback ablation: including executable feedback yields +4.2% (HumanEval) and +5.4% (MBPP) Pass@1 improvements; improves executability from 3.67 to 3.75 and reduces human revision cost from 2.25 to 0.83 (Table 1 & text).",
            "optimal_configurations": "Paper suggests SOP-driven pipelines with role specialization and the executable feedback loop as effective configurations; ablation indicates multi-role teams (Product + Architect + Project + Engineer) produce best executability (4.0 in Table 3). Use of structured outputs + publish-subscribe and including executable feedback are recommended as optimal components.",
            "uuid": "e2565.0",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatDev",
            "name_full": "ChatDev (Communicative Agents for Software Development)",
            "brief_description": "A multi-agent role-play framework for software development that uses conversational agents to coordinate programming tasks; used as a comparative baseline in this paper.",
            "citation_title": "Communicative agents for software development",
            "mention_or_use": "use",
            "system_name": "ChatDev",
            "system_description": "A multi-agent system where agents assume software development roles and interact (role-based conversations) to generate code. In the present paper ChatDev is used as a baseline for comparison on the SoftwareDev benchmark.",
            "number_of_agents": "variable (role-based team in prior work)",
            "agent_specializations": "Role-based software development agents (prior work): likely Product-like, Engineer-like, QA-like agents (paper references role-play paradigm), exact specialization details are from the cited ChatDev work.",
            "research_phases_covered": "Software engineering phases via role-play communication (requirements, design, coding, review) as described in cited work.",
            "coordination_mechanism": "Dialogue-driven role-play (chat-based multi-agent communication) rather than structured document handovers (as described in this paper about ChatDev).",
            "communication_protocol": "Unconstrained natural language dialogues between role agents (contrast: MetaGPT uses structured documents).",
            "feedback_mechanism": "Non-executable code review/self-reflection (as used in prior chat-based frameworks); lacks MetaGPT's executable feedback mechanism (per authors' comparison).",
            "communication_frequency": "Continual dialogue/message exchanges as agents converse.",
            "task_domain": "Software development / code generation (used as baseline in SoftwareDev experiments).",
            "performance_metrics": "Reported in MetaGPT comparison: ChatDev executability 2.25, running time 762 s, token usage 19,292, productivity 248.9 tokens/line, human revision cost 2.5 (Table 1).",
            "baseline_comparison": "Compared directly to MetaGPT in SoftwareDev; ChatDev is outperformed by MetaGPT on executability, running time, code statistics, and human revision cost.",
            "coordination_benefits": "ChatDev demonstrates multi-agent role-play can produce code, but less structured outputs lead to lower executability and higher revision cost relative to SOP-driven structured workflows.",
            "coordination_challenges": "Tends to produce more unproductive collaboration and idle chit-chat; more prone to hallucinations and lower executability versus structured SOP-based coordination.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.1",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "AutoGPT",
            "name_full": "Auto-GPT",
            "brief_description": "An autonomous multi-step agent framework built on LLMs for automating tasks via chains of actions and tool use; used as a baseline in this paper's comparisons.",
            "citation_title": "Auto-gpt",
            "mention_or_use": "use",
            "system_name": "AutoGPT",
            "system_description": "An autonomous agent framework that chains LLM outputs into sequences of actions (planning, tool use, and iteration). In this paper it is included as a baseline for comparison on software development tasks.",
            "number_of_agents": "variable / typically single autonomous agent orchestrating sub-actions (not structured as specialized team in the cited repo)",
            "agent_specializations": "Not explicitly role-specialized in the paper's comparison; AutoGPT typically operates as a goal-driven autonomous agent that decomposes tasks itself.",
            "research_phases_covered": "Task planning, decomposition, execution via tools; applied here as a baseline on software development tasks.",
            "coordination_mechanism": "Auto-chaining of actions by a single autonomous agent rather than a multi-role SOP pipeline (per MetaGPT's description and baseline usage).",
            "communication_protocol": "LLM prompt-response sequences and tool APIs, not structured multi-agent publish-subscribe.",
            "feedback_mechanism": "Iteration via repeated planning/execution cycles; not the same executable-feedback/unit-test loop described for MetaGPT.",
            "communication_frequency": "Sequential planning and action loops; on-demand per step.",
            "task_domain": "General autonomous task automation and software development (baseline in this work).",
            "performance_metrics": null,
            "baseline_comparison": "Included as a comparative baseline; MetaGPT reported to outperform general autonomous frameworks like AutoGPT on structured software engineering tasks in this paper.",
            "coordination_benefits": "AutoGPT demonstrates autonomous task decomposition and tool use but lacks SOP-structured multi-agent cooperation benefits according to authors.",
            "coordination_challenges": "Less structured role specialization and lack of SOPs can lead to inefficiencies and inconsistent intermediate outputs (as argued by the paper).",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.2",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "LangChain",
            "name_full": "LangChain",
            "brief_description": "A popular toolkit for building applications with LLMs, often employed to orchestrate chains of LLM calls and tool usage; used here with a Python REPL baseline in comparisons.",
            "citation_title": "LangChain",
            "mention_or_use": "use",
            "system_name": "LangChain (+ REPL)",
            "system_description": "A developer framework for composing LLMs, chains, and tools; in the paper it is used as a baseline combined with a Python REPL tool to emulate code generation workflows.",
            "number_of_agents": "Not a multi-agent system per se; used as a tooling baseline (single orchestrator invoking tools/LLMs).",
            "agent_specializations": "N/A (tooling/orchestration rather than role-specialized agents in the paper's baseline usage).",
            "research_phases_covered": "Code generation and execution when configured with REPL tools; used for baseline comparisons on SoftwareDev tasks.",
            "coordination_mechanism": "Chain-of-call orchestration via a controlling program; not role-based multi-agent SOP pipeline.",
            "communication_protocol": "API/tool calls and prompt-response exchanges; not structured role documents/publish-subscribe.",
            "feedback_mechanism": "Depends on how tool chains are constructed; not described as using MetaGPT's executable-feedback loop in the paper.",
            "communication_frequency": "Sequential tool/chain calls as configured by developer.",
            "task_domain": "Software development / code generation (baseline).",
            "performance_metrics": null,
            "baseline_comparison": "Used as a baseline; MetaGPT claims superiority for complex software engineering tasks due to SOPs and structured communication.",
            "coordination_benefits": "Flexible tool orchestration; widely used for prototyping LLM-based workflows.",
            "coordination_challenges": "Lacks built-in SOP, role specialization, and structured publish-subscribe coordination described as beneficial in MetaGPT.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.3",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "AgentVerse",
            "name_full": "AgentVerse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents",
            "brief_description": "A multi-agent platform for facilitating collaboration and exploring emergent behaviors among LLM-based agents; included as a baseline in comparisons.",
            "citation_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents",
            "mention_or_use": "use",
            "system_name": "AgentVerse",
            "system_description": "A platform/framework that facilitates interaction among multiple agents to explore emergent behaviors; used in this paper as a comparative baseline for multi-agent collaboration performance.",
            "number_of_agents": "variable (platform supports many agents; exact number dependent on experiments in cited work)",
            "agent_specializations": "AgentVerse supports heterogeneous agent roles and skills as described in its own work; in this paper it is referenced as a baseline without detailed re-description.",
            "research_phases_covered": "General multi-agent collaboration tasks; used as baseline for software engineering comparisons in this paper.",
            "coordination_mechanism": "Platform-level coordination enabling multi-agent interactions and emergent behaviors (details in the AgentVerse paper).",
            "communication_protocol": "Agent-to-agent messages within the AgentVerse platform (not detailed here).",
            "feedback_mechanism": "Platform-dependent interactions and iterations; not detailed in this paper.",
            "communication_frequency": "Depends on AgentVerse experimental setup; not specified in this paper.",
            "task_domain": "General multi-agent collaboration; used here as a baseline for software development tasks.",
            "performance_metrics": null,
            "baseline_comparison": "Included in baseline list; MetaGPT claims broader functionality and better handling of software complexity compared to AgentVerse for this domain.",
            "coordination_benefits": "AgentVerse demonstrates emergent multi-agent collaboration useful for exploration of behaviors; cited as relevant related work.",
            "coordination_challenges": "Not detailed in the present paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.4",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive simulacra of human behavior",
            "brief_description": "A multi-agent simulation creating a 'town' of agents to study language interaction, social understanding, and collective memory; cited as an example of multi-agent LLM research.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "system_name": "Generative Agents (Park et al., 2023)",
            "system_description": "A simulated environment of 25 agents (a 'town') designed to study emergent social behaviors, language interaction, collective memory and social understanding among LLM agents.",
            "number_of_agents": "25 (as reported in this paper's related work section)",
            "agent_specializations": "Heterogeneous personas representing human-like roles with memory and social behaviors (details in Park et al., 2023).",
            "research_phases_covered": "Behavioral simulation, interactive language behaviors, social memory — not focused on software engineering.",
            "coordination_mechanism": "Open-world simulation where agents interact via language to produce collective memory and social behaviors.",
            "communication_protocol": "Natural language interactions and memory-based recall mechanisms (simulated dialogues).",
            "feedback_mechanism": "Collective memory updates and interaction-driven behavior adjustments (per cited work).",
            "communication_frequency": "Continuous/dialogue-driven in-simulation interactions.",
            "task_domain": "Open-world human behavior simulation and social language interactions.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Useful for studying emergent social phenomena, collective memory, and language-driven interactions.",
            "coordination_challenges": "Noted as open-world simulation; not optimized for structured task-oriented engineering workflows.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.5",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "NLSOM",
            "name_full": "Natural Language-Based Society of Mind (NLSOM) / Mindstorms in natural language-based societies of mind",
            "brief_description": "A multi-agent approach where agents with different functions interact in rounds of 'mindstorms' to solve complex tasks; cited as related work motivating MetaGPT's SOP approach.",
            "citation_title": "Mindstorms in natural language-based societies of mind",
            "mention_or_use": "mention",
            "system_name": "NLSOM (Natural Language-Based Society of Mind)",
            "system_description": "A society-of-minds style framework where heterogeneous agents interact through multiple rounds of brainstorming ('mindstorms') to collaboratively solve complex tasks.",
            "number_of_agents": "variable (societies of many specialized agents as per cited work)",
            "agent_specializations": "Functionally heterogeneous agents each with specialized roles contributing during iterative 'mindstorm' interactions.",
            "research_phases_covered": "Complex problem-solving through iterative multi-agent reasoning and planning (idea generation and collaborative reasoning).",
            "coordination_mechanism": "Iterative multi-round interactions ('mindstorms') among agents to converge on solutions.",
            "communication_protocol": "Natural language interactions across agents facilitating multi-round debate/brainstorming.",
            "feedback_mechanism": "Multi-round discussion and consensus formation; details in cited NLSOM work.",
            "communication_frequency": "Multiple rounds of interactions; iterative.",
            "task_domain": "Complex task solving and collaborative reasoning; conceptual foundation for MetaGPT's multi-agent ideas.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Demonstrates how multiple specialized agents can interact iteratively to solve complex tasks.",
            "coordination_challenges": "Open interaction dynamics may suffer from inconsistency/hallucination without structured SOPs (motivates MetaGPT's design).",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.6",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ReAct",
            "name_full": "ReAct: Synergizing reasoning and acting in language models",
            "brief_description": "A prompting paradigm combining chain-of-thought reasoning with actions (tool calls) to produce reasoning traces and action plans; referenced as related work underlying agent behaviors.",
            "citation_title": "React: Synergizing reasoning and acting in language models",
            "mention_or_use": "mention",
            "system_name": "ReAct prompting paradigm",
            "system_description": "ReAct instructs agents to produce interleaved reasoning traces (chain-of-thought) and actions, enabling LLM-based agents to plan and act; MetaGPT agents follow React-style behavior as described in Yao et al. (2022).",
            "number_of_agents": "N/A (prompting paradigm used by agents)",
            "agent_specializations": "Used as an internal behavioral pattern (reasoning+action) for MetaGPT agents rather than a separate multi-agent system.",
            "research_phases_covered": "Reasoning and action planning during task execution.",
            "coordination_mechanism": "Individual agent behavior pattern (interleaving thought and action) rather than multi-agent coordination per se.",
            "communication_protocol": "Chain-of-thought style internal traces and tool calls; not a publish-subscribe multi-agent protocol.",
            "feedback_mechanism": "Provides intermediate reasoning/action traces which can be used for debugging and feedback.",
            "communication_frequency": "Interleaved within agent internal steps.",
            "task_domain": "General reasoning and acting tasks; foundational technique for agent behavior.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Enables agents to plan and act coherently by exposing intermediate reasoning steps.",
            "coordination_challenges": "Chain-of-thought traces are susceptible to hallucination; MetaGPT mitigates with structured outputs and SOPs.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.7",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion: An autonomous agent with dynamic memory and self-reflection",
            "brief_description": "An autonomous agent methodology that augments agents with dynamic memory and self-reflection to iteratively improve; cited as related work on self-improvement.",
            "citation_title": "Reflexion: an autonomous agent with dynamic memory and self-reflection",
            "mention_or_use": "mention",
            "system_name": "Reflexion",
            "system_description": "Reflexion augments agents with the ability to reflect on past failures and maintain dynamic memory to self-improve behavior; referenced as related prior work informing MetaGPT's self-improvement design.",
            "number_of_agents": "N/A (single-agent self-reflection paradigm) as described in cited work",
            "agent_specializations": "Not role-based in the referenced work; mechanism focuses on single-agent dynamic memory and reflection to improve performance.",
            "research_phases_covered": "Self-evaluation and iterative improvement of agent outputs.",
            "coordination_mechanism": "Self-reflection loops and dynamic memory updates (single-agent focus).",
            "communication_protocol": "Internal memory and reflection prompts rather than inter-agent message pools.",
            "feedback_mechanism": "Self-reflection-based correction using stored experiences and dynamic memory.",
            "communication_frequency": "Iteration-driven; invoked upon failures or periodically.",
            "task_domain": "General autonomous agent tasks and self-improvement.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Shows utility of reflection and memory for improving agent outputs; MetaGPT integrates related ideas in its handover feedback/self-improvement mechanism.",
            "coordination_challenges": "Limited to single-agent improvement; multi-agent coordination adds complexities addressed by MetaGPT.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.8",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Voyager",
            "name_full": "Voyager: An open-ended embodied agent with large language models",
            "brief_description": "An embodied agent leveraging LLMs in a Minecraft sandbox to perform open-ended tasks and learn from interaction; cited as related work on long-lived agent teams/simulated environments.",
            "citation_title": "Voyager: An open-ended embodied agent with large language models",
            "mention_or_use": "mention",
            "system_name": "Voyager",
            "system_description": "An LLM-driven embodied agent that interacts with a sandbox environment (Minecraft) to perform tasks and learn long-term skills; cited analogously to MetaGPT's simulated company concept.",
            "number_of_agents": "Single long-lived agent in cited work, though compared conceptually to simulated teams/towns.",
            "agent_specializations": "Embodied agent roles and tool use for open-ended tasks in a simulated environment (details in cited Voyager paper).",
            "research_phases_covered": "Open-ended task execution, long-term learning and skill acquisition.",
            "coordination_mechanism": "Environment-driven interactions and iterative learning within sandbox; not a multi-role SOP pipeline.",
            "communication_protocol": "Tool calls and environment interactions rather than inter-agent structured message pools.",
            "feedback_mechanism": "Environment feedback and iterative learning from interaction traces.",
            "communication_frequency": "Continuous interaction with environment.",
            "task_domain": "Embodied open-ended tasks (Minecraft sandbox); motivational example for long-lived agent teams.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Demonstrates long-term autonomous improvement and environment-driven learning.",
            "coordination_challenges": "Different focus from structured multi-agent SOP workflows; integration into team-based software workflows not explored here.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.9",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "AgentStore",
            "name_full": "AgentStore (DeepWisdom platform)",
            "brief_description": "A platform (AgentStore) for creating, managing, and monetizing agents; integrates with MetaGPT to enable credit-assigned multi-agent economies and plug-and-play agent capabilities.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AgentStore (DeepWisdom)",
            "system_description": "A platform for hosting heterogeneous agents with listed services and costs; users and agents can purchase services, subscribe to agents, and upgrade capabilities. The paper positions AgentStore as compatible with MetaGPT and with credit-assignment multi-agent economy concepts.",
            "number_of_agents": "platform supports many agents (variable, community-driven)",
            "agent_specializations": "Marketplace of agents with varied skills, personalities and capabilities; developers can add new agents and services.",
            "research_phases_covered": "Agent provisioning, service composition, and collaborative execution of complex tasks when combined into teams (integration with MetaGPT).",
            "coordination_mechanism": "Market-style credit assignment (Economy of Minds) and service purchase semantics; platform-driven composition rather than fixed SOPs.",
            "communication_protocol": "APIs for purchasing/using services, subscribing to agents; agents integrated under MetaGPT's communication protocols when used together.",
            "feedback_mechanism": "Monetary/credit assignment to agents for contributions; upgrades and subscriptions enable iterative capability improvement (conceptual, per Appendix A).",
            "communication_frequency": "On-demand (service purchases, subscriptions) and usage-driven.",
            "task_domain": "Agent development and deployment marketplace; supports collaborative multi-agent projects (including software development under MetaGPT).",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Enables modular plug-and-play agent composition and credit assignment to manage contribution and incentivize specialized services.",
            "coordination_challenges": "Economic mechanisms and dynamic SOP adaptation introduce complexity; platform details are implementation-specific and not deeply evaluated in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2565.10",
            "source_info": {
                "paper_title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "Mindstorms in natural language-based societies of mind",
            "rating": 2
        },
        {
            "paper_title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents",
            "rating": 2
        },
        {
            "paper_title": "React: Synergizing reasoning and acting in language models",
            "rating": 2
        },
        {
            "paper_title": "Reflexion: an autonomous agent with dynamic memory and self-reflection",
            "rating": 2
        },
        {
            "paper_title": "Voyager: An open-ended embodied agent with large language models",
            "rating": 1
        },
        {
            "paper_title": "Communicative agents for software development",
            "rating": 2
        },
        {
            "paper_title": "Auto-gpt",
            "rating": 1
        },
        {
            "paper_title": "LangChain",
            "rating": 1
        }
    ],
    "cost": 0.021241,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>MetagPT: Meta Programming for a Multi-Agent Collaborative Framework</h1>
<p>Sirui Hong ${ }^{1}$, Mingchen Zhuge ${ }^{2 *}$, Jiaqi Chen ${ }^{1}$, Xiawu Zheng ${ }^{3}$, Yuheng Cheng ${ }^{4}$, Ceyao Zhang ${ }^{4}$, Jinlin Wang ${ }^{1}$, Zili Wang, Steven Ka Shing Yau ${ }^{5}$, Zijuan Lin ${ }^{4}$, Liyang Zhou ${ }^{6}$, Chenyu Ran ${ }^{1}$, Lingfeng Xiao ${ }^{1,7}$, Chenglin Wu ${ }^{1}$ ，Jürgen Schmidhuber ${ }^{2,8}$<br>${ }^{1}$ DeepWisdom, ${ }^{2}$ AI Initiative, King Abdullah University of Science and Technology, ${ }^{3}$ Xiamen University, ${ }^{4}$ The Chinese University of Hong Kong, Shenzhen, ${ }^{5}$ Nanjing University, ${ }^{6}$ University of Pennsylvania, ${ }^{7}$ University of California, Berkeley, ${ }^{8}$ The Swiss AI Lab IDSIA/USI/SUPSI</p>
<h4>Abstract</h4>
<p>Remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Existing LLM-based multi-agent systems can already solve simple dialogue tasks. Solutions to more complex tasks, however, are complicated through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors. MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together. On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems. Our project can be found at https://github.com/geekan/MetaGPT.</p>
<h2>1 INTRODUCTION</h2>
<p>Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to enhance and replicate human workflows. In real-world applications, however, existing systems (Park et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023; Liang et al., 2023; Hao et al., 2023; Zhou et al., 2023b) tend to oversimplify the complexities. They struggle to achieve effective, coherent, and accurate problem-solving processes, particularly when there is a need for meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023a; Dong et al., 2023; Zhou et al., 2023a; Qian et al., 2023; Tang et al., 2023b; Hong et al., 2024).</p>
<p>Through extensive collaborative practice, humans have developed widely accepted Standardized Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco \&amp; Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coordination. Furthermore, SOPs outline the responsibilities of each team member, while establishing standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate execution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001; DeMarco \&amp; Lister, 2013; Wooldridge \&amp; Jennings, 1998). For instance, in a software company, Product Managers analyze competition and user needs to create Product Requirements Documents (PRDs) using a standardized structure, to guide the developmental process.</p>
<p>Inspired by such ideas, we design a promising GPT-based Meta-Programming framework called MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al., 2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The software development SOPs between MetaGPT and real-world human teams. In software engineering, SOPs promote collaboration among various roles. MetaGPT showcases its ability to decompose complex tasks into specific actionable procedures assigned to various roles (e.g., Product Manager, Architect, Engineer, etc.).
documents, design artifacts, flowcharts, and interface specifications. The use of intermediate structured outputs significantly increases the success rate of target code generation. Because it helps maintain consistency in communication, minimizing ambiguities and errors during collaboration. More graphically, in a company simulated by MetaGPT, all employees follow a strict and streamlined workflow, and all their handovers must comply with certain established standards. This reduces the risk of hallucinations caused by idle chatter between LLMs, particularly in role-playing frameworks, like: "Hi, hello and how are you?" - Alice (Product Manager); "Great! Have you had lunch?" - Bob (Architect).</p>
<p>Benefiting from SOPs, MetaGPT offers a promising approach to meta-programming. In this context, we adopt meta-programming ${ }^{1}$ as "programming to program", in contrast to the broader fields of meta learning and "learning to learn" (Schmidhuber, 1987; 1993a; Hochreiter et al., 2001; Schmidhuber, 2006; Finn et al., 2017).</p>
<p>This notion of meta-programming also encompasses earlier efforts like CodeBERT (Feng et al., 2020) and recent projects such as CodeLlama (Rozière et al., 2023) and WizardCoder (Luo et al., 2023). However, MetaGPT stands out as a unique solution that allows for efficient metaprogramming through a well-organized group of specialized agents. Each agent has a specific role and expertise, following some established standards. This allows for automatic requirement analysis, system design, code generation, modification, execution, and debugging during runtime, highlighting how agent-based techniques can enhance meta-programming.</p>
<p>To validate the design of MetaGPT, we use publicly available HumanEval (Chen et al., 2021a) and MBPP (Austin et al., 2021) for evaluations. Notably, in code generation benchmarks, MetaGPT achieves a new state-of-the-art (SoTA) with $85.9 \%$ and $87.7 \%$ in Pass@1. When compared to other popular frameworks for creating complex software projects, such as AutoGPT (Torantulino et al., 2023), LangChain (Chase, 2022), AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023). MetaGPT also stands out in handling higher levels of software complexity and offering extensive functionality. Remarkably, in our experimental evaluations, MetaGPT achieves a $100 \%$ task completion rate, demonstrating the robustness and efficiency (time and token costs) of our design.</p>
<p>We summarize our contributions as follows:</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<ul>
<li>We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on LLMs. It is highly convenient and flexible, with well-defined functions like role definition and message sharing, making it a useful platform for developing LLM-based multi-agent systems.</li>
<li>Our innovative integration of human-like SOPs throughout MetaGPT's design significantly enhances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore, we introduce a novel executive feedback mechanism that debugs and executes code during runtime, significantly elevating code generation quality (e.g., $5.4 \%$ absolute improvement on MBPP).</li>
<li>We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising meta-programming framework for developing LLM-based multi-agent systems.</li>
</ul>
<h1>2 Related Work</h1>
<p>Automatic Programming The roots of automatic programming reach back deep into the previous century. In 1969, Waldinger \&amp; Lee (1969) introduced "PROW," a system designed to accept program specifications written in predicate calculus, generate algorithms, and create LISP implementations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance automatic programming and identified potential methods to achieve it. Recent approaches use natural language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023a; Liu et al., 2023b; Tang et al., 2023a; Muennighoff et al., 2023). Automatic programming has grown into an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming development. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs. Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) and ToolLLM (Qin et al., 2023) can learn how to use external tools through simple APIs. The research most closely aligned with our work by Li et al. (2023) proposes a straightforward role-play framework for programming that involves communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved productivity, they have not fully tapped into effective workflows with structured output formats. This makes it harder to deal with complex software engineering issues.</p>
<p>LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained tremendous interest in both industry and academia (Wang et al., 2023b; Zhou et al., 2023b; Zhang et al., 2023b). Many works (Chen et al., 2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023; Tang et al., 2023b) have improved the problem-solving abilities of LLMs by integrating discussions among multiple agents. Stable-Alignment (Liu et al., 2023a) creates instruction datasets by deriving consensus on value judgments through interactions across a sandbox with LLM agents. Other works focus on sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a "town" of 25 agents to study language interaction, social understanding, and collective memory. In the Natural Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions interact to solve complex tasks through multiple rounds of "mindstorms." Cai et al. (2023) propose a model for cost reduction by combining large models as tool makers and small models as tool users.</p>
<p>Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al., 2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on openworld human behavior simulation, while MetaGPT aims to introduce human practice into multiagents frameworks. Besides, LLM-based agents face the challenges of "assistant repeated instruction" or "infinite loop of message" (Talebirad \&amp; Nadiri, 2023; Li et al., 2023). These challenges become more urgent in task-oriented collaborations, which require consistent and mutually beneficial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus on applying advanced concepts such as Standard Operating Procedures in software development to multi-agent frameworks.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: An example of the communication protocol (left) and iterative programming with executable feedback (right). Left: Agents use a shared message pool to publish structured messages. They can also subscribe to relevant messages based on their profiles. Right: After generating the initial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past messages stored in memory and compares them with the PRD, system design, and code files.</p>
<h1>3 MetaGPT: A Meta-Programming Framework</h1>
<p>MetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 provides an explanation of role specialization, workflow and structured communication in this framework, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2 presents a communication protocol that enhances role communication efficiency. We also implement structured communication interfaces and an effective publish-subscribe mechanism. These methods enable agents to obtain directional information from other roles and public information from the environment. Finally, we introduce executable feedback-a self-correction mechanism for further enhancing code generation quality during run-time in Sec. 3.3.</p>
<h3>3.1 Agents in Standard Operating Procedures</h3>
<p>Specialization of Roles Unambiguous role specialization enables the breakdown of complex work into smaller and more specific tasks. Solving complex tasks or problems often requires the collaboration of agents with diverse skills and expertise, each contributing specialized outputs tailored to specific issues.</p>
<p>In a software company, a Product Manager typically conducts business-oriented analysis and derives insights, while a software engineer is responsible for programming. We define five roles in our software company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as shown in Figure 1. In MetaGPT, we specify the agent's profile, which includes their name, profile, goal, and constraints for each role. We also initialize the specific context and skills for each role. For instance, a Product Manager can use web search tools, while an Engineer can execute code, as shown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).</p>
<p>Every agent monitors the environment (i.e., the message pool in MetaGPT) to spot important observations (e.g.., messages from other agents). These messages can either directly trigger actions or assist in finishing the job.</p>
<p>Workflow across Agents By defining the agents' roles and operational skills, we can establish basic workflows. In our work, we follow SOP in software development, which enables all agents to work in a sequential manner.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: A diagram showing the software development process in MetaGPT, emphasizing its significant dependence on SOPs. The more detailed demonstration can be found in Appendix B.</p>
<p>Specifically, as shown in Figure 1, upon obtaining user requirements, the Product Manager undertakes a thorough analysis, formulating a detailed PRD that includes User Stories and Requirement Pool. This serves as a preliminary functional breakdown. The structured PRD is then passed to the Architect, who translates the requirements into system design components, such as File Lists, Data Structures, and Interface Definitions. Once captured in the system design, the information is directed towards the Project Manager for task distribution. Engineers proceed to execute the designated classes and functions as outlined (detailed in Figure 2). In the following stage, the QA Engineer formulates test cases to enforce stringent code quality. In the final step, MetaGPT produces a meticulously crafted software solution. We provide a detailed schematic (Figure 3) and a concrete instance (Appendix B) of the SOP workflow in MetaGPT.</p>
<h1>3.2 COMMUNICATION PROTOCOL</h1>
<p>Structured Communication Interfaces Most current LLM-based multi-agent frameworks (Li et al., 2023; Zhuge et al., 2023; Zhang et al., 2023a; Park et al., 2023) utilize unconstrained natural language as a communication interface.</p>
<p>However, despite the versatility of natural language, a question arises: does pure natural language communication suffice for solving complex tasks? For example, in the telephone game (or Chinese</p>
<p>whispers) ${ }^{2}$, after several rounds of communication, the original information may be quite distorted. Inspired by human social structures, we propose using structured communication to formulate the communication of agents. We establish a schema and format for each role and request that individuals provide the necessary outputs based on their specific role and context.</p>
<p>As shown in Figure 3, the Architect agent generates two outputs: the system interface design and a sequence flow diagram. These contain system module design and interaction sequences, which serve as important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT communicate through documents and diagrams (structured outputs) rather than dialogue. These documents contain all necessary information, preventing irrelevant or missing content.</p>
<p>Publish-Subscribe Mechanism Sharing information is critical in collaboration. For instance, Architects and Engineers often need to reference PRDs. However, communicating this information each time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023; Zhang et al., 2023a), can complicate the communication topology, resulting in inefficiencies.</p>
<p>To address this challenge, a viable approach is to store information in a global message pool. As shown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange messages directly. These agents not only publish their structured messages in the pool but also access messages from other entities transparently. Any agent can directly retrieve required information from the shared pool, eliminating the need to inquire about other agents and await their responses. This enhances communication efficiency.</p>
<p>Sharing all information with every agent can lead to information overload. During task execution, an agent typically prefers to receive only task-related information and avoid distractions through irrelevant details. Effective management and dissemination of this information play a crucial role. We offer a simple and effective solution-subscription mechanism (in Figure 2 (left)). Instead of relying on dialogue, agents utilize role-specific interests to extract relevant information. They can select information to follow based on their role profiles. In practical implementations, an agent activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3, the Architect mainly focuses on PRDs provided by the Product Manager, while documents from roles such as the QA Engineer might be of lesser concern.</p>
<h1>3.3 ITERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK</h1>
<p>In daily programming tasks, the processes of debugging and optimization play important roles. However, existing methods often lack a self-correction mechanism, which leads to unsuccessful code generation. Previous work introduced non-executable code review and self-reflection (Zhao et al., 2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in ensuring code executability and runtime correctness.</p>
<p>Our first MetaGPT implementations overlooked certain errors during the review process, due to LLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we introduce an executable feedback mechanism to improve the code iteratively. More specifically, as shown in Figure 2, the Engineer is asked to write code based on the original product requirements and design.</p>
<p>This enables the Engineer to continuously improve code using its own historical execution and debugging memory. To obtain additional information, the Engineer writes and executes the corresponding unit test cases, and subsequently receives the test results. If satisfactory, additional development tasks are initiated. Otherwise the Engineer debugs the code before resuming programming. This iterative testing process continues until the test is passed or a maximum of 3 retries is reached.</p>
<h2>4 EXPERIMENTS</h2>
<h3>4.1 EXPERIMENTAL SETTING</h3>
<p>Datasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin et al., 2021), and a self-generated, more challenging software development benchmark named Soft-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>wareDev: (1) HumanEval includes 164 handwritten programming tasks. These tasks encompass function specifications, descriptions, reference codes, and tests. (2) MBPP consists of 427 Python tasks. These tasks cover core concepts and standard library features and include descriptions, reference codes, and automated tests. (3) Our SoftwareDev dataset is a collection of 70 representative examples of software development tasks, each with its own task prompt (see Table 8). These tasks have diverse scopes (See Figure 5), such as mini-games, image processing algorithms, data visualization. They offer a robust testbed for authentic development tasks. Contrary to previous datasets (Chen et al., 2021a; Austin et al., 2021), SoftwareDev focuses on the engineering aspects. In the comparisons, we randomly select seven representative tasks for evaluation.</p>
<p>Evaluation Metrics For HuamnEval and MBPP, we follow the unbiased version of Pass $@ k$ as presented by (Chen et al., 2021a; Dong et al., 2023), to evaluate the functional accuracy of the top-k generated codes: Pass $@ k=\mathbb{E}<em k="k">{\text {Problems }}\left[1-\frac{\left(\hat{c}</em>\right]$.}^{*}\right)}{\binom{k}{k}</p>
<p>For SoftwareDev, we prioritize practical use and evaluate performance through human evaluations (A, E) or statistical analysis (B, C, D): (A) Executability: this metric rates code from 1 (failure/nonfunctional) to 4 (flawless). ' 1 ' is for non-functional, ' 2 ' for runnable but imperfect, ' 3 ' for nearly perfect, and ' 4 ' for flawless code. (B) Cost: the cost evaluations here include the (1) running time, (2) token usage, and (3) expenses. (C) Code Statistics: this includes (1) code files, (2) lines of code per file, and (3) total code lines. (D) Productivity: basically, it is defined as the number of token usage divided by the number of lines of code, which refers to the consumption of tokens per code line. (E) Human Revision Cost: refers to times of manual code corrections, which tackle problems like package import errors, incorrect class names, or incomplete reference paths. Typically, each correction involves up to 3 lines of code.</p>
<p>Baselines We compare our method with recent domain-specific LLMs in the code generation field, including AlphaCode (Li et al., 2022), Incoder (Fried et al., 2022), CodeGeeX (Zheng et al., 2023), CodeGen (Nijkamp et al., 2023), CodeX (Chen et al., 2021a), and CodeT (Chen et al., 2022) and general domain LLMs such as PaLM (Chowdhery et al., 2022), and GPT-4 (OpenAI, 2023). Several results of baselines (such as Incoder, CodeGeeX) are provided by Dong et al. (2023). In HumanEval and MBPP, we slightly modified the prompts to align with response format requirements. These modifications aim to address format-specific issues (i.e., Python problems). With the SoftwareDev benchmark, we provide a comprehensive comparison between MetaGPT, AutoGPT (Torantulino et al., 2023), LangChain (Chase, 2022) with Python Read-Eval-Print Loop (REPL) tool ${ }^{3}$, AgentVerse (Chen et al., 2023), and ChatDev (Qian et al., 2023).</p>
<h1>4.2 MAIN RESULT</h1>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Pass rates on the MBPP and HumanEval with a single attempt.</p>
<p>Performance Figure 4 demonstrates that MetaGPT outperforms all preceding approaches in both HumanEval and MBPP benchmarks. When MetaGPT collaborates with GPT-4, it significantly improves the Pass $@ k$ in the HumanEval benchmark compared to GPT-4. It achieves $85.9 \%$ and $87.7 \%$</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Demo softwares developed by MetaGPT.
in these two public benchmarks. Moreover, as shown in Table 1, MetaGPT outperforms ChatDev on the challenging SoftwareDev dataset in nearly all metrics. For example, considering the executability, MetaGPT achieves a score of 3.75 , which is very close to 4 (flawless). Besides, it takes less time ( 503 seconds), clearly less than ChatDev. Considering the code statistic and the cost of human revision, it also significantly outperforms ChatDev. Although MetaGPT requires more tokens (24,613 or 31,255 compared to 19,292 ), it needs only $126.5 / 124.3$ tokens to generate one line of code. In contrast, ChatDev uses 248.9 tokens. These results highlight the benefits of SOPs in collaborations between multiple agents. Additionally, we demonstrate the autonomous software generation capabilities of MetaGPT through visualization samples (Figure 5). For additional experiments and analysis, please refer to Appendix C.</p>
<p>Table 1: The statistical analysis on SoftwareDev.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Statistical Index</th>
<th style="text-align: center;">ChatDev</th>
<th style="text-align: center;">MetaGPT w/o Feedback</th>
<th style="text-align: center;">MetaGPT</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">(A) Executability</td>
<td style="text-align: center;">2.25</td>
<td style="text-align: center;">3.67</td>
<td style="text-align: center;">$\mathbf{3 . 7 5}$</td>
</tr>
<tr>
<td style="text-align: left;">(B) Cost#1: Running Times (s)</td>
<td style="text-align: center;">762</td>
<td style="text-align: center;">$\mathbf{5 0 3}$</td>
<td style="text-align: center;">541</td>
</tr>
<tr>
<td style="text-align: left;">(B) Cost#2: Token Usage</td>
<td style="text-align: center;">$\mathbf{1 9 , 2 9 2}$</td>
<td style="text-align: center;">24,613</td>
<td style="text-align: center;">31,255</td>
</tr>
<tr>
<td style="text-align: left;">(C) Code Statistic#1: Code Files</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">4.6</td>
<td style="text-align: center;">$\mathbf{5 . 1}$</td>
</tr>
<tr>
<td style="text-align: left;">(C) Code Statistic#2: Lines of Code per File</td>
<td style="text-align: center;">40.8</td>
<td style="text-align: center;">42.3</td>
<td style="text-align: center;">$\mathbf{4 9 . 3}$</td>
</tr>
<tr>
<td style="text-align: left;">(C) Code Statistic#3: Total Code Lines</td>
<td style="text-align: center;">77.5</td>
<td style="text-align: center;">194.6</td>
<td style="text-align: center;">$\mathbf{2 5 1 . 4}$</td>
</tr>
<tr>
<td style="text-align: left;">(D) Productivity</td>
<td style="text-align: center;">248.9</td>
<td style="text-align: center;">126.5</td>
<td style="text-align: center;">$\mathbf{1 2 4 . 3}$</td>
</tr>
<tr>
<td style="text-align: left;">(E) Human Revision Cost</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">2.25</td>
<td style="text-align: center;">$\mathbf{0 . 8 3}$</td>
</tr>
</tbody>
</table>
<h1>4.3 CAPABILITIES ANALYSIS</h1>
<p>Compared to open-source baseline methods such as AutoGPT and autonomous agents such as AgentVerse and ChatDev, MetaGPT offers functions for software engineering tasks. As presented in Table 2, our framework encompasses a wide range of abilities to handle complex and specialized development tasks efficiently. Incorporating SOPs (e.g., role-play expertise, structured communication, streamlined workflow) can significantly improve code generation. Other baseline methods</p>
<p>Table 2: Comparison of capabilities for MetaGPT and other approaches. ' $\sqrt{ }$ ' indicates the presence of a specific feature in the corresponding framework, ' $\mathbb{K}$ ' its absence.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Framework Capabiliy</th>
<th style="text-align: center;">AutoGPT</th>
<th style="text-align: center;">LangChain</th>
<th style="text-align: center;">AgentVerse</th>
<th style="text-align: center;">ChatDev</th>
<th style="text-align: center;">MetaGPT</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PRD generation</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">Tenical design genenration</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">API interface generation</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">Code generation</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">Precompilation execution</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">Role-based task management</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">Code review</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
</tbody>
</table>
<p>Table 3: Ablation study on roles. ' $#$ ' denotes 'The number of', 'Product' denotes 'Product manager', and 'Project' denotes 'Project manager'. ' $\sqrt{ }$ ' indicates the addition of a specific role. 'Revisions' refers to 'Human Revision Cost'.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Engineer</th>
<th style="text-align: center;">Product</th>
<th style="text-align: center;">Architect</th>
<th style="text-align: center;">Project</th>
<th style="text-align: center;">#Agents</th>
<th style="text-align: center;">#Lines</th>
<th style="text-align: center;">Expense</th>
<th style="text-align: center;">Revisions</th>
<th style="text-align: center;">Executability</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">$\mathbf{\$ 0 . 9 1 5}$</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">1.0</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">112.0</td>
<td style="text-align: center;">$\$ 1.059$</td>
<td style="text-align: center;">6.5</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">143.0</td>
<td style="text-align: center;">$\$ 1.204$</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">2.5</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\mathbb{K}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">205.0</td>
<td style="text-align: center;">$\$ 1.251$</td>
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">191.0</td>
<td style="text-align: center;">$\$ 1.385$</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">4.0</td>
</tr>
</tbody>
</table>
<p>can easily integrate SOP-like designs to improve their performance, similar to injecting chain-ofthought (Wei et al., 2022) in LLMs.</p>
<h1>4.4 Ablation Study</h1>
<p>The Effectiveness of Roles To understand the impact of different roles on the final results, we perform two tasks that involve generating effective code and calculating average statistics. When we exclude certain roles, unworkable codes are generated. As indicated by Table 3, the addition of roles different from just the Engineer consistently improves both revisions and executability. While more roles slightly increase the expenses, the overall performance improves noticeably, demonstrating the effectiveness of the various roles.</p>
<p>The Effectiveness of Executable Feedback Mechanism As shown in Figure 4, adding executable feedback into MetaGPT leads to a significant improvement of $4.2 \%$ and $5.4 \%$ in Pass @1 on HumanEval and MBPP, respectively. Besides, Table 1 shows that the feedback mechanism improves feasibility ( 3.67 to 3.75 ) and reduces the cost of human revisions ( 2.25 to 0.83 ). These results illustrate how our designed feedback mechanism can produce higher-quality code. Additional quantitative results of MetaGPT and MetaGPT without executable feedback are shown in Table 4 and Table 9 .</p>
<h2>5 CONCLUSION</h2>
<p>This work introduces MetaGPT, a novel meta-programming framework that leverages SOPs to enhance the problem-solving capabilities of multi-agent systems based on Large Language Models (LLMs). MetaGPT models a group of agents as a simulated software company, analogous to simulated towns (Park et al., 2023) and the Minecraft Sandbox in Voyager (Wang et al., 2023a). MetaGPT leverages role specialization, workflow management, and efficient sharing mechanisms such as message pools and subscriptions, rendering it a flexible and portable platform for autonomous agents and multi-agent frameworks. It uses an executable feedback mechanism to enhance code generation quality during runtime. In extensive experiments, MetaGPT achieves state-of-the-art performance on multiple benchmarks. The successful integration of human-like SOPs inspires future research on human-inspired techniques for artificial multi-agent systems. We also view our work as an early attempt to regulate LLM-based multi-agent frameworks. See also the outlook (Appendix A).</p>
<h1>Acknowledgement</h1>
<p>We thank Sarah Salhi, the Executive Secretary of KAUST AI Initiative, and Yuhui Wang, Postdoctoral Fellow at the KAUST AI Initiative, for helping to polish some of the text. We would like to express our gratitude to Wenyi Wang, a PhD student at the KAUST AI Initiative, for providing comprehensive feedback on the paper and for helping to draft the outlook (Appendix A) with Mingchen. We also thank Zongze Xu, the vice president of DeepWisdom, for providing illustrative materials for AgentStore.</p>
<h2>Author Contributions</h2>
<p>Sirui Hong conducted most of the experiments and designed the executable feedback module. She also led the initial version of the write-up, supported by Ceyao Zhang, and also by Jinlin Wang and Zili Wang. Mingchen Zhuge designed the self-improvement module, discussed additional experiments, and led the current write-up. Jiaqi Chen helped with the MBPP experiments, outlined the methods section, and contributed to the current write-up. Xiawu Zheng provided valuable guidance, reviewed and edited the paper. Yuheng Cheng contributed to the evaluation metric design and HumanEval experiments. Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Lingfeng Xiao helped with the MBPP experiments and comparisons to open-source baseline methods. Chenyu Ran created most of the illustrative figures. Chenglin Wu is the CEO of DeepWisdom, initiated MetaGPT, made the most significant code contributions to it, and advised this project. Jürgen Schmidhuber, Director of the AI Initiative at KAUST and Scientific Director of IDSIA, advised this project and helped with the write-up.</p>
<h2>REFERENCES</h2>
<p>Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. Playing repeated games with large language models. arXiv preprint, 2023.</p>
<p>Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis with large language models, 2021.</p>
<p>Anton Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty, Daniel Fried, Andrew Goff, Jonathan Gray, Hengyuan Hu, et al. Human-level play in the game of diplomacy by combining language models with strategic reasoning. Science, 2022.</p>
<p>Robert Balzer. A 15 year perspective on automatic programming. TSE, 1985.
R.M. Belbin. Team Roles at Work. Routledge, 2012. URL https://books.google.co.uk/ books?id=MHIQBAAAQBAJ.</p>
<p>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as tool makers. arXiv preprint, 2023.</p>
<p>Harrison Chase. LangChain. https://github.com/hwchase17/langchain, 2022.
Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen. Codet: Code generation with generated tests, 2022.</p>
<p>Jiaqi Chen, Yuxian Jiang, Jiachen Lu, and Li Zhang. S-agents: self-organizing agents in open-ended environment. arXiv preprint, 2024.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code, 2021a.</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents, 2023.</p>
<p>Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In ICLR, 2018.</p>
<p>Xinyun Chen, Dawn Song, and Yuandong Tian. Latent execution for neural program synthesis beyond domain-specific languages. NeurIPS, 2021b.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.
T. DeMarco and T.R. Lister. Peopleware: Productive Projects and Teams. Addison-Wesley, 2013. URL https://books.google.co.uk/books?id=DVlsAQAAQBAJ.</p>
<p>Yihong Dong, Xue Jiang, Zhi Jin, and Ge Li. Self-collaboration code generation via chatgpt. arXiv preprint, 2023.</p>
<p>Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate, 2023.</p>
<p>Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze, and Yoav Goldberg. Measuring and improving consistency in pretrained language models. TACL, 2021.</p>
<p>Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. Codebert: A pre-trained model for programming and natural languages. arXiv preprint, 2020.</p>
<p>Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktäschel. Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint, 2023.</p>
<p>Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In ICML, 2017.</p>
<p>Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling and synthesis. arXiv preprint, 2022.</p>
<p>Irving John Good. Speculations concerning the first ultraintelligent machine. Adv. Comput., 1965.
Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network: More brains, more intelligence. arXiv preprint, 2023.
S. Hochreiter, A. S. Younger, and P. R. Conwell. Learning to learn using gradient descent. In Lecture Notes on Comp. Sci. 2130, Proc. Intl. Conf. on Artificial Neural Networks (ICANN-2001), pp. 8794. Springer: Berlin, Heidelberg, 2001.</p>
<p>Sirui Hong, Yizhang Lin, Bangbang Liu, Binhao Wu, Danyang Li, Jiaqi Chen, Jiayi Zhang, Jinlin Wang, Lingyao Zhang, Mingchen Zhuge, et al. Data interpreter: An llm agent for data science. arXiv preprint arXiv:2402.18679, 2024.</p>
<p>Xue Jiang, Yihong Dong, Lecheng Wang, Qiwei Shang, and Ge Li. Self-planning code generation with large language model. arXiv preprint, 2023.</p>
<p>Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for" mind" exploration of large scale language model society. arXiv preprint, 2023.</p>
<p>Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. Science, 2022.</p>
<p>Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. Encouraging divergent thinking in large language models through multiagent debate. arXiv preprint, 2023.</p>
<p>Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks. arXiv preprint, 2023.</p>
<p>Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, and Soroush Vosoughi. Training socially aligned language models in simulated human society. arXiv preprint, 2023a.</p>
<p>Yuliang Liu, Xiangru Tang, Zefan Cai, Junjie Lu, Yichi Zhang, Yanjun Shao, Zexuan Deng, Helan Hu, Zengxian Yang, Kaikai An, et al. Ml-bench: Large language models leverage open-source libraries for machine learning tasks. arXiv preprint arXiv:2311.09835, 2023b.</p>
<p>Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint, 2023.</p>
<p>Potsawee Manakul, Adian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. arXiv preprint, 2023.</p>
<p>Agile Manifesto. Manifesto for agile software development. Snowbird, UT, 2001.
John McCarthy. History of lisp. In History of programming languages. 1978.
Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, and Shayne Longpre. Octopack: Instruction tuning code large language models. arXiv preprint arXiv:2308.07124, 2023.</p>
<p>Ansong Ni, Srini Iyer, Dragomir Radev, Veselin Stoyanov, Wen-tau Yih, Sida Wang, and Xi Victoria Lin. Lever: Learning to verify language-to-code generation with execution. In ICML, 2023.</p>
<p>Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis, 2023.</p>
<p>OpenAI. Gpt-4 technical report, 2023.
Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint, 2023.</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development, 2023.</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023.</p>
<p>Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. Code llama: Open foundation models for code. arXiv preprint, 2023.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint, 2023.
J. Schmidhuber. A self-referential weight matrix. In Proceedings of the International Conference on Artificial Neural Networks, Amsterdam, pp. 446-451. Springer, 1993a.
J. Schmidhuber. Gödel machines: self-referential universal problem solvers making provably optimal self-improvements. Technical Report IDSIA-19-03, arXiv:cs.LO/0309048 v3, IDSIA, Manno-Lugano, Switzerland, December 2003.
J. Schmidhuber. Gödel machines: Fully self-referential optimal universal self-improvers. In B. Goertzel and C. Pennachin (eds.), Artificial General Intelligence, pp. 199-226. Springer Verlag, 2006. Variant available as arXiv:cs.LO/0309048.
J. Schmidhuber. Ultimate cognition à la Gödel. Cognitive Computation, 1(2):177-193, 2009.</p>
<p>Jürgen Schmidhuber. Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook. PhD thesis, 1987.</p>
<p>Jürgen Schmidhuber. A 'self-referential'weight matrix. In ICANN'93: Proceedings of the International Conference on Artificial Neural Networks Amsterdam, The Netherlands 13-16 September 1993 3, 1993b.</p>
<p>Jürgen Schmidhuber. On learning to think: Algorithmic information theory for novel combinations of reinforcement learning controllers and recurrent neural world models. arXiv preprint, 2015.</p>
<p>Jürgen Schmidhuber, Jieyu Zhao, and Nicol N Schraudolph. Reinforcement learning with selfmodifying policies. In Learning to learn. 1998.</p>
<p>Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint, 2023.</p>
<p>Marta Skreta, Naruki Yoshikawa, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Kourosh Darvish, Alán Aspuru-Guzik, Florian Shkurti, and Animesh Garg. Errors are useful prompts: Instruction guided task programming with verifier-assisted iterative prompting. arXiv preprint, 2023.</p>
<p>Elliot Soloway. Learning to program $=$ learning to construct mechanisms and explanations. Communications of the ACM, 1986.</p>
<p>Yashar Talebirad and Amirhossein Nadiri. Multi-agent collaboration: Harnessing the power of intelligent llm agents, 2023.</p>
<p>Xiangru Tang, Bill Qian, Rick Gao, Jiakang Chen, Xinyun Chen, and Mark Gerstein. Biocoder: A benchmark for bioinformatics code generation with contextual pragmatic knowledge. arXiv preprint arXiv:2308.16458, 2023a.</p>
<p>Xiangru Tang, Anni Zou, Zhuosheng Zhang, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. Medagents: Large language models as collaborators for zero-shot medical reasoning. arXiv preprint arXiv:2311.10537, 2023b.</p>
<p>Torantulino et al. Auto-gpt. https://github.com/Significant-Gravitas/ Auto-GPT, 2023.
R. J. Waldinger and R. C. T. Lee. PROW: a step toward automatic program writing. In D. E. Walker and L. M. Norton (eds.), Proceedings of the 1st International Joint Conference on Artificial Intelligence (IJCAI), 1969.</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint, 2023a.</p>
<p>Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents. arXiv preprint, 2023b.</p>
<p>Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint, 2022.</p>
<p>Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration. arXiv preprint, 2023c.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS, 2022.</p>
<p>Michael Wooldridge and Nicholas R. Jennings. Pitfalls of agent-oriented development. In Proceedings of the Second International Conference on Autonomous Agents, 1998. URL https: //doi.org/10.1145/280765.280867.</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint, 2022.</p>
<p>Eric Zelikman, Eliana Lorch, Lester Mackey, and Adam Tauman Kalai. Self-taught optimizer (stop): Recursively self-improving code generation. arXiv preprint, 2023.</p>
<p>Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language models. arXiv preprint, 2023a.</p>
<p>Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, et al. Igniting language intelligence: The hitchhiker's guide from chain-of-thought reasoning to language agents. arXiv preprint arXiv:2311.11797, 2023b.</p>
<p>Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, and Stefan Wermter. Chat with the environment: Interactive multimodal perception using large language models. arXiv preprint, 2023.</p>
<p>Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x, 2023.</p>
<p>Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building autonomous agents. arXiv preprint, 2023a.</p>
<p>Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, et al. Agents: An open-source framework for autonomous language agents. arXiv preprint arXiv:2309.07870, 2023b.</p>
<p>Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R Ashley, Róbert Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader Hammoud, Vincent Herrmann, Kazuki Irie, et al. Mindstorms in natural language-based societies of mind. arXiv preprint, 2023.</p>
<h1>A OUTLOOK</h1>
<h2>A. 1 SELF-IMPROVEMENT MECHANISMS</h2>
<p>One limitation of the MetaGPT version in the main text of this paper is that each software project is executed independently. However, through active teamwork, a software development team should learn from the experience gained by developing each project, thus becoming more compatible and successful over time.</p>
<p>This is somewhat related to the idea of recursive self-improvement, first informally proposed in 1965 (Good, 1965), with first concrete implementations since 1987 (Schmidhuber, 1987; 1993b; Schmidhuber et al., 1998), culminating in the concept of mathematically optimal self-referential self-improvers (Schmidhuber, 2003; 2009). Generally speaking, a system should learn from experience in the real world, and meta-learn better learning algorithms from experiences of learning, and meta-meta-learn better meta-learning algorithms from experiences of meta-learning, etc., without any limitations except those of computability and physics.</p>
<p>More recent, somewhat related work leverages the reasoning ability of Large Language Models (LLMs) and recursively improves prompts of LLMs, to improve performance on certain downstream tasks (Fernando et al., 2023; Zelikman et al., 2023), analogous to the adaptive prompt engineer of 2015 (Schmidhuber, 2015) where one neural network learns to generate sequence of queries or prompts for another pre-trained neural network whose answers may help the first network to learn new tasks more quickly.</p>
<p>In our present work, we also explore a self-referential mechanism that recursively modifies the constraint prompts of agents based on information they observe during software development. Our initial implementation works as follows. Prior to each project, every agent in the software company reviews previous feedback and makes necessary adjustments to their constraint prompts. This enables them to continuously learn from past project experiences and enhance the overall multi-agent system by improving each individual in the company. We first establish a handover feedback action for each agent. This action is responsible for critically summarizing the information received during the development of previous projects and integrating this information in an updated constraint prompt. The summarized information is stored in long-term memory such that it can be inherited by future constraint prompt updates. When initiating a new project, each agent starts with a react action. Each agent evaluates the received feedback and summarizes how they can improve in a constraint prompt.</p>
<p>One current limitation is that these summary-based optimizations only modify constraints in the specialization of roles (Sec. 3.1) rather than structured communication interfaces in communication protocols (Sec. 3.2). Future advancements are yet to be explored.</p>
<h2>A. 2 Multi-Agent Economies</h2>
<p>In real-world teamwork, the interaction processes are often not hardcoded. For example, in a software company, the collaboration SOP may change dynamically.
One implementation of such self-organization is discussed in the paper on a "Natural LanguageBased Society of Mind" (NLSOM) (Zhuge et al., 2023), which introduced the idea of an "Economy of Minds" (EOM), a Reinforcement Learning (RL) framework for societies of LLMs and other agents. Instead of using standard RL techniques to optimize the total reward of the system through modifications of neural network parameters, EOMs use the principles of supply and demand in free markets to assign credit (money) to those agents that contribute to economic success (reward).</p>
<p>The recent agent-based platform of DeepWisdom (AgentStore ${ }^{4}$ ) is compatible with the credit assignment concept of EOMs. Each agent in AgentStore provides a list of services with corresponding costs. A convenient API is provided so that human users or agents in the platform can easily purchase services from other agents to accomplish their services. Figure 6 displays the User Interface (UI) of AgentStore, where various agents with different skills are showcased. Besides, individual developers can participate in building new agents and enable collaborative development within the community. Specifically, AgentStore allows users to subscribe to agents according to their demands</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>and pay according to their usage. Moreover, users can purchase additional capabilities to expand the plug-and-play functions of their existing agents. This allows users to gradually upgrade their agents. Within the MetaGPT framework, AgentStore can support the collaboration of various agents. Users can collect several agents together to carry out more complex tasks or projects, and all the agents share and comply with development and communication protocols defined in MetaGPT.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: AgentStore is a platform dedicated to serving users in the creation and development of agents within the MetaGPT framework. This platform provides users with an operational interface, allowing users to easily manage a variety of agents with different emotions, personalities, and capabilities for specific tasks.</p>
<h1>B A DEMO OF THE EXECUTION</h1>
<p>In this section, we outline the complete process of software development using MetaGPT. It begins with a user's input command (as shown in Appendix B.1) and ends with software designed according to the user's specifications.</p>
<h2>B. 1 USER INPUT</h2>
<p>Upon receiving an instruction from the user, MetaGPT collaborates with a professional development team to fulfill the task. Here is a demo of user input:</p>
<h2>User input</h2>
<p>I write a python3 GUI app such that you can draw an image with it</p>
<h2>B. 2 METAGPT DEVELOPMENT PROCESS</h2>
<p>Now we provide a step-by-step explanation of the standardized output process for each agent.</p>
<p>Product Manager The Product Manager generates a Product Requirement Document (PRD), as detailed in the specified documentation. This document encompasses goals, user stories, competitive analysis, requirement analysis and requirement pool. Additionally, a competitive quadrant chart is produced (see Figure 7). Subsequently, these documents and charts are handed over to the architect for system design.</p>
<h2>Product Requirement Document</h2>
<p>## Original Requirements
The boss requires a Python3 GUI color meter that outputs the RGB values when it moves.
## Product Goals
"python
"Create a user-friendly GUI color meter",
"Ensure the color meter accurately outputs RGB values",
"Ensure the color meter updates RGB values in real-time as it moves"
"User Stories
"python
"As a user, I want to select any color on the screen, so that I can get its RGB values",
"As a user, I want the RGB values to update in real-time as I move the color meter, so that I $\hookrightarrow$ can get accurate color information",
"As a user, I want a simple and intuitive interface, so that I can easily use the color meter"
##
# Competitive Analysis
"python
"Color Cop: A popular color picker for Windows. It's simple and easy to use, but lacks real$\sim$ time RGB value updates",
"Just Color Picker: Offers real-time color picking and multiple color code formats. However, $\hookrightarrow$ its interface is cluttered and not very user-friendly",
"Instant Eyedropper: A simple color picker that lives in the system tray. It's convenient but $\hookrightarrow$ lacks advanced features",
"ColorZilla: A color picker extension for browsers. It's convenient for web design but not $\hookrightarrow$ suitable for desktop applications",
"ColorPic: Offers color palettes and mixer tools. It's feature-rich but can be overwhelming $\hookrightarrow$ for simple tasks"
## "</p>
<h1>Product Requirement Document</h1>
<div class="codehilite"><pre><span></span><code><span class="mf">1</span>
<span class="mf">2</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="n">Requirement</span><span class="w"> </span><span class="n">Analysis</span>
<span class="mf">3</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">product</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Python3</span><span class="w"> </span><span class="n">GUI</span><span class="w"> </span><span class="n">application</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">serves</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="n">meter</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">allow</span>
<span class="w">            </span><span class="err">|</span><span class="w"> </span><span class="n">users</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">select</span><span class="w"> </span><span class="n">any</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">screen</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">display</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">corresponding</span><span class="w"> </span><span class="n">RGB</span><span class="w"> </span><span class="nb">val</span><span class="n">ues</span><span class="mf">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">RGB</span>
<span class="w">                </span><span class="err">|</span><span class="w"> </span><span class="nb">val</span><span class="n">ues</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">update</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">real</span><span class="o">-</span><span class="n">time</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="n">meter</span><span class="w"> </span><span class="n">moves</span><span class="mf">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="nb">int</span><span class="n">erface</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span>
<span class="w">                </span><span class="err">|</span><span class="w"> </span><span class="n">simple</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">user</span><span class="o">-</span><span class="n">friendly</span><span class="mf">.</span>
<span class="mf">4</span>
<span class="mf">5</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="n">Requirement</span><span class="w"> </span><span class="n">Pool</span>
<span class="mf">6</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="n">python</span>
<span class="mf">7</span><span class="w"> </span><span class="err">{</span>
<span class="mf">8</span><span class="w"> </span><span class="p">(</span><span class="s">&quot;Design a user-friendly GUI for the color meter&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;P0&quot;</span><span class="p">),</span>
<span class="mf">9</span><span class="w"> </span><span class="p">(</span><span class="s">&quot;Implement color selection functionality&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;P0&quot;</span><span class="p">),</span>
<span class="mf">10</span><span class="w"> </span><span class="p">(</span><span class="s">&quot;Display RGB values of the selected color&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;P0&quot;</span><span class="p">),</span>
<span class="mf">11</span><span class="w"> </span><span class="p">(</span><span class="s">&quot;Update RGB values in real-time as the color meter moves&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;P0&quot;</span><span class="p">),</span>
<span class="mf">12</span><span class="w"> </span><span class="p">(</span><span class="s">&quot;Test the application for accuracy and performance&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;P1&quot;</span><span class="p">)</span>
<span class="mf">13</span><span class="w"> </span><span class="err">}</span>
<span class="mf">14</span><span class="w"> </span><span class="s">&quot; &quot;</span>
<span class="mf">15</span>
<span class="mf">16</span><span class="err">##</span><span class="w"> </span><span class="n">UI</span><span class="w"> </span><span class="n">Design</span><span class="w"> </span><span class="n">draft</span>
<span class="mf">17</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">UI</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">minimalistic</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="nb">int</span><span class="n">uitive</span><span class="mf">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">primarily</span><span class="w"> </span><span class="n">consist</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="n">meter</span><span class="p">,</span><span class="w"> </span><span class="n">which</span>
<span class="w">            </span><span class="err">|</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">magnified</span><span class="w"> </span><span class="n">area</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">screen</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">user</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">move</span><span class="w"> </span><span class="n">around</span><span class="mf">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">RGB</span><span class="w"> </span><span class="nb">val</span><span class="n">ues</span><span class="w"> </span><span class="n">of</span>
<span class="w">                </span><span class="err">|</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">currently</span><span class="w"> </span><span class="n">selected</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">prominently</span><span class="w"> </span><span class="n">displayed</span><span class="p">,</span><span class="w"> </span><span class="n">updating</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">real</span><span class="o">-</span><span class="n">time</span><span class="w"> </span><span class="n">as</span>
<span class="w">                </span><span class="err">|</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="n">meter</span><span class="w"> </span><span class="n">moves</span><span class="mf">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">layout</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">clean</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">uncluttered</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">focus</span><span class="w"> </span><span class="kr">on</span>
<span class="w">                </span><span class="err">|</span><span class="w"> </span><span class="n">functionality</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">ease</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">use</span><span class="mf">.</span>
<span class="mf">18</span>
<span class="mf">19</span><span class="err">##</span><span class="w"> </span><span class="n">Anything</span><span class="w"> </span><span class="n">UNCLEAR</span>
<span class="mf">20</span><span class="w"> </span><span class="n">There</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">unclear</span><span class="w"> </span><span class="n">points</span><span class="mf">.</span>
</code></pre></div>

<p>Reach and engagement of campaigns
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: The quadrant chart for the "Drawing App" generated by the product manager agent.</p>
<p>Architect Based on the requirements in PRD, the Architect agent devises technical specifications including system architecture diagrams and interface definitions. Initially, the Architect defines the overarching technical trajectory. Subsequently, the project's architecture, including files, classes (Figure 8) and the sequence flow chart (Figure 12), is designed. The Architect's documentation is then given to the project manager for task allocation and execution.</p>
<h1>System design</h1>
<div class="codehilite"><pre><span></span><code><span class="mi">1</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Implementation</span><span class="w"> </span><span class="nx">approach</span>
<span class="mi">2</span><span class="p">}</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="w"> </span><span class="nx">We</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="nx">use</span><span class="w"> </span><span class="nx">Python</span><span class="err">&#39;</span><span class="nx">s</span><span class="w"> </span><span class="nx">Tkinter</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">create</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">GUI</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">color</span><span class="w"> </span><span class="nx">meter</span><span class="p">.</span><span class="w"> </span><span class="nx">Tkinter</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">standard</span>
<span class="w">            </span><span class="err">\</span><span class="nx">hookrightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">Python</span><span class="w"> </span><span class="kd">interface</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">Tk</span><span class="w"> </span><span class="nx">GUI</span><span class="w"> </span><span class="nx">toolkit</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">included</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">most</span><span class="w"> </span><span class="nx">Python</span><span class="w"> </span><span class="nx">installations</span><span class="p">.</span><span class="w"> </span><span class="nx">It</span><span class="p">}</span>
<span class="w">            </span><span class="err">\</span><span class="nx">hookrightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">simple</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">use</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">powerful</span><span class="w"> </span><span class="nx">enough</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">our</span><span class="w"> </span><span class="nx">needs</span><span class="p">.}</span>
<span class="mi">3</span>
<span class="mi">4</span><span class="p">}</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">color</span><span class="w"> </span><span class="nx">selection</span><span class="w"> </span><span class="nx">functionality</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">implemented</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">PIL</span><span class="w"> </span><span class="p">(</span><span class="nx">Pillow</span><span class="p">)</span><span class="w"> </span><span class="kn">library</span><span class="p">,</span><span class="w"> </span><span class="nx">which</span><span class="w"> </span><span class="nx">allows</span>
<span class="w">            </span><span class="err">\</span><span class="nx">hookrightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">us</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">capture</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">screen</span><span class="err">&#39;</span><span class="nx">s</span><span class="w"> </span><span class="nx">pixel</span><span class="w"> </span><span class="nx">data</span><span class="p">.</span><span class="w"> </span><span class="nx">By</span><span class="w"> </span><span class="nx">moving</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">mouse</span><span class="p">,</span><span class="w"> </span><span class="nx">we</span><span class="w"> </span><span class="nx">can</span><span class="w"> </span><span class="nx">get</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">RGB</span><span class="w"> </span><span class="nx">values</span><span class="w"> </span><span class="nx">of</span><span class="p">}</span>
<span class="w">            </span><span class="err">\</span><span class="nx">hookrightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">pixel</span><span class="w"> </span><span class="nx">under</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">mouse</span><span class="w"> </span><span class="nx">cursor</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">real</span><span class="o">-</span><span class="nx">time</span><span class="p">.}</span>
<span class="mi">5</span>
<span class="mi">6</span><span class="p">}</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">RGB</span><span class="w"> </span><span class="nx">values</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">displayed</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">GUI</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">Tkinter</span><span class="err">&#39;</span><span class="nx">s</span><span class="w"> </span><span class="nx">Label</span><span class="w"> </span><span class="nx">widget</span><span class="p">.</span><span class="w"> </span><span class="nx">We</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="nx">use</span><span class="w"> </span><span class="nx">Python</span><span class="err">&#39;</span><span class="nx">s</span>
<span class="w">            </span><span class="err">\</span><span class="nx">hookrightarrow</span><span class="w"> </span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nx">threading</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">update</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">RGB</span><span class="w"> </span><span class="nx">values</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">real</span><span class="o">-</span><span class="nx">time</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">color</span><span class="w"> </span><span class="nx">meter</span><span class="w"> </span><span class="nx">moves</span><span class="p">.}</span>
<span class="mi">7</span>
<span class="mi">8</span><span class="p">}</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">application</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">tested</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">accuracy</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">performance</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">Python</span><span class="err">&#39;</span><span class="nx">s</span><span class="w"> </span><span class="nx">unittest</span><span class="w"> </span><span class="kn">library</span><span class="p">.</span>
<span class="mi">9</span>
<span class="mi">10</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Python</span><span class="w"> </span><span class="kn">package</span><span class="w"> </span><span class="nx">name</span>
<span class="mi">11</span><span class="w"> </span><span class="s">&quot;python</span>
<span class="s">12 &quot;</span><span class="nx">color_meter</span><span class="s">&quot;</span>
<span class="s">13 &quot;</span><span class="w"> </span>\
<span class="mi">14</span>
<span class="mi">15</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">File</span><span class="w"> </span><span class="nx">list</span>
<span class="mi">16</span><span class="w"> </span><span class="s">&quot;python</span>
<span class="s">17 {</span>
<span class="s">18 &quot;</span><span class="nx">main</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;,</span>
<span class="s">19 &quot;</span><span class="nx">color_picker</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;,</span>
<span class="s">20 &quot;</span><span class="nx">gui</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;,</span>
<span class="s">21 &quot;</span><span class="nx">teata</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;</span>
<span class="s">22 }</span>
<span class="s">23 &quot;</span><span class="w"> </span>\
<span class="mi">24</span>
<span class="mi">25</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Anything</span><span class="w"> </span><span class="nx">UNCLEAR</span>
<span class="mi">26</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">requirement</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">clear</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">me</span><span class="p">.</span>
</code></pre></div>

<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Data structures and interface definitions for the "Drawing App" generated by the architect agent.</p>
<p>Project Manager The Project Manager breaks down the project into a task list. Furthermore, each code file is analyzed based on its intended functionality and then treated as a separate task assigned to Engineers.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: The program call flow for the "Drawing App" generated by the architect agent.</p>
<h1>Tasks</h1>
<div class="codehilite"><pre><span></span><code><span class="mf">1</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="n">Required</span><span class="w"> </span><span class="n">Python</span><span class="w"> </span><span class="n">third</span><span class="o">-</span><span class="n">party</span><span class="w"> </span><span class="n">packages</span>
<span class="mf">2</span>
<span class="mf">3</span>
<span class="mf">4</span><span class="o">***</span>
<span class="mf">5</span>
<span class="mf">6</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">tklister</span><span class="o">==</span><span class="mf">8.6</span>
<span class="mf">6</span><span class="err">}\</span><span class="n">mathrm</span><span class="err">{</span><span class="w"> </span><span class="n">Pillow</span><span class="o">==</span><span class="mf">8.3.1</span>
<span class="mf">7</span>
<span class="mf">8</span><span class="o">***</span>
<span class="mf">9</span>
<span class="mf">10</span>
<span class="mf">11</span>
<span class="mf">12</span><span class="o">***</span>
<span class="mf">13</span><span class="w"> </span><span class="n">No</span><span class="w"> </span><span class="n">third</span><span class="o">-</span><span class="n">party</span><span class="w"> </span><span class="n">packages</span><span class="w"> </span><span class="n">required</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">languages</span><span class="mf">.</span>
<span class="mf">14</span>
<span class="mf">15</span><span class="o">***</span>
<span class="mf">16</span>
<span class="mf">17</span>
<span class="mf">18</span><span class="o">***</span>
<span class="mf">20</span>
<span class="mf">21</span><span class="o">***</span>
<span class="mf">22</span><span class="o">***</span>
<span class="mf">23</span>
<span class="mf">24</span>
<span class="mf">25</span><span class="o">***</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="p">(</span><span class="s2">&quot;main.py&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Contains the main application loop and initializes all the other components.&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="p">(</span><span class="s2">&quot;canvas.py&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Implements the drawing canvas, responds to mouse events, and uses the selected</span>
<span class="w">        </span>\<span class="n">Leftrightarrow</span><span class="w"> </span><span class="k">tool</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">color</span><span class="o">.</span><span class="s2">&quot;),</span>
<span class="w">    </span><span class="p">(</span><span class="s2">&quot;tools.py&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Implements the tool selection interface.&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="p">(</span><span class="s2">&quot;color_picker.py&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Implements the color selection interface.&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="p">(</span><span class="s2">&quot;file_manager.py&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Implements the file saving and opening functionality.&quot;</span><span class="p">)</span>
<span class="mi">32</span>
</code></pre></div>

<h1>Product Requirement Document</h1>
<div class="codehilite"><pre><span></span><code><span class="mi">1</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Task</span><span class="w"> </span><span class="nx">list</span>
<span class="mi">2</span><span class="w"> </span><span class="o">**</span><span class="nx">python</span>
<span class="mi">3</span><span class="w"> </span><span class="p">{</span>
<span class="mi">4</span><span class="w"> </span><span class="o">*</span><span class="nx">main</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;,</span>
<span class="s">5 *canvas.py&quot;</span><span class="p">,</span>
<span class="mi">6</span><span class="w"> </span><span class="o">*</span><span class="nx">tools</span><span class="p">.</span><span class="nx">py</span><span class="s">&quot;,</span>
<span class="s">7 *color_picker.py&quot;</span><span class="p">,</span>
<span class="mi">8</span><span class="w"> </span><span class="o">*</span><span class="nx">file_manager</span><span class="p">.</span><span class="nx">py</span><span class="o">*</span>
<span class="mi">9</span><span class="w"> </span><span class="p">}</span>
<span class="mi">10</span><span class="w"> </span><span class="o">***</span>
<span class="mi">11</span>
<span class="mi">12</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Shared</span><span class="w"> </span><span class="nx">Knowledge</span>
<span class="mi">13</span><span class="w"> </span><span class="o">***</span><span class="nx">python</span>
<span class="mi">14</span><span class="w"> </span><span class="o">***</span>
<span class="mi">15</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">Tkinter</span><span class="err">&#39;</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">creating</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">GUI</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">application</span><span class="p">.</span><span class="w"> </span><span class="nx">It</span><span class="w"> </span><span class="nx">provides</span><span class="w"> </span><span class="nx">various</span><span class="w"> </span><span class="nx">widgets</span>
<span class="w">        </span><span class="o">~</span><span class="w"> </span><span class="k">like</span><span class="w"> </span><span class="nx">frames</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">canvases</span><span class="w"> </span><span class="nx">which</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">used</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">this</span><span class="w"> </span><span class="nx">project</span><span class="p">.</span>
<span class="mi">16</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">Pillow</span><span class="err">&#39;</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">handling</span><span class="w"> </span><span class="nx">image</span><span class="w"> </span><span class="nx">files</span><span class="p">.</span><span class="w"> </span><span class="nx">It</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">used</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">file_manager</span><span class="p">.</span><span class="nx">py</span><span class="err">&#39;</span><span class="w"> </span><span class="k">for</span>
<span class="w">        </span><span class="o">~</span><span class="w"> </span><span class="nx">saving</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">opening</span><span class="w"> </span><span class="nx">image</span><span class="w"> </span><span class="nx">files</span><span class="p">.</span>
<span class="mi">17</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">main</span><span class="p">.</span><span class="nx">py</span><span class="err">&#39;</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">entry</span><span class="w"> </span><span class="nx">point</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">application</span><span class="p">.</span><span class="w"> </span><span class="nx">It</span><span class="w"> </span><span class="nx">initializes</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">other</span><span class="w"> </span><span class="nx">components</span>
<span class="w">        </span><span class="o">~</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">starts</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">application</span><span class="w"> </span><span class="nx">loop</span><span class="p">.</span>
<span class="mi">18</span><span class="w"> </span><span class="o">***</span>
<span class="mi">19</span><span class="w"> </span><span class="o">***</span>
<span class="mi">20</span>
<span class="mi">21</span><span class="w"> </span><span class="err">##</span><span class="w"> </span><span class="nx">Anything</span><span class="w"> </span><span class="nx">UNCLEAR</span>
<span class="mi">22</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">project</span><span class="w"> </span><span class="nx">requirements</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">implementation</span><span class="w"> </span><span class="nx">approach</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">clear</span><span class="p">.</span><span class="w"> </span><span class="nx">However</span><span class="p">,</span><span class="w"> </span><span class="nx">we</span><span class="w"> </span><span class="nx">need</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">ensure</span><span class="w"> </span><span class="nx">that</span>
<span class="w">        </span><span class="o">~</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="nx">team</span><span class="w"> </span><span class="nx">members</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">familiar</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">Tkinter</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">Pillow</span><span class="w"> </span><span class="nx">libraries</span><span class="p">.</span><span class="w"> </span><span class="nx">If</span><span class="w"> </span><span class="k">not</span><span class="p">,</span><span class="w"> </span><span class="nx">they</span><span class="w"> </span><span class="nx">may</span>
<span class="w">        </span><span class="o">~</span><span class="w"> </span><span class="nx">need</span><span class="w"> </span><span class="nx">some</span><span class="w"> </span><span class="nx">time</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">learn</span><span class="w"> </span><span class="nx">these</span><span class="w"> </span><span class="nx">libraries</span><span class="w"> </span><span class="nx">before</span><span class="w"> </span><span class="nx">starting</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">development</span><span class="p">.</span>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ http://beta.deepwisdom.ai&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>