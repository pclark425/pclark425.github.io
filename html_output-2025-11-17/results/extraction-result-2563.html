<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2563 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2563</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2563</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-ad97671a924a9b3a060fee857e561f140ec79dd7</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ad97671a924a9b3a060fee857e561f140ec79dd7" target="_blank">AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> A multi-agent framework that can collaboratively and dynamically adjust its composition as a greater-than-the-sum-of-its-parts system and delve into the emergence of social behaviors among individual agents within a group during collaborative task accomplishment is proposed.</p>
                <p><strong>Paper Abstract:</strong> Autonomous agents empowered by Large Language Models (LLMs) have undergone significant improvements, enabling them to generalize across a broad spectrum of tasks. However, in real-world scenarios, cooperation among individuals is often required to enhance the efficiency and effectiveness of task accomplishment. Hence, inspired by human group dynamics, we propose a multi-agent framework \framework that can collaboratively and dynamically adjust its composition as a greater-than-the-sum-of-its-parts system. Our experiments demonstrate that \framework framework can effectively deploy multi-agent groups that outperform a single agent. Furthermore, we delve into the emergence of social behaviors among individual agents within a group during collaborative task accomplishment. In view of these behaviors, we discuss some possible strategies to leverage positive ones and mitigate negative ones for improving the collaborative potential of multi-agent groups. Our codes for \framework will soon be released at \url{https://github.com/OpenBMB/AgentVerse}.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2563.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2563.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AGENTVERSE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AGENTVERSE (multi-agent collaboration framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general multi-agent framework introduced in this paper that simulates human group problem-solving via four iterative stages (Expert Recruitment, Collaborative Decision-Making, Action Execution, Evaluation) to dynamically compose and coordinate specialist LLM-driven agents for complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AGENTVERSE</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AGENTVERSE is a modular multi-agent framework that models problem solving as an MDP and runs iterative rounds of: (1) Expert Recruitment – an LLM recruiter M_r generates role/expert descriptions for agents dynamically based on the goal; (2) Collaborative Decision-Making – agents discuss using either a horizontal (democratic) or vertical (solver + reviewers) communication structure to produce a group decision A; (3) Action Execution – agents (some or all) execute actions in the environment, often using ReAct-style thought/tool calls; (4) Evaluation – an evaluator (agent or human-in-the-loop) computes verbal feedback r = R(s_new, g) comparing state to goal and returns it to influence the next round (including re-recruitment). The framework supports dynamic adjustment of group composition and role specialization across rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (predefined per task in experiments: typically 4 for many tasks; 2 for math reasoning; 2-3 for tool utilization)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Recruiter agent (M_r) — generates expert role descriptions; Solver agent — produces main proposed solution in vertical structure; Reviewer agents / Critics — provide critiques and request refinements; Evaluator agent — assesses solution correctness and issues verbal feedback; Summarizer — consolidates subtask assignments in horizontal discussions (used in tool-using experiments); Task-specific specialists observed in case studies (e.g., UI designer, software tester, unit-testing agent) that focus on UX, robustness, and testing respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea/problem analysis and expert recruitment, collaborative decision-making (strategy/formulation), implementation/action execution (including tool use and code generation), evaluation and iterative refinement. (Covers literature/problem understanding implicitly via web/tool queries in experiments.)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Hybrid hierarchical/dynamic coordination: a recruiter centralizes initial team composition; decision-making uses either horizontal (democratic, ensemble/summarization function f) or vertical (hierarchical: single solver iteratively refined by reviewers) structures; overall process is iterative with feedback loops that can change group composition between rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language message passing between LLM agents (prompt-based dialogues). In collaborative decision-making agents exchange textual proposals, critiques and refinements in a sequential order; action execution uses ReAct-style structured messages containing 'thought' and 'action/tool call' and receives tool responses (implemented via OpenAI function-calls). A summarizer agent may output consolidated structured summaries of sub-tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Evaluator (agent or human) issues verbal feedback r = R(s_new, g) that details shortcomings and suggestions; feedback is routed back into Expert Recruitment and subsequent decision-making rounds to (a) adjust group composition (recruit new experts or change roles) and (b) drive iterative refinement of actions/solutions. Peer feedback occurs in vertical reviewer critiques; reviewers request solver refinements until consensus or max iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Round-based and event-driven: agents discuss during the decision-making phase every round; during action execution individual agents iterate tool calls up to a per-agent cap (10 iterations in experiments) and then submit a conclusion; evaluator returns feedback after each execution round; summarizer consolidates at the end of horizontal discussions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General problem-solving: text understanding and conversational generation, creative writing, mathematical and logical reasoning, code generation (Humaneval), multi-tool web/API-based tasks (tool utilization), and embodied AI (Minecraft) — i.e., broad general scientific / engineering task domains rather than a single scientific field.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Multiple benchmarks and metrics reported: (selected numbers from the paper) Conversation (FED) GPT-4: CoT 95.4%, Solo 95.8%, Group 96.8%; Creative Writing (Commongen-Challenge) GPT-4: CoT 95.9%, Solo 99.0%, Group 99.1% (concept coverage %); Mathematical Reasoning (MGSM) GPT-4: CoT 95.2%, Solo 96.0%, Group 95.2%; Logical Reasoning (Logic Grid Puzzles) GPT-4: CoT 59.5%, Solo 64.0%, Group 66.5%; Coding (Humaneval pass@1) GPT-4: CoT 83.5%, Solo 87.2%, Group 89.0%; Tool utilization tasks: AGENTVERSE solved 9/10 complex multi-tool tasks vs single ReAct agent 3/10. (All results expressed as percentages or counts as reported.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to: (1) CoT (single chain-of-thought agent) baseline; (2) Solo AGENTVERSE variant (AGENTVERSE pipeline but single agent in decision-making); (3) Single ReAct agent for tool-use baselines. Results show Solo and Group AGENTVERSE generally outperform CoT; Group often improves over Solo (not uniformly for all LLMs/tasks). Tool-use baseline: AGENTVERSE 9/10 vs ReAct 3/10.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Quantitative: improved benchmark scores and pass@1 (e.g., GPT-4 coding pass@1 improved from 83.5% (CoT) to 89.0% (Group)); solved far more multi-tool tasks (9 vs 3). Qualitative: broader coverage and deeper, role-specific advice in consulting case, more robust and user-friendly software (UI suggestions, exception handling) from multi-role feedback; emergent volunteer and assistance behaviors accelerate multi-step embodied tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Conflicting/erroneous peer feedback can degrade performance (notably for weaker LLMs: GPT-3.5-Turbo Group underperformed Solo on some reasoning tasks); ~10% of MGSM errors traced to agents being swayed by incorrect peer critiques. Emergent negative behaviors in embodied environments (destructive shortcuts, harming agents) raise safety concerns. Overhead: increased complexity and potential coordination cost; dependence on evaluator quality.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Comparisons between CoT (single CoT agent), Solo (AGENTVERSE pipeline with single decision-maker), and Group (multi-agent decision-making) act as ablations for the contribution of collaboration. The paper also notes an empirical ablation: limiting reviewers for math tasks (they used 2 reviewers) because increasing reviewers increased erroneous critiques and harmed correctness for mathematical reasoning. No formal per-component ablation beyond these comparisons is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Domain-specific recommendations from experiments: use vertical (solver+reviewers) structure for tasks needing a single refined answer (math reasoning, coding); use horizontal (democratic) structure for multi-subtask / multi-tool tasks (tool utilization) to allow subtask partitioning; suggested numbers: 4 agents for dialogue/code/constrained generation tasks, 2 agents for math reasoning (to reduce erroneous critiques), 2-3 agents for tool utilization. The paper notes these are empirical/predefined and suggests automating agent-count selection as future work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2563.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReAct (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReAct: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting paradigm combining chain-of-thought style internal reasoning ('Thoughts') with explicit external actions/tool calls, enabling LLMs to iteratively interact with tools and environments; used in this paper as both a baseline single-agent tool-using approach and as the internal action-execution style for AGENTVERSE agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>React: Synergizing reasoning and acting in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReAct</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Single-agent prompting architecture where the agent interleaves natural-language 'thought' traces and discrete 'actions' (tool calls), receives tool outputs, and iterates until a solution is produced; in AGENTVERSE experiments ReAct is used for per-agent action execution (agents write thoughts, call tools via OpenAI function calls, and receive responses) and as the single-agent baseline for multi-tool tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (single agent baseline); also used as per-agent internal procedure inside multi-agent AGENTVERSE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not a multi-role system: a single agent reasons and acts, generating code/tool calls and interpreting tool outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Action execution / tool utilization and iterative problem-solving via tool calls.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>None (single-agent). When used inside AGENTVERSE, coordination across agents is handled by AGENTVERSE structures; ReAct controls per-agent internal action loops.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language thought/action sequences + structured tool calls (implemented with function calls).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>No peer feedback; iterative local feedback from tool responses only. In AGENTVERSE, evaluator provides cross-agent feedback external to ReAct.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Agent iterates thought->tool->response cycles up to a maximum iterations (10 in experiments) then finalizes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Tool utilization and other tasks that require interactions with external APIs, code interpreters, web/search, and testing.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>As single-agent baseline on 10 complex tool tasks: ReAct completed 3/10 tasks vs AGENTVERSE 9/10. Used internally with a 10-iteration cap per agent.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Serves as the single-agent baseline for multi-tool experiments; AGENTVERSE outperformed it substantially (9 vs 3 tasks solved).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>When used as per-agent behavior inside AGENTVERSE, it enables structured, interpretable tool interactions for each agent; however, coordination benefits between agents must come from AGENTVERSE orchestration rather than ReAct itself.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>As a standalone approach it lacks cross-agent decomposition and inter-agent critique; prone to early exits or missing subtasks in complex multi-tool tasks (observed failures where ReAct did not follow all task criteria).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Comparison of single ReAct agent vs AGENTVERSE multi-agent shows benefit of multi-agent orchestration for multi-tool tasks; no internal ablation of ReAct reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper uses ReAct with up to 10 iterations per agent and OpenAI function-calls for tool integration; within AGENTVERSE, use horizontal discussion + summarizer for multi-tool partitioning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2563.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT (autonomous GPT-4 experiment)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as an inspiring example of autonomous agents that operate with some degree of autonomy to accomplish multi-step goals; mentioned as background motivating multi-agent/autonomous agent research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Auto-gpt: An autonomous gpt-4 experiment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned in the introduction as an example of autonomous agents advancing capabilities; no implementation details or experiments on Auto-GPT are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not specified in this paper (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not specified in this paper (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not specified in this paper (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>cited as general autonomous agent example (background)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>mentioned only in related-work context, not experimentally compared here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2563.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as another example of autonomous-agent systems (a project that chains LLM-driven components for goal-directed behavior); referenced as inspiration/background.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Babyagi.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as an example of single-agent/autonomous multi-step pipelines; no experimental use or design details provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>mentioned as general autonomous agent work</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>none (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2563.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as an example of autonomous/agent frameworks that orchestrate LLM-driven agents to perform tasks; cited for context in the introduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Agentgpt, 2023.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as part of existing autonomous agent examples; the paper does not provide experimental use or internal details of AgentGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>referenced broadly as autonomous agents</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>not used as baseline in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2563.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAMEL: communicative agents for 'mind' exploration of large scale language model society</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited prior work that conceptualizes assemblies of LLM agents as societies and studies inter-agent communication and emergent behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CAMEL: communicative agents for "mind" exploration of large scale language model society</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned in related work as an example of research exploring communicative multi-agent assemblies; the paper references CAMEL to motivate group-based agent research but does not implement it.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>not specified (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not detailed here (see original CAMEL paper)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not detailed here (see original CAMEL paper)</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not detailed here (see original CAMEL paper)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>multi-agent social/communication experiments (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>mentioned as related work only</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2563.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as work finding emergent social behaviors in multi-agent life simulation, motivating the study of emergent behaviors in AGENTVERSE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Generative Agents (Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited for empirical observation of emergent social behaviors in multi-agent simulations; this paper leverages such prior observations as motivation but does not run Park et al.'s system.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not detailed in this paper (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>multi-agent life simulation / emergent behavior study (as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>mentioned as related work</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2563.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Communicative agents for software development (Qian et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited prior work that uses multiple communicating agents for software development tasks; referenced as related work demonstrating role-specialized multi-agent cooperation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Communicative agents for software development</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as prior work that assigned communicative roles to agents for software development; the current paper relates to and extends these ideas with AGENTVERSE's dynamic recruitment and evaluation loop.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>role-specialized agents for software development (referenced only)</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>software design and development (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not specified here (see original reference)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>software development (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>mentioned as related work</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2563.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autogen (multiagent convo)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autogen: Enabling next-gen LLM applications via multiagent conversation framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as related work: a framework for multi-agent conversations enabling multi-party coordination of LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autogen: Enabling next-gen llm applications via multiagent conversation framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autogen</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as another multi-agent conversation framework in related work; AGENTVERSE builds on similar ideas but contributes explicit recruitment/evaluation loops and domain-specific communication structures.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>conversation-driven multi-agent tasks (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>not described here (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not described here</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>not described here</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not described here</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>general LLM multi-agent conversation applications (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>related work mention only</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2563.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2563.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multiagent debate (Du et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Improving factuality and reasoning in language models through multiagent debate</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited related work that uses multi-agent debate mechanisms to enhance factuality and reasoning, mentioned as background motivating reviewer/critic roles in AGENTVERSE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Improving factuality and reasoning in language models through multiagent debate</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multiagent debate (Du et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Referenced as prior art where multi-agent debate is used to improve model reasoning/factuality; this influenced AGENTVERSE's use of reviewer/critic roles and evaluation loops, but the paper does not directly implement Du et al.'s method.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>pro-/anti-debaters / reviewers (implied by citation)</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>reasoning and evaluation (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>debate-style peer review (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>peer critiques as feedback (reference only)</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>reasoning/factuality improvements (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>not implemented here</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>inspiration for reviewer/evaluator roles in AGENTVERSE</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>not detailed here</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>not specified here</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>CAMEL: communicative agents for "mind" exploration of large scale language model society <em>(Rating: 2)</em></li>
                <li>React: Synergizing reasoning and acting in language models <em>(Rating: 2)</em></li>
                <li>Autogen: Enabling next-gen llm applications via multiagent conversation framework <em>(Rating: 2)</em></li>
                <li>Improving factuality and reasoning in language models through multiagent debate <em>(Rating: 2)</em></li>
                <li>Communicative agents for software development <em>(Rating: 2)</em></li>
                <li>Auto-gpt: An autonomous gpt-4 experiment <em>(Rating: 1)</em></li>
                <li>Babyagi. <em>(Rating: 1)</em></li>
                <li>Agentgpt, 2023. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2563",
    "paper_id": "paper-ad97671a924a9b3a060fee857e561f140ec79dd7",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "AGENTVERSE",
            "name_full": "AGENTVERSE (multi-agent collaboration framework)",
            "brief_description": "A general multi-agent framework introduced in this paper that simulates human group problem-solving via four iterative stages (Expert Recruitment, Collaborative Decision-Making, Action Execution, Evaluation) to dynamically compose and coordinate specialist LLM-driven agents for complex tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AGENTVERSE",
            "system_description": "AGENTVERSE is a modular multi-agent framework that models problem solving as an MDP and runs iterative rounds of: (1) Expert Recruitment – an LLM recruiter M_r generates role/expert descriptions for agents dynamically based on the goal; (2) Collaborative Decision-Making – agents discuss using either a horizontal (democratic) or vertical (solver + reviewers) communication structure to produce a group decision A; (3) Action Execution – agents (some or all) execute actions in the environment, often using ReAct-style thought/tool calls; (4) Evaluation – an evaluator (agent or human-in-the-loop) computes verbal feedback r = R(s_new, g) comparing state to goal and returns it to influence the next round (including re-recruitment). The framework supports dynamic adjustment of group composition and role specialization across rounds.",
            "number_of_agents": "variable (predefined per task in experiments: typically 4 for many tasks; 2 for math reasoning; 2-3 for tool utilization)",
            "agent_specializations": "Recruiter agent (M_r) — generates expert role descriptions; Solver agent — produces main proposed solution in vertical structure; Reviewer agents / Critics — provide critiques and request refinements; Evaluator agent — assesses solution correctness and issues verbal feedback; Summarizer — consolidates subtask assignments in horizontal discussions (used in tool-using experiments); Task-specific specialists observed in case studies (e.g., UI designer, software tester, unit-testing agent) that focus on UX, robustness, and testing respectively.",
            "research_phases_covered": "Idea/problem analysis and expert recruitment, collaborative decision-making (strategy/formulation), implementation/action execution (including tool use and code generation), evaluation and iterative refinement. (Covers literature/problem understanding implicitly via web/tool queries in experiments.)",
            "coordination_mechanism": "Hybrid hierarchical/dynamic coordination: a recruiter centralizes initial team composition; decision-making uses either horizontal (democratic, ensemble/summarization function f) or vertical (hierarchical: single solver iteratively refined by reviewers) structures; overall process is iterative with feedback loops that can change group composition between rounds.",
            "communication_protocol": "Natural-language message passing between LLM agents (prompt-based dialogues). In collaborative decision-making agents exchange textual proposals, critiques and refinements in a sequential order; action execution uses ReAct-style structured messages containing 'thought' and 'action/tool call' and receives tool responses (implemented via OpenAI function-calls). A summarizer agent may output consolidated structured summaries of sub-tasks.",
            "feedback_mechanism": "Evaluator (agent or human) issues verbal feedback r = R(s_new, g) that details shortcomings and suggestions; feedback is routed back into Expert Recruitment and subsequent decision-making rounds to (a) adjust group composition (recruit new experts or change roles) and (b) drive iterative refinement of actions/solutions. Peer feedback occurs in vertical reviewer critiques; reviewers request solver refinements until consensus or max iterations.",
            "communication_frequency": "Round-based and event-driven: agents discuss during the decision-making phase every round; during action execution individual agents iterate tool calls up to a per-agent cap (10 iterations in experiments) and then submit a conclusion; evaluator returns feedback after each execution round; summarizer consolidates at the end of horizontal discussions.",
            "task_domain": "General problem-solving: text understanding and conversational generation, creative writing, mathematical and logical reasoning, code generation (Humaneval), multi-tool web/API-based tasks (tool utilization), and embodied AI (Minecraft) — i.e., broad general scientific / engineering task domains rather than a single scientific field.",
            "performance_metrics": "Multiple benchmarks and metrics reported: (selected numbers from the paper) Conversation (FED) GPT-4: CoT 95.4%, Solo 95.8%, Group 96.8%; Creative Writing (Commongen-Challenge) GPT-4: CoT 95.9%, Solo 99.0%, Group 99.1% (concept coverage %); Mathematical Reasoning (MGSM) GPT-4: CoT 95.2%, Solo 96.0%, Group 95.2%; Logical Reasoning (Logic Grid Puzzles) GPT-4: CoT 59.5%, Solo 64.0%, Group 66.5%; Coding (Humaneval pass@1) GPT-4: CoT 83.5%, Solo 87.2%, Group 89.0%; Tool utilization tasks: AGENTVERSE solved 9/10 complex multi-tool tasks vs single ReAct agent 3/10. (All results expressed as percentages or counts as reported.)",
            "baseline_comparison": "Compared to: (1) CoT (single chain-of-thought agent) baseline; (2) Solo AGENTVERSE variant (AGENTVERSE pipeline but single agent in decision-making); (3) Single ReAct agent for tool-use baselines. Results show Solo and Group AGENTVERSE generally outperform CoT; Group often improves over Solo (not uniformly for all LLMs/tasks). Tool-use baseline: AGENTVERSE 9/10 vs ReAct 3/10.",
            "coordination_benefits": "Quantitative: improved benchmark scores and pass@1 (e.g., GPT-4 coding pass@1 improved from 83.5% (CoT) to 89.0% (Group)); solved far more multi-tool tasks (9 vs 3). Qualitative: broader coverage and deeper, role-specific advice in consulting case, more robust and user-friendly software (UI suggestions, exception handling) from multi-role feedback; emergent volunteer and assistance behaviors accelerate multi-step embodied tasks.",
            "coordination_challenges": "Conflicting/erroneous peer feedback can degrade performance (notably for weaker LLMs: GPT-3.5-Turbo Group underperformed Solo on some reasoning tasks); ~10% of MGSM errors traced to agents being swayed by incorrect peer critiques. Emergent negative behaviors in embodied environments (destructive shortcuts, harming agents) raise safety concerns. Overhead: increased complexity and potential coordination cost; dependence on evaluator quality.",
            "ablation_studies": "Comparisons between CoT (single CoT agent), Solo (AGENTVERSE pipeline with single decision-maker), and Group (multi-agent decision-making) act as ablations for the contribution of collaboration. The paper also notes an empirical ablation: limiting reviewers for math tasks (they used 2 reviewers) because increasing reviewers increased erroneous critiques and harmed correctness for mathematical reasoning. No formal per-component ablation beyond these comparisons is reported.",
            "optimal_configurations": "Domain-specific recommendations from experiments: use vertical (solver+reviewers) structure for tasks needing a single refined answer (math reasoning, coding); use horizontal (democratic) structure for multi-subtask / multi-tool tasks (tool utilization) to allow subtask partitioning; suggested numbers: 4 agents for dialogue/code/constrained generation tasks, 2 agents for math reasoning (to reduce erroneous critiques), 2-3 agents for tool utilization. The paper notes these are empirical/predefined and suggests automating agent-count selection as future work.",
            "uuid": "e2563.0",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ReAct (baseline)",
            "name_full": "ReAct: Synergizing reasoning and acting in language models",
            "brief_description": "A prompting paradigm combining chain-of-thought style internal reasoning ('Thoughts') with explicit external actions/tool calls, enabling LLMs to iteratively interact with tools and environments; used in this paper as both a baseline single-agent tool-using approach and as the internal action-execution style for AGENTVERSE agents.",
            "citation_title": "React: Synergizing reasoning and acting in language models",
            "mention_or_use": "use",
            "system_name": "ReAct",
            "system_description": "Single-agent prompting architecture where the agent interleaves natural-language 'thought' traces and discrete 'actions' (tool calls), receives tool outputs, and iterates until a solution is produced; in AGENTVERSE experiments ReAct is used for per-agent action execution (agents write thoughts, call tools via OpenAI function calls, and receive responses) and as the single-agent baseline for multi-tool tasks.",
            "number_of_agents": "1 (single agent baseline); also used as per-agent internal procedure inside multi-agent AGENTVERSE",
            "agent_specializations": "Not a multi-role system: a single agent reasons and acts, generating code/tool calls and interpreting tool outputs.",
            "research_phases_covered": "Action execution / tool utilization and iterative problem-solving via tool calls.",
            "coordination_mechanism": "None (single-agent). When used inside AGENTVERSE, coordination across agents is handled by AGENTVERSE structures; ReAct controls per-agent internal action loops.",
            "communication_protocol": "Natural-language thought/action sequences + structured tool calls (implemented with function calls).",
            "feedback_mechanism": "No peer feedback; iterative local feedback from tool responses only. In AGENTVERSE, evaluator provides cross-agent feedback external to ReAct.",
            "communication_frequency": "Agent iterates thought-&gt;tool-&gt;response cycles up to a maximum iterations (10 in experiments) then finalizes.",
            "task_domain": "Tool utilization and other tasks that require interactions with external APIs, code interpreters, web/search, and testing.",
            "performance_metrics": "As single-agent baseline on 10 complex tool tasks: ReAct completed 3/10 tasks vs AGENTVERSE 9/10. Used internally with a 10-iteration cap per agent.",
            "baseline_comparison": "Serves as the single-agent baseline for multi-tool experiments; AGENTVERSE outperformed it substantially (9 vs 3 tasks solved).",
            "coordination_benefits": "When used as per-agent behavior inside AGENTVERSE, it enables structured, interpretable tool interactions for each agent; however, coordination benefits between agents must come from AGENTVERSE orchestration rather than ReAct itself.",
            "coordination_challenges": "As a standalone approach it lacks cross-agent decomposition and inter-agent critique; prone to early exits or missing subtasks in complex multi-tool tasks (observed failures where ReAct did not follow all task criteria).",
            "ablation_studies": "Comparison of single ReAct agent vs AGENTVERSE multi-agent shows benefit of multi-agent orchestration for multi-tool tasks; no internal ablation of ReAct reported in this paper.",
            "optimal_configurations": "Paper uses ReAct with up to 10 iterations per agent and OpenAI function-calls for tool integration; within AGENTVERSE, use horizontal discussion + summarizer for multi-tool partitioning.",
            "uuid": "e2563.1",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Auto-GPT",
            "name_full": "Auto-GPT (autonomous GPT-4 experiment)",
            "brief_description": "Referenced as an inspiring example of autonomous agents that operate with some degree of autonomy to accomplish multi-step goals; mentioned as background motivating multi-agent/autonomous agent research.",
            "citation_title": "Auto-gpt: An autonomous gpt-4 experiment",
            "mention_or_use": "mention",
            "system_name": "Auto-GPT",
            "system_description": "Mentioned in the introduction as an example of autonomous agents advancing capabilities; no implementation details or experiments on Auto-GPT are provided in this paper.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified in this paper",
            "research_phases_covered": "not specified in this paper",
            "coordination_mechanism": "not specified in this paper (reference only)",
            "communication_protocol": "not specified in this paper (reference only)",
            "feedback_mechanism": "not specified in this paper (reference only)",
            "communication_frequency": "not specified in this paper",
            "task_domain": "cited as general autonomous agent example (background)",
            "performance_metrics": "not provided in this paper",
            "baseline_comparison": "mentioned only in related-work context, not experimentally compared here",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified in this paper",
            "uuid": "e2563.2",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "BabyAGI",
            "name_full": "BabyAGI",
            "brief_description": "Mentioned as another example of autonomous-agent systems (a project that chains LLM-driven components for goal-directed behavior); referenced as inspiration/background.",
            "citation_title": "Babyagi.",
            "mention_or_use": "mention",
            "system_name": "BabyAGI",
            "system_description": "Cited as an example of single-agent/autonomous multi-step pipelines; no experimental use or design details provided in this paper.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified in this paper",
            "research_phases_covered": "not specified in this paper",
            "coordination_mechanism": "not specified in this paper",
            "communication_protocol": "not specified in this paper",
            "feedback_mechanism": "not specified in this paper",
            "communication_frequency": "not specified in this paper",
            "task_domain": "mentioned as general autonomous agent work",
            "performance_metrics": "not provided here",
            "baseline_comparison": "none (reference only)",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified in this paper",
            "uuid": "e2563.3",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "AgentGPT",
            "name_full": "AgentGPT",
            "brief_description": "Mentioned as an example of autonomous/agent frameworks that orchestrate LLM-driven agents to perform tasks; cited for context in the introduction.",
            "citation_title": "Agentgpt, 2023.",
            "mention_or_use": "mention",
            "system_name": "AgentGPT",
            "system_description": "Referenced as part of existing autonomous agent examples; the paper does not provide experimental use or internal details of AgentGPT.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified in this paper",
            "research_phases_covered": "not specified in this paper",
            "coordination_mechanism": "not specified in this paper",
            "communication_protocol": "not specified in this paper",
            "feedback_mechanism": "not specified in this paper",
            "communication_frequency": "not specified in this paper",
            "task_domain": "referenced broadly as autonomous agents",
            "performance_metrics": "not provided here",
            "baseline_comparison": "not used as baseline in experiments",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified in this paper",
            "uuid": "e2563.4",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "CAMEL",
            "name_full": "CAMEL: communicative agents for 'mind' exploration of large scale language model society",
            "brief_description": "Cited prior work that conceptualizes assemblies of LLM agents as societies and studies inter-agent communication and emergent behaviors.",
            "citation_title": "CAMEL: communicative agents for \"mind\" exploration of large scale language model society",
            "mention_or_use": "mention",
            "system_name": "CAMEL",
            "system_description": "Mentioned in related work as an example of research exploring communicative multi-agent assemblies; the paper references CAMEL to motivate group-based agent research but does not implement it.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified (reference only)",
            "research_phases_covered": "not specified (reference only)",
            "coordination_mechanism": "not detailed here (see original CAMEL paper)",
            "communication_protocol": "not detailed here (see original CAMEL paper)",
            "feedback_mechanism": "not detailed here (see original CAMEL paper)",
            "communication_frequency": "not detailed here",
            "task_domain": "multi-agent social/communication experiments (as cited)",
            "performance_metrics": "not provided in this paper",
            "baseline_comparison": "mentioned as related work only",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified in this paper",
            "uuid": "e2563.5",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Generative Agents (Park et al.)",
            "name_full": "Generative agents: Interactive simulacra of human behavior",
            "brief_description": "Referenced as work finding emergent social behaviors in multi-agent life simulation, motivating the study of emergent behaviors in AGENTVERSE.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "system_name": "Generative Agents (Park et al.)",
            "system_description": "Cited for empirical observation of emergent social behaviors in multi-agent simulations; this paper leverages such prior observations as motivation but does not run Park et al.'s system.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified here",
            "research_phases_covered": "not specified here",
            "coordination_mechanism": "not detailed in this paper (reference only)",
            "communication_protocol": "not detailed here",
            "feedback_mechanism": "not detailed here",
            "communication_frequency": "not detailed here",
            "task_domain": "multi-agent life simulation / emergent behavior study (as cited)",
            "performance_metrics": "not provided here",
            "baseline_comparison": "mentioned as related work",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not provided here",
            "uuid": "e2563.6",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Communicative agents for software development",
            "name_full": "Communicative agents for software development (Qian et al.)",
            "brief_description": "Cited prior work that uses multiple communicating agents for software development tasks; referenced as related work demonstrating role-specialized multi-agent cooperation.",
            "citation_title": "Communicative agents for software development",
            "mention_or_use": "mention",
            "system_name": "Communicative agents for software development",
            "system_description": "Referenced as prior work that assigned communicative roles to agents for software development; the current paper relates to and extends these ideas with AGENTVERSE's dynamic recruitment and evaluation loop.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "role-specialized agents for software development (referenced only)",
            "research_phases_covered": "software design and development (referenced)",
            "coordination_mechanism": "not specified here (see original reference)",
            "communication_protocol": "not specified here",
            "feedback_mechanism": "not specified here",
            "communication_frequency": "not specified here",
            "task_domain": "software development (related work)",
            "performance_metrics": "not provided in this paper",
            "baseline_comparison": "mentioned as related work",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified here",
            "uuid": "e2563.7",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Autogen (multiagent convo)",
            "name_full": "Autogen: Enabling next-gen LLM applications via multiagent conversation framework",
            "brief_description": "Mentioned as related work: a framework for multi-agent conversations enabling multi-party coordination of LLMs.",
            "citation_title": "Autogen: Enabling next-gen llm applications via multiagent conversation framework",
            "mention_or_use": "mention",
            "system_name": "Autogen",
            "system_description": "Cited as another multi-agent conversation framework in related work; AGENTVERSE builds on similar ideas but contributes explicit recruitment/evaluation loops and domain-specific communication structures.",
            "number_of_agents": "not specified in this paper",
            "agent_specializations": "not specified here",
            "research_phases_covered": "conversation-driven multi-agent tasks (referenced)",
            "coordination_mechanism": "not described here (reference only)",
            "communication_protocol": "not described here",
            "feedback_mechanism": "not described here",
            "communication_frequency": "not described here",
            "task_domain": "general LLM multi-agent conversation applications (related work)",
            "performance_metrics": "not provided here",
            "baseline_comparison": "related work mention only",
            "coordination_benefits": "not detailed here",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified here",
            "uuid": "e2563.8",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "Multiagent debate (Du et al.)",
            "name_full": "Improving factuality and reasoning in language models through multiagent debate",
            "brief_description": "Cited related work that uses multi-agent debate mechanisms to enhance factuality and reasoning, mentioned as background motivating reviewer/critic roles in AGENTVERSE.",
            "citation_title": "Improving factuality and reasoning in language models through multiagent debate",
            "mention_or_use": "mention",
            "system_name": "Multiagent debate (Du et al.)",
            "system_description": "Referenced as prior art where multi-agent debate is used to improve model reasoning/factuality; this influenced AGENTVERSE's use of reviewer/critic roles and evaluation loops, but the paper does not directly implement Du et al.'s method.",
            "number_of_agents": "not specified here",
            "agent_specializations": "pro-/anti-debaters / reviewers (implied by citation)",
            "research_phases_covered": "reasoning and evaluation (referenced)",
            "coordination_mechanism": "debate-style peer review (reference only)",
            "communication_protocol": "not detailed here",
            "feedback_mechanism": "peer critiques as feedback (reference only)",
            "communication_frequency": "not detailed here",
            "task_domain": "reasoning/factuality improvements (related work)",
            "performance_metrics": "not provided here",
            "baseline_comparison": "not implemented here",
            "coordination_benefits": "inspiration for reviewer/evaluator roles in AGENTVERSE",
            "coordination_challenges": "not detailed here",
            "ablation_studies": "none in this paper",
            "optimal_configurations": "not specified here",
            "uuid": "e2563.9",
            "source_info": {
                "paper_title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "CAMEL: communicative agents for \"mind\" exploration of large scale language model society",
            "rating": 2
        },
        {
            "paper_title": "React: Synergizing reasoning and acting in language models",
            "rating": 2
        },
        {
            "paper_title": "Autogen: Enabling next-gen llm applications via multiagent conversation framework",
            "rating": 2
        },
        {
            "paper_title": "Improving factuality and reasoning in language models through multiagent debate",
            "rating": 2
        },
        {
            "paper_title": "Communicative agents for software development",
            "rating": 2
        },
        {
            "paper_title": "Auto-gpt: An autonomous gpt-4 experiment",
            "rating": 1
        },
        {
            "paper_title": "Babyagi.",
            "rating": 1
        },
        {
            "paper_title": "Agentgpt, 2023.",
            "rating": 1
        }
    ],
    "cost": 0.021152,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>AGENTVERSE: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</h1>
<p>Weize Chen ${ }^{1 <em>}$, Yusheng $\mathbf{S u}^{1 </em>}$, Jingwei Zuo ${ }^{1}$, Cheng Yang ${ }^{3 \text { SS }}$, Chenfei Yuan ${ }^{1}$, Chi-Min Chan ${ }^{1}$, Heyang $\mathbf{Y u}^{1}$, Yaxi $\mathbf{L u}^{1}$, Yi-Hsin Hung ${ }^{2}$, Chen Qian ${ }^{1}$, Yujia Qin ${ }^{1}$, Xin Cong ${ }^{1}$, Ruobing Xie ${ }^{4}$, Zhiyuan Liu ${ }^{1 \text { SS }}$, Maosong Sun ${ }^{1}$, Jie Zhou ${ }^{4}$<br>${ }^{1}$ Department of Computer Science and Technology, Tsinghua University<br>${ }^{2}$ School of Economics and Management, Tsinghua University<br>${ }^{3}$ School of Computer Science, Beijing University of Posts and Telecommunications<br>${ }^{4}$ Pattern Recognition Center, WeChat AI, Tencent Inc.<br>chenwz21@mails.tsinghua.edu.cn, yushengsu.thu@gmail.com</p>
<h4>Abstract</h4>
<p>Autonomous agents empowered by Large Language Models (LLMs) have undergone significant improvements, enabling them to generalize across a broad spectrum of tasks. However, in real-world scenarios, cooperation among individuals is often required to enhance the efficiency and effectiveness of task accomplishment. Hence, inspired by human group dynamics, we propose a multi-agent framework AGENTVERSE that can effectively orchestrate a collaborative group of expert agents as a greater-than-the-sum-of-its-parts system. Our experiments demonstrate that AGENTVERSE can proficiently deploy multi-agent groups that outperform a single agent. Extensive experiments on text understanding, reasoning, coding, tool utilization, and embodied AI confirm the effectiveness of AGENTVERSE. Moreover, our analysis of agent interactions within AGENTVERSE reveals the emergence of specific collaborative behaviors, contributing to heightened group efficiency. Our code has been released at https://github.com/OpenBMB/AgentVerse/.</p>
<h2>1 INTRODUCTION</h2>
<p>The pursuit of creating intelligent and autonomous agents that can seamlessly assist humans and operate in real-world settings has been a foundational goal in artificial intelligence (Wooldridge \&amp; Jennings, 1995; Minsky, 1988; Bubeck et al., 2023). The recent advance of Large Language Models (LLMs) (OpenAI, 2023a; Anil et al., 2023; Touvron et al., 2023b) has created newfound avenues in this domain. These LLMs, especially GPT-4 (OpenAI, 2023a), are particularly adept in comprehending human intent and executing commands. They have demonstrated remarkable proficiency in domains such as language understanding, vision (OpenAI, 2023b), and coding (Bubeck et al., 2023). By harnessing the power of LLMs, autonomous agents can make more nuanced decisions and perform actions with an unprecedented degree of autonomy (Zhou et al., 2023). Agents like AutoGPT (Richards \&amp; et al., 2023), BabyAGI (Nakajima, 2023), and AgentGPT (Reworkd, 2023), are inspiring examples. Furthermore, recent research has endowed autonomous agents with more human-analogous cognitive mechanisms, spanning from reflection (Yao et al., 2023b; Shinn et al., 2023), task decomposition (Wei et al., 2022b; Yao et al., 2023a), and tool utilization (Schick et al., 2023b; Qin et al., 2023a;b; Qian et al., 2023b). These advancements edge us closer to realizing the concept of artificial general intelligence (AGI) (Goertzel \&amp; Pennachin, 2007; Clune, 2019) that can generalize across a broader range of tasks.</p>
<p>However, complex real-world tasks often require cooperation among individuals to achieve better effectiveness. Throughout history, numerous studies have delved into methods for enhancing collaboration among humans to improve work efficiency and effectiveness (Woolley et al., 2010; Fehr \&amp; Gächter, 2000). More recently, with the evolution of autonomous agents towards AGI, extensive research conceptualizes the assemblies of agents as a society or group (Li et al., 2023), and focuses on exploring the potential of their cooperation. For example, Park et al. (2023) found emergent</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An illustration of the AGENTVERSE.
social behaviors in multi-agent life simulation. Du et al. (2023); Wang et al. (2023b); Zhang et al. (2023a); Qian et al. (2023a); Chan et al. (2023) also underscored the enhanced decision-making of collaborating agents during collaborative problem-solving. However, a limitation in these studies is their narrow focus on specific and limited tasks, leaving the generalizability of their findings uncertain. An additional constraint is their static approach to agent collaboration, where agents' roles and capabilities remain rigid, hindering adaptability.</p>
<p>To address this problem, we introduce AGENTVERSE. This general multi-agent framework simulates the problem-solving procedures of human groups, and allows for dynamic adjustment of group members based on current progress. Specifically, AGENTVERSE splits the problem-solving process into four pivotal stages as shown in Figure 1: (1) Expert Recruitment: Determine and adjust the agent group's composition based on the ongoing problem-solving progression. (2) Collaborative Decision-Making: Engage the selected agents in joint discussions to devise problem-solving strategies. (3) Action Execution: Agents interact with their environment to implement the devised actions. (4) Evaluation - Assess the differences between the current state and desired outcomes. If the current state is unsatisfactory, feedback is given to the next iteration for further refinement.</p>
<p>We conduct extensive experiments and case studies in diverse aspects including text understanding, reasoning, coding, tool utilization and embodied AI to show the effectiveness of AGENTVERSE. Additionally, we highlight the social behaviors that emerge from the multi-agent collaboration, and discuss their advantages and potential risks. In summary, our contributions are:</p>
<ul>
<li>Inspired by the collaborative process of a human team, we propose AGENTVERSE as an effective framework for promoting collaboration among multiple agents in problem-solving.</li>
<li>We conduct extensive experiments to show that AGENTVERSE effectively improve the agents’ understanding, reasoning, coding, tool utilizing capabilities and their potential in embodied AI.</li>
<li>In the multi-agent collaboration, especially within tool utilization and Minecraft game playing, agents manifest certain emergent behaviors. For example, (1) volunteer behaviors, characterized by agents offering assistance to peers, thus improving team efficiency; (2) conformity behaviors, where agents adjust their deviated behaviors to align with the common goal under the critics from others; (3) destructive behaviors, occasionally leading to undesired and detrimental outcomes.</li>
</ul>
<h1>2 AGENTVERSE FRAMEWORK</h1>
<p>A problem-solving process is a sequence of iterative stages within a human group (Bransford \&amp; Stein, 1993). Initially, the group assesses the difference between the current state and the desired goal, dynamically adjusting its composition to enhance collaboration in decision-making, and subsequently</p>
<p>executing well-informed actions. In order to enhance the effectiveness of an autonomous multi-agent group in achieving their goals, we simulate the problem-solving processes of a human group to propose the AGENTVERSE framework, which is composed of four crucial stages: Expert Recruitment, Collaborative Decision-Making, Action Execution, and Evaluation, as shown in Figure 1. The entire process can be modeled as a Markov decision process (MDP), characterized as a tuple $(\mathcal{S}, \mathcal{A}, \mathcal{T}, \mathcal{R}, \mathcal{G})$. This encompasses the autonomous agent and environment state space $\mathcal{S}$, solution and action space $\mathcal{A}$, transition function $\mathcal{T}: \mathcal{S} \times \mathcal{A} \rightarrow \mathcal{S}$, reward function $\mathcal{R}$, and goal space $\mathcal{G}$.</p>
<h1>2.1 EXPERT RECRUITMENT</h1>
<p>Expert Recruitment stage determines the composition of a multi-agent group, playing an important role in deciding the upper bounds of the group's capabilities. Empirical evidence suggests that diversity within human groups introduces varied viewpoints, enhancing the group's performance across different tasks (Woolley et al., 2015; Phillips \&amp; O'Reilly, 1998). Parallel findings from recent research suggest that designating specific roles for autonomous agents, similar to recruiting experts to form a group, can augment their efficacy (Li et al., 2023; Salewski et al., 2023; Qian et al., 2023a). Current methodologies for assigning role descriptions to autonomous agents predominantly involve manual assignment, necessitating prior knowledge and understanding of the task. Consequently, the scalability remains ambiguous, especially in the face of diverse and intricate problem contexts.</p>
<p>In view of this, AGENTVERSE automates expert recruitment to make agent configuration more scalable. For a given goal $g \in \mathcal{G}$, a particular agent $M_{r}$ is prompted as the "recruiter", similar to a human resource manager. Instead of relying on pre-defined expert descriptions, $M_{r}$ dynamically generates a set of expert descriptions based on $g$. The different agents prompted with these different expert descriptions then form an expert group $\mathcal{M}=M_{r}(g)$ on the given goal $g$. Notably, the composition of a multi-agent group will be dynamically adjusted based on feedback from the evaluation stage (Section 2.4). This allows AGENTVERSE to employ the most suitable group based on the current state to make better decisions in future rounds.</p>
<h3>2.2 COLlaborative DECISION-MAKING</h3>
<p>This stage engages expert agents in collaborative decision-making. To facilitate effective decisionmaking, previous research has investigated the impact of different communication structures among agents (Chan et al., 2023; Zhang et al., 2023b; Wu et al., 2023). We focus on two typical communication structures: horizontal structure and vertical structure, respectively.
Horizontal Structure ( $\square$ In this democratic structure, each agent, denoted as $m_{i} \in \mathcal{M}$, shares and refines its decision $a_{m_{i}}$. The group's collective decision, $A=f\left(\left{a_{m_{i}}\right}<em k="k">{i}\right) \in \mathcal{A}$, emerges as an integration of individual agents' decisions using a function $f$, which might involve techniques like summarization or ensemble. This structure is especially effective in scenarios like consulting and tool using.
Vertical Structure ( $\square$ Conversely, vertical structure has a clear division of roles. An agent, termed the solver $m^{<em>}$, proposes an initial decision $a_{0}^{</em>}$. Other agents, as reviewers, provide feedback on this proposal, prompting iterative refinements by the solver until a consensus is reached among reviewers or a set number of iterations is exhausted. The final decision $A$ is given as $A=a</em>$, with $k$ indicating the number of refinements. Vertical structure is preferable for tasks like math problem-solving and software development, where only one refined decision is required.}^{*} \in \mathcal{A</p>
<h3>2.3 ACTION EXECUTION</h3>
<p>In the decision-making stage, agents collaboratively contribute to a group decision $A$ containing actions that need to be executed in the current environment. Within the action execution stage, agents then execute the collectively-decided actions in the environment. Depending on the implementation, some agents might not perform any execution. As a result of these actions, the state of the environment transitions from $s_{\text {old }}$ to $s_{\text {new }}=\mathcal{T}\left(s_{\text {old }}, A\right)$.</p>
<p>Table 1: The results on different tasks that evaluate the agents’ general capabilities.</p>
<p>| Task | GPT-3.5-Turbo | | | GPT-4 | | |
| | CoT | Solo | Group | CoT | Solo | Group |
| --- | --- | --- | --- | --- | --- | --- |
| Conversation (FED) | 81.6 | 81.1 | 85.1 | 95.4 | 95.8 | 96.8 |
| Creative Writing (Commongen-Challenge) | 76.6 | 93.6 | 92.3 | 95.9 | 99.0 | 99.1 |
| Mathematical Reasoning (MGSM) | 80.4 | 82.4 | 80.8 | 95.2 | 96.0 | 95.2 |
| Logical Reasoning (Logic Grid Puzzles) | - | - | - | 59.5 | 64.0 | 66.5 |</p>
<h1>2.4 Evaluation</h1>
<p>The evaluation stage is vital for AGENTVERSE, guiding improvements for subsequent rounds. At this stage, the feedback mechanism $\mathcal{R}$ assesses the difference between the current state $s_{\text {new }}$ and the desired goal $g \in G$. It then offers verbal feedback $r=\mathcal{R}\left(s_{\text {new }}, g\right)$, detailing areas of shortcoming and suggesting ways to enhance performance. $\mathcal{R}$ can either be defined by humans (in a human-in-the-loop (Amershi et al., 2014) setting) or an agent for automatic feedback, depending on the implementation.</p>
<p>If the goal $g$ remains unmet, the feedback $r$ returns to the initial expert recruitment stage. In the next round, the expert recruitment stage will consider both feedback $r$ and the goal $g$ to adjust the group’s composition, aiming to evolve a more effective multi-agent group according to the current progress.</p>
<h2>3 EXPERIMENTS</h2>
<p>To validate the superiority of AGENTVERSE in facilitating agent collaboration over standalone agents, we design four experimental tasks. Each task is designed to assess distinct aspects of an agent group: general understanding and reasoning capabilities, coding capabilities, tool utilization capabilities, and their potential in Embodied AI. Our findings, which are detailed in this section, consistently highlight the superior performance of AGENTVERSE across these varied and multi-faceted tasks. Of particular interest is the emergence of unique collaborative behaviors within agent groups. While this section focuses on the advantages of multi-agent setups, a deeper exploration of these emergent behaviors will be presented in Section 4.</p>
<p>Setups. In all the experiments, we evaluate the performance of agents driven by GPT-3.5-Turbo0613 and GPT-4-0613 across various tasks. All the experiments are done in zero-shot setting. For all the quantitative experiments in this section, we compare three settings: (1) CoT: The CoT(chain-of-thought) agent; (2) Solo: Using AGENTVERSE with a single agent in the decisionmaking stage. Compared with CoT, Solo additionally incorporates the expert recruitment, action execution, and evaluation modules; (3) Group: Implementing AGENTVERSE with multiple agents collaborating during the decision-making. More detailed experimental setups for each task can be found in Appendix A.</p>
<h3>3.1 GENERAL UNDERSTANDING AND REASONING CAPABILITIES</h3>
<p>To assess the agents’ general understanding and reasoning capabilities, we use four datasets: FED (Mehri \&amp; Eskénazi, 2020), Commongen Challenge (Madaan et al., 2023), MGSM (Shi et al., 2023), and Logic Grid Puzzles (Srivastava et al., 2022). Detailed descriptions of these datasets and metrics can be found in Appendix A. The first two datasets are used to measure the agents’ text understanding and creative writing abilities, while the latter two focus on examining the agents’ reasoning abilities, including mathematical and logical reasoning.</p>
<p>Experimental Results. The results in Table 1 show that agents assembled by AGENTVERSE (Solo and Group setups) consistently outperform the standalone CoT agent, irrespective of the LLM used. In our preliminary evaluations, GPT-3.5-Turbo struggles with accurately handling the logic grid puzzles dataset; therefore, we omit the result of GPT-3.5-Turbo on logical reasoning.</p>
<p>Interestingly, for GPT-3.5-Turbo, the Group setup underperforms the Solo setup in two of three tasks, indicating that the discussion in decision-making might adversely impact performance for agents based on GPT-3.5-Turbo in certain contexts. Delving deeper into this observation, one predominant factor surfaces: the susceptibility to erroneous feedback. A recurring pattern observed in the Group</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The illustration of an example process of consulting. The task is to give some suggestions on building a compressed hydrogen storage station in Ohio.
setup is that: sometimes Agent A, despite starting with a correct answer, would be easily swayed by Agent B's incorrect feedback. Roughly $10 \%$ of errors in the MGSM dataset can be traced to this dynamic. Notably, this phenomenon is absent in GPT-4-based agents, highlighting the importance of agents' resilience to conflicting information during collaborative discussions.</p>
<p>Overall, the results show that AGENTVERSE effectively enhances the general understanding and reasoning capabilities of agents. Moreover, agents driven by advanced LLMs demonstrate better performance when engaged in collaborative decision-making. The nuanced challenges observed with GPT-3.5-Turbo indicate the need to improve LLMs' robustness on incorrect information so that the collaboration can amplify individual strengths without introducing new vulnerabilities.</p>
<p>Case Study: Consulting. In Table 1, the Group setup does not show a clear advantage over the Solo setup for both LLMs. This is mainly because the evaluation metrics for each benchmark have a limited scope. In the following case, we highlight the benefits of the group formed by GPT-4 agents by focusing on a consulting scenario where the group acts as a consultancy, responding to inquiries as shown in Figure 2. The goal is to offer suggestions for a hydrogen storage station in Ohio.
At first glance, the Solo setup seems to cover a broader scope than the Group setup at round 0. However, the Group setup offers more depth thanks to the recruited experts. For instance, while the Solo setup might suggest something basic like "Find an optimal location", the Group setup provides detailed advice, such as "evaluating site soil properties to ensure storage tank stability." By the second round, different experts offer new insights in the Group setup. As a result, the Group setup not only covers a broader range (highlighted in red in the referenced figure) but also gives more detailed advice. For a detailed look at agent interactions, see Appendix F.</p>
<h1>3.2 CODING CAPABILITIES</h1>
<p>In this section, we first assess the agents' coding capabilities using the Humaneval code completion dataset. Next, through a case study, we illustrate how collaboration among multiple agents improves output quality, highlighting its superiority over software development by just one agent.</p>
<p>Experimental Results. In Table 2, we see a clear performance improvement moving from CoT to Solo and then to Group setup. This trend is especially pronounced with GPT-4, which sees a performance boost from 83.5 to 89.0. These results highlight AGENTVERSE's effectiveness in managing a skilled group of agents for coding. For GPT-3.5-Turbo, although we have observed a drop</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The illustration of an example process of developing a calculator with GUI in Python.
in performance with Group setup in Section 3.1 due to incorrect agent feedback in math reasoning, the coding evaluations show benefits. We posit that this might be attributed to LLMs' extensive pre-training on codes, potentially rendering them more adept at coding than mathematical reasoning and, consequently, more resilient to erroneous information in coding.</p>
<p>Table 2: The pass@1 on Humaneval.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Setting</th>
<th style="text-align: center;">GPT-3.5-Turbo</th>
<th style="text-align: center;">GPT-4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">83.5</td>
</tr>
<tr>
<td style="text-align: left;">Solo</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">87.2</td>
</tr>
<tr>
<td style="text-align: left;">Group</td>
<td style="text-align: center;">$\mathbf{7 5 . 6}$</td>
<td style="text-align: center;">$\mathbf{8 9 . 0}$</td>
</tr>
</tbody>
</table>
<p>Case Study: Software Development. Our examination of the code generated for Humaneval by the Group setup in AGENTVERSE offers benefits beyond mere correctness. The agent group refines solutions, yielding more efficient, robust, and secure algorithms that are not covered by simple pass@1 metric. To better elucidate these advantages, we present a case study with GPT-4 on software development, a domain requiring multifaceted collaboration and refinement.
We present an example where AGENTVERSE creates a Python-based calculator GUI by bringing together diverse expert agents. A concise development process overview is visualized in Figure 3. Comparing the applications from the Group and Solo setups reveals notable distinctions. Both achieve core functionality, but the Group-created calculator boasts a user-friendly interface with features like color distinctions and keyboard input. This improved design resulted from the diverse feedback of the multi-agent group. Suggestions from UI designer and evaluators enhance the user experience, while software tester enhances code robustness. A deeper examination of the code confirms that the multi-agent group's output excels in exception handling compared to that of a solo agent. The codes generated by the two setups and the complete progress can be seen at Appendix F.</p>
<h1>3.3 TOOL UTILIZATION CAPABILITIES</h1>
<p>The capability of LLMs to use real-world tools has been emphasized in many recent studies (Schick et al., 2023a; Qin et al., 2023a). By equipping the LLMs with different tools such as a calculator, a web browser, and a code interpreter, the capabilities of LLMs can be significantly improved. In this section, we demonstrate that AGENTVERSE enables a group of agents to address intricate and multi-faceted tasks that require interaction with multiple tools, thereby enhancing work efficiency.</p>
<p>Experimental Results. We design a set of 10 intricate tasks, each requiring the use of at least two distinct tools to accomplish. By providing agents access to several tools, including Bing search API, a web browser, a code interpreter, and task-related APIs, we explore how AGENTVERSE facilitates agent collaboration, dissects the overarching task into manageable sub-tasks, and effectively deploys the available tools to address realistic user queries. Of the $\mathbf{1 0}$ challenging tasks provided, an agent group orchestrated by AGENTVERSE adeptly accomplishes $\mathbf{9}$ tasks. On the other hand, a standalone ReAct agent (Yao et al., 2023b), which is a prevalent agent designed for tool using, can only fulfill $\mathbf{3}$ tasks. In 6 out of 7 tasks where the single ReAct agent fails, the agent does not adhere to one or more criteria detailed in the task, and exit earlier than expected. We refer interested readers to Appendix B for a comprehensive comparison of the solutions given by AGENTVERSE and a single ReAct agent.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: An example process of multi-agent solving user query with three different tools.</p>
<p>Case Study: Solving 24-Point Game and Providing Similar Games. Here, we present an example in Figure 4, illustrating how AGENTVERSE searches for the rules of 24-point game, implements the code along with test cases, and explores similar games. The task is multifaceted; thus, during decision-making stage, the agents split the task into two sub-tasks in their discussion, and each assigned to a certain agent. While agent Charlie overlooks the sub-task of identifying games similar to the 24 -point game in round 0 , feedback from the evaluation module rectifies this in the subsequent iteration. Ultimately, the agent group provides not only the 24 -point game rules and a solving code with test cases, but also a summary of a similar game. In contrast, a standalone ReAct agent merely provides the game's definition along with a code and omits the query for similar games.</p>
<h1>4 Emergent Behaviors within a Multi-agent Group</h1>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: An illustration of the collaborative process involving three agents crafting a bookshelf. The process begins with the decision-making and breaking down the goal into several sub-tasks, with each agent receiving an assignment. The execution results and the current environmental state are then passed to the evaluator. This process repeats until the goal of crafting a bookshelf is achieved.</p>
<p>In the preceding section, the efficacy of AGENTVERSE has been illustrated across a spectrum of tasks that necessitate multi-agent decision-making, especially for GPT-4-based agents. Our endeavor, however, surpasses just improvements on benchmark datasets. We delve deeper into emergent collaborative behaviors exhibited by agents within realistic, embodied AI contexts. Minecraft, a sandbox game, serves as an ideal platform for such exploration due to its intricate parallelisms with real-world dynamics. In the game, agents must not just execute tasks but also plan, coordinate, and adjust to evolving situations. We task agents with collaboratively crafting a variety of items, spanning from paper and paintings to books and bookshelves. A succinct figure showcasing three agents adeptly crafting a bookshelf can be viewed in Figure 5. An elaborate visualization is placed at Appendix F, and details of the setups can be found in Appendix C.</p>
<p>By examining the decision-making process, we identify several emergent behaviors and categorize them into three aspects: volunteer, conformity, and destructive behaviors. Note that these behaviors not necessarily only appear in Minecraft but also in previous experiments such as tool utilization.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Examples of the properties emerge in the agent interactions in Minecraft.</p>
<h1>4.1 VOLUNTEER BEHAVIORS</h1>
<p>Volunteer behaviors refer to actions intended to enhance the benefits of others in human society (Omoto \&amp; Snyder, 1995; Mowen \&amp; Sujan, 2005). We observe similar behaviors emerging in a multi-agent group as follows:</p>
<p>Time Contribution. The agents are willing to contribute their unallocated time to enhance collaboration efficiency. As shown in the examples in Figure 6 (1a), Alice and Bob need to collaboratively craft 2 paper, which necessitates three sugar canes as the raw material. Initially, Alice proposes that she will collect the sugar canes while Bob waits until the materials are ready. However, this plan is suboptimal, as it offers Bob spare time. Recognizing inefficiency, Bob suggests that both gather sugar canes concurrently, leading to expedited task completion.</p>
<p>Resource Contribution. Our analysis reveals that the agents are willing to contribute the possessed materials. As illustrated in Figure 6 (1b), at the end of the task crafting 2 paper, Alice has collected all the raw materials (sugar canes), whereas Bob possesses the crafting table essential for the paper's creation. In the decision-making stage, Alice suggests transferring her materials to Bob by dropping them on the ground. This enables Bob to utilize them for the intended crafting process.</p>
<p>Assistance Contribution. In the process of accomplishing tasks, we observe that agents, upon completing their individual assignments, actively extend support to their peers, thereby expediting the overall task resolution. As shown in Figure 6 (1c), Alice and Bob have successfully completed their assigned sub-tasks, while Charlie is still struggling to gather three leathers. During the collaborative decision-making phase, Alice and Bob propose to assist Charlie in gathering.</p>
<p>These behaviors highlight how agents willingly contribute their capabilities and efforts to assist other agents, culminating in an accelerated achievement of their mutual goal.</p>
<h1>4.2 CONFORMITY BEHAVIOR</h1>
<p>In human society, individuals tend to adjust their behavior to align with the norms or goals of a group (Cialdini \&amp; Goldstein, 2004; Cialdini \&amp; Trost, 1998), which we refer to as conformity behavior. We also observe similar behaviors within multi-agent groups. As shown in Figure 6 (2), all agents are asked to gather three pieces of leather. However, Charlie gets sidetracked and begins crafting items that do not contribute directly to the task. In the subsequent decision-making stage, Alice and Bob critique Charlie's actions. Charlie acknowledges his mistake and re-focuses on the mutual tasks. The conformity behavior enables agents to align with mutual goals as work progresses.</p>
<h3>4.3 DESTRUCTIVE BEHAVIOR</h3>
<p>Additionally, we have also observed that agents may exhibit behaviors aimed at achieving greater efficiency, which could raise safety concerns. As depicted in Figure 6 (3a) and Figure 6 (3b), an agent occasionally bypasses the procedure of gathering raw materials and resorts to harming other agents or destroying an entire village library to acquire the necessary materials.</p>
<p>With advancements in autonomous agents, deploying them in real-world scenarios has become increasingly plausible. However, the emergence of hazardous behaviors could pose risks, especially when humans are involved in collaborative processes. Thus, designing strategies to prevent agents from adopting such hazardous behaviors is a critical area for future research.</p>
<h2>5 Related Work</h2>
<p>Autonomous Agents. The pursuit of creating autonomous agents that can operate intelligently in real-world environments without human involvement has been a persistent goal throughout the history of AI (Wooldridge \&amp; Jennings, 1995; Minsky, 1988; Bubeck et al., 2023). Recently LLMs (Touvron et al., 2023a; OpenAI, 2023a) have opened up new opportunities to achieve this goal. These LLMs possess remarkable understanding, reasoning, and generation capabilities, allowing autonomous agents to utilize them as a backbone for handling increasingly complex scenarios (Richards \&amp; et al., 2023; Nakajima, 2023; Reworkd, 2023; Liu et al., 2023). However, even though these autonomous agents already demonstrate considerable power, they still lack certain essential human-analogous cognitive capabilities. Hence, some research designs external mechanisms that endow agents with reflection (Yao et al., 2023b; Shinn et al., 2023), task decomposition (Wei et al., 2022b; Yao et al., 2023a), and tool utilization/creation (Schick et al., 2023b; Qin et al., 2023a;b; Qian et al., 2023b) capabilities, which bring autonomous agents closer to achieving artificial general intelligence.</p>
<p>Multi-agent System. In human society, a well-organized group composed of individual humans can often collaboratively handle a greater workload and accomplish complex tasks with higher efficiency and effectiveness. In the field of AI, researchers draw inspiration from human society and aim to enhance work efficiency and effectiveness by leveraging cooperation among individuals through the study of multi-agent systems (MAS) (Stone \&amp; Veloso, 2000), also referred to as a multi-agent group in this paper. The multi-agent group collaboratively makes decisions and executes corresponding actions in a distributed and parallel manner to achieve the common goal, which significantly improves work efficiency and effectiveness. Previous works have leveraged multi-agent joint training to achieve this goal. Recently, some studies have attempted to leverage the intelligence and capabilities of agents for autonomous collaboration. Li et al. (2023) have conceptualized assemblies of agents as a group, and focused on exploring the potential of their cooperation. Park et al. (2023) found social behaviors autonomously emerge within a group of agents, and Du et al. (2023); Wang et al. (2023b); Zhang et al. (2023a); Qian et al. (2023a); Chan et al. (2023) further leverage multi-agent cooperation to achieve better performance on reasoning tasks. Based on these findings, we introduce a framework, denoted as AGENTVERSE, capable of leveraging group cooperation to manage more intricate scenarios. This framework can dynamically adjust its composition according to the current state, aiming to facilitate optimal decision-making and execution.</p>
<h1>6 CONCLUSION</h1>
<p>In this study, we present AGENTVERSE, a novel and general multi-agent framework designed to emulate human group problem-solving processes. Our comprehensive experimental results highlight the efficacy of AGENTVERSE, demonstrating its enhanced performance in comparison to individual agents across a myriad of tasks. These tasks encompass general understanding, reasoning, coding, and tool utilization. Notably, AGENTVERSE consistently delivers remarkable results in addressing intricate user queries when fortified with the appropriate tools. In our investigations within the Minecraft environment, we identify both positive and negative emergent social behaviors among agents. As advancements in artificial general intelligence progress, understanding multi-agent interactions should become increasingly crucial. AGENTVERSE serves as a valuable step toward this endeavor, and we are optimistic about its potential adaptability and refinement for a wider array of tasks and contexts in the future.</p>
<h2>REFERENCES</h2>
<p>Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alexander Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil J. Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, and Mengyuan Yan. Do as I can, not as I say: Grounding language in robotic affordances. CoRR, abs/2204.01691, 2022. doi: 10.48550/arXiv.2204.01691. URL https://doi.org/10.48550/arXiv.2204.01691.</p>
<p>Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza. Power to the people: The role of humans in interactive machine learning. AI Magazine, 35(4):105-120, Dec. 2014. doi: 10.1609/aimag.v35i4.2513. URL https://ojs.aaai.org/aimagazine/index.php/ aimagazine/article/view/2513.</p>
<p>Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernández Ábrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan A. Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vladimir Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, and et al. Palm 2 technical report. CoRR, abs/2305.10403, 2023. doi: 10.48550/arXiv.2305.10403. URL https://doi.org/10.48550/arXiv.2305.10403.
J.D. Bransford and B.S. Stein. The Ideal Problem Solver: A Guide for Improving Thinking, Learning, and Creativity. W.H. Freeman, 1993. ISBN 978-0-7167-2205-2. URL https://books. google.com.tw/books?id=nnRxQgAACAAJ.</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott M. Lundberg, Harsha Nori, Hamid Palangi, Marco Túlio Ribeiro, and Yi Zhang. Sparks of artificial general intelligence: Early experiments with GPT-4. CoRR, abs/2303.12712, 2023. doi: 10.48550/arXiv.2303.12712. URL https://doi.org/10. 48550/arXiv.2303.12712.</p>
<p>Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better llm-based evaluators through multi-agent debate, 2023. URL https://doi.org/10.48550/arXiv.2308.07201.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,</p>
<p>Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021. URL https://arxiv. org/abs/2107.03374.</p>
<p>Robert B Cialdini and Noah J Goldstein. Social influence: Compliance and conformity. Annu. Rev. Psychol., 55:591-621, 2004. URL https://www.annualreviews.org/doi/abs/10. 1146/annurev.psych.55.090902.142015.</p>
<p>Robert B Cialdini and Melanie R Trost. Social influence: Social norms, conformity and compliance. 1998. URL https://psycnet.apa.org/RECORD/1998-07091-021.</p>
<p>Jeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence. CoRR, abs/1905.10985, 2019. URL http://arxiv.org/abs/1905.10985.</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. CoRR, abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.</p>
<p>Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, and Pete Florence. Palm-e: An embodied multimodal language model. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pp. 8469-8488. PMLR, 2023. URL https://proceedings. mlr.press/v202/driess23a.html.</p>
<p>Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. CoRR, abs/2305.14325, 2023. doi: 10.48550/arXiv.2305.14325. URL https://doi.org/10.48550/arXiv.2305.14325.</p>
<p>Ernst Fehr and Simon Gächter. Cooperation and punishment in public goods experiments. American Economic Review, 90(4):980-994, 2000. URL https://pubs.aeaweb.org/doi/pdf/ 10.1257/aer.90.4.980.</p>
<p>Ben Goertzel and Cassio Pennachin. Artificial general intelligence, volume 2. Springer, 2007. URL https://link.springer.com/book/10.1007/978-3-540-68677-4.</p>
<p>Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. CAMEL: communicative agents for "mind" exploration of large scale language model society. CoRR, abs/2303.17760, 2023. doi: 10.48550/arXiv.2303.17760. URL https://doi.org/10. 48550/arXiv.2303.17760.</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. Agentbench: Evaluating llms as agents, 2023.</p>
<p>Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative refinement with self-feedback. CoRR, abs/2303.17651, 2023. doi: 10.48550/arXiv.2303.17651. URL https://doi.org/10.48550/arXiv.2303.17651.</p>
<p>Shikib Mehri and Maxine Eskénazi. Unsupervised evaluation of interactive dialog with dialogpt. In Olivier Pietquin, Smaranda Muresan, Vivian Chen, Casey Kennington, David Vandyke, Nina Dethlefs, Koji Inoue, Erik Ekstedt, and Stefan Ultes (eds.), Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGdial 2020, 1st virtual meeting, July 1-3, 2020, pp. 225-235. Association for Computational Linguistics, 2020. URL https://aclanthology.org/2020.sigdial-1.28/.</p>
<p>Marvin Minsky. The Society of Mind. Simon \&amp; Schuster, 1988. ISBN 0671657135. URL https : //jmvidal.cse.sc.edu/lib/minsky88a.html.</p>
<p>John C Mowen and Harish Sujan. Volunteer behavior: A hierarchical model approach for investigating its trait and functional motive antecedents. Journal of consumer psychology, 15(2):170182, 2005. URL https://myscp.onlinelibrary.wiley.com/doi/abs/10.1207/ s15327663jcp1502_9.</p>
<p>Yohei Nakajima. Babyagi. 2023. URL https://github.com/yoheinakajima/babyagi. [Software].</p>
<p>Allen M Omoto and Mark Snyder. Sustained helping without obligation: motivation, longevity of service, and perceived attitude change among aids volunteers. Journal of personality and social psychology, 68(4):671, 1995. URL https://psycnet.apa.org/record/ 1995-26640-001.</p>
<p>OpenAI. GPT-4 technical report. CoRR, abs/2303.08774, 2023a. doi: 10.48550/arXiv.2303.08774. URL https://doi.org/10.48550/arXiv.2303.08774.</p>
<p>OpenAI. Chatgpt can now see, hear, and speak, 2023b. URL https://openai.com/blog/ chatgpt-can-now-see-hear-and-speak.</p>
<p>Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior. CoRR, abs/2304.03442, 2023. doi: 10.48550/arXiv.2304.03442. URL https://doi.org/10. 48550/arXiv.2304.03442.</p>
<p>Katherine Phillips and Charles O'Reilly. Demography and diversity in organizations: A review of 40 years of research. Research in Organizational Behavior, 20:77-140, 01 1998. URL https://www.researchgate.net/publication/234022034_Demography_ and_Diversity_in_Organizations_A_Review_of_40_Years_of_Research.</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development. CoRR, abs/2307.07924, 2023a. doi: 10.48550/arXiv.2307.07924. URL https://doi.org/10.48550/arXiv.2307.07924.</p>
<p>Cheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. CREATOR: disentangling abstract and concrete reasonings of large language models through tool creation. CoRR, abs/2305.14318, 2023b. doi: 10.48550/arXiv.2305.14318. URL https://doi.org/10. 48550/arXiv.2305.14318.</p>
<p>Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and Maosong Sun. Tool learning with foundation models. CoRR, abs/2304.08354, 2023a. doi: 10.48550/arXiv.2304.08354. URL https://doi.org/10.48550/arXiv. 2304.08354.</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023b. URL https://arxiv.org/abs/2307.16789.</p>
<p>Reworkd. Agentgpt, 2023. URL https://github.com/reworkd/AgentGPT. [Software].</p>
<p>Toran Bruce Richards and et al. Auto-gpt: An autonomous gpt-4 experiment, 2023. URL https: //github.com/Significant-Gravitas/Auto-GPT. [Software].</p>
<p>Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz, and Zeynep Akata. In-context impersonation reveals large language models' strengths and biases. CoRR, abs/2305.14930, 2023. doi: 10.48550/arXiv.2305.14930. URL https://doi.org/10.48550/arXiv.2305.14930.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. CoRR, abs/2302.04761, 2023a. doi: 10.48550/arXiv.2302.04761. URL https: //doi.org/10.48550/arXiv.2302.04761.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. CoRR, abs/2302.04761, 2023b. doi: 10.48550/arXiv.2302.04761. URL https: //doi.org/10.48550/arXiv.2302.04761.</p>
<p>Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models are multilingual chain-of-thought reasoners. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/pdf?id=fR3wGCk-IXp.</p>
<p>Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning, 2023. URL https: //doi.org/10.48550/arXiv.2303.11366.</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. CoRR, abs/2206.04615, 2022. doi: 10.48550/arXiv.2206.04615. URL https://doi.org/10. 48550/arXiv. 2206.04615.</p>
<p>Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel M. Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F. Christiano. Learning to summarize with human feedback. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/ 1f89885d556929e98d3ef9b86448f951-Abstract.html.</p>
<p>Peter Stone and Manuela Veloso. Multiagent systems: A survey from a machine learning perspective. Auton. Robots, 8(3):345-383, jun 2000. ISSN 0929-5593. doi: 10.1023/A:1008942012299. URL https://doi.org/10.1023/A:1008942012299.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971, 2023a. doi: 10.48550/arXiv.2302.13971. URL https://doi. org/10.48550/arXiv.2302.13971.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar</p>
<p>Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288, 2023b. doi: 10.48550/arXiv.2307.09288. URL https://doi.org/ 10.48550/arXiv. 2307.09288 .</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. CoRR, abs/2305.16291, 2023a. doi: 10.48550/arXiv.2305.16291. URL https://doi.org/ 10.48550/arXiv. 2305.16291 .</p>
<p>Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration. CoRR, abs/2307.05300, 2023b. doi: 10.48550/arXiv.2307.05300. URL https: //doi.org/10.48550/arXiv.2307.05300.</p>
<p>Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022a. URL https://openreview.net/forum?id= gEZrGCozdqR.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In NeurIPS, 2022b. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html.</p>
<p>Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek, and Mojtaba Komeili. Multi-party chat: Conversational agents in group settings with humans and models. CoRR, abs/2304.13835, 2023. doi: 10.48550/arXiv.2304.13835. URL https://doi.org/10. 48550/arXiv. 2304.13835 .</p>
<p>Michael J. Wooldridge and Nicholas R. Jennings. Intelligent agents: theory and practice. Knowl. Eng. Rev., 10(2):115-152, 1995. doi: 10.1017/S0269888900008122. URL https://doi.org/10. 1017/S0269888900008122.</p>
<p>Anita Williams Woolley, Christopher F. Chabris, Alex Pentland, Nada Hashmi, and Thomas W. Malone. Evidence for a collective intelligence factor in the performance of human groups. Science, 330(6004):686-688, 2010. doi: 10.1126/science.1193147. URL https://www.science. org/doi/abs/10.1126/science. 1193147 .</p>
<p>Anita Williams Woolley, Ishani Aggarwal, and Thomas W. Malone. Collective intelligence and group performance. Current Directions in Psychological Science, 24(6):420-424, 2015. doi: 10.1177/0963721415599543. URL https://doi.org/10.1177/0963721415599543.</p>
<p>Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multiagent conversation framework, 2023. URL https://doi.org/10.48550/arXiv. 2308. 08155 .</p>
<p>Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. CoRR, abs/2305.10601, 2023a. doi: 10.48550/arXiv.2305.10601. URL https://doi.org/10. 48550/arXiv. 2305.10601 .</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023b. URL https://openreview.net/pdf?id=WE_vluYUL-X.</p>
<p>Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B. Tenenbaum, Tianmin Shu, and Chuang Gan. Building cooperative embodied agents modularly with large language models. CoRR, abs/2307.02485, 2023a. doi: 10.48550/arXiv.2307.02485. URL https: //doi.org/10.48550/arXiv.2307.02485.</p>
<p>Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, and Yongbin Li. Wider and deeper llm networks are fairer llm evaluators. arXiv preprint arXiv:2308.01862, 2023b. URL https://doi.org/10.48550/arXiv.2308.01862.</p>
<p>Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig. Webarena: A realistic web environment for building autonomous agents. CoRR, abs/2307.13854, 2023. doi: 10.48550/arXiv.2307.13854. URL https://doi.org/10.48550/arXiv.2307.13854.</p>
<h1>A CONFIGURATIONS OF THE EXPERIMENTS</h1>
<p>Datasets and Evaluation Metrics Our evaluation assesses different aspects of agents, including general understanding and reasoning capabilities, coding capabilities and tool utilization capabilities.</p>
<ul>
<li>General Understanding Capabilities: We utilize two datasets. The first one is a Dialogue response dataset, FED (Mehri \&amp; Eskénazi, 2020), where given a multi-round chat history, the agent or agent group is required to generate the next chat. Following previous work (Madaan et al., 2023), we utilize GPT-4 as the evaluator to score the agent-generated response against the human-written ones, and report the agent's win rate. The second dataset is CommongenChallenge (Madaan et al., 2023), which is a constrained generation dataset where given 20 concepts, the agent is required to generate a coherent and grammatically correct paragraph containing as many concepts as possible. We report the average percentage of the covered concepts.</li>
<li>General Reasoning Capabilities: We utilize the English subset of MGSM (Shi et al., 2023), which is a subset of GSM-8k (Cobbe et al., 2021), to evaluate the agents' mathematical reasoning capabilities. It is a dataset containing grade school math problems. We report the percentage of the correct answers. And we use the logic grid puzzles task from BigBench (Srivastava et al., 2022), which contains logic problems that requires multi-step logic reasoning, to assess the agents' logical reasoning capabilities. We report the accuracy.</li>
<li>Coding Capabilities: We utilize Humaneval (Chen et al., 2021), which is a code completion dataset, and report Pass@1 metric ${ }^{1}$</li>
<li>Tool Utilization Capabilities: Since automatic evaluation on the performance of tool utilization is difficult, and there is currently no relevant benchmark, we craft 10 complex instructions and manually assess the performance. The instructions are listed in Appendix B.</li>
</ul>
<p>Expert Recruitment For tasks including dialogue response, code completion, and constrained generation, four agents is recruited into the system. For the task of mathematical reasoning, we limited the number to two agents. This decision was based on our observation that an increase in the number of reviewers for mathematical reasoning tasks correlates with a higher likelihood of them giving erroneous critiques, leading to incorrect solutions by the solver. We have a discussion on this topic in Section 3.1. For tool utilization, we recruit two or three agents to engage in collaborative decision-making and action execution depending on the specific task. The detailed setups are listed at Appendix B. Currently the number of experts is pre-defined by us for each task. We are seeking a way to automate this decision as well.</p>
<p>Collaborative Decision-Making For tasks in coding and general understanding and reasoning, we use the vertical structure because all these tasks require only one response as the answer, and the solver in the vertical structure can be responsible for answering. For tool utilization, we use the horizontal structure because the agents should clarify their own sub-tasks in the discussion.</p>
<p>Action Execution For the Humaneval code completion dataset benchmarked with GPT-4, we incorporate an additional agent during the action execution stage to craft unit testing code (in an zero-shot manner). Subsequently, the generated code is subjected to unit testing, and the testing results are conveyed as the environment state to the evaluation module.</p>
<p>Regarding the constrained generation dataset, Commongen-Challenge, the agent-generated response undergoes a concept coverage check. Any missing concepts are then passed to the evaluation module as the environment state.</p>
<p>In the context of tool utilization, each agent iteratively calls the tool in the ReAct manner, up to a maximum of 10 iterations. Upon reaching the final iteration, the agent is forced to draw a conclusion regarding the result, labeling the task's status as either "pending" or "finished". These conclusions are then forwarded to the evaluator for assessment.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Evaluation To facilitate a feedback loop, an agent was tasked with the role of evaluator. This agent, provided with the initial problem $p$ and the decisions $A$ made during the collaborative decisionmaking stage, is charged with determining the correctness of those decisions. In cases where the decision is identified as erroneous, feedback is channeled back to the expert recruitment stage. If the decision meets the accuracy criteria, it is determined as the final answer to $p$. While our current configuration employs an agent for evaluation, we acknowledge the potential of human evaluators and intend to incorporate such experiments in future endeavors.</p>
<h1>B EXPERIMENT Details for Multi-Agent Tool Using</h1>
<h2>B. 1 SEtuPS</h2>
<p>This section provides specific implementation details for enabling multiple agents in AGENTVERSE to collaboratively utilize tools to accomplish user's query. Unless specified herein, the implementation adheres to the standard procedures defined in the other experiments.</p>
<p>Collaborative Decision-Making Agents recruited during the Expert Recruitment stage engage in collaborative discussions regarding the assigned task using a horizontal communication structure. In this configuration, agents communicate in a predetermined sequential order. At the conclusion of their discussions, an additional agent is designated as the "summarizer" and is responsible for consolidating the discussed sub-tasks for each participant.</p>
<p>Action Execution During action execution, we follow the ReAct prompting technique to let the agents write down their thought, and then call the tool, and we return the tool response to the agent. The agent again write down the thought and call the tools. The process iterates until the agent decide to submit its conclusion, or a maximum iteration number, which we set to be 10 , is reached. In practice, we use OpenAI's function call to handle the tools.</p>
<h2>B. 2 ReSults</h2>
<p>For action execution, the ReAct prompting technique is employed. Agents articulate their thought process, invoke the respective tool, and subsequently receive feedback from the tool. This cycle of reflection and tool interaction continues iteratively. The process concludes either when the agent finalizes its execution with its conclusion or after a pre-set maximum number of iterations-set (10 in our experiments). We utilize OpenAI's function call to handle the tool calls.</p>
<p>Instruction 1 Recently, it has become popular in the AI field to verify the mathematical reasoning abilities of large language models by observing if they can solve the "24-Point Game." What is this game? Does it have a code-based solution? If it does, provide a Python code along with test cases and test its functionality. What are some other similar games that can be used to test the models' mathematical reasoning abilities?
Single ReAct Agent: (The generated code is omitted) The '24-Point Game' is a mathematical game where four numbers must be used with the basic arithmetic operations (addition, subtraction, multiplication, and division) to make the number 24. The Python code I developed generates all possible combinations of the four numbers and operations to find a solution that equals 24 . The code was tested with different sets of numbers, and it correctly identified whether a solution existed and what it was. This task tested my ability to understand the rules of a game and to develop and test a program that solves it. (game rule $\boldsymbol{\checkmark}$, code $\boldsymbol{\checkmark}$, similar games $\boldsymbol{\square}$ )
AGENTVERSE (2 agents): (The generated code is omitted) The "24-Point Game" is a mathematical game where four numbers must be used with the basic arithmetic operations (addition, subtraction, multiplication, and division) to make the number 24. A Python code was developed and tested that generates all possible combinations of the four numbers and operations to find a solution that equals 24 . The code was tested with different sets of numbers, and it correctly identified whether a solution existed and what it was. Similar games to the '24-Point Game' that can be used to test mathematical reasoning abilities include 'Make a Number' and 'Math Safe'. 'Make a Number' is a game where players are given 4 numbers and 4 operations and they have to use these to create a target number. 'Math Safe' is a game where players use four given single-digit numbers and any of</p>
<p>the four operations to reach a target number and open a safe. Both these games require the use of operations and logical thinking to reach a target number, similar to the '24-Point Game'. (game rule $\checkmark$, code $\checkmark$, similar games $\checkmark$ )</p>
<p>Instruction 2 (Additional API: Weather) I want to hold a party at somewhere around Tsinghua University tomorrow. I need you to look for some best places for holding a party nearby, and tell me whether the weather is good for holding a party tomorrow. Also, I want to know what activities can be considered in my party. Help me search the web.</p>
<p>Single ReAct Agent: There are several restaurants near Tsinghua University that could be good places for a party, including Lan Yang ShuFang, YiLan ShaoKao, Guan Shi JiChi, Dong Lai Shun, and Xibu Mahua Beef Noodle. The weather in Beijing tomorrow is expected to be overcast with a temperature of 26 degrees Celsius, which might be suitable for a party. Some activities that can be considered for the party include the Saran Wrap Game, Post It Note Game, Most Likely To, Never Have I Ever, Would You Rather, and many more. ( $\boldsymbol{\sim}$ )</p>
<p>AGENTVERSE (3 agents): The weather in the Tsinghua University area tomorrow is expected to be overcast with a temperature of 26 degrees Celsius, which is suitable for holding a party. The best places for a party near Tsinghua University include the Summer Palace, Wudaokou, Zhongguancun, and Peking University, as well as several restaurants nearby. For party activities, you could consider games such as the Saran Wrap Game, the Post It Note Game, How's Yours?, Most Likely To, Never Have I Ever, Would You Rather?, Heads Up!, I'm Hosting a Party..., Two Truths and a Lie, Sticker Stalker, Great Minds Think Alike, murder mystery games, Who Am I?, the Newlywed Game, Truth or Dare, Spoons, Pictionary, Kiss Marry Kill, the Don't Say Yes game, Cards Against Humanity, What Do You Meme, Drawing Without Dignity, and That's What She Said. These games are suitable for various party occasions and there are also suggestions for icebreakers for guests who don't know each other well. ( $\checkmark$ provide more details)</p>
<p>Instruction 3 (Additional API: Billboard) I'm currently analyzing what is popular on the website. Can you help me find the recent trending stuff. It could be anything, like trending news, products, books, movies, music, etc. Give a summarization for me.</p>
<p>Single ReAct Agent: The recent trending products on the web include Apple AirPods Pro, Diamond Dazzle Cleaner Pen, Ugg Slippers, Squishmallows, Winix Air Purifier, ThisWorx Car Vacuum Cleaner, All-Clad Cookware, Eufy Robot Vacuum, Renpho Eye Massager, Crocs, Throw blankets, Chuckit! Sport Dog Ball Launcher, Apple AirTags, Revlon Hair Dryer Brush, Lego Sets, KitchenAid Stand Mixer, Winc Wine Subscription, Saatva Mattress, Home Chef Subscription, and MasterClass Subscription. Unfortunately, we were unable to find specific information on recent trending books. (trending product $\checkmark$ )</p>
<p>AGENTVERSE (3 agents): Here is a summary of the trending topics on the website:
Music:</p>
<ol>
<li>'Heat Waves' by Glass Animals</li>
<li>'We Don’t Talk About Bruno' by Carolina Gaitan, Mauro Castillo, Adassa, Rhenzy Feliz, Diane Guerrero, Stephanie Beatriz \&amp; Encanto Cast</li>
<li>'Super Gremlin' by Kodak Black</li>
<li>'Slime You Out' by Drake Featuring SZA</li>
<li>'Paint The Town Red' by Doja Cat</li>
<li>'Snooze' by SZA</li>
</ol>
<p>Movies:</p>
<ol>
<li>'No One Will Save You'</li>
<li>'A Haunting in Venice'</li>
<li>'Expend4bles'</li>
</ol>
<p>Books:</p>
<ol>
<li>'The Midnight Library'</li>
<li>'The Invisible Life of Addie LaRue'</li>
<li>'The Seven Husbands of Evelyn Hugo'</li>
</ol>
<h1>Products:</h1>
<ol>
<li>Laser hair removal</li>
<li>Head scarfs</li>
<li>Detangling hair brushes</li>
<li>Hair wigs</li>
<li>Straight-leg jeans</li>
<li>Shapewear</li>
<li>Athleisure</li>
<li>Abdominal crunch straps</li>
<li>Swimsuits</li>
<li>Power tool accessories</li>
<li>Dog toys</li>
<li>Shot glasses</li>
<li>Costume shoes</li>
<li>Slipcovers</li>
<li>Wall plates and covers</li>
<li>Baby shirts</li>
<li>Curtain and drape rings</li>
<li>Cabinet knobs and handles</li>
<li>Watch accessories</li>
<li>Tumblers</li>
<li>Model train sets</li>
<li>Signage</li>
<li>Wedding dresses</li>
<li>Table runners</li>
</ol>
<p>Please note that the popularity of these items can vary based on the region and demographic of the consumers. (music $\boldsymbol{\sim}$, movie $\boldsymbol{\sim}$, books $\boldsymbol{\sim}$, products $\boldsymbol{\sim}$ )</p>
<p>Instruction 4 I'm planning a two-week vacation to Japan next month. Help me plan my itinerary. I want to visit Tokyo, Kyoto, and Osaka. Look for the top tourist attractions in each city, and also suggest the best mode of travel between these cities. Additionally, find out the weather forecast for the month I'll be visiting.</p>
<p>Single ReAct Agent: The top tourist attractions in Tokyo are the Tokyo Skytree, Senso-ji Temple, Meiji Shrine, Tokyo Disneyland, Ueno Park, and Odaiba. In Kyoto, the top attractions are Nijo Castle, Fushimi-Inari Taisha Shrine, Kinkaku-ji: The Golden Pavilion, Kiyomizu-dera Temple, Sanjūsangendō Temple, and Kyoto Imperial Palace. In Osaka, tourists can visit Osaka Castle, Shitennō-ji Temple, Osaka Aquarium Kaiyukan, Tempozan Ferris Wheel and Harbor Village, and Universal Studios Japan. These attractions offer a mix of historical, cultural, and modern experiences for visitors. (tourist attractions $\boldsymbol{\sim}$, best mode of travel between cities $\boldsymbol{\aleph}$, weather forecast $\boldsymbol{\aleph}$ )
AGENTVERSE (3 agents): Your two-week vacation to Japan is shaping up to be quite exciting. In Tokyo, you can visit the Tokyo Skytree, Senso-ji Temple, Meiji Shrine, Tokyo Disneyland and DisneySea, and the Odaiba area. In Kyoto, the top attractions are Nijo Castle, Fushimi-Inari Taisha Shrine, Kinkaku-ji (Golden Pavilion), Kiyomizu-dera Temple, and Sanjūsangen-dō Temple. While in Osaka, you should visit Osaka Castle, Shitennō-ji Temple, Osaka Aquarium Kaiyukan, and Universal Studios Japan.</p>
<p>As for transportation, the best way to travel between these cities is by train, specifically the Shinkansen bullet train. You can also consider flights with ANA or JAL, or if you're on a budget, the night bus or LCC flights by Jetstar and Peach.</p>
<p>Regarding the weather, it's difficult to provide an exact forecast for the next month, but we've gathered the average weather data for these cities based on previous years. Please remember to check the weather forecast closer to your departure date for a more accurate prediction. Enjoy your trip! (tourist attractions $\boldsymbol{\sim}$, best mode of travel between cities $\boldsymbol{\sim}$, weather forecast $\boldsymbol{\sim}$ )</p>
<p>Instruction 5 I am planning a date with my girlfriend this week, please search for a good movie theater and a restaurant near Tsinghua University in Beijing and recommend a good movie to watch. Please search the web.</p>
<p>Single ReAct Agent: Your date near Tsinghua University in Beijing is all set. For dining, you can choose from Lan Yang ShuFang, YiLan ShaoKao, Guan Shi JiChi (Zhongguancun), or Dong Lai Shun (Zhongguancun HaiTu). As for the movie, there are several highly-rated ones showing in 2023. Some of these include M3GAN, Plane, Missing, Infinity Pool, John Wick: Chapter 4, Creed III, Scream VI, Air, Suzume, Rise, Are You There God? It's Me, Margaret, Showing Up, and The Covenant. Enjoy your date! (restaurant $\boldsymbol{\checkmark}$, movie $\boldsymbol{\checkmark}$, theater $\boldsymbol{\mathcal { K }}$ )
AGENTVERSE (3 agents): Your date is all set! For dining, we recommend either Jiasuo Restaurant or Zijingyuan, both located conveniently on the Tsinghua University campus. For your movie, we suggest 'No Bears', which is currently popular and highly rated. You can watch it at the Maple Garden Drive-In Cinema, one of the top-rated movie theaters near Tsinghua University. Enjoy your date! (restaurant $\boldsymbol{\checkmark}$, movie $\boldsymbol{\checkmark}$, theater $\boldsymbol{\checkmark}$ )</p>
<p>Instruction 6 I want to kick off a book club with my friends. Can you tell me the top 5 bestselling books this month, gather the content summary for each, and find online platforms where we can buy or borrow them?</p>
<p>Single ReAct Agent: I was unable to find the top 5 bestselling books for October 2023. The websites I visited did not provide the required information. Therefore, I am unable to provide the content summary for each of the top 5 bestselling books and find online platforms where they can be bought or borrowed. ( $\boldsymbol{\aleph}$ )</p>
<p>AGENTVERSE (2 agents):The top 5 bestsellers this month can be bought or borrowed from several online platforms. These include OverDrive, which allows you to borrow books for free through your local library or school. Other platforms include the Amazon Kindle Store, Barnes \&amp; Noble's Nook Book Store, Fictionwise, eBooks.com, eReader.com, Google Play Book Store, Powell's Books, as well as eBook lending and borrowing services like eBookFling, Lendle, and BookLending.com. (online platforms $\boldsymbol{\checkmark}$, top 5 bestselling books $\boldsymbol{\aleph}$, content summary $\boldsymbol{\aleph}$ )</p>
<p>Instruction 7 I am planning to buy a new car. Could you help me compare the features and prices of the latest models of Tesla, Ford, and Toyota? Include details about range, charging time, safety features, and after-sales service. Also, provide a brief analysis of the pros and cons of each car.</p>
<p>Single ReAct Agent: The 2023 Tesla Model 3 starts at $\$ 41,880$ and goes up to $\$ 54,880$. It comes with standard features such as heated front seats, navigation, and Tesla's Autopilot semi-autonomous driving system. In terms of safety features, the Model 3 includes standard automated emergency braking, lane-departure warning, and adaptive cruise control. Tesla's after-sales service is characterized by a vertically integrated format that eliminates third-party intermediaries and relies on over-the-air (OTA) update capabilities and a mobile service fleet. The company's OTA update capabilities will open up new subscription-based aftersales revenue streams, while its closed-loop system allows access to vehicle data for driving-related feedback loops and predictive maintenance. (Tesla $\boldsymbol{\checkmark}$, Other brands $\boldsymbol{\aleph}$ )</p>
<p>AGENTVERSE (3 agents): The starting price for the 2023 Ford Mustang Mach-E is around \$43,895 and it takes approximately 38 hours to fully charge using a 120 V outlet, 14 hours using a 240 V outlet, and around 45 minutes to $80 \%$ capacity with DC fast charging. The starting price for the 2023 Toyota bZ4X is approximately $\$ 42,000$. The charging time varies depending on the method: 52 hours for Level 1 charging, 26 hours or 18.75 hours for Level 2 charging, and 30-45 minutes to $80 \%$ capacity for Level 3 DC fast charging. Unfortunately, the price for the 2023 Tesla Model 3 was not found, but the charging time can be as quick as 15 minutes with a 250 kW Tesla Supercharger. At home, using a standard 120-volt outlet takes around three to four days for a full charge, while a 240 -volt outlet with a NEMA 14-50 adapter reduces charging time to 10 or 11 hours. A Tesla Wall Connector can fully charge the car in about five hours.</p>
<p>In terms of safety, all three models come equipped with a variety of features such as anti-lock brakes, stability control, front-impact airbags, side impact airbags, overhead airbags, knee airbags, pretensioners, and a security system. The Tesla Model 3 also includes autopilot and collision warning features.</p>
<p>Regarding after-sales service, Tesla offers a comprehensive warranty and roadside assistance with service centers across the globe and mobile service. Toyota's after-sales service is known for being top-notch and continually improving with expert technicians and quality genuine parts. However, Ford's after-sales service has received negative reviews, with customers reporting poor customer support and inefficient handling of issues.</p>
<p>Please consider these factors when making your decision. (Prices $\boldsymbol{\checkmark}$, charging time, safety features, after-sales service)</p>
<p>Instruction 8 I've recently taken an interest in DIY home projects. Search for beginner-friendly DIY projects that can be completed over the weekend. Also, provide a list of materials required and a step-by-step guide for each project.</p>
<p>Single ReAct Agent: I found a variety of beginner-friendly DIY home projects from three different websites. These projects include painting a room, replacing cabinet pulls, repairing torn window screens, fixing interior doors, balancing furnace dampers, repairing leaky faucets, refreshing caulk in the bathroom, building garage storage shelves, constructing a fire pit, hanging a ceiling fan, installing a wall-mounted television, and cleaning out sink traps. These projects are suitable for beginners and can help improve DIY skills while boosting confidence. (DIY projects $\boldsymbol{\checkmark}$, list of materials $\boldsymbol{x}$ )</p>
<p>AGENTVERSE (2 agents): The team has successfully found a variety of beginner-friendly DIY home projects that can be completed over the weekend. These projects range from painting a room, replacing cabinet pulls, installing a wall-mounted television, building a fire pit, to more complex tasks like kitchen remodels and furniture updates. The materials required for these projects are basic and easy to source, including tools like a roller and pan for painting, a cordless drill for replacing cabinet pulls, a stud finder for installing a wall-mounted television, and concrete work tools for building a fire pit. Detailed, step-by-step guides for each project have been provided to ensure a smooth DIY experience. Happy DIY-ing! (DIY projects $\boldsymbol{\checkmark}$, list of materials $\boldsymbol{\checkmark}$ )</p>
<p>Instruction 9 Winter is coming, and I want to update my wardrobe. Search for the latest winter fashion trends for men and women. Also, suggest some online stores where I can buy trendy winter clothing.</p>
<p>Single ReAct Agent: The latest winter fashion trends for both men and women this year include suiting, bold shoulders, western touches, maxis, electric hues, bombers, mismatched maximalism, corseting, cut-outs, Y2K fashion, and chunky boots. You can purchase these trendy winter clothes at online stores like PrettyLittleThing and Windsor. (fashion trends $\boldsymbol{\checkmark}$, online stores $\boldsymbol{\checkmark}$ )</p>
<p>AGENTVERSE (3 agents): The latest winter fashion trends for men include a reinvention of classic staples, misery chic, pops of pink, throwback jackets, showstopping trousers, and Mac coats. For women, the trends include corseting, cowboy boots, Y2K styles, oversized outerwear, pleated skirts, and balaclavas. You can shop for these trendy winter clothes at popular online stores such as Uniqlo, Everlane, and Target. (fashion trends $\boldsymbol{\checkmark}$, online stores $\boldsymbol{\checkmark}$ )</p>
<p>Instruction 10 I want to lose 5 kg in the next 2 months. I weigh 70 kg , am 170 cm tall, and my age is 25 . Calculate my BMI and based on that, suggest a workout routine and daily calorie intake to help me achieve my goal.</p>
<p>Single ReAct Agent: Your BMI is 24.22 , which is within the normal range. To lose 5 kg in 2 months, you should aim for a daily calorie deficit of 500-1000 calories. This can be achieved through a combination of a balanced diet and regular exercise. Your diet should focus on whole foods, lean proteins, fruits, and vegetables. For exercise, a combination of cardio and strength training is recommended. Cardio exercises like running, cycling, swimming can help burn calories, while strength training exercises like weight lifting can help build muscle, which can increase your metabolic rate and aid in weight loss. Don't forget to get enough sleep and stay hydrated. (bmi $\boldsymbol{\checkmark}$, workout routine $\boldsymbol{\checkmark}$, daily calorie intake $\boldsymbol{\checkmark}$ )</p>
<p>AGENTVERSE (2 agents): Your Body Mass Index (BMI) is approximately 24.22, which is within the healthy weight range. To achieve your weight loss goal, you should aim to consume between 1400 and 1600 calories per day. This will create a calorie deficit necessary for weight loss. In terms of physical activity, you should start with a 4-week program that includes upper and lower body strength training, interval training/conditioning, and low intensity cardio exercises. After completing</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ The method for calculating Pass@1 differs from the approach in Chen et al. (2021). Instead of generating multiple responses and calculating an unbiased estimator, we directly employ the first response to compute the Pass@1.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>