<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5346 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5346</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5346</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-111.html">extraction-schema-111</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <p><strong>Paper ID:</strong> paper-0d502a1e300336ae628f5c8b99ee4d3766c8f60b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/0d502a1e300336ae628f5c8b99ee4d3766c8f60b" target="_blank">Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Inspired by the latest ChatGPT and Toolformer models, the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework is proposed to teach LLMs themselves with prompts augmented by ChatG PT to use external graph reasoning API tools.</p>
                <p><strong>Paper Abstract:</strong> In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}. To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools. Specifically, we will investigate to teach Graph-ToolFormer to handle various graph data reasoning tasks in this paper, including both (1) very basic graph data loading and graph property reasoning tasks, ranging from simple graph order and size to the graph diameter and periphery, and (2) more advanced reasoning tasks on real-world graph data, such as bibliographic networks, protein molecules, sequential recommender systems, social networks and knowledge graphs.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5346.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5346.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph-ToolFormer API Serialization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph-ToolFormer API-call Text Serialization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-to-text representation that embeds structured graph operations (data loading and graph-reasoning calls) directly into generated text as special API-call tokens (e.g., <API> ... </API> or [GL(...)]/[GR(...) -> r]). The LLM is fine-tuned to insert these API tokens at appropriate positions; parsed tokens are executed by external graph toolkits and optionally replaced by the returned results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>API-call serialization (API-annotated linearization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Graphs and graph reasoning requests are represented in text by inserting special API-call spans into natural language outputs. An API-call span has the form <API>f(args)</API> or <API>f(args) -> r</API>, and can be nested or sequential (e.g., <API>GR(GL("cora"), "graph-bert:topic", {Paper#1}) -> r</API>). Domains and functions are encoded as domain:function (e.g., toolx:density, graph-bert:topic), parameters may be explicit or defaulted, and special token substitutions (e.g., '[' and ']' for <API>, '->' for ->r) are used to avoid modifying the LM tokenizer.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Multiple: classic synthetic graphs (GPR toy graphs), bibliographic networks (Cora, Citeseer, Pubmed), molecular graphs (PROTEINS, MUTAG, NCI1, PTC), recommender bipartite graphs (Amazon, Last.FM, MovieLens), online social networks (Twitter, Foursquare), knowledge graphs (WordNet, Freebase).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_properties</strong></td>
                            <td>Faithfulness: representation defers actual graph computation to external toolkits and can insert exact computed results (-> r) back into text, so final textual answers can be faithful once API executed; Compactness: uses short API tokens instead of serializing entire adjacency lists; Interpretability: API calls explicitly name domain and property/function (domain:function) enabling straightforward parsing; Expressivity: supports nested and sequential calls, domain-qualified functions, and optional in-text result insertion; Information loss: the textual representation alone does not contain computed property values until API execution — raw semantics depend on the external tool; Ease of learning: amenable to fine-tuning LLMs with many annotated examples; Implementation constraint: avoids tokenizer changes by substituting special tokens with rare ASCII tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>Evaluated as part of graph reasoning pipelines across multiple downstream tasks: basic graph attribute computation (order, size, diameter, eccentricity, shortest paths), node classification (paper-topic inference on bibliographic networks), graph classification (molecular function prediction), link prediction / sequential recommendation (BPR-based recommendation scoring), community detection (KMeans-based clustering on social graphs), and knowledge-graph entity/relation reasoning (TransE-based inference). Also evaluated on the quality of LLM-generated API-annotated text (API insertion correctness).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported as numeric end-to-end scores in the provided text for the graph-to-text mapping itself; empirical dataset sizes and prompt dataset statistics are reported (e.g., GL prompt dataset ~2,803 pairs after filtering; many task-specific prompt counts appear in Table 3: Cora prompts 18,956; Citeseer 23,184; Pubmed 138,019; PROTEINS 6,678; Amazon 2,252,890; Freebase 1,695,651; etc.). The paper states "the LLMs can add the correct graph reasoning API calls into the output at the correct position for majority of the graph reasoning input statements," but no numeric accuracy or F1 values are provided in the excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_representations</strong></td>
                            <td>Compared qualitatively to prior Toolformer (Meta) approach which used a small set of simple APIs (Calendar, Calculator, WikiSearch), Graph-ToolFormer extends that idea to a much richer, domain-qualified API space and supports nested/sequential calls for complex graph tasks. Unlike serializing the entire graph into token sequences (full linearization), this approach keeps graph content external and only inserts concise API invocations into text. No quantitative head-to-head performance numbers vs other graph-to-text linearizations or Graph2Seq methods are given in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires reliable external graph toolkits and pre-trained graph models to compute values — the textual API token alone is not a self-contained answer; parsing nested API calls increases complexity; large API-function search space and similar function names can mislead the model; parameter extraction can be challenging (masked vs causal completion trade-offs); execution/validation requires runtime infrastructure (graph data hub, model hub, working memory); dependency on working memory caching capacity and eviction policy; the paper reports filtering of ChatGPT-generated annotations because some annotated API calls were non-runnable or returned incorrect results, indicating automatic annotation noise that must be filtered; no numeric evaluation of generation accuracy presented in excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5346.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5346.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for converting graphs into text for language model training, including details of the representation, properties, evaluation tasks, performance, and comparisons to other methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT Prompt Augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT-augmented Prompt Annotation and Dataset Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to convert graph tasks into training pairs for LLMs by using ChatGPT (gpt-3.5-turbo) to insert API-call annotations into human-written input sentences and to produce many rephrasings; outputs are post-validated by executing API calls and filtered, producing a large prompt dataset used to fine-tune causal LLMs to emit API-annotated text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>ChatGPT-annotated API-call prompt pairs (automatic graph-to-text example synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Human-written instructions and a handful of seed examples are provided to ChatGPT with a system role that instructs it to add API calls (e.g., [GL(...)] and [GR(...)->r]) into inputs at appropriate positions; ChatGPT also generates paraphrases of inputs to increase diversity. Generated input-output pairs are post-processed: non-runnable or incorrect API annotations are filtered by executing the corresponding API functions against local toolkits; the retained pairs form a fine-tuning dataset for LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Same diverse set as used by Graph-ToolFormer: synthetic graphs (GPR), bibliographic networks, molecular graphs, recommender graphs, social networks, knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_properties</strong></td>
                            <td>Scalability: enables generation of thousands to millions of annotated prompt pairs efficiently; Coverage: includes paraphrases to expand linguistic diversity; Validation: integrates execution-time filtering to keep only runnable/correct pairs, improving faithfulness of training data; Noise: initial ChatGPT outputs can include non-runnable or incorrect API annotations requiring filtering; Automation trade-off: reduces manual annotation but requires compute to validate API calls.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>Used to generate training data for fine-tuning LLMs to insert API-call annotations; downstream evaluation tasks mirror Graph-ToolFormer tasks (graph property Q&A, bibliographic topic inference, molecular function classification, recommender predictions, social community detection, knowledge graph queries). Also evaluated by running the generated API calls and comparing returned results to ground truth to filter bad samples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Dataset generation statistics reported: the graph loading generation attempt asked for 5000 pairs; after manual removal and proofreading ~2,803 graph loading API call input-output pairs were preserved. Table 3 lists prompt counts per task/dataset (examples: GL-Prompt 2,802; GPR-Prompt 2,587; Cora 18,956 prompts; Pubmed 138,019 prompts; Amazon 2,252,890 prompts; Freebase 1,695,651 prompts). No numeric metrics for LLM fine-tuning gains (e.g., precision/recall of API insertion) are reported in the provided excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_representations</strong></td>
                            <td>Compared to small-scale, hand-crafted prompt templates and to Toolformer-style synthetic API examples, this method uses a large-scale language model (ChatGPT) to produce many diverse, paraphrased API-annotated examples and then validates them by actual execution. The advantage is scale and linguistic diversity; the disadvantage is the need for execution-based post-filtering. No quantitative comparison (e.g., model performance using ChatGPT-augmented vs purely hand-crafted datasets) is reported in the excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Quality depends on ChatGPT outputs and on the correctness of pre-executed graph-toolkit responses; generation requires subsequent execution/validation stage which can be compute- and I/O-intensive; filtering removed a substantial fraction of generated pairs (e.g., 5,000 -> ~2,803 kept in one example), showing annotation noise; generated prompts are tied to the exact API surface and backend toolkits — changing backends requires regenerating/validating data or careful abstraction; potential licensing/costs when using ChatGPT for large-scale generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Toolformer: Language Models Can Teach Themselves to Use Tools <em>(Rating: 2)</em></li>
                <li>Translating Embeddings for Modeling Multi-relational Data <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5346",
    "paper_id": "paper-0d502a1e300336ae628f5c8b99ee4d3766c8f60b",
    "extraction_schema_id": "extraction-schema-111",
    "extracted_data": [
        {
            "name_short": "Graph-ToolFormer API Serialization",
            "name_full": "Graph-ToolFormer API-call Text Serialization",
            "brief_description": "A graph-to-text representation that embeds structured graph operations (data loading and graph-reasoning calls) directly into generated text as special API-call tokens (e.g., &lt;API&gt; ... &lt;/API&gt; or [GL(...)]/[GR(...) -&gt; r]). The LLM is fine-tuned to insert these API tokens at appropriate positions; parsed tokens are executed by external graph toolkits and optionally replaced by the returned results.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "API-call serialization (API-annotated linearization)",
            "representation_description": "Graphs and graph reasoning requests are represented in text by inserting special API-call spans into natural language outputs. An API-call span has the form &lt;API&gt;f(args)&lt;/API&gt; or &lt;API&gt;f(args) -&gt; r&lt;/API&gt;, and can be nested or sequential (e.g., &lt;API&gt;GR(GL(\"cora\"), \"graph-bert:topic\", {Paper#1}) -&gt; r&lt;/API&gt;). Domains and functions are encoded as domain:function (e.g., toolx:density, graph-bert:topic), parameters may be explicit or defaulted, and special token substitutions (e.g., '[' and ']' for &lt;API&gt;, '-&gt;' for -&gt;r) are used to avoid modifying the LM tokenizer.",
            "graph_type": "Multiple: classic synthetic graphs (GPR toy graphs), bibliographic networks (Cora, Citeseer, Pubmed), molecular graphs (PROTEINS, MUTAG, NCI1, PTC), recommender bipartite graphs (Amazon, Last.FM, MovieLens), online social networks (Twitter, Foursquare), knowledge graphs (WordNet, Freebase).",
            "representation_properties": "Faithfulness: representation defers actual graph computation to external toolkits and can insert exact computed results (-&gt; r) back into text, so final textual answers can be faithful once API executed; Compactness: uses short API tokens instead of serializing entire adjacency lists; Interpretability: API calls explicitly name domain and property/function (domain:function) enabling straightforward parsing; Expressivity: supports nested and sequential calls, domain-qualified functions, and optional in-text result insertion; Information loss: the textual representation alone does not contain computed property values until API execution — raw semantics depend on the external tool; Ease of learning: amenable to fine-tuning LLMs with many annotated examples; Implementation constraint: avoids tokenizer changes by substituting special tokens with rare ASCII tokens.",
            "evaluation_task": "Evaluated as part of graph reasoning pipelines across multiple downstream tasks: basic graph attribute computation (order, size, diameter, eccentricity, shortest paths), node classification (paper-topic inference on bibliographic networks), graph classification (molecular function prediction), link prediction / sequential recommendation (BPR-based recommendation scoring), community detection (KMeans-based clustering on social graphs), and knowledge-graph entity/relation reasoning (TransE-based inference). Also evaluated on the quality of LLM-generated API-annotated text (API insertion correctness).",
            "performance_metrics": "Not reported as numeric end-to-end scores in the provided text for the graph-to-text mapping itself; empirical dataset sizes and prompt dataset statistics are reported (e.g., GL prompt dataset ~2,803 pairs after filtering; many task-specific prompt counts appear in Table 3: Cora prompts 18,956; Citeseer 23,184; Pubmed 138,019; PROTEINS 6,678; Amazon 2,252,890; Freebase 1,695,651; etc.). The paper states \"the LLMs can add the correct graph reasoning API calls into the output at the correct position for majority of the graph reasoning input statements,\" but no numeric accuracy or F1 values are provided in the excerpt.",
            "comparison_to_other_representations": "Compared qualitatively to prior Toolformer (Meta) approach which used a small set of simple APIs (Calendar, Calculator, WikiSearch), Graph-ToolFormer extends that idea to a much richer, domain-qualified API space and supports nested/sequential calls for complex graph tasks. Unlike serializing the entire graph into token sequences (full linearization), this approach keeps graph content external and only inserts concise API invocations into text. No quantitative head-to-head performance numbers vs other graph-to-text linearizations or Graph2Seq methods are given in the provided text.",
            "limitations_or_challenges": "Requires reliable external graph toolkits and pre-trained graph models to compute values — the textual API token alone is not a self-contained answer; parsing nested API calls increases complexity; large API-function search space and similar function names can mislead the model; parameter extraction can be challenging (masked vs causal completion trade-offs); execution/validation requires runtime infrastructure (graph data hub, model hub, working memory); dependency on working memory caching capacity and eviction policy; the paper reports filtering of ChatGPT-generated annotations because some annotated API calls were non-runnable or returned incorrect results, indicating automatic annotation noise that must be filtered; no numeric evaluation of generation accuracy presented in excerpt.",
            "uuid": "e5346.0",
            "source_info": {
                "paper_title": "Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "ChatGPT Prompt Augmentation",
            "name_full": "ChatGPT-augmented Prompt Annotation and Dataset Generation",
            "brief_description": "A method to convert graph tasks into training pairs for LLMs by using ChatGPT (gpt-3.5-turbo) to insert API-call annotations into human-written input sentences and to produce many rephrasings; outputs are post-validated by executing API calls and filtered, producing a large prompt dataset used to fine-tune causal LLMs to emit API-annotated text.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "ChatGPT-annotated API-call prompt pairs (automatic graph-to-text example synthesis)",
            "representation_description": "Human-written instructions and a handful of seed examples are provided to ChatGPT with a system role that instructs it to add API calls (e.g., [GL(...)] and [GR(...)-&gt;r]) into inputs at appropriate positions; ChatGPT also generates paraphrases of inputs to increase diversity. Generated input-output pairs are post-processed: non-runnable or incorrect API annotations are filtered by executing the corresponding API functions against local toolkits; the retained pairs form a fine-tuning dataset for LLMs.",
            "graph_type": "Same diverse set as used by Graph-ToolFormer: synthetic graphs (GPR), bibliographic networks, molecular graphs, recommender graphs, social networks, knowledge graphs.",
            "representation_properties": "Scalability: enables generation of thousands to millions of annotated prompt pairs efficiently; Coverage: includes paraphrases to expand linguistic diversity; Validation: integrates execution-time filtering to keep only runnable/correct pairs, improving faithfulness of training data; Noise: initial ChatGPT outputs can include non-runnable or incorrect API annotations requiring filtering; Automation trade-off: reduces manual annotation but requires compute to validate API calls.",
            "evaluation_task": "Used to generate training data for fine-tuning LLMs to insert API-call annotations; downstream evaluation tasks mirror Graph-ToolFormer tasks (graph property Q&A, bibliographic topic inference, molecular function classification, recommender predictions, social community detection, knowledge graph queries). Also evaluated by running the generated API calls and comparing returned results to ground truth to filter bad samples.",
            "performance_metrics": "Dataset generation statistics reported: the graph loading generation attempt asked for 5000 pairs; after manual removal and proofreading ~2,803 graph loading API call input-output pairs were preserved. Table 3 lists prompt counts per task/dataset (examples: GL-Prompt 2,802; GPR-Prompt 2,587; Cora 18,956 prompts; Pubmed 138,019 prompts; Amazon 2,252,890 prompts; Freebase 1,695,651 prompts). No numeric metrics for LLM fine-tuning gains (e.g., precision/recall of API insertion) are reported in the provided excerpt.",
            "comparison_to_other_representations": "Compared to small-scale, hand-crafted prompt templates and to Toolformer-style synthetic API examples, this method uses a large-scale language model (ChatGPT) to produce many diverse, paraphrased API-annotated examples and then validates them by actual execution. The advantage is scale and linguistic diversity; the disadvantage is the need for execution-based post-filtering. No quantitative comparison (e.g., model performance using ChatGPT-augmented vs purely hand-crafted datasets) is reported in the excerpt.",
            "limitations_or_challenges": "Quality depends on ChatGPT outputs and on the correctness of pre-executed graph-toolkit responses; generation requires subsequent execution/validation stage which can be compute- and I/O-intensive; filtering removed a substantial fraction of generated pairs (e.g., 5,000 -&gt; ~2,803 kept in one example), showing annotation noise; generated prompts are tied to the exact API surface and backend toolkits — changing backends requires regenerating/validating data or careful abstraction; potential licensing/costs when using ChatGPT for large-scale generation.",
            "uuid": "e5346.1",
            "source_info": {
                "paper_title": "Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
            "rating": 2
        },
        {
            "paper_title": "Translating Embeddings for Modeling Multi-relational Data",
            "rating": 1
        }
    ],
    "cost": 0.0160155,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT</h1>
<p>Jiawei Zhang<br>jiawei@ifmlab.org<br>IFM Lab<br>Department of Computer Science, University of California, Davis<br>Davis, California, USA<br>https://github.com/jwzhanggy/Graph_Toolformer</p>
<h4>Abstract</h4>
<p>In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with data in multiple modalities. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their inherited weaknesses in performing precise mathematical calculation, multi-step logic reasoning, perception about the spatial and topological factors, and handling the temporal progression.</p>
<p>To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with the graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools. Specifically, we will investigate to teach Graph-ToolFormer to handle various graph data reasoning tasks in this paper, including both (1) very basic graph data loading and graph property reasoning tasks, ranging from simple graph order and size to the graph diameter and periphery, and (2) more advanced reasoning tasks on real-world graph data, such as bibliographic paper citation networks, protein molecular graphs, sequential recommender systems, online social networks and knowledge graphs.</p>
<p>Technically, to build Graph-ToolFormer, we propose to handcraft both the instruction and a small amount of prompt templates for each of the graph reasoning tasks, respectively. Via in-context learning, based on such instructions and prompt template examples, we adopt ChatGPT to annotate and augment a larger graph reasoning statement dataset with the most appropriate calls of external API functions. Such augmented prompt datasets will be post-processed with selective filtering and used for fine-tuning existing pre-trained causal LLMs, such as the GPT-J and LLaMA, to teach them how to use graph reasoning tools in the output generation. To demonstrate the effectiveness of Graph-ToolFormer, we conduct extensive experimental studies on various graph reasoning datasets and tasks, and have also launched a LLM demo with various graph reasoning abilities. All the source code of Graph-ToolFormer framework, the demo for graph reasoning, and the graph and prompt datasets have been released online at the project github page.</p>
<h2>KEYWORDS</h2>
<p>Tool Transformer; ChatGPT; In-Context Learning; Language Model; Graph Learning</p>
<h2>1 INTRODUCTION</h2>
<p>In recent years, large language models (LLMs) [8, 34, 50] have achieved very impressive performance on a variety of natural language processing tasks [32, 34, 49], extensions of which have also been extensively applied to solve many other problems with data in different modalities as well [10, 32, 40, 41]. With the launch of ChatGPT and new Microsoft Bing Chat based on both GPT-3.5 and GPT-4, LLMs have also been widely used in people's daily production and life. At the same time, due to their inherent limitations, these LLMs have also received lots of criticisms in their usages due to their inherited weaknesses, like inability in performing precise calculations [36], difficulty in addressing multi-step logic reasoning problems [6], incapable to conduct spatial and topological reasoning [1], and unawareness of progression of temporal factors [9].</p>
<p>With the parallel development of natural language processing and computer vision, transformer based deep learning models on graph structured data has also received lots of attention from the community in recent years [16, 56, 60]. Graph provides a unified representation for many inter-connected data in the real-world, which models both the diverse attributes of the nodes and the extensive links connecting the nodes with each other. Besides the classic graph structures we learn from the discrete math and algorithm courses, as shown in Figure 1, lots of real-world data can also be modeled as graphs [45], like bibliographic networks [47], protein molecular graphs [52], recommender systems [28], online social networks [31], and knowledge graphs [18].</p>
<p>Meanwhile, compared with the prosperous research explorations on incorporating vision and language data into LLMs for designing the ambitious AGI development plan [33], it seems researchers have either "unintentionally" or "intentionally" ignored the widely existed graph data and don't seem to have any plans to include them into the LLMs building for achieving the AGI.</p>
<p>Here, we say researchers have "unintentionally" ignored graphs, since compared with texts and images that we deal with everyday, graph has long-time been merely used as an intermediate modeling data structure for real-world data and we normally have no direct interactions with graph actually. It is natural that people may mistakenly think graph should not be the focus at the current stage for creating AIGC and building the AGI systems. At the same time, we say researchers may have "intentionally" ignored graphs,</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An Illustration of LLMs based Graph Reasoning Tasks. Based on the input graph data from various domains and a handful number of prompt examples with brief instructions, we propose to use ChatGPT to annotate and augment a large prompt dataset that contains graph reasoning API calls of external graph reasoning tools. The generated prompt dataset will be used to fine-tune the existing pre-trained LLMs, like GPT-J or LLaMA, to teach them to automatically use the most appropriate external API tools for accomplishing the input graph reasoning tasks.
since graph learning may involve (1) lots of precise mathematical calculations of graph properties, (2) multi-hop logical reasoning through the links, (3) capturing the extensively connected graph spatial and topological structures, and (4) sometimes we also need to handle the dynamics of graphs that are changing with time. Careful readers may have noticed that these requirements mentioned for graph learning actually hit the nail on the head, which exactly correspond to the weaknesses of the current LLMs we mentioned at the very beginning.</p>
<p>Regardless of the potential challenges ahead of us, "an AGI without graph reasoning ability will never be the AGI we may desire". Based on such motivations, we write this paper trying to incorporate graph data into LLMs for various graph reasoning tasks. On the one hand, we really hope the currently AI-leading companies like OpenAI, Microsoft, Google and Meta can take graph structured data reasoning into consideration when they develop their missions and plans for achieving the AGI, so that the graph learning community will be able to contribute our efforts to building the AGI system together with the language and vision communities. On the other hand, we also hope to empower the existing LLMs with the ability to overcome the weaknesses in their performance when handling graph structured data for complex graph reasoning tasks.</p>
<p>So, the latest developed LLMs can also benefit the graph learning community for solving various graph reasoning tasks as well.</p>
<p>Considering the current language models and their extremely high pre-training costs, we cannot fundamentally re-design a new LLM with pre-training to equip them with the graph reasoning capabilities. Pre-training such LLMs from scratch is an infeasible task for most research groups in academia and majority of companies in the industry as well. To adapt to the common practices of NLP approaches, we will introduce the Graph Reasoning oriented Toolformer framework (Graph-Toolformer) by fine-tuning some existing pre-trained LLMs (e.g., GPT-J or LLaMA) in this paper. Technically, as illustrated in Figure 1, based on the latest ChatGPT from OpenAI and Toolformer model from Meta [43], we propose to provide the existing pre-trained LLMs (e.g., GPT-J or LLaMA) with the ability to perform various complex graph reasoning tasks by allowing them to use external graph learning tools, such as other pre-trained graph neural network models and existing graph reasoning toolkits. Instead of manually hard-coding the graph data loading and external graph learning tool usage function calls in the reasoning statements, to make Graph-Toolformer as a general graph reasoning interface, we will fine-tune the LLMs to teach the models to decide not only where to retrieve the graph data, but also what tools to be used, as well as when and how to use these tools.</p>
<p>More technical details about the Graph-ToolFormer model will be introduced in the following methodology section.</p>
<p>As the first exploration attempt to use LLMs for general graph reasoning tasks, we summarize the contributions of this paper as follows:</p>
<ul>
<li>Graph Reasoning with LLMs: This paper is the first paper that attempts to propose a general LLM, i.e., GraphToolFormer, that can handle graph reasoning tasks. It effectively remedies the weaknesses of existing LLMs on graph reasoning. More importantly, it helps bridge the graph learning community with the latest development on LLMs and AIGC led by the language and vision learning communities. So people in the graph learning community will also have the stage to demonstrate our skills and expertises in the current era of AIGC and the future era AGI.</li>
<li>Graph Reasoning Prompt Dataset: In this paper, we create a handful number of human-written language instructions and prompt examples of how graph learning tools can be used. Based on the self-supervised in-context learning, we use ChatGPT to annotate and augment a large graph reasoning dataset with API calls of different external graph learning tools, which will also be post-processed with selective filtering. Via the github page ${ }^{1}$, we have released both the graph raw datasets and the generated graph reasoning prompt dataset used in this paper with the community for future explorations.</li>
<li>Extensive Experimental Studies: We have extensively tested the effectiveness of our proposed Graph-ToolFormer with various graph reasoning based application tasks studied in the real-world, which include the most basic graph data loading and general graph property computation tasks, as well as some more advanced ones. Specifically, we study several challenging advanced graph reasoning tasks in the experiments, which include paper topic inference in bibliographic networks, molecular graph function prediction, online social network community detection, personalized sequential recommendation in recommender systems and knowledge graph entity and relation reasoning.</li>
</ul>
<p>The remaining sections of this paper are organized as follows. We will briefly introduce the related work in Section 2. The definitions of some terminologies and the formulation of the studied problem will be provided in Section 3. A detailed introduction about the Graph-ToolFormer framework will be provided in Section 4. The effectiveness of Graph-ToolFormer will be tested with extensive experiments on real-world benchmark graph datasets in Section 5. Finally, we will conclude this paper in Section 6 and briefly discuss about some potential future exploration directions in Section 7.</p>
<h2>2 RELATED WORK</h2>
<p>In this section, we will discuss about several research topics that are related to our Graph-ToolFormer framework proposed in this paper, which include graph neural networks, language models, language model based graph learning and prompt tuning.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h3>2.1 Graph Neural Networks</h3>
<p>Graph neural networks (GNNs) aim to learn the embedding representations of the graph structured data. Representative examples of GNNs proposed already include GCN [19] and Graph-Bert [60], based on which various extended variants [20, 46, 51] have been introduced as well. As mentioned above, GCN and its variant models are all based on the approximated graph convolutional operator [13], which may lead to the suspended animation problem [59] and over-smoothing problem [23] for deep model architectures. Theoretic analyses of the causes are provided in [12, 23, 59]. To handle such problems, [59] generalizes the graph raw residual terms and proposes a method based on graph residual learning; [23] proposes to adopt residual/dense connections and dilated convolutions into the GCN architecture. Besides the GCN and Graph-Bert based models, several other work [17, 46] also seeks to involve the recurrent network for deep graph representation learning instead.</p>
<h3>2.2 Language Models</h3>
<p>Since the proposal of Transformer [50], large language models (LLMs) have become the dominant deep model for various NLP tasks. Assisted with pre-training, the giant tech-companies have also introduced their own versions of different LLMs, like BERT from Google [8], BART from Meta [22], GPT from OpenAI [5, 38, 39], ELMo from AI2 [37] and MT-DNN from Microsoft [25]. Many of these LLMs have also been open-sourced with both model algorithm and learned parameters released to the community for both research and application purposes. One research paper closely related to this work is Toolformer [43] from Meta, which proposes to incorporate external APIs into language models. Equipped with such external APIs, the models will be able to automatically decide how to use which tool. Meanwhile, even prior to the Toolformer model, several other previous papers [29, 35] have also explored to augment language models with external tools.</p>
<h3>2.3 Prompt Tuning</h3>
<p>Prompts have been shown to be effective in tuning the pre-trained language models with zero-shot or few-shot learning [5], which can help language models learn faster than traditional fine tuning tasks. By now, we have witnessed three categories of prompt tuning approaches, i.e., discrete prompts [44], continuous prompts [24] and priming [5]. Discrete prompts [44] reformat data instances with some template text, like,
"{ premise } Should we assume that {hypothesis }? [prediction]".
Discrete prompts will typically tune all parameters of the model. On the other hand, continuous prompts [24] will prepend examples with embedding vectors of special tokens, which will only update a much smaller set of model parameters. Very different from the discrete and continuous prompts, priming [5] initially adopted in GPT-3 will prepend several priming examples to the target evaluation example instead, like
"Example 1: { sentence 1} True or False? {label 1}.
Example 2: { sentence 2} True or False? {label 2}.
Example k: { sentence k} True or False? {label k}.
Evaluation: { eval-sentence } True or False? [prediction]."</p>
<p>According to the analysis reported in [54], discrete prompts works very well in few-shot tuning, continuous prompts have not yet reported success in few-shot setting yet, while priming is very costly and seems to work well for the largest GPT-3 (175B) model.</p>
<h2>3 NOTATION, TERMINOLOGY DEFINITION AND PROBLEM FORMULATION</h2>
<p>In this section, we will first introduce the notations used in this paper. After that, we will provide the definitions of several used terminologies used and the formulations of the graph reasoning tasks studied in this paper.</p>
<h3>3.1 Basic Notations</h3>
<p>In the sequel of this paper, we will use the lower case letters (e.g., $x$ ) to represent scalars, lower case bold letters (e.g., $\mathbf{x}$ ) to denote column vectors, bold-face upper case letters (e.g., $\mathbf{X}$ ) to denote matrices, and upper case calligraphic letters (e.g., $\mathcal{X}$ ) to denote sets or high-order tensors. Given a matrix $\mathbf{X}$, we denote $\mathbf{X}(i,)$ and $\mathbf{X}(:, j)$ as its $i_{t h}$ row and $j_{t h}$ column, respectively. The $\left(i_{t h}, j_{t h}\right)$ entry of matrix $\mathbf{X}$ can be denoted as $\mathbf{X}(i, j)$. We use $\mathbf{X}^{\top}$ and $\mathbf{x}^{\top}$ to represent the transpose of matrix $\mathbf{X}$ and vector $\mathbf{x}$. For vector $\mathbf{x}$, we represent its $L_{p}$-norm as $|\mathbf{x}|<em i="i">{p}=\left(\sum</em>|}|\mathbf{x}(i)|^{p}\right)^{\frac{1}{p}}$. The Frobenius-norm of matrix $\mathbf{X}$ is represented as $|\mathbf{X<em i_="i," j="j">{F}=\left(\sum</em>$.}|\mathbf{X}(i, j)|^{2}\right)^{\frac{1}{2}}$. The element-wise product of vectors $\mathbf{x}$ and $\mathbf{y}$ of the same dimension is represented as $\mathbf{x} \otimes \mathbf{y}$, whose concatenation is represented as $\mathbf{x} \sqcup \mathbf{y</p>
<h3>3.2 Terminology Definitions</h3>
<p>In this paper, we will investigate the reasoning tasks on graph structured data. The graph datasets studied in this paper all come from different domains, which have very different structures and carry very different properties. Here, in this subsection, we will provide the general terminology definitions of these different graph structured data studied in this paper.</p>
<p>Definition 1. (Graph): Generally, the graph studied in this paper can be represented as $G=(\mathcal{V}, \mathcal{E})$. In the representation, notation $\mathcal{V}=\left{v_{1}, v_{2}, \cdots, v_{n}\right}$ denotes the set of $n$ nodes in the graph and $\mathcal{E}=\left{e_{i, j}=\left(v_{i}, v_{j}\right)\right}<em i="i">{v</em>|=m$ are also normally called the order and size of the graph $G$, respectively.}, v_{j} \in \mathcal{V}}$ denotes the set of $m$ links among these nodes, where $|\mathcal{V}|=n$ and $|\mathcal{E</p>
<p>Depending on the application domains, the graph data to be studied may have very different property and structural information. For some graph, the nodes may carry some feature and label information, which can be represented via mappings $x: \mathcal{V} \rightarrow \mathbb{R}^{d_{x}}$ and $y: \mathcal{V} \rightarrow \mathbb{R}^{d_{y}}$, respectively. For each node $v_{i} \in \mathcal{V}$, we can represent its features as $x\left(v_{i}\right)=\mathbf{x}<em i="i">{v</em>}} \in \mathbb{R}^{d_{x}}$ and its label vector as $y\left(v_{i}\right)=\mathbf{y<em i="i">{v</em>}} \in \mathbb{R}^{d_{y}}$, where $d_{x}$ and $d_{y}$ denote the feature and label space dimensions, respectively. If there are also features and labels attached to the links in graph $G$, we can also represent the corresponding feature and label vectors of link $e_{i, j} \in \mathcal{E}$ in a similar way as $\mathbf{x<em i_="i," j="j">{e</em>}} \in \mathbb{R}^{d_{x}}$ and $\mathbf{y<em i_="i," j="j">{e</em>$, respectively.}} \in \mathbb{R}^{d_{y}</p>
<p>For the graph data from many domains, like bibliographic network, online social network, recommender systems, knowledge graph, there will exist one single large-scale graph structure in the dataset, but the graph may contain thousands, millions or even billions of
nodes and links. Such large-scale graphs can be perfectly represented with the above definition. Meanwhile, for the graphs from many other domains, like the special graph structures we learn from the discrete math course, and the bio-chemical molecular graphs, there will exist a large number of much smaller graph instances in the dataset, and each graph instance normally contain tens or a few hundred nodes and links instead. To differentiate these two types of graph structured data, some existing work [57] also names first categories of graphs as the giant networks and calls the second categories of graphs as the small graph instances set. Meanwhile, to represent the set of such small-sized graph instances, we introduce the concept of graph set as follows.</p>
<p>Definition 2. (Graph Set): For the generated special graph instances (to be introduced in this paper) and the bio-chemical molecular graph instances, we can represent the set of graph instances in these datasets as $\mathcal{G}=\left{g_{1}, g_{2}, \cdots, g_{l}\right}$, where $g_{i}=\left(V_{g_{i}}, \mathcal{E}<em i="i">{g</em>\right)$ denotes an individual graph instance and it can be represented according to the above graph definition.}</p>
<p>For some application domains, in the above graph set, each graph instance may also have its unique feature and label information, denoting its topological properties and tags of the graph instance. Formally, for a graph instance $g_{i} \in \mathcal{G}$ in the graph set $\mathcal{G}$, we can represent its raw feature and label vectors as $\mathbf{x}<em i="i">{g</em>}} \in \mathbb{R}^{d_{x}}$ and $\mathbf{y<em i="i">{g</em>$, respectively.}} \in \mathbb{R}^{d_{y}</p>
<h3>3.3 Problem Formulation</h3>
<p>In this paper, we aim to empower the existing pre-trained LLMs to carry out graph reasoning tasks. As introduced before, the graph reasoning tasks studied in this paper include (1) basic graph property reasoning, (2) bibliographic paper topic reasoning, (3) bio-chemical molecular graph function reasoning, (4) recommender system sequential recommendation reasoning, (5) online social network community reasoning, and (6) knowledge graph entity and relation reasoning. Specifically, these graph reasoning tasks studied in this paper are carefully selected, which can be categorized into six types of the most fundamental graph learning problems listed as follows:</p>
<ul>
<li>Attribute Calculation: For the tasks like basic graph property reasoning, we actually aim to calculate either explicit or implicit attributes of the input graph data, ranging from the simple number of nodes/links in the graph, to the graph radius and diameter, and the more complex graph periphery and node pairwise short path length.</li>
<li>Node Classification: For the bibliographic paper topic reasoning task, we aim to predict the topic of the academic papers in the bibliographic network, which can be modeled as the node classification task actually. Via the raw features of the paper nodes and their nearby neighboring nodes, we can classify the papers into different classes, which correspond to the specific topics of these papers.</li>
<li>Graph Classification: For the bio-chemical molecular graph function reasoning task, based on the molecular graph structures, we aim to infer the potential functions of the biochemical molecules, which can be defined as the graph instance classification task. Via both the molecular graph structure and raw attributes, we can classify the graph instances</li>
</ul>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The Outline of the Graph-ToolFormer Framework. The framework has three main parts: (1) prompt data annotation and augmentation with ChatGPT, (2) existing pre-trained causal LLMs fine-tuning with the generated prompt dataset, and (3) inference of the fine-tuned model for adding graph reasoning API calls into statements.
into different classes, which correspond to different predefined bio-chemical molecule functions.</p>
<ul>
<li>Link Prediction: For the sequential recommender system reasoning task, based on the historical user-item interaction records, we aim to infer the potential preferences of users towards certain items in the system, which can be defined as the link prediction task (connecting user and item) in graph learning. Depending on the recommender system settings, we can either predict the link existence label denoting whether the user will be interested in the item or not, or infer the potential link weights denoting the rating scores that users will give to the items.</li>
<li>Graph Partition/Clustering: For the online social network community reasoning task, we aim to infer the community structures of online social networks, which can be defined as the graph partition/clustering task. Based on the user social interaction patterns, we want to partition the users in online social networks into different clusters, each of which denote one social community formed by the users with very frequent social interactions.</li>
<li>Graph Searching: For the knowledge graph reasoning task, we aim to infer the potential entities or relations based on the input parameters, which can be modeled as the graph searching problem. Starting from the input entity or relation, we aim to expand and search for the related entities or relations
for generating the outputs, that can effectively preserve the desired semantics of the inputs.
To address these above diverse graph reasoning tasks with one single LLM, we propose to include the API calls of external graph learning tools into to the graph reasoning statements seamlessly. Based on the above notations, we will design a set of graph reasoning API calls for different graph tasks in the real-world. Such API calls include both the external graph learning tool name and the parameters, which will be surrounded with special tokens to differentiate from regular text. Based on a handful human-written prompt examples, with ChatGPT, we will generate a large language modeling prompt dataset containing such API calls, which will be used for fine-tuning the LLMs, like GPT-J and LLaMA. Such LLMs to be studied in this paper have all been pre-trained already and we will only fine-tune them with the generated prompt datasets. More information about the technical details on address these tasks will be introduced in the following methodology section.</li>
</ul>
<h2>4 PROPOSED METHOD</h2>
<p>In this section, we will introduce the Graph-ToolFormer framework proposed in this paper. At the beginning, in Section 4.1, we will first briefly describe the Graph-ToolFormer framework outline for readers. After that, we will talk about the graph reasoning API call general representations in Section 4.2, and introduce the specific graph reasoning task oriented API calls in Section 4.3. Based</p>
<p>on the hand-crafted graph reasoning prompt examples, we will introduce how to use the ChatGPT to augment the prompt dataset in Section 4.4. Detailed information about the language model finetuning with the augmented prompt datasets will be introduced in Section 4.5. Meanwhile, to also allow Graph-ToolFormer to handle some basic Q\&amp;A for graph reasoning, we will also introduce a few number of graph reasoning Q\&amp;A prompts in Section 4.6, which will be merged into the statement prompts for LLM fine-tuning. Finally, based on the output statements with API calls generated by the language models, the graph reasoning tasks oriented API call parsing, execution, graph task reasoning and output post-processing will be introduced in Section 4.7.</p>
<h3>4.1 Framework Outline</h3>
<p>In Figure 2, we provide an outline of the Graph-ToolFormer framework illustrating the internal functional components and pipeline of Graph-ToolFormer. According to the framework outline, based on the hand-crafted instructions and a handful number of prompt examples, we use ChatGPT to annotate and augment a large prompt dataset about graph reasoning API call statements. With the generated prompt dataset, we will fine-tune the existing pre-trained causal LLMs, such as GPT-J [11, 53] and LLaMA [49] to teach them how to use the external graph reasoning tools. With both LoRA (Low-Rank Adaptation) [15] and 8-bit Adam and the model quantization techniques [7], Graph-ToolFormer can be fine-tuned on GPUs with very small memory space, such as Nvidia GeForce RTX 4090 (24GB RAM) and even Nvidia GeForce RTX 1080Ti (11GB RAM). The fine-tuned Graph-ToolFormer will be used for inference purposes. Given the input query statements and questions, Graph-ToolFormer will add the corresponding graph reasoning API calls into the output statements at the most appropriate positions automatically. Detailed information about these mentioned components and steps in building Graph-ToolFormer will be introduced in detail in the following subsections.</p>
<h3>4.2 Prompts with API Calls</h3>
<p>In this paper, we can represent the API calls of external graph learning tools as $f($ args $)$, where $f$ is the external tool function name and args denotes the list of parameters of the function. For representation simplicity, we can also represent such an API call as a tuple notation $c=(f, \operatorname{args})$, which will be frequently used in the following part of this paper. Instead of merely generating the external API calls as the output, we propose to inset the API calls into the generated output statements instead, which allows the LLMs to handle and respond the graph reasoning tasks with regular conversations via texts.</p>
<p>Formally, to insert the API calls into the output statements, we can represent the sequence of tokens for API call $c=(f$, args $)$ as</p>
<p>$$
\mathbf{s}(c)=\langle\text { API }&gt;f(\text { args })&lt;\mid \text { API }\rangle
$$</p>
<p>or</p>
<p>$$
\mathbf{s}(c, r)=\langle\text { API }&gt;f(\text { args }) \rightarrow r&lt;\mid \text { API }\rangle
$$</p>
<p>where both "<API>" and " $&lt;$ /API&gt;" surrounding the API call function are the special tokens to differentiate it from other tokens in the generated output statements. For the Graph-ToolFormer framework, when it generates the "<API>" and " $&lt;$ /API&gt;" tokens, the
framework parser will recognize that the tokens inside it denotes the API function call. As to the second API call representation, the notation $r$ denotes the return result of $f($ args $)$. For the API calls with notations " $\rightarrow r$ ", Graph-ToolFormer will also replace and insert the API call results into the statements after query parsing and execution; otherwise, the API calls will be executed at the backend with return results recorded into the working memory instead. Detailed information about the output statement API call parsing, execution and post-processing will be introduced later in Section 4.7. Depends on both the function $f($ args $)$ and the contexts for the API call in the reasoning task, the LLMs to be fine-tuned later will automatically decide whether the output results will be inserted into the output statement.</p>
<p>Different from the very simple API calls (e.g., "Calendar", "Calculator" and "WikiSearch") studied in [43], in graph reasoning, some of the API calls may involve complicated and nested calls of various external functions. For instance, some of the parameters in one API call can actually be the returning results of other API calls, or we may need to call multiple sequential APIs concurrently for accomplishing one graph reasoning task. In the following Section 4.3, when discussing about the specific graph reasoning tasks, we will encounter some of such complicated graph reasoning API calls.</p>
<p>To address such complicated graph reasoning tasks, in this paper, we will also allow Graph-ToolFormer to generated nested and sequential API calls surrounded by the special tokens "<API>" and "</API>". For instance, given two API calls $c_{1}=\left(f_{1}, \operatorname{args}<em 2="2">{1}\right)$ and $c</em>}=\left(f_{2}, \operatorname{args<em 1="1">{2}\right)$ with their own input parameters, the first API function $f</em>$ as its input parameter, we can represent such nested API calls as}$ needs to use the return result of the second API function $f_{2</p>
<p>$$
\mathbf{s}\left(c_{1} \mid c_{2}\right)=\langle\text { API }&gt;f_{1}\left(\operatorname{args}<em 2="2">{1}=f</em>\rangle
$$}\left(\operatorname{args}_{2}\right)\right)&lt;\mid \text { API </p>
<p>or just simply as</p>
<p>$$
\mathbf{s}\left(c_{1} \mid c_{2}\right)=\langle\text { API }&gt;f_{1}\left(f_{2}\left(\operatorname{args}_{2}\right)\right)&lt;\mid \text { API }\rangle
$$</p>
<p>where the notation " $c_{1} \mid c_{2}$ " denotes these two API calls are nested.
Meanwhile, if a task needs to call multiple sequential APIs simultaneously, e.g., $c_{1}=\left(f_{1}, \operatorname{args}<em 2="2">{1}\right)$ and $c</em>\right)$, we can represent such sequential API calls as}=\left(f_{2}, \operatorname{args}_{2</p>
<p>$$
\begin{aligned}
&amp; \mathbf{s}\left(c_{1}, c_{2}\right)=\langle\text { API }&gt;f_{1}\left(\operatorname{args}<em 2="2">{1}\right), f</em>}\left(\operatorname{args<em 1="1">{2}\right)&lt;\mid \text { API }&gt; \
&amp; =\langle\text { API }&gt;f</em>}\left(\operatorname{args<em 2="2">{1}\right)&lt;\mid \text { API }&gt;,&lt;\text { API }&gt;f</em>}\left(\operatorname{args<em 1="1">{2}\right)&lt;\mid \text { API }&gt; \
&amp; =\mathbf{s}\left(c</em>\right)
\end{aligned}
$$}\right), \mathbf{s}\left(c_{2</p>
<p>which is equivalent to two sequential API calls of $c_{1}$ and $c_{2}$ as well.
Meanwhile, for some even more complicated graph reasoning cases, we can rewrite the above API call representations with either more input parameters denoted by other API calls or with deeply nested API calls instead, e.g.,</p>
<p>$$
\mathbf{s}\left(c_{1} \mid\left(c_{2}, c_{3}\right)\right)=\langle\text { API }&gt;f_{1}\left(f_{2}\left(\operatorname{args}<em 3="3">{2}\right), f</em>\rangle
$$}\left(\operatorname{args}_{3}\right)\right)&lt;\mid \text { API </p>
<p>or</p>
<p>$$
\mathbf{s}\left(c_{1} \mid\left(c_{2} \mid c_{3}\right)\right)=\langle\text { API }&gt;f_{1}\left(f_{2}\left(f_{3}\left(\operatorname{args}_{3}\right)\right)\right)&lt;\mid \text { API }\rangle
$$</p>
<p>where $c_{3}=\left(f_{3}, \operatorname{args}_{3}\right)$ denotes the notation of a third API call.
Such graph reasoning function API calls will be inserted into statements for LLMs fine-tuning later. Without modifying the LLMs' vocabulary set and the pre-trained tokenizer, in implementation, we can replace the special tokens "<API>", "</API>" and $\rightarrow$ with some less frequently used tokens like " $[", "]$ " and " $-&gt;$ " instead. In</p>
<p>Table 1: A summary of API call examples for basic graph Loading and property reasoning studied in this paper. In this table, we use notations $G L(\cdot)$ and $G R(\cdot)$ to represent the graph loading and graph reasoning API calls. Without introducing new special tokens to the pre-trained tokenizer of LLMs, we use "[", "]" and "-&gt;" to represent the " $&lt;$ API $&lt;$ ", " $&lt;$ /API $&gt;$ " and " $\rightarrow$ " tokens introduced in this paper. Notation "[TBR]" denotes the "to be reasoned" placeholder token. We refer to the top left Lollipop graph (in green color) illustrated in Figure 1 as the "Lollipop graph" example in the table. In the graph property reasoning API call notations, we use $G_{l}$ to represent the result ob API call "[GL(file-path:",/graphs/lollipop") $\rightarrow G_{l}$ ]" and use the notation "tools:desired_property" to denote the reasoning of the desired properties with the toolx graph toolkit (to be introduced in the following experiment section).</p>
<table>
<thead>
<tr>
<th>Tasks</th>
<th>API Call Templates</th>
<th>Prompt Examples</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Inputs</td>
<td>Outputs</td>
</tr>
<tr>
<td>Graph Data Loading</td>
<td>GL(file-path)</td>
<td>"The structure of the molecular graph of the benzene ring contains a hexagon."</td>
<td>"The structure of the [GL(file-path",/graphs/benzene] ring." molecular graph of the benzene ring contains a hexagon."</td>
</tr>
<tr>
<td></td>
<td>GL(file-path, node-subset, link-subset)</td>
<td>"There exist a carbon-oxygen double bond in the Acetaldehyde molecular graph,"</td>
<td>"There exist a [GL(file-path",/graphs/acetaldehyde] ${ }^{\text {n }}$ node subset in the Acetaldehyde molecular graph."</td>
</tr>
<tr>
<td></td>
<td>GL(file-path) $\rightarrow r$</td>
<td>"Lollipop graph looks like a spoon."</td>
<td>"GL(file-path",/graphs/lollipop") $\rightarrow G_{l}$ Lollipop graph looks like a spoon."</td>
</tr>
<tr>
<td>Graph Property Reasoning</td>
<td>GR(graph,"order") $\rightarrow r$</td>
<td>"There exist [TBR] nodes in the lollipop graph,"</td>
<td>"There exist [GRO3, "node nodes"] $\rightarrow$ in nodes in the lollipop graph."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"size") $\rightarrow r$</td>
<td>"Via [TBR] links, nodes in the lollipop graph are all connected."</td>
<td>"Via [GRO3, "node size"] $\rightarrow$ in links, nodes in the example lollipop graph are all connected."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"density",is-directed) $\rightarrow r$</td>
<td>"The undirected lollipop graph has a density of $\lambda$ "</td>
<td>"The undirected lollipop graph has a density of [GRO3, node number] $\rightarrow$ in node numbers" $\rightarrow$ in."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"eccentricity") $\rightarrow r$</td>
<td>"The long 'tail' will lead to large eccentricity [TBR] for many nodes in the lollipop graph,"</td>
<td>"The long 'tail' will lead to large eccentricity [GRO3, node eccentricity] $\rightarrow$ in node numbers" $\rightarrow$ in. (see Figure 2 for many nodes in the lollipop graph."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"eccentricity", node-subset) $\rightarrow r$</td>
<td>"The eccentricity of node #4 in the lollipop graph is [TBR],"</td>
<td>"The eccentricity of node #4 in the lollipop graph is [GRO3, node eccentricity] $\rightarrow$ in node numbers" $\rightarrow$ in."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"radius") $\rightarrow r$</td>
<td>"The radius of the lollipop graph is [TBR],"</td>
<td>"The radius of the lollipop graph is [GRO3, "node radius"] $\rightarrow$ in</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"center") $\rightarrow r$</td>
<td>"The center of the lollipop graph include node(s) [TBR],"</td>
<td>"The center of the lollipop graph include node(s) [GRO3, node center"] $\rightarrow$ in</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"shortest-path", node ${ }<em 2="2">{1}$, node ${ }</em>$ ) $\rightarrow r$</td>
<td>"In the lollipop graph, the length of shortest path between node #1 and node #5 is [GRO3, node shortest path", node #1, node "1" $\rightarrow$ in"</td>
<td>"In the lollipop graph, the length of shortest path between node #1 and node #5 is [GRO3, node shortest path", node #1, node "1" $\rightarrow$ in.</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"aog-shortest-path") $\rightarrow r$</td>
<td>"The average length of shortest path for all nodes in the lollipop graph is [TBR],"</td>
<td>"The average length of shortest path for all nodes in the lollipop graph is [GRO3, "node aog-shortest path"] $\rightarrow$ in.</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"diameter") $\rightarrow r$</td>
<td>"The diameter of the lollipop graph is [TBR] due to the long 'tail'."</td>
<td>"The diameter of the lollipop graph is [GRO3, "node diameter"] $\rightarrow$ in due to the long 'tail'."</td>
</tr>
<tr>
<td></td>
<td>GR(graph,"periphery") $\rightarrow r$</td>
<td>"The periphery of the lollipop graph includes the nodes [TBR],"</td>
<td>"The periphery of the lollipop graph includes the nodes [GRO3, node periphery] $\rightarrow$ in" $\rightarrow$ in."</td>
</tr>
</tbody>
</table>
<p>this paper, we will study several very different graph reasoning tasks involving diverse graph learning API calls, which will be introduced in detail in the following subsection for readers.</p>
<h3>4.3 Graph Reasoning Oriented Prompts</h3>
<p>We will study several graph reasoning tasks in this paper with Graph-ToolFormer, which include both the very basic tasks, like the general graph property reasoning, and more advanced ones, like the reasoning tasks on graphs from different specific application domains. As introduced before in Section 3, these graph reasoning tasks studied in this paper are all carefully selected, which can be categorized into different types of fundamental graph learning tasks, e.g., graph attribute calculation, node classification, graph classification, link prediction, graph partition/clustering and graph searching. All these fundamental graph learning tasks have extensive applications in real-world graph data reasoning tasks. Besides the tasks studied in this paper, with minor changes to the API calls,
we can also apply the Graph-ToolFormer to other graph reasoning related application tasks as well.
4.3.1 Graph Data Loading. Different from texts and images, the graph data we have in the real-world may have a relatively larger size, extensively connected structures and complex raw attributes. Except for some small-sized hand-crafted graph examples, it is almost impossible to manually type in the graph structured data as a sequence of token inputs to LLMs for reasoning. Therefore, in this paper, we propose to empower the Graph-ToolFormer model with the ability to automatically load the desired graph data from offline files or online repositories based on the provided the dataset name, local file path or online repository URL link.</p>
<p>Technically, the first API call that we will introduce in this paper is for graph data loading, which can load either the whole graph or just a subgraph involving one or a few nodes and links. Specifically,</p>
<p>we can represent the graph loading API call as</p>
<p>$$
&lt;\text { API }&gt;G L(\text { file-path, node-subset, link-subset }) \rightarrow G&lt;/ \text { API }&gt;
$$</p>
<p>where " $G L()$ " denotes abbreviation of the "Graph Loading" function name, and the function parameters "file-path", "node-subset" and "link-subset" specify the local graph data file path (or the online repository URL if the data is stored on the web), subsets of specific nodes and links, respectively. The notation " $\rightarrow G$ " explicitly represents the loaded graph data with the reference variable $G=(\mathcal{V}, \mathcal{E})$, which is optional actually depending on the application task and settings. What's more, if the local file directory or the online repository root URL has been pre-provided to the " $G L()$ " function already, then we can just simplify the "file-path" with the specific "graph-name" instead when calling this API function.</p>
<p>Furthermore, when the parameters "node-subset" and "linksubset" are either omitted or assigned with the strings "all nodes" and "all links", respectively, then the API function call will just load the whole graph. For some cases, we can only specify the subset of nodes to be loaded (e.g., $\left{v_{i}, v_{j}, \cdots, v_{k}\right} \subset \mathcal{V}$ in the graph) but cannot enumerate all the related links, we can just assign the "nodesubset" and "link-subset" parameters with values " $\left{v_{i}, v_{j}, \cdots, v_{k}\right}$ " and "all related links" (or the "link-subset" parameter is just omitted). It will provide us with more flexibility in loading sub-graphs based on the provided node set and their internal links. Similarly, we can also only specify the subset of links, by assigning the "node-subset" with "all related nodes" or just omitted it, it will automatically load the nodes composing those provided links in the graph data, like the second graph data loading prompt example shown in Table 1.</p>
<p>Besides that example, as shown at the top part of Table 1, we also provide a few other prompt examples of the graph data loading API calls, which can retrieve and load the requested graph data from the (local) files according to the input textual statements.
4.3.2 Graph Property Reasoning. Graph structured data may have various properties, such as diameter, density, center and shortest path, which can capture different characteristics of the graph data and have extensive applications in real-world graph structured data. For reasoning such graph properties, it usually requires the model to not only know the property definitions but also has very strong logic reasoning and mathematical calculation abilities to compute such properties. For the existing language models, either masked language models or autoregressive language models, it will be very hard (almost impossible) for them to conduct the reasoning process for such complex properties based on the input graphs.</p>
<p>In this paper, to empower LLMs with the graph property reasoning ability, we introduce a group of external APIs, which can be called by the language models for reasoning about those properties. To illustrate how Graph-ToolFormer handles such graph property reasoning tasks, we will use the small-sized lollipop graph shown in Figure 1 (the top-left graph in green color) as an example in this part, which can be loaded via the following API calls as introduced before:</p>
<p>$$
&lt;\mathrm{API}&gt;G L(" \text { lollipop }") \rightarrow G_{l}&lt;/ \mathrm{API}&gt;
$$</p>
<p>where the loaded the graph can also be referred to by notation $G_{l}$. For simplicity, in the following part, we will also use the above loaded lollipop graph $G_{l}$ as an example to introduce the graph property reasoning APIs for readers.</p>
<p>Order and Size: Formally, given a graph, like the loaded lollipop graph $G_{l}=(\mathcal{V}, \mathcal{E})$, its order denotes the number of nodes in the graph, i.e., $|\mathcal{V}|$, and its size is the number of links in the graph, i.e., $|\mathcal{E}|$. We can represent the API calls for reasoning the order and size properties of the lollipop graph as</p>
<p>$$
\begin{aligned}
&amp; &lt;\text { API }&gt;G R\left(G L(" \text { lollipop"), "toolx:order") } \rightarrow r&lt;/ \text { API }&gt;\right. \
&amp; &lt;\text { API }&gt;G R\left(G L(" \text { lollipop"), "toolx:size") } \rightarrow r&lt;/ \text { API }&gt;\right.
\end{aligned}
$$</p>
<p>If the lollipop graph has been pre-loaded via other API calls already and can be referred to as $G_{l}$, the above API calls can also be simplified as follows:</p>
<p>$$
\begin{aligned}
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:order } "\right) \rightarrow r&lt;/ \text { API }&gt; \
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:size" }\right) \rightarrow r&lt;/ \text { API }&gt;
\end{aligned}
$$</p>
<p>where the notation $G R()$ denotes the abbreviated "Graph Reasoning" function name and the parameters "order" and "size" represent the graph properties to be reasoned. The notation "toolx:desired_property" denotes the desired graph property reasoning with the toolx toolkit. The toolx is a graph property calculation toolkit created in this paper for Graph-ToolFormer based on the networkx, and we will introduce more information about the graph reasoning models and toolkits used in this paper in the next experiment section instead. The notation " $\rightarrow r$ " specifies the output result $r$ by the graph property reasoning API call to be included into the output statements. As introduced before, the returning output result tag " $\rightarrow r$ " of the API calls is actually optional, inclusion of which depends on both the reasoning context and application task.</p>
<p>Density: Graph density denotes the ratio of existing links in a graph compared with the maximal number of potential links among nodes in a graph. If the input lollipop graph $G_{l}=(\mathcal{V}, \mathcal{E})$ is directed, its density can be represented as $\frac{|\mathcal{E}|}{|\mathcal{V}|(|\mathcal{V}|-1)}$; while if $G_{l}$ is undirected, its density can be represented as $\frac{2|\mathcal{E}|}{|\mathcal{V}|(|\mathcal{V}|-1)}$. Formally, the API calls that can be used for computing the density of graph can be represented as follows:</p>
<p>$$
&lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:density", is-directed }\right) \rightarrow r&lt;/ \text { API }&gt;
$$</p>
<p>where the boolean "is-directed" parameter differentiates directed graph from undirected ones in the density calculation.</p>
<p>Shortest Path: The shortest path between two nodes in a graph is a path of shortest possible length connecting them via the nodes and links in the graph. The API call for reasoning the length of the shortest path from node $<em 2="2">{1}$ to node $</em>$ in a graph can be represented as</p>
<p>$$
&lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:shortest-path", node }<em 2="2">{1}, \text { node }</em>&gt;
$$}\right) \rightarrow r&lt;/ \text { API </p>
<p>Meanwhile, the average length of shortest path for all nodes in the graph can be obtained via the following API call instead</p>
<p>$$
&lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:aog-shortest-path" }\right) \rightarrow r&lt;/ \text { API }&gt;
$$</p>
<p>Besides the average shortest path length, we can also reason for the largest shortest path length and the smallest shortest path length of a graph as follows:</p>
<p>$$
\begin{aligned}
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:max-shortest-path" }\right) \rightarrow r&lt;/ \text { API }&gt; \
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:min-shortest-path" }\right) \rightarrow r&lt;/ \text { API }&gt;
\end{aligned}
$$</p>
<p>Eccentricity: Given a connected graph, like the lollipop graph $G_{l}=(\mathcal{V}, \mathcal{E})$, for node $v_{i} \in \mathcal{V}$, its eccentricity denotes the maximum graph distance between $v_{i}$ and any other node $v_{j} \in \mathcal{V}$ in the graph. According to such a definition, for disconnected graph, all nodes are defined to have infinite eccentricity. We can compute the eccentricity either for the whole graph (i.e., for all nodes in the graph) or for specific node(s) via the following two API calls:</p>
<p>$$
\begin{aligned}
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:eccentricity" }\right) \rightarrow r&lt;/ \text { API }&gt; \
&amp; &lt;\text { API }&gt;G R\left(G_{l}, " \text { toolx:eccentricity", node-subset }\right) \rightarrow r&lt;/ \text { API }&gt;
\end{aligned}
$$</p>
<p>Diameter: The diameter of a graph denotes the "longest shortest path" between any two nodes in the graph, whose API call can be represented as</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G_{l}, " \text { toolx:diameter" }\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>whose result will be equal to the result of the above API call $&lt;$ API $&gt;G R\left(G_{l}, " \text { max-shortest-path" }\right)&lt;$ /API $&gt;$ actually.</p>
<p>Radius: Graph radius denotes the is the minimum graph eccentricity of any node in a graph. A disconnected graph therefore has infinite radius. The API call for computing a graph radius can be represented as</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G_{l}, " \text { toolx:radius" }\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>Center: Formally, the center of a graph denotes the set of nodes whose eccentricity is equal to the graph radius. The API call for identifying a graph center can be represented as</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G_{l}, " \text { toolx:center" }\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>Periphery: The periphery of a graph is the subgraph of the graph induced by nodes that have the eccentricities equal to the graph diameter, whose API call can be represented as</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G_{l}, " \text { toolx:periphery" }\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>A Summary of Basic Graph Reasoning API Calls: According to our descriptions above, the readers should have observed that those graph properties may require very complex logic reasoning. Via some preliminary experimental testings, the current LLMs (such as ChatGPT and LLaMA) cannot handle them very well. At the same time, the above reasoning properties, like the shortest-path, also have very extensive applications in the real-world graph reasoning tasks, e.g., traffic network reasoning and traffic route planning. Currently, the LLMs have been criticized since they cannot provide the correct reasoning results for the spatial traffic data, e.g., estimating the traveling distance and time between different locations. Equipped with the above shortest path based property API calls on traffic networks, we will be able to provide more precise reasoning results for LLMs in handling such queries. To incorporate them into language models, we also show some examples of the above API calls in Table 1, which can load the graph data from specified data sources and conduct the reasoning of some general graph properties as discussed above.
4.3.3 Advanced Graph Reasoning Tasks. Besides the basic graph property reasoning tasks, we will also study several advanced reasoning tasks on real-world graph data with more complex structures in this paper, which include (1) academic paper topic reasoning on bibliographic network, (2) protein function reasoning based on protein graph structures, (2) sequential product recommendation reasoning based on recommender systems, (4) social community reasoning from online social networks and (5) semantics reasoning on knowledge graphs.</p>
<p>For many other advanced graph reasoning tasks not studied in this paper, via very minor changes to the Graph-ToolFormer framework, they can also be effectively incorporated into GraphToolFormer as well by adding the corresponding API calls into the reasoning prompts. The Graph-ToolFormer framework can serve as the backbone for hosting various graph reasoning application tasks with LLMs as the general interface. In Section 7, we will also describe some potential future research opportunities for the readers at the very end of this paper.</p>
<p>Bibliographic Paper Topic Reasoning: Bibliographic network [47] defines a complex graph structured data involving diverse entities, such as academic papers, authors, institutions and publication venues, as well as diverse links among these entities, such as the citation links, authorship links, affiliation links and publication links. In this part, we will discuss about the academic paper topic reasoning task based on the bibliographic network. The topics of a paper can be inferred with not only its own textual descriptions but also the other papers cited by/citing it, which requires the graph reasoning model to utilize both the raw textual features of the papers and the extensive citation links among the papers.</p>
<p>Formally, based on the terminology definition provided in the previous Section 3.2, we can represent the bibliographic network as $G=(\mathcal{V}, \mathcal{E})$, which can be loaded via the API call</p>
<p>$$
&lt;\mathrm{API}&gt;G L(" \text { bibliographic-network" }) \rightarrow G&lt;/ \mathrm{API}&gt;
$$</p>
<p>Each paper is represented as a node $v_{i} \in \mathcal{V}$ in the bibliographic network, which has both its raw feature vector $\mathbf{x}<em i="i">{v</em>}}$ and label vector $\mathbf{y<em i="i">{v</em>$. The raw feature vector includes the textual information about the paper (like its title or abstract), and its label vector indicates the topics of the paper. Existing graph neural networks (GNNs) infer the paper topics by learning their representations with both raw features and connected neighbors' information [19, 60], which can be further used to infer the topic label vector. For the GraphToolFormer model introduced in this paper, we will use the pretrained Graph-Bert [60] as the default topic inference model for bibliographic networks. Based on the above descriptions, we can represent the paper topic reasoning via graph neural network model with the following API call:}</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G, " \text { graph-bert:topic", paper-node }\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>The function notation "GR( $\cdot$, "graph-bert:topic", $\cdot$)" denotes it is a paper topic reasoning API with the Graph-Bert model [60]. Actually, the Graph-ToolFormer framework proposed in this paper is a general framework. Besides the Graph-Bert model, many other existing graph neural network models can also be used here for academic paper topic inference as well. Based on the provided source code, the readers can customize the Graph-ToolFormer to include</p>
<p>Table 2: A summary of API call examples for advanced graph reasoning tasks studied in this paper. In this table, we use notations $G L(\cdot)$ and $G R(\cdot)$ to represent the graph loading and graph reasoning API calls. Similarly, we use " $[$, "]" and " $-&gt;$ " to represent the "<API>", "</API>" and " $\rightarrow$ " tokens, and use notation "[TBR]" to denote the "to be reasoned" placeholder token.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Tasks</th>
<th style="text-align: center;">API Call Templates</th>
<th style="text-align: center;">Prompt Examples</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Inputs</td>
<td style="text-align: center;">Outputs</td>
</tr>
<tr>
<td style="text-align: center;">Bibliographic <br> Paper Topic <br> Reasoning</td>
<td style="text-align: center;">GR(graph,"topic",paper-node) $\rightarrow r$</td>
<td style="text-align: center;">In the core bibliographic network, paper #31366 focuses on the topic of [TBR].</td>
<td style="text-align: center;">In the core bibliographic network, paper #31366 focuses on the topic of [TBR]. <br> This is "graph_bert-topic", paper#31366: <br> (format "TBR"</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Within cora, paper #13195 is dedicated to the study of [TBR].</td>
<td style="text-align: center;">Within cora, paper #13195 is dedicated to the study of [TBR]. <br> This is "graph_bert-topic", paper#13195: -Reinforce- <br> (code "cora").</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">The citeseer bibliographic network's paper #2 is concerned with the area of [TBR].</td>
<td style="text-align: center;">The citeseer bibliographic network's paper #2 is concerned with the area of [TBR]. <br> This is "graph_bert-topic", paper#2: <br> (format "TBR").</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paper #3 in the citeseer network investigates the field of [TBR].</td>
<td style="text-align: center;">Paper #3 in the citeseer network investigates the field of [TBR]. <br> This is "graph_bert-topic", paper#31: -TBR.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paper #7, situated in the pubmed bibliographic network, is centered around the [TBR] topic.</td>
<td style="text-align: center;">Paper #7, situated in the pubmed bibliographic network, is centered around the [TBR] topic.</td>
</tr>
<tr>
<td style="text-align: center;">Protein <br> Function <br> Reasoning</td>
<td style="text-align: center;">GR(graph,"protein-function", $g_{i}$ ) $\rightarrow r$</td>
<td style="text-align: center;">The protein molecular graph instance #63 in the PROTEIN dataset has a function of [TBR] for the disease.</td>
<td style="text-align: center;">The protein molecular graph instance #63 in the PROTEIN dataset has a function of [TBR] for the disease. <br> This is "graph_bert-topic", paper#63: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">In PROTEIN, instance #985 of the protein molecular graph demonstrates a function of [TBR] for the disease.</td>
<td style="text-align: center;">In PROTEIN, instance #985 of the protein molecular graph demonstrates a function of [TBR] for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">The chemical molecular graph numbered 63 in PTC is characterized by a function of [TBR].</td>
<td style="text-align: center;">The chemical molecular graph numbered 63 in PTC is characterized by a function of [TBR]. <br> This is "graph_bert-topic", paper#63: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">For chemical molecular graph instance #63 in NCI1, its function is [TBR].</td>
<td style="text-align: center;">For chemical molecular graph instance #63 in NCI1, its function is [TBR]. <br> This is "graph_bert-topic", paper#63: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">The molecular graph of chemical compound #121 in MUTAG possesses a function of [TBR].</td>
<td style="text-align: center;">The molecular graph of chemical compound #121 in MUTAG possesses a function of [TBR]. <br> This is "graph_bert-topic", paper#121: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;">Sequential <br> Recommender <br> System <br> Reasoning</td>
<td style="text-align: center;">GR(graph,"recommendation", $u_{j}, i_{l}$ ) $\rightarrow r$</td>
<td style="text-align: center;">In the Amazon recommender system, user #A240ORQ2LP8LUI rates item #0077613252 with a score of [TBR].</td>
<td style="text-align: center;">In the Amazon recommender system, user #A240ORQ2LP8LUI rates item #0077613252 with a score of [TBR]. <br> This is "graph_bert-topic", paper#2: <br> (format "A240ORQ2LP8LUI"</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Within Last.fm, user #2 awards item #52 with a [TBR] tag,</td>
<td style="text-align: center;">Within Last.fm, user #2 awards item #52 with a [TBR]. <br> This is "graph_bert-topic", paper#2: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">User #196 gives a rating of [TBR] to item #251 at MovieLens.</td>
<td style="text-align: center;">User #196 gives a rating of [TBR] to item #251 at MovieLens.</td>
</tr>
<tr>
<td style="text-align: center;">Online <br> Social Network <br> Reasoning</td>
<td style="text-align: center;">GR(graph,"community") $\rightarrow r$</td>
<td style="text-align: center;">In the academic collaboration network dblp, scholar #355233 is involved in [TBR] local community formed by his/her collaborators.</td>
<td style="text-align: center;">In the academic collaboration network dblp, scholar #355233 is involved in [TBR] local community formed by his/her collaborators.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">In the email communication social network, there exist a number of [TBR] local communities formed by users.</td>
<td style="text-align: center;">In the email communication social network, there exist a number of [TBR] local communities formed by users.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">The video sharing social network youtube houses the largest user-formed local community, which consists of [TBR] users.</td>
<td style="text-align: center;">The video sharing social network youtube houses the largest user-formed local community, which consists of [TBR] users.</td>
</tr>
<tr>
<td style="text-align: center;">Knowledge <br> Graph <br> Reasoning</td>
<td style="text-align: center;">GR(graph,reasoning-type, inputs) $\rightarrow r$</td>
<td style="text-align: center;">According to the Freebase knowledge graph, the relation between entity /m/027rn and entity /m/06cx9 is [TBR].</td>
<td style="text-align: center;">According to the Freebase knowledge graph, the relation between entity /m/027rn and entity /m/06cx9 is [TBR]. <br> This is "graph_bert-topic", paper#31: -TBR for the disease.</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">According to the WordNet knowledge graph, from entity plaything.n.01, via relation_hyponym, we can derive entity [TBR].</td>
<td style="text-align: center;">According to the WordNet knowledge graph, from entity plaything.n.01, via relation_hyponym, we can derive entity [TBR].</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">According to the WordNet knowledge graph, from entity plaything.n.01, via relation_hyponym, we can derive entity [TBR].</td>
<td style="text-align: center;">According to the WordNet knowledge graph, from entity plaything.n.01, via relation_hyponym, we can derive entity [TBR].</td>
</tr>
</tbody>
</table>
<p>more different graph models that can be used for accomplishing their own graph reasoning tasks.</p>
<p>Protein Molecule Function Reasoning: Protein and chemical molecule function inference [52] has been a classic problem studied in bio-chemical research for decades, which has fundamental applications in the real-world, such as helping design some new drugs for curing some existing rare diseases. Protein function inference is not an easy task, because homologous proteins often have several different functions at the same time. Also such a prediction needs to be fine-tuned with respect to some mutations but robust with respect to others. Researchers have been exploring on this problem with machine learning models, and have also developed a relatively large protein function database [48] already. However, compared with the number of protein existing in the real world, the specific proteins with known functions included in the database is still very limited. In graph learning, inferring the function of protein molecules based on its structure has also be extensively studied as well. Therefore, in this part, we also include it as a graph reasoning task into Graph-ToolFormer as well.</p>
<p>Different from the bibliographic network, the protein molecular graphs have much smaller sizes and there will also exist multiple such graph instances in the dataset. What's more, the features and labels of protein molecular graphs are both about the whole molecular graph, not about the individual nodes anymore. As introduced in Section 3.2, we can represent the set of studied protein molecular graphs as $\mathcal{G}=\left{g_{1}, g_{2}, \cdots, g_{l}\right}$, which can be loaded with the following graph loading API call:</p>
<p>$$
&lt;\mathrm{API}&gt;G L(\text { "protein-graph-set") } \rightarrow \mathcal{G}&lt;\mid \mathrm{API}&gt;
$$</p>
<p>For each molecular graph instance $g_{i}=\left({ }^{\prime} V_{g_{i}}, \mathcal{E}<em i="i">{g</em>}}\right)$ in the dataset $\mathcal{G}$, there will also be raw features and labels related to each protein molecular graph instance. For instance, for the graph instance $g_{i} \in$ $\mathcal{G}$, we can represent its raw feature as $\mathbf{x<em i="i">{g</em>}}$ and its label as $\mathbf{y<em i="i">{g</em>$, where the label vector will indicate its corresponding functions. Based on the protein graph structure and its raw features, we can define the following API call for protein molecule function reasoning as follows:}</p>
<p>$$
&lt;\mathrm{API}&gt;\mathrm{GR}\left(\mathcal{G}, \text { "seg-bert:molecule-function", } g_{i}\right) \rightarrow r&lt;/ \mathrm{API}&gt;
$$</p>
<p>which will call the pre-trained graph neural network SEG-Bert proposed in [58]. The SEG-Bert with full name "Segmented GraphBert" [58] extends the Graph-Bert model for molecular graph instance representation learning. Besides the SEG-Bert model used in Graph-ToolFormer, the readers can also customize the GraphToolFormer framework to include other graph models for addressing the molecular graph reasoning tasks as well.</p>
<p>Sequential Recommender System Reasoning: In the era of big data, as more and more data are generated both online and offline, manual search of information from such big data sources has become infeasible nowadays and we may need recommender systems [28] to automatically recommend desired information for us instead. Based on the historical records, sequential recommender system aims to infer the next item(s) that users may be interested in, which may lead to either the future purchase action or the review rating scores of those items. When studying the sequential recommender
systems, it is a common way to model recommender systems as the bipartite graphs, where the user-item interaction record also has an attached timestamp. With considerations about the timestamps, sequential recommender systems aim to infer the potential existence (or the weight) of links between user and their interested items for the next future timestamp. In other words, we can define the sequential recommendation problem in recommender systems as a link prediction task with considerations about the temporal factor.</p>
<p>Formally, according to the above description, we can represent the sequential recommender system as a bipartite graph $G=(\mathcal{V}, \mathcal{E})$, where the node set $\mathcal{V}=\mathcal{U} \cup \mathcal{I}$ covers both users and items and the links in set $\mathcal{E} \subset \mathcal{M} \times \mathcal{I}$ only exist between users and item instead. For each user-item pair $\left(u_{j}, i_{l}\right) \in \mathcal{E}$ in the link set, we can also obtain its timestamp. The sequential recommender system data can be loaded with the following API call:</p>
<p>$$
&lt;\mathrm{API}&gt;G L(\text { "recommender-system") } \rightarrow G&lt;\mid \mathrm{API}&gt;
$$</p>
<p>For each user $u_{j}$ and item $i_{l}$ in the recommender system $G$, based on the historical interaction records (before the current timestamp), we can learn the embedding representations of them, which will be used to infer the label between them in the future. Depending on the modeling approach, the label vector can indicate either whether the user will purchase the item or not (i.e., binary classification task) or the rating score of the user for the item (i.e., the regression task). Regardless of the specific modeling settings, we can represent the recommender system reasoning API call in LLMs as follows:</p>
<p>$$
&lt;\mathrm{API}&gt;G R\left(G, " b p r: r e c o m m e n d a t i o n ", u_{j}, i_{l}\right) \rightarrow r&lt;\mid \mathrm{API}&gt;
$$</p>
<p>which will return either the probability scores that the user $u_{j}$ will be interested in the item $i_{l}$ or the specific rating scores that $u_{j}$ will give to $i_{l}$. We use BPR (Bayesian Personalized Ranking) [42] as the default recommendation model in Graph-ToolFormer in this paper, but other recommendation models can also be used for defining the above recommendation API calls as well. Besides the recommendation API calls to infer the scores between user and item, for one specific user $u_{j}$, we can also return the list of top- $k$ recommended items with the following API call:</p>
<p>$$
&lt;\mathrm{API}&gt;\operatorname{GR}\left(G, " b p r: t o p k \text {-recommendation", } u_{j}, k\right) \rightarrow r&lt;\mid \mathrm{API}&gt;
$$</p>
<p>where the notation $k$ denotes a hyper-parameter to be extracted from the input statements for the recommendation reasoning.</p>
<p>Online Social Network Community Reasoning: Online social networks [31], like Facebook, Twitter and Tiktok, provide different online services for their users to facilitate their online socialization with friends, family members and colleagues. Users in online social networks tend to interact more frequently with their online friends, and they will naturally form their online social communities based on their online social behaviors. Reasoning for the social communities of users in online social networks is a complicated problem. In this part, we will introduce the API calls to empower LLMs to detect social communities from online social networks.</p>
<p>Formally, we can represent the online social network studied in this paper as $G=(\mathcal{V}, \mathcal{E})$, where $\mathcal{V}$ denotes the set of user nodes and $\mathcal{E}$ denotes the social interactions among the users in the</p>
<p>network. The online social network data can be loaded with the following API call:</p>
<p>$$
&lt;\mathrm{API}&gt;G L(\text { "social-network") } \rightarrow G&lt;/ \mathrm{API}&gt;
$$</p>
<p>Based on $G$, we can represent its detected social community structure as $\mathcal{C}=\left{C_{1}, C_{2}, \cdots, C_{k}\right}$, where $\bigcup_{i=1}^{k} C_{i}=\mathcal{V}$. Depending on the problem setting, the social communities to be detected can be based on either hard partition or soft partition of the user node set. For hard partition, we will have $C_{i} \cap C_{j}=\emptyset, \forall i, j \in{1,2, \cdots, k}$ (i.e., there exist no overlap between any two communities); whereas for the soft partition, the communities may have overlaps and one user node may belong to multiple social communities simultaneously.</p>
<p>Based on the above description, given on the loaded online social network $G$, we can infer both the communities of the whole loaded social network or only the local community for a specific user (e.g., $u_{i} \in \mathcal{V}$ ) with the following API calls:</p>
<p>$$
\begin{aligned}
&amp; &lt;\mathrm{API}&gt;G R\left(G, " k \text { means:community" } \rightarrow r&lt;/ \mathrm{API}\right.&gt; \
&amp; &lt;\mathrm{API}&gt;G R\left(G, " k \text { means:community", } u_{i}\right) \rightarrow r&lt;/ \mathrm{API}&gt;
\end{aligned}
$$</p>
<p>which will call various pre-trained social network community detection algorithms to identify the community structures. In this paper, we will use the KMeans algorithm to partition the user node set into different communities by calculating the number of common neighbors among them as the affinity score.</p>
<p>Knowledge Graph Entity and Relation Reasoning: Compared with unstructured documents, knowledge graph [18] aggregates information about entities and their relations from textual data sources in a well-organized representation. Knowledge graph is a powerful tool for supporting a large spectrum of applications in the real-world, like searching, ranking, Q\&amp;A and chatbot dialogue systems. Reasoning of knowledge graphs helps provide the evidences for providing the results with factual basis. At the same time, such a reasoning process will also provide the justification and explanation for the obtained results by the current natural language processing systems. In this paper, we will not study how to build the knowledge graph from textual document sources. Instead, we assume the knowledge graph has been built and is ready to be used for reasoning in the downstream applications.</p>
<p>Formally, we can represent the built knowledge graph (e.g., Wikipedia) as $G=(\mathcal{V}, \mathcal{E})$, where the node set $\mathcal{V}$ covers the set of named entities and the link set $\mathcal{E}$ includes the set of relations among these entities instead. The knowledge graph can be loaded with the following API call:</p>
<p>$$
&lt;\mathrm{API}&gt;G L(\text { "knowledge-graph") } \rightarrow G&lt;/ \mathrm{API}&gt;
$$</p>
<p>Such a loaded knowledge graph structure can be effectively used in the reasoning tasks to infer the potential head-entities, the relations between a pair of entities, and the tail-entities. Formally, we can represent the knowledge graph reasoning API calls used in this
paper as:</p>
<p>$$
\begin{aligned}
&lt;\mathrm{API}&gt;G R(G, " \text { transe:head-entity", relation, tail-entity }) &amp; \rightarrow r&lt;/ \mathrm{API}&gt;, \
&lt;\mathrm{API}&gt;G R(G, " \text { transe:relation", head-entity, tail-entity }) &amp; \rightarrow r&lt;/ \mathrm{API}&gt;, \
&lt;\mathrm{API}&gt;G R(G, " \text { transe:tail-entity", head-entity, relation }) &amp; \rightarrow r&lt;/ \mathrm{API}&gt;
\end{aligned}
$$</p>
<p>For the (head-entity, relation, tail-entity) tuples in the knowledge graph, given any two of them, we can infer the remaining one based on their learned representations. Various pre-trained knowledge graph representation learning models can be used to define the function called in the above API. In this paper, we will use the TransE [4] as the default knowledge graph embedding and reasoning model.</p>
<p>A Summary of Advanced Graph Reasoning API Calls: we also provide a summary of API call examples of the advanced graph reasoning tasks mentioned above in Table 2. For each of the tasks, we provide several different input reasoning statements, and insert the corresponding reasoning API calls at the most appropriate positions in the output statements. As introduced above, some of the API calls introduced above can be used in different ways to reason for different types of desired information, like based on the online social network community reasoning results, we can further define the functions to reason for the community-count, communitysize. Some examples of which have also been provided in Table 2 as well.</p>
<h3>4.4 Prompt Augmentation with ChatGPT</h3>
<p>For the prompt examples provided in Table 1 and Table 2, they can only cover a handful number of examples about how to use the API calls for different graph reasoning tasks. Such a small number of instances are not sufficient for the fine-tuning of the existing LLMs. In this paper, we propose to augment the prompt instances with ChatGPT (gpt-3.5-turbo), which has demonstrated excellent fewshot and zero-shot in-context learning ability [5] in many different language learning tasks already.
4.4.1 Graph Loading Prompt Dataset Generation. Similar to [34], to help the generation of prompt examples, we also provide a detailed instruction for ChatGPT to specify its system role. Here, we can take the graph data loading API call as an example. The instruction together with the prompt examples fed to ChatGPT are provided as follows. Based on both the instruction and prompt examples, we will ask the ChatGPT to generate the graph data loading prompt dataset.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>data, and "nodes" and "links" are the mentioned nodes and links.
If no specific nodes or links are mentioned, then the API will write "all nodes" and "all links" for the "nodes" and "links" parameters.
If only nodes are specified, the API will list the mentioned nodes for the "nodes" parameter entry, and write "all related links" for the "links" parameter entry.
If only links are specified, the API will and write "all related nodes" for the "nodes" parameter entry, and list the mentioned links for the "links" parameter entry.</p>
<p>Here are some examples of the API call for loading graph structured data. In the examples, the output will repeat the input, and also insert the API call at the most appropriate position.</p>
<ul>
<li>Input: The structure of the benzene ring molecular graph of benzene ring contains a hexagon.</li>
<li>Output: The structure of the [GL("benzene-ring")] molecular graph of benzene ring contains a hexagon.</li>
<li>Input: There exist a carbon-oxygen double bond in the Acetaldehyde molecular graph.</li>
<li>Output: There exist a [GL("acetaldehydemolecular-graph", {Carbon, Oxygen}, { {Carbon, Oxygen }))] carbon-oxygen double bond in the Acetaldehyde molecular graph.</li>
<li>Input: The lollipop graph looks like a spoon.</li>
<li>Output: The [GL("lollipop-graph", "all nodes", "all links")] lollipop graph looks like a spoon.</li>
<li>Input: The paper#10 in the Cora bibliographic network introduces the Transformer model.</li>
<li>Output: The [GL("cora", {Paper#10}, "all related citation links")] paper#10 in the bibliographic network introduces the Transformer model.</li>
<li>Input: Insulin is a small globular protein containing two long amino acid chains.</li>
<li>Output: [GL("insulin-protein-graph", "all atom nodes", "all atom bond links")] Insulin is a small globular protein containing two long amino acid chains.</li>
<li>Input: At the IMDB recommender system, David rates the "The Avengers" movie with a 10 -star review score.</li>
<li>Output: At the [GL("imdb-recommendersystem", {"David", "The Avengers"}, {("David", "The Avengers")))] IMDB recommender system, David rates the "The Avengers" movie with a 10 -star review score.</li>
<li>Input: Among the existing online social apps, Tiktok makes it easy for users to socialize with each other online via livestream videos.</li>
<li>Output: Among the existing online social apps, [GL("tiktok-social-network", "all user and video nodes", "all user-video links and user-user links")] Tiktok makes it easy for users to socialize with each other online via livestream videos.</li>
<li>Input: According to the Freebase knowledge graph, Donald Trump was born in 1946 at the Jamaica Hospital Medical Center in New York. - Output: According to the [GL("freebase", {"Donald Trump", "Jamaica Hospital Medical Center", "New York"}, {("Donald Trump", "Jamaica Hospital Medical Center"), ("Jamaica Hospital Medical Center", "New York")))] Freebase knowledge graph, Donald Trump was born in 1946 at the Jamaica Hospital Medical Center in New York.</li>
</ul>
<p>Query: Based on the instruction and examples, please generate 5000 such input-output pairs for real-world graph data loading. Please make sure the data loaded are in graph structures and the API call is insert ahead of the mentioned graphs or the mentioned nodes or links.</p>
<p>Based on the instruction, examples and query, by calling ChatGPT API, we obtained a prompt dataset with 5,000 input-output pair instances. With manual removal the incomplete instances and brief proofreading, about 2,803 graph data loading API call inputoutput pairs are preserved in the dataset, which will be used for the fine-tuning to be introduced later.
4.4.2 Graph Reasoning Prompt Dataset Generation. As to the other graph reasoning prompts, with similar instruction and prompt examples, we can use ChatGPT to generate a large number of similar input-output pairs. Meanwhile, slightly different from graph loading API calls, to ensure the graph reasoning prompts are valid, we propose to compose all the inputs statements manually by calling the graph reasoning toolkits in advance. For instance, for the first</p>
<p>paper in the Cora bibliographic network, its topic is about "Neural Networks" and we will compose its input statement as follows:</p>
<ul>
<li>Input: The first paper in Cora has a topic of Neural Networks.</li>
</ul>
<p>We will feed such input to ChatGPT and ask it helps insert the graph reasoning API calls to the statement with the query.</p>
<p>Query: Based on the instruction and examples, generate the output with graph reasoning API calls for the input. Please make sure the API call is insert at the most appropriate position.</p>
<p>Based on the query and input statement, ChatGPT will return the following output:</p>
<ul>
<li>Output: The first paper in Cora has a topic of [GR(GL("cora", "all paper nodes", "all citation links"), "topic", (Paper#1)) -&gt; r] Neural Networks.</li>
</ul>
<p>Besides using ChatGPT to annotate the API calls and generate the above output, we also use ChatGPT to rewrite the input statement in another way without changing its semantic meanings. For instance, for the input statement shown above, we also obtain several of its rephrased versions as follows:</p>
<ul>
<li>Input: The initial article in Cora focuses on the subject of Neural Networks.</li>
<li>Input: In Cora, the premier paper addresses Neural Networks as its main theme.</li>
<li>Input: The foremost paper in the Cora collection pertains to the field of Neural Networks.</li>
<li>Input: Cora's inaugural publication delves into the subject matter of Neural Networks.</li>
</ul>
<p>These rephrased input will also be fed to ChatGPT again for the API call annotation as well. Such a process will be done for all the node/graph instances studied in both the basic graph property reasoning tasks and the advanced graph reasoning tasks for generating the input-output prompt pair datasets. Based on the generated dataset, we will run the API calls generated by ChatGPT and compare the return result of the graph reasoning API functions with the true values in the statements. For the outputs whose API calls (1) are not runnable or (2) cannot return the correct result, they will be filtered from the dataset. Finally, after the filtering, the ChatGPT augmented generated datasets will be used for the LLMs fine-tuning, whose statistical information will be provided later in the following experiment section. Meanwhile, for the other graph reasoning tasks not studied in this paper, their reasoning API call datasets can be generated in a similar way as described above.</p>
<h3>4.5 LLMs Fine-Tuning for Graph Reasoning</h3>
<p>Based on the above augmented graph reasoning prompt datasets, in this part, we will introduce how to fine-tune existing pre-trained LLMs, so the LLMs can learn how to use the API tools to address the graph reasoning tasks. Formally, as shown by the prompt examples in Table 1 and Table 2, given the input statements with a sequence of tokens, i.e., $\mathbf{w}=\left[w_{1}, w_{2}, \cdots, w_{n}\right]$, the LLMs in Graph-Toolformer aim to identify the most appropriate position where we can insert the API calls, i.e., $\mathbf{s}(c)=&lt;$ API $&gt;f($ args $)&lt;$ /API $&gt;$ as introduced in the previous Section 4.2. The major challenges lie in (1) precisely identify the most appropriate positions to insert the API call, (2) correctly the choose the API functions to be used for the call, and (3) also accurately extract the parameters from the context and feed them to the functions. In this section, we will address all these three challenges.
4.5.1 API Call Insertion Position Prediction. For the provided input statement, there may exist multiple potential positions for inserting the API calls. Different from [43] that choose top-k positions for API call data generation, in this paper, we aim to identify the most likely position to insert the API calls instead. Formally, based on a pre-trained language model $M$, given the input statement $\mathbf{w}=$ $\left[w_{1}, w_{2}, \cdots, w_{n}\right]$, we can insert an API call at the $i_{t h}$ (where $i \in$ ${1,2, \cdots, n})$ position (i.e., right between the tokens $w_{i-1}$ and $w_{i}$ ) with the probability</p>
<p>$$
P(i \mid \mathbf{w}(1: i-1))=P_{M}(&lt;\text { API }&gt;\mid \mathbf{w}(1: i-1))
$$</p>
<p>Once the LLM $M$ generates the special beginning token <API> at the $i_{t h}$ position, the model will know it should insert an API call here. All the tokens generated after the <API> token and before the special ending token </API> will be the API call function name or the input parameters. For the position index with the latest probability, $\arg \max _{i \in{1,2, \cdots, n}} P(i \mid \mathbf{w}(1: i-1))$, it will be selected as the most appropriate position to insert the API calls.
4.5.2 API Call Domain and Function Selection. Different from the very few API call functions studied in [43], the graph reasoning APIs studied in this paper are much more diverse, which may create challenges in the framework implementation and tuning. On the one hand, as more graph reasoning tasks and API functions are incorporated into tuning the LLMs, the graph reasoning API function search space will grow exponentially, which makes it harder to select the correct and the best API functions into the call. On the other hand, some API functions for different graph reasoning tasks may even share similar function names, which may mislead Graph-ToolFormer in selecting the correct ones in the API calls. What's more, different graph reasoning tasks may call different API functions from different toolkits, and some may require different graph functions and trained models to be pre-loaded at the backend. We may also want to specify the trained graph models and graph toolkits to be loaded in the API calls, so Graph-ToolFormer can pre-load the models and toolkits in the generation stage in advance to lower down the overall graph reasoning time costs.</p>
<p>Therefore, according to the graph reasoning API call examples shown before, we propose to slightly change the graph reasoning API call templates introduced in Section 4.2 as follows:</p>
<p>$$
\mathbf{s}(c)=\langle\text { API }&gt;G R(G, \text { domain:func, args })&lt;\mid \text { API }\rangle
$$</p>
<p>or</p>
<p>$$
\mathbf{s}(c, r)=\langle\mathrm{API}\rangle G R(G, \text { domain:func, args }) \rightarrow r&lt;/ \mathrm{API}\rangle
$$</p>
<p>where the corresponding "domain" of the API function is prepend to the specific graph reasoning tasks in the API function call. The domain can be either the used toolkit names or the specific pretrained model names.</p>
<p>For instance, for the graph reasoning API calls shown in Table 1 and Table 2, we will use toolx developed in this paper based on networkx toolkit ${ }^{2}$ for graph property reasoning and can represent the corresponding parameter as "toolx:property-names"; as to the bibliographic paper topic reasoning with Graph-Bert [60], we can represent the corresponding parameter as "graph-bert:topic". For some other cases, if the domain is not specified, we will just use the function in the default domain for the graph reasoning task. More information about the used pre-trained graph models for defining the "domain:function" entry in the API call will be provided in the following Section 5 for readers.</p>
<p>In other words, when inserting the API function calls into the statement, we need to infer both the domain and function name of the API call. At the inference stage, as the LLMs generate the domain, the system can pre-load the domain code at the backend even before the whole API call output statement generation is completed. At the same time, it will also allow the LLMs to choose the optimal domain to be used in the API call, since to accomplish the same graph reasoning task, there will exist several different approaches with different performance in terms of effectiveness and efficiency.</p>
<p>Technically, within the function parameters, we may need to select the best domain from the available candidate domain set, i.e., $\mathcal{D}=\left{d_{1}, d_{2}, \cdots, d_{n}\right}$, according to the prefix context, i.e., the selected domain after the sequence "w( $1: i-1)&lt;$ API $&gt;G R(G$," can be represented as</p>
<p>$$
d^{i}=\arg \max <em j="j">{d</em>\right\rangle G R(G)
$$} \in \mathcal{D}} P_{M}\left(d_{j} \mid \mathbf{w}(1: i-1)&lt;\mathrm{API</p>
<p>Furthermore, based on the selected domain $d^{i}$, we may need to select the best function from it that may meet our needs. Formally, we can represent the available functions from the selected domain $d^{i}$ as set $\mathscr{Y}<em 1="1">{d^{i}}=\left{f</em>\right}$, and the function which can maximize the generation probability will be selected, i.e.,}, f_{2}, \cdots, f_{m</p>
<p>$$
f^{i}=\arg \max <em l="l">{f</em>} \in \mathcal{F<em M="M">{j}^{i}} P</em>:\right)
$$}\left(f_{l} \mid \mathbf{w}(1: i-1)&lt;\mathrm{API}\right\rangle G R\left(G, d^{i</p>
<p>where the "." mark is appended after domain $d^{i}$ automatically. Once the domain and function are selected, the model may also need to fill in the remaining parameters for the functions accordingly, which will be introduced in the following subsection for readers.
4.5.3 API Call Function Parameter Completion. Once the domain and function tokens $d^{i}: f^{i}$ are determined, Graph-ToolFormer will also need to provide the parameters for the selected function based on the statement context. There exist two different ways for completing the parameter entries, i.e., masked parameter completion and causal parameter completion.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>For the masked parameter completion, once the domain and function are selected, Graph-ToolFormer will automatically generate and insert the remaining tokens, include the function parameter names, the parentheses, the comma and colon marks, and API call ending special token </API>. For instance, based on the current token sequence "w( $1: i-1)&lt;$ API $&gt;G R\left(G, d^{i}: f^{i} ;{ }^{\prime \prime}\right.$, GraphToolFormer will automatically complete the API call as follows:</p>
<p>$$
\begin{aligned}
\mathbf{w}(1: i-1) &amp; &lt;\mathrm{API}&gt;G R\left(G, d^{i}: f^{i}, \arg <em 1="1">{1}:\left[M A S K</em>\right]\right. \
&amp; \left.\arg <em 2="2">{2}:\left[M A S K</em>\right], \cdots, \arg <em n="n">{n}:\left[M A S K</em>&gt;
\end{aligned}
$$}\right]\right)&lt;\mid \mathrm{API</p>
<p>where terms $\arg <em 2="2">{1}, \arg </em>$. In the API call, we mask the parameter values, which will be inferred based on both the prefix context and the function parameter names.}, \cdots, \arg _{n}$ are the list of parameter names of function $d^{i}: f^{i</p>
<p>The disadvantages of the above masked parameter completion is that the model need to complete the full list of parameters of the function. However, in the real world function calls, only a few number of parameters will be provided actually, whereas the remaining parameters will use their default values instead. Also the masked parameter completion is inconsistent with the previous autoregressive special token and domain/function prediction process. Therefore, in this paper, we propose to use the consistent autoregressive parameter completion with causal language models instead.</p>
<p>For the causal language model based completion of the function parameters, its completion process is similar to the above special token and domain/function selection process. Based on the provided statement and generated tokens, Graph-ToolFormer can generate the list of provided parameter values for the API call, e.g.,</p>
<p>$$
\begin{aligned}
&amp; \arg <em M="M">{j}^{i}=\arg \max P</em>,\right) \
&amp; \operatorname{val}}(\arg | \mathbf{w}(1: i-1)&lt;\mathrm{API}&gt;G R\left(G, d^{i}: f^{i<em M="M">{j}^{i}=\arg \max P</em>\right)
\end{aligned}
$$}(\operatorname{val}\left|\mathbf{w}(1: i-1)&lt;\mathrm{API}\right\rangle G R\left(G, d^{i}: f^{i}, \arg _{j}^{i</p>
<p>Such a process continues until the end API call special token "</API>" is generated. By adding the generated parameter name and value into the token list, we can get the model generation result to be "w( $1: i-1)&lt;$ API $&gt;G R\left(G, d^{i}: f^{i}, \arg <em j="j">{j}^{i}: \operatorname{val}</em>, \arg }^{i}, \cdots\right)&lt;$ /API $&gt;\mathbf{w}(i: n)$ " or "w( $1: i-1)&lt;$ API $&gt;G R\left(G, d^{i}: f^{i<em j="j">{j}^{i}: \operatorname{val}</em>(i: n)$ " (with the output tag " $\rightarrow r$ "). For the parameters that are not generated by the Graph-ToolFormer model, we will use their default parameter values in the API function calls in the follow-up graph reasoning process.
4.5.4 LLMs Fine-Tuning with Augmented API Call Dataset. Formally, given the ChatGPT augmented graph reasoning prompt dataset $\mathcal{D}=\left{\left(\mathbf{w}}^{i}, \cdots\right) \rightarrow r&lt;$ /API $&gt;\mathbf{w<em 1="1">{1}, \hat{\mathbf{w}}</em>}\right),\left(\mathbf{w<em 2="2">{2}, \hat{\mathbf{w}}</em>}\right), \cdots,\left(\mathbf{w<em _mathcal_D="|\mathcal{D">{|\mathcal{D}|}, \hat{\mathbf{w}}</em>}|}\right)\right}$ involving a set of input-output prompt pairs, where the notation $\hat{\mathbf{w}<em i="i">{i}(\forall i \in$ ${1,2, \cdots,|\mathcal{D}|})$ is the output statement of $\mathbf{w}</em>$ to LLMs, we can represent the generated output by the model as}$ with inserted API call annotations, according to the above generation process, by feeding the input statement $\mathbf{w}_{i</p>
<p>$$
\hat{\mathbf{w}}<em i="i">{i}=L L M\left(\mathbf{w}</em>|}
$$}\right), \forall i \in{1,2, \cdots,|\mathcal{D</p>
<p>Furthermore, by comparing the generation output $\hat{\mathbf{w}}<em i="i">{i}$ with the ChatGPT annotated output statement $\hat{\mathbf{w}}</em>$, we can define the loss</p>
<p>function for fine-tuning the LLM as</p>
<p>$$
\begin{aligned}
\ell(\mathcal{D}) &amp; =\frac{1}{|\mathcal{D}|} \sum_{\left(\mathbf{w}<em i="i">{i}, \hat{\mathbf{w}}</em>}\right) \in \mathcal{D}} \ell\left(\hat{\mathbf{w}<em i="i">{i}, \hat{\mathbf{w}}</em>\right) \
&amp; =\frac{1}{|\mathcal{D}|} \sum_{\left(\mathbf{w}<em i="i">{i}, \hat{\mathbf{w}}</em>}\right) \in \mathcal{D}} \sum_{j} \text { cross-entropy }\left(\hat{\mathbf{w}<em i="i">{i}(j), \hat{\mathbf{w}}</em>(j)\right)
\end{aligned}
$$</p>
<h3>4.6 Graph Reasoning Q\&amp;A Prompts</h3>
<p>What's more, to provide Graph-ToolFormer with basic Q\&amp;A ability for graph reasoning, besides the above statements based graph reasoning prompts, we will also design some Q\&amp;A based prompts for fine-tuning Graph-ToolFormer as well. The graph reasoning Q\&amp;A based prompts are created in a very similar way as above, but we will replace the input statements with other reasoning questions instead, and the output will still be a statement with graph reasoning API calls corresponding to the input question.</p>
<p>Formally, we also list of the graph reasoning Q\&amp;A prompt examples used in this paper as follows, which will be merged into the previous prompts for fine-tuning Graph-ToolFormer. Different from the previous input-output statement prompts (where the output is almost a duplicated copy of the input but with API calls), the inputs and outputs in question-answer prompts are not duplicated copies of each other anymore. However, with the above autoregressive generation of the desired output statement introduced before, the Graph-ToolFormer using causal language models as the backbone is still capable to generate the desired output statements for the input question queries.</p>
<h2>1. Graph Property Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: What is the order of the barbell graph?</li>
<li>Output: The order of the barbell graph is [GR(GL("gpr", "barbell_graph"), "toolx:order")-&gt;r].</li>
<li>Input: What is the size of the star graph?</li>
<li>Output: The size of the star graph is [GR(GL("gpr", "star_graph"), "toolx:size")&gt;r].</li>
<li>Input: What is the density of the dodecahedral graph?</li>
<li>Output: The density of dodecahedral graph is [GR(GL("gpr", "dodecahedral_graph"), "toolx:density")-&gt;r].</li>
<li>Input: What is the eccentricity of node #25 in the balanced tree?</li>
<li>Output: The eccentricity of node #25 in the balanced tree is [GR(GL("gpr", "balanced_tree"), "toolx:eccentricity", "node#25")-&gt;r].</li>
<li>Input: What is the radius of the lollipop graph?</li>
<li>Output: The radius of the lollipop graph is [GR(GL("gpr", "lollipop_graph"), "toolx:radius")-&gt;r].</li>
<li>Input: What is the center of the star graph?</li>
<li>Output: The center of the star graph includes node(s) [GR(GL("gpr", "star_graph"), "toolx:center")-&gt;r].</li>
<li>Input: What is the length of shortest path between node #5 and node #0 in the octahedral graph?</li>
<li>Output: In the octahedral graph, the length of shortest path between node #5 and node #0 is [GR(GL("gpr", "octahedral_graph"), "toolx:shortest_path", "node#5", "node#0")&gt;r].</li>
<li>Input: What is the diameter of the binomial tree?</li>
<li>Output: The diameter of the binomial tree is [GR(GL("gpr", "binomial_tree"), "toolx:diameter")-&gt;r].</li>
<li>Input: What is the periphery of the house x graph?</li>
<li>Output: The periphery of the house x graph includes node(s) [GR(GL("gpr", "house_x_graph"), "toolx:periphery")-&gt;r].</li>
</ul>
<h2>2. Bibliographic Network Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: What is the topic of paper #83826 in the cora bibliographic network?</li>
<li>Output: The topic of paper #83826 in the cora bibliographic network is [GR(GL("cora"), "graph_bert:topic", paper#83826)-&gt;r].</li>
<li>Input: What is the topic of paper #5832 in the pubmed bibliographic network?</li>
<li>Output: The topic of paper #5832 in the pubmed bibliographic network is [GR(GL("pubmed"), "graph_bert:topic", paper#5832)-&gt;r].</li>
<li>
<p>Input: What is the topic of paper #3230 in the citeseer bibliographic network?</p>
</li>
<li>
<p>Output: The topic of paper #3230 in the citeseer bibliographic network is [GR(GL("citeseer"), "graph_bert:topic", paper#3230)-&gt;r].</p>
</li>
</ul>
<h2>3. Molecular Graph Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: What is the function for the protein molecular graph #138 in proteins?</li>
<li>Output: The function for the protein molecular graph #138 in proteins is [GR(GL("proteins"), "seg_bert:molecule_function", instance#138)-&gt;r].</li>
<li>Input: What is the function for the chemical molecular graph #129 in mutag?</li>
<li>Output: The function for the chemical molecular graph #129 in mutag is [GR(GL("mutag"), "seg_bert:molecule_function", instance#129)-&gt;r].</li>
<li>Input: What is the function for the chemical molecular graph #322 in ncil?</li>
<li>Output: The function for the chemical molecular graph #322 in ncil is [GR(GL("ncil"), "seg_bert:molecule_function", instance#322)-&gt;r].</li>
<li>Input: What is the function for the chemical molecular graph #44 in ptc?</li>
<li>Output: The function for the chemical molecular graph #44 in ptc is [GR(GL("ptc"), "seg_bert:molecule_function", instance#44)-&gt;r].</li>
</ul>
<h2>4. Social Network Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: In foursquare, what is the id of user sparkey215's community?</li>
<li>Output: In foursquare, the id of user sparkey215's community is [GR(GL("foursquare"), "kmeans:community", user#sparkey215)-&gt;r].</li>
<li>Input: In the online social network foursquare, are user #user/9674821 and user #1janiszewski8 belong to the same community?</li>
<li>Output: In the online social network foursquare, user #user/9674821
and user #1janiszewski8 belong to [GR(GL("foursquare"), "kmeans: common_community_check", user#user/9674821, user#1janiszewski8)-&gt;r] community.</li>
</ul>
<h2>5. Recommender System Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: How likely user #A23E9QQHJLNGUI will be interested in item #B004PIPG2A in Amazon?</li>
<li>Output: The likelihood that user #A23E9QQHJLNGUI will be interested in item #B004PIPG2A in Amazon is [GR(GL("amazon"), "bpr:recommendation", user#A23E9QQHJLNGUI, item#B004PIPG2A)-&gt;r].</li>
<li>Input: How likely user #u329 will be interested in music of artist #i8323 in Last-fm?</li>
<li>Output: The likelihood that user #u329 will be interested in music from artist #i8323 in Last-fm is [GR(GL("lastfm"), "bpr:recommendation", user#u329, artist#i8323)-&gt;r].</li>
<li>Input: How likely user #u650 will be interested in movie #i671 in Movielens?</li>
<li>Output: The likelihood that user #u650 will be interested in movie #i671 in Movielens is [GR(GL("movielens"), "bpr:recommendation", user#u650, movie#i671)-&gt;r].</li>
</ul>
<h2>6. Knowledge Graph Reasoning Q\&amp;A Prompt Examples:</h2>
<ul>
<li>Input: According to the Freebase knowledge graph, what is the relation between entity#/m/053yx and entity#/m/015_lq?</li>
<li>Output: According to the Freebase knowledge graph, the relation between entity#/m/053yx and entity#/m/015_lq is [GR(GL("freebase"), "transe:relation", entity#/m/053yx, entity#/m/015_lq)-&gt;r].</li>
<li>Input: According to the WordNet knowledge graph, via relation #_hypernym, we derive entity #imagination.n. 02 from what entity? - Output: According to the WordNet knowledge graph, via relation #_hypernym, we can obtain entity #imagination.n. 02 from entity [GR(GL("wordnet"), "transe:head_entity", relation#_hypernym, entity#imagination.n.02)-&gt;r].</li>
</ul>
<h3>4.7 LLMs Inference and Graph Reasoning Query Parsing, Execution and Post-Processing</h3>
<p>Finally, at the end of this section, we will introduce the details about how to use the fine-tuned LLMs in Graph-ToolFormer for addressing various graph reasoning tasks. As shown in Figure 3, the graph reasoning process has several important steps based on several functional modules, which include (1) LLMs based output query statement generation, (2) query extraction and parsing, (3) query execution, (4) graph data hub, (5) graph model hub, (6) graph task hub, (7) working memory and (8) reasoning output post-processing. In this subsection, we will introduce these steps and the involved functional modules/hubs used in Graph-ToolFormer for readers.
4.7.1 LLMs Inference. Based on the prompt datasets, we have discussed about how to fine-tune the LLMs in Graph-ToolFormer in the previous subsections already, which is capable to generate the graph reasoning query statement outputs for the input statements. To apply the the fine-tuned LLMs for the inference, given any graph reasoning input statement, the LLMs will project the input statement to the corresponding output statement annotated with the API calls. We also provide an example about the inference process as follows:</p>
<ul>
<li>Input: The first paper in Cora has a topic of [TBR].</li>
<li>Output: The first paper in Cora has a topic of [GR(GL("cora"), "graph-bert:topic", {Paper#1}) -&gt; r].</li>
</ul>
<p>Meanwhile, by including the Q\&amp;A based prompt datasets for LLMs fine-tuning, the Graph-ToolFormer will also be capable to generate the graph reasoning statements for the input question queries as well, such as</p>
<ul>
<li>Input: What is the topic of the first paper in Cora bibliographic network?</li>
<li>Output: The first paper in Cora has a topic of [GR(GL("cora"), "graph-bert:topic", {Paper#1}) -&gt; r].</li>
</ul>
<p>The LLMs in Graph-ToolFormer can add the correct graph reasoning API calls into the output at the correct position for majority of the graph reasoning input statements and questions (we will illustrate the experimental results in the following Section 5). Such generated output statements with API calls will be fed to the following parser module to extract the graph reasoning queries.
4.7.2 Query Parser Module. Since we allow both nested and sequential API calls in Graph-ToolFormer, the parsing of the LLMs' generated output graph reasoning queries is never an easy task. Here, we can take the output query
"[GR(GL("cora"), "graph-bert:topic", {Paper#1})$&gt;r$ " generated by the LLMs introduced in the above subsection as an example. The Graph-ToolFormer framework introduce a query parser module that is capable to identify and parse the queries to a standard format that is recognizable and executable by the executor module. The expected parsing result of the query will involve two parts:</p>
<ul>
<li>Function Call Parsing: To differentiate normal textual tokens in the statement from the graph reasoning API call queries, we will use the regular expression to identify and parse the queries. The function call part of the query can be effectively identified with the following regular expression in python:</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="n">function_call_pattern</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">r</span><span class="o">&#39;\</span><span class="n">b</span><span class="p">([</span><span class="n">a</span><span class="o">-</span><span class="n">zA</span><span class="o">-</span><span class="n">Z_</span><span class="p">][</span><span class="n">a</span><span class="o">-</span><span class="n">zA</span><span class="o">-</span><span class="n">Z0</span><span class="o">-</span>9<span class="n">_</span>
<span class="w">    </span><span class="p">]</span><span class="o">*</span><span class="p">)</span><span class="o">\</span><span class="n">s</span><span class="o">*\</span><span class="p">(([</span>&quot;<span class="o">\</span><span class="c">%]])*)\&#39;</span>
</code></pre></div>

<p>which will detect both the API GR/GL function tokens, as well as the parameters in the API call. For the parameters in the API call, if we identify there exist any nested API calls (via detecting the parentheses marks ( and )), we will recursively parse the nested API call.</p>
<ul>
<li>Output Insertion Parsing: The extraction of the output insertion tag " $-&gt;r$ " will be much easier, which can be identified with the regular expression as well, i.e.,
output_variable_pattern = r')\s<em>([--&gt;]</em>)([a-zA-Z0
$-9 . \backslash s] <em>)\left{</em> *\right]$</li>
</ul>
<p>For the API calls studied in this paper, if the tag " $-&gt;r$ " exists, we will replace the query text to insert the graph reasoning results into the original text; otherwise, the query will be executed in the backend only, whose result will be recorded in the working memory to be introduced later.
For instance, for the example query generated by the LLM "[GR(GL("cora"), "graph-bert:topic", {Paper#1})$&gt;r$ ", its nested parsing result by the query parser module in the Graph-ToolFormer framework can be represented as "((GR, [(GL, ["cora"]), "graph-bert:topic", {Paper#1}]), [True])", where the "True" tag denotes the existence of the output insertion tag " $-&gt;r$ ", i.e., we need to replace the query text with the reasoning result into the output statement.
4.7.3 Graph Reasoning Hubs. Prior to the reasoning stage to execute the parsed queries, all the graph loading and reasoning API toolkits and models will be pre-loaded and ready-to-use. Also all the graph data to be loaded will be organized into a unified format that the graph loading API functions can handle. Specifically, we introduce several hubs in the Graph-ToolFormer framework, that will host the various graph datasets, pre-trained graph models and graph reasoning tasks, respectively.</p>
<ul>
<li>Graph Dataset Hub: A set of pre-processed graph datasets to be used in the Graph-ToolFormer framework will be organized into the graph dataset hub. All these datasets will have a unified format, and it will allow both the GraphToolFormer framework and the pre-trained graph models to access the desired information in the reasoning process. In the Appendix, we will describe the standard data organization format used by the source code of Graph-ToolFormer</li>
</ul>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: An Illustration of Graph Reasoning Query Processing. The graph reasoning query processing component in Graph-ToolFormer has several modules/hubs: (1) LLM based query statement generation, (2) query extraction and parsing model, (3) query execution model, (4) working memory module, and (5) output post-processing module. The graph reasoning query execution module is built based on the (6) graph reasoning task hub, (7) graph data hub, and (8) graph model hub. The Graph-ToolFormer framework will recognize the parsed graph reasoning queries, load the corresponding graph data, call the corresponding graph reasoning model, execute the reasoning task API function to generate the result, store the result into working memory and insert the output result to replace the reasoning query in the LLM generated reasoning response statement as well.
in the experiment. Specifically, the datasets hosted in the graph dataset hub include</p>
<ul>
<li>Graph Property Reasoning Dataset: GPR;</li>
<li>Bibliographic Network Datasets: Cora, Pubmed, Citeseer;</li>
<li>Molecular Graph Datasets: Proteins, Mutag, Nci1, Ptc;</li>
<li>Online Social Network Datasets: Twitter, Foursquare;</li>
<li>Recommender System Datasets: Amazon, Last-FM, Movielens;</li>
<li>Knowledge Graph Datasets: WordNet, Freebase.</li>
</ul>
<p>More detailed information about the graph datasets studied in this paper will be introduced in the following Section 5 when talking about the experiments.</p>
<ul>
<li>Graph Model Hub: In the Graph-ToolFormer framework, we also define a graph model hub for hosting several (ready-to-use) graph tools and pre-trained graph neural network models. Specifically, the graph models included in the GraphToolFormer framework include</li>
<li>Tools: created in this paper based on networkx for property calculation;</li>
<li>Graph-Bert [60]: built for graph representation and node classification;</li>
<li>SEG-Bert [58]: built for graph representation and graph instance classification;</li>
<li>KMeans [26]: built for graph partitioning and node clustering;</li>
<li>BPR [42]: built for link ranking and recommendation;</li>
<li>TransE [4]: built for graph entity/relation searching. More detailed information about these models will be introduced in the following Section 5. These graph models will implement the basic graph reasoning functions, which will be called in the specific graph reasoning tasks on the provided graph datasets.</li>
<li>Graph Task Hub: Finally, the graph task hub will define the specific graph reasoning tasks to be studied in the GraphToolFormer framework. As introduced in the previous Section 3.3, most of the graph reasoning tasks can be reduced to several very fumdamental graph learning tasks, e.g., (1) graph attribute calculation, (2) node classification, (3) graph classification, (4) graph partition/clustering, (5) link prediction/ranking and (6) graph searching tasks. For all the application oriented graph reasoning tasks as introduced in Section 4.3, i.e., (1) graph property reasoning, (2) bibliographic paper topic reasoning, (3) molecular graph function reasoning, (4) social network community reasoning, (5) recommender system reasoning and (6) knowledge graph reasoning, we will reduce them to the very fumdamental graph learning tasks in the graph task hub.</li>
</ul>
<p>Besides the hubs we mention above, within the GraphToolFormer framework, we also have an extra hub for hosting the LLMs to be used for the graph reasoning API generation based on the inputs received from the interaction with the end users.</p>
<p>The LLM hub will host a set of fine-tuned language models for the graph reasoning tasks. Specifically, within the Graph-ToolFormer framework studied in this paper, several LLMs (like GPT-3 6B 8bit can be included in the hub for the output graph reasoning statement generation.
4.7.4 Query Executor Module. Furthermore, the generation output will be further post-processed by detecting and initiating the API calls in it. Depending on whether the API call return result needs to be outputted or not, the executor Graph-ToolFormer will also further replace the API calls with its return result in the statement. For instance, for the example mentioned in Section 4.7.1, based on the parsing result "((GR, [(GL, ["cora"]), "graph-bert:topic", {Paper#1}]), [True])", Graph-ToolFormer will recognize and execute the query as follows:</p>
<ul>
<li>Outer Function: "GR", i.e., the outer function is a for graph reasoning.</li>
<li>Outer Function Parameters: "[(GL, ["cora"]), "graph-bert:topic", {Paper#1}]".</li>
<li>Parameter 1: " (GL, ["cora"])", the first parameter is a nested API call.</li>
<li>Inner Function: "GL", i.e., the inner function is a for graph loading.</li>
<li>Inner Function Parameter(s): "["cora"]", i.e., the graph loading API will load the Cora network dataset.</li>
<li>Parameter 2: " "graph-bert:topic"", the second parameter denotes the outer reasoning function aims to infer the topic with the Graph-Bert model.</li>
<li>Parameter 3: " {Paper#1}", the third parameter denotes the outer reasoning function focuses on the "Paper#1" in the input graph dataset.</li>
<li>Output Insertion Tag: "True", i.e., this query requires the replacement and insertion of this query result back into the statement.</li>
</ul>
<p>After parsing the query in the text, the query executor module in Graph-ToolFormer will execute the query by calling the corresponding API function with the provided graph data and parameters, i.e., "Graph-Bert.topic(cora, {Paper#1})", which will return the graph reasoning query result, i.e., Neural Networks, as the output bibliographic paper topic reasoning query. Furthermore, since the output insertion token " $-&gt;$ " exist in the query, the query executor module in Graph-ToolFormer will also replace the query token sequence with the reasoning results, which will generate the final output by the Graph-ToolFormer as follows:</p>
<ul>
<li>Input: The first paper in Cora has a topic of $[T B R]$.</li>
<li>Post-processed Output: The first paper in Cora has a topic of Neural Networks.
4.7.5 Working Memory Module. What's more, within the GraphToolFormer model, we also maintain a small-sized working memory, which keeps records of both the recent external API function calls (including both GL and GR API function calls) and their output results for the model in the reference stage. For instance, if the API calls on the graph loading $G L($ file-path, node-subset, link-subset) or on the graph reasoning $G R\left(G, d^{1}: f^{1}, a r g_{1}: o a l_{1}, a r g_{2}: o a l_{2}, \cdots, a r g_{n}: o a l_{n}\right)$ has been executed, then its read-only result will be stored into the working memory. In the future, if we have similar queries on the same graph dataset again, the stored results can be retrieved from the working memory directly as the output. Such a working memory is very helpful, especially for the API function calls like data loading or other graph reasoning API calls with large time or space costs. For instance, as shown in Table 1, after the example lollipop graph (the top left green graph) shown in Figure 1 has been loaded as $G_{I}$, we will just replace the data loading file name path with the graph $G_{I}$ directly. The reuse of pre-stored result from the working memory will save lots of time costs on graph reasoning tasks. The working memory has a pre-defined memory capacity in GraphToolFormer, and will maintain its stored information similar to a queue (i.e., FIFO). Once the stored information exceeds the working memory capacity, the result of the oldest API calls or the results which has been rewritten already will be removed from the working memory by Graph-ToolFormer.</li>
</ul>
<h2>5 EXPERIMENTS</h2>
<p>In this section, we will conduct extensive experiments to evaluate the performance of Graph-ToolFormer on various graph reasoning tasks that we have discussed before. According to the previous method section, we will use ChatGPT to generate a largesize of graph reasoning prompt dataset based on both the textual instructions and a small number of hand-crafted prompt reasoning examples. To ensure Graph-ToolFormer can handle diverse graph reasoning tasks, we will merge the generated prompt datasets for different graph reasoning tasks on different graph datasets together to obtain a mixed prompt dataset. By partitioning the mixed prompt dataset into training and testing sets, we will fine-tune existing pre-trained LLMs (e.g., GPT-1 or LLaMA) on the training set, and evaluate its generation performance on the testing set. What's more, the fine-tuned LLMs will be further plugged into GraphToolFormer for conducting graph reasoning based on the textual input statement or question queries. More details about the experimental settings and some experimental results will be provided in the following parts of this section. All the source code, datasets, and checkpoints of all the pre-trained graph models and fine-tuned LLMs have been released and shared to the community, which can be accessed via the github link provided at the beginning of this paper.</p>
<h3>5.1 Graph Benchmark Dataset Descriptions</h3>
<p>As introduced in the previous Section 4.7.3, about 15 different graph benchmark datasets are studied in this paper, which include</p>
<ul>
<li>Graph Property Reasoning Dataset: We create a toy dataset named "GPR" in this paper containing 37 special connected graph instances generated by networkx toolkit, which</li>
</ul>
<p>Table 3: A statistical summary of graph datasets used in the experiments of this paper. For the GPR and molecular graph datasets (including PROTEIN, PTC, NCI1 and MUTAG), the "Node#" and "Edge#" denote the average numbers of nodes and edges for the graph instances in the datasets, respectively. For the graphs without features or labels, we will fill the entries with "NA" in the table.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Tasks</th>
<th style="text-align: center;">Datasets</th>
<th style="text-align: center;">Graph Types</th>
<th style="text-align: center;">Node#</th>
<th style="text-align: center;">Edge#</th>
<th style="text-align: center;">Graph#</th>
<th style="text-align: center;">Feature#</th>
<th style="text-align: center;">Class#</th>
<th style="text-align: center;">Prompt#</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Graph Loading</td>
<td style="text-align: center;">GL-Prompt</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2,802</td>
</tr>
<tr>
<td style="text-align: center;">Property <br> Reasoning</td>
<td style="text-align: center;">GPR-Prompt</td>
<td style="text-align: center;">Generated classic graphs</td>
<td style="text-align: center;">14.70 (avg)</td>
<td style="text-align: center;">28.27 (avg)</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2,587</td>
</tr>
<tr>
<td style="text-align: center;">Paper <br> Topic <br> Reasoning</td>
<td style="text-align: center;">Cora</td>
<td style="text-align: center;">Bibliographic network</td>
<td style="text-align: center;">2,708</td>
<td style="text-align: center;">5,429</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1,433</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">18,956</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Citeseer</td>
<td style="text-align: center;">Bibliographic network</td>
<td style="text-align: center;">3,327</td>
<td style="text-align: center;">4,732</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3,703</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">23,184</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Pubmed</td>
<td style="text-align: center;">Bibliographic network</td>
<td style="text-align: center;">19,717</td>
<td style="text-align: center;">44,338</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">500</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">138,019</td>
</tr>
<tr>
<td style="text-align: center;">Molecule <br> Function <br> Reasoning</td>
<td style="text-align: center;">PROTEINS</td>
<td style="text-align: center;">Protein molecular graphs</td>
<td style="text-align: center;">39.05 (avg)</td>
<td style="text-align: center;">72.82 (avg)</td>
<td style="text-align: center;">1,113</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">6,678</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PTC</td>
<td style="text-align: center;">Chemical molecular graphs</td>
<td style="text-align: center;">25.56 (avg)</td>
<td style="text-align: center;">25.96 (avg)</td>
<td style="text-align: center;">344</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2,064</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NCI1</td>
<td style="text-align: center;">Chemical molecular graphs</td>
<td style="text-align: center;">29.86 (avg)</td>
<td style="text-align: center;">32.30 (avg)</td>
<td style="text-align: center;">4,110</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">24,660</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MUTAG</td>
<td style="text-align: center;">Chemical molecular graphs</td>
<td style="text-align: center;">17.93 (avg)</td>
<td style="text-align: center;">19.79 (avg)</td>
<td style="text-align: center;">188</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1,128</td>
</tr>
<tr>
<td style="text-align: center;">Sequential <br> Recommendation <br> Reasoning</td>
<td style="text-align: center;">MovieLens</td>
<td style="text-align: center;">Recommender system</td>
<td style="text-align: center;">2,625</td>
<td style="text-align: center;">100,000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">5 (rating)</td>
<td style="text-align: center;">500,000</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Last.FM</td>
<td style="text-align: center;">Recommender system</td>
<td style="text-align: center;">19,524</td>
<td style="text-align: center;">118,268</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">2 (binary)</td>
<td style="text-align: center;">355,320</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Amazon</td>
<td style="text-align: center;">Recommender system</td>
<td style="text-align: center;">396,810</td>
<td style="text-align: center;">450,578</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">5 (rating)</td>
<td style="text-align: center;">2,252,890</td>
</tr>
<tr>
<td style="text-align: center;">Social <br> Community <br> Reasoning</td>
<td style="text-align: center;">Foursquare</td>
<td style="text-align: center;">Social network</td>
<td style="text-align: center;">5,392</td>
<td style="text-align: center;">76,972</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">64,710</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Twitter</td>
<td style="text-align: center;">Social network</td>
<td style="text-align: center;">5,223</td>
<td style="text-align: center;">164,920</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">52,240</td>
</tr>
<tr>
<td style="text-align: center;">Knowledge <br> Graph <br> Reasoning</td>
<td style="text-align: center;">Freebase</td>
<td style="text-align: center;">Knowledge graph</td>
<td style="text-align: center;">14,951</td>
<td style="text-align: center;">592,213</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">1,695,651</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">WordNet</td>
<td style="text-align: center;">Knowledge graph</td>
<td style="text-align: center;">41,105</td>
<td style="text-align: center;">151,442</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">NA</td>
<td style="text-align: center;">454,326</td>
</tr>
</tbody>
</table>
<p>include the "bull graph", "wheel graph", "lollipop graph", etc. These generated graph instances all have a relatively small size with about 15 nodes and and 28 links on average.</p>
<ul>
<li>Bibliographic Network Datasets: We use three benchmark bibliographic network datasets in the experiment for to infer the paper topics with Graph-ToolFormer, which include Cora, Pubmed, Citeseer [19, 60]. Each node in these bibliographic networks denotes an academic paper, which are annotated with both numerical features and categorical labels indicating the paper topics.</li>
<li>Molecular Graph Datasets: We use four molecular graph benchmark datasets in the experiments, which include PROTEINS, MUTAG, NCI1, PTC [55, 58]. For the molecular graphs in these four datasets, we can obtain their topological structures and categorical label indicating the molecular graph functions.</li>
<li>Social Network Datasets: Two online social network benchmark datasets Twitter, Foursquare [21] are investigated in this experiment. We can obtain both the social connections among the users and other diverse heterogeneous
information. In the experiment, we will only use the social connections among the users to reason for the social communities from the social networks.</li>
<li>Recommender System Datasets: Three sequential recommender system datasets Amazon (Software) [27], Last-FM [3], Movielens (100K) [14] are studied in this paper. For each recommender system, we have the user-item interaction records annotated with the timestamps. Existing sequential recommender systems will partition the datasets into training/testing sets by the timestamps: the historical records will be used for model training and the last interaction is used for testing. We will follow the same settings in the experiment.</li>
<li>Knowledge Graph Datasets: We also obtain and use two knowledge graph benchmark datasets WordNet [30], Freebase [2] in the experiments. These datasets will be partitioned into training/testing sets for knowledge graph embedding and model training.</li>
</ul>
<p>To make it easier for the graph data hub to load the graph datasets for various reasoning tasks, we will pre-process the datasets and organize the graph information into a unified format, which has</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://networkx.org/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>