<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3450 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3450</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3450</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-214605613</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2003.08978v2.pdf" target="_blank">Generating new concepts with hybrid neuro-symbolic models</a></p>
                <p><strong>Paper Abstract:</strong> Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3450.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3450.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-based / Structured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured knowledge / theory-based representation (intuitive theories, symbolic representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of functional-level theories that represent concepts as structured, compositional, and often causal knowledge (e.g., hierarchies, grammars, programs or intuitive theories) rather than as unstructured statistical patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>theory-based representation (structured/intuitive theories)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as symbolic, compositional structures or programs (parts, relations, causal procedures) that encode causal roles, reusable parts, and rules for composition and substitution; learning proceeds by inferring structured hypotheses (e.g., programs) that generate observed examples.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Behavioral and modeling work motivating structured representations is cited (e.g., BPL results): structured inductive biases enable strong few-shot generalization and explain humanlike compositional generalization; in this paper, models that embody stronger compositional structure (Full NS, and prior BPL) generalize better to novel alphabets and produce character samples that are structurally coherent and more creative.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Purely symbolic/parametric structured models (e.g., BPL as implemented previously) can make simplifying parametric assumptions that fail to capture rich, nonparametric correlations and style-level variability in high-dimensional raw data; such models can produce characters lacking the rich correlational structure of human drawings because of restrictive priors (e.g., stroke-independence assumptions in BPL's prior).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted repeatedly with statistical/distributed accounts: the paper argues structured representations better support compositional/causal generalization (Full NS and BPL outperform generic neural models on novel-alphabet/generalization tasks), while purely statistical neural models capture richer low-level correlations but struggle with systematic compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to combine the flexible, nonparametric correlational power of statistical models with the causal/compositional strengths of symbolic theories remains open; symbolic models' parametric simplifications limit fit to raw sensory data, and it is unclear which form of symbolic abstraction best matches human internal representations across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3450.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3450.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Statistical / Distributed</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Statistical knowledge / distributed representation (neural networks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of functional-level views that conceptual knowledge emerges from rich patterns of correlations learned by statistical systems such as neural networks, yielding distributed representations rather than explicit symbolic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>statistical / distributed representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented implicitly as patterns of activation or parameters in statistical models (e.g., neural network weights and distributed embeddings) learned from co-occurrence and sensory statistics, without explicit symbolic compositional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Neural-network-based generative models capture complex correlational structure, stylistic consistency, and high-dimensional invariances in raw data; in this paper, generic neural models (Hierarchical LSTM and Baseline LSTM) produce samples with rich detail and can perform well on easier within-alphabet generalization (character-splits), sometimes matching or exceeding structured models.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Standard neural networks lack explicit compositional and causal structure, which leads to poorer generalization to novel systematic variations (e.g., novel alphabets) and difficulties in creative generalization; they may rely on exemplar-like memorization rather than inferring generative rules (evidence: Baseline/H-LSTM performed worse on alphabet-splits and produced samples closer to nearest training examples).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Paper contrasts statistical accounts with structured/program-based accounts, arguing that pure statistical representations excel at capturing low-level correlations but fail at systematic compositional generalization that structured representations handle; motivates hybrid neuro-symbolic approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Unclear how distributed statistical representations can be constrained to encode compositional causal knowledge without hand-designed structure; determining what architectural biases or learning objectives yield humanlike compositional generalization remains an open problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3450.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3450.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BPL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Program Learning (BPL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic program induction framework that represents concepts as generative programs capturing compositional and causal structure and performs Bayesian inference to learn programs from few examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Human-level concept learning through probabilistic program induction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>probabilistic program / program-induction representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as generative programs (symbolic expressions) that generate sensory data; learning is Bayesian inference over program hypotheses, exploiting strong compositional and causal inductive biases to support few-shot generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Prior BPL work (cited and sampled in this paper) demonstrates human-level few-shot concept learning and can generate novel characters; in the present paper, BPL samples are used as a baseline showing strong compositional structure in generated characters.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>As implemented previously, BPL uses parametric simplifications (e.g., stroke-independence in the prior) that limit its ability to capture rich, nonparametric correlations and stylistic variation in human drawings; thus BPL samples can lack the finer correlational structure captured by neural-enhanced models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>BPL exemplifies the structured/theory-based approach and is directly compared to both hybrid (Full NS) and purely neural models: Full NS outperforms BPL qualitatively by combining symbolic programs with learned neural components that capture richer correlations, while BPL retains strong compositional expressivity but weaker fit to raw high-dimensional statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to relax BPL's parametric assumptions and incorporate richer, learned perceptual/statistical modules while preserving programmatic compositionality; scalability of full program-induction approaches to more complex, high-dimensional concepts remains an open issue.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3450.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3450.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Full NS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Full Neuro-Symbolic model (Full NS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid neuro-symbolic probabilistic program that represents characters as sequences of symbolic parts (strokes) rendered to an image canvas, with neural networks (CNNs, LSTMs with attention) providing flexible conditional distributions over part locations and trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>neuro-symbolic probabilistic program (hybrid representation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are functionally represented as symbolic, compositional generative programs (sequence of strokes with explicit rendering) whose stochastic parameters and conditional distributions are implemented by neural networks; the symbolic program enforces causal/compositional structure while neural modules capture complex, nonparametric correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Empirical results in this paper: Full NS achieves the best negative log-likelihoods on held-out novel-alphabet (alphabet-splits) and on the held-out evaluation set, and its generated samples are judged more creative and less exemplar-mimicking (fewer samples match nearest training neighbors) than purely neural alternatives; Full NS samples also show stylistic/structural consistency across strokes.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Model imposes stronger structural constraints that can limit arbitrary information flow between parts compared to monolithic networks, potentially missing correlations that require cross-part interactions beyond rendering-and-encoding; design choices (e.g., renderer interface, attention architecture) may restrict model flexibility and require careful engineering; the approach has been tested only on simple visual concepts (Omniglot).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Compared directly to purely neural (H-LSTM, Baseline) and purely symbolic (BPL) models: Full NS outperforms generic neural models on generalization to novel alphabets and produces richer correlations than BPL—supporting the claim that hybrid representations combine the strengths of structured and statistical accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Open questions include how far this hybrid approach scales to richer domains beyond simple handwritten characters, how symbolic and neural components should be balanced, and whether the representational constraints align with human brain representations; also, Full NS's restriction of inter-part information flow may be limiting in some domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3450.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3450.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>H-LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hierarchical LSTM (H-LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A more structured neural baseline that models characters as sequences of stroke parts with a hierarchical recurrent architecture: a character-level LSTM that receives encoded strokes and outputs distributions for next stroke location and trajectory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>hierarchical recurrent (part-based distributed representation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented implicitly in hierarchical recurrent activations: strokes are explicit parts but their interactions and causal mappings are learned via recurrent state (encoders + character-level LSTM) rather than by an explicit symbolic renderer.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>H-LSTM captures part structure via explicit stroke decomposition and can model dependencies between parts through recurrent state; in some character-split experiments it performs competitively, reflecting its capacity to learn compositional-like structure from data.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Lacks an explicit causal renderer mapping motor actions to pixel images, so it must learn how strokes affect images via recurrent memory, which can be harder and lead to worse generalization on novel alphabets; in alphabet-splits and holdout tests it underperforms Full NS.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Serves as an intermediate between purely symbolic (BPL) and fully unstructured neural (Baseline): compared to Full NS it lacks an explicit symbolic rendering step and thus captures less causal structure, which the paper links to reduced generalization to novel alphabets.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How much explicit causal machinery (like rendering) is necessary versus what can be learned end-to-end by recurrent architectures; whether hierarchical recurrent memory can scale to richer compositional domains without explicit symbolic interfaces remains open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3450.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3450.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baseline unrolled LSTM (Sketch-RNN style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A monolithic, purely statistical recurrent model that represents a character as one long sequence of pen actions (offsets and pen state), trained to predict next pen offsets and termination states with mixture-density outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>sequential distributed representation (action-sequence based)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as long sequences of low-level motor/pen actions encoded in recurrent neural activations without explicit part decomposition or symbolic causal structure; generation is purely statistical prediction of next action conditioned on sequence history.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Baseline LSTM can produce detailed character samples and performs competitively on easier within-alphabet generalization (character-splits), sometimes achieving the best losses when test characters are similar to training classes, indicating strong exemplar-style learning.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Tends to mimic training examples and shows weaker generalization to novel alphabets (poorer performance on alphabet-splits and holdout set); samples are more often near nearest training neighbors, suggesting reliance on memorization rather than abstract generative structure.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Represents the extreme statistical end of the spectrum; compared to structured and hybrid models, it captures rich low-level correlations but fails at systematic compositional generalization; contrasted empirically with Full NS and H-LSTM in the paper's evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Does not explicitly encode compositionality or causal rendering; open questions include what architectural or training changes (inductive biases) are required for such sequential distributed models to acquire humanlike compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Human-level concept learning through probabilistic program induction <em>(Rating: 2)</em></li>
                <li>How to grow a mind: Statistics, structure, and abstraction <em>(Rating: 2)</em></li>
                <li>A neural representation of sketch drawings <em>(Rating: 2)</em></li>
                <li>Generating sequences with recurrent neural networks <em>(Rating: 2)</em></li>
                <li>The discovery of structural form <em>(Rating: 2)</em></li>
                <li>Building machines that learn and think like people <em>(Rating: 2)</em></li>
                <li>The Algebraic Mind: Integrating Connectionism and Cognitive Science <em>(Rating: 1)</em></li>
                <li>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3450",
    "paper_id": "paper-214605613",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "Theory-based / Structured",
            "name_full": "Structured knowledge / theory-based representation (intuitive theories, symbolic representations)",
            "brief_description": "A family of functional-level theories that represent concepts as structured, compositional, and often causal knowledge (e.g., hierarchies, grammars, programs or intuitive theories) rather than as unstructured statistical patterns.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "theory-based representation (structured/intuitive theories)",
            "theory_description": "Concepts are represented as symbolic, compositional structures or programs (parts, relations, causal procedures) that encode causal roles, reusable parts, and rules for composition and substitution; learning proceeds by inferring structured hypotheses (e.g., programs) that generate observed examples.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Behavioral and modeling work motivating structured representations is cited (e.g., BPL results): structured inductive biases enable strong few-shot generalization and explain humanlike compositional generalization; in this paper, models that embody stronger compositional structure (Full NS, and prior BPL) generalize better to novel alphabets and produce character samples that are structurally coherent and more creative.",
            "counter_evidence_or_challenges": "Purely symbolic/parametric structured models (e.g., BPL as implemented previously) can make simplifying parametric assumptions that fail to capture rich, nonparametric correlations and style-level variability in high-dimensional raw data; such models can produce characters lacking the rich correlational structure of human drawings because of restrictive priors (e.g., stroke-independence assumptions in BPL's prior).",
            "comparison_to_other_theories": "Contrasted repeatedly with statistical/distributed accounts: the paper argues structured representations better support compositional/causal generalization (Full NS and BPL outperform generic neural models on novel-alphabet/generalization tasks), while purely statistical neural models capture richer low-level correlations but struggle with systematic compositional generalization.",
            "notable_limitations_or_open_questions": "How to combine the flexible, nonparametric correlational power of statistical models with the causal/compositional strengths of symbolic theories remains open; symbolic models' parametric simplifications limit fit to raw sensory data, and it is unclear which form of symbolic abstraction best matches human internal representations across domains.",
            "uuid": "e3450.0",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Statistical / Distributed",
            "name_full": "Statistical knowledge / distributed representation (neural networks)",
            "brief_description": "A class of functional-level views that conceptual knowledge emerges from rich patterns of correlations learned by statistical systems such as neural networks, yielding distributed representations rather than explicit symbolic structures.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "statistical / distributed representation",
            "theory_description": "Concepts are represented implicitly as patterns of activation or parameters in statistical models (e.g., neural network weights and distributed embeddings) learned from co-occurrence and sensory statistics, without explicit symbolic compositional structure.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Neural-network-based generative models capture complex correlational structure, stylistic consistency, and high-dimensional invariances in raw data; in this paper, generic neural models (Hierarchical LSTM and Baseline LSTM) produce samples with rich detail and can perform well on easier within-alphabet generalization (character-splits), sometimes matching or exceeding structured models.",
            "counter_evidence_or_challenges": "Standard neural networks lack explicit compositional and causal structure, which leads to poorer generalization to novel systematic variations (e.g., novel alphabets) and difficulties in creative generalization; they may rely on exemplar-like memorization rather than inferring generative rules (evidence: Baseline/H-LSTM performed worse on alphabet-splits and produced samples closer to nearest training examples).",
            "comparison_to_other_theories": "Paper contrasts statistical accounts with structured/program-based accounts, arguing that pure statistical representations excel at capturing low-level correlations but fail at systematic compositional generalization that structured representations handle; motivates hybrid neuro-symbolic approaches.",
            "notable_limitations_or_open_questions": "Unclear how distributed statistical representations can be constrained to encode compositional causal knowledge without hand-designed structure; determining what architectural biases or learning objectives yield humanlike compositional generalization remains an open problem.",
            "uuid": "e3450.1",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "BPL",
            "name_full": "Bayesian Program Learning (BPL)",
            "brief_description": "A probabilistic program induction framework that represents concepts as generative programs capturing compositional and causal structure and performs Bayesian inference to learn programs from few examples.",
            "citation_title": "Human-level concept learning through probabilistic program induction",
            "mention_or_use": "use",
            "theory_name": "probabilistic program / program-induction representation",
            "theory_description": "Concepts are represented as generative programs (symbolic expressions) that generate sensory data; learning is Bayesian inference over program hypotheses, exploiting strong compositional and causal inductive biases to support few-shot generalization.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Prior BPL work (cited and sampled in this paper) demonstrates human-level few-shot concept learning and can generate novel characters; in the present paper, BPL samples are used as a baseline showing strong compositional structure in generated characters.",
            "counter_evidence_or_challenges": "As implemented previously, BPL uses parametric simplifications (e.g., stroke-independence in the prior) that limit its ability to capture rich, nonparametric correlations and stylistic variation in human drawings; thus BPL samples can lack the finer correlational structure captured by neural-enhanced models.",
            "comparison_to_other_theories": "BPL exemplifies the structured/theory-based approach and is directly compared to both hybrid (Full NS) and purely neural models: Full NS outperforms BPL qualitatively by combining symbolic programs with learned neural components that capture richer correlations, while BPL retains strong compositional expressivity but weaker fit to raw high-dimensional statistics.",
            "notable_limitations_or_open_questions": "How to relax BPL's parametric assumptions and incorporate richer, learned perceptual/statistical modules while preserving programmatic compositionality; scalability of full program-induction approaches to more complex, high-dimensional concepts remains an open issue.",
            "uuid": "e3450.2",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Full NS",
            "name_full": "Full Neuro-Symbolic model (Full NS)",
            "brief_description": "A hybrid neuro-symbolic probabilistic program that represents characters as sequences of symbolic parts (strokes) rendered to an image canvas, with neural networks (CNNs, LSTMs with attention) providing flexible conditional distributions over part locations and trajectories.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "neuro-symbolic probabilistic program (hybrid representation)",
            "theory_description": "Concepts are functionally represented as symbolic, compositional generative programs (sequence of strokes with explicit rendering) whose stochastic parameters and conditional distributions are implemented by neural networks; the symbolic program enforces causal/compositional structure while neural modules capture complex, nonparametric correlations.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Empirical results in this paper: Full NS achieves the best negative log-likelihoods on held-out novel-alphabet (alphabet-splits) and on the held-out evaluation set, and its generated samples are judged more creative and less exemplar-mimicking (fewer samples match nearest training neighbors) than purely neural alternatives; Full NS samples also show stylistic/structural consistency across strokes.",
            "counter_evidence_or_challenges": "Model imposes stronger structural constraints that can limit arbitrary information flow between parts compared to monolithic networks, potentially missing correlations that require cross-part interactions beyond rendering-and-encoding; design choices (e.g., renderer interface, attention architecture) may restrict model flexibility and require careful engineering; the approach has been tested only on simple visual concepts (Omniglot).",
            "comparison_to_other_theories": "Compared directly to purely neural (H-LSTM, Baseline) and purely symbolic (BPL) models: Full NS outperforms generic neural models on generalization to novel alphabets and produces richer correlations than BPL—supporting the claim that hybrid representations combine the strengths of structured and statistical accounts.",
            "notable_limitations_or_open_questions": "Open questions include how far this hybrid approach scales to richer domains beyond simple handwritten characters, how symbolic and neural components should be balanced, and whether the representational constraints align with human brain representations; also, Full NS's restriction of inter-part information flow may be limiting in some domains.",
            "uuid": "e3450.3",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "H-LSTM",
            "name_full": "Hierarchical LSTM (H-LSTM)",
            "brief_description": "A more structured neural baseline that models characters as sequences of stroke parts with a hierarchical recurrent architecture: a character-level LSTM that receives encoded strokes and outputs distributions for next stroke location and trajectory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "hierarchical recurrent (part-based distributed representation)",
            "theory_description": "Concepts are represented implicitly in hierarchical recurrent activations: strokes are explicit parts but their interactions and causal mappings are learned via recurrent state (encoders + character-level LSTM) rather than by an explicit symbolic renderer.",
            "level_of_analysis": "functional",
            "supporting_evidence": "H-LSTM captures part structure via explicit stroke decomposition and can model dependencies between parts through recurrent state; in some character-split experiments it performs competitively, reflecting its capacity to learn compositional-like structure from data.",
            "counter_evidence_or_challenges": "Lacks an explicit causal renderer mapping motor actions to pixel images, so it must learn how strokes affect images via recurrent memory, which can be harder and lead to worse generalization on novel alphabets; in alphabet-splits and holdout tests it underperforms Full NS.",
            "comparison_to_other_theories": "Serves as an intermediate between purely symbolic (BPL) and fully unstructured neural (Baseline): compared to Full NS it lacks an explicit symbolic rendering step and thus captures less causal structure, which the paper links to reduced generalization to novel alphabets.",
            "notable_limitations_or_open_questions": "How much explicit causal machinery (like rendering) is necessary versus what can be learned end-to-end by recurrent architectures; whether hierarchical recurrent memory can scale to richer compositional domains without explicit symbolic interfaces remains open.",
            "uuid": "e3450.4",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Baseline LSTM",
            "name_full": "Baseline unrolled LSTM (Sketch-RNN style)",
            "brief_description": "A monolithic, purely statistical recurrent model that represents a character as one long sequence of pen actions (offsets and pen state), trained to predict next pen offsets and termination states with mixture-density outputs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "sequential distributed representation (action-sequence based)",
            "theory_description": "Concepts are represented as long sequences of low-level motor/pen actions encoded in recurrent neural activations without explicit part decomposition or symbolic causal structure; generation is purely statistical prediction of next action conditioned on sequence history.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Baseline LSTM can produce detailed character samples and performs competitively on easier within-alphabet generalization (character-splits), sometimes achieving the best losses when test characters are similar to training classes, indicating strong exemplar-style learning.",
            "counter_evidence_or_challenges": "Tends to mimic training examples and shows weaker generalization to novel alphabets (poorer performance on alphabet-splits and holdout set); samples are more often near nearest training neighbors, suggesting reliance on memorization rather than abstract generative structure.",
            "comparison_to_other_theories": "Represents the extreme statistical end of the spectrum; compared to structured and hybrid models, it captures rich low-level correlations but fails at systematic compositional generalization; contrasted empirically with Full NS and H-LSTM in the paper's evaluations.",
            "notable_limitations_or_open_questions": "Does not explicitly encode compositionality or causal rendering; open questions include what architectural or training changes (inductive biases) are required for such sequential distributed models to acquire humanlike compositional generalization.",
            "uuid": "e3450.5",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Human-level concept learning through probabilistic program induction",
            "rating": 2,
            "sanitized_title": "humanlevel_concept_learning_through_probabilistic_program_induction"
        },
        {
            "paper_title": "How to grow a mind: Statistics, structure, and abstraction",
            "rating": 2,
            "sanitized_title": "how_to_grow_a_mind_statistics_structure_and_abstraction"
        },
        {
            "paper_title": "A neural representation of sketch drawings",
            "rating": 2,
            "sanitized_title": "a_neural_representation_of_sketch_drawings"
        },
        {
            "paper_title": "Generating sequences with recurrent neural networks",
            "rating": 2,
            "sanitized_title": "generating_sequences_with_recurrent_neural_networks"
        },
        {
            "paper_title": "The discovery of structural form",
            "rating": 2,
            "sanitized_title": "the_discovery_of_structural_form"
        },
        {
            "paper_title": "Building machines that learn and think like people",
            "rating": 2,
            "sanitized_title": "building_machines_that_learn_and_think_like_people"
        },
        {
            "paper_title": "The Algebraic Mind: Integrating Connectionism and Cognitive Science",
            "rating": 1,
            "sanitized_title": "the_algebraic_mind_integrating_connectionism_and_cognitive_science"
        },
        {
            "paper_title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
            "rating": 1,
            "sanitized_title": "generalization_without_systematicity_on_the_compositional_skills_of_sequencetosequence_recurrent_networks"
        }
    ],
    "cost": 0.01172175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Generating new concepts with hybrid neuro-symbolic models</p>
<p>Reuben Feinman reuben.feinman@nyu.edu 
Center for Neural Science
Department of Psychology and Center for Data Science
New York University
Brenden M. Lake</p>
<p>New York University</p>
<p>Generating new concepts with hybrid neuro-symbolic models
Neural networkscompositionalitycausalitygenerative models
Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
<p>Introduction</p>
<p>People can synthesize new concepts in imaginative ways; architects design new houses, chefs invent new recipes, and entrepreneurs create new business models. The resulting productions exhibit novel variations but maintain important structural consistencies with known entities. In contrast, state-of-the-art generative models from machine learning struggle with creative imagination, producing samples that either closely mimic the training data or that exhibit anomalous characteristics . How do people create novel yet coherent new concepts? How can we understand these abilities in computational terms?</p>
<p>Human conceptual knowledge plays a central role in creative generalization. A chef knows not only a repertoire of recipes, but also understands that recipes are built from reusable ingredients (e.g. carrots, flour, butter), and that these ingredients satisfy specific roles (thickening, seasoning, greasing). Furthermore, a chef understands which ingredients can substitute for others (e.g. butter for oil when greasing) and which should never be combined (e.g. ketchup and milk). In addition, they understand that recipes are composed of reusable causal procedures (cutting, whisking, browning), and they know how to compose these procedures in terms of order and substitutability. This causal and compositional knowledge is essential to understanding a culinary concept, as opposed to merely executing it, and is essential to a chef's ability to create new culinary concepts such as "carrots tartar" or "pea guacamole."</p>
<p>There have been two traditions of work on computational models of conceptual knowledge. The first tradition emphasizes "structured knowledge" for capturing relations between concepts and correlations between conceptual features, viewing concepts as embedded in intuitive theories (Murphy &amp; Medin, 1985) or capturing structured knowledge through symbolic representations such as hierarchies, trees, grammars and programs (Kemp &amp; Tenenbaum, 2008, 2009Tenenbaum et al., 2011). This tradition has prioritized the compositional and causal nature of conceptual knowledge, as emphasized through accounts of concept learning as program induction (Goodman et al., 2008;Stuhlmuller et al., 2010;Lake et al., 2015;Goodman et al., 2015;Ellis et al., 2018;Lake &amp; Piantadosi, 2019). The Bayesian Program Learning (BPL) framework (Lake et al., 2015), for example, demonstrates how to learn programs from images to express the causal and compositional nature of concepts and background knowledge. Although these models offer a convincing account for how strong inductive biases support flexible generalization, they often make simplifying and rigid parametric assumptions about the distributions of concepts in pursuit of a structured representation. As a result, they so far have been unsuccessful in characterizing the most complex correlations and invariances associated with human concepts in raw, highdimensional stimulus spaces.</p>
<p>The second tradition in models of conceptual knowledge emphasizes "statistical knowledge," a more amorphous form of background knowledge that is often not amenable to symbolic description. In the statistics view, conceptual knowledge manifests as complex systems of patterns and correlations recorded from observations. The meaning of a word, for example, can be derived from its patterns of co-occurrance with other words (Deerwester et al., 1990). Similarly, latent representations of objects and other sensory stimuli can be derived from "suspicious coincidences" noted in the data (Barlow, 1989). The statistics view emphasizes emergence, where conceptual knowledge emerges from the interaction of simpler processes, as operationalized through training neural network architectures (McClelland, 2010). Although a powerful modeling tool, standard neural networks do not explicitly model the compositional and causal structure of concepts. As result, they have difficulty generalizing to examples that vary systematically from training (Marcus, 2003;Lake &amp; Baroni, 2018), and to novel tasks, especially those that demand more generative and creative abilities (Lake et al., 2017.</p>
<p>Our goal in this paper is to explore generative models of concepts at the interface of these structured and statistical traditions, offering new ways of synthesizing key ideas from each. Previous efforts to integrate these traditions have demonstrated ways of performing statistical inference over structured representations . This includes models of concept learning as Bayesian inference over fully-symbolic expressions in formal logical (Goodman et al., 2008;Piantadosi et al., 2016), or models of inductive reasoning supported by structured intuitive theories (Kemp &amp; Tenenbaum, 2009). In accounts of this nature, statistics is primary in selecting between structured symbolic hypotheses (Kemp &amp; Tenenbaum, 2008;Perfors et al., 2011;Lake et al., 2015;Lake &amp; Piantadosi, 2019), while only secondary in selecting the constrained parametric distributions encapsulated in those hypotheses (Gaussians, multinomials, etc.).</p>
<p>Here we aim to more thoroughly integrate the structured and statistical traditions through hybrid neuro-symbolic generative models. Our goal is to devise a causal generative model with explicit compositional structure, and with complex correlations represented implicitly through neural networks rather than simple parametric distributions. We use simple visual concepts -handwritten characters from the world's languages -as a case study for exploring neurosymbolic models of concept generation. The Omniglot dataset (Lake et al., 2015) of handwritten characters provides an excellent preliminary modeling environment: it contains a large number of natural, simple concepts that people learn and use, and it has been explored extensively in prior work from both cognitive science and AI. Following the mixture density network framework for handwriting generation (Graves, 2013), we explore three distinct generative neural architectures, varying the strength and form of inductive bias imposed on the model, including their position on the neurosymbolic spectrum and the fidelity in which compositionality and causality are presented. We evaluate the generalization capacity of these models by comparing their log-likelihoods on a holdout set of characters. Furthermore, we analyze the samples produced by each model, looking for characters that are qualitatively consistent but sufficiently dissimilar from the training set. We find that a hybrid neuro-symbolic architecture with the strongest form of compositional structure exhibits the best generalization performance, and that it generates characters that are highly consistent with human drawings. In contrast, our generic neural models exhibit weaker performance on the holdout set, and they produce characters that more closely mimic the training examples.</p>
<p>Related Work</p>
<p>In the machine learning community, there have been a number of works studying generative neural network models for handwritten characters, including DRAW (Gregor et al., 2015), AIR (Eslami et al., 2016) and SPIRAL (Ganin et al., 2018). Although these models learn a procedure to generate new characters, they do not use the human drawing data from Omniglot, and therefore the generative process may not reflect the true causal processes of human character production. Our goal is different in that we aim to model the causal process of human handwriting directly from drawing data. Ha &amp; Eck (2018) introduced a neural network architecture called Sketch-RNN to model human drawing data for simple objects like cats, firetrucks, and windmills. Although their goal loosely resembles our own, the Sketch-RNN model is trained on just a single class of objects at one time (e.g. "cat"), and it receives 70,000 examples from the class. In contrast, our motivation is to model human conceptual knowledge of handwriting concepts in general. This background knowledge plays a central role in creative generalization, enabling people to synthesize new concepts that deviate from the observed entities. We train our models on many character classes at once, providing only 20 training examples of each class and asking them to generate new character concepts. The Sketch-RNN model has not been applied in this way.</p>
<p>Most related to our work is the Bayesian Program Learning (BPL) approach of Lake et al. (2015) that was also applied to the simple visual concepts in Omniglot. BPL is a parametric Bayesian model that captures causal, compositional structure in human background knowledge of handwriting, and shows that these ingredients are important for few-shot learning of new character concepts. Beyond supporting fewshot learning, the BPL character prior can also generate new character concepts by unconditional sampling. Although a powerful demonstration of compositional representation, the BPL parametric model makes many simplifying assumptions about characters. For example, it assumes that strokes in a character are generated largely independently from each other in the prior (although they are strongly correlated in the posterior). As result, new characters generated by the model often lack the rich correlation structure of human drawings. We build on this work and develop a new neuro-symbolic model that represents the compositional structure of characters while using neural networks to capture richer correlations.</p>
<p>Omniglot Case Study</p>
<p>We use simple visual concepts as a case study for modeling conceptual structure and developing generative models of concepts. The Omniglot dataset contains human drawings of characters from 50 unique alphabets, providing a large set of cognitively natural concepts that are simple enough for evaluating models (Lake et al., 2015. In our experiments, we use drawings from the Omniglot background set to train our models, which contains 30 alphabets and a total of 19,280 unique drawings. We also use 10 alphabets from the Omniglot evaluation set as a holdout set for quantitative evaluations, reserving the remaining 10 alphabets for future work on few-shot classification.</p>
<p>In the drawing data, a stroke is represented as a variablelength sequence of pen locations {z 1 , ..., z T }, with z i ∈ R 2 (Fig. 2, left). As a pre-processing step, we convert each stroke into a minimal spline representation using least-squares optimization ( Fig. 2, right), borrowing the B-spline tools from Lake et al. (2015). The number of spline control points depends on the stroke complexity and is determined by a resid-  GenerateCharacter consists of sequentially reading from and rendering to an image canvas, which is initialized to zero. At each time step, the current canvas I is fed to procedure GenerateStroke, which produces a stroke sample. The canvas is first processed by the location model, a CNN-MLP architecture that processes the image and returns a Gaussian mixture model (GMM) distribution for the starting location of the next stroke y. The location y is then sampled and passed along with I to the stroke model. The stroke model processes I with a CNN and feeds the embedding to an LSTM with attention. The LSTM samples a stroke trajectory x sequentially one offset at a time using GMM outputs. The sampled stroke is passed to a symbolic renderer, and the updated image canvas is then processed by a termination model that decides whether to continue the character sample.
GenerateStroke(I) location model p(y | I) stroke model p(x | y, I) CNN MLP CNN LSTM y I I I I, y attention p(Δ 1 ) p(Δ 2 | Δ 1 ) p(Δ T | Δ 1:T−1 ) … y ∼ p ( y | I ) I, y, x x ∼ p ( x | y , I ) procedure GENERATECHARACTER I 0 . Initialize
ual threshold. Furthermore, we removed small strokes from the data using a threshold on the trajectory length. These processing steps help suppress noise and emphasize signal in the character drawings. Our generative models are trained to produce character drawings, where each drawing is represented as an ordered set of splines (strokes). The number of strokes, and the number of spline coordinates per stroke, are allowed to vary. </p>
<p>Neuro-Symbolic Model</p>
<p>Our primary interest is to test whether a hybrid neurosymbolic model can capture the compositional, causal structure in a large corpus of simple character concepts. The architecture and sampling procedure of our hybrid model, which we call the "Full Neuro-Symbolic" (Full NS) model, is given in Fig. 1. Compared to generic neural networks, the Full NS model lies closer to structure on the structure-statistics spectrum, possessing a much stronger inductive bias. As in BPL (Lake et al., 2015), the generative model is a probabilistic program that captures real compositional and causal structure by sampling characters as a sequence of parts and locations/relations. Unlike BPL, the model has a symbolic engine that renders each part to an image canvas before producing the next one, and parts are generated using a powerful recurrent neural network that encodes and attends to the current canvas. Although correlations between parts can be captured through a process of rendering and then encoding, the model does not allow arbitrary information to flow between parts and variables as in monolithic neural networks. The Full NS model represents a character as a sequence of strokes, with each stroke decomposed into a starting location y t ∈ R 2 , conveying the first spline control point, and a stroke trajectory x t = {∆ 1 , ..., ∆ N }, conveying deltas between spline control points. It generates characters one stroke at a time, using a symbolic renderer as an intermediate processing step after forming each stroke. An image canvas I is used as a memory state to convey information about previous strokes. At each time step t, the next stroke's starting location and trajectory are sampled with procedure GenerateStroke. In this procedure, the current image canvas I is first read by the location model ( Fig. 1; bottom middle), a convolutional neural network (CNN) that processes the image and returns a probability distribution for starting location y t :
y t ∼ p(y t | I).
A visualization of the density p(y t | I) is given in Fig. 3, "Location Prediction." The starting location y t is then passed along with the image canvas I to the stroke model ( Fig. 1;  bottom right), a Long Short-Term Memory (LSTM) architecture with a CNN-based image attention mechanism inspired by Xu et al. (2016). The stroke model samples the next stroke trajectory x t sequentially one offset at a time, selectively attending to different parts of the image canvas at each sample step and combining this information with the context of y t :</p>
<p>x t ∼ p(x t | y t , I). After each stroke, the model receives the current image canvas ("Input Canvas") and makes a series of predictions. Termination Prediction. First, the model predicts a termination probability p (blue bar), i.e. a probability of terminating the drawing. Location Prediction. Next, the model predicts a probability density for the next stroke's starting location. The heatmap indicates the predicted density, and the hollow red dot indicates the ground-truth location. Stroke Prediction. Finally, the model predicts an auto-regressive probability density for the next stroke's trajectory (the "stroke"). Red dots indicate the previous control points, heatmaps indicate the predicted density for the next control point, and hollow red dot indicates the ground-truth next control point.</p>
<p>A visualization of the auto-regressive density p(x t | y t , I) is given in Fig. 3, "Stroke Prediction." Mixture Outputs. Both our location model and stroke model follow a technique from Graves (2013), who proposed to use neural networks with mixture outputs to model handwriting data. The parameters θ = {π 1:K , µ 1:K , σ 1:K , ρ 1:K } output by our network specify a Gaussian mixture model (GMM) with K components ( Fig. 1; colored ellipsoids), where π k ∈ (0, 1) is the mixture weight of the k th component, µ k ∈ R 2 its means, σ k ∈ R 2 + its standard deviations, and ρ k ∈ (−1, 1) its correlation. In our location model, a single GMM describes the distribution p(y t | I). In our stroke model, the LSTM outputs one GMM at each timestep, describing p(∆ t |∆ 1:t−1 , y t , I).</p>
<p>Training. Our Full NS model provides a density function which can be used to score the log-likelihood for any character drawing. We train the model to maximize the loglikelihood (minimize log-loss) of the training set drawings, using mini-batch gradient descent with a batch size of 200 and the Adam update rule.</p>
<p>Alternative Models</p>
<p>In addition to our Full NS model, we explored two alternative models with more generic neural network architectures. In each alternative, we lesioned key structural ingredients of the Full NS model, hoping to test the importance of these ingredients to model performance.</p>
<p>Hierarchical LSTM. As one alternative neural model, we explored a hierarchical recurrent architecture (Sordoni et al., 2015;Ling et al., 2016;Chung et al., 2017), which we denote "Hierarchical LSTM" (H-LSTM). Like our Full NS architecture, the H-LSTM model is trained on causal data demonstrating how people actually produce drawings of characters. In addition, it models the compositional structure of characters by separating them into explicit stroke parts, which defines the hierarchy in the hierarchical LSTM. Unlike our Full NS model, however, the H-LSTM has no renderer and thus lacks any explicit causal knowledge of how motor actions become raw images of inked characters. Instead, information about the previous strokes is written to memory via recurrent connections and gating mechanisms. These transformations can propagate arbitrary correlations, and they must be learned entirely from the data. Specifically, at each time step t, the previous stroke x t−1 is read by a stroke encoder f enc , a bi-directional LSTM that processes the stroke and returns a fixed-length vector (red box in Fig. 4). This vector is then passed as an input to the character LSTM along with previous location y t−1 and previous hidden state h t−1 :
h t = f LSTM (y t−1 , f enc (x t−1 ), h t−1 ).
The new hidden state h t is then fed to the location model p(y t | h t ), a multi-layer perceptron that outputs a GMM distribution for the next stroke's starting location y t (green box in Fig. 4). The location is sampled from this distribution and passed as an input along with h t to the stroke model p(x t | h t , y t ), an LSTM that samples a stroke trajectory one offset at a time with GMM outputs (yellow box in Fig. 4):
y t ∼ p(y t | h t ) x t ∼ p(x t | h t , y t ).
Baseline LSTM. A second alternative is even less structured and represents the most purely statistical architecture we examined. For this model, we explored a naive unrolled LSTM, denoted "Baseline." This model is a reproduction of the unconditional version of Sketch-RNN (Ha &amp; Eck, 2018, Sec 3.3). Similar to Full NS and H-LSTM, the Baseline LSTM is trained on causal data demonstrating the process of producing character; however, it does not explicitly take the compositional structure of characters into account in the architecture itself. Instead, it uses a single RNN to model a character as one long sequence of pen actions with stroke breaks.</p>
<p>Following Sketch-RNN, we expand the binary pen state variable v t ∈ {0, 1} from Graves (2013) to a ternary variable v t ∈ {0, 1, 2} to handle multi-stroke drawings. Value 0 indicates that we are continuing the current stroke, 1 that we are ending the current stroke and starting a new one, and 2 that we are ending the drawing. The initial hidden and cell states of the LSTM are set to zero, and at each time step t, the previous offset ∆ t−1 , previous pen state v t−1 , and previous hidden state h t−1 are fed as inputs to the LSTM, which outputs new hidden state h t :
h t = f LSTM (∆ t−1 , v t−1 , h t−1 ).
An output layer receives h t and returns a categorical distribution for next pen state v t , as well as a GMM distribution for next offset ∆ t :
θ v = f v (h t ), v t ∼ p(v t | θ v ) θ ∆ = f ∆ (h t ), ∆ t ∼ p(∆ t | θ ∆ ).</p>
<p>Experiments</p>
<p>We evaluated the creative generalizations of our 3 neural network models using both quantitative and qualitative analyses. Each of our models estimates a probability density function for characters from training examples. This density function can be used to compute likelihoods for held-out characters and to generate new character samples. A generative model for characters that exhibits creative generalization should produce high likelihood scores for novel character concepts from  Table 1: Test losses from our 3 models. Losses indicate the average negative log-likelihood per test character (lower is better). In our alphabet splits task, we divide the background set into train/test splits such that the model must generalize to new characters from novel alphabets. In our "character splits task, we divide the background set such that the model must generalize to new characters from familiar alphabets. In our "holdout task, we provide the entire background set for training and use the held-out evaluation setwhich contains new characters from novel alphabets-for testing.</p>
<p>held-out classes. In addition, the model should generate new characters that are sufficiently dissimilar from the training examples, but that are structurally consistent with ground truth. In our quantitative analysis, we tested our models for their likelihood performance on novel character classes using a rigorous set of experiments with different train/test splits. In our qualitative analysis, we inspected character samples produced by each model, comparing them to characters from both BPL and ground truth and looking at nearest neighbors from the training set.</p>
<p>Evaluation on Held-Out Concepts</p>
<p>Methods. In our quantitative analysis, we evaluated our models for two different forms of likelihood generalization, corresponding to different train/test splits. In the first generalization task, denoted "character splits," we asked whether our models could generalize to new character classes from familiar alphabets. We created 3 train/test splits from the Omniglot background set, sampling 80% of characters per alphabet for train and 20% for test. In our second task, denoted "alphabet splits," we asked whether our models could generalize to new character classes from novel alphabets. We again sampled 3 train/test splits of size 80-20, this time splitting by alphabet. In both the "character splits" and "alphabet splits" tasks, we explored multiple hyperparameter configurations for our models, varying parameters such as the number of hidden layers, number of units per layer, and dropout probability. 1 Average validation loss across splits was used to select the best configuration for each model in each task. We then took our best configurations in each task and reported their validation losses on all 3 splits. As a final quantitative analysis, we tested our models on one additional task that extends the "alphabet splits" task. Our motivation was to provide a more rigorous analysis using a completely withheld test set as per standard practice in machine learning evaluations. We re-trained our best configurations of each model on the entire background set, using the hyperparameters selected from our "alphabet splits" task. We then reported losses on the evaluation set, which contains character drawings from 10 novel alphabets. Results. Results from our CV-splits experiments are given in Table 1, "Alphabet Splits" and "Character Splits." In our alphabet splits experiment, the Full NS model consistently outperformed its alternatives, exhibiting the best generalization performance in each of the 3 splits with losses of 13.77, 14.18 and 17.53, respectively (per character average). Thus, our neuro-symbolic architecture appears best equipped to capture overarching principles in handwriting concepts that generalize far outside of the training examples. In our character splits task, the Baseline LSTM exhibited best performance in 2 out of 3 splits, and the Full NS model in 1 of 3. The character splits test present a much easier generalization task, where exemplar-based learning could offer a suitable alternative to learning general structural principals. Although our naive Baseline model performs well, its lack of consistency across splits suggests that this model may rely on more of an exemplar-based technique for learning, which we investigate further in our sample analyses. Interestingly, the selected hyperparameter configuration for our Full NS model remained constant across the "alphabet" and "character" split tasks, whereas the configuration changed for both the Baseline and H-LSTM models.</p>
<p>Results for each model on the held-out set of characters are shown in Table 1, "Holdout." Similarly to the "alphabets" task, our Full NS model outperforms both alternative models on the holdout set, providing further support that this architecture learns the best general model of these simple visual concepts.</p>
<p>Generating New Concepts</p>
<p>Methods. In our qualitative analysis, we analyzed the 3 neural network models on their ability to produce novel visual concepts. We took our trained models from the previous experiment and sampled 36 characters from each model, following the model's causal generative procedure. In addition, we sampled 36 characters from the BPL character prior, and we selected 36 "ground truth" characters from Omniglot at random. Samples were then compared visually side-by-side.</p>
<p>As an additional qualitative analysis, we compared character samples from each model for their similarity to the training examples. Although the complexity and structural coherency of generated characters are important criteria, these observations alone provide insufficient evidence for a human- like generative process; a model that memorizes the training examples might produce samples with structural coherence and rich variations, but such a model does not account for the flexible ways that humans generate new concepts. In our second analysis, we took the character samples from our models and found the 5 most-similar training characters for each, using cosine distance in the last hidden layer of a CNN classifier as a metric space for perceptual similarity. The CNN was trained to classify characters from the Omniglot background set, a 964-way classification task.</p>
<p>Results. Fig. 5 shows samples from each of our three models, as well as from the BPL forward model 2 and from the Omniglot data (ground truth). Compared to BPL, the neuralenhanced models capture more correlational structure and character complexity. For instance, the Full NS model propagates stylistic and structural consistency across three strokes to form a Braille-like character, as shown by the sample in column 1, row 2. Fig. 6 Figure 7: Topologically-Organized character samples and their nearest Omniglot neighbors. We drew 100 character samples from our Full NS model and organized them into a 10x10 grid such that neighboring characters have similar drawing styles (left). We then found the "nearest neighbor" of each sample from the Omniglot character dataset and organized the neighbors into a corresponding 10x10 grid (right).</p>
<p>acters that closely mimic the nearest training examples in the majority (7/9 by our eyes) of cases. In contrast, our Full NS model produces only a few (3/9) characters that directly mirror the nearest training examples, suggesting that it can generalize further from the training observations.</p>
<p>To get an idea of the different character styles produced by our Full NS model, we sampled 100 characters from the model and organized them into a 10x10 grid such that neighboring characters have high perceptual similarity (Fig. 7, left). Characters were sampled at a lower level of stochasticity, using the temperature parameter proposed by Ha &amp; Eck (2018) to modify the entropy of the mixture density outputs (we used T = 0.5). The model produces characters in multiple distinct styles, with some having more angular, linebased structure and others relying on complex curves. In Fig.  7, (right) we plotted the most-similar Omniglot character for each sample in a corresponding grid. In many cases, samples from the model have a distinct style and are visually dissimilar from their nearest Omniglot neighbor.</p>
<p>Conclusion</p>
<p>We presented a new neuro-symbolic generative model of simple visual concepts. Our model successfully captures compositional and causal structure in handwritten character concepts, forming a representation that generalizes to new concepts. We tested our model by comparing its likelihood scores on a holdout set of novel characters, finding that it consistently outperforms two generic neural network alternatives when the test characters deviate significantly from the training examples. Furthermore, our generative model produces new character concepts with richer variations than simple parametric models, yet that remain structurally coherent and visually consistent with human productions.</p>
<p>Neuro-symbolic models offer a promising set of tools to express the rich background knowledge that enables creative imagination. These models can explain the nonparametric correlation structure embodied in conceptual knowledge while maintaining important inductive biases to account for the structured ways that people generate new concepts. We believe that models of this kind will be useful to explain a variety of human imaginative behaviors, such as when a chef creates the new recipe "pea guacamole." In future work, we'd like to explore applications of neuro-symbolic models to other types of concepts with varying complexity.</p>
<p>Figure 1 :
1Full neuro-symbolic (Full NS) model. Our Full NS model produces character samples one stroke at a time. The procedure</p>
<p>Figure 2 :
2Spline representation. Raw strokes (left) are converted into minimal splines (right) using least-squares optimization. Crosses (left) indicate pen locations and red dots (right) indicate spline control points.</p>
<p>Figure 3 :
3Predictions of the Full NS model for a test character.</p>
<p>Figure 4 :
4Hierarchical LSTM model. The model samples characters one stroke at a time, using a character-level LSTM as a memory state. At each time, the model samples a starting location for the next stroke from a location predictor (MLP), and a stroke trajectory from the stroke predictor (LSTM). These samples are then fed to the model as inputs for the next time, with the location fed directly and the trajectory processed by a stroke encoder (bi-directional LSTM).</p>
<p>Figure 5 :
5Character sample comparison. Characters generated by our Full NS, H-LSTM and Baseline LSTM models are shown side-byside, along with samples from the BPL forward model 2 as well as ground truth characters from Omniglot.</p>
<p>Figure 6 :
6Novelty of character samples. Character drawings sampled from each model were compared to their 5 nearest neighbors from the training set. Each row corresponds to one character sample from the model. The red box indicates the model sample, and the 5 nearest neighbors are shown in the succeeding columns.</p>
<p>shows a handful of character samples produced by each neural model plotted alongside their five nearest neighbors from the Omniglot training set. Both the H-LSTM and the Baseline LSTM models produce char-samples from Full NS 
model (T=0.5) </p>
<p>corresponding 
Omniglot neighbors </p>
<p>stroke key: </p>
<p>For details about hyperparameters, see Appendix A.
BPL character samples have been centered for better visual appearance; the actual samples often protrude outside of the image window. A more complex non-parametric BPL model was used in the visual Turing tests inLake et al. (2015) that has explicit re-use of character parts. Those samples were also centered.
AcknowledgementsWe thank Maxwell Nye, Josh Tenenbaum, Tuan-Anh Le, and Jay McClelland for helpful discussions regarding this work.Appendix A. Model HyperparametersHere we review the hyperparameters (HPs) used for each of our models, indicating which HPs were fixed and which were tuned. All neural networks with GMM output layers use 20 mixture components.Full NS. The Full NS model has 3 submodules: a location model, a stroke model, and a termination model. Each submodule uses a distinct CNN, and each receives an image canvas of size (28,28). The location and termination modelswhich return outputs for a single time step-each use a feedforward CNN architecture inspired byVinyals et al. (2016). The CNNs consist of a stack of 4 blocks, with each block i including a 3x3 convolution with K i filters, batch normalization, nonlinear activation f , 2x2 max-pooling, and dropout with rate p. These blocks are followed by a single fully-connected layer with D units, activation f and dropout p. Hyperparameters {K i }, f , p and D were selected from tuning. The stroke model uses a modified CNN architecture without spatial pooling, designed to convey high-resolution spatial information for visual attention. The CNN returns a feature map of size(64,14,14), which is then passed to an LSTM. The LSTM predicts the spline trajectory of the next stroke one offset at a time, attending to different parts of the feature map at each step. The HPs of the CNN were fixed, but the HPs of the LSTM were tuned, including the number of LSTM layers and number of units per layer.Hierarchical LSTM. The Hierarchical LSTM model has a character-level LSTM backbone and 3 submodules: a stroke encoder (BiLSTM), a location model (MLP), and a stroke model (LSTM). The number of LSTM layers, number of units per layer and dropout rate in the character-level LSTM were selected from tuning, but HPs of all submodules were fixed. The stroke encoder is a bidirectional LSTM with a single layer of 256 units. It outputs a fixed-length vector representation of the previous stroke, which is fed to the character LSTM as input. The location model is a 2-layer MLP that receives the current hidden state of the character LSTM and outputs a GMM for the next stroke's starting location. The stroke model is an LSTM with a single layer of 256 units and outputs a GMM at each time step for the next spline offset.Baseline LSTM. The Baseline LSTM is a single module. It has L LSTM layers, each with K units and dropout rate p. The values of L, K and p were selected from tuning.B. Samples with stroke decompositionInFig. 8, we show a larger collection of characters from our Full NS model, using color coding to convey the stroke composition of each sample. We produced character samples at two different levels of stochasticity, using a temperature parameter to modify the entropy of the mixture density outputs(Ha &amp; Eck, 2018, Eq.8). Samples are shown for temperature settings T = 1.0 and T = 0.5.
Unsupervised learning. H B Barlow, Neural Computation. 13Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1(3), 295-311.</p>
<p>Hierarchical multiscale recurrent neural networks. J Chung, S Ahn, Y Bengio, In ICLRChung, J., Ahn, S., &amp; Bengio, Y. (2017). Hierarchical multiscale recurrent neural networks. In ICLR.</p>
<p>Indexing by latent semantic analysis. S Deerwester, S T Dumais, G W Furnas, T K Landauer, R Harshman, JASIS. 41Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. JASIS, 41, 391-407.</p>
<p>Learning to infer graphics programs from hand-drawn images. K Ellis, D Ritchie, A Solar-Lezama, J B Tenenbaum, NIPS. Ellis, K., Ritchie, D., Solar-lezama, A., &amp; Tenenbaum, J. B. (2018). Learning to infer graphics programs from hand-drawn images. In NIPS.</p>
<p>Attend, infer, repeat: Fast scene understanding with generative models. S M A Eslami, N Heess, T Weber, Y Tassa, D Szepesvari, K Kavukcuoglu, G E Hinton, NIPS. Eslami, S. M. A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Kavukcuoglu, K., &amp; Hinton, G. E. (2016). Attend, infer, repeat: Fast scene understanding with generative models. In NIPS.</p>
<p>Synthesizing programs for images using reinforced adversarial learning. Y Ganin, T Kulkarni, I Babuschkin, S M A Eslami, O Vinyals, ICML. Ganin, Y., Kulkarni, T., Babuschkin, I., Eslami, S. M. A., &amp; Vinyals, O. (2018). Syn- thesizing programs for images using reinforced adversarial learning. In ICML.</p>
<p>A rational analysis of rule-based concept learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, Cognitive Science. 32Goodman, N. D., Tenenbaum, J. B., Feldman, J., &amp; Griffiths, T. L. (2008). A rational analysis of rule-based concept learning. Cognitive Science, 32, 108-154.</p>
<p>Concepts in a probabilistic language of thought. N D Goodman, J B Tenenbaum, T Gerstenberg, The conceptual mind: New directions in the study of concepts. E. Margolis and S. LaurenceCambridge, MAMIT PressGoodman, N. D., Tenenbaum, J. B., &amp; Gerstenberg, T. (2015). Concepts in a proba- bilistic language of thought. In E. Margolis and S. Laurence (Ed.), The conceptual mind: New directions in the study of concepts (pp. 623-653). Cambridge, MA: MIT Press.</p>
<p>Generating sequences with recurrent neural networks. A Graves, arXiv:1308.0850arXiv preprintGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</p>
<p>DRAW: A recurrent neural network for image generation. K Gregor, I Danihelka, A Graves, D J Rezende, D Wierstra, ICML. Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., &amp; Wierstra, D. (2015). DRAW: A recurrent neural network for image generation. In ICML.</p>
<p>A neural representation of sketch drawings. D Ha, D Eck, ICLR. Ha, D., &amp; Eck, D. (2018). A neural representation of sketch drawings. In ICLR.</p>
<p>The discovery of structural form. C Kemp, J B Tenenbaum, PNASKemp, C., &amp; Tenenbaum, J. B. (2008). The discovery of structural form. PNAS, 105(31), 10687-92.</p>
<p>Structured statistical models of inductive reasoning. C Kemp, J B Tenenbaum, Psychological Review. 116Kemp, C., &amp; Tenenbaum, J. B. (2009). Structured statistical models of inductive rea- soning. Psychological Review, 116, 20-58.</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. B M Lake, M Baroni, ICML. Lake, B. M., &amp; Baroni, M. (2018). Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In ICML.</p>
<p>B M Lake, S T Piantadosi, People Infer Recursive Visual Concepts from Just a Few Examples. Lake, B. M., &amp; Piantadosi, S. T. (2019). People Infer Recursive Visual Concepts from Just a Few Examples. Computational Brain &amp; Behavior.</p>
<p>Human-level concept learning through probabilistic program induction. B M Lake, R Salakhutdinov, J B Tenenbaum, Science. 350Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350, 1332-1338.</p>
<p>The Omniglot challenge: A 3-year progress report. B M Lake, R Salakhutdinov, J B Tenenbaum, Behavioral Sciences. 29Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2019). The Omniglot challenge: A 3-year progress report. Behavioral Sciences, 29, 97-104.</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 40253Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). Building machines that learn and think like people. Behavioral and Brain Sciences, 40, E253.</p>
<p>Character-based neural machine translation. W Ling, I Trancoso, C Dyer, A Black, ICLR. Ling, W., Trancoso, I., Dyer, C., &amp; Black, A. (2016). Character-based neural machine translation. In ICLR.</p>
<p>The Algebraic Mind: Integrating Connectionism and Cognitive Science. G F Marcus, MIT PressCambridge, MAMarcus, G. F. (2003). The Algebraic Mind: Integrating Connectionism and Cognitive Science. Cambridge, MA: MIT Press.</p>
<p>Emergence in Cognitive Science. J L Mcclelland, Topics in Cognitive Science. 24McClelland, J. L. (2010). Emergence in Cognitive Science. Topics in Cognitive Science, 2(4), 751-770.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological Review. 923Murphy, G. L., &amp; Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological Review, 92(3), 289-316.</p>
<p>The learnability of abstract syntactic principles. A Perfors, J B Tenenbaum, T Regier, Cognition. 1183Perfors, A., Tenenbaum, J. B., &amp; Regier, T. (2011). The learnability of abstract syntactic principles. Cognition, 118(3), 306-338.</p>
<p>The logical primitives of thought: Empirical foundations for compositional cognitive models. S T Piantadosi, J B Tenenbaum, N D Goodman, Psych. Rev. Piantadosi, S. T., Tenenbaum, J. B., &amp; Goodman, N. D. (2016). The logical primitives of thought: Empirical foundations for compositional cognitive models. Psych. Rev..</p>
<p>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. A Sordoni, Y Bengio, H Vahabi, C Lioma, J G Simonsen, J Y Nie, CIKM. Sordoni, A., Bengio, Y., Vahabi, H., Lioma, C., Simonsen, J. G., &amp; Nie, J. Y. (2015). A hierarchical recurrent encoder-decoder for generative context-aware query sugges- tion. In CIKM.</p>
<p>Learning Structured Generative Concepts. A Stuhlmuller, J B Tenenbaum, N D Goodman, In CogSciStuhlmuller, A., Tenenbaum, J. B., &amp; Goodman, N. D. (2010). Learning Structured Generative Concepts. In CogSci.</p>
<p>How to grow a mind: Statistics, structure, and abstraction. J B Tenenbaum, C Kemp, T L Griffiths, N D Goodman, Science. 3316022Tenenbaum, J. B., Kemp, C., Griffiths, T. L., &amp; Goodman, N. D. (2011). How to grow a mind: Statistics, structure, and abstraction. Science, 331(6022), 1279-1285.</p>
<p>Matching networks for one shot learning. O Vinyals, C Blundell, T Lillicrap, D Wierstra, NIPS. Vinyals, O., Blundell, C., Lillicrap, T., &amp; Wierstra, D. (2016). Matching networks for one shot learning. In NIPS.</p>
<p>Show, attend and tell: Neural image caption generation with visual attention. K Xu, J L Ba, R Kiros, K Cho, A Courville, R Salakhutdinov, . . Bengio, Y , ICML. Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., . . . Bengio, Y. (2016). Show, attend and tell: Neural image caption generation with visual attention. In ICML.</p>            </div>
        </div>

    </div>
</body>
</html>