<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2620 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2620</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2620</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-0d03c970454f55fc3627c340e92a1de55220a304</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/0d03c970454f55fc3627c340e92a1de55220a304" target="_blank">Max-value Entropy Search for Efficient Bayesian Optimization</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Machine Learning</p>
                <p><strong>Paper TL;DR:</strong> It is observed that MES maintains or improves the good empirical performance of ES/PES, while tremendously lightening the computational burden, and is much more robust to the number of samples used for computing the entropy, and hence more efficient for higher dimensional problems.</p>
                <p><strong>Paper Abstract:</strong> Entropy Search (ES) and Predictive Entropy Search (PES) are popular and empirically successful Bayesian Optimization techniques. Both rely on a compelling information-theoretic motivation, and maximize the information gained about the $\arg\max$ of the unknown function; yet, both are plagued by the expensive computation for estimating entropies. We propose a new criterion, Max-value Entropy Search (MES), that instead uses the information about the maximum function value. We show relations of MES to other Bayesian optimization methods, and establish a regret bound. We observe that MES maintains or improves the good empirical performance of ES/PES, while tremendously lightening the computational burden. In particular, MES is much more robust to the number of samples used for computing the entropy, and hence more efficient for higher dimensional problems.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2620.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2620.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Max-value Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-theoretic Bayesian optimization acquisition function that selects queries by maximizing mutual information between a candidate evaluation and the unknown maximum function value y_*; computationally efficient because it reasons about the 1D distribution of the maximum value instead of the d-dimensional argmax.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Max-value Entropy Search (MES)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MES is an acquisition strategy for Bayesian optimization. It defines the acquisition as the mutual information I({x,y}; y_* | D_t) between the next evaluation (x,y) and the maximum function value y_*. The predictive term p(y|D_t,x) is Gaussian; conditioning on y_* makes the predictive a truncated Gaussian. MES approximates the expectation over the (1-D) distribution p(y_*|D_t) via (a) a Gumbel approximation of the maximum CDF computed on a discretized input set, or (b) Monte Carlo: sample posterior functions via random Fourier features (random features / 1-hidden-layer neural-net surrogate), maximize each sampled function to obtain y_* samples. MES also supports marginalization over GP hyperparameters and an additive-GP extension for high-dimensional inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Black-box optimization / experimental design / active learning across robotics, machine learning hyperparameter tuning, control (robot pushing, bipedal walker), and synthetic function optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates the next function evaluation by maximizing estimated mutual information about y_*, selecting x that maximally reduces uncertainty about the maximum value. It controls resource allocation (computational budget for acquisition evaluation) via the number of y_* samples K and choice of sampling method (Gumbel = cheap; posterior-function maximization = more expensive). For high-dimensions it decomposes the problem via additive-GP and performs component-wise acquisition and concatenation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Measured in wall-clock time to select the next input (seconds) and analyzed asymptotically: sampling via the discretized CDF costs O(M |X~| log(1/δ)) for M samples, while the Gumbel approximation reduces cost to O(M + |X~| log(1/δ)). Reported runtimes in the paper (example): MES-G (K=100) = 0.12 ± 0.02 s; MES-R (K=100) = 5.85 ± 0.86 s. Complexity statements (big-O) are provided for CDF queries and sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Mutual information I({x,y}; y_* | D_t) — computed as H[p(y|D_t,x)] - E_{p(y_*|D_t)}[ H[p(y|D_t,x,y_*)] ], approximated by sample averaging with closed-form truncated-Gaussian entropies and the gamma-function expression (uses Gaussian PDF ψ and CDF Ψ).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Implicitly controlled by the information objective: points that most reduce uncertainty about the maximum value are preferred. The sampled y_* values control the exploration-exploitation bias: (i) large sampled y_* encourage exploration (since many points remain plausible maxima), (ii) small y_* samples bias toward exploitation. The single-sample MES is mathematically equivalent to EST/PI/GP-UCB variants (Lemma 3.1), tying MES to established exploration-exploitation tradeoff parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit, separate diversity-promoting constraint. Diversity arises implicitly from maximizing mutual information and from using multiple y_* samples which can yield different acquisition preferences across samples; additive decomposition yields per-component searches that diversify across subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed query budget (number of function evaluations T) and computational budget for acquisition computation (time per candidate selection).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Reduces acquisition computation through (a) reducing the target distribution dimension from d to 1 (y_*), (b) using a Gumbel approximation for y_* CDF to avoid expensive maximizations, (c) controlling the number of y_* samples K, and (d) additive-GP decomposition for high-dimensional inputs to reduce optimization complexity per component.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; the paper uses simple regret and inference regret as proxies for discovery of high-performing inputs (i.e., lower regret indicates finding better/novel optima).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Primary metrics: simple regret r_T (max_x f(x) - max_{t<=T} f(x_t)) and inference regret R_T (max_x f(x) - f(tilde{x}_T)). Example numeric results reported: selection runtime per iteration — MES-G (K=100): 0.12 ± 0.02 s, MES-G (K=10): 0.09 ± 0.02 s, MES-G (K=1): 0.09 ± 0.03 s; MES-R (K=100): 5.85 ± 0.86 s, MES-R (K=10): 0.67 ± 0.11 s, MES-R (K=1): 0.13 ± 0.03 s. Inference-regret (Table 2): MES-G on Eggholder: 46.56 ± 27.05; Shekel: 5.45 ± 2.07; Michalewicz: 4.49 ± 0.51. Robot pushing (Table 4) inference-regret examples: 3-d action MES-R: 0.61 ± 1.23; MES-G: 0.61 ± 1.26.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally to ES, PES (entropy-search family), GP-UCB (UCB), PI, EI, EST, add-GP-UCB (in high-d tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MES methods matched or outperformed ES/PES in many scenarios, while being much cheaper computationally. Examples: MES methods achieved lower simple regret than ES/PES on many higher-dimensional test functions; MES-G selection runtime (K=100) = 0.12 s vs PES (K=100) = 15.24 s (≈127× faster). MES methods were less sensitive to the number of samples K than PES was to number of x_* samples, obtaining good performance even with K=1 or 10.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Substantial reduction in acquisition computation: e.g., MES-G (K=100) ~0.12s vs PES (K=100) ~15.24s (≈127× speedup for next-input selection in that experimental setting). MES-G runtime comparable to fast heuristics like EI (~0.07 s) while producing superior or similar regret performance. MES-R (K large) is more expensive but still often faster than PES due to cheaper y_* sampling via random features.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper analyzes tradeoffs between computational cost (K and sampling strategy), information gain, and optimization performance: (1) Replacing argmax (d-dimensional) by y_* (1-D) dramatically lowers sampling cost while keeping information-theoretic motivation. (2) Gumbel approximation is cheap but tends to overestimate maxima (more exploration); random-feature posterior sampling (MES-R) is costlier but may underestimate maxima (more exploitation) due to imperfect global optimization of sampled functions; (3) MES is empirically robust to small K (unlike PES); (4) The regret bound (Theorem 3.2) depends on distribution of sampled y_* (too-large y_* can worsen the regret bound). These points quantify the cost-quality tradeoffs in allocation decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key conclusions: (a) Reasoning about y_* (1-D) is an effective and computationally efficient surrogate for information about argmax locations — allows allocating more resources to evaluations rather than to acquisition computation; (b) use Gumbel approximation for fast, scalable acquisition when evaluations are expensive and sample-efficient acquisitions are needed; (c) using a small number of y_* samples (even K=1) often suffices in practice, enabling lower computational cost without sacrificing information gain; (d) in high dimensions, additive-GP decomposition plus per-component MES (add-MES) gives effective resource allocation across subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2620.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>add-MES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Additive Max-value Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Extension of MES to high-dimensional problems that assumes the target function decomposes into a sum of independent lower-dimensional component functions and runs MES per component to guide component-wise query selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Additive Max-value Entropy Search (add-MES)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Assumes f(x)=sum_m f^{(m)}(x^{A_m}) with disjoint active dimension sets A_m. For each component m, add-MES computes acquisition α_t^{(m)}(x^{A_m}) = I({x^{A_m}, y^{(m)}} ; y_*^{(m)} | D_t), samples y_*^{(m)} (Gumbel or posterior-function sampling) and selects per-component maximizers; the final x_t is the concatenation of per-component argmaxes. Random-feature posterior sampling respects additive structure by using features active only on corresponding sub-vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>High-dimensional Bayesian optimization where additive structure is plausible — synthetic additive functions, high-dimensional robotics control (14D pushing, 25D bipedal walker), hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates evaluation budget across components by independently selecting the most informative input sub-vector for each component via component-wise mutual-information acquisitions, then concatenating them to form a full-dimensional query; sampling strategy per-component controls computation (K samples per component).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time per iteration and per-component optimization cost; per-component acquisition reduces search complexity compared to full-d acquisition. Empirical runtimes depend on K and additive partitioning; asymptotic cost reduced by lower-dim optimization per component.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Component-wise mutual information I({x^{A_m}, y^{(m)}}; y_*^{(m)} | D_t), approximated by per-component y_*^{(m)} samples and truncated-Gaussian entropies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Same principle as MES applied per-component: select sub-vectors that maximize reduction in uncertainty about their component maxima; tradeoffs controlled by sampling method (Gumbel vs posterior) and per-component y_* samples, resulting in componentwise exploration/exploitation balance.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism beyond decomposing search into multiple independent components which encourages exploring different subspaces; multiple per-component y_* samples provide variability in component-level allocations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of total evaluations; per-iteration per-component computation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Reduces search and acquisition optimization cost by decomposing the domain into lower-dimensional components and using cheap y_* sampling (Gumbel) per component when needed; selects K small (often 1) per component to save computation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; uses simple and inference regret aggregated across full-dimensional queries as primary performance indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Simple regret reported in synthetic add-GP experiments: add-MES methods outperform add-GP-UCB on many synthetic additive functions. Observed qualitative behaviors: add-MES-G performed best for lower dimensions (d=10,20,30) while add-MES-R performed better for higher dimensions (d=50,100). On real tasks: add-MES competitive with add-GP-UCB on 14D pushing and 25D bipedal walker optimization (plots shown but numeric regret values not tabulated in-text).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>add-GP-UCB (Kandasamy et al., 2015) and other BO baselines used in high-d experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>add-MES generally achieved lower simple regret than add-GP-UCB on the tested synthetic additive functions and was competitive on real high-d control tasks; relative advantage depended on dimensionality and sampling strategy (Gumbel vs posterior).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>By restricting acquisition and optimization to lower-dimensional components, add-MES reduces per-iteration search cost and enables practical BO in higher dimensions where full-d acquisition would be intractable. Exact speedups depend on M and |A_m|; empirical gains shown qualitatively in figures.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper observes that add-MES-G (Gumbel) tends to overestimate maxima (promotes exploration) and works better in lower-d settings, while add-MES-R (random-feature posterior samples) tends to underestimate maxima (promotes exploitation) and works better in higher-d settings; this identifies a computational-quality tradeoff in sampler choice and dimensional regime.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation: exploit additive structure when present; use Gumbel sampling to favor exploration cheaply in lower-d components, and consider posterior-sampling (MES-R) for higher-d components where exploitation is preferable or global optima easier to find via sampled functions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2620.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bayesian optimization acquisition that selects queries to maximize information about the location x_* of the global optimum by reducing the entropy of the posterior over argmax locations; computationally expensive because it requires approximating a d-dimensional distribution over x_*.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Entropy search for information-efficient global optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Entropy Search (ES)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ES measures acquisition α_t(x)=I({x,y}; x_* | D_t) — mutual information between a candidate evaluation and the optimizer location x_*. It requires approximating the posterior p(x_*|D_t) (a distribution over input locations) and its entropy; PES uses a symmetric formulation. ES approximations rely on many samples from the input space and are computationally expensive and sensitive to the number of samples.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Black-box optimization / experimental design where queries are costly and information about optimizer location is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates evaluations by maximizing expected information gain about x_*; high computational cost associated with estimating p(x_*|D_t) often outweighs gains when function evaluations are cheap.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Measured in wall-clock selection time; reported runtime example: ES selection time ≈ 8.07 ± 3.02 s per iteration in the paper's synthetic experiment (higher for large numbers of x_* samples).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Mutual information about x_* (entropy reduction H[p(x_*|D_t)] - E[H[p(x_*|D_t ∪ {x,y})]] ).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Selects points that most reduce uncertainty about the optimizer location, inherently encouraging exploration that is informative about x_*; the computationally expensive approximation controls the degree of exploration via sample budget.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No separate explicit diversity mechanism beyond information-theoretic objective which tends to pick informative, potentially diverse points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed evaluation budget; high acquisition computation budget required for effective p(x_*) estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Not efficient under tight computational budgets; often impractical when acquisition cost must be low.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not defined; uses regret metrics in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Compared in experiments for regret; ES often competitive in low-d with sufficient computation but slower than MES; selection runtime reported (see above).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to PES, MES, GP-UCB, PI, EI, EST in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ES achieves strong query-efficiency but at much higher computational cost than MES; MES matched or improved performance while reducing computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not applicable to ES itself; MES provides efficiency gains relative to ES.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>ES/PES trade computational cost for potential improved query-efficiency; the paper demonstrates MES trades much less computation for similar or better empirical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When function evaluations are extremely expensive and computational cost of acquisition is acceptable, ES/PES may be justified; otherwise MES is preferable due to computational savings with preserved information-theoretic motivation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2620.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An entropy-search variant that maximizes expected information about the optimizer location x_* using an equivalent symmetric formulation that conditions on x_*; also computationally expensive and sensitive to the number of x_* samples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predictive entropy search for efficient global optimization of black-box functions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Predictive Entropy Search (PES)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PES computes α_t(x)=I({x,y}; x_* | D_t) using a symmetric expression that involves expectations over p(x_*|D_t); approximations require sampling candidate argmax locations x_* by maximizing posterior function samples which is computationally costly. PES is empirically effective but sensitive to the number of x_* samples and scales poorly with input dimension.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Same as ES: expensive black-box optimization and experimental design.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects queries that maximize expected information about optimizer location x_*. The sampling budget for x_* (number of posterior-sampled argmaxes) controls computational cost and information quality.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock selection time; reported examples: PES (K_x*=100) ≈ 15.24 ± 4.44 s, PES (K=10) ≈ 1.61 ± 0.50 s, PES (K=1) ≈ 0.20 ± 0.06 s in the synthetic experiment — performance strongly depends on K.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Mutual information about x_* (entropy reduction) computed via symmetric PES formula.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Similar to ES — focuses on reducing uncertainty about optimizer location; number of x_* samples controls exploration thoroughness.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism beyond information objective; diversity influenced by variety of sampled x_* candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for acquisition (sensitive to number of x_* samples), fixed evaluation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Requires more computation to improve accuracy of p(x_*); paper shows PES becomes much slower as sample count increases, making it unsuitable when acquisition-time must be low.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; uses regret measures to evaluate performance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>PES can achieve strong regret when many x_* samples are used; however, performance degrades with fewer samples. Example: PES (K=100) gave better results than PES (K=10) or PES (K=1) in 3D synthetic experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to MES variants, ES, GP-UCB, PI, EI, EST in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PES can outperform alternatives given high computational budget (large K), but MES matches or exceeds PES performance with far less computation in many cases; PES is more sensitive to sample count.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not an efficiency-improving method per se; MES offers much lower acquisition cost for similar or better performance.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper documents PES tradeoff: more x_* samples improve information quality but increase computation drastically; MES avoids this by sampling 1-D y_*.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>If acquisition-time is plentiful relative to function evaluation cost, PES with many samples can be effective; otherwise approximate 1-D approaches like MES are preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2620.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP-UCB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Upper Confidence Bound</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used BO acquisition heuristic that picks x maximizing μ_t(x) + √β_t σ_t(x), balancing exploitation and exploration via a confidence parameter β_t; theoretical no-regret guarantees exist under suitable β_t scheduling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gaussian process optimization in the bandit setting: no regret and experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GP-UCB</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GP-UCB selects points by maximizing an upper confidence bound constructed from the GP posterior mean and standard deviation: x_t = argmax_x ( μ_t(x) + √β_t σ_t(x) ). The parameter β_t controls exploration; theoretical β_t schedules yield regret bounds. In the paper GP-UCB is used as a baseline and is shown to be connected to MES/EST under particular parameter settings.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General-purpose BO and experimental design for expensive black-box functions.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates queries by an optimism-in-face-of-uncertainty rule: choose the point with the highest upper confidence bound. Computationally cheap per-step (closed-form acquisition), suitable when acquisition must be fast.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Low wall-clock selection time (example: UCB reported ≈ 0.08 ± 0.05 s per selection in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not explicitly maximize mutual information; indirectly reduces uncertainty via the confidence bound heuristic. Information-theoretic connections to MES/EST exist via parameter mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit via β_t: larger β_t increases exploration (weight on σ_t), smaller β_t favors exploitation (weight on μ_t).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism; diversity arises from sampling points with high posterior uncertainty σ_t.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed evaluation budget; low per-iteration computational budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Efficient closed-form acquisition allows many iterations to be scheduled under tight computational budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; evaluated with regret metrics in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported selection runtime ~0.08 ± 0.05 s; regret performance competitive in some tasks but often outperformed by MES or PES in terms of query-efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as a baseline alongside PI, EI, ES, PES, EST, MES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>GP-UCB is computationally cheap but can be less sample-efficient than information-theoretic methods; MES/EST can be mapped to GP-UCB parameterizations (Lemma 3.1) showing theoretical connection.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Fast selection time; less sample-efficient in some problems compared to MES/PES depending on β_t and problem structure.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Exploration-exploitation tradeoff controlled by β_t; paper leverages equivalence to EST under specific β_t choices to relate behavior to MES.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>GP-UCB is recommended when acquisition-time must be minimal; for expensive evaluations but moderate acquisition compute, MES offers better sample efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2620.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EST</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Optimization as Estimation (EST)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BO approach that chooses points by estimating the function maximum m and selecting x that minimizes the standardized distance γ_m(x) = (m - μ_t(x)) / σ_t(x); paper shows EST is equivalent to single-sample MES and related to GP-UCB and PI under parameter mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization as estimation with Gaussian processes in bandit settings</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EST (Optimization as Estimation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EST uses an estimate m of the function maximum and selects the next point by minimizing γ_m(x) = (m - μ_t(x)) / σ_t(x), i.e., picks the point most likely to reach m in standardized units. The paper proves single-sample MES (using a single y_* sample) is equivalent to EST with m = y_* and thereby connects EST to GP-UCB and PI via parameter correspondences.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Bayesian optimization and bandit problems where an explicit estimate of the maximum is available or can be sampled.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates queries by minimizing standardized distance to an estimated maximum; the quality of the estimate m (sampling distribution) affects exploration-exploitation bias.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Comparable to GP-UCB/PI (closed-form expressions per candidate), low per-step computational cost; used as baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not directly optimize mutual information; implicitly related because estimating the maximum guides information-seeking queries. Single-sample MES equivalence shows implicit information-theoretic connection.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration-exploitation arises through the estimated m: larger m encourages exploration, smaller m favors exploitation. Equivalent to setting GP-UCB β and PI thresholds via m.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism beyond the standardized-score selection which can promote exploring uncertain candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of evaluations; low acquisition-computation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Computationally cheap acquisition; estimate m can be drawn from a distribution (sampling) to control robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; performance assessed via regret.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>EST shown to have inference-regret comparable to MES in several experiments; runtime comparable to GP-UCB/PI (fast).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared in experiments to MES, ES, PES, GP-UCB, PI, EI.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>EST often performs similarly to MES in inference regret when single-sample strategies are used; MES with multiple samples can outperform EST by averaging over y_* samples.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Low computational cost similar to UCB/PI; offers a principled mapping to information-theoretic MES with single-sample equivalence.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Shows how an estimate of the maximum (m) encodes a tradeoff between exploration and exploitation; sampling m from a distribution (as MES does) randomizes that tradeoff.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Using estimates of the maximum can yield simple and efficient allocation rules with provable connections to UCB/PI; MES generalizes EST by averaging over multiple y_* samples for more robust allocations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2620.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2620.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>add-GP-UCB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Additive Gaussian Process UCB</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of GP-UCB that exploits additive decomposition of high-dimensional functions to scale BO to higher dimensions by optimizing component-wise UCB acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>High dimensional Bayesian optimisation and bandits via additive models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>add-GP-UCB</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Assumes f(x)=∑_m f^{(m)}(x^{A_m}). add-GP-UCB applies GP-UCB per component with component-specific β_t^{(m)} and selects component-wise maximizers which are combined into a full-dimensional query. It reduces optimization complexity in high dimensions by limiting searches to lower-dimensional subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>High-dimensional Bayesian optimization where additive structure is plausible (synthetic functions, robotics control, parameter tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates queries by maximizing component-wise upper confidence bounds and concatenating the component argmaxes. The β_t^{(m)} schedule controls exploration per component.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-iteration cost is reduced relative to full-d GP-UCB because per-component optimization is lower-dimensional; empirical comparison in paper shows add-MES often outperforms add-GP-UCB in simple regret.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not explicitly measure mutual information; uses UCB heuristic per component.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration-exploitation controlled per-component via β_t^{(m)}; recommended schedules from Kandasamy et al. are used in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity constraint; decomposed search encourages exploration across component subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of evaluations; need to handle high-dimensional search complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Mitigates budget issues by reducing per-query optimization to lower-dimensional subproblems; uses β schedules to ensure theoretical coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined; evaluated by simple and inference regret in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>add-GP-UCB used as baseline in high-d experiments. add-MES methods generally achieved lower simple regret on synthetic additive functions and were competitive on real-world high-d tasks (14D push, 25D walker).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as the main baseline for add-MES in high-dimensional experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>add-MES often outperformed add-GP-UCB in simple-regret on synthetic add-GP tasks; on some real tasks add-MES was competitive.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Efficient relative to full-d methods by restricting optimizations to component dimensions; empirical gains depend on decomposition quality.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes differences in component-level sampler behaviors (Gumbel vs posterior) and dimensionality effects on which sampler works better for add-MES vs add-GP-UCB.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When additive structure holds, per-component acquisition (either UCB or MES) is effective; MES per-component acquisitions yielded better empirical simple regret in tested scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Max-value Entropy Search for Efficient Bayesian Optimization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Entropy search for information-efficient global optimization <em>(Rating: 2)</em></li>
                <li>Predictive entropy search for efficient global optimization of black-box functions <em>(Rating: 2)</em></li>
                <li>Optimization as estimation with Gaussian processes in bandit settings <em>(Rating: 2)</em></li>
                <li>High dimensional Bayesian optimisation and bandits via additive models <em>(Rating: 2)</em></li>
                <li>Gaussian process optimization in the bandit setting: no regret and experimental design <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2620",
    "paper_id": "paper-0d03c970454f55fc3627c340e92a1de55220a304",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "MES",
            "name_full": "Max-value Entropy Search",
            "brief_description": "An information-theoretic Bayesian optimization acquisition function that selects queries by maximizing mutual information between a candidate evaluation and the unknown maximum function value y_*; computationally efficient because it reasons about the 1D distribution of the maximum value instead of the d-dimensional argmax.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Max-value Entropy Search (MES)",
            "system_description": "MES is an acquisition strategy for Bayesian optimization. It defines the acquisition as the mutual information I({x,y}; y_* | D_t) between the next evaluation (x,y) and the maximum function value y_*. The predictive term p(y|D_t,x) is Gaussian; conditioning on y_* makes the predictive a truncated Gaussian. MES approximates the expectation over the (1-D) distribution p(y_*|D_t) via (a) a Gumbel approximation of the maximum CDF computed on a discretized input set, or (b) Monte Carlo: sample posterior functions via random Fourier features (random features / 1-hidden-layer neural-net surrogate), maximize each sampled function to obtain y_* samples. MES also supports marginalization over GP hyperparameters and an additive-GP extension for high-dimensional inputs.",
            "application_domain": "Black-box optimization / experimental design / active learning across robotics, machine learning hyperparameter tuning, control (robot pushing, bipedal walker), and synthetic function optimization.",
            "resource_allocation_strategy": "Allocates the next function evaluation by maximizing estimated mutual information about y_*, selecting x that maximally reduces uncertainty about the maximum value. It controls resource allocation (computational budget for acquisition evaluation) via the number of y_* samples K and choice of sampling method (Gumbel = cheap; posterior-function maximization = more expensive). For high-dimensions it decomposes the problem via additive-GP and performs component-wise acquisition and concatenation.",
            "computational_cost_metric": "Measured in wall-clock time to select the next input (seconds) and analyzed asymptotically: sampling via the discretized CDF costs O(M |X~| log(1/δ)) for M samples, while the Gumbel approximation reduces cost to O(M + |X~| log(1/δ)). Reported runtimes in the paper (example): MES-G (K=100) = 0.12 ± 0.02 s; MES-R (K=100) = 5.85 ± 0.86 s. Complexity statements (big-O) are provided for CDF queries and sampling.",
            "information_gain_metric": "Mutual information I({x,y}; y_* | D_t) — computed as H[p(y|D_t,x)] - E_{p(y_*|D_t)}[ H[p(y|D_t,x,y_*)] ], approximated by sample averaging with closed-form truncated-Gaussian entropies and the gamma-function expression (uses Gaussian PDF ψ and CDF Ψ).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Implicitly controlled by the information objective: points that most reduce uncertainty about the maximum value are preferred. The sampled y_* values control the exploration-exploitation bias: (i) large sampled y_* encourage exploration (since many points remain plausible maxima), (ii) small y_* samples bias toward exploitation. The single-sample MES is mathematically equivalent to EST/PI/GP-UCB variants (Lemma 3.1), tying MES to established exploration-exploitation tradeoff parameters.",
            "diversity_mechanism": "No explicit, separate diversity-promoting constraint. Diversity arises implicitly from maximizing mutual information and from using multiple y_* samples which can yield different acquisition preferences across samples; additive decomposition yields per-component searches that diversify across subspaces.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed query budget (number of function evaluations T) and computational budget for acquisition computation (time per candidate selection).",
            "budget_constraint_handling": "Reduces acquisition computation through (a) reducing the target distribution dimension from d to 1 (y_*), (b) using a Gumbel approximation for y_* CDF to avoid expensive maximizations, (c) controlling the number of y_* samples K, and (d) additive-GP decomposition for high-dimensional inputs to reduce optimization complexity per component.",
            "breakthrough_discovery_metric": "Not explicitly defined; the paper uses simple regret and inference regret as proxies for discovery of high-performing inputs (i.e., lower regret indicates finding better/novel optima).",
            "performance_metrics": "Primary metrics: simple regret r_T (max_x f(x) - max_{t&lt;=T} f(x_t)) and inference regret R_T (max_x f(x) - f(tilde{x}_T)). Example numeric results reported: selection runtime per iteration — MES-G (K=100): 0.12 ± 0.02 s, MES-G (K=10): 0.09 ± 0.02 s, MES-G (K=1): 0.09 ± 0.03 s; MES-R (K=100): 5.85 ± 0.86 s, MES-R (K=10): 0.67 ± 0.11 s, MES-R (K=1): 0.13 ± 0.03 s. Inference-regret (Table 2): MES-G on Eggholder: 46.56 ± 27.05; Shekel: 5.45 ± 2.07; Michalewicz: 4.49 ± 0.51. Robot pushing (Table 4) inference-regret examples: 3-d action MES-R: 0.61 ± 1.23; MES-G: 0.61 ± 1.26.",
            "comparison_baseline": "Compared experimentally to ES, PES (entropy-search family), GP-UCB (UCB), PI, EI, EST, add-GP-UCB (in high-d tasks).",
            "performance_vs_baseline": "MES methods matched or outperformed ES/PES in many scenarios, while being much cheaper computationally. Examples: MES methods achieved lower simple regret than ES/PES on many higher-dimensional test functions; MES-G selection runtime (K=100) = 0.12 s vs PES (K=100) = 15.24 s (≈127× faster). MES methods were less sensitive to the number of samples K than PES was to number of x_* samples, obtaining good performance even with K=1 or 10.",
            "efficiency_gain": "Substantial reduction in acquisition computation: e.g., MES-G (K=100) ~0.12s vs PES (K=100) ~15.24s (≈127× speedup for next-input selection in that experimental setting). MES-G runtime comparable to fast heuristics like EI (~0.07 s) while producing superior or similar regret performance. MES-R (K large) is more expensive but still often faster than PES due to cheaper y_* sampling via random features.",
            "tradeoff_analysis": "The paper analyzes tradeoffs between computational cost (K and sampling strategy), information gain, and optimization performance: (1) Replacing argmax (d-dimensional) by y_* (1-D) dramatically lowers sampling cost while keeping information-theoretic motivation. (2) Gumbel approximation is cheap but tends to overestimate maxima (more exploration); random-feature posterior sampling (MES-R) is costlier but may underestimate maxima (more exploitation) due to imperfect global optimization of sampled functions; (3) MES is empirically robust to small K (unlike PES); (4) The regret bound (Theorem 3.2) depends on distribution of sampled y_* (too-large y_* can worsen the regret bound). These points quantify the cost-quality tradeoffs in allocation decisions.",
            "optimal_allocation_findings": "Key conclusions: (a) Reasoning about y_* (1-D) is an effective and computationally efficient surrogate for information about argmax locations — allows allocating more resources to evaluations rather than to acquisition computation; (b) use Gumbel approximation for fast, scalable acquisition when evaluations are expensive and sample-efficient acquisitions are needed; (c) using a small number of y_* samples (even K=1) often suffices in practice, enabling lower computational cost without sacrificing information gain; (d) in high dimensions, additive-GP decomposition plus per-component MES (add-MES) gives effective resource allocation across subspaces.",
            "uuid": "e2620.0",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "add-MES",
            "name_full": "Additive Max-value Entropy Search",
            "brief_description": "Extension of MES to high-dimensional problems that assumes the target function decomposes into a sum of independent lower-dimensional component functions and runs MES per component to guide component-wise query selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Additive Max-value Entropy Search (add-MES)",
            "system_description": "Assumes f(x)=sum_m f^{(m)}(x^{A_m}) with disjoint active dimension sets A_m. For each component m, add-MES computes acquisition α_t^{(m)}(x^{A_m}) = I({x^{A_m}, y^{(m)}} ; y_*^{(m)} | D_t), samples y_*^{(m)} (Gumbel or posterior-function sampling) and selects per-component maximizers; the final x_t is the concatenation of per-component argmaxes. Random-feature posterior sampling respects additive structure by using features active only on corresponding sub-vectors.",
            "application_domain": "High-dimensional Bayesian optimization where additive structure is plausible — synthetic additive functions, high-dimensional robotics control (14D pushing, 25D bipedal walker), hyperparameter tuning.",
            "resource_allocation_strategy": "Allocates evaluation budget across components by independently selecting the most informative input sub-vector for each component via component-wise mutual-information acquisitions, then concatenating them to form a full-dimensional query; sampling strategy per-component controls computation (K samples per component).",
            "computational_cost_metric": "Wall-clock time per iteration and per-component optimization cost; per-component acquisition reduces search complexity compared to full-d acquisition. Empirical runtimes depend on K and additive partitioning; asymptotic cost reduced by lower-dim optimization per component.",
            "information_gain_metric": "Component-wise mutual information I({x^{A_m}, y^{(m)}}; y_*^{(m)} | D_t), approximated by per-component y_*^{(m)} samples and truncated-Gaussian entropies.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Same principle as MES applied per-component: select sub-vectors that maximize reduction in uncertainty about their component maxima; tradeoffs controlled by sampling method (Gumbel vs posterior) and per-component y_* samples, resulting in componentwise exploration/exploitation balance.",
            "diversity_mechanism": "No explicit diversity mechanism beyond decomposing search into multiple independent components which encourages exploring different subspaces; multiple per-component y_* samples provide variability in component-level allocations.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed number of total evaluations; per-iteration per-component computation budget.",
            "budget_constraint_handling": "Reduces search and acquisition optimization cost by decomposing the domain into lower-dimensional components and using cheap y_* sampling (Gumbel) per component when needed; selects K small (often 1) per component to save computation.",
            "breakthrough_discovery_metric": "Not explicitly defined; uses simple and inference regret aggregated across full-dimensional queries as primary performance indicators.",
            "performance_metrics": "Simple regret reported in synthetic add-GP experiments: add-MES methods outperform add-GP-UCB on many synthetic additive functions. Observed qualitative behaviors: add-MES-G performed best for lower dimensions (d=10,20,30) while add-MES-R performed better for higher dimensions (d=50,100). On real tasks: add-MES competitive with add-GP-UCB on 14D pushing and 25D bipedal walker optimization (plots shown but numeric regret values not tabulated in-text).",
            "comparison_baseline": "add-GP-UCB (Kandasamy et al., 2015) and other BO baselines used in high-d experiments.",
            "performance_vs_baseline": "add-MES generally achieved lower simple regret than add-GP-UCB on the tested synthetic additive functions and was competitive on real high-d control tasks; relative advantage depended on dimensionality and sampling strategy (Gumbel vs posterior).",
            "efficiency_gain": "By restricting acquisition and optimization to lower-dimensional components, add-MES reduces per-iteration search cost and enables practical BO in higher dimensions where full-d acquisition would be intractable. Exact speedups depend on M and |A_m|; empirical gains shown qualitatively in figures.",
            "tradeoff_analysis": "Paper observes that add-MES-G (Gumbel) tends to overestimate maxima (promotes exploration) and works better in lower-d settings, while add-MES-R (random-feature posterior samples) tends to underestimate maxima (promotes exploitation) and works better in higher-d settings; this identifies a computational-quality tradeoff in sampler choice and dimensional regime.",
            "optimal_allocation_findings": "Recommendation: exploit additive structure when present; use Gumbel sampling to favor exploration cheaply in lower-d components, and consider posterior-sampling (MES-R) for higher-d components where exploitation is preferable or global optima easier to find via sampled functions.",
            "uuid": "e2620.1",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "ES",
            "name_full": "Entropy Search",
            "brief_description": "Bayesian optimization acquisition that selects queries to maximize information about the location x_* of the global optimum by reducing the entropy of the posterior over argmax locations; computationally expensive because it requires approximating a d-dimensional distribution over x_*.",
            "citation_title": "Entropy search for information-efficient global optimization",
            "mention_or_use": "use",
            "system_name": "Entropy Search (ES)",
            "system_description": "ES measures acquisition α_t(x)=I({x,y}; x_* | D_t) — mutual information between a candidate evaluation and the optimizer location x_*. It requires approximating the posterior p(x_*|D_t) (a distribution over input locations) and its entropy; PES uses a symmetric formulation. ES approximations rely on many samples from the input space and are computationally expensive and sensitive to the number of samples.",
            "application_domain": "Black-box optimization / experimental design where queries are costly and information about optimizer location is critical.",
            "resource_allocation_strategy": "Allocates evaluations by maximizing expected information gain about x_*; high computational cost associated with estimating p(x_*|D_t) often outweighs gains when function evaluations are cheap.",
            "computational_cost_metric": "Measured in wall-clock selection time; reported runtime example: ES selection time ≈ 8.07 ± 3.02 s per iteration in the paper's synthetic experiment (higher for large numbers of x_* samples).",
            "information_gain_metric": "Mutual information about x_* (entropy reduction H[p(x_*|D_t)] - E[H[p(x_*|D_t ∪ {x,y})]] ).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Selects points that most reduce uncertainty about the optimizer location, inherently encouraging exploration that is informative about x_*; the computationally expensive approximation controls the degree of exploration via sample budget.",
            "diversity_mechanism": "No separate explicit diversity mechanism beyond information-theoretic objective which tends to pick informative, potentially diverse points.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed evaluation budget; high acquisition computation budget required for effective p(x_*) estimation.",
            "budget_constraint_handling": "Not efficient under tight computational budgets; often impractical when acquisition cost must be low.",
            "breakthrough_discovery_metric": "Not defined; uses regret metrics in comparisons.",
            "performance_metrics": "Compared in experiments for regret; ES often competitive in low-d with sufficient computation but slower than MES; selection runtime reported (see above).",
            "comparison_baseline": "Compared to PES, MES, GP-UCB, PI, EI, EST in experiments.",
            "performance_vs_baseline": "ES achieves strong query-efficiency but at much higher computational cost than MES; MES matched or improved performance while reducing computational cost.",
            "efficiency_gain": "Not applicable to ES itself; MES provides efficiency gains relative to ES.",
            "tradeoff_analysis": "ES/PES trade computational cost for potential improved query-efficiency; the paper demonstrates MES trades much less computation for similar or better empirical performance.",
            "optimal_allocation_findings": "When function evaluations are extremely expensive and computational cost of acquisition is acceptable, ES/PES may be justified; otherwise MES is preferable due to computational savings with preserved information-theoretic motivation.",
            "uuid": "e2620.2",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "PES",
            "name_full": "Predictive Entropy Search",
            "brief_description": "An entropy-search variant that maximizes expected information about the optimizer location x_* using an equivalent symmetric formulation that conditions on x_*; also computationally expensive and sensitive to the number of x_* samples.",
            "citation_title": "Predictive entropy search for efficient global optimization of black-box functions",
            "mention_or_use": "use",
            "system_name": "Predictive Entropy Search (PES)",
            "system_description": "PES computes α_t(x)=I({x,y}; x_* | D_t) using a symmetric expression that involves expectations over p(x_*|D_t); approximations require sampling candidate argmax locations x_* by maximizing posterior function samples which is computationally costly. PES is empirically effective but sensitive to the number of x_* samples and scales poorly with input dimension.",
            "application_domain": "Same as ES: expensive black-box optimization and experimental design.",
            "resource_allocation_strategy": "Selects queries that maximize expected information about optimizer location x_*. The sampling budget for x_* (number of posterior-sampled argmaxes) controls computational cost and information quality.",
            "computational_cost_metric": "Wall-clock selection time; reported examples: PES (K_x*=100) ≈ 15.24 ± 4.44 s, PES (K=10) ≈ 1.61 ± 0.50 s, PES (K=1) ≈ 0.20 ± 0.06 s in the synthetic experiment — performance strongly depends on K.",
            "information_gain_metric": "Mutual information about x_* (entropy reduction) computed via symmetric PES formula.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Similar to ES — focuses on reducing uncertainty about optimizer location; number of x_* samples controls exploration thoroughness.",
            "diversity_mechanism": "No explicit diversity mechanism beyond information objective; diversity influenced by variety of sampled x_* candidates.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Computational budget for acquisition (sensitive to number of x_* samples), fixed evaluation budget.",
            "budget_constraint_handling": "Requires more computation to improve accuracy of p(x_*); paper shows PES becomes much slower as sample count increases, making it unsuitable when acquisition-time must be low.",
            "breakthrough_discovery_metric": "Not explicitly defined; uses regret measures to evaluate performance.",
            "performance_metrics": "PES can achieve strong regret when many x_* samples are used; however, performance degrades with fewer samples. Example: PES (K=100) gave better results than PES (K=10) or PES (K=1) in 3D synthetic experiments.",
            "comparison_baseline": "Compared to MES variants, ES, GP-UCB, PI, EI, EST in experiments.",
            "performance_vs_baseline": "PES can outperform alternatives given high computational budget (large K), but MES matches or exceeds PES performance with far less computation in many cases; PES is more sensitive to sample count.",
            "efficiency_gain": "Not an efficiency-improving method per se; MES offers much lower acquisition cost for similar or better performance.",
            "tradeoff_analysis": "Paper documents PES tradeoff: more x_* samples improve information quality but increase computation drastically; MES avoids this by sampling 1-D y_*.",
            "optimal_allocation_findings": "If acquisition-time is plentiful relative to function evaluation cost, PES with many samples can be effective; otherwise approximate 1-D approaches like MES are preferable.",
            "uuid": "e2620.3",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "GP-UCB",
            "name_full": "Gaussian Process Upper Confidence Bound",
            "brief_description": "A widely used BO acquisition heuristic that picks x maximizing μ_t(x) + √β_t σ_t(x), balancing exploitation and exploration via a confidence parameter β_t; theoretical no-regret guarantees exist under suitable β_t scheduling.",
            "citation_title": "Gaussian process optimization in the bandit setting: no regret and experimental design",
            "mention_or_use": "use",
            "system_name": "GP-UCB",
            "system_description": "GP-UCB selects points by maximizing an upper confidence bound constructed from the GP posterior mean and standard deviation: x_t = argmax_x ( μ_t(x) + √β_t σ_t(x) ). The parameter β_t controls exploration; theoretical β_t schedules yield regret bounds. In the paper GP-UCB is used as a baseline and is shown to be connected to MES/EST under particular parameter settings.",
            "application_domain": "General-purpose BO and experimental design for expensive black-box functions.",
            "resource_allocation_strategy": "Allocates queries by an optimism-in-face-of-uncertainty rule: choose the point with the highest upper confidence bound. Computationally cheap per-step (closed-form acquisition), suitable when acquisition must be fast.",
            "computational_cost_metric": "Low wall-clock selection time (example: UCB reported ≈ 0.08 ± 0.05 s per selection in experiments).",
            "information_gain_metric": "Does not explicitly maximize mutual information; indirectly reduces uncertainty via the confidence bound heuristic. Information-theoretic connections to MES/EST exist via parameter mapping.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Explicit via β_t: larger β_t increases exploration (weight on σ_t), smaller β_t favors exploitation (weight on μ_t).",
            "diversity_mechanism": "No explicit diversity mechanism; diversity arises from sampling points with high posterior uncertainty σ_t.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed evaluation budget; low per-iteration computational budget.",
            "budget_constraint_handling": "Efficient closed-form acquisition allows many iterations to be scheduled under tight computational budgets.",
            "breakthrough_discovery_metric": "Not explicitly defined; evaluated with regret metrics in comparisons.",
            "performance_metrics": "Reported selection runtime ~0.08 ± 0.05 s; regret performance competitive in some tasks but often outperformed by MES or PES in terms of query-efficiency.",
            "comparison_baseline": "Used as a baseline alongside PI, EI, ES, PES, EST, MES.",
            "performance_vs_baseline": "GP-UCB is computationally cheap but can be less sample-efficient than information-theoretic methods; MES/EST can be mapped to GP-UCB parameterizations (Lemma 3.1) showing theoretical connection.",
            "efficiency_gain": "Fast selection time; less sample-efficient in some problems compared to MES/PES depending on β_t and problem structure.",
            "tradeoff_analysis": "Exploration-exploitation tradeoff controlled by β_t; paper leverages equivalence to EST under specific β_t choices to relate behavior to MES.",
            "optimal_allocation_findings": "GP-UCB is recommended when acquisition-time must be minimal; for expensive evaluations but moderate acquisition compute, MES offers better sample efficiency.",
            "uuid": "e2620.4",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "EST",
            "name_full": "Optimization as Estimation (EST)",
            "brief_description": "A BO approach that chooses points by estimating the function maximum m and selecting x that minimizes the standardized distance γ_m(x) = (m - μ_t(x)) / σ_t(x); paper shows EST is equivalent to single-sample MES and related to GP-UCB and PI under parameter mappings.",
            "citation_title": "Optimization as estimation with Gaussian processes in bandit settings",
            "mention_or_use": "use",
            "system_name": "EST (Optimization as Estimation)",
            "system_description": "EST uses an estimate m of the function maximum and selects the next point by minimizing γ_m(x) = (m - μ_t(x)) / σ_t(x), i.e., picks the point most likely to reach m in standardized units. The paper proves single-sample MES (using a single y_* sample) is equivalent to EST with m = y_* and thereby connects EST to GP-UCB and PI via parameter correspondences.",
            "application_domain": "Bayesian optimization and bandit problems where an explicit estimate of the maximum is available or can be sampled.",
            "resource_allocation_strategy": "Allocates queries by minimizing standardized distance to an estimated maximum; the quality of the estimate m (sampling distribution) affects exploration-exploitation bias.",
            "computational_cost_metric": "Comparable to GP-UCB/PI (closed-form expressions per candidate), low per-step computational cost; used as baseline in experiments.",
            "information_gain_metric": "Does not directly optimize mutual information; implicitly related because estimating the maximum guides information-seeking queries. Single-sample MES equivalence shows implicit information-theoretic connection.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration-exploitation arises through the estimated m: larger m encourages exploration, smaller m favors exploitation. Equivalent to setting GP-UCB β and PI thresholds via m.",
            "diversity_mechanism": "No explicit diversity mechanism beyond the standardized-score selection which can promote exploring uncertain candidates.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed number of evaluations; low acquisition-computation budget.",
            "budget_constraint_handling": "Computationally cheap acquisition; estimate m can be drawn from a distribution (sampling) to control robustness.",
            "breakthrough_discovery_metric": "Not explicitly defined; performance assessed via regret.",
            "performance_metrics": "EST shown to have inference-regret comparable to MES in several experiments; runtime comparable to GP-UCB/PI (fast).",
            "comparison_baseline": "Compared in experiments to MES, ES, PES, GP-UCB, PI, EI.",
            "performance_vs_baseline": "EST often performs similarly to MES in inference regret when single-sample strategies are used; MES with multiple samples can outperform EST by averaging over y_* samples.",
            "efficiency_gain": "Low computational cost similar to UCB/PI; offers a principled mapping to information-theoretic MES with single-sample equivalence.",
            "tradeoff_analysis": "Shows how an estimate of the maximum (m) encodes a tradeoff between exploration and exploitation; sampling m from a distribution (as MES does) randomizes that tradeoff.",
            "optimal_allocation_findings": "Using estimates of the maximum can yield simple and efficient allocation rules with provable connections to UCB/PI; MES generalizes EST by averaging over multiple y_* samples for more robust allocations.",
            "uuid": "e2620.5",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "add-GP-UCB",
            "name_full": "Additive Gaussian Process UCB",
            "brief_description": "An extension of GP-UCB that exploits additive decomposition of high-dimensional functions to scale BO to higher dimensions by optimizing component-wise UCB acquisition functions.",
            "citation_title": "High dimensional Bayesian optimisation and bandits via additive models",
            "mention_or_use": "use",
            "system_name": "add-GP-UCB",
            "system_description": "Assumes f(x)=∑_m f^{(m)}(x^{A_m}). add-GP-UCB applies GP-UCB per component with component-specific β_t^{(m)} and selects component-wise maximizers which are combined into a full-dimensional query. It reduces optimization complexity in high dimensions by limiting searches to lower-dimensional subspaces.",
            "application_domain": "High-dimensional Bayesian optimization where additive structure is plausible (synthetic functions, robotics control, parameter tuning).",
            "resource_allocation_strategy": "Allocates queries by maximizing component-wise upper confidence bounds and concatenating the component argmaxes. The β_t^{(m)} schedule controls exploration per component.",
            "computational_cost_metric": "Per-iteration cost is reduced relative to full-d GP-UCB because per-component optimization is lower-dimensional; empirical comparison in paper shows add-MES often outperforms add-GP-UCB in simple regret.",
            "information_gain_metric": "Does not explicitly measure mutual information; uses UCB heuristic per component.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration-exploitation controlled per-component via β_t^{(m)}; recommended schedules from Kandasamy et al. are used in comparisons.",
            "diversity_mechanism": "No explicit diversity constraint; decomposed search encourages exploration across component subspaces.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed number of evaluations; need to handle high-dimensional search complexity.",
            "budget_constraint_handling": "Mitigates budget issues by reducing per-query optimization to lower-dimensional subproblems; uses β schedules to ensure theoretical coverage.",
            "breakthrough_discovery_metric": "Not explicitly defined; evaluated by simple and inference regret in experiments.",
            "performance_metrics": "add-GP-UCB used as baseline in high-d experiments. add-MES methods generally achieved lower simple regret on synthetic additive functions and were competitive on real-world high-d tasks (14D push, 25D walker).",
            "comparison_baseline": "Used as the main baseline for add-MES in high-dimensional experiments.",
            "performance_vs_baseline": "add-MES often outperformed add-GP-UCB in simple-regret on synthetic add-GP tasks; on some real tasks add-MES was competitive.",
            "efficiency_gain": "Efficient relative to full-d methods by restricting optimizations to component dimensions; empirical gains depend on decomposition quality.",
            "tradeoff_analysis": "Paper notes differences in component-level sampler behaviors (Gumbel vs posterior) and dimensionality effects on which sampler works better for add-MES vs add-GP-UCB.",
            "optimal_allocation_findings": "When additive structure holds, per-component acquisition (either UCB or MES) is effective; MES per-component acquisitions yielded better empirical simple regret in tested scenarios.",
            "uuid": "e2620.6",
            "source_info": {
                "paper_title": "Max-value Entropy Search for Efficient Bayesian Optimization",
                "publication_date_yy_mm": "2017-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Entropy search for information-efficient global optimization",
            "rating": 2
        },
        {
            "paper_title": "Predictive entropy search for efficient global optimization of black-box functions",
            "rating": 2
        },
        {
            "paper_title": "Optimization as estimation with Gaussian processes in bandit settings",
            "rating": 2
        },
        {
            "paper_title": "High dimensional Bayesian optimisation and bandits via additive models",
            "rating": 2
        },
        {
            "paper_title": "Gaussian process optimization in the bandit setting: no regret and experimental design",
            "rating": 1
        }
    ],
    "cost": 0.024072499999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Max-value Entropy Search for Efficient Bayesian Optimization</h1>
<p>Zi Wang ${ }^{1}$ Stefanie Jegelka ${ }^{1}$</p>
<h4>Abstract</h4>
<p>Entropy Search (ES) and Predictive Entropy Search (PES) are popular and empirically successful Bayesian Optimization techniques. Both rely on a compelling information-theoretic motivation, and maximize the information gained about the $\arg \max$ of the unknown function; yet, both are plagued by the expensive computation for estimating entropies. We propose a new criterion, Max-value Entropy Search (MES), that instead uses the information about the maximum function value. We show relations of MES to other Bayesian optimization methods, and establish a regret bound. We observe that MES maintains or improves the good empirical performance of ES/PES, while tremendously lightening the computational burden. In particular, MES is much more robust to the number of samples used for computing the entropy, and hence more efficient for higher dimensional problems.</p>
<h2>1. Introduction</h2>
<p>Bayesian optimization (BO) has become a popular and effective way for black-box optimization of nonconvex, expensive functions in robotics, machine learning, computer vision, and many other areas of science and engineering (Brochu et al., 2009; Calandra et al., 2014; Krause \&amp; Ong, 2011; Lizotte et al., 2007; Snoek et al., 2012; Thornton et al., 2013; Wang et al., 2017). In BO, a prior is posed on the (unknown) objective function, and the uncertainty given by the associated posterior is the basis for an acquisition function that guides the selection of the next point to query the function. The selection of queries and hence the acquisition function is critical for the success of the method.</p>
<p>Different BO techniques differ in this acquisition function.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Among the most popular ones range the Gaussian process upper confidence bound (GP-UCB) (Auer, 2002; Srinivas et al., 2010), probability of improvement (PI) (Kushner, 1964), and expected improvement (EI) (Močkus, 1974). Particularly successful recent additions are entropy search (ES) (Hennig \&amp; Schuler, 2012) and predictive entropy search (PES) (Hernández-Lobato et al., 2014), which aim to maximize the mutual information between the queried points and the location of the global optimum.</p>
<p>ES and PES are effective in the sense that they are queryefficient and identify a good point within competitively few iterations, but determining the next query point involves very expensive computations. As a result, these methods are most useful if the black-box function requires a lot of effort to evaluate, and are relatively slow otherwise. Moreover, they rely on estimating the entropy of the $\arg \max$ of the function. In high dimensions, this estimation demands a large number of samples from the input space, which can quickly become inefficient.</p>
<p>We propose a twist to the viewpoint of ES and PES that retains the information-theoretic motivation and empirically successful query-efficiency of those methods, but at a much reduced computational cost. The key insight is to replace the uncertainty about the $\arg \max$ with the uncertainty about the maximum function value. As a result, we refer to our new method as Max-value Entropy Search (MES). As opposed to the $\arg \max$, the maximum function value lives in a one-dimensional space, which greatly facilitates the estimation of the mutual information via sampling. We explore two strategies to make the entropy estimation efficient: an approximation by a Gumbel distribution, and a Monte Carlo approach that uses random features.</p>
<p>Our contributions are as follows: (1) MES, a variant of the entropy search methods, which enjoys efficient computation and simple implementation; (2) an intuitive analysis which establishes the first connection between ES/PES and the previously proposed criteria GP-UCB, PI and EST (Wang et al., 2016), where the bridge is formed by MES; (3) a regret bound for a variant of MES, which, to our knowledge, is the first regret bound established for any variant of the entropy search methods; (4) an extension of MES to the high dimensional settings via additive Gaussian processes; and (5) empirical evaluations which demon-</p>
<p>strate that MES identifies good points as quickly or better than ES/PES, but is much more efficient and robust in estimating the mutual information, and therefore much faster than its input-space counterparts.</p>
<p>After acceptance of this work, we learned that Hoffman \&amp; Ghahramani (2015) independently arrived at the acquisition function in Eq. (5). Yet, our approximation (Eq. (6)) is different, and hence the actual acquisition function we evaluate and analyze is different.</p>
<h2>2. Background</h2>
<p>Our goal is to maximize a black-box function $f: \mathfrak{X} \rightarrow \mathbb{R}$ where $\mathfrak{X} \subset \mathbb{R}^{d}$ and $\mathfrak{X}$ is compact. At time step $t$, we select point $\boldsymbol{x}<em t="t">{t}$ and observe a possibly noisy function evaluation $y</em>}=f\left(\boldsymbol{x<em t="t">{t}\right)+\epsilon</em>\right)$ are i.i.d. Gaussian variables. We use Gaussian processes (Rasmussen \&amp; Williams, 2006) to build a probabilistic model of the blackbox function to be optimized. For high dimensional cases, we use a variant of the additive Gaussian process (Duvenaud et al., 2011; Kandasamy et al., 2015). For completeness, we here introduce some basics of GP and add-GP.}$, where $\epsilon_{t} \sim \mathcal{N}\left(0, \sigma^{2</p>
<h3>2.1. Gaussian Processes</h3>
<p>Gaussian processes (GPs) are distributions over functions, and popular priors for Bayesian nonparametric regression. In a GP, any finite set of function values has a multivariate Gaussian distribution. A Gaussian process $G P(\mu, k)$ is fully specified by a mean function $\mu(\boldsymbol{x})$ and covariance (kernel) function $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)$. Let $f$ be a function sampled from $G P(\mu, k)$. Given the observations $D_{t}=\left{\left(\boldsymbol{x}<em _tau="\tau">{\tau}, y</em>\right)\right}<em t="t">{\tau=1}^{t}$, we obtain the posterior mean $\mu</em>}(\boldsymbol{x})=\boldsymbol{k<em t="t">{t}(\boldsymbol{x})^{\mathrm{T}}\left(\boldsymbol{K}</em>}+\sigma^{2} \boldsymbol{I}\right)^{-1} \boldsymbol{y<em t="t">{t}$ and posterior covariance $k</em>}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)-\boldsymbol{k<em t="t">{t}(\boldsymbol{x})^{\mathrm{T}}\left(\boldsymbol{K}</em>}+\sigma^{2} \boldsymbol{I}\right)^{-1} \boldsymbol{k<em t="t">{t}\left(\boldsymbol{x}^{\prime}\right)$ of the function via the kernel matrix $\boldsymbol{K}</em>}=\left[k\left(\boldsymbol{x<em j="j">{i}, \boldsymbol{x}</em>\right)\right]<em i="i">{\boldsymbol{x}</em>}, \boldsymbol{x<em t="t">{j} \in D</em>}}$ and $\boldsymbol{k<em i="i">{t}(\boldsymbol{x})=\left[k\left(\boldsymbol{x}</em>\right)\right]}, \boldsymbol{x<em i="i">{\boldsymbol{x}</em>)$.} \in D_{t}}$ (Rasmussen \&amp; Williams, 2006). The posterior variance is $\sigma_{t}^{2}(\boldsymbol{x})=k_{t}(\boldsymbol{x}, \boldsymbol{x</p>
<h3>2.2. Additive Gaussian Processes</h3>
<p>Additive Gaussian processes (add-GP) were proposed in (Duvenaud et al., 2011), and analyzed in the BO setting in (Kandasamy et al., 2015). Following the latter, we assume that the function $f$ is a sum of independent functions sampled from Gaussian processes that are active on disjoint sets $A_{m}$ of input dimensions. Precisely, $f(x)=\sum_{m=1}^{M} f^{(m)}\left(x^{A_{m}}\right)$, with $A_{i} \cap A_{j}=$ $\emptyset$ for all $i \neq j, \quad \cup_{i=1}^{M} A_{i} \mid=d$, and $f^{(m)} \sim$ $G P\left(\mu^{(m)}, k^{(m)}\right)$, for all $m \leq M(M \leq d&lt;\infty)$. As a result of this decomposition, the function $f$ is distributed according to $G P\left(\sum_{m=1}^{M} \mu^{(m)}, \sum_{m=1}^{M} k^{(m)}\right)$. Given a set of noisy observations $D_{t}=\left{\left(\boldsymbol{x}<em _tau="\tau">{\tau}, y</em>\right)\right}<em _tau="\tau">{\tau=1}^{t}$ where $y</em>\right)$, the posterior mean and
covariance of the function component $f^{(m)}$ can be inferred as $\mu_{t}^{(m)}(\boldsymbol{x})=\boldsymbol{k}} \sim \mathcal{N}\left(f\left(x_{\tau}\right), \sigma^{2<em t="t">{t}^{(m)}(\boldsymbol{x})^{\mathrm{T}}\left(\boldsymbol{K}</em>}+\sigma^{2} \boldsymbol{I}\right)^{-1} \boldsymbol{y<em t="t">{t}$ and $k</em>}^{(m)}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=k^{(m)}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)-\boldsymbol{k<em t="t">{t}^{(m)}(\boldsymbol{x})^{\mathrm{T}}\left(\boldsymbol{K}</em>}+\right.$ $\left.\sigma^{2} \boldsymbol{I}\right)^{-1} \boldsymbol{k<em t="t">{t}^{(m)}\left(\boldsymbol{x}^{\prime}\right)$, where $\boldsymbol{k}</em>}^{(m)}(\boldsymbol{x})=\left[k^{(m)}\left(\boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{i}, \boldsymbol{x}\right)\right]</em><em t="t">{i} \in D</em>}}$ and $\boldsymbol{K<em m="1">{t}=\left[\sum</em>}^{M} k^{(m)}\left(\boldsymbol{x<em j="j">{i}, \boldsymbol{x}</em>\right)\right]<em i="i">{\boldsymbol{x}</em>}, \boldsymbol{x<em t="t">{j} \in D</em>\right)$.}}$. For simplicity, we use the shorthand $k^{(m)}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=k^{(m)}\left(\boldsymbol{x}^{A_{m}}, \boldsymbol{x}^{\prime A_{m}</p>
<h3>2.3. Evaluation Criteria</h3>
<p>We use two types of evaluation criteria for BO, simple regret and inference regret. In each iteration, we choose to evaluate one input $\boldsymbol{x}<em T="T">{t}$ to "learn" where the $\arg \max$ of the function is. The simple regret $r</em>=$ $\max <em T_="T]" _in_1_="\in[1," t="t">{\boldsymbol{x} \in \mathfrak{X}} f(\boldsymbol{x})-\max </em>} f\left(\boldsymbol{x<em T="T">{t}\right)$ measures the value of the best queried point so far. After all queries, we may infer an $\arg \max$ of the function, which is usually chosen as $\tilde{\boldsymbol{x}}</em>=\arg \max <em T="T">{\boldsymbol{x} \in \mathfrak{X}} \mu</em>=\max }(\boldsymbol{x})$ (Hennig \&amp; Schuler, 2012; Hernández-Lobato et al., 2014). We denote the inference regret as $R_{T<em T="T">{\boldsymbol{x} \in \mathfrak{X}} f(\boldsymbol{x})-f\left(\tilde{x}</em>\right)$ which characterizes how satisfying our inference of the $\arg \max$ is.</p>
<h2>3. Max-value Entropy Search</h2>
<p>Entropy search methods use an information-theoretic perspective to select where to evaluate. They find a query point that maximizes the information about the location $\boldsymbol{x}<em>{<em>}=\arg \max <em>{\boldsymbol{x} \in \mathfrak{X}} f(x)$ whose value $y</em>{</em>}=f\left(\boldsymbol{x}</em>{<em>}\right)$ achieves the global maximum of the function $f$. Using the negative differential entropy of $p\left(\boldsymbol{x}_{</em>}\left|D_{t}\right)\right.$ to characterize the uncertainty about $\boldsymbol{x}_{*}$, ES and PES use the acquisition functions</p>
<p>$$
\begin{aligned}
&amp; \alpha_{t}(x)=I({\boldsymbol{x}, y} ; \boldsymbol{x}<em t="t">{<em>} \mid D_{t}) \
&amp; \quad=H\left(p\left(\boldsymbol{x}_{</em>}\left|D</em>_{}\right)\right)-\mathbb{E}\left[H\left(p\left(\boldsymbol{x<em>}\left|D_{t} \cup{\boldsymbol{x}, y}\right)\right)\right]\right. \
&amp; \quad=H\left(p\left(y \mid D_{t}, \boldsymbol{x}\right)\right)-\mathbb{E}\left[H\left(p\left(y \mid D_{t}, \boldsymbol{x}, \boldsymbol{x}_{</em>}\right)\right)\right]
\end{aligned}
$$</p>
<p>ES uses formulation (2), in which the expectation is over $p\left(y \mid D_{t}, \boldsymbol{x}\right)$, while PES uses the equivalent, symmetric formulation (3), where the expectation is over $p\left(\boldsymbol{x}<em t="t">{<em>}\left|D_{t}\right)\right.$. Unfortunately, both $p\left(\boldsymbol{x}_{</em>}\left|D</em>\right)\right.$ and its entropy is analytically intractable and have to be approximated via expensive computations. Moreover, the optimum may not be unique, adding further complexity to this distribution.</p>
<p>We follow the same information-theoretic idea but propose a much cheaper and more robust objective to compute. Instead of measuring the information about the $\operatorname{argmax} \boldsymbol{x}<em>{<em>}$, we use the information about the maximum value $y_{</em>}=$ $f\left(\boldsymbol{x}</em>{<em>}\right)$. Our acquisition function is the gain in mutual information between the maximum $y_{</em>}$ and the next point we query, which can be approximated analytically by evaluating the entropy of the predictive distribution:</p>
<p>$$
\begin{aligned}
&amp; \alpha_{t}(x)=I\left({\boldsymbol{x}, y} ; y_{<em>} \mid D_{t}\right) \
&amp; =H\left(p\left(y \mid D_{t}, \boldsymbol{x}\right)\right)-\mathbb{E}\left[H\left(p\left(y \mid D_{t}, \boldsymbol{x}, y_{</em>}\right)\right)\right]
\end{aligned}
$$</p>
<p>$$
\approx \frac{1}{K} \sum_{y_{<em>} \in Y_{</em>}}\left[\frac{\gamma_{y_{<em>}}(\boldsymbol{x}) \psi\left(\gamma_{y_{</em>}}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{<em>}}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{</em>}}(\boldsymbol{x})\right)\right)\right]
$$</p>
<p>where $\psi$ is the probability density function and $\Psi$ the cumulative density function of a normal distribution, and $\gamma_{y_{<em>}}(\boldsymbol{x})=\frac{y_{</em>}-\mu_{t}(\boldsymbol{x})}{\sigma_{t}(\boldsymbol{x})}$. The expectation in Eq. (5) is over $p\left(y_{<em>} \mid D_{n}\right)$, which is approximated using Monte Carlo estimation by sampling a set of $K$ function maxima. Notice that the probability in the first term $p\left(y \mid D_{t}, \boldsymbol{x}\right)$ is a Gaussian distribution with mean $\mu_{t}(\boldsymbol{x})$ and variance $k_{t}(\boldsymbol{x}, \boldsymbol{x})$. The probability in the second term $p\left(y \mid D_{n}, \boldsymbol{x}, y_{</em>}\right)$ is a truncated Gaussian distribution: given $y_{<em>}$, the distribution of $y$ needs to satisfy $y&lt;y_{</em>}$. Importantly, while ES and PES rely on the expensive, $d$-dimensional distribution $p\left(\boldsymbol{x}<em n="n">{<em>} \mid D_{t}\right)$, here, we use the one-dimensional $p\left(y_{</em>} \mid D</em>\right)$, which is computationally much easier.</p>
<p>It may not be immediately intuitive that the value should bear sufficient information for a good search strategy. Yet, the empirical results in Section 5 will demonstrate that this strategy is typically at least as good as ES/PES. From a formal perspective, Wang et al. (2016) showed how an estimate of the maximum value implies a good search strategy (EST). Indeed, Lemma 3.1 will make the relation between EST and a simpler, degenerate version of MES explicit.</p>
<p>Hence, it remains to determine how to sample $y_{<em>}$. We propose two strategies: (1) sampling from an approximation via a Gumbel distribution; and (2) sampling functions from the posterior Gaussian distribution and maximizing the functions to obtain samples of $y_{</em>}$. We present the MES algorithm in Alg. 1.</p>
<h3>3.1. Gumbel Sampling</h3>
<p>The marginal distribution of $f(x)$ for any $x$ is a onedimensional Gaussian, and hence the distribution of $y^{<em>}$ may be viewed as the maximum of an infinite collection of dependent Gaussian random variables. Since this distribution is difficult to compute, we make two simplifications. First, we replace the continuous set $\mathfrak{X}$ by a discrete (finite), dense subset $\tilde{\mathfrak{X}}$ of representative points. If we select $\tilde{\mathfrak{X}}$ to be an $\epsilon$ cover of $\mathfrak{X}$ and the function $f$ is Lipschitz continuous with constant $L$, then we obtain a valid upper bound on $f(\mathfrak{X})$ by adding $\epsilon L$ to any upper bound on $f(\tilde{\mathfrak{X}})$.
Second, we use a "mean field" approximation and treat the function values at the points in $\tilde{\mathfrak{X}}$ as independent. This approximation tends to over-estimate the maximum; this follows from Slepian's lemma if $k\left(x, x^{\prime}\right) \geq 0$. Such upper bounds still lead to optimization strategies with vanishing regret, whereas lower bounds may not (Wang et al., 2016).
We sample from the approximation $\hat{p}\left(y^{</em>} \mid D_{n}\right)$ via its cumulative distribution function (CDF) $\widehat{\operatorname{Pr}}\left[y_{*}&lt;z\right]=$ $\prod_{\boldsymbol{x} \in \tilde{\mathfrak{X}}} \Psi\left(\gamma_{z}(\boldsymbol{x})\right)$. That means we sample $r$ uniformly from</p>
<div class="codehilite"><pre><span></span><code>Algorithm 1 Max-value Entropy Search (MES)
function \(\operatorname{MES}\left(f, D_{0}\right)\)
    for \(t=1, \cdots, T\) do
        \(\alpha_{t-1}(\cdot) \leftarrow\) APPROX-MI \(\left(D_{t-1}\right)\)
        \(\boldsymbol{x}_{t} \leftarrow \arg \max <span class="ge">_{\boldsymbol{x} \in \mathfrak{X}} \alpha_</span>{t-1}(\boldsymbol{x})\)
        \(y_{t} \leftarrow f\left(\boldsymbol{x}_{t}\right)+\epsilon_{t}, \epsilon_{t} \sim \mathcal{N}\left(0, \sigma^{2}\right)\)
        \(\mathfrak{D}_{t} \leftarrow D_{t-1} \cup\left\{\boldsymbol{x}_{t}, y_{t}\right\}\)
    end for
    end function
    function Approx-MI \(\left(D_{t}\right)\)
        if Sample with Gumbel then
            approximate \(\operatorname{Pr}\left[\hat{y}_{*}&lt;y\right]\) with \(\mathcal{G}(a, b)\)
            sample a \(K\)-length vector \(\boldsymbol{r} \sim \operatorname{Unif}([0,1])\)
            \(\boldsymbol{y}_{*} \leftarrow a-b \log (-\log \boldsymbol{r})\)
        else
            for \(i=1, \cdots, K\) do
                sample \(\hat{f} \sim G P\left(\mu_{t}, k_{t} \mid D_{t}\right)\)
                \(y_{*(i)} \leftarrow \max <span class="ge">_{\boldsymbol{x} \in \mathfrak{X}} \hat{f}(\boldsymbol{x})\)</span>
<span class="ge">            end for</span>
<span class="ge">            \(\boldsymbol{y}_</span>{*} \leftarrow\left[y_{*(i)}\right]_{i=1}^{K}\)
        end if
        return \(\alpha_{t}(\cdot)\) in Eq. (6)
    end function
</code></pre></div>

<p>$[0,1]$ and find $z$ such that $\operatorname{Pr}\left[y_{<em>}&lt;z\right]=r$. A binary search for $z$ to accuracy $\delta$ requires $O\left(\log \frac{1}{\delta}\right)$ queries to the CDF, and each query takes $O(|\tilde{\mathfrak{X}}|) \approx O\left(n^{d}\right)$ time, so we obtain an overall time of $O\left(M|\tilde{\mathfrak{X}}| \log \frac{1}{\delta}\right)$ for drawing $M$ samples.
To sample more efficiently, we propose a $O(M+$ $|\tilde{\mathfrak{X}}| \log \frac{1}{\delta})$-time strategy, by approximating the CDF by a Gumbel distribution: $\widehat{\operatorname{Pr}}\left[y_{</em>}&lt;z\right] \approx \mathcal{G}(a, b)=e^{-e^{-\frac{b-a}{b}}}$. This choice is motivated by the Fisher-Tippett-Gnedenko theorem (Fisher, 1930), which states that the maximum of a set of i.i.d. Gaussian variables is asymptotically described by a Gumbel distribution (see the appendix for further details). This does not in general extend to non-i.i.d. Gaussian variables, but we nevertheless observe that in practice, this approach yields a good and fast approximation.
We sample from the Gumbel distribution via the Gumbel quantile function: we sample $r$ uniformly from $[0,1]$, and let the sample be $y=\mathcal{G}^{-1}(a, b)=a-b \log (-\log r)$. We set the appropriate Gumbel distribution parameters $a$ and $b$ by percentile matching and solve the two-variable linear equations $a-b \log \left(-\log r_{1}\right)=y_{1}$ and $a-$ $b \log \left(-\log r_{2}\right)=y_{2}$, where $\operatorname{Pr}\left[y_{<em>}&lt;y_{1}\right]=r_{1}$ and $\operatorname{Pr}\left[y_{</em>}&lt;y_{2}\right]=r_{2}$. In practice, we use $r_{1}=0.25$ and $r_{2}=0.75$ so that the scale of the approximated Gumbel distribution is proportional to the interquartile range of the $\operatorname{CDF} \widehat{\operatorname{Pr}}\left[y_{*}&lt;z\right]$.</p>
<h3>3.2. Sampling $y_{*}$ via Posterior Functions</h3>
<p>For an alternative sampling strategy we follow (HernándezLobato et al., 2014): we draw functions from the posterior GP and then maximize each of the sampled functions. Given the observations $D_{t}=\left{\left(\boldsymbol{x}<em _tau="\tau">{\tau}, y</em>\right)<em t="t">{\tau=1}^{t}\right}$, we can approximate the posterior Gaussian process using a 1-hiddenlayer neural network $\hat{f}(\boldsymbol{x})=\boldsymbol{a}</em>}^{\mathrm{T}} \boldsymbol{\phi}(\boldsymbol{x})$ where $\boldsymbol{\phi}(x) \in \mathbb{R}^{D}$ is a vector of feature functions (Neal, 1996; Rahimi et al., 2007) and the Gaussian weight $\boldsymbol{a<em t="t">{t} \in \mathbb{R}^{D}$ is distributed according to a multivariate Gaussian $\mathcal{N}\left(\boldsymbol{\nu}</em>}, \boldsymbol{\Sigma<em _hat_k="\hat{k" _omega="\omega" _sim="\sim">{t}\right)$.
Computing $\boldsymbol{\phi}(x)$. By Bochner's theorem (Rudin, 2011), the Fourier transform $\hat{k}$ of a continuous and translation-invariant kernel $k$ is guaranteed to be a probability distribution. Hence we can write the kernel of the GP to be $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=\mathbb{E}</em>}(\omega)}\left[e^{i \omega^{\mathrm{T}}\left(\boldsymbol{x}-\boldsymbol{x}^{\prime}\right)}\right]=$ $\mathbb{E<em _hat_k="\hat{k">{c \sim U[0,2 \pi]} \mathbb{E}</em> \sim$ $U[0,2 \pi]$ for $i=1, \ldots, D$.
Computing $\boldsymbol{\nu}}}\left[2 \cos \left(\omega^{\mathrm{T}} \boldsymbol{x}+c\right) \cos \left(\omega^{\mathrm{T}} \boldsymbol{x}^{\prime}+c\right)\right]$ and approximate the expectation by $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right) \approx \boldsymbol{\phi}^{\mathrm{T}}(\boldsymbol{x}) \boldsymbol{\phi}\left(\boldsymbol{x}^{\prime}\right)$ where $\phi_{i}(\boldsymbol{x})=\sqrt{\frac{2}{D}} \cos \left(\omega_{i}^{\mathrm{T}} \boldsymbol{x}+c_{i}\right), \omega_{i} \sim \hat{\kappa}(\omega)$, and $c_{i<em t="t">{t}, \boldsymbol{\Sigma}</em>}$. By writing the GP as a random linear combination of feature functions $\boldsymbol{a<em t="t">{t}^{T} \boldsymbol{\phi}(\boldsymbol{x})$, we are defining the mean and covariance of the GP to be $\mu</em>}(\boldsymbol{x})=$ $\boldsymbol{\nu}^{\mathrm{T}} \boldsymbol{\phi}(\boldsymbol{x})$ and $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=\boldsymbol{\phi}(\boldsymbol{x})^{\mathrm{T}} \boldsymbol{\Sigma<em 1="1">{t} \boldsymbol{\phi}\left(\boldsymbol{x}^{\prime}\right)$. Let $Z=$ $\left[z</em>}, \cdots, z_{t}\right] \in \mathbb{R}^{D \times t}$, where $z_{\tau}:=\boldsymbol{\phi}\left(\boldsymbol{x<em t="t">{\tau}\right) \in \mathbb{R}^{D}$. The GP posterior mean and covariance in Section 2.1 become $\mu</em>}(\boldsymbol{x})=z^{\mathrm{T}} Z\left(Z^{\mathrm{T}} Z+\sigma^{2} \boldsymbol{I}\right)^{-1} \boldsymbol{y<em t="t">{t}$ and $k</em>}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right)=z^{\mathrm{T}} z^{\prime}-$ $z^{\mathrm{T}} Z\left(Z^{\mathrm{T}} Z+\sigma^{2} \boldsymbol{I}\right)^{-1} Z^{\mathrm{T}} z^{\prime}$. Because $Z\left(Z^{\mathrm{T}} Z+\sigma^{2} \boldsymbol{I}\right)^{-1}=$ $\left(Z Z^{\mathrm{T}}+\sigma^{2} \boldsymbol{I}\right)^{-1} Z$, we can simplify the above equations and obtain $\boldsymbol{\nu<em t="t">{t}=\sigma^{-2} \boldsymbol{\Sigma}</em>} Z_{t} \boldsymbol{y<em t="t">{t}$ and $\boldsymbol{\Sigma}</em>$.
To sample a function from this random 1-hidden-layer neural network, we sample $\hat{\boldsymbol{a}}$ from $\mathcal{N}\left(\boldsymbol{\nu}}=\left(Z Z^{\mathrm{T}} \sigma^{-2}+\boldsymbol{I}\right)^{-1<em t="t">{t}, \boldsymbol{\Sigma}</em>)$.}\right)$ and construct the sampled function $\hat{f}=\hat{\boldsymbol{a}}^{\mathrm{T}} \boldsymbol{\phi}(\boldsymbol{x})$. Then we optimize $\hat{f}$ with respect to its input to get a sample of the maximum of the function $\max _{\boldsymbol{x} \in \mathfrak{X}} \hat{f}(\boldsymbol{x</p>
<h3>3.3. Relation to Other BO Methods</h3>
<p>As a side effect, our new acquisition function draws connections between ES/PES and other popular BO methods. The connection between MES and ES/PES follows from the information-theoretic viewpoint; the following lemma makes the connections to other methods explicit.
Lemma 3.1. The following methods are equivalent:</p>
<ol>
<li>MES, where we only use a single sample $y_{*}$ for $\alpha_{t}(x)$;</li>
<li>EST with $m=y_{*}$;</li>
<li>GP-UCB with $\beta^{\frac{1}{2}}=\min <em _="*">{\boldsymbol{x} \in \mathfrak{X}} \frac{y</em>$;}-\mu_{t}(\boldsymbol{x})}{\sigma_{t}(\boldsymbol{x})</li>
<li>PI with $\theta=y_{*}$.</li>
</ol>
<p>This equivalence no longer holds if we use $M&gt;1$ samples of $y_{*}$ in MES.</p>
<p>Proof. The equivalence among 2,3,4 is stated in Lemma 2.1 in (Wang et al., 2016). What remains to be shown is the equivalence between 1 and 2 . When using a single $y_{<em>}$ in MES, the next point to evaluate is chosen by maximizing $\alpha_{t}(\boldsymbol{x})=\gamma_{y_{</em>}}(\boldsymbol{x}) \frac{\psi\left(\gamma_{y_{<em>}}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{</em>}}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{<em>}}(\boldsymbol{x})\right)\right)$ and $\gamma_{y_{</em>}}=\frac{y_{<em>}-\mu_{t}(\boldsymbol{x})}{\sigma_{t}(\boldsymbol{x})}$. For EST with $m=y_{</em>}$, the next point to evaluate is chosen by minimizing $\gamma_{y_{<em>}}(\boldsymbol{x})$. Let us define a function $g(u)=u \frac{\psi(u)}{2 \Psi(u)}-\log (\Psi(u))$. Clearly, $\alpha_{t}(\boldsymbol{x})=g\left(\gamma_{y_{</em>}}(\boldsymbol{x})\right)$. Because $g(u)$ is a monotonically decreasing function, maximizing $g\left(\gamma_{y_{<em>}}(\boldsymbol{x})\right)$ is equivalent to minimizing $\gamma_{y_{</em>}}(\boldsymbol{x})$. Hence 1 and 2 are equivalent.</p>
<h3>3.4. Regret Bound</h3>
<p>The connection with EST directly leads to a bound on the simple regret of MES, when using only one sample of $y_{<em>}$. We prove Theorem 3.2 in the appendix.
Theorem 3.2 (Simple Regret Bound). Let $F$ be the cumulative probability distribution for the maximum of any function $f$ sampled from $G P(\mu, k)$ over the compact search space $\mathfrak{X} \subset R^{d}$, where $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right) \leq 1, \forall \boldsymbol{x}, \boldsymbol{x}^{\prime} \in \mathfrak{X}$. Let $f_{</em>}=\max <em>{\boldsymbol{x} \in \mathfrak{X}} f(\boldsymbol{x})$ and $w=F\left(f</em>{<em>}\right) \in(0,1)$, and assume the observation noise is iid $\mathcal{N}(0, \sigma)$. If in each iteration $t$, the query point is chosen as $\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t}=$ $\arg \max </em> \gamma_{y_{} \in \mathfrak{X}</em>}^{t}}(\boldsymbol{x}) \frac{\psi\left(\gamma_{y_{<em>}^{t}}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{</em>}^{t}}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{<em>}^{t}}(\boldsymbol{x})\right)\right)$, where $\gamma_{y_{</em>}^{t}}(\boldsymbol{x})=\frac{y_{<em>}^{t}-\mu_{t}(\boldsymbol{x})}{\sigma_{t}(\boldsymbol{x})}$ and $y_{</em>}^{t}$ is drawn from $F$, then with probability at least $1-\delta$, in $\mathcal{T}^{\prime}=\sum_{i=1}^{T} \log <em i="i">{w} \frac{\delta}{2 \pi</em>$ number of iterations, the simple regret satisfies}</p>
<p>$$
r_{T^{\prime}} \leq \sqrt{\frac{C \rho_{T}}{T}}\left(\nu_{t^{*}}+\zeta_{T}\right)
$$</p>
<p>where $C=2 / \log \left(1+\sigma^{-2}\right)$ and $\zeta_{T}=\left(2 \log \left(\frac{\pi_{T}}{\delta}\right)\right)^{\frac{1}{2}} ; \pi$ satisfies $\sum_{i=1}^{T} \pi_{i}^{-1} \leq 1$ and $\pi_{t}&gt;0$, and $t^{<em>}=\arg \max <em t="t">{t} \nu</em> \triangleq \min }$ with $\nu_{t<em>{\boldsymbol{x} \in \mathfrak{X}, y</em>{</em>}^{t}&gt;f_{<em>}} \gamma_{y_{</em>}^{t}}(\boldsymbol{x})$, and $\rho_{T}$ is the maximum information gain of at most $T$ selected points.</p>
<h3>3.5. Model Adaptation</h3>
<p>In practice we do not know the hyper-parameters of the GP, so we must adapt our GP model as we observe more data. A standard way to learn the GP hyper-parameters is to optimize the marginal data likelihood with respect to the hyperparameters. As a full Bayesian treatment, we can also draw samples of the hyper-parameters using slice sampling (Vanhatalo et al., 2013), and then marginalize out the hyperparameters in our acquisition function in Eq. (6). Namely, if we use $E$ to denote the set of sampled settings for the GP hyper-parameters, our acquisition function becomes
$\alpha_{t}(x)=\sum_{\eta \in E} \sum_{y_{<em>} \in Y_{</em>}}\left[\frac{\gamma_{y_{<em>}}^{\eta}(\boldsymbol{x}) \psi\left(\gamma_{y_{</em>}}^{\eta}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{<em>}}^{\eta}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{</em>}}^{\eta}(\boldsymbol{x})\right)\right)\right]$,</p>
<p>where $\gamma_{y_{<em>}}^{\eta}(\boldsymbol{x})=\frac{y_{</em>}-\mu_{t}^{\eta}(\boldsymbol{x})}{\sigma_{t}^{\eta}(\boldsymbol{x})}$ and the posterior inference on the mean function $\mu_{t}^{\eta}$ and $\sigma_{t}^{\eta}$ depends on the GP hyperparameter setting $\eta$. Similar approaches have been used in (Hernández-Lobato et al., 2014; Snoek et al., 2012).</p>
<h2>4. High Dimensional MES with Add-GP</h2>
<p>The high-dimensional input setting has been a challenge for many BO methods. We extend MES to this setting via additive Gaussian processes (Add-GP). In the past, AddGP has been used and analyzed for GP-UCB (Kandasamy et al., 2015), which assumed the high dimensional blackbox function is a summation of several disjoint lower dimensional functions. Utilizing this special additive structure, we overcome the statistical problem of having insufficient data to recover a complex function, and the difficulty of optimizing acquisition functions in high dimensions.</p>
<p>Since the function components $f^{(m)}$ are independent, we can maximize the mutual information between the input in the active dimensions $A_{m}$ and maximum of $f^{(m)}$ for each component separately. Hence, we have a separate acquisition function for each component, where $y^{(m)}$ is the evaluation of $f^{(m)}$ :</p>
<p>$$
\begin{aligned}
&amp; \alpha_{t}^{(m)}(\boldsymbol{x})=I\left(\left{\boldsymbol{x}^{A_{m}}, y^{(m)}\right} ; y_{<em>}^{(m)} \mid D_{t}\right) \
&amp; =H\left(p\left(y^{(m)} \mid D_{t}, \boldsymbol{x}^{A_{m}}\right)\right) \
&amp; \quad-\mathbb{E}\left[H\left(p\left(y^{(m)} \mid D_{t}, \boldsymbol{x}^{A_{m}}, y_{</em>}^{(m)}\right)\right)\right] \
&amp; \approx \sum_{y_{<em>}^{(m)}} \gamma_{y_{</em>}}^{(m)}(\boldsymbol{x}) \frac{\psi\left(\gamma_{y_{<em>}}^{(m)}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{</em>}}^{(m)}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{*}}^{(m)}(\boldsymbol{x})\right)\right)
\end{aligned}
$$</p>
<p>where $\gamma_{y_{<em>}}^{(m)}(\boldsymbol{x})=\frac{y_{</em>}^{(m)}-\mu_{t}^{(m)}(\boldsymbol{x})}{\sigma_{t}^{(m)}(\boldsymbol{x})}$. Analogously to the nonadditive case, we sample $y_{*}^{(m)}$, separately for each function component. We select the final $x_{t}$ by choosing a sub-vector $x_{t}^{(m)} \in \arg \max <em m="m">{\boldsymbol{x}^{(m)} \in A</em>\right)$ and concatenating the components.}} \alpha_{t}^{(m)}\left(\boldsymbol{x}^{(m)</p>
<p>Sampling $y_{<em>}^{(m)}$ with a Gumbel distribution. The Gumbel sampling from Section 3.1 directly extends to sampling $y_{</em>}^{(m)}$, approximately. We simply need to sample from the component-wise $\operatorname{CDF} \widehat{\operatorname{Pr}}\left[y_{*}^{(m)}&lt;z\right]=$ $\prod_{\boldsymbol{x} \in \bar{X}} \Psi\left(\gamma_{y}^{(m)}(\boldsymbol{x})\right)$ ), and use the same Gumbel approximation.</p>
<p>Sampling $y_{<em>}^{(m)}$ via posterior functions. The additive structure removes some connections on the input-to-hidden layer of our 1-hidden-layer neural network approximation $\tilde{f}(\boldsymbol{x})=\boldsymbol{a}<em m="m">{t}^{\mathrm{T}} \boldsymbol{\phi}(\boldsymbol{x})$. Namely, for each feature function $\phi$ there exists a unique group $m$ such that $\phi$ is only active on $\boldsymbol{x}^{A</em> \ni \omega \sim$
$\tilde{\kappa}^{(m)}(\omega)$ and $c \sim U[0,2 \pi]$. Similar to the non-additive case, we may draw a posterior sample $\boldsymbol{a}}}$, and $\phi(\boldsymbol{x})=\sqrt{\frac{\tilde{f}}{D}} \cos \left(\omega^{\mathrm{T}} \boldsymbol{x}^{A_{m}}+c\right)$ where $\mathbb{R}^{|A_{m}|<em t="t">{t} \sim \mathcal{N}\left(\boldsymbol{\nu}</em>}, \boldsymbol{\Sigma<em t="t">{t}\right)$ where $\boldsymbol{\nu}</em>}=\sigma^{-2} \boldsymbol{\Sigma<em t="t">{t} Z</em>} \boldsymbol{y<em t="t">{t}$ and $\boldsymbol{\Sigma}</em>}=\left(Z Z^{\mathrm{T}} \sigma^{-2}+\boldsymbol{I}\right)^{-1}$. Let $B_{m}=\left{i: \boldsymbol{\phi<em m="m">{i}(\boldsymbol{x})\right.$ is active on $\left.\boldsymbol{x}^{A</em>}}\right}$. The posterior sample for the function component $f^{(m)}$ is $\tilde{f}^{(m)}(\boldsymbol{x})=$ $\left(\boldsymbol{a<em m="m">{t}^{B</em>$ to obtain a sample for $y_{}}\right)^{\mathrm{T}} \phi^{B_{m}}\left(\boldsymbol{x}^{A_{m}}\right)$. Then we can maximize $\tilde{f}^{(m)</em>}^{(m)}$.</p>
<p>The algorithm for the additive max-value entropy search method (add-MES) is shown in Algorithm 2. The function APPROX-MI does the pre-computation for approximating the mutual information in a similar way as in Algorithm 1, except that it only acts on the active dimensions in the $m$-th group.</p>
<div class="codehilite"><pre><span></span><code>Algorithm 2 Additive Max-value Entropy Search
    function Add-MES \(\left(f, D_{0}\right)\)
        for \(t=1, \cdots, T\) do
            for \(m=1, \cdots, M\) do
                \(\alpha_{t-1}^{(m)}(\cdot) \leftarrow\) APPROX-MI \(\left(D_{t-1}\right)\)
                \(\boldsymbol{x}_{t}^{A_{m}} \leftarrow \arg \max <span class="ge">_{\boldsymbol{x}^{A_</span>{m}} \in \bar{X}^{A_{m}}} \alpha_{t-1}^{(m)}(\boldsymbol{x})\)
            end for
            \(y_{t} \leftarrow f\left(\boldsymbol{x}_{t}\right)+\epsilon_{t}, \epsilon_{t} \sim \mathcal{N}\left(0, \sigma^{2}\right)\)
            \(\mathfrak{D}_{t} \leftarrow D_{t-1} \cup\left\{\boldsymbol{x}_{t}, y_{t}\right\}\)
        end for
    end function
</code></pre></div>

<h2>5. Experiments</h2>
<p>In this section, we probe the empirical performance of MES and add-MES on a variety of tasks. Here, MES-G denotes MES with $y_{<em>}$ sampled from the approximate Gumbel distribution, and MES-R denotes MES with $y_{</em>}$ computed by maximizing a sampled function represented by random features. Following (Hennig \&amp; Schuler, 2012; HernándezLobato et al., 2014), we adopt the zero mean function and non-isotropic squared exponential kernel as the prior for the GP. We compare to methods from the entropy search family, i.e., ES and PES, and to other popular Bayesian optimization methods including GP-UCB (denoted by UCB), PI, EI and EST. The parameter for GP-UCB was set according to Theorem 2 in (Srinivas et al., 2010); the parameter for PI was set to be the observation noise $\sigma$. For the functions with unknown GP hyper-parameters, every 10 iterations, we learn the GP hyper-parameters using the same approach as was used by PES (Hernández-Lobato et al., 2014). For the high dimensional tasks, we follow (Kandasamy et al., 2015) and sample the additive structure/GP parameters with the highest data likelihood when they are unknown. We evaluate performance according to the simple regret and inference regret as defined in Section 2.3. We used the open source Matlab implementation of PES, ES and EST (Hennig \&amp; Schuler, 2012; Hernández-Lobato</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. (a) Inference regret; (b) simple regret. MES methods are much less sensitive to the number of maxima $y_{<em>}$ sampled for the acquisition function ( 1,10 or 100 ) than PES is to the number of argmaxes $x_{</em>}$.</p>
<p>Table 1. The runtime of selecting the next input. PES 100 is significantly slower than other methods. MES-G's runtime is comparable to the fastest method EI while it performs better in terms of simple and inference regrets.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Time (s)</th>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Time (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">UCB</td>
<td style="text-align: left;">$0.08 \pm 0.05$</td>
<td style="text-align: left;">PES 1</td>
<td style="text-align: left;">$0.20 \pm 0.06$</td>
</tr>
<tr>
<td style="text-align: left;">PI</td>
<td style="text-align: left;">$0.10 \pm 0.02$</td>
<td style="text-align: left;">MES-R 100</td>
<td style="text-align: left;">$5.85 \pm 0.86$</td>
</tr>
<tr>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">$0.07 \pm 0.03$</td>
<td style="text-align: left;">MES-R 10</td>
<td style="text-align: left;">$0.67 \pm 0.11$</td>
</tr>
<tr>
<td style="text-align: left;">EST</td>
<td style="text-align: left;">$0.15 \pm 0.02$</td>
<td style="text-align: left;">MES-R 1</td>
<td style="text-align: left;">$0.13 \pm 0.03$</td>
</tr>
<tr>
<td style="text-align: left;">ES</td>
<td style="text-align: left;">$8.07 \pm 3.02$</td>
<td style="text-align: left;">MES-G 100</td>
<td style="text-align: left;">$0.12 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;">PES 100</td>
<td style="text-align: left;">$15.24 \pm 4.44$</td>
<td style="text-align: left;">MES-G 10</td>
<td style="text-align: left;">$0.09 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;">PES 10</td>
<td style="text-align: left;">$1.61 \pm 0.50$</td>
<td style="text-align: left;">MES-G 1</td>
<td style="text-align: left;">$0.09 \pm 0.03$</td>
</tr>
</tbody>
</table>
<p>et al., 2014; Wang et al., 2016). Our Matlab code and test functions are available at https://github.com/ zi-w/Max-value-Entropy-Search/.</p>
<h3>5.1. Synthetic Functions</h3>
<p>We begin with a comparison on synthetic functions sampled from a 3-dimensional GP, to probe our conjecture that MES is much more robust to the number of $y_{<em>}$ sampled to estimate the acquisition function than PES is to the number of $x_{</em>}$ samples. For PES, we sample 100 (PES 100), 10 (PES 10) and 1 (PES 1) argmaxes for the acquisition function. Similarly, we sample 100, 10, $1 y_{*}$ values for MES-R and MES-G. We average the results on 100 functions sampled from the same Gaussian kernel with scale parameter 5.0 and bandwidth parameter 0.0625 , and observation noise $\mathcal{N}\left(0,0.01^{2}\right)$.</p>
<p>Figure 1 shows the simple and inference regrets. For both regret measures, PES is very sensitive to the the number of $x_{*}$ sampled for the acquisition function: 100 samples lead to much better results than 10 or 1 . In contrast, both MES-G and MES-R perform competitively even with 1 or 10 samples. Overall, MES-G is slightly better than MESR, and both MES methods performed better than other ES methods. MES methods performed better than all other methods with respect to simple regret. For inference regret, MES methods performed similarly to EST, and much better than all other methods including PES and ES.</p>
<p>In Table 1, we show the runtime of selecting the next input per iteration ${ }^{1}$ using GP-UCB, PI, EI, EST, ES, PES, MES-R and MES-G on the synthetic data with fixed GP hyper-parameters. For PES and MES-R, every $x_{<em>}$ or $y_{</em>}$ requires running an optimization sub-procedure, so their running time grows noticeably with the number of samples. MES-G avoids this optimization, and competes with the fastest methods EI and UCB.</p>
<p>In the following experiments, we set the number of $x_{<em>}$ sampled for PES to be 200, and the number of $y_{</em>}$ sampled for MES-R and MES-G to be 100 unless otherwise mentioned.</p>
<h3>5.2. Optimization Test Functions</h3>
<p>We test on three challenging optimization test functions: the 2-dimensional eggholder function, the 10-dimensional Shekel function and the 10-dimensional Michalewicz function. All of these functions have many local optima. We randomly sample 1000 points to learn a good GP hyperparameter setting, and then run the BO methods with the same hyper-parameters. The first observation is the same for all methods. We repeat the experiments 10 times. The averaged simple regret is shown in the appendix, and the inference regret is shown in Table 2. On the 2-d eggholder function, PES was able to achieve better function values faster than all other methods, which verified the good performance of PES when sufficiently many $x_{*}$ are sampled. However, for higher-dimensional test functions, the 10-d Shekel and 10-d Michalewicz function, MES methods performed much better than PES and ES, and MES-G performed better than all other methods.</p>
<h3>5.3. Tuning Hyper-parameters for Neural Networks</h3>
<p>Next, we experiment with Levenberg-Marquardt optimization for training a 1-hidden-layer neural network. The 4 parameters we tune with BO are the number of neurons, the damping factor $\mu$, the $\mu$-decrease factor, and the $\mu$-increase factor. We test regression on the Boston housing dataset</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 2. Inference regret $R_{T}$ for optimizing the eggholder function, Shekel function, and Michalewicz function.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Eggholder</th>
<th>Shekel</th>
<th>Michalewicz</th>
</tr>
</thead>
<tbody>
<tr>
<td>UCB</td>
<td>$141.00 \pm 70.96$</td>
<td>$9.40 \pm 0.26$</td>
<td>$6.07 \pm 0.53$</td>
</tr>
<tr>
<td>PI</td>
<td>$52.04 \pm 39.03$</td>
<td>$6.64 \pm 2.00$</td>
<td>$4.97 \pm 0.39$</td>
</tr>
<tr>
<td>EI</td>
<td>$71.18 \pm 59.18$</td>
<td>$6.63 \pm 0.87$</td>
<td>$4.80 \pm 0.60$</td>
</tr>
<tr>
<td>EST</td>
<td>$55.84 \pm 24.85$</td>
<td>$5.57 \pm 2.56$</td>
<td>$5.33 \pm 0.46$</td>
</tr>
<tr>
<td>ES</td>
<td>$48.85 \pm 29.11$</td>
<td>$6.43 \pm 2.73$</td>
<td>$5.11 \pm 0.73$</td>
</tr>
<tr>
<td>PES</td>
<td>$37.94 \pm 26.05$</td>
<td>$8.73 \pm 0.67$</td>
<td>$5.17 \pm 0.74$</td>
</tr>
<tr>
<td>MES-R</td>
<td>$54.47 \pm 37.71$</td>
<td>$6.17 \pm 1.80$</td>
<td>$4.97 \pm 0.59$</td>
</tr>
<tr>
<td>MES-G</td>
<td>$46.56 \pm 27.05$</td>
<td>$5.45 \pm 2.07$</td>
<td>$4.49 \pm 0.51$</td>
</tr>
</tbody>
</table>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Tuning hyper-parameters for training a neural network, (a) Boston housing dataset; (b) breast cancer dataset. MES methods perform better than other methods on (a), while for (b), MESG, UCB, PES perform similarly and better than others.
and classification on the breast cancer dataset (Bache \&amp; Lichman, 2013). The experiments are repeated 20 times, and the neural network's weight initialization and all other parameters are set to be the same to ensure a fair comparison. Both of the datasets were randomly split into train/validation/test sets. We initialize the observation set to have 10 random function evaluations which were set to be the same across all the methods. The averaged simple regret for the regression L2-loss on the validation set of the Boston housing dataset is shown in Fig. 2(a), and the classification accuracy on the validation set of the breast cancer dataset is shown in Fig. 2(b). For the classification problem on the breast cancer dataset, MES-G, PES and UCB achieved a similar simple regret. On the Boston housing dataset, MES methods achieved a lower simple regret. We also show the inference regrets for both datasets in Table 3.</p>
<h3>5.4. Active Learning for Robot Pushing</h3>
<p>We use BO to do active learning for the pre-image learning problem for pushing (Kaelbling \&amp; Lozano-Pérez, 2017). The function we optimize takes as input the pushing action of the robot, and outputs the distance of the pushed object to the goal location. We use BO to minimize the function in</p>
<p>Table 3. Inference regret $R_{T}$ for tuning neural network hyperparameters on the Boston housing and breast cancer datasets.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Boston</th>
<th style="text-align: left;">Cancer (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">UCB</td>
<td style="text-align: left;">$1.64 \pm 0.43$</td>
<td style="text-align: left;">$3.83 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">PI</td>
<td style="text-align: left;">$2.15 \pm 0.99$</td>
<td style="text-align: left;">$4.40 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">$1.99 \pm 1.03$</td>
<td style="text-align: left;">$4.40 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">EST</td>
<td style="text-align: left;">$1.65 \pm 0.57$</td>
<td style="text-align: left;">$3.93 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">ES</td>
<td style="text-align: left;">$1.79 \pm 0.61$</td>
<td style="text-align: left;">$4.14 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">PES</td>
<td style="text-align: left;">$1.52 \pm 0.32$</td>
<td style="text-align: left;">$3.84 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">MES-R</td>
<td style="text-align: left;">$1.54 \pm 0.56$</td>
<td style="text-align: left;">$3.96 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">MES-G</td>
<td style="text-align: left;">$1.51 \pm 0.61$</td>
<td style="text-align: left;">$3.83 \pm 0.01$</td>
</tr>
</tbody>
</table>
<p>Table 4. Inference regret $R_{T}$ for action selection in robot pushing.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">3-d ACTION</th>
<th style="text-align: left;">4-d ACTION</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">UCB</td>
<td style="text-align: left;">$1.10 \pm 0.66$</td>
<td style="text-align: left;">$0.56 \pm 0.44$</td>
</tr>
<tr>
<td style="text-align: left;">PI</td>
<td style="text-align: left;">$2.03 \pm 1.77$</td>
<td style="text-align: left;">$0.16 \pm 0.20$</td>
</tr>
<tr>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">$1.89 \pm 1.87$</td>
<td style="text-align: left;">$0.30 \pm 0.33$</td>
</tr>
<tr>
<td style="text-align: left;">EST</td>
<td style="text-align: left;">$0.70 \pm 0.90$</td>
<td style="text-align: left;">$0.24 \pm 0.17$</td>
</tr>
<tr>
<td style="text-align: left;">ES</td>
<td style="text-align: left;">$0.62 \pm 0.59$</td>
<td style="text-align: left;">$0.25 \pm 0.20$</td>
</tr>
<tr>
<td style="text-align: left;">PES</td>
<td style="text-align: left;">$0.81 \pm 1.27$</td>
<td style="text-align: left;">$0.38 \pm 0.38$</td>
</tr>
<tr>
<td style="text-align: left;">MES-R</td>
<td style="text-align: left;">$0.61 \pm 1.23$</td>
<td style="text-align: left;">$0.16 \pm 0.10$</td>
</tr>
<tr>
<td style="text-align: left;">MES-G</td>
<td style="text-align: left;">$0.61 \pm 1.26$</td>
<td style="text-align: left;">$0.24 \pm 0.25$</td>
</tr>
</tbody>
</table>
<p>order to find a good pre-image for pushing the object to the designated goal location. The first function we tested has a 3-dimensional input: robot location $\left(r_{x}, r_{y}\right)$ and pushing duration $t_{r}$. We initialize the observation size to be one, the same across all methods. The second function has a 4-dimensional input: robot location and angle $\left(r_{x}, r_{y}, r_{\theta}\right)$, and pushing duration $t_{r}$. We initialize the observation to be 50 random points and set them the same for all the methods. We select 20 random goal locations for each function to test if BO can learn where to push for these locations. We show the simple regret in Fig. 4 and the inference regret in Table 4. MES methods performed on a par with or better than their competitors.</p>
<h3>5.5. High Dimensional BO with Add-MES</h3>
<p>In this section, we test our add-MES algorithm on high dimensional black-box function optimization problems. First we compare add-MES and add-GP-UCB (Kandasamy et al., 2015) on a set of synthetic additive functions with known additive structure and GP hyper-parameters. Each function component of the synthetic additive function is active on at most three input dimensions, and is sampled from a GP with zero mean and Gaussian kernel (bandwidth $=0.1$ and scale $=5$ ). For the parameter of add-GP-UCB, we follow (Kandasamy et al., 2015) and set $\beta_{t}^{(m)}=\left|A_{m}\right| \log 2 t / 5$. We set the number of $y_{i}^{(m)}$ sampled for each function component in add-MES-R and add-MES-G to be 1. We repeat each experiment for 50 times</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Simple regrets for add-GP-UCB and add-MES methods on the synthetic add-GP functions. Both add-MES methods outperform add-GP-UCB except for add-MES-G on the input dimension $d=100$. Add-MES-G achieves the lowest simple regret when $d$ is relatively low, while for higher $d$ add-MES-R becomes better than add-MES-G.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. BO for active data selection on two robot pushing tasks for minimizing the distance to a random goal with (a) 3-D actions and (b) 4-D actions. MES methods perform better than other methods on the 3-D function. For the 4-D function, MES methods converge faster to a good regret, while PI achieves lower regret in the very end.</p>
<p>for each dimension setting. The results for simple regret are shown in Fig. 3. Add-MES methods perform much better than add-GP-UCB in terms of simple regret. Interestingly, add-MES-G works better in lower dimensional cases where $d = 10, 20, 30$, while add-MES-R outperforms both add-MES-G and add-GP-UCB for higher dimensions where $d = 50, 100$. In general, MES-G tends to overestimate the maximum of the function because of the independence assumption, and MES-R tends to underestimate the maximum of the function because of the imperfect global optimization of the posterior function samples. We conjecture that MES-R is better for settings where exploitation is preferred over exploration (e.g., not too many local optima), and MES-G works better if exploration is preferred.</p>
<p>To further verify the performance of add-MES in high dimensional problems, we test on two real-world high dimensional experiments. One is a function that returns the distance between a goal location and two objects being pushed by a robot which has 14 parameters<sup>2</sup>. The other function returns the walking speed of a planar bipedal robot, with 25 parameters to tune (Westervelt et al., 2007). In Fig. 5, we show the simple regrets achieved by add-GP-UCB and add-MES. Add-MES methods performed competitively compared to add-GP-UCB on both tasks.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Simple regrets for add-GP-UCB and add-MES methods on (a) a robot pushing task with 14 parameters and (b) a planar bipedal walker optimization task with 25 parameters. Both MES methods perform competitively comparing to add-GP-UCB.</p>
<h1>6. Conclusion</h1>
<p>We proposed a new information-theoretic approach, max-value entropy search (MES), for optimizing expensive black-box functions. MES is competitive with or better than previous entropy search methods, but at a much lower computational cost. Via additive GPs, MES is adaptable to high-dimensional settings. We theoretically connected MES to other popular Bayesian optimization methods including entropy search, GP-UCB, PI, and EST, and showed a bound on the simple regret for a variant of MES. Empirically, MES performs well on a variety of tasks.</p>
<p><sup>2</sup>We implemented the function in (Catto, 2011).</p>
<h2>Acknowledgements</h2>
<p>We thank Prof. Leslie Pack Kaelbling and Prof. Tomás Lozano-Pérez for discussions on active learning and Dr. William Huber for his solution to "Extreme Value Theory - Show: Normal to Gumbel" at stats. stackexchange. com, which leads to our Gumbel approximation in Section 3.1. We gratefully acknowledge support from NSF CAREER award 1553284, NSF grants 1420927 and 1523767, from ONR grant N00014-14-10486, and from ARO grant W911NF1410433. We thank MIT Supercloud and the Lincoln Laboratory Supercomputing Center for providing computational resources. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors.</p>
<h2>References</h2>
<p>Auer, Peter. Using confidence bounds for exploitation-exploration tradeoffs. Journal of Machine Learning Research, 3:397-422, 2002.</p>
<p>Bache, Kevin and Lichman, Moshe. UCI machine learning repository. 2013.</p>
<p>Brochu, Eric, Cora, Vlad M, and De Freitas, Nando. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. Technical Report TR-2009-023, University of British Columbia, 2009.</p>
<p>Calandra, Roberto, Seyfarth, André, Peters, Jan, and Deisenroth, Marc Peter. An experimental comparison of Bayesian optimization for bipedal locomotion. In International Conference on Robotics and Automation (ICRA), 2014.</p>
<p>Catto, Erin. Box2D, a 2D physics engine for games. http: //box2d.org, 2011.</p>
<p>Djolonga, Josip, Krause, Andreas, and Cevher, Volkan. Highdimensional Gaussian process bandits. In Advances in Neural Information Processing Systems (NIPS), 2013.</p>
<p>Duvenaud, David K, Nickisch, Hannes, and Rasmussen, Carl E. Additive Gaussian processes. In Advances in Neural Information Processing Systems (NIPS), 2011.</p>
<p>Fisher, Ronald Aylmer. The genetical theory of natural selection: a complete variorum edition. Oxford University Press, 1930.</p>
<p>Hennig, Philipp and Schuler, Christian J. Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 13:1809-1837, 2012.</p>
<p>Hernández-Lobato, José Miguel, Hoffman, Matthew W, and Ghahramani, Zoubin. Predictive entropy search for efficient global optimization of black-box functions. In Advances in Neural Information Processing Systems (NIPS), 2014.</p>
<p>Hoffman, Matthew W and Ghahramani, Zoubin. Output-space predictive entropy search for flexible global optimization. In NIPS workshop on Bayesian Optimization, 2015.</p>
<p>Kaelbling, Leslie Pack and Lozano-Pérez, Tomás. Learning composable models of primitive actions. In International Conference on Robotics and Automation (ICRA), 2017.</p>
<p>Kandasamy, Kirthevasan, Schneider, Jeff, and Poczos, Barnabas. High dimensional Bayesian optimisation and bandits via additive models. In International Conference on Machine Learning (ICML), 2015.</p>
<p>Kawaguchi, Kenji, Kaelbling, Leslie Pack, and Lozano-Pérez, Tomás. Bayesian optimization with exponential convergence. In Advances in Neural Information Processing Systems (NIPS), 2015.</p>
<p>Kawaguchi, Kenji, Maruyama, Yu, and Zheng, Xiaoyu. Global continuous optimization with error bound and fast convergence. Journal of Artificial Intelligence Research, 56(1):153195, 2016.</p>
<p>Krause, Andreas and Ong, Cheng S. Contextual Gaussian process bandit optimization. In Advances in Neural Information Processing Systems (NIPS), 2011.</p>
<p>Kushner, Harold J. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. Journal of Fluids Engineering, 86(1):97-106, 1964.</p>
<p>Li, Chun-Liang, Kandasamy, Kirthevasan, Póczos, Barnabás, and Schneider, Jeff. High dimensional Bayesian optimization via restricted projection pursuit models. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2016.</p>
<p>Lizotte, Daniel J, Wang, Tao, Bowling, Michael H, and Schuurmans, Dale. Automatic gait optimization with Gaussian process regression. In International Conference on Artificial Intelligence (IJCAI), 2007.</p>
<p>Massart, Pascal. Concentration Inequalities and Model Selection, volume 6. Springer, 2007.</p>
<p>Močkus, J. On Bayesian methods for seeking the extremum. In Optimization Techniques IFIP Technical Conference, 1974.</p>
<p>Neal, R.M. Bayesian Learning for Neural networks. Lecture Notes in Statistics 118. Springer, 1996.</p>
<p>Rahimi, Ali, Recht, Benjamin, et al. Random features for largescale kernel machines. In Advances in Neural Information Processing Systems (NIPS), 2007.</p>
<p>Rasmussen, Carl Edward and Williams, Christopher KI. Gaussian processes for machine learning. The MIT Press, 2006.</p>
<p>Rudin, Walter. Fourier analysis on groups. John Wiley \&amp; Sons, 2011.</p>
<p>Slepian, David. The one-sided barrier problem for Gaussian noise. Bell System Technical Journal, 41(2):463-501, 1962.</p>
<p>Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan P. Practical Bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems (NIPS), 2012.</p>
<p>Srinivas, Niranjan, Krause, Andreas, Kakade, Sham M, and Seeger, Matthias. Gaussian process optimization in the bandit setting: no regret and experimental design. In International Conference on Machine Learning (ICML), 2010.</p>
<p>Thornton, Chris, Hutter, Frank, Hoos, Holger H, and LeytonBrown, Kevin. Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2013.</p>
<p>Vanhatalo, Jarno, Riihimäki, Jaakko, Hartikainen, Jouni, Jylänki, Pasi, Tolvanen, Ville, and Vehtari, Aki. Gpstuff: Bayesian modeling with gaussian processes. Journal of Machine Learning Research, 14(Apr):1175-1179, 2013.</p>
<p>Von Mises, Richard. La distribution de la plus grande de n valeurs. Rev. math. Union interbalcanique, 1936.</p>
<p>Wang, Zi, Zhou, Bolei, and Jegelka, Stefanie. Optimization as estimation with Gaussian processes in bandit settings. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2016.</p>
<p>Wang, Zi, Jegelka, Stefanie, Kaelbling, Leslie Pack, and LozanoPérez, Tomás. Focused model-learning and planning for nonGaussian continuous state-action systems. In International Conference on Robotics and Automation (ICRA), 2017.</p>
<p>Wang, Ziyu, Zoghi, Masrour, Hutter, Frank, Matheson, David, and De Freitas, Nando. Bayesian optimization in high dimensions via random embeddings. In International Conference on Artificial Intelligence (IJCAI), 2013.</p>
<p>Westervelt, Eric R, Grizzle, Jessy W, Chevallereau, Christine, Choi, Jun Ho, and Morris, Benjamin. Feedback control of dynamic bipedal robot locomotion, volume 28. CRC press, 2007.</p>
<h2>A. Related work</h2>
<p>Our work is largely inspired by the entropy search (ES) methods (Hennig \&amp; Schuler, 2012; Hernández-Lobato et al., 2014), which established the information-theoretic view of Bayesian optimization by evaluating the inputs that are most informative to the $\arg \max$ of the function we are optimizing.</p>
<p>Our work is also closely related to probability of improvement (PI) (Kushner, 1964), expected improvement (EI) (Močkus, 1974), and the BO algorithms using upper confidence bound to direct the search (Auer, 2002; Kawaguchi et al., 2015; 2016), such as GP-UCB (Srinivas et al., 2010). In (Wang et al., 2016), it was pointed out that GP-UCB and PI are closely related by exchanging the parameters. Indeed, all these algorithms build in the heuristic that the next evaluation point needs to be likely to achieve the maximum function value or have high probability of improving the current evaluations, which in turn, may also give more information on the function optima like how ES methods queries. These connections become clear as stated in Section 3.1 of our paper.</p>
<p>Finding these points that may have good values in high dimensional space is, however, very challenging. In the
past, high dimensional BO algorithms were developed under various assumptions such as the existence of a lower dimensional function structure (Djolonga et al., 2013; Wang et al., 2013), or an additive function structure where each component is only active on a lower manifold of the space (Li et al., 2016; Kandasamy et al., 2015). In this work, we show that our method also works well in high dimensions with the additive assumption made in (Kandasamy et al., 2015).</p>
<h2>B. Using the Gumbel distribution to sample $y_{*}$</h2>
<p>To sample the function maximum $y_{<em>}$, our first approach is to approximate the distribution for $y^{</em>}$ and then sample from that distribution. We use independent Gaussians to approximate the correlated $f(\boldsymbol{x}), \forall \boldsymbol{x} \in \hat{\mathfrak{X}}$ where $\hat{\mathfrak{X}}$ is a discretization of the input search space $\mathfrak{X}$ (unless $\mathfrak{X}$ is discrete, in which case $\hat{\mathfrak{X}}=\mathfrak{X}$ ). A similar approach was adopted in (Wang et al., 2016). We can show that by assuming ${f(\boldsymbol{x})}_{\boldsymbol{x} \in \hat{\mathfrak{X}}}$, our approximated distribution gives a distribution for an upperbound on $f(\boldsymbol{x})$.
Lemma B. 1 (Slepian's Comparison Lemma (Slepian, 1962; Massart, 2007)). Let $\boldsymbol{u}, \boldsymbol{v} \in \mathbb{R}^{n}$ be two multivariate Gaussian random vectors with the same mean and variance, such that</p>
<p>$$
\mathbb{E}\left[\boldsymbol{v}<em j="j">{i} \boldsymbol{v}</em>}\right] \leq \mathbb{E}\left[\boldsymbol{u<em j="j">{i} \boldsymbol{u}</em>\right], \forall i, j
$$</p>
<p>Then for every $y$</p>
<p>$$
\operatorname{Pr}\left[\sup <em i="i">{i \in[1, n]} \boldsymbol{v}</em>\left[\sup } \leq y\right] \leq \operatorname{Pr<em i="i">{i \in[1, n]} \boldsymbol{u}</em> \leq y\right]
$$</p>
<p>By the Slepian's lemma, if the covariance $k_{t}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right) \geq$ $0, \forall \boldsymbol{x}, \boldsymbol{x}^{\prime} \in \hat{\mathfrak{X}}$, using the independent assumption with give us a distribution on the upperbound $\hat{y}<em _boldsymbol_x="\boldsymbol{x">{<em>}$ of $f(\boldsymbol{x}), \operatorname{Pr}\left[\hat{y}_{</em>}&lt;\right.$ $\left.y]=\prod</em>)\right)\right)$.
We then use the Gumbel distribution to approximate the distribution for the maximum of the function values for $\hat{\mathfrak{X}}$, $\operatorname{Pr}\left[\hat{y}} \in \hat{\mathfrak{X}}} \Psi\left(\gamma_{y}(\boldsymbol{x<em n="n">{*}<y\right]=\prod_{\boldsymbol{x} \in \hat{\mathfrak{X}}} \Psi\left(\gamma_{y}(\boldsymbol{x})\right)$ ). If for all $\boldsymbol{x} \in \hat{\mathfrak{X}}, f(\boldsymbol{x})$ have the same mean and variance, the Gumbel approximation is in fact asymptotically correct by the Fisher-TippettGnedenko theorem (Fisher, 1930).
Theorem B. 2 (The Fisher-Tippett-Gnedenko Theorem (Fisher, 1930)). Let $\left\{v_{i}\right\}_{i=1}^{\infty}$ be a sequence of independent and identically-distributed random variables, and $M_{n}=\max _{1 \leq i \leq n} v_{i}$. If there exist constants $a_{n}>0, b</em>$ and a non degenerate distribution function $F$ such that $\lim } \in \mathbb{R<em n="n">{n \rightarrow \infty} \operatorname{Pr}\left(\frac{M</em> \leq x\right)=F(x)$, then the limit distribution $F$ belongs to either the Gumbel, the Fréchet or the Weibull family.}-b_{n}}{a_{n}</p>
<p>In particular, for i.i.d. Gaussians, the limit distribution of the maximum of them belongs to the Gumbel distri-</p>
<p>bution (Von Mises, 1936). Though the Fisher-TippettGnedenko theorem does not hold for independent and differently distributed Gaussians, in practice we still find it useful in approximating $\operatorname{Pr}\left[\hat{y}<em t="t">{*}&lt;y\right]$. In Figure 6, we show an example of the result of the approximation for the distribution of the maximum of $f(\boldsymbol{x}) \sim G P\left(\mu</em>$ given 50 observed data points randomly selected from a function sample from a GP with 0 mean and Gaussian kernel.
}, k_{t}\right) \forall \boldsymbol{x} \in \hat{\mathfrak{X}<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6. An example of approximating the cumulative probability of the maximum of independent differently distributed Gaussians $\operatorname{Pr}\left[\hat{y}_{*}&lt;y\right]$ (Exact) with a Gumbel distribution $\mathcal{G}(a, b)$ (Approx) via percentile matching.</p>
<h2>C. Regret bounds</h2>
<p>Based on the connection of MES to EST, we show the bound on the learning regret for MES with a point estimate for $\alpha(x)$.
Theorem 3.2 (Simple Regret Bound). Let $F$ be the cumulative probability distribution for the maximum of any function $f$ sampled from $G P(\mu, k)$ over the compact search space $\mathfrak{X} \subset R^{d}$, where $k\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right) \leq 1, \forall \boldsymbol{x}, \boldsymbol{x}^{\prime} \in \mathfrak{X}$. Let $f_{<em>}=\max <em>{\boldsymbol{x} \in \mathfrak{X}} f(\boldsymbol{x})$ and $w=F\left(f</em>{</em>}\right) \in(0,1)$, and assume the observation noise is iid $\mathcal{N}(0, \sigma)$. If in each iteration $t$, the query point is chosen as $\boldsymbol{x}<em _boldsymbol_x="\boldsymbol{x">{t}=$ $\arg \max </em> \gamma_{y_{} \in \mathfrak{X}<em>}^{t}}(\boldsymbol{x}) \frac{\psi\left(\gamma_{y_{</em>}^{t}}(\boldsymbol{x})\right)}{2 \Psi\left(\gamma_{y_{<em>}^{t}}(\boldsymbol{x})\right)}-\log \left(\Psi\left(\gamma_{y_{</em>}^{t}}(\boldsymbol{x})\right)\right)$, where $\gamma_{y_{<em>}^{t}}(\boldsymbol{x})=\frac{y_{</em>}^{t}-\mu_{t}(\boldsymbol{x})}{\sigma_{t}(\boldsymbol{x})}$ and $y_{*}^{t}$ is drawn from $F$, then with probability at least $1-\delta$, in $T^{\prime}=\sum_{i=1}^{T} \log <em i="i">{w} \frac{\delta}{2 \pi</em>$ number of iterations, the simple regret satisfies}</p>
<p>$$
r_{T^{\prime}} \leq \sqrt{\frac{C \rho_{T}}{T}}\left(\nu_{t^{*}}+\zeta_{T}\right)
$$</p>
<p>where $C=2 / \log \left(1+\sigma^{-2}\right)$ and $\zeta_{T}=\left(2 \log \left(\frac{\pi_{T}}{2}\right)\right)^{\frac{1}{2}} ; \pi$ satisfies $\sum_{i=1}^{T} \pi_{t}^{-1} \leq 1$ and $\pi_{t}&gt;0$, and $t^{<em>}=\arg \max <em t="t">{t} \nu</em> \triangleq \min }$ with $\nu_{t<em>{\boldsymbol{x} \in \mathfrak{X}, y</em>{</em>}^{t}&gt;f_{<em>}} \gamma_{y_{</em>}^{t}}(\boldsymbol{x})$, and $\rho_{T}$ is the maximum information gain of at most $T$ selected points.</p>
<p>Before we continue to the proof, notice that if the function
upper bound $\hat{y}<em>{<em>}$ is sampled using the approach described in Section 3.1 and $k_{t}\left(\boldsymbol{x}, \boldsymbol{x}^{\prime}\right) \geq 0, \forall \boldsymbol{x}, \boldsymbol{x}^{\prime} \in \hat{\mathfrak{X}}$, we may still get the regret guarantee by setting $y_{</em>}=\hat{y}</em>{<em>}$ (or $y_{</em>}=\hat{y}<em _="*">{<em>}+\epsilon L$ if $\mathfrak{X}$ is continuous) since $\operatorname{Pr}\left[\max <em>{\hat{\mathfrak{X}}} \leq y\right] \geq \operatorname{Pr}\left[\hat{y}</em>{</em>}<y\right]$. Moreover, Theorem 3.2 assumes $y_{*}$ is sampled from a universal maximum distribution of functions from $G P(\mu, k)$, but it is not hard to see that if we have a distribution of maximums adapted from $G P\left(\mu_{t}, k_{t}\right)$, we can still get the same regret bound by setting $T^{\prime}=\sum_{i=1}^{T} \log _{w_{i}} \frac{\delta}{2 \pi_{i}}$, where $w_{i}=F_{i}\left(f_{*}\right)$ and $F_{i}$ corresponds to the maximum distribution at an iteration where $y_{*}>f</em>$. Next we introduce a few lemmas and then prove Theorem 3.2.
Lemma C. 1 (Lemma 3.2 in (Wang et al., 2016)). Pick $\delta \in(0,1)$ and set $\zeta_{t}=\left(2 \log \left(\frac{\pi_{t}}{2 \delta}\right)\right)^{\frac{1}{2}}$, where $\sum_{t=1}^{T} \pi_{t}^{-1} \leq$ $1, \pi_{t}&gt;0$. Then, it holds that $\operatorname{Pr}\left[\mu_{t-1}\left(\boldsymbol{x}<em t="t">{t}\right)-f\left(\boldsymbol{x}</em>}\right) \leq\right.$ $\left.\zeta_{t} \sigma_{t-1}\left(\boldsymbol{x<em t-1="t-1">{t}\right), \forall t \in[1, T]\right] \geq 1-\delta$.
Lemma C. 2 (Lemma 3.3 in (Wang et al., 2016)). If $\mu</em>}\left(\boldsymbol{x<em t="t">{t}\right)-f\left(\boldsymbol{x}</em>}\right) \leq \zeta_{t} \sigma_{t-1}\left(\boldsymbol{x<em t="t">{t}\right)$, the regret at time step $t$ is upper bounded as $\bar{r}</em>} \leq\left(\nu_{t}+\zeta_{t}\right) \sigma_{t-1}\left(\boldsymbol{x<em t="t">{t}\right)$, where $\nu</em> \triangleq \min <em t="t">{\boldsymbol{x} \in \mathfrak{X}} \frac{\bar{m}</em>}-\mu_{t-1}(\boldsymbol{x})}{\sigma_{t-1}(\boldsymbol{x})}$, and $\hat{m<em _boldsymbol_x="\boldsymbol{x">{t} \geq \max </em>)$, $\forall t \in[1, T]$.
Lemma C. 3 (Lemma 5.3 in (Srinivas et al., 2010)). The information gain for the points selected can be expressed in terms of the predictive variances. If $f_{T}=\left(f\left(\boldsymbol{x}_{t}\right)\right) \in \mathbb{R}^{T}$ :} \in \mathfrak{X}} f(\boldsymbol{x</p>
<p>$$
I\left(\boldsymbol{y}<em T="T">{T} ; \boldsymbol{f}</em>\right)\right)
$$}\right)=\frac{1}{2} \sum_{t=1}^{T} \log \left(1+\sigma^{-2} \sigma_{t-1}^{2}\left(\boldsymbol{x}_{t</p>
<p>Proof. (Theorem 3.2) By lemma 3.1 in our paper, we know that the theoretical results from EST (Wang et al., 2016) can be adapted to MES if $y_{<em>} \geq f_{</em>}$. The key question is when a sampled $y_{<em>}$ that can satisfy this condition. Because the cumulative density $w=F\left(f_{</em>}\right) \in(0,1)$ and $y_{<em>}^{t}$ are independent samples from $F$, there exists at least one $y_{</em>}^{t}$ that satisfies $y_{<em>}^{t}&gt;f_{</em>}$ with probability at least $1-w^{k_{i}}$ in $k_{i}$ iterations.
Let $T^{\prime}=\sum_{i=1}^{T} k_{i}$ be the total number of iterations. We split these iterations to $T$ parts where each part have $k_{i}$ iterations, $i=1, \cdots, T$. By union bound, with probability at least $1-\sum_{i=1}^{T} w^{k_{i}}$, in all the $T$ parts of iterations, we have at least one iteration $t_{i}$ which samples $y_{<em>}^{t_{i}}$ satisfying $y_{</em>}^{t_{i}}&gt;f_{<em>}, \forall i=1, \cdots, T$.
Let $\sum_{i=1}^{T} w^{k_{i}}=\frac{\delta}{2}$, we can set $k_{i}=\log <em i="i">{w} \frac{\delta}{2 \pi</em>$, there exist a sampled $y_{}}$ for any $\sum_{i=1}^{T}\left(\pi_{i}\right)^{-1}=1$. A convenient choice for $\pi_{i}$ is $\pi_{i}=\frac{\pi^{2} i^{2}}{6}$. Hence with probability at least $1-\frac{\delta}{2</em>}^{t_{i}}$ satisfying $y_{<em>}^{t_{i}}&gt;f_{</em>}, \forall i=1, \cdots, T$.
Now let $\zeta_{t_{i}}=\left(2 \log \frac{\pi_{t_{i}}}{2}\right)^{\frac{1}{2}}$. By Lemma C. 1 and Lemma C.2, the immediate regret $r_{t_{i}}=f_{*}-f\left(\boldsymbol{x}<em i="i">{t</em>\right)$ can be bounded as}</p>
<p>$$
r_{t_{i}} \leq\left(\nu_{t_{i}}+\zeta_{t_{i}}\right) \sigma_{t_{i}-1}\left(\boldsymbol{x}<em i="i">{t</em>\right)
$$}</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7. (a) 2-D eggholder function; (b) 10-D Shekel function; (c) 10-D Michalewicz function. PES achieves lower regret on the 2-d function while MES-G performed better than other methods on the two 10-d optimization test functions.</p>
<p>Note that by assumption $0 \leq \sigma_{t_{i}-1}^{2}\left(\boldsymbol{x}<em i="i">{t</em>}}\right) \leq 1$, so we have $\sigma_{t_{i}-1}^{2} \leq \frac{\log \left(1+\sigma^{-2} \sigma_{t_{i}-1}^{2}\left(\boldsymbol{x<em i="i">{t</em>}}\right)\right)}{\log \left(1+\sigma^{-2}\right)}$. Then by Lemma C.3, we have $\sum_{i=1}^{T} \sigma_{t_{i}-1}^{2}\left(\boldsymbol{x<em i="i">{t</em>}}\right) \leq \frac{2}{\log \left(1+\sigma^{-2}\right)} I\left(\boldsymbol{y<em T="T">{T} ; \boldsymbol{f}</em>}\right)$ where $\boldsymbol{f<em t__i="t_{i">{T}=\left(f\left(\boldsymbol{x}</em>\right)\right)}<em T="T">{i=1}^{T} \in \mathbb{R}^{T}, \boldsymbol{y}</em>\right)}=\left(y_{t_{i}<em T="T">{i=1}^{T} \in \mathbb{R}^{T}$. From assumptions, we have $I\left(\boldsymbol{y}</em>} ; \boldsymbol{f<em T="T">{T}\right) \leq \rho</em>}$. By Cauchy-Schwarz inequality, $\sum_{i=1}^{T} \sigma_{t_{i}-1}\left(\boldsymbol{x<em i="i">{t</em>}}\right) \leq \sqrt{T \sum_{i=1}^{T} \sigma_{t_{i}-1}^{2}\left(\boldsymbol{x<em i="i">{t</em>$. It follows that with probability at least $1-\delta$,}}\right)} \leq$ $\sqrt{\frac{2 T \rho_{T}}{\log \left(1+\sigma^{-2}\right)}</p>
<p>$$
\sum_{i=1}^{T} r_{t_{i}} \leq\left(\nu_{t^{*}}+\zeta_{T}\right) \sqrt{\frac{2 T \rho_{T}}{\log \left(1+\sigma^{-2}\right)}}
$$</p>
<p>As a result, our learning regret is bounded as</p>
<p>$$
r_{T^{\prime}} \leq \frac{1}{T} \sum_{i=1}^{T} r_{t_{i}} \leq\left(\nu_{t^{*}}+\zeta_{T}\right) \sqrt{\frac{2 \rho_{T}}{T \log \left(1+\sigma^{-2}\right)}}
$$</p>
<p>where $T^{\prime}=\sum_{i=1}^{T} k_{i}=\sum_{i=1}^{T} \log <em i="i">{w} \frac{\delta}{2 \pi</em>$ is the total number of iterations.}</p>
<p>At first sight, it might seem like MES with a point estimate does not have a converging rate as good as EST or $G P-U C B$. However, notice that $\min <em y__1="y_{1">{\boldsymbol{x} \in \mathfrak{X}} \gamma</em>$, which decides the rate of convergence in Eq. 7. So if we use $y_{}}(\boldsymbol{x})&lt;$ $\min \boldsymbol{x} \in \mathfrak{X} \gamma_{y_{2}}(\boldsymbol{x})$ if $y_{1}&lt;y_{2<em>}$ that is too large, the regret bound could be worse. If we use $y_{</em>}$ that is smaller than $f_{<em>}$, however, its value won't count towards the learning regret in our proof, so it is also bad for the regret upper bound. With no principled way of setting $y_{</em>}$ since $f_{<em>}$ is unknown. Our regret bound in Theorem 3.2 is a randomized trade-off between sampling large and small $y_{</em>}$.</p>
<p>For the regret bound in add-GP-MES, it should follow add-GP-UCB. However, because of some technical problems in the proofs of the regret bound for add-GP-UCB, we haven't been able to show a regret bound for add-GP-MES either. Nevertheless, from the experiments on high dimensional functions, the methods worked well in practice.</p>
<h2>D. Experiments</h2>
<p>In this section, we provide more details on our experiments.
Optimization test functions In Fig. 7, we show the simple regret comparing BO methods on the three challenging optimization test functions: the 2-D eggholder function, the 10-D Shekel function, and the 10-D Michalewicz function.</p>
<p>Choosing the additive decomposition We follow the approach in (Kandasamy et al., 2015), and sample 10000 random decompositions (at most 2 dimensions in each group) and pick the one with the best data likelihood based on 500 data points uniformly randomly sampled from the search space. The decomposition setting was fixed for all the 500 iterations of BO for a fair comparison.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ All the timing experiments were run exclusively on an Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz. The function evaluation time is excluded.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>