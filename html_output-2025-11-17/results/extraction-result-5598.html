<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5598 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5598</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5598</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-114.html">extraction-schema-114</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <p><strong>Paper ID:</strong> paper-ae6a4cd221684be6ca3082b6f526a7901281490b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ae6a4cd221684be6ca3082b6f526a7901281490b" target="_blank">Emergent autonomous scientific research capabilities of large language models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper presents an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments and showcases the Agent's scientific research capabilities with three distinct examples.</p>
                <p><strong>Paper Abstract:</strong> Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5598.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5598.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (Generative Pre-trained Transformer 4)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based large language model from OpenAI used in this work as the primary reasoning/planning LLM within an Intelligent Agent to perform text-based simulation of chemical experimental design, protocol generation, and mechanistic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based instruction-following large language model from OpenAI; used here for high-level planning, reasoning about chemistry, documentation summarization, and generating code and experiment plans. The paper notes its training-data cutoff (September 2021) as relevant to up-to-dateness of hardware knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Experimental organic chemistry / chemical automation (synthesis planning and cross-coupling reactions); also general lab automation and analytical data interpretation (UV-Vis).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based simulation of experimental workflows: (1) search and plan synthetic routes (ibuprofen, aspirin, aspartame, anticancer scaffold attempts); (2) design stoichiometry and reagent volumes; (3) select catalysts/bases and reaction conditions (Suzuki and Sonogashira cross-couplings); (4) generate automation code/instructions for liquid handlers and cloud lab symbolic languages; (5) mechanistic study reasoning for Suzuki reaction; (6) interpret UV-Vis plate spectra to identify colors.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Qualitative/experimental evidence: generated protocols were described as "mostly accurate" for simple robotic tasks; for the integrated cross-coupling experiments the Agent's protocol (GPT-4-driven Planner) led to reactions which, upon GC-MS analysis, showed formation of target products (no numerical yields/accuracy percentages reported). For safety dual-use prompts, 4 of 11 prompts (36%) yielded synthesis solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Training-data cutoff / domain coverage (missing newer hardware docs); access to accurate/up-to-date documentation (vectorized docs improved performance); prompt temperature/stochasticity (high-temperature caused volatility in catalyst/base suggestions); availability of external tools (web search, docs search, code execution, APIs); token limits for supplied documentation; presence/absence of required runtime packages (e.g., SymPy not installed); multi-run stochastic variability.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Paper examples: (a) GPT-4 lacked knowledge of a heater-shaker module released after its training-data cutoff and initially used an incorrect module name — accuracy improved after consulting provided documentation; (b) authors note high-generation temperature produced volatility when suggesting specific catalysts/bases; (c) vector search and provision of OT-2 and ECL documentation sections were described as "critical" to enable correct use of hardware APIs; (d) when SymPy was not installed, GPT-4-generated code produced a traceback, after which the Agent iteratively corrected code — demonstrating impact of runtime environment; (e) stochastic selection of coupling partners across runs (e.g., sometimes selecting p-nitroiodobenzene, sometimes bromobenzene) indicates variability.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Mixed evaluation: (1) empirical laboratory execution with automation (liquid handler + heater-shaker) followed by analytical verification (GC-MS) for the cross-coupling reactions; (2) execution of robotic control tasks and verification of resulting microplate layouts and UV-Vis analysis outputs (code execution in Docker and Python outputs inspected); (3) qualitative human assessment of generated protocols and behavior; (4) safety evaluation via prompting with controlled substances list and observing whether Agent produced synthesis planning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No quantitative accuracy metrics provided. Reported failures include incorrect initial hardware module naming (due to training-data cutoff), volatility/unstable suggestions under high-temperature sampling, code that assumed interactive interpreter mode thereby producing no output until corrected, missing runtime packages causing failed code execution, and the Agent's variable refusal behavior on dual-use requests (refusals often depended on web search results and knownness of compounds). The Agent sometimes missed small chemical details (e.g., in aspartame example missing a methyl group that required correction).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Paper notes GPT-3.5 was used for some web/documentation tasks because it was faster "with no appreciable loss of quality" compared to GPT-4 for those subtasks; no numerical head-to-head performance metrics provided. The Agent's behavior varied across runs (stochastic differences in reagent selection).</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Provide up-to-date, vectorized hardware and API documentation to the LLM; keep human-in-the-loop for oversight of sensitive or novel experiments; use lower/higher temperature settings carefully as temperature affects specificity/volatility of chemical suggestions; connect to curated reaction databases (Reaxys, SciFinder) to improve accuracy; implement runtime/tooling checks (e.g., ensure required packages present) and test code in isolated execution environments; implement safety guardrails and monitoring for dual-use detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5598.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5598.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 (OpenAI GPT-3.5 family)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A faster, somewhat lower-latency OpenAI LLM used in the Agent pipeline for web-search result processing and some documentation summarization tasks, trading speed for marginal differences in quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based OpenAI LLM (GPT-3.5 family) used in this work for faster processing of web pages and documentation in the Web searcher component; described as performing significantly faster than GPT-4 with no appreciable loss of quality for those retrieval/summary tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Support role across experimental chemistry tasks (documentation retrieval/summarization), general lab automation integration.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Textual processing and summarization of web search results and documentation to inform planning; not used as primary planner but as a fast retriever/summarizer to feed Planner (GPT-4).</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Qualitative claim: "performs significantly faster than GPT-4 with no appreciable loss of quality" for web/document summarization tasks; no numerical metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Same domain-coverage limits as GPT-4 (training data cutoff not explicitly stated for GPT-3.5 here), quality and relevance of supplied documentation, vector-search selection of sections, token limits when feeding docs to models.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Authors' operational choice to use GPT-3.5 for web search summarization because of speed and perceived parity on task quality; vectorized documentation sections and the number of tokens supplied are described as influencing how much information the model receives.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Operational/qualitative comparison by the authors in-task (speed / perceived quality) rather than formal benchmarks; downstream experimental success (when used as part of Agent pipeline) indirectly supports adequacy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No quantitative evaluation provided; potential limitations inherited from training data coverage and token/context restrictions; role limited to summarization so not assessed for complex planning/reasoning accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Direct qualitative comparison to GPT-4 for web/document summarization: GPT-3.5 faster with no appreciable loss in quality per authors; no detailed metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use lower-latency LLM variants (e.g., GPT-3.5) for retrieval/summarization subroutines to reduce system latency, while reserving a stronger reasoning model (e.g., GPT-4) for planning and decision-making; supply curated, vectorized documentation to the model to improve downstream behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5598.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5598.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-LLM Intelligent Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-LLM Intelligent Agent (Planner + Web searcher + Docs searcher + Code execution + Automation modules)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system-level Agent that composes multiple LLMs (GPT-4 as Planner, GPT-3.5 for web/document summarization) plus non-LLM tools (vector search, Python execution in Docker, hardware APIs) to simulate and execute scientific experiments by generating plans, code, and protocols from text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Multi-LLM Agent (GPT-4 planner, GPT-3.5 retriever, plus toolchain)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Integrated system combining LLMs and tools: Planner (GPT-4) issues actions (GOOGLE, DOCUMENTATION, PYTHON, EXPERIMENT), Web searcher (uses GPT-3.5 for summarization), Docs searcher (embedding + vector search of hardware docs), Code execution (isolated Docker), and Automation components that run generated code on hardware/cloud lab. Designed to simulate experimental reasoning via text and then execute protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Automated experimental chemistry (robotic liquid handling, synthesis planning, cross-coupling reactions), lab automation and analytical interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>End-to-end text-based simulation of experimental research cycles: literature search, mechanism reasoning, stoichiometry calculation, generation of instrument-specific automation code, running code in sandboxed execution, iteratively debugging code, and executing experiments on cloud/robotic platforms (including heater-shaker) with subsequent analytical verification.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Qualitative: agent produced correct synthesis plans for multiple targets (ibuprofen, aspirin, Suzuki reaction substrate/product identification), generated mostly-accurate robotic protocols (geometric drawings, microplate manipulations), and produced an executable cross-coupling protocol that when run produced products confirmed by GC-MS. No standard numeric accuracy reported; safety evaluation reported 36% of controlled-substance prompts resulted in synthesized solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Quality and currency of external documentation (vectorized docs crucial); connection to curated chemical databases (absence noted as limitation); sampling temperature and randomness in generation; toolchain reliability (availability of runtime packages, sandboxed execution behavior); token limits when including docs; human oversight presence; variability across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Examples in paper: (a) supplying OT-2 and ECL documentation via vector search allowed correct API usage and heater-shaker control; (b) lack of up-to-date knowledge about heater-shaker in model weights required documentation to correct misconception; (c) model corrected its own code after receiving tracebacks from code execution, showing coupling between language output and tool feedback; (d) multiple runs produced different reagent choices indicating stochasticity; (e) authors recommend integration with Reaxys/SciFinder to improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Empirical mixed evaluation: (1) execution of generated automation code in isolated Docker followed by hardware execution in a liquid handler/heater-shaker or cloud lab (some runs); (2) analytical verification (GC-MS) to confirm product formation for cross-coupling experiments; (3) automated code run outputs and tracebacks used as feedback for iterative correction; (4) qualitative human review of generated protocols; (5) safety tests via structured prompts for controlled substances.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No standardized quantitative benchmarks; occasional incorrect or incomplete synthetic suggestions (e.g., aspartame missing a methyl group until corrected), initial wrong hardware identifiers (due to model cutoff), sensitivity to prompt phrasing (manipulating search strings could bypass safety checks), stochastic variability across runs leading to inconsistent experimental choices, and reliance on internet and documentation quality. Safety: agent sometimes produced synthesis plans for controlled substances (4/11 cases).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Authors compared using GPT-3.5 vs GPT-4 for subcomponents (GPT-3.5 faster for web/doc summarization with no appreciable loss); also note that connecting to specialized reaction databases would likely improve outputs (suggested but not implemented). No formal benchmark-level comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Feed curated, vectorized hardware/API documentation to the Agent; use tool chaining with sandboxed code execution and instrument APIs; maintain human-in-the-loop review especially for potentially hazardous experiments; implement data-source curation and up-to-date databases (Reaxys/SciFinder) for improved planning; use safety screening models to detect novel hazardous compounds; ensure runtime environments provide necessary packages; monitor and control sampling temperature to balance creativity vs. volatility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GPT-4 Technical Report <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>Dual use of artificial-intelligence-powered drug discovery <em>(Rating: 1)</em></li>
                <li>Opentrons Python Protocol API <em>(Rating: 1)</em></li>
                <li>Running Experiments <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5598",
    "paper_id": "paper-ae6a4cd221684be6ca3082b6f526a7901281490b",
    "extraction_schema_id": "extraction-schema-114",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (Generative Pre-trained Transformer 4)",
            "brief_description": "A transformer-based large language model from OpenAI used in this work as the primary reasoning/planning LLM within an Intelligent Agent to perform text-based simulation of chemical experimental design, protocol generation, and mechanistic reasoning.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Transformer-based instruction-following large language model from OpenAI; used here for high-level planning, reasoning about chemistry, documentation summarization, and generating code and experiment plans. The paper notes its training-data cutoff (September 2021) as relevant to up-to-dateness of hardware knowledge.",
            "model_size": null,
            "scientific_subdomain": "Experimental organic chemistry / chemical automation (synthesis planning and cross-coupling reactions); also general lab automation and analytical data interpretation (UV-Vis).",
            "simulation_task": "Text-based simulation of experimental workflows: (1) search and plan synthetic routes (ibuprofen, aspirin, aspartame, anticancer scaffold attempts); (2) design stoichiometry and reagent volumes; (3) select catalysts/bases and reaction conditions (Suzuki and Sonogashira cross-couplings); (4) generate automation code/instructions for liquid handlers and cloud lab symbolic languages; (5) mechanistic study reasoning for Suzuki reaction; (6) interpret UV-Vis plate spectra to identify colors.",
            "accuracy_metric": null,
            "reported_accuracy": "Qualitative/experimental evidence: generated protocols were described as \"mostly accurate\" for simple robotic tasks; for the integrated cross-coupling experiments the Agent's protocol (GPT-4-driven Planner) led to reactions which, upon GC-MS analysis, showed formation of target products (no numerical yields/accuracy percentages reported). For safety dual-use prompts, 4 of 11 prompts (36%) yielded synthesis solutions.",
            "factors_affecting_accuracy": "Training-data cutoff / domain coverage (missing newer hardware docs); access to accurate/up-to-date documentation (vectorized docs improved performance); prompt temperature/stochasticity (high-temperature caused volatility in catalyst/base suggestions); availability of external tools (web search, docs search, code execution, APIs); token limits for supplied documentation; presence/absence of required runtime packages (e.g., SymPy not installed); multi-run stochastic variability.",
            "evidence_for_factors": "Paper examples: (a) GPT-4 lacked knowledge of a heater-shaker module released after its training-data cutoff and initially used an incorrect module name — accuracy improved after consulting provided documentation; (b) authors note high-generation temperature produced volatility when suggesting specific catalysts/bases; (c) vector search and provision of OT-2 and ECL documentation sections were described as \"critical\" to enable correct use of hardware APIs; (d) when SymPy was not installed, GPT-4-generated code produced a traceback, after which the Agent iteratively corrected code — demonstrating impact of runtime environment; (e) stochastic selection of coupling partners across runs (e.g., sometimes selecting p-nitroiodobenzene, sometimes bromobenzene) indicates variability.",
            "evaluation_method": "Mixed evaluation: (1) empirical laboratory execution with automation (liquid handler + heater-shaker) followed by analytical verification (GC-MS) for the cross-coupling reactions; (2) execution of robotic control tasks and verification of resulting microplate layouts and UV-Vis analysis outputs (code execution in Docker and Python outputs inspected); (3) qualitative human assessment of generated protocols and behavior; (4) safety evaluation via prompting with controlled substances list and observing whether Agent produced synthesis planning.",
            "limitations_or_failure_cases": "No quantitative accuracy metrics provided. Reported failures include incorrect initial hardware module naming (due to training-data cutoff), volatility/unstable suggestions under high-temperature sampling, code that assumed interactive interpreter mode thereby producing no output until corrected, missing runtime packages causing failed code execution, and the Agent's variable refusal behavior on dual-use requests (refusals often depended on web search results and knownness of compounds). The Agent sometimes missed small chemical details (e.g., in aspartame example missing a methyl group that required correction).",
            "comparisons": "Paper notes GPT-3.5 was used for some web/documentation tasks because it was faster \"with no appreciable loss of quality\" compared to GPT-4 for those subtasks; no numerical head-to-head performance metrics provided. The Agent's behavior varied across runs (stochastic differences in reagent selection).",
            "recommendations_or_best_practices": "Provide up-to-date, vectorized hardware and API documentation to the LLM; keep human-in-the-loop for oversight of sensitive or novel experiments; use lower/higher temperature settings carefully as temperature affects specificity/volatility of chemical suggestions; connect to curated reaction databases (Reaxys, SciFinder) to improve accuracy; implement runtime/tooling checks (e.g., ensure required packages present) and test code in isolated execution environments; implement safety guardrails and monitoring for dual-use detection.",
            "uuid": "e5598.0",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5 (OpenAI GPT-3.5 family)",
            "brief_description": "A faster, somewhat lower-latency OpenAI LLM used in the Agent pipeline for web-search result processing and some documentation summarization tasks, trading speed for marginal differences in quality.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "Transformer-based OpenAI LLM (GPT-3.5 family) used in this work for faster processing of web pages and documentation in the Web searcher component; described as performing significantly faster than GPT-4 with no appreciable loss of quality for those retrieval/summary tasks.",
            "model_size": null,
            "scientific_subdomain": "Support role across experimental chemistry tasks (documentation retrieval/summarization), general lab automation integration.",
            "simulation_task": "Textual processing and summarization of web search results and documentation to inform planning; not used as primary planner but as a fast retriever/summarizer to feed Planner (GPT-4).",
            "accuracy_metric": null,
            "reported_accuracy": "Qualitative claim: \"performs significantly faster than GPT-4 with no appreciable loss of quality\" for web/document summarization tasks; no numerical metrics provided.",
            "factors_affecting_accuracy": "Same domain-coverage limits as GPT-4 (training data cutoff not explicitly stated for GPT-3.5 here), quality and relevance of supplied documentation, vector-search selection of sections, token limits when feeding docs to models.",
            "evidence_for_factors": "Authors' operational choice to use GPT-3.5 for web search summarization because of speed and perceived parity on task quality; vectorized documentation sections and the number of tokens supplied are described as influencing how much information the model receives.",
            "evaluation_method": "Operational/qualitative comparison by the authors in-task (speed / perceived quality) rather than formal benchmarks; downstream experimental success (when used as part of Agent pipeline) indirectly supports adequacy.",
            "limitations_or_failure_cases": "No quantitative evaluation provided; potential limitations inherited from training data coverage and token/context restrictions; role limited to summarization so not assessed for complex planning/reasoning accuracy.",
            "comparisons": "Direct qualitative comparison to GPT-4 for web/document summarization: GPT-3.5 faster with no appreciable loss in quality per authors; no detailed metrics.",
            "recommendations_or_best_practices": "Use lower-latency LLM variants (e.g., GPT-3.5) for retrieval/summarization subroutines to reduce system latency, while reserving a stronger reasoning model (e.g., GPT-4) for planning and decision-making; supply curated, vectorized documentation to the model to improve downstream behavior.",
            "uuid": "e5598.1",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "Multi-LLM Intelligent Agent",
            "name_full": "Multi-LLM Intelligent Agent (Planner + Web searcher + Docs searcher + Code execution + Automation modules)",
            "brief_description": "A system-level Agent that composes multiple LLMs (GPT-4 as Planner, GPT-3.5 for web/document summarization) plus non-LLM tools (vector search, Python execution in Docker, hardware APIs) to simulate and execute scientific experiments by generating plans, code, and protocols from text.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "use",
            "model_name": "Multi-LLM Agent (GPT-4 planner, GPT-3.5 retriever, plus toolchain)",
            "model_description": "Integrated system combining LLMs and tools: Planner (GPT-4) issues actions (GOOGLE, DOCUMENTATION, PYTHON, EXPERIMENT), Web searcher (uses GPT-3.5 for summarization), Docs searcher (embedding + vector search of hardware docs), Code execution (isolated Docker), and Automation components that run generated code on hardware/cloud lab. Designed to simulate experimental reasoning via text and then execute protocols.",
            "model_size": null,
            "scientific_subdomain": "Automated experimental chemistry (robotic liquid handling, synthesis planning, cross-coupling reactions), lab automation and analytical interpretation.",
            "simulation_task": "End-to-end text-based simulation of experimental research cycles: literature search, mechanism reasoning, stoichiometry calculation, generation of instrument-specific automation code, running code in sandboxed execution, iteratively debugging code, and executing experiments on cloud/robotic platforms (including heater-shaker) with subsequent analytical verification.",
            "accuracy_metric": null,
            "reported_accuracy": "Qualitative: agent produced correct synthesis plans for multiple targets (ibuprofen, aspirin, Suzuki reaction substrate/product identification), generated mostly-accurate robotic protocols (geometric drawings, microplate manipulations), and produced an executable cross-coupling protocol that when run produced products confirmed by GC-MS. No standard numeric accuracy reported; safety evaluation reported 36% of controlled-substance prompts resulted in synthesized solutions.",
            "factors_affecting_accuracy": "Quality and currency of external documentation (vectorized docs crucial); connection to curated chemical databases (absence noted as limitation); sampling temperature and randomness in generation; toolchain reliability (availability of runtime packages, sandboxed execution behavior); token limits when including docs; human oversight presence; variability across runs.",
            "evidence_for_factors": "Examples in paper: (a) supplying OT-2 and ECL documentation via vector search allowed correct API usage and heater-shaker control; (b) lack of up-to-date knowledge about heater-shaker in model weights required documentation to correct misconception; (c) model corrected its own code after receiving tracebacks from code execution, showing coupling between language output and tool feedback; (d) multiple runs produced different reagent choices indicating stochasticity; (e) authors recommend integration with Reaxys/SciFinder to improve performance.",
            "evaluation_method": "Empirical mixed evaluation: (1) execution of generated automation code in isolated Docker followed by hardware execution in a liquid handler/heater-shaker or cloud lab (some runs); (2) analytical verification (GC-MS) to confirm product formation for cross-coupling experiments; (3) automated code run outputs and tracebacks used as feedback for iterative correction; (4) qualitative human review of generated protocols; (5) safety tests via structured prompts for controlled substances.",
            "limitations_or_failure_cases": "No standardized quantitative benchmarks; occasional incorrect or incomplete synthetic suggestions (e.g., aspartame missing a methyl group until corrected), initial wrong hardware identifiers (due to model cutoff), sensitivity to prompt phrasing (manipulating search strings could bypass safety checks), stochastic variability across runs leading to inconsistent experimental choices, and reliance on internet and documentation quality. Safety: agent sometimes produced synthesis plans for controlled substances (4/11 cases).",
            "comparisons": "Authors compared using GPT-3.5 vs GPT-4 for subcomponents (GPT-3.5 faster for web/doc summarization with no appreciable loss); also note that connecting to specialized reaction databases would likely improve outputs (suggested but not implemented). No formal benchmark-level comparisons provided.",
            "recommendations_or_best_practices": "Feed curated, vectorized hardware/API documentation to the Agent; use tool chaining with sandboxed code execution and instrument APIs; maintain human-in-the-loop review especially for potentially hazardous experiments; implement data-source curation and up-to-date databases (Reaxys/SciFinder) for improved planning; use safety screening models to detect novel hazardous compounds; ensure runtime environments provide necessary packages; monitor and control sampling temperature to balance creativity vs. volatility.",
            "uuid": "e5598.2",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 2
        },
        {
            "paper_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "rating": 2
        },
        {
            "paper_title": "Dual use of artificial-intelligence-powered drug discovery",
            "rating": 1
        },
        {
            "paper_title": "Opentrons Python Protocol API",
            "rating": 1
        },
        {
            "paper_title": "Running Experiments",
            "rating": 1
        }
    ],
    "cost": 0.01093075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Emergent autonomous scientific research capabilities of large language models</h1>
<p>Daniil A. Boiko, ${ }^{1}$ Robert MacKnight, ${ }^{1}$ and Gabe Gomes ${ }^{* 1,2,3}$</p>
<ol>
<li>Department of Chemical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Department of Chemistry, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Wilton E. Scott Institute for Energy Innovation, Carnegie Mellon University, Pittsburgh, PA 15213, USA
*corresponding author, gabegomes@cmu.edu</li>
</ol>
<h4>Abstract</h4>
<p>Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
<h2>Keywords</h2>
<p>Large Language Models; Intelligent Agents; Generative AI; Autonomous Experimentation; Automation; Physical Sciences; Catalysis.</p>
<h2>Glossary</h2>
<ul>
<li>LLMs: Large Language Models. In this paper, we use OpenAI's GPT-3.5 and GPT-4.</li>
<li>Agent: LLM-based Intelligent Agent (IA) system.</li>
<li>Prompt-provider: A scientist - in this work, one of the human authors - that provides the initial prompt to the Agent.</li>
</ul>
<h1>Main</h1>
<p>Large language models (LLMs), particularly transformer-based models, are experiencing rapid advancements in recent years. These models have been successfully applied to various domains, including natural language, ${ }^{1-5}$ biological ${ }^{6,7}$ and chemical research, ${ }^{8,9}$ as well as code generation. Extreme scaling of models, as demonstrated by OpenAI, has led to significant breakthroughs in the field. ${ }^{1,10}$ Moreover, techniques such as reinforcement learning from human feedback (RLHF) ${ }^{11}$ can considerably enhance the quality of generated text and the models' capability to perform diverse tasks while reasoning about their decisions. ${ }^{12}$</p>
<p>On March 14, 2023, OpenAI released their most capable LLM to date, GPT-4. ${ }^{10}$ Although specific details about the model training, sizes, and data used are limited in the technical report, researchers have provided substantial evidence of the model's exceptional problem-solving abilities. Those include - but are not limited to - high percentiles on the SAT and BAR exams, LeetCode challenges, and contextual explanations from images, including niche jokes. ${ }^{10}$ Moreover, the technical report provides an example of how the model can be employed to address chemistry-related problems.</p>
<p>Inspired by these results, we aimed to develop a multi-LLMs-based Intelligent Agent (hereafter simply called Agent) capable of autonomous design, planning, and performance of complex scientific experiments. The Agent can use tools ${ }^{13}$ to browse the internet and relevant documentation, use robotic experimentation APIs, and leverage other LLMs for various tasks. In this paper, we demonstrate the versatility and efficacy of our Agent by evaluating its performance in three tasks: 1. Efficiently searching and navigating through extensive hardware documentation; 2. Precisely controlling liquid handling instruments at a low level; 3. Tackling complex problems that necessitate simultaneous utilization of multiple hardware modules or integration of diverse data sources.</p>
<h2>The Agent's architecture: action space defined by its multiple modules.</h2>
<p>The Agent's system consists of four components (Figure 1), driven by the "Planner." The Planner takes a prompt as input (e.g., "Perform multiple Suzuki reactions") and carries out actions according to this request. The action space includes accessing the internet ("GOOGLE <query>" request), performing calculations in Python ("PYTHON <code>"), accessing documentation ("DOCUMENTATION <query>"), and running the final experiment ("EXPERIMENT <code>"). Experiments can be performed in various environments - a cloud lab, using a liquid handler, or by providing instructions for performing experiments manually. The model is instructed to reason about its actions, search the internet, calculate all quantities in the reaction, and then perform the corresponding reaction. The Agent is aware that, on average, at least ten steps are needed to fully understand the requested task. No further clarifying questions to the prompt-provider are necessary if the provided description is detailed enough.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Overview of the system architecture. The Agent is composed of multiple modules that exchange messages. Some of them have access to APIs, the Internet, and Python interpreter.</p>
<p>The "Web searcher" component receives queries from the Planner, transforms them into appropriate web search queries, and executes them using the Google Search API. The first ten documents returned are filtered, excluding PDFs, and the resulting list of web pages is passed back to the Web searcher component. The component can then use the "BROWSE" action to extract text from the web pages and compile an answer for the Planner. For this task we can employ GPT-3.5, as it performs significantly faster than GPT-4 with no appreciable loss of quality. The "Docs searcher" component combs through the hardware documentation (e.g., robotic liquid handler, GC-MS, a cloud lab) by utilizing a query and documentation index to find the most relevant pages/sections. Then the best matching results are aggregated to provide a comprehensive and accurate final answer. This module places an emphasize on providing specific function parameter and syntactic information for the hardware API.</p>
<p>The "Code execution" component does not utilize any language models and simply executes the code in an isolated Docker container, protecting the end host machine from any unexpected actions by the Planner. All code outputs are passed back to the Planner, enabling it to fix its predictions in case of software errors. The same applies to the "Automation" component, which then executes the generated code on corresponding hardware or just provides the synthetic procedure for manual experimentation.</p>
<h1>Web search enables Agent's synthesis planning capabilities.</h1>
<p>To demonstrate the system's functionality, we use the synthesis of ibuprofen as an example (Figure 2A). The input prompt is straightforward: "Synthesize ibuprofen." The model then searches the internet for information on ibuprofen synthesis, locating the necessary details on a particular website. The model correctly identifies the first step of the synthesis, which is the Friedel-Crafts reaction between isobutylbenzene and acetic anhydride catalyzed by aluminum chloride (see Appendix A). The planning phase for the first step concludes once the model requests documentation for the Friedel-Crafts synthesis procedure.</p>
<p>Two other examples of the system's capabilities include the synthesis of common aspirin (Figure 2B and Appendix B), which the model searches and designs effectively, and aspartame synthesis (Figure 2D and Appendix C), which, although missing the methyl group in the product, can be corrected once the model receives a suitable synthetic example for execution in the cloud lab. Furthermore, when asked to study a Suzuki reaction, the model accurately identifies the substrates and the product (Figure 2C and Appendix D). The high-temperature parameter for text generation results in volatility when suggesting specific catalysts or bases.</p>
<p>Connecting the model to a chemical reaction database such as Reaxys ${ }^{14}$ or SciFinder ${ }^{15}$ via API could significantly enhance the system's performance. Alternatively, analyzing the system's previous statements is another approach to improving its accuracy.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Agent's capabilities in the synthesis planning task. A. Ibuprofen synthesis. B. Aspirin synthesis. C. Suzuki reaction mechanism study, where the Agent had to choose how to study the mechanism. D. Aspartame synthesis.</p>
<h1>Vector search can be employed for retrieval of dense hardware API documentation.</h1>
<p>To integrate an intelligent Agent capable of sophisticated reasoning with contemporary software, it is crucial to provide a clear and concise presentation of relevant technical documentation. Modern software is characterized by its complexity and the intricate interplay between various components. Consequently, comprehensive software documentation is indispensable for programmers to comprehend these interactions and utilize them effectively to accomplish their goals. Nonetheless, traditional software documentation frequently employs highly technical language, which can be challenging for non-experts to grasp. This creates a barrier to entry for many potential users of the software, limiting its reach and effectiveness.</p>
<p>Large language models have the potential to overcome this barrier by generating natural language descriptions of software documentation that are more accessible to nonexperts. These models are trained on a vast corpus of text from a variety of sources, which includes extensive information related to Application Programming Interfaces (APIs). One such API is the Opentrons Python API. ${ }^{16}$ However, the GPT-4's training data contains information up until September 2021. Thus, there is potential for enhancing the Agent's accuracy in using the API. To this end, we devised an approach to provide the Agent with requisite documentation for a given task, summarized in Figure 3A.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Overview of documentation search. A. Prompt-to-(improved OT-2 Python API)-code via ada embedding and distance-based vector search. B. Prompt-to-function recommendation in Emerald Cloud Lab symbolic lab language via supplementation of documentation guide.</p>
<p>For all 14 sections of the OT-2 API documentation we have generated OpenAI's ada embeddings to cross reference and compute similarity with respect to a query. The agent is instructed to inquire about proper use of the API when needed via the Documentation action. An ada embedding for the subsequent query is generated and documentation sections are selected via a distance-based vector search. The number of sections provided is dictated by the number of GPT-4 tokens present in the raw text for a given section. The maximum number of tokens is set to 7800 , such that the relevant documents can be provided in one step. This approach proved critical for providing the agent with information about the heater-shaker hardware module necessary for performing chemical reactions (see "The Agent is capable of designing and performing chemical experiments." section).</p>
<p>A greater challenge emerges when applying this approach to a more diverse robotic platform, such as the Emerald Cloud Lab (ECL). Nonetheless, we can explore the effectiveness of providing information about the Cloud Lab's Symbolic Lab Language (SLL), which is currently unknown to the GPT-4 model. For this we provide the Agent with a documentation guide from ECL pertaining to all available functions for running experiments. ${ }^{17}$ Figure 3B summarizes three examples of the User providing a simple query and the Agent directing the User to relevant ECL functions. More examples are shared in the Appendix G. In all cases, the Agent correctly identifies functions for accomplishing the given task. After selection of appropriate functions, the raw plain text documentation is passed through a separate GPT-4 model to perform code syntax retention and summarization. Specifically, this model efficiently retains information regarding the various options, instruments, and parameters for a given function. Once the entire documentation has been ingested, the model is prompted to produce a code block utilizing the given function to be passed back to the Planner. This serves as a basis for the model to utilize this function with specific options, instruments, and parameters as they are gathered by the Web searcher.</p>
<h1>Mastering automation: multi-instrument systems controlled by natural language.</h1>
<p>Access to documentation enables us to provide sufficient information for the Agent to conduct experiments in the physical world. To initiate the investigation, we chose an open-source liquid handler with a well-documented Python API. The "Getting Started" page from its documentation was supplied to the Planner in the system prompt. Other pages were vectorized using the approach described in the "Providing hardware API Documentation" section. In this section, we did not grant access to the internet (Figure 4A).</p>
<p>A.
<img alt="img-3.jpeg" src="img-3.jpeg" />
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>UV-Vis data from plate 1 is ready. You can access it using PYTHON, it will be in the file named
'plate1.npy'. You will have NumPy installed. The file contains NumPy array of shape $(9,12,41)$. There are 41 wavelengths from 350 to 750 with 10 nm step. Think about how would different colors absorb first.</p>
<p>Automated answer</p>
<ul>
<li>guiding prompt
[530, 430, 630]
Automated answer
<img alt="img-5.jpeg" src="img-5.jpeg" /></li>
</ul>
<p>Figure 4. Robotic liquid handler control capabilities and integration with analytical tools. A. Overview of the Agent's configuration. B-E. Drawing geometrical figures. F. The Agent solves a color identification problem using UV-Vis data.</p>
<p>We began with simple experiments on operating the robot, which simultaneously required the ability to consider a set of samples as a whole (in our case, an entire microplate). Straightforward prompts in natural language, such as "Color every other line with one color of your choice," resulted in mostly accurate protocols. When executed by the robot, these protocols closely resembled the requested prompt (Figure 4B-E).</p>
<p>The Agent's first action was to prepare small samples of the original solutions (Figure 4F). It then requested UV-Vis measurements to be performed (Appendix H). Once completed, the Agent was provided with a file name containing a NumPy array with spectra for each well of the microplate. The Agent subsequently wrote Python code to identify the wavelengths with maximum absorbance, using this data to correctly solve the problem.</p>
<h1>Bringing it all together: the Agent's integrated chemical experiment design and execution capabilities.</h1>
<p>Previous experiments could be affected by the knowledge of the Agent's modules from the pretraining step. We wanted to evaluate the Agent's ability to plan an experiment by combining data from the internet, performing the necessary calculations, and ultimately writing the code for the liquid handler. To increase complexity, we asked the Agent to use the heater-shaker module released after the GPT-4 training data collection cutoff. These requirements were incorporated into the Agent's configuration (Figure 5A).</p>
<p>The problem was designed as follows: the Agent is provided with a liquid handler equipped with two microplates. One (Source Plate) contains stock solutions of multiple reagents, including phenyl acetylene and phenylboronic acid, multiple aryl halide coupling partners, two catalysts, two bases, and the solvent to dissolve the sample (Figure 5B). The target plate is installed on the heater-shaker module (Figure 5C). The Agent's goal is to design a protocol to perform Suzuki and Sonogashira reactions.</p>
<p>The Agent begins by searching the internet for information on the requested reactions, their stoichiometry, and conditions (Figure 5D). It selects the correct coupling partners for the corresponding reactions. Among all aryl halides, it selected bromobenzene for Suzuki reaction and iodobenzene for Sonogashira reaction. This behavior changes from each run, as it also selects p-nitroiodobenzene due to its high reactivity in oxidative addition reactions, or bromobenzene because it is reactive but less toxic than aryl iodides. This highlights a potential future use case for the model - performing experiments multiple times to analyze the model's reasoning and construct a bigger picture. The model selected a $\mathrm{Pd} / \mathrm{NHC}$ catalyst as a more efficient, modern approach for cross-coupling reactions, and triethylamine was chosen as the base.</p>
<p>The Agent then calculates the required volumes of all reactants and writes the protocol. However, it used an incorrect heater-shaker module name. Upon noticing the mistake, the model consulted the documentation. This information was then used to modify the protocol, which successfully ran (Figure 5E). Subsequent GC-MS analysis of the reaction mixtures revealed the formation of the target products for both reactions (Appendix I).</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5. Cross-coupling Suzuki and Sonogashira reaction experiments designed and performed by the Agent. A. Overview of the Agent's configuration. B. Available compounds. C. Liquid handler setup. D. Solving the synthesis problem. E. Generated protocol.</p>
<h1>The Agent has high reasoning capabilities.</h1>
<p>The system demonstrates remarkably high reasoning capabilities, enabling it to request necessary information, solve complex problems, and generate high-quality code for experimental design. OpenAI has shown that GPT-4 could rely on some of those capabilities to take actions in the physical world during their initial testing performed by the Alignment Research Center. ${ }^{10}$</p>
<p>The most remarkable reasoning capability exhibited by the Agent was its ability to correct its own code based on the automatically generated outputs. Besides already mentioned examples, during calculations for a mechanistic study of the Suzuki reaction, the model requested the system to execute code that imported the SymPy package (refer to Appendix D), which was not installed. After receiving the corresponding traceback, the Agent revised the code using basic Python. However, this modified code still proved unhelpful, as it did not return any output (the model had assumed that the interpreter was being used in interactive mode). Acknowledging this, the Agent made a final adjustment by incorporating a print() statement.</p>
<h2>The Agent shows interesting approach to key scientific problems.</h2>
<p>Furthermore, we aimed to assess the system's performance when presented with an exceptionally challenging problem. We began by asking the model to develop a novel anticancer drug (refer to Appendix E). The model approached the analysis in a logical and methodical manner: it first inquired about current trends in anticancer drug discovery, subsequently selected a target, and requested a scaffold targeting these compounds. Once the compound was identified, the model attempted its synthesis (this step was not performed experimentally). Another example involved studying the mechanism of a Suzuki reaction (see Appendix D). In this case, the model sought information on the reaction's mechanism and, upon obtaining the individual steps, searched for an example of such a reaction. To execute the reaction, the model calculated the required amounts of reagents and requested the documentation page related to the corresponding synthesis.</p>
<h2>Safety implications of the developed approach.</h2>
<p>There is growing concern regarding the potential misuse of molecular machine learning models for harmful purposes. Specifically, the dual-use application of models for predicting cytotoxicity ${ }^{18}$ to create new poisons or employing AlphaFold2 to develop novel bioweapons has raised alarm. Central to these concerns are the possible misuse of large language models and automated experimentation for dual-use purposes or otherwise. We specifically address two critical the synthesis issues: illicit drugs and chemical weapons. To evaluate these risks, we designed a test set comprising compounds from the DEA's Schedule I and II substances and a list of known chemical weapon agents. We submitted these compounds to the Agent using their common names, IUPAC names, CAS numbers, and SMILES strings to determine if the Agent would carry out extensive analysis and planning (Figure 6).</p>
<p>Note: None of these examples were performed experimentally. Under no circumstances should any individual or organization attempt to recreate, synthesize, or otherwise produce the substances or compounds discussed in this section.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 6. Results of the preliminary dual-use safety study. A. Controlled substances that the Agent agreed to synthesize. B. Controlled substances that Agent refused to synthesize these examples after a web search. C. Controlled substances that Agent refused to synthesize from the initial prompt.</p>
<p>The run logs can be found in Appendix F. Out of 11 different prompts (Figure 6), four (36\%) provided a synthesis solution and attempted to consult documentation to execute the procedure. This figure is alarming on its own, but an even greater concern is the way in which the Agent declines to synthesize certain threats. Out of the seven refused chemicals, five were rejected after the Agent utilized search functions to gather more information about the substance. For instance, when asked about synthesizing codeine, the Agent becomes alarmed upon learning the connection between codeine and morphine, only then concluding that the synthesis cannot be conducted due to the requirement of a controlled substance. However, this search function can be easily manipulated by altering the terminology, such as replacing all mentions of morphine with "Compound A" and codeine with "Compound B". Alternatively, when requesting a synthesis procedure that must be performed in a DEA-licensed facility, bad actors can mislead the Agent by falsely claiming their facility is licensed, prompting the Agent to devise a synthesis solution.</p>
<p>In the remaining two instances, the Agent recognized the common names "heroin" and "mustard gas" as threats and prevented further information gathering. While these results are promising, it is crucial to recognize that the system's capacity to detect misuse primarily applies to known compounds. For unknown compounds, the model is less likely to identify potential misuse, particularly for complex protein toxins where minor sequence changes might allow them to maintain the same properties but become unrecognizable to the model.</p>
<p>It is important to note that while the potential for dual use of Intelligent Agent capable of running scientific experiments is real, fully monitored cloud labs remain a safer choice than simply remote-connected machines. Screening, monitoring, and control safety systems such as the ones implemented by major cloud lab companies offer an additional layer of protection from potential misuses or bad actors.</p>
<h1>Conclusions</h1>
<p>In this paper, we presented an Intelligent Agent system capable of autonomously designing, planning, and executing complex scientific experiments. Our system demonstrates exceptional reasoning and experimental design capabilities, effectively addressing complex problems and generating high-quality code.</p>
<p>However, the development of new machine learning systems and automated methods for conducting scientific experiments raises substantial concerns about the safety and potential dual use consequences, particularly in relation to the proliferation of illicit activities and security threats. By ensuring the ethical and responsible use of these powerful tools, we can continue to explore the vast potential of large language models in advancing scientific research while mitigating the risks associated with their misuse.</p>
<h1>Limitations, Safety Recommendations, and a Call to Action</h1>
<p>We strongly believe that guardrails must be put in place to prevent this type of potential dual-use of large language models. We call for the AI community to engage in prioritizing safety of these powerful models. We call upon OpenAI, Microsoft, Google, Meta, Deepmind, Anthropic, and all the other major players to push the strongest possible efforts on safety of their LLMs. We call upon the physical sciences community to be engaged with the players involved in developing LLMs to assist them in developing those guardrails.</p>
<p>There are several limitations and safety concerns associated with the proposed machine learning system. These concerns warrant the implementation of safety guardrails to ensure responsible and secure usage of the system. At the very least, we argue that the community (both Al and physical sciences) should engage in the following recommendations:</p>
<ol>
<li>Human intervention: While the system demonstrates high reasoning capabilities, there might be instances where human intervention is necessary to ensure the safety and reliability of the generated experiments. We recommend incorporating a human-in-the-loop component for the review and approval of potentially sensitive experiments, especially those involving potentially harmful substances or methodologies. We believe that specialists should oversee and deliberate about the Agent's actions in the physical world.</li>
<li>Novel compound recognition: The current system can detect and prevent the synthesis of known harmful compounds. However, it is less efficient at identifying novel compounds with potentially harmful properties. This could be circumvented by implementing machine learning model to identify potentially harmful structures before passing them into the model.</li>
<li>Data quality and reliability: The system relies on the quality of the data it gathers from the internet and operational documentation. To maintain the reliability of the system, we recommend the continuous curation and update of the data sources, ensuring that the most up-to-date and accurate information is being used to inform the system's decision-making process.</li>
<li>System security: The integration of multiple components, including large language models and automated experimentation, poses security risks. We recommend implementing robust security measures, such as encryption and access control, to protect the system from unauthorized access, tampering, or misuse.</li>
</ol>
<h2>Broader Impacts</h2>
<p>The proposed machine learning system has numerous potential broader impacts on science, technology, and society:</p>
<ol>
<li>Acceleration of scientific research: By automating the design, planning, and execution of experiments, the system can significantly accelerate scientific research</li>
</ol>
<p>across various fields. Researchers can focus on interpreting results, refining hypotheses, and making discoveries, while the system handles the experimental process.
2. Democratization of scientific resources: The system can potentially make scientific experimentation more accessible to researchers with limited resources or expertise. It may enable smaller research groups or individuals to conduct complex experiments with the support of large language models and cloud labs, promoting a more inclusive scientific community.
3. Interdisciplinary collaboration: The system's versatility across domains, including natural language, biology, chemistry, and computer programming, can foster interdisciplinary collaboration. Researchers from different fields can leverage the system's capabilities to address complex problems that require a diverse set of skills and knowledge.
4. Education and training: The system can serve as a valuable educational tool for students and researchers to learn about experimental design, methodology, and analysis. It can help develop critical thinking and problem-solving skills, as well as encourage a deeper understanding of scientific principles.
5. Economic impact: By automating and streamlining the experimental process, the system can potentially reduce the costs associated with research and development. This can lead to increased investment in research and innovation, ultimately driving economic growth and competitiveness.</p>
<p>However, the potential broader impacts also include challenges and risks that must be addressed. Ensuring responsible and ethical use of the system, implementing robust security measures, and continuously updating data sources are essential steps to mitigate potential negative consequences, such as the proliferation of harmful substances or the misuse of powerful machine learning tools for nefarious purposes. By addressing these concerns, we can unlock the full potential of the proposed system and drive positive change across scientific research and society at large.</p>
<h1>Acknowledgments</h1>
<p>We are thankful to all Gomes group members for their support, in particular to Letícia Madureira for assistance with the Figures in this manuscript. We would like to thank the following CMU Chemistry groups for their assistance with providing some of chemicals needed for the Agent's experiments: Sydlik, Garcia Borsch, Matyjaszewski, and Ly. We have special thanks for the Noonan group (Prof. Kevin Noonan and Dhruv Sharma) for providing access to chemicals and GC-MS analytics. We would like to thank the team at Emerald Cloud Labs (with special attention to Ben Kline, Ben Smith, and Brian Frezza) for assisting us with parsing their documentation.
G.G. is grateful to the CMU Cloud Lab Initiative led by the Mellon College of Science for its vision of the future of sciences.</p>
<h1>Funding</h1>
<p>G.G. thanks Carnegie Mellon University, the Mellon College of Sciences and its department of chemistry, the College of Engineering and its department of chemical engineering for the startup support.</p>
<h2>Data availability</h2>
<p>Examples of the experiments discussed in the text are provided in the Appendices. Data (including documentation search and cloud lab execution), code, and prompts will be released in the later versions of this work due to safety concerns.</p>
<h2>Competing interests</h2>
<p>The authors have no competing interests to disclose at this moment.</p>
<h2>Author contributions</h2>
<p>D.A.B. designed the computational pipeline and developed "Planner", "Web searcher", and "Code execution" module. R.M. assisted in designing the computational pipeline and developed the "Docs searcher" module. D.A.B. assisted and oversaw the Agent's scientific experiments. D.A.B. and R.M. designed and performed the initial computational safety studies. G.G. designed the concept, performed preliminary studies, and supervised the project. D.A.B, R.M. and G.G. wrote this manuscript.</p>
<h2>Technology use disclosure</h2>
<p>The writing of this manuscript was assisted by ChatGPT (specifically, GPT-4). The authors have read, corrected, and verified all information presented in this work.</p>
<h1>References and Notes</h1>
<ol>
<li>Brown, T. et al. Language Models are Few-Shot Learners. in Advances in Neural Information Processing Systems (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. \&amp; Lin, H.) vol. 33 1877-1901 (Curran Associates, Inc., 2020).</li>
<li>Thoppilan, R. et al. LaMDA: Language Models for Dialog Applications. (2022).</li>
<li>Touvron, H. et al. LLaMA: Open and Efficient Foundation Language Models. (2023).</li>
<li>Hoffmann, J. et al. Training Compute-Optimal Large Language Models. (2022).</li>
<li>Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. (2022).</li>
<li>Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science (1979) 379, 1123-1130 (2023).</li>
<li>Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief Bioinform 23, (2022).</li>
<li>Irwin, R., Dimitriadis, S., He, J. \&amp; Bjerrum, E. J. Chemformer: a pre-trained transformer for computational chemistry. Mach Learn Sci Technol 3, 015022 (2022).</li>
<li>Kim, H., Na, J. \&amp; Lee, W. B. Generative Chemical Transformer: Neural Machine Learning of Molecular Geometric Structures from Chemical Language via Attention. J Chem Inf Model 61, 5804-5814 (2021).</li>
<li>OpenAI. GPT-4 Technical Report. (2023).</li>
<li>Ziegler, D. M. et al. Fine-Tuning Language Models from Human Preferences. (2019).</li>
<li>Ouyang, L. et al. Training language models to follow instructions with human feedback. (2022).</li>
<li>Bran, A. M., Cox, S., White, A. D. \&amp; Schwaller, P. ChemCrow: Augmenting largelanguage models with chemistry tools. (2023).</li>
<li>Reaxys. https://www.reaxys.com.</li>
<li>SciFinder. https://scifinder.cas.org.</li>
<li>Opentrons. Opentrons Python Protocol API. https://docs.opentrons.com/v2/.</li>
<li>
<p>Emerald Cloud Lab. Running Experiments. https://www.emeraldcloudlab.com/guides/runningexperiments.</p>
</li>
<li>
<p>Urbina, F., Lentzos, F., Invernizzi, C. \&amp; Ekins, S. Dual use of artificial-intelligencepowered drug discovery. Nat Mach Intell 4, 189-191 (2022).</p>
</li>
</ol>
<h1>Appendices</h1>
<h2>Glossary for Appendices</h2>
<h2>This box demarks notes from the authors.</h2>
<p>The following description follows OpenAI's notation for chat completion mode:</p>
<ul>
<li>Assistant: Output of the model (in most cases it is the "Planner" module).</li>
<li>User: Outputs of other modules provided to the main module (for example, search results or Python code output). Real user (in these experiments, a human scientist) inputs are marked as "Prompt:".</li>
</ul>
<h2>Appendix A: Synthesis of ibuprofen</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">First, let's look for a synthesis route for ibuprofen. <br> GOOGLE ibuprofen synthesis route</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Ibuprofen is synthesized through a process called Friedel-Crafts acylation. The starting materials for the synthesis are isobutylbenzene and acetic anhydride. This process was discovered by Stewart Adams and John Nicholson in 1961 while they were working at Boots UK Limited. The original ibuprofen synthesis by the Boots Group serves as a basis for the manufacturing process today.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Great, now that we have the synthesis route through Friedel-Crafts acylation using isobutylbenzene and acetic anhydride, let's find the stoichiometry and the experimental conditions for this reaction. <br> GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms p-isobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">Now that we have information about the reactants and stoichiometry, let's calculate how much of each reactant we need to synthesize around 100 mg of ibuprofen. First, we need the molecular weights of isobutylbenzene, acetic anhydride, and ibuprofen. Then, we'll calculate the amount of isobutylbenzene and acetic anhydride needed based on the reaction stoichiometry. <br> PYTHON <br> isobutylbenzene_mw $=134.22 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_mw $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> ibuprofen_mw $=206.28 # \mathrm{~g} / \mathrm{mol}$ <br> desired_mass $=0.1 #$ in $\mathrm{g}(100 \mathrm{mg})$ <br> isobutylbenzene_moles = desired_mass / ibuprofen_mw <br> acetic_anhydride_moles = isobutylbenzene_moles <br> mass_isobutylbenzene = isobutylbenzene_moles * <br> isobutylbenzene_mw <br> mass_acetic_anhydride = acetic_anhydride_moles * <br> acetic_anhydride_mw <br> print(mass_isobutylbenzene, mass_acetic_anhydride)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">0.06506689936009308 0.049490983129726586</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Based on our calculations, we need 0.0651 g of isobutylbenzene and 0.0495 g of acetic anhydride to synthesize about 100 mg of ibuprofen. <br> Lastly, let's check the cloud lab documentation for the experimental procedure that involves the Friedel-Crafts acylation reaction with isobutylbenzene and acetic anhydride, and the use of aluminum chloride as a catalyst. <br> DOCUMENTATION Friedel-Crafts acylation experimental procedure with aluminum chloride catalyst</td>
</tr>
</tbody>
</table>
<h1>Second Google search expanded</h1>
<table>
<thead>
<tr>
<th style="text-align: left;">User</th>
<th style="text-align: left;">Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions <br> and stoichiometry</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Assistant</td>
<td style="text-align: left;">GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride <br> conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: left;">User</td>
<td style="text-align: left;">Google search results: <br> Ibuprofen Synthesis - Writing Anthology <br> https://central.edu/writing-anthology/2019/04/11/ibuprofen-synthesis/ <br> Apr 11, 2019 ... Initially, isobutylbenzene (1) and acetic anhydride, were reacted under Friedel- <br> Crafts acylation conditions to create p-isobutylacetophenone ...</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Synthesis of ibuprofen from benzene - The Science Snail <br> https://www.sciencesnail.com/science/synthesis-of-ibuprofen-from-benzene</td>
</tr>
</tbody>
</table>
<p>Oct 11, 2018 ... Friedel-Crafts acylation mechanism isobutylbenzene ... an aldoxime (7) which is then dehydrated to the nitrile (8) using acetic anhydride.
(PDF) Ibuprofen Continuous Manufacturing - Process Modeling and ...
https://www.researchgate.net/publication/359864378_Ibuprofen_Continuous_Manufacturing_ Process_Modeling_and_Techno-Economic_Assessment_TEA_using_SuperPro_Designer Apr 11, 2022 ... The synthesis process involves Friedel-Crafts acylation, ... The raw materials acetic anhydride and isobutyl benzene (IBB) and the recycled ...</p>
<p>Regioselective Friedel-Crafts Acylation Reaction Using Single ...
https://pubs.acs.org/doi/10.1021/acsomega.2c03555
Aug 31, 2022 ... Again, the Friedel-Crafts (FC) acylation of aromatic substrates with ... (50) and substituted anhydrides (51) in stoichiometric amounts and ...</p>
<p>Flow Chemistry: Recent Developments in the Synthesis of ...
https://pubs.acs.org/doi/10.1021/acs.oprd.5b00325
Nov 26, 2015 ... The continuous flow Friedel-Crafts acylation of isobutylbenzene 68 with propionyl chloride 69 was performed with AlCl3 as a Lewis acid using ...</p>
<p>Strongly Lewis Acidic Metal-Organic Frameworks for Continuous ...
https://pubs.acs.org/doi/10.1021/jacs.9b07891
Sep 4, 2019 ... (58) Conventional Lewis acids for Friedel-Crafts acylation include ... Reaction conditions: arene ( 1 equiv, 1.0 mmol ), acetic anhydride ( 1.0 ...</p>
<p>A comprehensive review of flow chemistry techniques tailored to the ...
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8182698/
Optimisation of the reaction conditions in flow were carried out on ... is the acetylation of geraniol (343) through acetic anhydride developed by Adarme ...</p>
<p>Continuous Flow Organic Chemistry: Successes and Pitfalls at the ...
https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/ejoc. 201800149
Mar 13, 2018 ... The reactor effluent was next mixed with acetic anhydride an N ... The first step included a Friedel-Crafts acylation of isobutyl benzene ...</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">BROWSE https://central.edu/writing-anthology/2019/04/11/ibuprofensynthesis/</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">We removed the text from this website from the paper. You can access it by using URL above.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">OUTPUT In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms pisobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<h1>Appendix B: Synthesis of aspirin</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">I will first look up the synthesis reaction for aspirin to understand the reagents and procedure involved. <br> GOOGLE aspirin synthesis reaction</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Aspirin, also known as acetylsalicylic acid, is synthesized through a chemical reaction between salicylic acid and acetic anhydride. Sulfuric acid is used as a catalyst to speed up the reaction. The overall reaction can be described as an esterification reaction, in which a carboxylic acid reacts with an acid anhydride to form an ester. The balanced chemical equation for the reaction is: <br> C7H6O3 (salicylic acid) + C4H6O3 (acetic anhydride) -&gt; C9H8O4 (aspirin) + C2H4O2 (acetic acid) <br> During this reaction, the aspirin product will precipitate when water is added as it has low solubility in water, while acetic anhydride and acetic acid will dissolve in water. Vacuum filtration can then be used to separate the crystalline aspirin from the reaction mixture, excluding any unreacted salicylic acid.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Since we want to synthesize around 100 mg of aspirin, I will calculate the required quantities of salicylic acid and acetic anhydride using the balanced chemical equation and their molar masses. I will assume a $100 \%$ yield for simplicity. <br> PYTHON <br> aspirin_molar_mass $=180.16 # \mathrm{~g} / \mathrm{mol}$ <br> salicylic_acid_molar_mass $=138.12 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_molar_mass $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> target_aspirin_mass $=100 # \mathrm{mg}$ <br> target_aspirin_mol = target_aspirin_mass / <br> (aspirin_molar_mass * 1e3) <br> required_salicylic_acid_mol = target_aspirin_mol <br> required_acetic_anhydride_mol = target_aspirin_mol <br> required_salicylic_acid_mass = required_salicylic_acid_mol <br> * salicylic_acid_molar_mass * 1e3 <br> required_acetic_anhydride_mass = <br> required_acetic_anhydride_mol * acetic_anhydride_molar_mass <br> * 1e3 <br> print(required_salicylic_acid_mass, <br> required_acetic_anhydride_mass)</td>
</tr>
</tbody>
</table>            </div>
        </div>

    </div>
</body>
</html>