<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2636 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2636</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2636</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-8f5562ead9861744a1192c1bef69283e25200aa8</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8f5562ead9861744a1192c1bef69283e25200aa8" target="_blank">Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> It is argued that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique.</p>
                <p><strong>Paper Abstract:</strong> Optimizing multiple competing black-box objectives is a challenging problem in many fields, including science, engineering, and machine learning. Multi-objective Bayesian optimization (MOBO) is a sample-efficient approach for identifying the optimal trade-offs between the objectives. However, many existing methods perform poorly when the observations are corrupted by noise. We propose a novel acquisition function, NEHVI, that overcomes this important practical limitation by applying a Bayesian treatment to the popular expected hypervolume improvement (EHVI) criterion and integrating over this uncertainty in the Pareto frontier. We argue that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique. Through this lens, we derive a natural parallel variant, $q$NEHVI, that reduces computational complexity of parallel EHVI from exponential to polynomial with respect to the batch size. $q$NEHVI is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments, and we show that it can be optimized effectively with gradient-based methods via sample average approximation. Empirically, we demonstrate not only that $q$NEHVI is substantially more robust to observation noise than existing MOBO approaches, but also that it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments.</p>
                <p><strong>Cost:</strong> 0.031</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2636.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2636.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Noisy Expected Hypervolume Improvement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayes-optimal acquisition function for multi-objective Bayesian optimization under noisy observations that integrates EHVI over posterior uncertainty in the in-sample Pareto frontier to avoid overfitting to noisy measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NEHVI (Noisy Expected Hypervolume Improvement)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NEHVI computes the acquisition value for candidate designs by integrating expected hypervolume improvement (EHVI) over the posterior distribution of the true (noise-free) function values at previously observed points. Practically this is approximated with Monte Carlo samples of the joint posterior across in-sample points and candidate points: for each posterior sample, compute the sample-specific Pareto frontier, compute HVI for candidate(s) relative to that frontier, then average. NEHVI therefore accounts for observation noise by marginalizing the uncertainty in the existing Pareto frontier and is one-step Bayes-optimal for hypervolume maximization in noisy and noiseless settings.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General multi-objective experimental design and automated discovery tasks (applied in the paper to synthetic MOO benchmarks, adaptive bitrate policy tuning, and vehicle design optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects next experiment(s) by maximizing expected hypervolume improvement integrated over posterior uncertainty in previously observed (noisy) outcomes, i.e., allocate evaluation budget to candidate(s) with largest Monte Carlo-averaged HVI across posterior samples of in-sample function values.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time for acquisition optimization (GPU/CPU), plus asymptotic computational complexity (time/space) expressed in Big-O using number of MC samples N, batch size q, number of past points n, number of objectives M and optimization iterations N_opt (see tradeoff fields).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected hypervolume improvement (EHVI) averaged over posterior samples of in-sample function values (i.e., Monte Carlo estimate of E_p[HVI(· | P)] ).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balances exploration and exploitation implicitly via the EHVI criterion applied across posterior uncertainty: EHVI rewards candidates that either improve Pareto hypervolume (exploitation) or lie in regions of high posterior uncertainty leading to expected HVI (exploration). By integrating over in-sample uncertainty, NEHVI avoids over-committing to noisy apparent optima.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity of solutions is encouraged implicitly via hypervolume maximization (which favors spread along the Pareto frontier) and submodularity guarantees that greedy batch selection encourages diverse sets; NEHVI's marginalization over in-sample uncertainty further discourages clumping caused by noisy observations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of experiments / batch evaluation budgets and wall-time constraints (batch size q); also implicit computational budget for acquisition optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Supports sequential greedy batch selection to choose q candidates (reducing the qd optimization to q sequential d-dimensional problems) with submodularity-based regret guarantees; uses Cached Box Decompositions (CBD) and sample average approximation to reduce acquisition optimization cost and enable larger batch sizes under computational limits.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Breakthroughs are identified via large hypervolume improvements — candidate(s) that produce large increments in dominated hypervolume relative to the current Pareto frontier (averaged over posterior uncertainty).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Log hypervolume gap (log difference between true Pareto hypervolume and found frontier) over evaluations; wall-clock acquisition optimization time on GPU/CPU; robustness across additive noise levels (experiments at 1%–30% of objective range). Reported empirical findings: NEHVI (and qNEHVI-1) outperform baselines across noisy benchmarks; shown robust up to 30% noise. Specific experimental settings include budgets such as 224 function evaluations in batch-scaling experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against EHVI / qEHVI (and qEHVI-PM-CBD), DGEMO, PESMO, MESMO, PFES, TSEMO, TS-TCH, ParEGO variants (qParEGO/qNParEGO), MOEA/D-EGO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Empirically achieves state-of-the-art optimization performance on noisy multi-objective benchmarks in the paper; NEHVI avoids clumping seen in EHVI and posterior-mean plug-in EHVI, and produces better-distributed Pareto frontiers. qNEHVI and qNEHVI-1 outperform all compared methods on noisy benchmarks (qualitative and plotted results in paper), with qNEHVI-1 offering the fastest batch selection times on GPU.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Computational scaling improvement via CBD: reduces q-EHVI complexity from exponential in batch size (IEP formulation) to polynomial in q; wall-time speedups reported (figures show orders-of-magnitude improvements in acquisition time for larger q when using CBD and for qNEHVI-1 on GPU).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper analyzes tradeoffs between computational cost and expected information/utility: NEHVI integrates over in-sample uncertainty (increasing MC cost) but CBD and SAA (fixed samples) make optimization tractable; CBD trades a one-time cost of computing and caching N Pareto-frontier box decompositions per BO iteration against large savings when evaluating acquisition many times during optimization. They present Big-O time/space complexity formulas showing CBD yields polynomial dependence on batch size q (O(N_opt N M (n+q)^M q)) versus exponential dependence under IEP (O(N_opt N M n^M 2^q q)). Also present SAA convergence guarantees that deterministic acquisition (fixed base samples) converges to true NEHVI optimum as N increases.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key insight: marginalizing over uncertainty in previously observed (noisy) in-sample function values produces a one-step Bayes-optimal acquisition for hypervolume maximization in noisy settings; sequential greedy batch selection is justified by submodularity and has provable regret bound (no more than 1/e of optimal). Practical recommendation: use NEHVI with CBD and SAA (fixed MC base samples) to balance computational cost and information-theoretic optimality when allocating batch evaluations under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2636.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>qNEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallel / Batch Noisy Expected Hypervolume Improvement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parallel/batch extension of NEHVI that selects q candidates using a sequential greedy approximation and cached box decompositions to make joint batch selection computationally feasible under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>qNEHVI (parallel NEHVI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extends NEHVI to select batches of q candidates by maximizing expected joint hypervolume improvement integrated over in-sample posterior uncertainty. Joint optimization is approximated with a sequential greedy policy: choose candidates one at a time, holding previous selections fixed; for each stage, update cached MC Pareto frontiers and CBDs that include the already-chosen candidates. CBD reduces complexity from exponential to polynomial in q, and SAA with fixed base samples makes acquisition deterministic for gradient-based optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Same as NEHVI — multi-objective experimental design requiring parallel evaluations (e.g., A/B tests, high-throughput chemistry, parallel hardware tests).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates a batch of q experiments by sequential greedy maximization of the MC-approximated NEHVI; each candidate selection uses cached posterior samples and box decompositions (CBD) updated to include previously selected points within the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time and GPU/CPU memory; algorithmic complexity in Big-O in terms of MC samples N, batch size q, number of past points n, objectives M, and optimization iterations N_opt. Empirical wall-time measurements presented (GPU V100 and multi-core CPU).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>q-NEHVI: Monte Carlo average of joint hypervolume improvement (q-EHVI) across posterior samples of in-sample function values.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Greedy sequential selection implicitly trades exploration and exploitation via NEHVI (each candidate is chosen to maximize expected marginal hypervolume gain given already-chosen batch members and uncertainty). Submodularity gives performance guarantees for greedy approximation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Hypervolume objective encourages coverage along Pareto frontier; sequential greedy selection with submodularity bound (regret ≤ 1/e of optimum) encourages diverse batches empirically and theoretically.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size q and total evaluation budget; computational budget for acquisition optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Sequential greedy reduces joint q d-dimensional optimization to q sequential d-dimensional optimizations; CBD caches N per-sample decompositions to avoid recomputing expensive decompositions repeatedly, enabling larger q under fixed compute/memory limits.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Marginal q-HVI per candidate (expected incremental dominated hypervolume contributed by candidate i given prior selections), averaged across posterior samples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same hypervolume-gap and wall-time metrics as NEHVI; empirical experiments show qNEHVI achieves highest hypervolume for increasing batch sizes and scales more gracefully than baselines; reported experiments include a budget of 224 function evaluations and batch size sweeps.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>qEHVI (IEP), qEHVI-PM-CBD (posterior mean plug-in with CBD), DGEMO, TSEMO, TS-TCH, qNParEGO, ParEGO variants, information-theoretic methods (PESMO/MESMO/PFES).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>qNEHVI generally achieves the greatest hypervolume across batch sizes in experiments, outperforming qEHVI-PM-CBD and other baselines; CBD-enabled qNEHVI scales to batch sizes infeasible for IEP-based qEHVI.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>CBD reduces time/space complexity from exponential in q (IEP) to polynomial in q; empirical acquisition optimization wall-times show CBD avoids out-of-memory errors on GPU and enables much larger q (plots in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper quantifies tradeoffs via Big-O expressions: CBD approach time complexity: O(N_opt N M (n+q)^M q) vs IEP exponential dependence O(N_opt N M n^M 2^q q). The CBD saves computation at the cost of computing and caching N box decompositions per BO iteration (one-time per acquisition optimization).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Sequential greedy qNEHVI is justified theoretically due to submodularity (expected qNEHVI is submodular), giving a worst-case approximation guarantee; practically recommended when batch parallelism is required and computational resources are constrained, using CBD and SAA to make batch selection tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2636.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>qNEHVI-1</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Single-sample RFF Approximation of qNEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computationally cheaper approximate variant of qNEHVI that uses a single approximate GP sample path generated via random Fourier features (RFF) to accelerate batch candidate optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>qNEHVI-1 (RFF single-sample approximation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Instead of averaging over many posterior samples, qNEHVI-1 generates a single deterministic approximate GP sample path via Random Fourier Features (RFF) and optimizes HVI under that sample path for each sequential candidate. Because the RFF model is deterministic and cheap to evaluate, gradient-based optimization (including higher-order methods) can be applied efficiently, making batch selection (with CBD) very fast.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Low-to-moderate dimensional multi-objective optimization where fast batch selection is needed (e.g., high-throughput experimental design).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experiments by optimizing HVI under a single deterministic approximate GP sample path, selecting candidates sequentially (greedy) using CBD; this reduces computational cost at the expense of a cruder approximation to the expected objective.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock acquisition optimization time; number of RFF basis functions (e.g., paper uses 500) as a proxy for compute; memory for CBD still required.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Approximate sample-path HVI (not full expected-information metric); effectively approximates expected improvement by using one sampled function.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration arises from variability in the single sampled function path (Thompson-sampling-like behavior), while exploitation is achieved by choosing candidates that maximize HVI on that sample; being single-sample, this is a stochastic heuristic approximating the full NEHVI objective.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity arises from HVI objective on the sampled path and sequential greedy selection; RFF sampling across restarts or multiple RFFs could increase diversity but qNEHVI-1 as described uses a single RFF sample per candidate selection step.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for acquisition optimization (favoring low wall-time) and experiment batch budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Reduces acquisition computational cost by replacing expensive joint posterior evaluations with cheap RFF sample evaluations, enabling much faster batch selection and scaling to larger q when dimensionality is modest.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>HVI under the RFF sample path; large HVI on the sampled path is taken as proxy for high-impact candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirically among top performers for low-dimensional problems; achieves fastest batch selection times on GPU among tested methods and good anytime performance across q values. Paper reports qNEHVI-1 being an order-of-magnitude faster than qNEHVI for many problems (figures in appendix).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to qNEHVI, TSEMO, DGEMO, qEHVI, ParEGO variants and others in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>qNEHVI-1 often matches or comes very close to qNEHVI's optimization quality on low-dimensional problems while being substantially faster; outperforms TSEMO in speed and often in final hypervolume.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Orders-of-magnitude faster batch selection on GPU in many cases (paper reports qNEHVI-1 has the lowest wall time of any method tested on GPU across problems).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes a tradeoff: qNEHVI-1 gains large computational savings by using a single sample approximation but can be less robust in higher-dimensional spaces; qNEHVI (full MC) is more robust but costlier. Paper suggests RFF basis count and problem dimensionality determine the sweet spot.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>qNEHVI-1 is recommended when fast batch selection is critical and the search dimensionality is modest; for higher dimensions or when robustness to approximation error is needed, full qNEHVI is preferred.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2636.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CBD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cached Box Decompositions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational technique for reusing box decompositions of sampled Pareto frontiers to dramatically reduce repeated hypervolume/HVI computation when optimizing Monte Carlo acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Cached Box Decompositions (CBD)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CBD uses a fixed set of posterior samples of in-sample function values to compute per-sample Pareto frontiers and box decompositions once per BO iteration and caches these decompositions for repeated evaluation of acquisition functions during inner-loop optimization. Under sequential greedy batch selection, cached decompositions are incrementally updated when previously selected batch points are added. CBD enables efficient batched tensor computation (with padding) and reduces time/space complexity of parallel EHVI/NEHVI from exponential in batch size q (IEP method) to polynomial in q.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Computational acceleration of MOBO acquisition evaluation — applicable in any multi-objective BO pipeline that uses EHVI or HVI computations (e.g., materials, chemistry, policy tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Not an allocation policy itself; it enables more aggressive allocation strategies (e.g., large q batches and gradient-based acquisition optimization) by reducing the computational cost of evaluating/optimizing acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Big-O time and space complexity in terms of MC samples N, batch size q, number of prior points n, number of objectives M, and optimization iterations N_opt. Empirical wall-clock times measured on GPU/CPU and memory (OOM avoidance).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Indirect: by reducing acquisition evaluation cost it enables more thorough optimization (more multi-starts, more gradient steps), indirectly improving the exploration/exploitation balance realizable in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Indirect: CBD enables fast computation of hypervolume objectives that inherently encourage Pareto diversity; it does not itself impose explicit diversity heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget (time, memory) for acquisition optimization; also supports large experimental batch budgets by making large-batch acquisition tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Caches expensive per-sample decompositions (one-time per BO iteration) to avoid recomputing them at each acquisition evaluation; pads decompositions to enable efficient batched tensor operations; supports pruning dominated in-sample points to reduce decomposition size.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical reductions in acquisition optimization wall time and memory usage enabling larger batch sizes; paper demonstrates CBD avoids GPU OOM and scales to batch sizes infeasible for IEP; complexity reductions outlined mathematically (exponential→polynomial).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>IEP (inclusion-exclusion principle) approach for computing q-EHVI, which has exponential time/space scaling in q.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>CBD and IEP are mathematically equivalent in computed acquisition values when using common randomness, but CBD reduces time/space complexity significantly; asymptotic comparison: CBD time complexity polynomial in q versus IEP exponential(2^q) dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Asymptotic gain: CBD reduces acquisition time/space from O(... 2^q q ...) to O(... (n+q)^M q ...); empirical speed-ups shown in acquisition wall-time plots and enables scaling to larger q without OOM.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>CBD trades a one-time cost of computing N per-sample box decompositions for large savings during inner-loop acquisition optimization; SAA (fixed base samples) further stabilizes computation and allows deterministic gradients for faster optimizer convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Practical recommendation: use CBD (and SAA) when optimizing MC-based EHVI/NEHVI acquisition functions to allow gradient-based optimization and to scale batch sizes while controlling computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2636.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EHVI / qEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Hypervolume Improvement (and its parallel q-EHVI variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of acquisition functions that extend Expected Improvement to multi-objective problems by maximizing expected increase in Pareto-dominated hypervolume; qEHVI is the batch/parallel generalization that considers joint hypervolume improvement of q candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EHVI / qEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EHVI computes the expectation of hypervolume improvement for a single candidate under the posterior; qEHVI generalizes this to joint sets of q candidates by computing expected joint hypervolume improvement (often via MC and an inclusion-exclusion principle). Analytic formulas exist under strong independence assumptions; practical methods use box decompositions and MC. qEHVI via IEP suffers exponential scaling in q; CBD provides polynomial alternative.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective Bayesian optimization across science and engineering domains (used as baseline in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects experiments by maximizing (expected) hypervolume improvement; in practice qEHVI may be approximated via sequential greedy selection due to optimization complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Time/space complexity (IEP exponential in q), wall-clock acquisition optimization time; number of MC samples N.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected hypervolume improvement (EHVI) — a decision-theoretic expected-utility measure rather than mutual-information.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>EHVI balances exploration and exploitation through the posterior: candidates with high expected hypervolume improvement are either promising (exploitation) or uncertain (exploration) depending on posterior predictive distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Hypervolume objective itself favors diverse Pareto coverage; qEHVI (joint HVI) explicitly considers interactions among candidates to avoid redundant batch members (but exact joint computation is expensive).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch size q; computational constraints (IEP scaling limits q).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Common practical approach: sequential greedy selection and CBD or plug-in posterior-mean heuristics (EHVI-PM) to reduce compute.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Expected increase in dominated hypervolume (EHVI) — large EHVI values indicate candidates with breakthrough potential.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Hypervolume gap over number of evaluations; EHVI is one-step Bayes-optimal in noiseless, fully sequential settings.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to NEHVI, NEHVI-PM (posterior mean plug-in), and other MOBO methods in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>EHVI works well when observations are noise-free; in noisy settings naive EHVI (using observed noisy in-sample points) can be misled and produce clumped Pareto points, while NEHVI (which marginalizes in-sample uncertainty) performs better. EHVI-PM (posterior mean plug-in) partially mitigates noise but can still lead to clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Analytic EHVI formulas exist in special cases; parallel qEHVI IEP formulation is expensive but CBD can reduce cost to polynomial.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper contrasts EHVI's one-step Bayes-optimality in noiseless sequential cases with NEHVI's Bayes-optimality in noisy settings; highlights computational tradeoffs for qEHVI versus CBD-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation: in noisy settings, marginalizing uncertainty over in-sample values (NEHVI) is preferable to naive EHVI; for batch settings, use CBD and sequential greedy selection to balance compute and performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2636.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DGEMO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diversity-Guided Multi-Objective Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parallel MOBO method that greedily maximizes hypervolume improvement while explicitly encouraging diversity among sampled designs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Diversity-guided multi-objective bayesian optimization with batch evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DGEMO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DGEMO constructs batches by greedily maximizing HVI but incorporates explicit diversity guidance in selecting batch members to avoid redundant samples; it scales well to large batch sizes but (as implemented) does not account for noisy observations.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Parallel multi-objective optimization tasks requiring diverse batches (e.g., engineering design, expensive simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy selection maximizing a combination of HVI and a diversity-guiding term (details in DGEMO paper); aims to allocate batch budget to diverse, high-impact candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Designed for scalability—empirically scales to large batch sizes; wall-clock time depending on implementation (paper compares wall-times).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>HVI-based utility (not explicit mutual information); diversity term supplements HVI.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via explicit diversity encouragement in batch formation; exploitation via HVI maximization.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicitly includes diversity-guiding heuristics to spread batch members (primary selling point of DGEMO).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Large batch sizes (q) and total evaluation budget; computational time/throughput budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy batch construction that scales well to large q; however, does not account for observation noise in original formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>HVI plus diversity-driven scoring — candidates that increase hypervolume and increase frontier spread are favored.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to scale well to large q; in this paper DGEMO is included as baseline and performs well in some settings but is outperformed by NEHVI under noisy observations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally to NEHVI, qNEHVI-1 and others.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>DGEMO scales well to large q but does not handle noisy observations; in experiments DGEMO showed clumping or lower performance relative to NEHVI on noisy benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Designed for large-batch scalability; empirical runtime depends on implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes DGEMO scales to large batch sizes but lacks noise-awareness; tradeoff is computational scalability vs. handling noisy observations robustly.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>DGEMO is effective when diverse batch exploration is primary objective and noise is negligible; if observations are noisy, marginalizing in-sample uncertainty (NEHVI) yields better Pareto discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2636.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PESMO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive Entropy Search for Multi-Objective Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-theoretic acquisition function that selects experiments to reduce uncertainty (entropy) about the Pareto frontier, and is designed to be robust to noise in some variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predictive entropy search for multi-objective bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PESMO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PESMO is an entropy-based MOBO method that aims to select evaluations that maximally reduce posterior entropy about the Pareto frontier. It computes expected information gain about the Pareto set/frontier, typically relying on complex approximations due to intractable entropies. PESMO (in original form) can account for noise but involves expensive computations and approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization tasks where information about Pareto frontier structure is critical and evaluations may be noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experiments by maximizing expected reduction in entropy over the Pareto frontier (information gain), subject to approximation/tractability constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High wall-clock computational cost due to intractable entropy computations and required approximations; often slower acquisition optimization than gradient-based EHVI/CBD approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected information gain (reduction in entropy of Pareto frontier / Pareto set).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit exploration via maximizing expected information gain; exploitation occurs when information gain aligns with improving objective values.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Entropy criterion implicitly promotes sampling in regions that reduce uncertainty about frontier geometry, which can lead to diverse sampling but not necessarily direct diversity heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for acquisition optimization and evaluation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Requires approximations and expensive optimization; in practice can be slow and was run with fewer replications in experiments due to runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Information gain about Pareto frontier rather than explicit hypervolume improvement; breakthrough implies a large reduction in uncertainty about frontier location or detection of a previously unknown Pareto region.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Measured by hypervolume gap over evaluations but PESMO was slower to optimize and performed poorly relative to NEHVI in experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally to NEHVI, MESMO, PFES and others.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Information-theoretic methods (PESMO, MESMO, PFES) performed worse than NEHVI on the tested benchmarks in this paper and were slower; PESMO was able to handle noise in principle but relied on approximations that proved computationally challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No efficiency gain reported; rather PESMO is noted as computationally intensive requiring approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper comments that while information-theoretic methods allow decoupled evaluations (useful when objectives have different evaluation costs), optimizing them is non-trivial and current implementations may underperform compared to NEHVI when computational constraints are tight.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Information-theoretic acquisition can be principled for budgeted, decoupled evaluations (when querying some objectives is costlier), but requires improved optimization procedures to be competitive in practical noisy MOBO settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2636.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MESMO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Max-value Entropy Search for Multi-Objective Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An entropy-based MOBO method that extends max-value entropy search to multi-objective settings to choose evaluations that reduce uncertainty about optimal values.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Max-value entropy search for multi-objective bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MESMO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MESMO is an information-theoretic acquisition function that targets reduction in uncertainty regarding the maximal values (Pareto-optimal values) by sampling points expected to provide large entropy reductions about the Pareto-optimal levels. The authors of this paper extended MESMO to handle noisy observations using noisy information gain from Takeno et al. [52] for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization tasks where quantifying and reducing uncertainty about optima is desired.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects experiments by maximizing expected reduction in entropy about max-values / Pareto frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High computational cost due to intractable entropy approximations and expensive optimization (empirically slower than NEHVI/CBD).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected information gain (entropy reduction) about the Pareto max-values/frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration is driven by information maximization (entropy reduction); exploitation occurs when information gain coincides with high predicted performance.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via information-seeking behavior; not an explicit diversity heuristic.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget and evaluation budget; parallelization approximate via sample-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Relies on approximations; the authors extended MESMO for noisy observations using noisy information gain approximations for parallelization.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Entropy reduction about Pareto-optimal values; large information gain implies potential for discovering impactful (breakthrough) Pareto points.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported hypervolume gap; MESMO performed worse than NEHVI on tested noisy benchmarks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally against NEHVI and other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Generally underperformed NEHVI in the paper's experiments, and was slower due to complex entropy computations.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>None reported in this paper; MESMO is computationally heavy.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes information-theoretic methods' potential for decoupled queries but highlights practical optimization difficulty and computational expense compared with EHVI-based CBD approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>While theoretically principled for maximizing information, MESMO requires further practical improvements to trade off computational cost and performance effectively in noisy, parallel MOBO.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2636.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PFES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pareto-Frontier Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An entropy-based MOBO acquisition that aims to reduce entropy over the Pareto frontier (PFES), similar in spirit to PESMO and MESMO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Multi-objective Bayesian optimization using pareto-frontier entropy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PFES</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PFES is an entropy-based acquisition that constructs an information gain objective focused on the Pareto frontier; like PESMO/MESMO it requires approximations to make entropy computations tractable and can be computationally intensive.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization where explicit uncertainty quantification of the Pareto frontier is desired.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experiments by maximizing expected reduction in entropy over the Pareto frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High wall-clock time due to entropy approximations and optimization complexity; in this paper PFES used finite-difference gradient approximations, adding to cost.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected entropy reduction over Pareto frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration by targeting regions that reduce uncertainty about the frontier; exploitation occurs when reducing uncertainty aligns with improving objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via information-seeking across frontier regions; no explicit diversity heuristic beyond entropy objective.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational evaluation budget; acquisition optimization budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Approximation-heavy; computational cost limits practical application to larger problems in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Information-theoretic reduction in uncertainty about PF; not a hypervolume metric directly.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Measured via hypervolume gap; in paper PFES underperformed NEHVI and incurred higher computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally to NEHVI and other MOBO baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PFES did not match NEHVI's performance on noisy benchmarks; slower acquisition optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>None reported; PFES is computationally intensive in current implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>PFES demonstrates the classic tradeoff: solving a more informative objective (entropy) is computationally costly and may underperform less costly but better-optimized heuristics (NEHVI with CBD) in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Information-theoretic PFES may be valuable when decoupled, cost-differential objective evaluations are central, but current methods' optimization and approximation overhead limit their practical competitiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2636.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TSEMO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Thompson Sampling Evolutionary Multi-objective Optimization (TSEMO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A heuristic MOBO method that uses Thompson sampling to draw approximate GP sample functions (via RFFs) and optimizes those samples using an evolutionary algorithm (NSGA-II), selecting candidates from the resulting population.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Efficient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TSEMO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>TSEMO draws random function samples from GP surrogates (via Random Fourier Features) and uses NSGA-II to find Pareto-optimal sets on each sampled function; a subset of points from the evolutionary population is then chosen (via greedy HVI or heuristics) to form a batch. It is robust to noise because Thompson sampling naturally incorporates posterior uncertainty but relies on expensive zero-order optimization (EA).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization where sampling-based exploration is preferred and gradient-free optimization is acceptable (engineering, simulation-heavy domains).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experiments by optimizing sampled functions (Thompson sampling), effectively exploring according to posterior randomness; candidate selection often involves choosing high-HVI points from the EA population.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Optimization cost dominated by NSGA-II runs on sampled functions (zeroth-order), making it slower than gradient-based EHVI/CBD approaches; wall-clock time substantial for large problems.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicit via Thompson sampling (posterior sampling) rather than explicit mutual information or expected improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via randomness of sampled functions (Thompson sampling); exploitation by optimizing those samples and selecting promising candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>NSGA-II population provides diverse candidate pool; subsequent selection may use HVI to pick diverse, high-value points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for EA optimization and total experimental budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Heuristic; can be computationally heavy due to EA usage; in paper, TSEMO was slower and placed mid-pack in performance.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Candidates selected from high-performing regions of sampled function paths; large improvements on sampled paths suggest potential breakthroughs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Hypervolume gap and wall-time; TSEMO performed moderately relative to other baselines, slower than gradient-based CBD methods.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to qNEHVI-1 (which uses RFFs but optimizes with gradients), DGEMO, qEHVI, and others.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>TSEMO provided robustness to noise but was typically slower and less efficient than qNEHVI-1 and NEHVI with CBD; it occupied a middle performance tier in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No major efficiency gain relative to gradient-based EHVI/CBD approaches; qNEHVI-1 obtained similar or better results much faster by optimizing sample paths with gradients rather than EA.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Tradeoff: Thompson sampling + EA yields robustness and diversity at cost of computational speed; alternative RFF+gradient optimization (qNEHVI-1) can be faster while retaining benefits.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>TSEMO is a reasonable heuristic when gradient information is unavailable or users prefer sampling-based methods, but gradient-based CBD-enabled methods offer better computational efficiency for many MOBO tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2636.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ParEGO / qParEGO / qNParEGO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ParEGO and batch/noisy extensions (qParEGO, qNParEGO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Scalarization-based MOBO methods that reduce multi-objective problems to single-objective ones via random scalarizations (e.g., augmented Chebyshev) and then apply single-objective BO (e.g., EI); batch and noisy variants extend this idea for parallel evaluation and noisy observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ParEGO family (ParEGO, qParEGO, qNParEGO)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ParEGO uses random scalarizations (augmented Chebyshev) to convert MOO to a scalar BO problem and optimizes expected improvement; qParEGO extends to batch by using multiple scalarizations in parallel (often optimized by an EA like MOEA/D). qNParEGO is a noisy variant that attempts to incorporate observation noise into scalarized acquisition computations.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization where scalarization is acceptable or simpler BO tools are preferred; used as baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates evaluations by sampling scalarization weights and optimizing the corresponding single-objective acquisition (EI), thereby spreading evaluations across different scalarizations to cover diverse Pareto regions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock acquisition optimization time; complexity grows with number of scalarizations and use of EA for parallelization.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Improvement on scalarized objectives (not explicit information-theoretic metric).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via randomization of scalarization weights (diversifies search); exploitation via EI on scalarized objective.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Multiple random scalarizations produce diverse Pareto candidates; MOEA/D or parallel scalarization approaches expand diversity across batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch evaluation budgets and computational cost of optimizing multiple scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Batch variants run multiple scalarized optimizations in parallel (using MOEA/D or greedy selection) to utilize batch budget; noisy variant attempts to account for observation noise in scalarization evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>High scalarized EI values indicating large improvement under particular weightings; discovery of extreme Pareto trade-offs via varied scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Hypervolume gap and wall-time; qParEGO/qNParEGO sometimes underperform EHVI-based approaches on noisy benchmarks in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to NEHVI, qNEHVI-1, qEHVI, and other MOBO methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ParEGO family can be competitive in some settings but generally was outperformed by qNEHVI and qNEHVI-1 on the noisy benchmarks studied here.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Batch variants can exploit parallel resources but may require population-based optimizers (EA) increasing computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Scalarization trades simplicity and parallelizability for potential bias in covering the Pareto frontier; random weight sampling helps but does not replace marginalizing in-sample noise as done in NEHVI.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>ParEGO-type methods are pragmatic when simpler scalarization-based BO pipelines are in use, but marginalizing uncertainty and using hypervolume-based acquisition (NEHVI) is preferable under noisy multi-objective settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2636.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2636.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TS-TCH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Thompson Sampling with Random Chebyshev Scalarizations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach that combines Thompson sampling with random Chebyshev scalarizations to produce robust, scalarized multi-objective optimization via posterior sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TS-TCH</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>TS-TCH applies Thompson sampling to randomly sampled Chebyshev scalarizations; posterior samples are optimized and used to select candidates. Thompson sampling confers robustness to noise when objectives are scalarized, and random scalarizations help cover the Pareto frontier.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective BO where scalarization combined with sampling is used; paper uses TS-TCH as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocation via sampled scalarized objectives (Thompson sampling), choosing candidates that are optimal under sampled scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time (relies on optimizing sampled scalarizations; in experiments optimized approximate functions using RFFs and gradient methods).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicit via Thompson sampling randomness rather than explicit information metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via randomness of Thompson samples; exploitation from optimizing sampled scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Random scalarizations produce diverse trade-offs; selection across sampled weights yields diversity in candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch or sequential evaluation budgets and computational budget for optimization of sampled scalarizations.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Optimizes sampled scalarizations (RFF approximations) using gradient-based methods for speed; compared in experiments to other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>High scalarized performance on sampled weight indicates candidate with potential breakthrough under those preferences.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Hypervolume gap and wall-time; TS-TCH generally in middle of pack in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared experimentally to NEHVI, qNEHVI-1, TSEMO, qEHVI, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>TS-TCH offered robustness and moderate performance but was outperformed by NEHVI variants on noisy benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Faster than some EA-based heuristics when using RFF+gradients; still typically slower or less effective than CBD-enabled qNEHVI-1 in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Combines simple scalarization sampling with Thompson sampling for noise robustness at the cost of potential inefficiencies in covering entire Pareto set compared to NEHVI's expected hypervolume objective.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>TS-TCH is a practical baseline for noise-robust scalarized BO, but hypervolume-integrated approaches with proper noise marginalization (NEHVI) outperform it in the paper's benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization <em>(Rating: 2)</em></li>
                <li>Predictive entropy search for multi-objective bayesian optimization <em>(Rating: 2)</em></li>
                <li>Max-value entropy search for multi-objective bayesian optimization <em>(Rating: 2)</em></li>
                <li>Diversity-guided multi-objective bayesian optimization with batch evaluations <em>(Rating: 2)</em></li>
                <li>A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations <em>(Rating: 1)</em></li>
                <li>Random hypervolume scalarizations for provable multi-objective black box optimization <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2636",
    "paper_id": "paper-8f5562ead9861744a1192c1bef69283e25200aa8",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "NEHVI",
            "name_full": "Noisy Expected Hypervolume Improvement",
            "brief_description": "A Bayes-optimal acquisition function for multi-objective Bayesian optimization under noisy observations that integrates EHVI over posterior uncertainty in the in-sample Pareto frontier to avoid overfitting to noisy measurements.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "NEHVI (Noisy Expected Hypervolume Improvement)",
            "system_description": "NEHVI computes the acquisition value for candidate designs by integrating expected hypervolume improvement (EHVI) over the posterior distribution of the true (noise-free) function values at previously observed points. Practically this is approximated with Monte Carlo samples of the joint posterior across in-sample points and candidate points: for each posterior sample, compute the sample-specific Pareto frontier, compute HVI for candidate(s) relative to that frontier, then average. NEHVI therefore accounts for observation noise by marginalizing the uncertainty in the existing Pareto frontier and is one-step Bayes-optimal for hypervolume maximization in noisy and noiseless settings.",
            "application_domain": "General multi-objective experimental design and automated discovery tasks (applied in the paper to synthetic MOO benchmarks, adaptive bitrate policy tuning, and vehicle design optimization).",
            "resource_allocation_strategy": "Selects next experiment(s) by maximizing expected hypervolume improvement integrated over posterior uncertainty in previously observed (noisy) outcomes, i.e., allocate evaluation budget to candidate(s) with largest Monte Carlo-averaged HVI across posterior samples of in-sample function values.",
            "computational_cost_metric": "Wall-clock time for acquisition optimization (GPU/CPU), plus asymptotic computational complexity (time/space) expressed in Big-O using number of MC samples N, batch size q, number of past points n, number of objectives M and optimization iterations N_opt (see tradeoff fields).",
            "information_gain_metric": "Expected hypervolume improvement (EHVI) averaged over posterior samples of in-sample function values (i.e., Monte Carlo estimate of E_p[HVI(· | P)] ).",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Balances exploration and exploitation implicitly via the EHVI criterion applied across posterior uncertainty: EHVI rewards candidates that either improve Pareto hypervolume (exploitation) or lie in regions of high posterior uncertainty leading to expected HVI (exploration). By integrating over in-sample uncertainty, NEHVI avoids over-committing to noisy apparent optima.",
            "diversity_mechanism": "Diversity of solutions is encouraged implicitly via hypervolume maximization (which favors spread along the Pareto frontier) and submodularity guarantees that greedy batch selection encourages diverse sets; NEHVI's marginalization over in-sample uncertainty further discourages clumping caused by noisy observations.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of experiments / batch evaluation budgets and wall-time constraints (batch size q); also implicit computational budget for acquisition optimization.",
            "budget_constraint_handling": "Supports sequential greedy batch selection to choose q candidates (reducing the qd optimization to q sequential d-dimensional problems) with submodularity-based regret guarantees; uses Cached Box Decompositions (CBD) and sample average approximation to reduce acquisition optimization cost and enable larger batch sizes under computational limits.",
            "breakthrough_discovery_metric": "Breakthroughs are identified via large hypervolume improvements — candidate(s) that produce large increments in dominated hypervolume relative to the current Pareto frontier (averaged over posterior uncertainty).",
            "performance_metrics": "Log hypervolume gap (log difference between true Pareto hypervolume and found frontier) over evaluations; wall-clock acquisition optimization time on GPU/CPU; robustness across additive noise levels (experiments at 1%–30% of objective range). Reported empirical findings: NEHVI (and qNEHVI-1) outperform baselines across noisy benchmarks; shown robust up to 30% noise. Specific experimental settings include budgets such as 224 function evaluations in batch-scaling experiments.",
            "comparison_baseline": "Compared against EHVI / qEHVI (and qEHVI-PM-CBD), DGEMO, PESMO, MESMO, PFES, TSEMO, TS-TCH, ParEGO variants (qParEGO/qNParEGO), MOEA/D-EGO.",
            "performance_vs_baseline": "Empirically achieves state-of-the-art optimization performance on noisy multi-objective benchmarks in the paper; NEHVI avoids clumping seen in EHVI and posterior-mean plug-in EHVI, and produces better-distributed Pareto frontiers. qNEHVI and qNEHVI-1 outperform all compared methods on noisy benchmarks (qualitative and plotted results in paper), with qNEHVI-1 offering the fastest batch selection times on GPU.",
            "efficiency_gain": "Computational scaling improvement via CBD: reduces q-EHVI complexity from exponential in batch size (IEP formulation) to polynomial in q; wall-time speedups reported (figures show orders-of-magnitude improvements in acquisition time for larger q when using CBD and for qNEHVI-1 on GPU).",
            "tradeoff_analysis": "Paper analyzes tradeoffs between computational cost and expected information/utility: NEHVI integrates over in-sample uncertainty (increasing MC cost) but CBD and SAA (fixed samples) make optimization tractable; CBD trades a one-time cost of computing and caching N Pareto-frontier box decompositions per BO iteration against large savings when evaluating acquisition many times during optimization. They present Big-O time/space complexity formulas showing CBD yields polynomial dependence on batch size q (O(N_opt N M (n+q)^M q)) versus exponential dependence under IEP (O(N_opt N M n^M 2^q q)). Also present SAA convergence guarantees that deterministic acquisition (fixed base samples) converges to true NEHVI optimum as N increases.",
            "optimal_allocation_findings": "Key insight: marginalizing over uncertainty in previously observed (noisy) in-sample function values produces a one-step Bayes-optimal acquisition for hypervolume maximization in noisy settings; sequential greedy batch selection is justified by submodularity and has provable regret bound (no more than 1/e of optimal). Practical recommendation: use NEHVI with CBD and SAA (fixed MC base samples) to balance computational cost and information-theoretic optimality when allocating batch evaluations under noise.",
            "uuid": "e2636.0",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "qNEHVI",
            "name_full": "Parallel / Batch Noisy Expected Hypervolume Improvement",
            "brief_description": "A parallel/batch extension of NEHVI that selects q candidates using a sequential greedy approximation and cached box decompositions to make joint batch selection computationally feasible under noise.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "qNEHVI (parallel NEHVI)",
            "system_description": "Extends NEHVI to select batches of q candidates by maximizing expected joint hypervolume improvement integrated over in-sample posterior uncertainty. Joint optimization is approximated with a sequential greedy policy: choose candidates one at a time, holding previous selections fixed; for each stage, update cached MC Pareto frontiers and CBDs that include the already-chosen candidates. CBD reduces complexity from exponential to polynomial in q, and SAA with fixed base samples makes acquisition deterministic for gradient-based optimization.",
            "application_domain": "Same as NEHVI — multi-objective experimental design requiring parallel evaluations (e.g., A/B tests, high-throughput chemistry, parallel hardware tests).",
            "resource_allocation_strategy": "Allocates a batch of q experiments by sequential greedy maximization of the MC-approximated NEHVI; each candidate selection uses cached posterior samples and box decompositions (CBD) updated to include previously selected points within the batch.",
            "computational_cost_metric": "Wall-clock time and GPU/CPU memory; algorithmic complexity in Big-O in terms of MC samples N, batch size q, number of past points n, objectives M, and optimization iterations N_opt. Empirical wall-time measurements presented (GPU V100 and multi-core CPU).",
            "information_gain_metric": "q-NEHVI: Monte Carlo average of joint hypervolume improvement (q-EHVI) across posterior samples of in-sample function values.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Greedy sequential selection implicitly trades exploration and exploitation via NEHVI (each candidate is chosen to maximize expected marginal hypervolume gain given already-chosen batch members and uncertainty). Submodularity gives performance guarantees for greedy approximation.",
            "diversity_mechanism": "Hypervolume objective encourages coverage along Pareto frontier; sequential greedy selection with submodularity bound (regret ≤ 1/e of optimum) encourages diverse batches empirically and theoretically.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size q and total evaluation budget; computational budget for acquisition optimization.",
            "budget_constraint_handling": "Sequential greedy reduces joint q d-dimensional optimization to q sequential d-dimensional optimizations; CBD caches N per-sample decompositions to avoid recomputing expensive decompositions repeatedly, enabling larger q under fixed compute/memory limits.",
            "breakthrough_discovery_metric": "Marginal q-HVI per candidate (expected incremental dominated hypervolume contributed by candidate i given prior selections), averaged across posterior samples.",
            "performance_metrics": "Same hypervolume-gap and wall-time metrics as NEHVI; empirical experiments show qNEHVI achieves highest hypervolume for increasing batch sizes and scales more gracefully than baselines; reported experiments include a budget of 224 function evaluations and batch size sweeps.",
            "comparison_baseline": "qEHVI (IEP), qEHVI-PM-CBD (posterior mean plug-in with CBD), DGEMO, TSEMO, TS-TCH, qNParEGO, ParEGO variants, information-theoretic methods (PESMO/MESMO/PFES).",
            "performance_vs_baseline": "qNEHVI generally achieves the greatest hypervolume across batch sizes in experiments, outperforming qEHVI-PM-CBD and other baselines; CBD-enabled qNEHVI scales to batch sizes infeasible for IEP-based qEHVI.",
            "efficiency_gain": "CBD reduces time/space complexity from exponential in q (IEP) to polynomial in q; empirical acquisition optimization wall-times show CBD avoids out-of-memory errors on GPU and enables much larger q (plots in paper).",
            "tradeoff_analysis": "Paper quantifies tradeoffs via Big-O expressions: CBD approach time complexity: O(N_opt N M (n+q)^M q) vs IEP exponential dependence O(N_opt N M n^M 2^q q). The CBD saves computation at the cost of computing and caching N box decompositions per BO iteration (one-time per acquisition optimization).",
            "optimal_allocation_findings": "Sequential greedy qNEHVI is justified theoretically due to submodularity (expected qNEHVI is submodular), giving a worst-case approximation guarantee; practically recommended when batch parallelism is required and computational resources are constrained, using CBD and SAA to make batch selection tractable.",
            "uuid": "e2636.1",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "qNEHVI-1",
            "name_full": "Single-sample RFF Approximation of qNEHVI",
            "brief_description": "A computationally cheaper approximate variant of qNEHVI that uses a single approximate GP sample path generated via random Fourier features (RFF) to accelerate batch candidate optimization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "qNEHVI-1 (RFF single-sample approximation)",
            "system_description": "Instead of averaging over many posterior samples, qNEHVI-1 generates a single deterministic approximate GP sample path via Random Fourier Features (RFF) and optimizes HVI under that sample path for each sequential candidate. Because the RFF model is deterministic and cheap to evaluate, gradient-based optimization (including higher-order methods) can be applied efficiently, making batch selection (with CBD) very fast.",
            "application_domain": "Low-to-moderate dimensional multi-objective optimization where fast batch selection is needed (e.g., high-throughput experimental design).",
            "resource_allocation_strategy": "Allocates experiments by optimizing HVI under a single deterministic approximate GP sample path, selecting candidates sequentially (greedy) using CBD; this reduces computational cost at the expense of a cruder approximation to the expected objective.",
            "computational_cost_metric": "Wall-clock acquisition optimization time; number of RFF basis functions (e.g., paper uses 500) as a proxy for compute; memory for CBD still required.",
            "information_gain_metric": "Approximate sample-path HVI (not full expected-information metric); effectively approximates expected improvement by using one sampled function.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration arises from variability in the single sampled function path (Thompson-sampling-like behavior), while exploitation is achieved by choosing candidates that maximize HVI on that sample; being single-sample, this is a stochastic heuristic approximating the full NEHVI objective.",
            "diversity_mechanism": "Diversity arises from HVI objective on the sampled path and sequential greedy selection; RFF sampling across restarts or multiple RFFs could increase diversity but qNEHVI-1 as described uses a single RFF sample per candidate selection step.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget for acquisition optimization (favoring low wall-time) and experiment batch budgets.",
            "budget_constraint_handling": "Reduces acquisition computational cost by replacing expensive joint posterior evaluations with cheap RFF sample evaluations, enabling much faster batch selection and scaling to larger q when dimensionality is modest.",
            "breakthrough_discovery_metric": "HVI under the RFF sample path; large HVI on the sampled path is taken as proxy for high-impact candidates.",
            "performance_metrics": "Empirically among top performers for low-dimensional problems; achieves fastest batch selection times on GPU among tested methods and good anytime performance across q values. Paper reports qNEHVI-1 being an order-of-magnitude faster than qNEHVI for many problems (figures in appendix).",
            "comparison_baseline": "Compared to qNEHVI, TSEMO, DGEMO, qEHVI, ParEGO variants and others in experiments.",
            "performance_vs_baseline": "qNEHVI-1 often matches or comes very close to qNEHVI's optimization quality on low-dimensional problems while being substantially faster; outperforms TSEMO in speed and often in final hypervolume.",
            "efficiency_gain": "Orders-of-magnitude faster batch selection on GPU in many cases (paper reports qNEHVI-1 has the lowest wall time of any method tested on GPU across problems).",
            "tradeoff_analysis": "Paper notes a tradeoff: qNEHVI-1 gains large computational savings by using a single sample approximation but can be less robust in higher-dimensional spaces; qNEHVI (full MC) is more robust but costlier. Paper suggests RFF basis count and problem dimensionality determine the sweet spot.",
            "optimal_allocation_findings": "qNEHVI-1 is recommended when fast batch selection is critical and the search dimensionality is modest; for higher dimensions or when robustness to approximation error is needed, full qNEHVI is preferred.",
            "uuid": "e2636.2",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "CBD",
            "name_full": "Cached Box Decompositions",
            "brief_description": "A computational technique for reusing box decompositions of sampled Pareto frontiers to dramatically reduce repeated hypervolume/HVI computation when optimizing Monte Carlo acquisition functions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Cached Box Decompositions (CBD)",
            "system_description": "CBD uses a fixed set of posterior samples of in-sample function values to compute per-sample Pareto frontiers and box decompositions once per BO iteration and caches these decompositions for repeated evaluation of acquisition functions during inner-loop optimization. Under sequential greedy batch selection, cached decompositions are incrementally updated when previously selected batch points are added. CBD enables efficient batched tensor computation (with padding) and reduces time/space complexity of parallel EHVI/NEHVI from exponential in batch size q (IEP method) to polynomial in q.",
            "application_domain": "Computational acceleration of MOBO acquisition evaluation — applicable in any multi-objective BO pipeline that uses EHVI or HVI computations (e.g., materials, chemistry, policy tuning).",
            "resource_allocation_strategy": "Not an allocation policy itself; it enables more aggressive allocation strategies (e.g., large q batches and gradient-based acquisition optimization) by reducing the computational cost of evaluating/optimizing acquisition functions.",
            "computational_cost_metric": "Big-O time and space complexity in terms of MC samples N, batch size q, number of prior points n, number of objectives M, and optimization iterations N_opt. Empirical wall-clock times measured on GPU/CPU and memory (OOM avoidance).",
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Indirect: by reducing acquisition evaluation cost it enables more thorough optimization (more multi-starts, more gradient steps), indirectly improving the exploration/exploitation balance realizable in practice.",
            "diversity_mechanism": "Indirect: CBD enables fast computation of hypervolume objectives that inherently encourage Pareto diversity; it does not itself impose explicit diversity heuristics.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Computational budget (time, memory) for acquisition optimization; also supports large experimental batch budgets by making large-batch acquisition tractable.",
            "budget_constraint_handling": "Caches expensive per-sample decompositions (one-time per BO iteration) to avoid recomputing them at each acquisition evaluation; pads decompositions to enable efficient batched tensor operations; supports pruning dominated in-sample points to reduce decomposition size.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Empirical reductions in acquisition optimization wall time and memory usage enabling larger batch sizes; paper demonstrates CBD avoids GPU OOM and scales to batch sizes infeasible for IEP; complexity reductions outlined mathematically (exponential→polynomial).",
            "comparison_baseline": "IEP (inclusion-exclusion principle) approach for computing q-EHVI, which has exponential time/space scaling in q.",
            "performance_vs_baseline": "CBD and IEP are mathematically equivalent in computed acquisition values when using common randomness, but CBD reduces time/space complexity significantly; asymptotic comparison: CBD time complexity polynomial in q versus IEP exponential(2^q) dependence.",
            "efficiency_gain": "Asymptotic gain: CBD reduces acquisition time/space from O(... 2^q q ...) to O(... (n+q)^M q ...); empirical speed-ups shown in acquisition wall-time plots and enables scaling to larger q without OOM.",
            "tradeoff_analysis": "CBD trades a one-time cost of computing N per-sample box decompositions for large savings during inner-loop acquisition optimization; SAA (fixed base samples) further stabilizes computation and allows deterministic gradients for faster optimizer convergence.",
            "optimal_allocation_findings": "Practical recommendation: use CBD (and SAA) when optimizing MC-based EHVI/NEHVI acquisition functions to allow gradient-based optimization and to scale batch sizes while controlling computational cost.",
            "uuid": "e2636.3",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "EHVI / qEHVI",
            "name_full": "Expected Hypervolume Improvement (and its parallel q-EHVI variant)",
            "brief_description": "A family of acquisition functions that extend Expected Improvement to multi-objective problems by maximizing expected increase in Pareto-dominated hypervolume; qEHVI is the batch/parallel generalization that considers joint hypervolume improvement of q candidates.",
            "citation_title": "Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization.",
            "mention_or_use": "use",
            "system_name": "EHVI / qEHVI",
            "system_description": "EHVI computes the expectation of hypervolume improvement for a single candidate under the posterior; qEHVI generalizes this to joint sets of q candidates by computing expected joint hypervolume improvement (often via MC and an inclusion-exclusion principle). Analytic formulas exist under strong independence assumptions; practical methods use box decompositions and MC. qEHVI via IEP suffers exponential scaling in q; CBD provides polynomial alternative.",
            "application_domain": "Multi-objective Bayesian optimization across science and engineering domains (used as baseline in experiments).",
            "resource_allocation_strategy": "Selects experiments by maximizing (expected) hypervolume improvement; in practice qEHVI may be approximated via sequential greedy selection due to optimization complexity.",
            "computational_cost_metric": "Time/space complexity (IEP exponential in q), wall-clock acquisition optimization time; number of MC samples N.",
            "information_gain_metric": "Expected hypervolume improvement (EHVI) — a decision-theoretic expected-utility measure rather than mutual-information.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "EHVI balances exploration and exploitation through the posterior: candidates with high expected hypervolume improvement are either promising (exploitation) or uncertain (exploration) depending on posterior predictive distribution.",
            "diversity_mechanism": "Hypervolume objective itself favors diverse Pareto coverage; qEHVI (joint HVI) explicitly considers interactions among candidates to avoid redundant batch members (but exact joint computation is expensive).",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch size q; computational constraints (IEP scaling limits q).",
            "budget_constraint_handling": "Common practical approach: sequential greedy selection and CBD or plug-in posterior-mean heuristics (EHVI-PM) to reduce compute.",
            "breakthrough_discovery_metric": "Expected increase in dominated hypervolume (EHVI) — large EHVI values indicate candidates with breakthrough potential.",
            "performance_metrics": "Hypervolume gap over number of evaluations; EHVI is one-step Bayes-optimal in noiseless, fully sequential settings.",
            "comparison_baseline": "Compared to NEHVI, NEHVI-PM (posterior mean plug-in), and other MOBO methods in experiments.",
            "performance_vs_baseline": "EHVI works well when observations are noise-free; in noisy settings naive EHVI (using observed noisy in-sample points) can be misled and produce clumped Pareto points, while NEHVI (which marginalizes in-sample uncertainty) performs better. EHVI-PM (posterior mean plug-in) partially mitigates noise but can still lead to clustering.",
            "efficiency_gain": "Analytic EHVI formulas exist in special cases; parallel qEHVI IEP formulation is expensive but CBD can reduce cost to polynomial.",
            "tradeoff_analysis": "Paper contrasts EHVI's one-step Bayes-optimality in noiseless sequential cases with NEHVI's Bayes-optimality in noisy settings; highlights computational tradeoffs for qEHVI versus CBD-based methods.",
            "optimal_allocation_findings": "Recommendation: in noisy settings, marginalizing uncertainty over in-sample values (NEHVI) is preferable to naive EHVI; for batch settings, use CBD and sequential greedy selection to balance compute and performance.",
            "uuid": "e2636.4",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "DGEMO",
            "name_full": "Diversity-Guided Multi-Objective Bayesian Optimization",
            "brief_description": "A parallel MOBO method that greedily maximizes hypervolume improvement while explicitly encouraging diversity among sampled designs.",
            "citation_title": "Diversity-guided multi-objective bayesian optimization with batch evaluations.",
            "mention_or_use": "use",
            "system_name": "DGEMO",
            "system_description": "DGEMO constructs batches by greedily maximizing HVI but incorporates explicit diversity guidance in selecting batch members to avoid redundant samples; it scales well to large batch sizes but (as implemented) does not account for noisy observations.",
            "application_domain": "Parallel multi-objective optimization tasks requiring diverse batches (e.g., engineering design, expensive simulations).",
            "resource_allocation_strategy": "Greedy selection maximizing a combination of HVI and a diversity-guiding term (details in DGEMO paper); aims to allocate batch budget to diverse, high-impact candidates.",
            "computational_cost_metric": "Designed for scalability—empirically scales to large batch sizes; wall-clock time depending on implementation (paper compares wall-times).",
            "information_gain_metric": "HVI-based utility (not explicit mutual information); diversity term supplements HVI.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration via explicit diversity encouragement in batch formation; exploitation via HVI maximization.",
            "diversity_mechanism": "Explicitly includes diversity-guiding heuristics to spread batch members (primary selling point of DGEMO).",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Large batch sizes (q) and total evaluation budget; computational time/throughput budget.",
            "budget_constraint_handling": "Greedy batch construction that scales well to large q; however, does not account for observation noise in original formulation.",
            "breakthrough_discovery_metric": "HVI plus diversity-driven scoring — candidates that increase hypervolume and increase frontier spread are favored.",
            "performance_metrics": "Reported to scale well to large q; in this paper DGEMO is included as baseline and performs well in some settings but is outperformed by NEHVI under noisy observations.",
            "comparison_baseline": "Compared experimentally to NEHVI, qNEHVI-1 and others.",
            "performance_vs_baseline": "DGEMO scales well to large q but does not handle noisy observations; in experiments DGEMO showed clumping or lower performance relative to NEHVI on noisy benchmarks.",
            "efficiency_gain": "Designed for large-batch scalability; empirical runtime depends on implementation.",
            "tradeoff_analysis": "Paper notes DGEMO scales to large batch sizes but lacks noise-awareness; tradeoff is computational scalability vs. handling noisy observations robustly.",
            "optimal_allocation_findings": "DGEMO is effective when diverse batch exploration is primary objective and noise is negligible; if observations are noisy, marginalizing in-sample uncertainty (NEHVI) yields better Pareto discovery.",
            "uuid": "e2636.5",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "PESMO",
            "name_full": "Predictive Entropy Search for Multi-Objective Optimization",
            "brief_description": "An information-theoretic acquisition function that selects experiments to reduce uncertainty (entropy) about the Pareto frontier, and is designed to be robust to noise in some variants.",
            "citation_title": "Predictive entropy search for multi-objective bayesian optimization",
            "mention_or_use": "use",
            "system_name": "PESMO",
            "system_description": "PESMO is an entropy-based MOBO method that aims to select evaluations that maximally reduce posterior entropy about the Pareto frontier. It computes expected information gain about the Pareto set/frontier, typically relying on complex approximations due to intractable entropies. PESMO (in original form) can account for noise but involves expensive computations and approximations.",
            "application_domain": "Multi-objective optimization tasks where information about Pareto frontier structure is critical and evaluations may be noisy.",
            "resource_allocation_strategy": "Allocates experiments by maximizing expected reduction in entropy over the Pareto frontier (information gain), subject to approximation/tractability constraints.",
            "computational_cost_metric": "High wall-clock computational cost due to intractable entropy computations and required approximations; often slower acquisition optimization than gradient-based EHVI/CBD approaches.",
            "information_gain_metric": "Expected information gain (reduction in entropy of Pareto frontier / Pareto set).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explicit exploration via maximizing expected information gain; exploitation occurs when information gain aligns with improving objective values.",
            "diversity_mechanism": "Entropy criterion implicitly promotes sampling in regions that reduce uncertainty about frontier geometry, which can lead to diverse sampling but not necessarily direct diversity heuristics.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget for acquisition optimization and evaluation budget.",
            "budget_constraint_handling": "Requires approximations and expensive optimization; in practice can be slow and was run with fewer replications in experiments due to runtime.",
            "breakthrough_discovery_metric": "Information gain about Pareto frontier rather than explicit hypervolume improvement; breakthrough implies a large reduction in uncertainty about frontier location or detection of a previously unknown Pareto region.",
            "performance_metrics": "Measured by hypervolume gap over evaluations but PESMO was slower to optimize and performed poorly relative to NEHVI in experiments in this paper.",
            "comparison_baseline": "Compared experimentally to NEHVI, MESMO, PFES and others.",
            "performance_vs_baseline": "Information-theoretic methods (PESMO, MESMO, PFES) performed worse than NEHVI on the tested benchmarks in this paper and were slower; PESMO was able to handle noise in principle but relied on approximations that proved computationally challenging.",
            "efficiency_gain": "No efficiency gain reported; rather PESMO is noted as computationally intensive requiring approximations.",
            "tradeoff_analysis": "Paper comments that while information-theoretic methods allow decoupled evaluations (useful when objectives have different evaluation costs), optimizing them is non-trivial and current implementations may underperform compared to NEHVI when computational constraints are tight.",
            "optimal_allocation_findings": "Information-theoretic acquisition can be principled for budgeted, decoupled evaluations (when querying some objectives is costlier), but requires improved optimization procedures to be competitive in practical noisy MOBO settings.",
            "uuid": "e2636.6",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "MESMO",
            "name_full": "Max-value Entropy Search for Multi-Objective Bayesian Optimization",
            "brief_description": "An entropy-based MOBO method that extends max-value entropy search to multi-objective settings to choose evaluations that reduce uncertainty about optimal values.",
            "citation_title": "Max-value entropy search for multi-objective bayesian optimization",
            "mention_or_use": "use",
            "system_name": "MESMO",
            "system_description": "MESMO is an information-theoretic acquisition function that targets reduction in uncertainty regarding the maximal values (Pareto-optimal values) by sampling points expected to provide large entropy reductions about the Pareto-optimal levels. The authors of this paper extended MESMO to handle noisy observations using noisy information gain from Takeno et al. [52] for experiments.",
            "application_domain": "Multi-objective optimization tasks where quantifying and reducing uncertainty about optima is desired.",
            "resource_allocation_strategy": "Selects experiments by maximizing expected reduction in entropy about max-values / Pareto frontier.",
            "computational_cost_metric": "High computational cost due to intractable entropy approximations and expensive optimization (empirically slower than NEHVI/CBD).",
            "information_gain_metric": "Expected information gain (entropy reduction) about the Pareto max-values/frontier.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration is driven by information maximization (entropy reduction); exploitation occurs when information gain coincides with high predicted performance.",
            "diversity_mechanism": "Implicit via information-seeking behavior; not an explicit diversity heuristic.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget and evaluation budget; parallelization approximate via sample-based methods.",
            "budget_constraint_handling": "Relies on approximations; the authors extended MESMO for noisy observations using noisy information gain approximations for parallelization.",
            "breakthrough_discovery_metric": "Entropy reduction about Pareto-optimal values; large information gain implies potential for discovering impactful (breakthrough) Pareto points.",
            "performance_metrics": "Reported hypervolume gap; MESMO performed worse than NEHVI on tested noisy benchmarks in this paper.",
            "comparison_baseline": "Compared experimentally against NEHVI and other methods.",
            "performance_vs_baseline": "Generally underperformed NEHVI in the paper's experiments, and was slower due to complex entropy computations.",
            "efficiency_gain": "None reported in this paper; MESMO is computationally heavy.",
            "tradeoff_analysis": "Paper notes information-theoretic methods' potential for decoupled queries but highlights practical optimization difficulty and computational expense compared with EHVI-based CBD approaches.",
            "optimal_allocation_findings": "While theoretically principled for maximizing information, MESMO requires further practical improvements to trade off computational cost and performance effectively in noisy, parallel MOBO.",
            "uuid": "e2636.7",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "PFES",
            "name_full": "Pareto-Frontier Entropy Search",
            "brief_description": "An entropy-based MOBO acquisition that aims to reduce entropy over the Pareto frontier (PFES), similar in spirit to PESMO and MESMO.",
            "citation_title": "Multi-objective Bayesian optimization using pareto-frontier entropy",
            "mention_or_use": "use",
            "system_name": "PFES",
            "system_description": "PFES is an entropy-based acquisition that constructs an information gain objective focused on the Pareto frontier; like PESMO/MESMO it requires approximations to make entropy computations tractable and can be computationally intensive.",
            "application_domain": "Multi-objective optimization where explicit uncertainty quantification of the Pareto frontier is desired.",
            "resource_allocation_strategy": "Allocates experiments by maximizing expected reduction in entropy over the Pareto frontier.",
            "computational_cost_metric": "High wall-clock time due to entropy approximations and optimization complexity; in this paper PFES used finite-difference gradient approximations, adding to cost.",
            "information_gain_metric": "Expected entropy reduction over Pareto frontier.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration by targeting regions that reduce uncertainty about the frontier; exploitation occurs when reducing uncertainty aligns with improving objectives.",
            "diversity_mechanism": "Implicit via information-seeking across frontier regions; no explicit diversity heuristic beyond entropy objective.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational evaluation budget; acquisition optimization budget.",
            "budget_constraint_handling": "Approximation-heavy; computational cost limits practical application to larger problems in experiments.",
            "breakthrough_discovery_metric": "Information-theoretic reduction in uncertainty about PF; not a hypervolume metric directly.",
            "performance_metrics": "Measured via hypervolume gap; in paper PFES underperformed NEHVI and incurred higher computational cost.",
            "comparison_baseline": "Compared experimentally to NEHVI and other MOBO baselines.",
            "performance_vs_baseline": "PFES did not match NEHVI's performance on noisy benchmarks; slower acquisition optimization.",
            "efficiency_gain": "None reported; PFES is computationally intensive in current implementations.",
            "tradeoff_analysis": "PFES demonstrates the classic tradeoff: solving a more informative objective (entropy) is computationally costly and may underperform less costly but better-optimized heuristics (NEHVI with CBD) in practice.",
            "optimal_allocation_findings": "Information-theoretic PFES may be valuable when decoupled, cost-differential objective evaluations are central, but current methods' optimization and approximation overhead limit their practical competitiveness.",
            "uuid": "e2636.8",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "TSEMO",
            "name_full": "Thompson Sampling Evolutionary Multi-objective Optimization (TSEMO)",
            "brief_description": "A heuristic MOBO method that uses Thompson sampling to draw approximate GP sample functions (via RFFs) and optimizes those samples using an evolutionary algorithm (NSGA-II), selecting candidates from the resulting population.",
            "citation_title": "Efficient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm.",
            "mention_or_use": "use",
            "system_name": "TSEMO",
            "system_description": "TSEMO draws random function samples from GP surrogates (via Random Fourier Features) and uses NSGA-II to find Pareto-optimal sets on each sampled function; a subset of points from the evolutionary population is then chosen (via greedy HVI or heuristics) to form a batch. It is robust to noise because Thompson sampling naturally incorporates posterior uncertainty but relies on expensive zero-order optimization (EA).",
            "application_domain": "Multi-objective optimization where sampling-based exploration is preferred and gradient-free optimization is acceptable (engineering, simulation-heavy domains).",
            "resource_allocation_strategy": "Allocates experiments by optimizing sampled functions (Thompson sampling), effectively exploring according to posterior randomness; candidate selection often involves choosing high-HVI points from the EA population.",
            "computational_cost_metric": "Optimization cost dominated by NSGA-II runs on sampled functions (zeroth-order), making it slower than gradient-based EHVI/CBD approaches; wall-clock time substantial for large problems.",
            "information_gain_metric": "Implicit via Thompson sampling (posterior sampling) rather than explicit mutual information or expected improvement.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration via randomness of sampled functions (Thompson sampling); exploitation by optimizing those samples and selecting promising candidates.",
            "diversity_mechanism": "NSGA-II population provides diverse candidate pool; subsequent selection may use HVI to pick diverse, high-value points.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget for EA optimization and total experimental budget.",
            "budget_constraint_handling": "Heuristic; can be computationally heavy due to EA usage; in paper, TSEMO was slower and placed mid-pack in performance.",
            "breakthrough_discovery_metric": "Candidates selected from high-performing regions of sampled function paths; large improvements on sampled paths suggest potential breakthroughs.",
            "performance_metrics": "Hypervolume gap and wall-time; TSEMO performed moderately relative to other baselines, slower than gradient-based CBD methods.",
            "comparison_baseline": "Compared to qNEHVI-1 (which uses RFFs but optimizes with gradients), DGEMO, qEHVI, and others.",
            "performance_vs_baseline": "TSEMO provided robustness to noise but was typically slower and less efficient than qNEHVI-1 and NEHVI with CBD; it occupied a middle performance tier in experiments.",
            "efficiency_gain": "No major efficiency gain relative to gradient-based EHVI/CBD approaches; qNEHVI-1 obtained similar or better results much faster by optimizing sample paths with gradients rather than EA.",
            "tradeoff_analysis": "Tradeoff: Thompson sampling + EA yields robustness and diversity at cost of computational speed; alternative RFF+gradient optimization (qNEHVI-1) can be faster while retaining benefits.",
            "optimal_allocation_findings": "TSEMO is a reasonable heuristic when gradient information is unavailable or users prefer sampling-based methods, but gradient-based CBD-enabled methods offer better computational efficiency for many MOBO tasks.",
            "uuid": "e2636.9",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "ParEGO / qParEGO / qNParEGO",
            "name_full": "ParEGO and batch/noisy extensions (qParEGO, qNParEGO)",
            "brief_description": "Scalarization-based MOBO methods that reduce multi-objective problems to single-objective ones via random scalarizations (e.g., augmented Chebyshev) and then apply single-objective BO (e.g., EI); batch and noisy variants extend this idea for parallel evaluation and noisy observations.",
            "citation_title": "Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems.",
            "mention_or_use": "use",
            "system_name": "ParEGO family (ParEGO, qParEGO, qNParEGO)",
            "system_description": "ParEGO uses random scalarizations (augmented Chebyshev) to convert MOO to a scalar BO problem and optimizes expected improvement; qParEGO extends to batch by using multiple scalarizations in parallel (often optimized by an EA like MOEA/D). qNParEGO is a noisy variant that attempts to incorporate observation noise into scalarized acquisition computations.",
            "application_domain": "Multi-objective optimization where scalarization is acceptable or simpler BO tools are preferred; used as baseline in experiments.",
            "resource_allocation_strategy": "Allocates evaluations by sampling scalarization weights and optimizing the corresponding single-objective acquisition (EI), thereby spreading evaluations across different scalarizations to cover diverse Pareto regions.",
            "computational_cost_metric": "Wall-clock acquisition optimization time; complexity grows with number of scalarizations and use of EA for parallelization.",
            "information_gain_metric": "Expected Improvement on scalarized objectives (not explicit information-theoretic metric).",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration via randomization of scalarization weights (diversifies search); exploitation via EI on scalarized objective.",
            "diversity_mechanism": "Multiple random scalarizations produce diverse Pareto candidates; MOEA/D or parallel scalarization approaches expand diversity across batch.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch evaluation budgets and computational cost of optimizing multiple scalarizations.",
            "budget_constraint_handling": "Batch variants run multiple scalarized optimizations in parallel (using MOEA/D or greedy selection) to utilize batch budget; noisy variant attempts to account for observation noise in scalarization evaluations.",
            "breakthrough_discovery_metric": "High scalarized EI values indicating large improvement under particular weightings; discovery of extreme Pareto trade-offs via varied scalarizations.",
            "performance_metrics": "Hypervolume gap and wall-time; qParEGO/qNParEGO sometimes underperform EHVI-based approaches on noisy benchmarks in the paper.",
            "comparison_baseline": "Compared to NEHVI, qNEHVI-1, qEHVI, and other MOBO methods.",
            "performance_vs_baseline": "ParEGO family can be competitive in some settings but generally was outperformed by qNEHVI and qNEHVI-1 on the noisy benchmarks studied here.",
            "efficiency_gain": "Batch variants can exploit parallel resources but may require population-based optimizers (EA) increasing computational cost.",
            "tradeoff_analysis": "Scalarization trades simplicity and parallelizability for potential bias in covering the Pareto frontier; random weight sampling helps but does not replace marginalizing in-sample noise as done in NEHVI.",
            "optimal_allocation_findings": "ParEGO-type methods are pragmatic when simpler scalarization-based BO pipelines are in use, but marginalizing uncertainty and using hypervolume-based acquisition (NEHVI) is preferable under noisy multi-objective settings.",
            "uuid": "e2636.10",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "TS-TCH",
            "name_full": "Thompson Sampling with Random Chebyshev Scalarizations",
            "brief_description": "A hybrid approach that combines Thompson sampling with random Chebyshev scalarizations to produce robust, scalarized multi-objective optimization via posterior sampling.",
            "citation_title": "A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations.",
            "mention_or_use": "use",
            "system_name": "TS-TCH",
            "system_description": "TS-TCH applies Thompson sampling to randomly sampled Chebyshev scalarizations; posterior samples are optimized and used to select candidates. Thompson sampling confers robustness to noise when objectives are scalarized, and random scalarizations help cover the Pareto frontier.",
            "application_domain": "Multi-objective BO where scalarization combined with sampling is used; paper uses TS-TCH as a baseline.",
            "resource_allocation_strategy": "Allocation via sampled scalarized objectives (Thompson sampling), choosing candidates that are optimal under sampled scalarizations.",
            "computational_cost_metric": "Wall-clock time (relies on optimizing sampled scalarizations; in experiments optimized approximate functions using RFFs and gradient methods).",
            "information_gain_metric": "Implicit via Thompson sampling randomness rather than explicit information metrics.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration via randomness of Thompson samples; exploitation from optimizing sampled scalarizations.",
            "diversity_mechanism": "Random scalarizations produce diverse trade-offs; selection across sampled weights yields diversity in candidates.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch or sequential evaluation budgets and computational budget for optimization of sampled scalarizations.",
            "budget_constraint_handling": "Optimizes sampled scalarizations (RFF approximations) using gradient-based methods for speed; compared in experiments to other methods.",
            "breakthrough_discovery_metric": "High scalarized performance on sampled weight indicates candidate with potential breakthrough under those preferences.",
            "performance_metrics": "Hypervolume gap and wall-time; TS-TCH generally in middle of pack in experiments.",
            "comparison_baseline": "Compared experimentally to NEHVI, qNEHVI-1, TSEMO, qEHVI, etc.",
            "performance_vs_baseline": "TS-TCH offered robustness and moderate performance but was outperformed by NEHVI variants on noisy benchmarks.",
            "efficiency_gain": "Faster than some EA-based heuristics when using RFF+gradients; still typically slower or less effective than CBD-enabled qNEHVI-1 in experiments.",
            "tradeoff_analysis": "Combines simple scalarization sampling with Thompson sampling for noise robustness at the cost of potential inefficiencies in covering entire Pareto set compared to NEHVI's expected hypervolume objective.",
            "optimal_allocation_findings": "TS-TCH is a practical baseline for noise-robust scalarized BO, but hypervolume-integrated approaches with proper noise marginalization (NEHVI) outperform it in the paper's benchmarks.",
            "uuid": "e2636.11",
            "source_info": {
                "paper_title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement",
                "publication_date_yy_mm": "2021-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Predictive entropy search for multi-objective bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Max-value entropy search for multi-objective bayesian optimization",
            "rating": 2
        },
        {
            "paper_title": "Diversity-guided multi-objective bayesian optimization with batch evaluations",
            "rating": 2
        },
        {
            "paper_title": "A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations",
            "rating": 1
        },
        {
            "paper_title": "Random hypervolume scalarizations for provable multi-objective black box optimization",
            "rating": 1
        }
    ],
    "cost": 0.03138175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement</h1>
<p>Samuel Daulton<br>Facebook, University of Oxford<br>sdaulton@fb.com</p>
<p>Maximilian Balandat<br>Facebook<br>balandat@fb.com</p>
<p>Eytan Bakshy<br>Facebook<br>ebakshy@fb.com</p>
<h4>Abstract</h4>
<p>Optimizing multiple competing black-box objectives is a challenging problem in many fields, including science, engineering, and machine learning. Multi-objective Bayesian optimization (MOBO) is a sample-efficient approach for identifying the optimal trade-offs between the objectives. However, many existing methods perform poorly when the observations are corrupted by noise. We propose a novel acquisition function, NEHVI, that overcomes this important practical limitation by applying a Bayesian treatment to the popular expected hypervolume improvement (EHVI) criterion and integrating over this uncertainty in the Pareto frontier. We argue that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique. Through this lens, we derive a natural parallel variant, $q$ NEHVI, that reduces computational complexity of parallel EHVI from exponential to polynomial with respect to the batch size. $q$ NEHVI is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments, and we show that it can be optimized effectively with gradient-based methods via sample average approximation. Empirically, we demonstrate not only that $q$ NEHVI is substantially more robust to observation noise than existing MOBO approaches, but also that it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments.</p>
<h2>1 Introduction</h2>
<p>Black-box optimization problems that involve multiple competing noisy objectives are ubiquitous in science and engineering. For example, a real-time communications service may be interested in tuning the parameters of a control policy to adapt video quality in real time in order to maximize video quality and minimize latency [10, 17]. In robotics, scientists may seek to design hardware components that maximize locomotive speed and minimize energy expended [8, 38]. In agriculture, development agencies may seek to balance crop yield and environmental impact [28]. For such multi-objective optimization (MOO) problems, there typically is no single solution that is best with respect to all objectives. Rather, the goal is to identify the Pareto frontier: a set of optimal trade-offs such that improving one objective means deteriorating another. In many cases, the objectives are expensive to evaluate. For instance, randomized trials used in agriculture and the internet industry may take weeks or months to conduct and incur opportunity costs, and manufacturing and testing hardware is both costly and time-consuming. Therefore, it is imperative to be able to identify good trade-offs with as few objective evaluations as possible.</p>
<p>Bayesian optimization (BO), a method for efficient global black-box optimization, is often used to tackle such problems. BO employs a probabilistic surrogate model in conjunction with an acquisition function to navigate the trade-off between exploration (evaluating designs with high uncertainty) and exploitation (evaluating designs that are believed to be optimal). Although a significant number of works have explored multi-objective Bayesian optimization (MOBO), most available methods</p>
<p>$[3,39,51,60]$ do not take into account the fact that, in practice, observations are often subject to noise. For example, results of an A/B test are highly variable due to heterogeneity in the underlying user population and other factors. Agricultural trials are affected by the stochastic nature of plant growth and environmental factors such as soil composition or wind currents. In robotics, devices are subject to manufacturing tolerances, and observations of quantities such as locomotive speed and efficiency may be corrupted by measurement error from noisy sensors and environmental factors such as temperature or surface friction. While previous work has shown that a principled treatment of noisy observations can significantly improve optimization performance in the single-objective case [24; 37], this issue is understudied in the multi-objective setting. Furthermore, many applications in which evaluations take a long time require evaluating large batches of candidates in parallel in order to achieve reasonable throughput. For example, when firms optimize systems via A/B tests, it may take several weeks to test any particular configuration. Because of this, large batches of candidate policies are tested simultaneously [36]. In biochemistry and materials design, dozens of tests can be conducted parallel on a single microplate [63]. Even in sophisticated high throughput chemistry settings, these batches may take several hours or days to set up and evaluate [42]. Most existing MOBO methods, however, are either designed for purely sequential optimization [3; 51] or do not scale well to large batch sizes [11].
Contributions: In this work, we propose a novel MOBO algorithm, based on expected hypervolume improvement (EHVI), that scales to highly parallel evaluations of noisy objectives. Our approach is made possible by a general-purpose, differentiable, cached box decomposition (CBD) implementation that dramatically speeds up critical computations needed to account for uncertainty introduced by noisy observations and generate new candidate points for highly parallel batch or asynchronous evaluation. In particular, our CBD-based approach solves the fundamental problem of scaling parallel EHVI-based methods to large batch sizes, reducing time and space complexity from exponential to polynomial. Our proposed algorithm, noisy expected hypervolume improvement (NEHVI), is the one-step Bayes-optimal policy for hypervolume improvement and provides state-of-the-art performance across a variety of benchmarks. To our knowledge, our work provides the most extensive evaluation of noisy parallel MOBO to date. A high-quality implementation of $q$ NEHVI, as well as many of the baselines considered here, will be made available as open-source software upon publication.</p>
<h1>2 Preliminaries</h1>
<p>Our goal is to find the set of optimal designs $\boldsymbol{x}$ over a bounded set $\mathcal{X} \subset \mathbb{R}^{d}$ that maximize one or more objectives $\boldsymbol{f}(\boldsymbol{x}) \in \mathbb{R}^{M}$, with no known analytical expression nor gradient information of $\boldsymbol{f}$.
Multi-Objective Optimization (MOO) aims to identify the set of Pareto optimal objective tradeoffs. We say a solution $\boldsymbol{f}(\boldsymbol{x})=\left[f^{(1)}(\boldsymbol{x}), \ldots, f^{(M)}(\boldsymbol{x})\right]$ dominates another solution $\boldsymbol{f}(\boldsymbol{x}) \succ \boldsymbol{f}\left(\boldsymbol{x}^{\prime}\right)$ if $f^{(m)}(\boldsymbol{x}) \geq f^{(m)}\left(\boldsymbol{x}^{\prime}\right)$ for $m=1, \ldots, M$ and $\exists m \in{1, \ldots, M}$ s.t. $f^{(m)}(\boldsymbol{x})&gt;f^{(m)}\left(\boldsymbol{x}^{\prime}\right)$. We define the Pareto frontier as $\mathcal{P}^{<em>}=\left{\boldsymbol{f}(\boldsymbol{x}): \boldsymbol{x} \in \mathcal{X}, \nexists \boldsymbol{x}^{\prime} \in \mathcal{X}\right.$ s.t. $\left.\boldsymbol{f}\left(\boldsymbol{x}^{\prime}\right) \succ \boldsymbol{f}(\boldsymbol{x})\right}$, and denote the set of Pareto optimal designs as $\mathcal{X}^{</em>}=\left{\boldsymbol{x}: \boldsymbol{f}(\boldsymbol{x}) \in \mathcal{P}^{<em>}\right}$. Since the Pareto frontier (PF) is often an infinite set of points, MOO algorithms usually aim to identify a finite approximate PF $\mathcal{P}$. A natural measure of the quality of a PF is the hypervolume of the region of objective space that is dominated by the PF and bounded from below by a reference point. Provided with the approximate PF, the decision-maker can select a particular Pareto optimal trade-off according to their preferences.
Bayesian Optimization (BO) is a sample-efficient optimization method that leverages a probabilistic surrogate model to make principled decisions to balance exploration and exploitation [19; 50]. Typically, the surrogate is a Gaussian Process (GP), a flexible, non-parametric model known for its well-calibrated predictive uncertainty [47]. To decide which points to evaluate next, BO employs an acquisition function $\alpha(\cdot)$ that specifies the value of evaluating a set of new points $\boldsymbol{x}$ based on the surrogate's predictive distribution at . While evaluating the true black-box function $\boldsymbol{f}$ is timeconsuming or costly, evaluating the surrogate is cheap and relatively fast; therefore, numerical optimization can be used to find the maximizer of the acquisition function $\boldsymbol{x}^{</em>}=\arg \max _{\boldsymbol{x} \in \mathcal{X}} \alpha(\boldsymbol{x})$ to evaluate next on the black-box function. BO sequentially selects new points to evaluate and updates the model to incorporate the new observations.
Evolutionary algorithms (EAs) such as NSGA-II [12] are a popular choice for solving MOO problems (see Zitzler et al. [67] for a review of various other approaches). However, EAs generally suffer from high sample complexity, rendering them infeasible for optimizing expensive-to-evaluate black-box</p>
<p>functions. Multi-objective Bayesian optimization (MOBO), which combines a Bayesian surrogate with an acquisition function designed for MOO, provides a much more sample-efficient alternative.</p>
<h1>3 Related Work</h1>
<p>Methods based on hypervolume improvement (HVI) seek to expand the volume of the objective space dominated by the Pareto frontier. Expected hypervolume improvement (EHVI) [16] is a natural extension of the popular expected improvement (EI) [29] acquisition function to the MOO setting. Recent work has led to efficient computational paradigms using box decomposition algorithms [59] and practical enhancements such as support for parallel candidate generation and gradient-based acquisition optimization [11, 58]. However, EHVI still suffers from some limitations, including (i) the assumption that observations are noise-free, and (ii) the exponential scaling of its batch variant, $q$ EHVI, in the batch size $q$, which precludes large-batch optimization. DGEMO [39] is a recent method for parallel MOBO that greedily maximizes HVI while balancing the diversity of the design points being sampled. Although DGEMO scales well to large batch sizes, it does not account for noisy observations. TSEMO [5] is a Thompson sampling (TS) heuristic that can acquire batches of points by optimizing a random fourier feature (RFF) [46] approximation of a GP surrogate using NSGA-II and selecting a subset of points from the EA's population to sequentially greedily maximize HVI. This heuristic approach for maximizing HVI currently has no theoretical guarantees and relies on zeroth-order optimization methods, which tend to be slower and exhibit worse optimization performance than gradient-based approaches.
Entropy-based methods such as PESMO [25], MESMO [3], and PFES [51] are an alternative to EHVI. Of these three methods, PESMO is the only one that accounts for observation noise. However, PESMO involves intractable entropy computations and therefore relies on complex approximations, as well as challenging and time-consuming numerical optimization procedures [25]. Garrido-Merchán \&amp; Hernández-Lobato [21] recently proposed an extension to PESMO that supports parallel candidate generation. However, the authors of this work provide limited evaluation and have not provided code to reproduce their results. ${ }^{1}$
MOO can also be cast into a single-objective problem by applying a random scalarization of the objectives. ParEGO maximizes the expected improvement using random augmented Chebyshev scalarizations [32]. MOEA/D-EGO [64] extends ParEGO to the batch setting using multiple random scalarizations and the genetic algorithm MOEA/D [65] to optimize these scalarizations in parallel. Recently, $q$ ParEGO, another batch variant of ParEGO was proposed that uses compositional Monte Carlo objectives and sequential greedy candidate selection [11]. Additionally, the authors proposed a noisy variant, $q$ NParEGO, but the empirical evaluation of that variant was limited. TS-TCH [45] combines random Chebyshev scalarizations with Thompson sampling [54], which is naturally robust to noise when the objective is scalarized. Golovin \&amp; Zhang [23] propose to use a hypervolume scalarization with the property that the expected value of the scalarization over a specific distribution of weights is equivalent to the hypervolume indicator. The authors propose a upper confidence bound algorithm using randomly sampled weights, but provide a very limited empirical evaluation.
Many prior attempts by the simulation community to handle MOO with noisy observations found that accounting for the noise did not improve optimization performance: Horn et al. [26] suggest that the best approach is to ignore noise, and Koch et al. [33] concluded that further research was needed to determine if modeling techniques such as re-interpolation could improve BO performance with noisy observations. In contrast, we find that accounting for noise does substantially improve performance in noisy settings.
Lastly, previous works have considered methods for quantifying and monitoring uncertainty in the Pareto frontiers during the optimization [4, 7]. In contrast, we provide a solution to performing MOBO in noisy settings, rather than purely reasoning about the uncertainty in the Pareto frontier.</p>
<h2>4 Background on Expected Hypervolume Improvement</h2>
<p>In this section, we review hypervolume, hypervolume improvement, and expected hypervolume improvement as well as efficient methods for computing these metrics using box decompositions.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Definition 1. The hypervolume indicator (HV) of a finite approximate Pareto frontier $\mathcal{P}$ is the $M$-dimensional Lebesgue measure $\lambda_{M}$ of the space dominated by $\mathcal{P}$ and bounded from below by a reference point. $\boldsymbol{r} \in \mathbb{R}^{M}: \operatorname{HV}(\mathcal{P} \mid \boldsymbol{r})=\lambda_{M}\left(\bigcup_{\boldsymbol{v} \in \mathcal{P}}[\boldsymbol{r}, \boldsymbol{v}]\right)$, where $[\boldsymbol{r}, \boldsymbol{v}]$ denotes the hyper-rectangle bounded by vertices $\boldsymbol{r}$ and $\boldsymbol{v}$.</p>
<p>As in previous work, we assume that the reference point $\boldsymbol{r}$ is known and specified by the decision maker [58].
Definition 2. The hypervolume improvement (HVI) of a set of points $\mathcal{P}^{\prime}$ w.r.t. an existing approximate Pareto frontier $\mathcal{P}$ and reference point $\boldsymbol{r}$ is defined as ${ }^{2} \mathrm{HVI}\left(\mathcal{P}^{\prime} \mid \mathcal{P}, \boldsymbol{r}\right)=\mathrm{HV}\left(\mathcal{P} \cup \mathcal{P}^{\prime} \mid \boldsymbol{r}\right)-\mathrm{HV}(\mathcal{P} \mid \boldsymbol{r})$.</p>
<p>Computing HV requires calculating the volume of a typically non-rectangular polytope and is known to have time complexity that is super-polynomial in the number of objectives [59]. An efficient approach for computing HV is to (i) decompose the region that is dominated by the Pareto frontier $\mathcal{P}$ and bounded from below by the reference point $\boldsymbol{r}$ into disjoint axis-aligned hyperrectangles [34], (ii) compute the volume of each hyperrectangle in the decomposition, and (iii) sum over all hyperrectangles. So-called box decomposition algorithms have also been applied to partition the region that is not dominated by the Pareto frontier $\mathcal{P}$, which can be used to compute the HVI from a set of new points [15, 59]. See Appendix B for further details.</p>
<p>Expected Hypervolume Improvement: Since function values at unobserved points are unknown in black-box optimization, so is the HVI of an out-of-sample point. However, in BO the probabilistic surrogate model provides a posterior distribution $p(\boldsymbol{f}(\boldsymbol{x}) \mid \mathcal{D})$ over the function values for each $\boldsymbol{x}$, which can be used to compute the expected hypervolume improvement (EHVI) acquisition function: $\alpha_{\text {EHVI }}(\boldsymbol{x} \mid \mathcal{P})=\mathbb{E}\left[\operatorname{HVI}(\boldsymbol{f}(\boldsymbol{x}) \mid \mathcal{P})\right]$. Although $\alpha_{\text {EHVI }}$ can be expressed analytically when (i) the objectives are assumed to be conditionally independent given $\boldsymbol{x}$ and (ii) the candidates are generated and evaluated sequentially [58], Monte Carlo (MC) integration is commonly used since it does not require either assumption [16]. The more general parallel variant using MC integration is given by</p>
<p>$$
\alpha_{q \mathrm{EHVI}}\left(\mathcal{X}<em _mathrm_EHVI="\mathrm{EHVI" q="q">{\text {cand }} \mid \mathcal{P}\right) \approx \hat{\alpha}</em>}}\left(\mathcal{X<em t="1">{\text {cand }} \mid \mathcal{P}\right)=\frac{1}{N} \sum</em>}^{N} \operatorname{HVI}\left(\hat{\boldsymbol{f}<em _cand="{cand" _text="\text">{t}\left(\mathcal{X}</em>\right)
$$}}\right) \mid \mathcal{P</p>
<p>where $\hat{\boldsymbol{f}}<em _cand="{cand" _text="\text">{t} \sim p(\boldsymbol{f} \mid \mathcal{D})$ for $t=1, \ldots, N$ and $\mathcal{X}</em>$ [11]. The same box decomposition algorithms used to compute HVI can be used to compute EHVI (either analytic or via MC) using piece-wise integration. EHVI computation is agnostic to the choice of box decomposition algorithm (and can also use approximate methods [9]). Similar to EI in the single-objective case, EHVI is a one-step Bayes-optimal algorithm for maximizing hypervolume in the MOO setting under the following assumptions: (i) only a single design will be generated and evaluated, (ii) the observations are noise-free, (iii) the final approximate Pareto frontier (and final design that will be deployed) will be drawn from the set of observed points [19].}}=\left{x_{i}\right}_{i=1}^{q</p>
<h1>5 Expected Hypervolume Improvement with Noisy Observations</h1>
<p>We consider the case that frequently arises in practice where we only receive noisy observations $\boldsymbol{y}<em i="i">{i}=\boldsymbol{f}\left(\boldsymbol{x}</em>}\right)+\boldsymbol{\epsilon<em i="i">{i}, \boldsymbol{\epsilon}</em>} \sim \mathcal{N}\left(0, \Sigma_{i}\right)$, where $\Sigma_{i}$ is the noise covariance. In this setting, EHVI is no longer (one-step) Bayes-optimal. This is because we can no longer compute the true Pareto frontier $\mathcal{P<em n="n">{n}=\left{\boldsymbol{f}(\boldsymbol{x}) \mid \boldsymbol{x} \in X</em>}, \nexists \boldsymbol{x}^{\prime} \in X_{n}\right.$ s.t. $\left.\boldsymbol{f}\left(\boldsymbol{x}^{\prime}\right) \succ \boldsymbol{f}(\boldsymbol{x})\right}$ over the previously evaluated points $X_{n}=$ $\left{\boldsymbol{x<em i="1">{i}\right}</em>}^{n}$. Simply using the observed Pareto frontier, $\mathcal{Y<em n="n">{n}=\left{\boldsymbol{y} \mid \boldsymbol{y} \in Y</em>}, \nexists \boldsymbol{y}^{\prime} \in Y_{n}\right.$ s.t. $\left.\boldsymbol{y}^{\prime} \succ \boldsymbol{y}, y\right}$ where $Y_{n}=\left{\boldsymbol{y<em i="1">{i}\right}</em>$, can have strong detrimental effects on optimization performance. This is illustrated in Figure 1, which shows how EHVI is misled by noisy observations that appear to be Pareto optimal. EHVI proceeds to spend its evaluation budget trying to optimize noise, resulting in a clumped Pareto frontier that lacks diversity. Although the posterior mean could serve as a "plug-in" estimate of the true function values at the observed points and provide some regularization [61], we find that this heuristic also leads to clustered Pareto frontiers (EHVI-PM in Fig. 1). Similar patterns emerge with DGEMO (which does not account for noise), and other baselines that utilize the posterior mean rather than the observed values when computing hypervolume improvement (see Appendix H). To our knowledge, all previous work on EHVI assumes that observations are noiseless [16, 58] or imputes the unknown true function values with the posterior mean.}^{n</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An illustration of the effect of noisy observations on the true noiseless Pareto frontiers identified by NEHVI (our proposed algorithm), EHVI, and EHVI-PM, which uses the modeled posterior mean as point estimate of the true in-sample function values. All algorithms are tested on a BraninCurrin synthetic problem, where observations are corrupted with zero-mean, additive Gaussian noise with a standard deviation of $5 \%$ of the range of respective objective. All methods use sequential $(q=1)$ optimization. See Appendix G for details.</p>
<h1>5.1 A Bayes-optimal algorithm for hypervolume maximization in noisy environments</h1>
<p>In contrast with EHVI(-PM), we instead approach the problem of hypervolume maximization under noisy observations from a Bayesian perspective and derive a novel one-step Bayes-optimal expected hypervolume improvement criterion that iterates the expectation over the posterior distribution $p\left(\boldsymbol{f}\left(X_{n}\right) \mid \mathcal{D}<em n="n">{n}\right)$ of the function values at the previously evaluated points $X</em>}$ given noisy observations $\mathcal{D<em i="i">{n}=\left{\boldsymbol{x}</em>}, \boldsymbol{y<em i="i">{i},\left(\Sigma</em>$. Our acquisition function, noisy expected hypervolume improvement (NEHVI), is defined as}\right)\right}_{i=1}^{n</p>
<p>$$
\alpha_{\mathrm{NEHVI}}(\boldsymbol{x})=\int \alpha_{\mathrm{EHVI}}\left(\boldsymbol{x} \mid \mathcal{P}<em n="n">{n}\right) p\left(\boldsymbol{f} \mid \mathcal{D}</em>
$$}\right) d \boldsymbol{f</p>
<p>where $P_{n}$ denotes the Pareto frontier over $\boldsymbol{f}\left(X_{n}\right)$.
By integrating over the uncertainty in the function values at the observed points, NEHVI retains one-step Bayes-optimality in noisy environments (in noiseless environments, NEHVI is equivalent to EHVI). Empirically, Figure 1 shows that NEHVI is robust to noise and identifies a well-distributed Pareto frontier with no signs of clumping, even under very noisy observations. ${ }^{3}$
The integral in (2) is analytically intractable, but can easily be approximated using MC integration. Let $\tilde{\boldsymbol{f}}<em n="n">{t} \sim p\left(\boldsymbol{f} \mid D</em>}\right)$ for $t=1, \ldots N$ be samples from the posterior, and let $\mathcal{P<em t="t">{t}=\left{\tilde{\boldsymbol{f}}</em>}(\boldsymbol{x}) \mid \boldsymbol{x} \in\right.$ $\left.X_{n}, \tilde{\boldsymbol{f}<em t="t">{t}(\boldsymbol{x}) \succ \tilde{\boldsymbol{f}}</em>}\left(\boldsymbol{x}^{\prime}\right) \forall \boldsymbol{x}^{\prime} \in X_{n}\right}$ be the Pareto frontier over the previously evaluated points under the sampled function $\tilde{\boldsymbol{f}<em _mathrm_NEHVI="\mathrm{NEHVI">{t}$. Then, $\alpha</em>}}(\boldsymbol{x}) \approx \frac{1}{N} \sum_{t=1}^{N} \alpha_{\mathrm{EHVI}}\left(\boldsymbol{x} \mid \mathcal{P<em _EHVI="{EHVI" _text="\text">{t}\right)$. Using MC integration, we can compute the inner expectation in $\alpha</em>}}$ simultaneously using samples from the joint posterior $\tilde{\boldsymbol{f}<em n="n">{t}\left(X</em>}, \boldsymbol{x}\right) \sim p\left(\boldsymbol{f}\left(X_{n}, \boldsymbol{x}\right) \mid \mathcal{D<em n="n">{n}\right)$ over $\boldsymbol{x}$ and $X</em>$ :</p>
<p>$$
\hat{\alpha}<em t="1">{\mathrm{NEHVI}}(\boldsymbol{x})=\frac{1}{N} \sum</em>}^{N} \operatorname{HVI}\left(\tilde{\boldsymbol{f}<em t="t">{t}(\boldsymbol{x}) \mid \mathcal{P}</em>\right)
$$</p>
<p>See Appendix B for details on computing (3) using box decompositions. Note that this "full-MC" variant of NEHVI does not require objectives to be modeled independently, and supports multi-task covariance functions across correlated objectives.</p>
<h3>5.2 Parallel Noisy Expected Hypervolume Improvement</h3>
<p>Generating and evaluating batches of candidates is imperative to achieving adequate throughput in many real-world scenarios. qNEHVI can naturally be extended to the parallel (asynchronous or batch) setting by evaluating HVI with respect to a batch of $q$ points $\mathcal{X}<em i="i">{\text {cand }}=\left{\boldsymbol{x}</em>$}\right}_{i=1}^{4</p>
<p>$$
\alpha_{q \mathrm{NEHVI}}\left(\mathcal{X}<em _mathrm_EHVI="\mathrm{EHVI" q="q">{\mathrm{cand}}\right)=\int \alpha</em>}}\left(\mathcal{X<em n="n">{\mathrm{cand}} \mid \mathcal{P}</em>}\right) p\left(\boldsymbol{f} \mid \mathcal{D<em _mathrm_NEHVI="\mathrm{NEHVI" q="q">{n}\right) d \boldsymbol{f} \approx \hat{\alpha}</em>}}\left(\mathcal{X<em t="1">{\mathrm{cand}}\right)=\frac{1}{N} \sum</em>}^{N} \operatorname{HVI}\left(\tilde{\boldsymbol{f}<em _mathrm_cand="\mathrm{cand">{t}\left(\mathcal{X}</em>\right)
$$}}\right) \mid \mathcal{P}_{t</p>
<p>Since optimizing $q$ candidates jointly is a difficult numerical optimization problem over a $q d$ dimensional domain, we use a sequential greedy approximation in the parallel setting and solve a sequence of $q$ simpler optimization problems with $d$ dimensions, which been shown empirically to improve optimization performance [57]. While selecting candidates according to a "sequential greedy" policy does not guarantee that the selected batch of candidates is a maximizer of the $\alpha_{q \text { NEHVI }}$, the submodularity of $\alpha_{q \text { NEHVI }}$ allows us to bound the regret of this approximation to be no more than $\frac{1}{e} \alpha_{q \text { NEHVI }}^{<em>}$, where $\alpha_{\mathrm{qNEHVI}}^{</em>}=\max <em _cand="{cand" _text="\text">{\mathcal{X}</em>\right)$ (see Appendix F).}} \in \mathcal{X}} \alpha_{\mathrm{qNEHVI}}\left(\mathcal{X}_{\text {cand }</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>6 Efficient Evaluation with Cached Box Decompositions</h1>
<p>Although $\hat{\alpha}<em t="t">{\text {NEHVI }}(\boldsymbol{x})$ in (3) has a concise mathematical form, computing it requires determining the Pareto frontier $\mathcal{P}</em>}$ under each sample $\tilde{\boldsymbol{f}<em t="t">{t}$ for $t=1, \ldots, N$ and then partitioning the region that is not dominated by $\mathcal{P}</em>\right}}$ into disjoint hyperrectangles $\left{S_{k_{t}<em t="t">{k</em>}=1}^{K_{t}}$. Optimizing the unbiased MC estimator of $\alpha_{\text {NEHVI }}$ would require re-sampling $\left{\tilde{\boldsymbol{f}<em t="1">{t}\right}</em>=\arg \max }^{N}$ at each evaluation of $\alpha_{\text {NEHVI }}$. However, computing the Pareto frontier and performing a box decomposition under each of the $N$ samples during every evaluation of $\alpha_{\text {NEHVI }}$ in the inner optimization loop $\left(\boldsymbol{x}^{*<em _NEHVI="{NEHVI" _text="\text">{\boldsymbol{x}} \alpha</em>}}\left(\boldsymbol{x} \mid \mathcal{D<em t="t">{n}\right)\right)$ would be prohibitively expensive. This is because box decomposition algorithms have super-polynomial time complexity in the number of objectives [59]. We instead propose an efficient alternative computational technique for repeated evaluations of EHVI with uncertain Pareto frontiers.
Cached Box Decompositions: For repeated evaluations of the integral in (2), we use a set of fixed samples $\left{\tilde{\boldsymbol{f}}</em>\right)\right}}\left(X_{n<em _NEHVI="{NEHVI" _text="\text">{t=1}^{N}$, which allows us to compute the Pareto frontiers and box decompositions once, and cache them for the entirety of the acquisition function optimization, thereby making those two computationally intensive operations a one-time cost per BO iteration. ${ }^{4}$ We refer to this approach as using cached box decompositions (CBD). The method of optimizing over fixed random samples is known as sample average approximation (SAA) [2].
Conditional Posterior Sampling: Under the CBD formulation, computing $\hat{\alpha}</em>}}(\boldsymbol{x})$ with joint samples from $\tilde{\boldsymbol{f}<em n="n">{t}\left(X</em>\right)$ requires sampling from the conditional distributions}, \boldsymbol{x}\right) \sim p\left(\boldsymbol{f}\left(X_{n}, \boldsymbol{x}\right) \mid \mathcal{D}_{n</p>
<p>$$
\tilde{\boldsymbol{f}}<em n="n">{t}(\boldsymbol{x}) \sim p\left(\boldsymbol{f}(\boldsymbol{x}) \mid \boldsymbol{f}\left(X</em>}\right)=\tilde{\boldsymbol{f}<em n="n">{t}\left(X</em>\right)
$$}\right), \mathcal{D}_{n</p>
<p>where $t=1, \ldots, N$ and $\left{\tilde{\boldsymbol{f}}<em n="n">{t}\left(X</em>\right)\right}<em n="n">{t=1}^{N}$ are the realized samples at the previously evaluated points. For multivariate Gaussian posteriors (as is the case with GP surrogates), we can sample from $p\left(\boldsymbol{f}\left(X</em>}\right) \mid \mathcal{D<em t="t">{n}\right)$ via the reparameterization trick [30] by evaluating $\tilde{\boldsymbol{f}}</em>}(\boldsymbol{x})=\boldsymbol{\mu<em n="n">{n}+L</em>}^{T} \boldsymbol{\zeta<em n_="n," t="t">{n, t}$, where $\boldsymbol{\zeta}</em>} \sim \mathcal{N}\left(\mathbf{0}, I_{n M}\right), \boldsymbol{\mu<em n="n">{n} \in \mathbb{R}^{n M}$ is the posterior mean, and $L</em>} \in \mathbb{R}^{n M \times n M}$ is a lower triangular root decomposition of the posterior covariance matrix, typically a Cholesky decomposition. Given $L_{n}$, we can obtain a root decomposition $L_{n}^{\prime}$ of the covariance matrix of the joint posterior $p\left(\boldsymbol{f}\left(X_{n}, \boldsymbol{x}\right) \mid \mathcal{D<em n="n">{n}\right)$ by performing efficient low-rank updates [44]. Given $L</em>}^{\prime}$ and the posterior mean of $p\left(\boldsymbol{f}\left(X_{n}, \boldsymbol{x}\right) \mid \mathcal{D<em n_="n," t="t">{n}\right)$, we can sample from (5) via the reparameterization trick by augmenting the existing base samples $\boldsymbol{\zeta}</em>$ with $M$ new base samples for the new point.</p>
<h3>6.1 Efficient Sequential Greedy Batch Selection using CBD</h3>
<p>The CBD technique addresses the general problem of inefficient repeated evaluations of EHVI with uncertain Pareto frontiers. In this section, we show that sequential greedy batch selection (with both $q$ EHVI and $q$ NEHVI) is an incarnation of EHVI with uncertain Pareto frontiers.
The original formulation of parallel EHVI in Daulton et al. [11] uses the inclusion-exclusion principle (IEP), which involves computing the volume jointly dominated by each of the $2^{q}-1$ nonempty subsets of points in $\mathcal{X}<em 1="1">{\text {cand }}$. However, using large batch sizes is not computationally feasible under this formulation because time and space complexity are exponential in $q$ and multiplicative in the number of hyperrectangles in the box decomposition [11] (see Appendix D for a complexity analysis). Although $q$ EHVI is optimized using sequential greedy batch selection, the IEP is used over all candidates $\boldsymbol{x}</em>}, \ldots, \boldsymbol{x<em _cand="{cand" _text="\text">{i}$ when selecting candidate $i$. Although the IEP could similarly be used to compute $q$ NEHVI, we instead leverage CBD, which yields a sequential greedy approximation of the joint (noisy) EHVI that is mathematically equivalent to the IEP formulation, but significantly reduces computational overhead. That is, the IEP and CBD approaches produce exactly the same acquisition value for a given set of points $\mathcal{X}</em>$, but the IEP and the CBD approaches have exponential and polynomial time complexities in $q$, respectively.
When selecting $\boldsymbol{x}}<em j="j">{i}$ for $i \in{2, \ldots, q}$, all $\boldsymbol{x}</em>}$ for which $j&lt;i$ have already been selected and are therefore held constant. Thus, we can decompose $q$ NEHVI into the $q$ NEHVI from the previously selected candidates $\boldsymbol{x<em i-1="i-1">{1}, \ldots, \boldsymbol{x}</em>$ given the previously selected candidates}$ and NEHVI from $\boldsymbol{x}_{i</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Acquisition optimization wall time under a sequential greedy approximation using L-BFGS-B. CBD enables scaling to much larger batch sizes $q$ than using the IEP and avoids running out-of-memory (OOM) on a GPU. Independent GPs are used for each outcome. The Pareto frontier of of the 2-objective, 6dimensional DTLZ2 problem [13] is initialized with 20 points. Wall times were measured on a Tesla V100 SXM2 GPU (16GB RAM) and a 2x Intel Xeon 6138 CPU @ 2GHz (251GB RAM). See Appendix H. 2 for results with more objectives.</p>
<p>$$
\hat{\alpha}<em j="j">{q \mathrm{NEHVI}}\left(\left{\boldsymbol{x}</em>\right}<em t="1">{j=1}^{i}\right)=\frac{1}{N} \sum</em>}^{N} \operatorname{HVI}\left(\left{\tilde{\boldsymbol{f}<em j="j">{t}\left(\boldsymbol{x}</em>\right)\right}<em t="t">{j=1}^{i-1}\right}\left|\mathcal{P}</em>}\right)+\frac{1}{N} \sum_{t=1}^{N} \operatorname{HVI}\left(\tilde{\boldsymbol{f}<em i="i">{t}\left(\boldsymbol{x}</em>}\right)\left|\mathcal{P<em t="t">{t} \cup\left{\tilde{\boldsymbol{f}}</em>}\left(\boldsymbol{x<em j="1">{j}\right)\right}</em>\right}\right)
$$}^{i-1</p>
<p>Note that the first term on the right hand side is constant, since $\left{\boldsymbol{x}<em j="1">{j}\right}</em>}^{i-1}$ and $\left{\tilde{\boldsymbol{f}<em j="j">{t}\left(\boldsymbol{x}</em>\right)\right}<em _mathrm_NEHVI="\mathrm{NEHVI">{j=1}^{i-1}$ are fixed for all $t=1, \ldots, N$. The second term is $\hat{\alpha}</em>}}\left(\boldsymbol{x<em n="n">{i}\right)$, where the NEHVI is taken with respect to the Pareto frontier across $\boldsymbol{f}\left(X</em>}, \boldsymbol{x<em i-1="i-1">{1}, \ldots, \boldsymbol{x}</em>}\right)$ and computed using the fixed samples $\left{\tilde{\boldsymbol{f}<em n="n">{t}\left(X</em>}, \boldsymbol{x<em i-1="i-1">{1}, \ldots \boldsymbol{x}</em>\right)\right}<em i="i">{t=1}^{N}$. To compute the second term when selecting candidate $\boldsymbol{x}</em>}$, the $N$ Pareto frontiers and CBDs are updated to include $\left{\tilde{\boldsymbol{f}<em n="n">{t}\left(X</em>}, \boldsymbol{x<em i-1="i-1">{1}, \ldots \boldsymbol{x}</em>\right)\right}<em t="t">{t=1}^{N}$. As in the sequential $q=1$ setting, the box decompositions are only computed and cached while selecting each candidate point. See Appendix C. 2 for a derivation of (6). Although we have focused on $q$ NEHVI in the above, the CBD formulation for $q$ EHVI is obtained by simply replacing $\mathcal{P}</em>}$ with the Pareto frontier over the observed values $\mathcal{Y<em i="i">{n}$.
Despite computing $N$ box decompositions when selecting each candidate $\boldsymbol{x}</em>$ for $i=2, \ldots, q$, the CBD approach reduces the time and space complexity from exponential (under the IEP) to polynomial in $q$ (see Appendix D for details on time and space complexity). Figure 2 shows the total acquisition optimization time (including box decompositions) for various batch sizes and demonstrates that using CBD allows to scale to batch sizes that are completely infeasible when using IEP.</p>
<h1>7 Optimizing NEHVI</h1>
<p>Differentiability: Importantly, $\hat{\alpha}<em n="n">{\mathrm{NEHVI}}(\boldsymbol{x})$ is differentiable w.r.t. $\boldsymbol{x}$. Although determining the Pareto frontier and computing the box decompositions are non-differentiable operations, these operations do not involve $\boldsymbol{x}$, even when re-sampling from the joint posterior $p\left(\boldsymbol{f}\left(X</em>}, \boldsymbol{x}\right) \mid \mathcal{D<em _boldsymbol_x="\boldsymbol{x">{n}\right)$. Exact sample-path gradients of $\nabla</em>}} \hat{\alpha<em n="n">{\mathrm{NEHVI}}(\boldsymbol{x})$ can easily be computed using auto-differentiation in modern computational frameworks. This enables efficient gradient-based optimization of $q$ NEHVI. ${ }^{5}$
SAA Convergence Results: In addition to approximating the outer expectation over $\boldsymbol{f}\left(X</em>$. This approach yields a deterministic acquisition function, which enables using (quasi-) higher-order optimization methods to obtain fast convergence rates for acquisition optimization [2]. Importantly, we prove that the theoretical convergence guarantees on acquisition optimization under the SAA approach proposed by Balandat et al. [2] also hold for NEHVI.
Theorem 1. Suppose $\mathcal{X}$ is compact and $\boldsymbol{f}$ has a multi-output GP prior with continuously differentiable mean and covariance functions. Let $X_{n}=\left{\boldsymbol{x}}\right)$ with fixed posterior samples, we can similarly fix the base samples used for the new candidate point $\boldsymbol{x<em i="1">{i}\right}</em>}}^{n}$ denote the previously evaluated points and ${\boldsymbol{\zeta<em M="M" _n_1_="(n+1)">{l=1}^{N}$ be base samples $\boldsymbol{\zeta} \sim \mathcal{N}\left(\mathbf{0}, I</em>}\right)$. Let $\hat{\alpha<em l="1">{\mathrm{NEHVI}}$ denote the deterministic acquisition function computed using ${\boldsymbol{\zeta}}</em>}^{N}$ as $\hat{\alpha<em _boldsymbol_x="\boldsymbol{x">{\mathrm{NEHVI}}^{N}$ and define $S^{<em>}:=\arg \max <em _mathrm_NEHVI="\mathrm{NEHVI">{\boldsymbol{x} \in \mathcal{X}} \alpha</em>^{}}(\boldsymbol{x})$ to be the set of maximizers of $\alpha_{\mathrm{NEHVI}}(\boldsymbol{x})$ over $\mathcal{X}$. Suppose $\hat{\boldsymbol{x}}_{N</em>} \in \arg \max </em>} \in \mathcal{X}} \hat{\alpha<em _mathrm_NEHVI="\mathrm{NEHVI">{\mathrm{NEHVI}}^{N}(\boldsymbol{x})$. Then (1) $\hat{\alpha}</em>}}^{N}\left(\hat{\boldsymbol{x}<em N="N">{N}^{<em>}\right) \rightarrow \alpha_{\mathrm{NEHVI}}\left(\boldsymbol{x}_{N}^{</em>}\right)$ almost surely, and (2) $\operatorname{dist}\left(\hat{\boldsymbol{x}}</em>^{<em>}, S^{</em>}\right) \rightarrow 0$, where $\operatorname{dist}\left(\hat{\boldsymbol{x}}<em _boldsymbol_x="\boldsymbol{x">{N}^{<em>}, \mathcal{S}^{</em>}\right):=$ $\inf </em> \in S^{<em>}}\left|\hat{\boldsymbol{x}}_{N}^{</em>}-\boldsymbol{x}\right|$ is the Euclidean distance between $\hat{\boldsymbol{x}}_{N}^{<em>}$ and the set $S^{</em>}$.</p>
<p>Theorem 1 also holds in the parallel setting, so $q$ NEHVI enjoys the same convergence guarantees as NEHVI on acquisition optimization under the SAA. See Appendix E for further details and proof.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>8 Approximation of $q$ NEHVI using Approximate GP Sample Paths</h1>
<p>Although CBD yields polynomial complexity of $q$ NEHVI with respect to $q$ (rather than exponential complexity with the IEP), it still requires computing $N$ box decompositions and repeatedly evaluating the joint posterior over $\boldsymbol{f}\left(X_{n},\left{\boldsymbol{x}<em j="1">{j}\right}</em>}^{i-1}\right)$ for selecting each candidate $\boldsymbol{x<em i="i">{i}$ for $i=1, \ldots, q$. A cheaper alternative is to approximate the integral in (4) using a single approximate GP sample path $\tilde{\boldsymbol{f}}</em>}$ using RFFs when optimizing candidate $\boldsymbol{x<em i="i">{i}$. A single-sample approximation of $q$ NEHVI, which we refer to as $q$ NEHVI-1, can be computed by using $\tilde{\boldsymbol{f}}</em>}$ as the sampled GP in (6). Since the RFF is a deterministic model, it is much less computationally expensive to evaluate than the GP posterior on out-of-sample points, and exact gradients of $q$ NEHVI-1 with respect to current candidate $\boldsymbol{x<em i="i">{i}$ can be computed and used for efficient multi-start optimization of $q$ NEHVI-1 using second-order gradient methods. $q$ NEHVI-1 requires CBD for efficient sequential greedy batch selection and gradient-based optimization, but does not use a sample average approximation for optimizing a new candidate $\boldsymbol{x}</em>$; instead, it uses an approximate sample path. See Rahimi \&amp; Recht [46] for details on RFFs.
$q$ NEHVI-1 is related to TSEMO in that both use sequential greedy batch selection using HVI based on RFF samples. However, TSEMO does not directly maximize HVI when selecting candidate $\boldsymbol{x}_{i}$, where $i=1, \ldots, q$; rather, it relies on a heuristic approach of running NSGA-II on an RFF sample of each objective to create a discrete population of candidates and then selecting the point from the discrete population that maximizes HVI under the RFF sample. In contrast, $q$ NEHVI-1 directly optimizes HVI under the RFF using exact sample-path gradients, which leads to improved optimization performance (see Appendix H). Furthermore, we find that $q$ NEHVI-1 is significantly faster than TSEMO, because rather than using NSGA-II it uses second order gradient methods to optimize HVI (see Appendix H). Gradient-based optimization is only possible because CBD enables scalable, differentiable HVI computation. While the primary goal of this work is to develop a principled, scalable method for parallel EHVI in noisy environments, we include empirical comparisons with $q$ NEHVI-1 throughout the appendix to demonstrate the generalizablility of the CBD approach and practical performance of the $q$ NEHVI-1 approximation. $q$ NEHVI-1 achieves the fastest batch selection timesof any method tested on a GPU on every problem; in many cases, this is an order of magnitude speed-up over $q$ NEHVI. Moreover, $q$ NEHVI-1 has a remarkable ability to scale to large batch sizes when the dimensionality of optimization problem is modest. Further investigation of $q$ NEHVI-1 is needed, but we hope that the readers can recognize the ways in which $q$ NEHVI can create broader opportunities for research into hypervolume improvement based acquisition functions.</p>
<h2>9 Experiments</h2>
<p>We empirically evaluate $q$ NEHVI on a set of synthetic and real-world benchmark problems. We compare it against the following recently proposed methods from the literature: PESMO, MESMO (which we extend to the handle noisy observations using the noisy information gain from Takeno et al. [52]), PFES, DGEMO, MOEA/D-EGO, TSEMO, TS-TCH, $q$ EHVI (and $q$ EHVI-PM-CBD, which uses the posterior mean as a plug-in estimate for the function values at the in-sample points, along with CBD to scale to large batch sizes), and qNParEGO. We optimize all methods using multi-start L-BFGS-B with exact gradients (except for PFES, which uses gradients approximated via finite differences), including TS-TCH where we optimize approximate function samples using RFFs with 500 basis functions. We model each outcome with an independent GP with a Matérn 5/2 ARD kernel and infer the GP hyperparameters via maximum a posteriori (MAP) estimation. For all problems, we assume that the noise variances are observed (except ABR, where we infer the noise level). See Appendix G for more details on the experiments and acquisition function implementations.
We evaluate all methods using the logarithm of the difference in hypervolume between the true Pareto frontier and the approximate Pareto frontier recovered by the algorithm. Since evaluations are noisy, we compute the hypervolume dominated by the noiseless Pareto frontier across the observed points for each method.
Synthetic Problems: We consider a noisy variants of the BraninCurrin problem $(M=2, d=2)$ and the DTLZ2 problem $(M=2, d=6)$ [13], in which observations are corrupted with zero-mean additive Gaussian noise with standard deviation of $5 \%$ of the range of each objective for BraninCurrin and $10 \%$ for DTLZ2.
Adaptive Bitrate (ABR) Control Policy Optimization: ABR controllers are used for real-time communication and media streaming applications. Policies for these controllers must be tuned to</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Sequential optimization performance. The shaded region indicates two standard errors of the mean over 100 replications (only 20 replications were feasible for PESMO due to large runtimes).</p>
<p>deliver a high quality of experience with respect to multiple objectives [40]. In industry settings, A/B tests with dozens of policies are tested simultaneously since each policy may take days or weeks to evaluate, producing noisy measurements across multiple objectives. In this experiment, we tune policies to maximize video quality (bitrate) and minimize stall time. The policy has d = 4 parameters, which are detailed in Appendix G. We use the Park simulator [41] and sample a random set of 100 traces to obtain noisy measurements of the objectives under a given policy. For comparing the performance of different methods, we estimate the true noiseless objective using mean objectives across 300 traces. We infer a homoskedastic noise level jointly with the GP hyperparameters via MAP estimation.</p>
<p><strong>Vehicle Design Optimization:</strong> Optimizing the design of the frame an automobile is important to maximizing passenger safety, vehicle durability and fuel efficiency. Evaluating a vehicle design is time-consuming, since either a vehicle must be manufactured and crashed, or a nonlinear finite element-based crash analysis must be run to simulate a collision (which can take over 20 hours per run) [62]. Hence, evaluating many designs in parallel is critical for reducing end-to-end optimization time. Observations are often noisy due to manufacturing imperfections, measurement error, or non-deterministic simulations. In this experiment, we tune the d = 5 widths of various components of a vehicle's frame to minimize proxy metrics for (1) fuel consumption, (2) passenger trauma in a full frontal collision, and (3) vehicle fragility [53]. See Appendix G for details. For this demonstration, we add zero-mean Gaussian noise with a standard deviation of 1% of the objective range, which roughly corresponds to the manufacturing noise level used in previous work [62].</p>
<h3>9.1 Summary of Results:</h3>
<p>We find that qNEHVI and qNEHVI-1 outperform all other methods on the noisy benchmarks, both in the sequential and parallel setting. In the sequential setting (Fig 3), qNEHVI and qNEHVI-1 are followed closely by qEHVI-PM, and in some cases, even qEHVI. TS-TCH is firmly in the middle of the pack, while information-theoretic acquisition functions appear to perform the worst. This is consistent across noise levels; for experiments where we add noise to the objectives, we consider noise levels ranging from 1% to 10% of the range of each objective (these are magnitudes of the noise often seen in practice). Previous works have only evaluated MOBO algorithms with noise levels of 1% [25]. In Appendix H, we perform a study showing that qNEHVI consistently performs best with increasing noise levels up to 30% of the range of each objective.</p>
<p>While parallel evaluation can provide optimization speedups on order of the batch size q, these evaluations do affect the overall sample complexity of the algorithm, since less information is available within the synchronous batch setting compared with fully sequential optimization. We find that, by and large, qNEHVI achieves the greatest hyper-volume for increasingly large batch sizes, and scales more elegantly relative to TS-TCH and the ParEGO variants (Fig 4). qNEHVI also consistently outperforms qEHVI-PM-CBD. In Appendix H, we observe that qNEHVI and qNEHVI-1 provides excellent anytime performance all values of q that we tested. We provide results on 4 additional test problems in Appendix H.3, and in Appendix H.8, we demonstrate that leveraging CBD and a single sample path approximation, qNEHVI-1 enables scaling to 5-objective problems, which is a first for an HVI-based method, to our knowledge.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The quality of the final Pareto frontier identified by each method with increasing batch sizes $q$ given a budget of 224 function evaluations. $q$ EHVI is only included for $q=1$ and $q=8$ because the IEP scales exponential with $q$. DGEMO is omitted on the ABR problem because it was prohibitively slow with time-consuming ABR simulations and on the VehicleSafety problem because DGEMO consistently crashed in the graph cutting algorithm.</p>
<p>In our experiments, we find that $q$ NEHVI-1 is among the top performers on relatively lowdimensional problems. Given the strong performance of $q$ NEHVI-1, we examine its performance as the dimensionality of the search space increases in Appendix H.5. We find that $q$ NEHVI is more robust than $q$ NEHVI-1 in higher-dimensional search spaces, but further investigation is needed into how the number of the Fourier basis functions affects the performance of $q$ NEHVI-1 in highdimensional search spaces.
Optimization wall time: Across all experiments, we observe competitive wall times for optimizing $q$ NEHVI and $q$ NEHVI-1 (all wall time comparisons are provided in Appendix H). On a GPU, optimizing $q$ NEHVI-1 incurs the lowest wall time of any method that we tested on every single problem and optimizing $q$ NEHVI is faster than optimizing information-theoretic methods on all problems. Using efficient low-rank Cholesky updates, $q$ NEHVI is often faster than the $q$ NParEGO implementation in BoTorch on a GPU.</p>
<h1>10 Discussion</h1>
<p>We proposed NEHVI, a novel acquisition function that provides a principled approach to parallel and noisy multi-objective Bayesian optimization. NEHVI is a one-step Bayes-optimal policy for maximizing the hypervolume dominated by the Pareto frontier in noisy and noise-free settings. NEHVI is made feasible by a new approach to computing joint hypervolumes (CBD), and we demonstrated that CBD enables scalable, parallel candidate generation with both noiseless $q$ EHVI and $q$ NEHVI. We provide theoretical results on optimizing a MC estimator of $q$ NEHVI using sample average approximation and demonstrate significant improvements in optimization performance over state-of-the-art MOBO algorithms.</p>
<p>Yet, our work has some limitations. While the information-theoretic acquisition functions tested here perform poorly on our benchmarks, they do allow for decoupled evaluations of different objectives in cases where querying one objective may be more resource-intensive than querying other objectives. Optimizing such acquisition functions is a non-trivial task, and it is possible that with improved procedures, such acquisition functions could yield improved performance and provide a principled approach to selecting evaluation sources on a budget. Although practically fast enough for most Bayesian optimization tasks, exact hypervolume computation has super-polynomial complexity in the number of objectives. Combining $q$ NEHVI with differentiable approximate methods for computing hypervolume (e.g. Couckuyt et al. [9], Golovin \&amp; Zhang [23]) could lead to further speed-ups.
We hope that the core ideas presented in this work, including the CBD approach, can provide a framework to support the development of new computationally efficient MOBO methods.</p>
<h1>References</h1>
<p>[1] Asadpour, A., Nazerzadeh, H., and Saberi, A. Stochastic submodular maximization. In Papadimitriou, C. and Zhang, S. (eds.), Internet and Network Economics. Springer Berlin Heidelberg, 2008.
[2] Balandat, M., Karrer, B., Jiang, D. R., Daulton, S., Letham, B., Wilson, A. G., and Bakshy, E. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020.
[3] Belakaria, S., Deshwal, A., and Doppa, J. R. Max-value entropy search for multi-objective bayesian optimization. In Advances in Neural Information Processing Systems 32, 2019.
[4] Binois, M., Ginsbourger, D., and Roustant, O. Quantifying uncertainty on pareto fronts with gaussian process conditional simulations. Eur. J. Oper. Res., 243:386-394, 2015.
[5] Bradford, E., Schweidtmann, A. M., and Lapkin, A. Efficient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm. Journal of global optimization, 71(2):407-438, 2018.
[6] Brockhoff, D., Tusar, T., Auger, A., and Hansen, N. Using well-understood single-objective functions in multiobjective black-box optimization test suites, 2019.
[7] Calandra, R. and Peters, J. Pareto front modeling for sensitivity analysis in multi-objective bayesian optimization. 2014.
[8] Calandra, R., Seyfarth, A., Peters, J., and Deisenroth, M. P. Bayesian optimization for learning gaits under uncertainty. Annals of Mathematics and Artificial Intelligence, 76(1):5-23, Feb 2016. ISSN 1573-7470. doi: 10.1007/s10472-015-9463-9.
[9] Couckuyt, I., Deschrijver, D., and Dhaene, T. Towards efficient multiobjective optimization: Multiobjective statistical criterions. In 2012 IEEE Congress on Evolutionary Computation, pp. $1-8,2012$.
[10] Daulton, S., Singh, S., Avadhanula, V., Dimmery, D., and Bakshy, E. Thompson sampling for contextual bandit problems with auxiliary safety constraints. In NeurIPS Workshop on Safety and Robustness in Decision Making, 2019.
[11] Daulton, S., Balandat, M., and Bakshy, E. Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. In Advances in Neural Information Processing Systems 33, NeurIPS, 2020.
[12] Deb, K., Pratap, A., Agarwal, S., and Meyarivan, T. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE Transactions on Evolutionary Computation, 6(2):182-197, 2002.
[13] Deb, K., Thiele, L., Laumanns, M., and Zitzler, E. Scalable multi-objective optimization test problems. volume 1, pp. 825-830, 06 2002. ISBN 0-7803-7282-4. doi: 10.1109/ CEC.2002.1007032.
[14] Deb, K., Gupta, S., Daum, D., Branke, J., Mall, A. K., and Padmanabhan, D. Reliability-based optimization using evolutionary algorithms. IEEE Transactions on Evolutionary Computation, 13(5):1054-1074, 2009. doi: 10.1109/TEVC.2009.2014361.
[15] Dächert, K., Klamroth, K., Lacour, R., and Vanderpooten, D. Efficient computation of the search region in multi-objective optimization. European Journal of Operational Research, 260 (3):841 - 855, 2017.
[16] Emmerich, M. T. M., Giannakoglou, K. C., and Naujoks, B. Single- and multiobjective evolutionary optimization assisted by gaussian random field metamodels. IEEE Transactions on Evolutionary Computation, 10(4):421-439, 2006.
[17] Feng, Q., Letham, B., Bakshy, E., and Mao, H. High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020.
[18] Fisher, M. L., Nemhauser, G. L., and Wolsey, L. A. An analysis of approximations for maximizing submodular set functions-II, pp. 73-87. Springer Berlin Heidelberg, Berlin, Heidelberg, 1978.
[19] Frazier, P. I. A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811, 2018.</p>
<p>[20] Garrido-Merchán, E. C. and Hernández-Lobato, D. Predictive entropy search for multi-objective bayesian optimization with constraints. Neurocomputing, 361:50-68, 2019.
[21] Garrido-Merchán, E. C. and Hernández-Lobato, D. Parallel predictive entropy search for multi-objective bayesian optimization with constraints, 2020.
[22] Gelbart, M. A., Snoek, J., and Adams, R. P. Bayesian optimization with unknown constraints. In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence, UAI, 2014.
[23] Golovin, D. and Zhang, Q. Random hypervolume scalarizations for provable multi-objective black box optimization, 2020.
[24] Hernández-Lobato, J. M., Hoffman, M. W., and Ghahramani, Z. Predictive entropy search for efficient global optimization of black-box functions. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 1, NIPS'14, pp. 918-926, Cambridge, MA, USA, 2014. MIT Press.
[25] Hernández-Lobato, D., Hernández-Lobato, J. M., Shah, A., and Adams, R. P. Predictive entropy search for multi-objective bayesian optimization, 2015.
[26] Horn, D., Dagge, M., Sun, X., and Bischl, B. First investigations on noisy model-based multiobjective optimization. volume 10173, pp. 298-313, 02 2017. ISBN 978-3-319-54156-3. doi: 10.1007/978-3-319-54157-0_21.
[27] Igel, C., Hansen, N., and Roth, S. Covariance matrix adaptation for multi-objective optimization. Evolutionary Computation, 15(1):1-28, 2007. doi: 10.1162/evco.2007.15.1.1.
[28] Jiang, S., Zhang, H., Cong, W., Liang, Z., Ren, Q., Wang, C., Zhang, F., and Jiao, X. Multiobjective optimization of smallholder apple production: Lessons from the bohai bay region. Sustainability, 12(16):6496, 2020.
[29] Jones, D. R., Schonlau, M., and Welch, W. J. Efficient global optimization of expensive black-box functions. Journal of Global Optimization, 13:455-492, 1998.
[30] Kingma, D. P. and Welling, M. Auto-Encoding Variational Bayes. arXiv e-prints, pp. arXiv:1312.6114, Dec 2013.
[31] Klamroth, K., Lacour, R., and Vanderpooten, D. On the representation of the search region in multi-objective optimization. European Journal of Operational Research, 245(3):767-778, Sep 2015. ISSN 0377-2217. doi: 10.1016/j.ejor.2015.03.031. URL http://dx.doi.org/ 10.1016/j.ejor.2015.03.031.
[32] Knowles, J. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1): 50-66, 2006.
[33] Koch, P., Wagner, T., Emmerich, M. T., Back, T., and Konen, W. Efficient multi-criteria optimization on noisy machine learning problems. Appl. Soft Comput., 29(C):357-370, April 2015. ISSN 1568-4946. doi: 10.1016/j.asoc.2015.01.005. URL https://doi.org/10.1016/ j.asoc.2015.01.005.
[34] Lacour, R., Klamroth, K., and Fonseca, C. M. A box decomposition algorithm to compute the hypervolume indicator. Computers \&amp; Operations Research, 79:347 - 360, 2017.
[35] LeCun, Y., Cortes, C., and Burges, C. Mnist handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/esdb/mnist, 2, 2010.
[36] Letham, B. and Bakshy, E. Bayesian optimization for policy search via online-offline experimentation. Journal of Machine Learning Research, 20(145):1-30, 2019. URL http: //jmlr.org/papers/v20/18-225.html.
[37] Letham, B., Karrer, B., Ottoni, G., and Bakshy, E. Constrained bayesian optimization with noisy experiments. Bayesian Analysis, 14(2):495-519, 06 2019. doi: 10.1214/18-BA1110.
[38] Liao, T., Wang, G., Yang, B., Lee, R., Pister, K., Levine, S., and Calandra, R. Data-efficient learning of morphology and controller for a microrobot. In 2019 International Conference on Robotics and Automation (ICRA), pp. 2488-2494. IEEE, 2019.
[39] Lukovic, K. M., Tian, Y., and Matusik, W. Diversity-guided multi-objective bayesian optimization with batch evaluations. Advances in Neural Information Processing Systems, 33, 2020.</p>
<p>[40] Mao, H., Chen, S., Dimmery, D., Singh, S., Blaisdell, D., Tian, Y., Alizadeh, M., and Bakshy, E. Real-world video adaptation with reinforcement learning. 2019.
[41] Mao, H., Negi, P., Narayan, A., Wang, H., Yang, J., Wang, H., Marcus, R., Addanki, R., Shirkoohi, M. K., He, S., Nathan, V., Cangialosi, F., Venkatakrishnan, S. B., Weng, W.-H., Han, S.-W., Kraska, T., and Alizadeh, M. Park: An open platform for learning-augmented computer systems. In NeurIPS, 2019.
[42] Mennen, S. M., Alhambra, C., Allen, C. L., Barberis, M., Berritt, S., Brandt, T. A., Campbell, A. D., Castañón, J., Cherney, A. H., Christensen, M., Damon, D. B., Eugenio de Diego, J., García-Cerrada, S., García-Losada, P., Haro, R., Janey, J., Leitch, D. C., Li, L., Liu, F., Lobben, P. C., MacMillan, D. W. C., Magano, J., McInturff, E., Monfette, S., Post, R. J., Schultz, D., Sitter, B. J., Stevens, J. M., Strambeanu, I. I., Twilton, J., Wang, K., and Zajac, M. A. The evolution of high-throughput experimentation in pharmaceutical development and perspectives on the future. Organic Process Research \&amp; Development, 23(6):1213-1242, 2019. doi: $10.1021 /$ acs.oprd.9b00140.
[43] Namkoong, H., Daulton, S., and Bakshy, E. Distilled thompson sampling: Practical and efficient thompson sampling via imitation learning. In NeurIPS Offline Reinforcement Learning Workshop, 2020.
[44] Osborne, M. A. Bayesian gaussian processes for sequential prediction, optimisation and quadrature. 2010.
[45] Paria, B., Kandasamy, K., and Póczos, B. A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations. ArXiv e-prints, May 2018.
[46] Rahimi, A. and Recht, B. Random features for large-scale kernel machines. In Proceedings of the 20th International Conference on Neural Information Processing Systems, NIPS'07, pp. 1177-1184, Red Hook, NY, USA, 2007. Curran Associates Inc. ISBN 9781605603520.
[47] Rasmussen, C. E. Gaussian Processes in Machine Learning, pp. 63-71. Springer Berlin Heidelberg, Berlin, Heidelberg, 2004.
[48] Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classifier architecture search. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01): 4780-4789, Jul. 2019. doi: 10.1609/aaai.v33i01.33014780. URL https://ojs.aaai.org/ index.php/AAAI/article/view/4405.
[49] Schuster, M. Speech recognition for mobile devices at google. In Zhang, B.-T. and Orgun, M. A. (eds.), PRICAI 2010: Trends in Artificial Intelligence, pp. 8-10, Berlin, Heidelberg, 2010. Springer Berlin Heidelberg. ISBN 978-3-642-15246-7.
[50] Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., and de Freitas, N. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148-175, 2016.
[51] Suzuki, S., Takeno, S., Tamura, T., Shitara, K., and Karasuyama, M. Multi-objective Bayesian optimization using pareto-frontier entropy. In III, H. D. and Singh, A. (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 9279-9288. PMLR, 13-18 Jul 2020. URL http://proceedings.mlr.press/v119/suzuki20a.html.
[52] Takeno, S., Fukuoka, H., Tsukada, Y., Koyama, T., Shiga, M., Takeuchi, I., and Karasuyama, M. Multi-fidelity Bayesian optimization with max-value entropy search and its parallelization. In III, H. D. and Singh, A. (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 9334-9345. PMLR, 13-18 Jul 2020. URL http://proceedings.mlr.press/v119/takeno20a.html.
[53] Tanabe, R. and Ishibuchi, H. An easy-to-use real-world multi-objective optimization problem suite. Applied Soft Computing, 89:106078, 2020. ISSN 1568-4946. doi: https://doi.org/10.1016/ j.asoc.2020.106078.
[54] Thompson, W. R. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3/4):285-294, 1933.
[55] Touré, C., Hansen, N., Auger, A., and Brockhoff, D. Uncrowded hypervolume improvement: Como-cma-es and the sofomore framework. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '19, pp. 638-646, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10.1145/3321707.3321852. URL https://doi.org/10.1145/3321707.3321852.</p>
<p>[56] Wang, R., Xiong, J., Ishibuchi, H., Wu, G., and Zhang, T. On the effect of reference point in moea/d for multi-objective optimization. Applied Soft Computing, 58:25-34, 2017. ISSN 1568-4946. doi: https://doi.org/10.1016/j.asoc.2017.04.002. URL https: //www.sciencedirect.com/science/article/pii/S1568494617301722.
[57] Wilson, J., Hutter, F., and Deisenroth, M. Maximizing acquisition functions for bayesian optimization. In Advances in Neural Information Processing Systems 31, pp. 9905-9916. 2018.
[58] Yang, K., Emmerich, M., Deutz, A., and Bäck, T. Multi-objective bayesian global optimization using expected hypervolume improvement gradient. Swarm and Evolutionary Computation, 44: 945 - 956, 2019. ISSN 2210-6502. doi: https://doi.org/10.1016/j.swevo.2018.10.007.
[59] Yang, K., Emmerich, M., Deutz, A. H., and Bäck, T. Efficient computation of expected hypervolume improvement using box decomposition algorithms. CoRR, abs/1904.12672, 2019.
[60] Yang, K., Palar, P., Emmerich, M., Shimoyama, K., and Bäck, T. A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. pp. 656-663, 072019 . doi: $10.1145 / 3321707.3321784$.
[61] Yang, K., Palar, P. S., Emmerich, M., Shimoyama, K., and Bäck, T. A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO '19, pp. 656-663, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10.1145/3321707.3321784. URL https://doi.org/10.1145/ 3321707.3321784.
[62] Youn, B. D., Choi, K., Yang, R.-J., and Gu, L. Reliability-based design optimization for crashworthiness of vehicle side impact. Structural and Multidisciplinary Optimization, 26: 272-283, 02 2004. doi: 10.1007/s00158-003-0345-0.
[63] Zhang, G. and Block, D. E. Using highly efficient nonlinear experimental design methods for optimization of lactococcus lactis fermentation in chemically defined media. Biotechnology progress, 25(6):1587-1597, 2009.
[64] Zhang, Q., Liu, W., Tsang, E., and Virginas, B. Expensive multiobjective optimization by moea/d with gaussian process model. IEEE Transactions on Evolutionary Computation, 14(3): 456-474, 2010. doi: 10.1109/TEVC.2009.2033671.
[65] Zhou, A., Zhang, Q., and Zhang, G. A multiobjective evolutionary algorithm based on decomposition and probability model. In 2012 IEEE Congress on Evolutionary Computation, pp. 1-8, 2012. doi: 10.1109/CEC.2012.6252954.
[66] Zitzler, E., Deb, K., and Thiele, L. Comparison of multiobjective evolutionary algorithms: Empirical results. Evol. Comput., 8(2):173-195, June 2000. ISSN 1063-6560. doi: 10.1162/ 106365600568202. URL https://doi.org/10.1162/106365600568202.
[67] Zitzler, E., Deb, K., and Thiele, L. Comparison of multiobjective evolutionary algorithms: Empirical results. Evolutionary computation, 8(2):173-195, 2000.</p>
<h1>Appendix to:</h1>
<h2>Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement</h2>
<h2>A Potential Societal Impact</h2>
<p>Bayesian Optimization specifically aims to increase sample efficiency for hard optimization algorithms, and consequently can help achieve better solutions without incurring large societal costs. For instance, as demonstrated in this work, automotive design problems may be solved much faster, reducing the amount of computationally costly simulations and thus the energy footprint during development. At the same time, improved solutions mean that high crash safety can be achieved with lighter cars, resulting in fewer resources required for their production and, importantly, improving fuel economy of the whole vehicle fleet. Increased robustness to noisy observations further helps reduce the resources spent on evaluating regions of the search space that are not promising. Improvements to the optimization performance and practicality of multi-objective Bayesian optimization have the potential to allow decision makers to better understand and make more informed decisions across multiple trade-offs. We expect these directions to be particularly important as Bayesian optimization is increasingly used for applications such as recommender systems [36], where auxiliary goals such as fairness must be accounted for. Of course, at the end of the day, exactly what objectives decision makers choose to optimize, and how they balance those trade-offs (and whether that is done in equitable fashion) is up to the individuals themselves.</p>
<h2>B Computing Hypervolume Improvement with Box Decompositions</h2>
<p>Definition 3. For a set of objective vectors $\left{\boldsymbol{f}\left(\boldsymbol{x}<em i="1">{i}\right)\right}</em>}^{q}$, a reference point $\boldsymbol{r} \in \mathbb{R}^{M}$, and a Pareto frontier $\mathcal{P}$, let $\Delta\left(\left{\boldsymbol{f}\left(\boldsymbol{x<em i="1">{i}\right)\right}</em>}^{q}, \mathcal{P}, \boldsymbol{r}\right) \subset \mathbb{R}^{M}$ denote the set of points (1) that are dominated by $\left{\boldsymbol{f}\left(\boldsymbol{x<em i="1">{i}\right)\right}</em>$.}^{q}$, (2) that dominate $\boldsymbol{r}$, and (3) that are not dominated by $\mathcal{P</p>
<p>Let $\left{S_{1}, \ldots, S_{K}\right}$ be a set of $K$ disjoint axis-aligned rectangles where each $S_{k}$ is defined by a pair of lower and upper vertices $\boldsymbol{l}<em k="k">{k} \in \mathbb{R}^{M}$ and $\boldsymbol{u}</em>} \in \mathbb{R}^{M} \cup{\infty}$. Figure 5 shows an example decomposition. Such a partitioning allows for efficient piece-wise computation of the hypervolume improvement from a new point $\boldsymbol{f}\left(\boldsymbol{x<em i="i">{i}\right)$ by computing the volume of the intersection of the region dominated exclusively by the new point with $\Delta\left(\left{f\left(\boldsymbol{x}</em>}\right), \mathcal{P}, \boldsymbol{r}\right)\right.$ (and not dominated by the $\left.P\right)$ with each hyperrectangle $S_{k}$. Although $\Delta\left(\boldsymbol{f}\left(\boldsymbol{x<em i="i">{i}\right), \mathcal{P}, \boldsymbol{r}\right)$ is a non-rectangular polytope, the intersection of $\Delta\left(\boldsymbol{f}\left(\boldsymbol{x}</em>}\right), \mathcal{P}, \boldsymbol{r}\right)$ with each rectangle $S_{k}$ is a rectangular polytope and the vertices bounding the hyperrectangle corresponding to $\Delta\left(\boldsymbol{f}\left(\boldsymbol{x<em k="k">{i}\right), \mathcal{P}, \boldsymbol{r}\right) \cap S</em>}$ can be easily computed: the lower bound vertex is $\boldsymbol{l<em k="k">{k}$ and the upper bound vertex is the component-wise minimum of $\boldsymbol{u}</em>}$ and the new point $\boldsymbol{f}(\boldsymbol{x}): \boldsymbol{z<em k="k">{k}:=\min \left[\boldsymbol{u}</em>}, \boldsymbol{f}(\boldsymbol{x})\right]$. The hypervolume improvement can be computed by summing over the volume of $\Delta\left(\boldsymbol{f}\left(\boldsymbol{x<em k="k">{i}\right), \mathcal{P}, \boldsymbol{r}\right) \cap S</em>$}$ over all $S_{k</p>
<p>$$
\operatorname{HVI}(\boldsymbol{f}(\boldsymbol{x}), \mathcal{P})=\sum_{k=1}^{K} \operatorname{HVI}<em k="k">{k}\left(\boldsymbol{f}(\boldsymbol{x}), \boldsymbol{l}</em>}, \boldsymbol{u<em k="1">{k}\right)=\sum</em>}^{K} \prod_{m=1}^{M}\left[\dot{z<em k="k">{k}^{(m)}-l</em>
$$}^{(m)}\right]_{+</p>
<p>where $[\cdot]_{+}$denotes the $\max (\cdot, 0)$ operation.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The hypervolume improvement from a new point $\boldsymbol{f}(\boldsymbol{x})$ is shown in blue. The current Pareto frontier $\mathcal{P}$ is given by the green points, the green area is the hypervolume of the Pareto frontier $\mathcal{P}$ given reference point $\boldsymbol{r}$. The white rectangles $S_{1}, \ldots, S_{k}$ are a disjoint, box decomposition of the non-dominated space that can be used to efficiently compute the hypervolume improvement.</p>
<h1>C $q$ NEHVI under Different Computational Approaches</h1>
<h2>C. 1 Derivation of IEP formulation of $q$ NEHVI</h2>
<p>From (4), the expected noisy joint hypervolume improvement is given by</p>
<p>$$
\hat{\alpha}<em _mathrm_cand="\mathrm{cand">{q \mathrm{NEHVI}}\left(\mathcal{X}</em>}}\right)=\frac{1}{N} \sum_{t=1}^{N} \operatorname{HVI}\left(\tilde{\boldsymbol{f}<em _mathrm_cand="\mathrm{cand">{t}\left(\mathcal{X}</em>\right)
$$}}\right) \mid \mathcal{P}_{t</p>
<p>Recall that the joint HVI formulation under the IEP derived by Daulton et al. [11] is given by</p>
<p>$$
\operatorname{HVI}\left(\boldsymbol{f}\left(\mathcal{X}<em k="1">{\mathrm{cand}}\right) \mid \mathcal{P}\right)=\sum</em>}^{K} \sum_{j=1}^{q} \sum_{X_{j} \in \mathcal{X<em m="1">{j}}(-1)^{j+1} \prod</em>
$$}^{M}\left[z_{k, X_{j}}^{(m)}-l_{k}^{(m)}\right]_{+</p>
<p>where $\mathcal{X}<em j="j">{j}:=\left{X</em>} \subseteq \mathcal{X<em j="j">{\text {cand }}:\left|X</em>}\right|=j\right}$ and $z_{k, t, X_{j}}^{(m)}:=\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}\right), \ldots, f^{(m)}\left(\boldsymbol{x<em j="j">{i</em>}}\right)\right]$ for $X_{j}=\left{\boldsymbol{x<em 1="1">{i</em>}}, \ldots, \boldsymbol{x<em j="j">{i</em>$. Hence,}}\right}$. In $q$ NEHVI, the lower and upper bounds and the number of rectangles in each box decomposition depend $\mathcal{P}_{t</p>
<p>$$
\hat{\alpha}<em _mathrm_cand="\mathrm{cand">{q \mathrm{NEHVI}}\left(\mathcal{X}</em>}}\right)=\frac{1}{N} \sum_{t=1}^{N} \sum_{k=1}^{K_{t}} \sum_{j=1}^{q} \sum_{X_{j} \in \mathcal{X<em m="1">{j}}(-1)^{j+1} \prod</em>
$$}^{M}\left[z_{k, t, X_{j}}^{(m)}-l_{k, t}^{(m)}\right]_{+</p>
<p>where $z_{k, t, X_{j}}^{(m)}:=\min \left[u_{k, t}^{(m)}, \tilde{f}<em i__1="i_{1">{t}^{(m)}\left(\boldsymbol{x}</em>}}\right), \ldots, \tilde{f<em i__j="i_{j">{t}^{(m)}\left(\boldsymbol{x}</em>}}\right)\right]$ for $X_{j}=\left{\boldsymbol{x<em 1="1">{i</em>}}, \ldots, \boldsymbol{x<em j="j">{i</em>\right}$.}</p>
<h2>C. 2 Derivation of CBD formulation of $q$ NEHVI</h2>
<p>Using Definition 2, we rewrite (4) as</p>
<p>$$
\begin{aligned}
\hat{\alpha}<em _mathrm_cand="\mathrm{cand">{q \mathrm{NEHVI}}\left(\mathcal{X}</em>}}\right) &amp; =\frac{1}{N} \sum_{t=1}^{N} \operatorname{HVI}\left(\tilde{\boldsymbol{f}<em _mathrm_cand="\mathrm{cand">{t}\left(\mathcal{X}</em>}}\right) \mid \mathcal{P<em t="1">{t}\right) \
&amp; =\frac{1}{N} \sum</em>}^{N}\left[\operatorname{HV}\left(\tilde{\boldsymbol{f}}\left(\mathcal{X<em t="t">{\mathrm{cand}}\right) \cup P</em>\right)\right]
\end{aligned}
$$}\right)-\operatorname{HV}\left(P_{t</p>
<p>Adding and subtracting $\operatorname{HV}\left(\tilde{\boldsymbol{f}}\left(\left{\boldsymbol{x}<em q-1="q-1">{1}\right), \ldots, \tilde{\boldsymbol{f}}\left(x</em>$ ) yields}\right)\right}\right) \cup P_{t</p>
<p>$$
\begin{aligned}
&amp; \hat{\alpha}<em _mathrm_cand="\mathrm{cand">{q \mathrm{NEHVI}}\left(\mathcal{X}</em>}}\right)=\frac{1}{N} \sum_{t=1}^{N}\left[\operatorname{HV}\left(\tilde{\boldsymbol{f}}\left(\mathcal{X<em t="t">{\mathrm{cand}}\right) \cup P</em>}\right)-\operatorname{HV}\left(\tilde{\boldsymbol{f}}\left(\left{\boldsymbol{x<em q-1="q-1">{1}\right), \ldots, \tilde{\boldsymbol{f}}\left(x</em>\right)\right. \
&amp; \left.+\operatorname{HV}\left(\left{\tilde{\boldsymbol{f}}\left(\boldsymbol{x}}\right)\right}\right) \cup P_{t<em q-1="q-1">{1}\right), \ldots, \tilde{\boldsymbol{f}}\left(x</em>\right)\right] .
\end{aligned}
$$}\right)\right} \cup P_{t}\right)-\operatorname{HV}\left(P_{t</p>
<p>Applying Definition 2 again leads to (6):</p>
<p>$$
\begin{aligned}
&amp; \hat{\alpha}<em _cand="{cand" _text="\text">{\mathrm{qNEHVI}}\left(\mathcal{X}</em>}}\right)=\frac{1}{N} \sum_{t=1}^{N} \operatorname{HVI}\left(\hat{\boldsymbol{f}}\left(\boldsymbol{x<em 1="1">{q}\right) \mid\left{\hat{\boldsymbol{f}}\left(\boldsymbol{x}</em>}\right), \ldots, \hat{\boldsymbol{f}}\left(\boldsymbol{x<em t="t">{q-1}\right)\right} \cup P</em>\right) \
&amp; +\frac{1}{N} \sum_{t=1}^{N} \operatorname{HVI}\left(\left{\hat{\boldsymbol{f}}\left(\boldsymbol{x}<em q-1="q-1">{1}\right), \ldots, \hat{\boldsymbol{f}}\left(\boldsymbol{x}</em>\right\rangle .
\end{aligned}
$$}\right)\right}\right)\left|P_{t</p>
<p>Note that using the method of common random numbers, the CBD formulation is mathematically equivalent to IEP formulation, but the computing $q \mathrm{NEHVI}$ with the CBD trick is much more efficient.</p>
<h1>D Complexity Analysis</h1>
<h2>D. 1 Complexity of Computing $q$ NEHVI</h2>
<p>In this section we study the complexity of computing the acquisition function. For brevity, we omit the cost of posterior sampling, which is the same for the CBD and IEP approaches. ${ }^{6}$
The CBD approach requires recomputing box decompositions when generating each new candidate. In the worst case, each new candidate is Pareto optimal under the fixed posterior samples, which leads to a time complexity of $O\left(N(n+i)^{M}\right)$ for computing the box decompositions in iteration $i$ [59]. Note that there are $O\left((n+i)^{M}\right)$ rectangles in each box decomposition. Given box decompositions and posterior samples at the new point, the complexity of computing the acquisition function on a single-threaded machine is $O\left(M N(n+i)^{M}\right)$. Hence, the total time complexity for generating $q$ candidates (ignoring potentially additional time complexity for automated gradient computations) is</p>
<p>$$
\begin{gathered}
O\left(N \sum_{i=1}^{q}(n+i)^{M}\right)+O\left(N_{\mathrm{opt}} M N \sum_{i=1}^{q}(n+i)^{M}\right)=O\left(N_{\mathrm{opt}} N M(n+q)^{M} q\right) \
O\left(N n^{M}\right)+O\left(N_{\mathrm{opt}} M N n^{M} \sum_{i=1}^{q} 2^{i-1}\right)=O\left(N_{\mathrm{opt}} N M n^{M} 2^{q} q\right)
\end{gathered}
$$</p>
<p>The second term on the left hand side in both (9) and (10) is the acquisition optimization complexity, which boils down to $O\left(N_{\text {opt }}\right)$ given infinite computing cores because the acquisition computation is completely parallelizable. However, as shown in Figure 2, even for relatively small values of $q$, CPU cores become saturated and GPU memory limits are reached.</p>
<p>Everything else fixed, the asymptotic relative time complexity of using CBD over IEP is therefore $q^{-M} 2^{q} \rightarrow \infty$ as $q \rightarrow \infty$.
Similarly, the space complexity under the CBD formulation, $O\left(M N(n+q)^{M}\right)$, is also polynomial in $q$, whereas the space complexity is exponential in $q$ under the IEP formulation: $O\left(M N n^{M} q 2^{q}\right)$.
Everything else fixed, the asymptotic relative complexity (both in terms of time and space) of using CBD over IEP is therefore $q^{M} 2^{-q} \rightarrow 0$ as $q \rightarrow \infty$.</p>
<h2>D. 2 Efficient Batched Computation</h2>
<p>As noted above, using either the IEP or CBD approach, the acquisition computation given the box decompositions is highly parallelizable. However, since the number of hyperrectangles $K_{t}$ in the box decompoosition can be different under each posterior sample $\hat{\boldsymbol{f}}_{t}$, stacking the box decompositions does not result in a rectangular matrix; the matrix is ragged. In order to leverage modern batched</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>tensor computational paradigms, we pad the box decompositions with empty hyperrectangles (e.g. $\boldsymbol{l}=\mathbf{0}, \boldsymbol{u}=\mathbf{0}$ ) such that the box decomposition under every posterior sample contains exactly $K=\max <em t="t">{t} K</em>$ hyperrectangles, which allows us to define a $t \times K$ dimensional matrix of box decompositions for use in batched tensor computation.</p>
<p>In the 2-objective case, instead of padding the box decomposition, the Pareto frontier under each posterior sample can be padded instead by repeating a point on the Pareto Frontier such that the padded Pareto frontier under every posterior sample has exactly $\max <em t="t">{t}\left|\mathcal{P}</em>\right|$ points. This enables computing the box decompositions analytically for all posterior samples in parallel using efficient batched computation. The resulting box decompositions all have $K=\max <em t="t">{t}\left|\mathcal{P}</em>\right|+1$ hyperrectangles (some of which may be empty).</p>
<h1>E Theoretical Results</h1>
<p>Let $\boldsymbol{x}<em n="n">{\text {prev }} \in \mathbb{R}^{n d}$ denote the stacked set of previously evaluated points in $X</em>}: \boldsymbol{x<em 1="1">{\text {prev }}:=\left[\boldsymbol{x}</em>}^{T}, \ldots, \boldsymbol{x<em _cand="{cand" _text="\text">{n}^{T}\right]^{T}$. Similarly, let $\boldsymbol{x}</em>}} \in \mathbb{R}^{q d}$ denote the stacked set of candidates in $\mathcal{X<em _cand="{cand" _text="\text">{\text {cand }}: \boldsymbol{x}</em>}}:=\left[\boldsymbol{x<em n_q="n+q">{n+1}^{T}, \ldots, \boldsymbol{x}</em>}^{T}\right]^{T}$. Let $\hat{\boldsymbol{f}<em _prev="{prev" _text="\text">{t}\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em t="t">{\text {cand }}\right):=\left[\hat{\boldsymbol{f}}</em>}\left(\boldsymbol{x<em t="t">{1}\right)^{T}, \ldots, \hat{\boldsymbol{f}}</em>$ sample of the corresponding objectives, which we write using the parameterization trick as}\left(\boldsymbol{x}_{n+q}\right)^{T}\right]^{T}$ denote the $t^{\text {th }</p>
<p>$$
\boldsymbol{f}<em _prev="{prev" _text="\text">{t}\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}\right)=\mu\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}\right)+L\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em t="t">{\text {cand }}\right) \boldsymbol{\zeta}</em>
$$</p>
<p>where $\mu\left(\boldsymbol{x}<em _cand="{cand" _text="\text">{\text {prev }}, \boldsymbol{x}</em>}}\right): \mathbb{R}^{(n+q) d} \rightarrow \mathbb{R}^{(n+q) M}$ is the multi-output GP's posterior mean and $L\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right) \in \mathbb{R}^{(n+q) M \times(n+q) M}$ is a root decomposition (often a Cholesky decomposition) of the multi-output GP's posterior covariance $\Sigma\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right) \in \mathbb{R}^{(n+q) M \times(n+q) M}$, and $\boldsymbol{\zeta<em t="t">{t} \in \mathbb{R}^{(n+q) M}$ with $\boldsymbol{\zeta}</em>$} \sim \mathcal{N}\left(0, I_{(n+q) M}\right) .^{7</p>
<p>Proof of Theorem 1. Since the sequential NEHVI is equivalent to the $q$ NEHVI with $q=1$, we prove Theorem 1 for the general $q&gt;1$ case. Recall from Section C.2, that using the method of common random numbers to fix the base samples, the IEP and CBD formulations are equivalent. Therefore, we proceed only with the IEP formulation for this proof.
We closely follow the proof of Theorem 2 in Daulton et al. [11]. We consider the setting from Balandat et al. [2, Section D.5]. Let $f_{t}^{(m)}\left(\boldsymbol{x}<em t="t">{i}, \boldsymbol{\zeta}</em>}\right)=S_{{i, m}}\left(\mu\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)+L\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right) \boldsymbol{\zeta<em i="i">{t}\right)$ denote the posterior distribution over the $m^{\text {th }}$ outcome at $\boldsymbol{x}</em>\right|}$ as a random variable, where $S_{{i, m}}$ denotes the selection matrix $\left(\left|S_{{i, m}<em i="i">{\infty} \leq 1\right.$ for all $\left.i=1, \ldots, n+q\right)$ and $\left.m=1, \ldots, M\right)$, to extract the element corresponding to outcome $m$ for the point $\boldsymbol{x}</em>$. The HVI under a single posterior sample is given by</p>
<p>$$
A\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>} ; \boldsymbol{x<em k="1">{\text {prev }}\right)=\sum</em>}^{K_{t}} \sum_{j=1}^{q} \sum_{X_{j} \in \mathcal{X<em m="1">{j}}(-1)^{j+1} \prod</em>}^{M}\left[z_{k, X_{j}}^{(m)}\left(\boldsymbol{\zeta<em k="k">{t}\right)-l</em>
$$}^{(m)}\right]_{+</p>
<p>where $\mathcal{X}<em j="j">{j}:=\left{X</em>}=\left{\boldsymbol{x<em 1="1">{i</em>}}, \ldots \boldsymbol{x<em j="j">{i</em>}}\right} \subseteq \mathcal{X<em j="j">{\text {cand }}:\left|X</em>}\right|=j, n+1 \leq i_{1} \leq i_{j} \leq n+q\right}$ and $z_{k, X_{j}}^{(m)}\left(\boldsymbol{\zeta<em k="k">{t}\right)=\min \left[u</em>}^{(m)}, f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 1="1">{t}\right)\right]$. Note that the box decomposition of the non-dominated space $\left{S</em>}, \ldots, S_{K_{t}}\right}$ and the number of rectangles in the box decomposition depend on $\boldsymbol{\zeta<em t="t">{t}$. Importantly, the number of hyperrectangles $K</em>}$ in the decomposition is a finite and bounded by $O\left(\left|\mathcal{P<em t="t">{t}\right|^{\left\lfloor\frac{M}{2}\right\rfloor+1}\right)[34,59]$, where $\left|\mathcal{P}</em>\right| \leq n$.
To satisfy the conditions of [2, Theorem 3], we need to show that there exists an integrable function $\ell: \mathbb{R}^{q \times M} \mapsto \mathbb{R}$ such that for almost every $\boldsymbol{\zeta}<em _cand="{cand" _text="\text">{t}$ and all $\boldsymbol{x}</em>$,}}, \boldsymbol{y}_{\text {cand }} \subseteq \mathcal{X</p>
<p>$$
\left|A\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>} ; \boldsymbol{x<em _cand="{cand" _text="\text">{\text {prev }}\right)-A\left(\boldsymbol{y}</em>}}, \boldsymbol{\zeta<em _prev="{prev" _text="\text">{t} ; \boldsymbol{x}</em>}}\right)\right| \leq \ell\left(\boldsymbol{\zeta<em _cand="{cand" _text="\text">{t}\right)\left|\boldsymbol{x}</em>\right|
$$}}-\boldsymbol{y}_{\text {cand }</p>
<p>We note that $\boldsymbol{x}<em _prev="{prev" _text="\text">{\text {prev }}$ is fixed and omit $\boldsymbol{x}</em>$ for brevity, except where necessary.
Let}</p>
<p>$$
\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right):=\left[\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em k_="k," t="t">{t}\right)\right]-l</em>
$$}^{(m)}\right]_{+</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Because of linearity, it suffices to show that this condition holds for</p>
<p>$$
\tilde{A}\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right):=\prod_{m=1}^{M} \tilde{a<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)=\prod_{m=1}^{M}\left[\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em k_="k," t="t">{t}\right)\right]-l</em>
$$}^{(m)}\right]_{+</p>
<p>for all $k, j$, and $X_{j}$. Note that we can bound $\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)$ by</p>
<p>$$
\begin{aligned}
\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right) &amp; \leq\left|\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em k_="k," t="t">{t}\right)\right]-l</em>\right| \
&amp; \leq\left|l_{k, t}^{(m)}\right|+\left|\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x}}^{(m)<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>\right)\right]\right|
\end{aligned}
$$}}, \boldsymbol{\zeta}_{t</p>
<p>Consider the case where $u_{k, t}^{(m)}=\infty$. Then</p>
<p>$$
\min \left[u_{k, t}^{(m)}, f\left(\boldsymbol{x}<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right)^{(m)}, \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em i__1="i_{1">{t}\right)\right]=\min \left[f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>\right)\right]
$$}}, \boldsymbol{\zeta}_{t</p>
<p>Now suppose $u_{k, t}^{(m)}&lt;\infty$. Then</p>
<p>$$
\min \left[u_{k, t}^{(m)}, f^{(m)}\left(\boldsymbol{x}<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em i__1="i_{1">{t}\right)\right]&lt;\left[\min \left[f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em k_="k," t="t">{t}\right)\right]\right]+\left|u</em>\right|
$$}^{(m)</p>
<p>Let</p>
<p>$$
w_{k, t}^{(m)}= \begin{cases}u_{k, t}^{(m)}, &amp; \text { if } u_{k, t}^{(m)}&lt;\infty \ 0, &amp; \text { otherwise }\end{cases}
$$</p>
<p>Note that $l_{k, t}^{(m)}$ is finite and bounded from above and below by $r^{(m)} \leq l_{k, t}^{(m)}&lt;u_{k, t}^{(m)}$ for all $k, t, m$, where $r^{(m)}$ is the $m^{\text {th }}$ dimension of the reference point.
Hence, we can express the bound in (13) as</p>
<p>$$
\begin{aligned}
\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right) &amp; \leq\left|l_{k, t}^{(m)}\right|+\left|w_{k, t}^{(m)}\right|+\left|\min \left[f^{(m)}\left(\boldsymbol{x<em 1="1">{i</em>}}, \boldsymbol{\zeta<em i__j="i_{j">{t}\right), \ldots, f^{(m)}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em k_="k," t="t">{t}\right)\right]\right| \
&amp; \leq\left|l</em>}^{(m)}\right|+\left|w_{k, t}^{(m)}\right|+\sum_{i_{1}, \ldots, i_{j}}\left|f^{(m)}\left(\boldsymbol{x<em j="j">{i</em>\right)\right|
\end{aligned}
$$}}, \boldsymbol{\zeta}_{t</p>
<p>Note that we can bound $\sum_{i_{1}, \ldots, i_{j}}\left|f^{(m)}\left(\boldsymbol{x}<em j="j">{i</em>\right)\right|$ by}}, \boldsymbol{\zeta}_{t</p>
<p>$$
\sum_{i_{1}, \ldots, i_{j}}\left|f^{(m)}\left(\boldsymbol{x}<em j="j">{i</em>}}, \boldsymbol{\zeta<em j="j">{t}\right)\right| \leq\left|X</em>}\right|\left(\left|\mu^{(m)}\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)\right|+\left|L^{(m)}\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>\right|\right)
$$}}\right)\right|\left|\boldsymbol{\zeta}_{t</p>
<p>Substituting this into (14) yields</p>
<p>$$
\left|\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\right| \leq\left|l_{k, t}^{(m)}\right|+\left|w_{k, t}^{(m)}\right|+\left|X_{j}\right|\left(\left|\mu^{(m)}\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)\right|+\left|L^{(m)}\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>\right|\right)
$$}}\right)\right|\left|\boldsymbol{\zeta}_{t</p>
<p>for all $k, m, j, X_{j}$.
Because of our assumptions of that $\mathcal{X}$ is compact and that the mean and covariance functions are continuously differentiable, $\mu\left(\boldsymbol{x}<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right), L\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right), \nabla_{\boldsymbol{x<em _cand="{cand" _text="\text">{\text {cand }}} \mu\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{\text {prev }}\right)$, and $\nabla</em><em _cand="{cand" _text="\text">{\text {cand }}} L\left(\boldsymbol{x}</em>}}, \boldsymbol{x<em 1="1">{\text {prev }}\right)$ are uniformly bounded. Hence, there exist $C</em>&lt;\infty$ such that}, C_{2</p>
<p>$$
\left|\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right|
$$}\right)\right| \leq C_{1}+C_{2}\left|\boldsymbol{\zeta}_{t</p>
<p>for all $k, m, j, X_{j}$.
Consider the $M=2$ case. Omitting the indices $k, t, j, X_{j}$ for brevity, we have</p>
<p>$$
\begin{aligned}
\left|\tilde{A}\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\right. &amp; \tilde{A}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right) \mid \
&amp; =\left|\tilde{a}<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right) \tilde{a}</em>}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{y}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right) \tilde{a}</em>}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)\right| \
&amp; =\left|\tilde{a}<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right)\left(\tilde{a}</em>}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em _cand="{cand" _text="\text">{2}\left(\boldsymbol{y}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right)\right)+\tilde{a}</em>}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\left(\tilde{a<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 1="1">{t}\right)-\tilde{a}</em>}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)\right)\right| \
&amp; \leq\left|\tilde{a}<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right)\right|\left|\tilde{a}</em>}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em _cand="{cand" _text="\text">{2}\left(\boldsymbol{y}</em>}}, \boldsymbol{\zeta<em 2="2">{t}\right)\right|+\left|\tilde{a}</em>}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\right|\left|\tilde{a<em _cand="{cand" _text="\text">{1}\left(\boldsymbol{x}</em>}}, \boldsymbol{\zeta<em 1="1">{t}\right)-\tilde{a}</em>}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)\right|
\end{aligned}
$$</p>
<p>Using (15), we can bound $\left|\tilde{a}<em j="j">{k, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em j="j">{k m j X</em>}}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)\right|$ by</p>
<p>$$
\begin{aligned}
&amp; \left|\tilde{a}<em j="j">{k, t, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em j="j">{k, t, m, j, X</em>}}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>\right)\right| \
&amp; \leq \sum_{i_{1}, \ldots, i_{j}}\left|S_{\left{i_{j}, m\right}}\left(\mu\left(\boldsymbol{x}<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)+L\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right) \boldsymbol{\zeta<em _left_123_i__j="\left{i_{j">{t}\right)-S</em>}, m\right}}\left(\mu\left(\boldsymbol{y<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)+L\left(\boldsymbol{y<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right) \boldsymbol{\zeta<em j="j">{t}\right)\right| \
&amp; \leq\left|X</em>}\right|\left(\left|\mu\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)-\mu\left(\boldsymbol{y<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)\right|+| L\left(\boldsymbol{x<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>}}\right)-L\left(\boldsymbol{y<em _prev="{prev" _text="\text">{\text {cand }}, \boldsymbol{x}</em>\right|\right) .
\end{aligned}
$$}}\right) |\left|\boldsymbol{\zeta}_{t</p>
<p>Since $\mu$ and $L$ have uniformly bounded gradients with respect to $\boldsymbol{x}<em _cand="{cand" _text="\text">{\text {cand }}$ and $\boldsymbol{y}</em>&lt;\infty$ such that}}$, they are Lipschitz. Therefore, there exist $C_{3}, C_{4</p>
<p>$$
\left|\tilde{a}<em j="j">{k, t, m, j, X</em>}}\left(\boldsymbol{x<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{a<em j="j">{k, t, m, j, X</em>}}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\right| \leq\left(C_{3}+C_{4}\left|\boldsymbol{\zeta<em _cand="{cand" _text="\text">{t}\right|\right)\left|\boldsymbol{x}</em>\right|
$$}}-\boldsymbol{y}_{\text {cand }</p>
<p>for all $\boldsymbol{x}<em _cand="{cand" _text="\text">{\text {cand }}, \boldsymbol{y}</em>$.
Substituting (17) into (16), we have}}, k, t, m, j, X_{j</p>
<p>$$
\left|\tilde{A}\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{A}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\right| \leq 2\left(C_{1} C_{3}+\left(C_{1} C_{4}+C_{2} C_{3}\right)\left|\boldsymbol{\zeta<em 2="2">{t}\right|+C</em>} C_{4}\left|\boldsymbol{\zeta<em _cand="{cand" _text="\text">{t}\right|^{2}\right)\left|\boldsymbol{x}</em>\right|
$$}}-\boldsymbol{y}_{\text {cand }</p>
<p>The $M&gt;2$ is very similar to the $M=2$ case in (16) albeit with more complex expansions. Similarly, There exist $C&lt;\infty$ such that</p>
<p>$$
\left|\tilde{A}\left(\boldsymbol{x}<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)-\tilde{A}\left(\boldsymbol{y<em t="t">{\text {cand }}, \boldsymbol{\zeta}</em>}\right)\right| \leq C \sum_{m=1}^{M}\left|\boldsymbol{\zeta<em _cand="{cand" _text="\text">{t}\right|^{m}\left|\boldsymbol{x}</em>\right|
$$}}-\boldsymbol{y}_{\text {cand }</p>
<p>Let us define $\ell\left(\boldsymbol{\zeta}<em m="1">{t}\right):=C \sum</em>}^{M}\left|\boldsymbol{\zeta<em t="t">{t}\right|^{m}$. Note that $\ell\left(\boldsymbol{\zeta}</em>\right)$ is integrable because all absolute moments exist for the Gaussian distribution. Since this satisfies the criteria for Theorem 3 in Balandat et al. [2], the theorem holds for $q$ NEHVI.</p>
<h1>E. 1 Unbiased Gradient estimates from the MC formulation</h1>
<p>As noted in Section 7, we can show the following (note that this result is not actually required for Theorem 1):
Proposition 1. Suppose that the GP mean and covariance function are continuously differentiable. Suppose further that the candidate set $\mathcal{X}<em _boldsymbol_x="\boldsymbol{x">{\text {cand }}$ has no duplicates, and that the sample-level gradients $\nabla</em>)\right)$ are obtained using the reparameterization trick as in Balandat et al. [2]. Then}} \operatorname{HVI}\left(\hat{f}_{t}(\boldsymbol{x</p>
<p>$$
\mathbb{E}\left[\nabla_{\boldsymbol{x}<em _mathrm_NEHVI="\mathrm{NEHVI" q="q">{\text {cand }}} \hat{\alpha}</em>}}^{N}\left(\boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{\text {cand }}\right)\right]=\nabla</em><em _mathrm_NEHVI="\mathrm{NEHVI" q="q">{\text {cand }}} \alpha</em>\right)
$$}}\left(\boldsymbol{x}_{\text {cand }</p>
<p>that is, the averaged sample-level gradient is an unbiased estimate of the gradient of the true acquisition function.</p>
<p>The proof of Proposition 1 closely follows the proof of Proposition 1 in Daulton et al. [11].</p>
<h2>F Error Bound on Sequential Greedy Approximation for NEHVI</h2>
<p>If the acquisition function $\mathcal{L}\left(\mathcal{X}<em _cand="{cand" _text="\text">{\text {cand }}\right)$ is a normalized (meaning $\mathcal{L}(\emptyset)=0$ ), monotone, submodular (meaning that the increase in $\mathcal{L}\left(\mathcal{X}</em>}}\right)$ is non-increasing as elements are added to $\mathcal{X<em _mathcal_X="\mathcal{X">{\text {cand }}$ set function), then the sequential greedy approximation $\mathcal{L}$ of $\mathcal{L}$ enjoys regret of no more than $\frac{1}{e} \mathcal{L}^{<em>}$, where $\mathcal{L}^{</em>}=\max </em><em _cand="{cand" _text="\text">{\text {cand }} \subseteq \mathcal{X}} L\left(\mathcal{X}</em>}}\right)$ is the optima of $\mathcal{L}$ [18]. We have $\alpha_{q \text { NEHVI }}\left(\mathcal{X<em _cand="{cand" _text="\text">{\text {cand }}\right)=\mathcal{L}\left(\mathcal{X}</em>}}\right)=$ $\mathbb{E<em _mathrm_EHVI="\mathrm{EHVI" q="q">{\mathcal{P}}\left[\alpha</em>}}\left(\mathcal{X<em _mathrm_EHVI="\mathrm{EHVI" q="q">{\text {cand }} \mid \mathcal{P}\right)\right]$. For a fixed, known $\mathcal{P}$, Daulton et al. [11] showed that $\alpha</em>}}$ is submodular set function. In $\alpha_{q \text { NEHVI }}, \mathcal{P}$ is a stochastic, so $\alpha_{q \mathrm{EHVI}}\left(\mathcal{X<em NEHVI="NEHVI" _="{" _text="\text" q="q">{\text {cand }} \mid \mathcal{P}\right)$ is a stochastic submodular set function. Because the expectation of a stochastic submodular function is submodular [1], $\alpha</em>}}$ is also submodular. Hence, the sequential greedy approximation of $\alpha_{q \text { NEHVI }}$ enjoys regret of no more than $\frac{1}{e} \alpha_{q \text { NEHVI }}{}$. Using the result from Wilson et al. [57], the MC-based approximation $\hat{\alpha<em _cand="{cand" _text="\text">{q \text { NEHVI }}\left(\mathcal{X}</em>}}\right)=\sum_{t=1}^{N} \operatorname{HVI}\left[\boldsymbol{f<em _cand="{cand" _text="\text">{t}\left(\mathcal{X}</em>$}}\right) \mid P_{t}\right]$ also enjoys the same regret bound because HVI is a normalized submodular set function. ${ }^{8</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>G Experiment Setup</h1>
<h2>G. 1 Implementation / Code used in the experiments</h2>
<p>Our implementations of $q$ NEHVI, MESMO, PFES are available in the supplementary files and will be open-sourced under MIT license upon publication. For PESMO, we use the open-source implementation in Spearmint (https://github.com/HIPS/Spearmint/tree/PESM), which is licensed by Harvard. For DGEMO, MOEA/D-EGO, and TSEMO we use the open-source implementations available at https://github.com/yunshengtian/DGEMO/tree/master under the MIT license. For TS-TCH, $q$ EHVI, and qNParEGO we use the open-source implementations in BoTorch, which are available at https://github.com/pytorch/botorch) under the MIT license.</p>
<p>For the ABR problem, we use the Park simulator, which is available in open-source at https: //github.com/park-project/park under the MIT license.</p>
<h2>G. 2 Algorithm Details</h2>
<p>All methods are initialized with $2(d+1)$ points from a scrambled Sobol sequence. All MC acquisition functions uses $N=128$ quasi-MC samples [2]. All parallel algorithms using sequential greedy optimization for selecting a batch of candidates points and the base samples are redrawn when selecting candidate $\boldsymbol{x}_{i}, i=1, \ldots, q$.
For EHVI-based methods, we leverage the two-step trick proposed by [59] to perform efficient box decompositions; (i) we find the set of local lower bounds for the maximization problem using Algorithm 5 from Klamroth et al. [31] ${ }^{9}$, and then (ii) using the local lower bounds as a Pareto frontier for the artificial minimization problem, we compute a box decomposition of the dominated space using Algorithm 1 from Lacour et al. [34].
$q$ EHVI uses the IEP for computing joint EHVI over a set of candidates and computes EHVI with respect to the observed Pareto frontier. $q$ EHVI-PM-CBD uses the Pareto frontier over the posterior means at the previously evaluated points, providing some amount of regularization with respect to the observed values. In addition, $q$ EHVI-PM-CBD uses CBD rather than the IEP, which enables scaling to large batch sizes. $q$ NEHVI-1 uses 500 fourier basis functions.
For PFES and MESMO, we use 10 sampled (approximate) functions using RFFs (with 500 basis functions) and optimize each function using 5000 iterations of NSGA-II [12] with a population size of 50. For PFES, we partition the dominated space under each sampled Pareto frontier using the algorithm proposed Lacour et al. [34], which is more efficient and yields fewer hyperrectangles than the Quick Hypervolume algorithm used by the PFES authors [51]. For $q$ NParEGO, we use a similar pruning strategy to that in $q$ NEHVI to only integrate over the function values of in-sample points that have positive probability of being best with respect to the sampled scalarization. We use the off-the-shelf implementation of $q$ NParEGO in BoTorch [2], which does not use low-rank Cholesky updates; however, we do note that $q$ NPAREGO would likely achieve lower wall times using more efficient linear algebra tricks.
For DGEMO, TSEMO, and MOEA/D-EGO, we use the default settings provided in https:// github.com/yunshengtian/DGEMO/tree/master.</p>
<h2>G. 3 Problem Details</h2>
<p>All benchmark problems are treated as maximization problems; the objectives for minimization problems are multiplied by -1 to obtain an equivalent maximization problem.</p>
<p><sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{9}$ More efficient methods for this step exist (e.g. Dächert et al. [15]), but Klamroth et al. [31] can easily leverage vectorized operations and we find it to be efficient in our experiments.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>