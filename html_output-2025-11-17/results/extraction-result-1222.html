<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1222 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1222</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1222</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-232404596</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2103.15551v7.pdf" target="_blank">Toward Building Science Discovery Machines</a></p>
                <p><strong>Paper Abstract:</strong> The dream of building machines that can do science has inspired scientists for decades. Remarkable advances have been made recently; however, we are still far from achieving this goal. In this paper, we focus on the scientific discovery process where a high level of reasoning and remarkable problem-solving ability are required. We review different machine learning techniques used in scientific discovery with their limitations. We survey and discuss the main principles driving the scientific discovery process. These principles are used in different fields and by different scientists to solve problems and discover new knowledge. We provide many examples of the use of these principles in different fields such as physics, mathematics, and biology. We also review AI systems that attempt to implement some of these principles. We argue that building science discovery machines should be guided by these principles as an alternative to the dominant approach of current AI systems that focuses on narrow objectives. Building machines that fully incorporate these principles in an automated way might open the doors for many advancements.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1222.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1222.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Feynman: a Physics-Inspired Method for Symbolic Regression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic-regression system that combines neural-network fitting with physics-inspired techniques to recover closed-form equations from data; evaluated on benchmark sets of physics equations with large improvements over prior methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AI Feynman: a Physics-Inspired Method for Symbolic Regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines neural network fitting with a set of physics-inspired techniques to perform symbolic regression and recover analytic equations from observed data; designed to exploit separability, dimensional analysis, and other structure to reduce search complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / Mathematics (symbolic regression, equation discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automatically discovers closed-form physical equations from numerical data. In the paper this system is reported to have been applied to benchmark problems drawn from the Feynman Lectures on Physics and other test sets, recovering underlying analytic expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper does not explicitly characterize AI Feynman's discoveries using labels such as 'incremental' or 'transformational'; it reports empirical improvements in recovery success rates which imply an incremental methodological advance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarks of equation-recovery from synthetic/physics-derived datasets (e.g., 100 equations from the Feynman lectures). Performance measured as exact recovery success rate (percentage of target equations exactly recovered) and comparison against prior state-of-the-art symbolic-regression algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison to known ground-truth equations in benchmark datasets (i.e., checking whether the algorithm returns the exact analytic form). The paper cites numerical success rates on those benchmark sets as validation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by the ability to recover analytic forms that prior state-of-the-art methods could not; e.g., achieving full recovery on a 100-equation Feynman set where the prior state-of-the-art recovered 71/100, and large improvements on harder test sets.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Success/recovery rates on benchmark equation sets (e.g., improvement from 71/100 to 100/100 on the Feynman set; improvement from 15% to 90% on a more difficult test set as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper reports comparisons to prior algorithmic state-of-the-art (numeric success rates) but does not explicitly compare AI Feynman's outputs to original human historical discoveries in terms of novelty or scientific impact.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Reported examples: recovered 100/100 equations from a Feynman set (state-of-the-art previously 71/100); on a more difficult test set improved state-of-the-art success from 15% to 90% (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes limitations on interpretability of learned representations for other deep-learning based discovery approaches; for symbolic regression specifically, success hinges on the suitability of assumptions (e.g., separability, chosen grammars) and benchmark formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1222.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Feynman 2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension/advance in the AI Feynman family that uses graph modularity and Pareto optimization to further improve symbolic-regression performance and scalability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Feynman 2.0</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Builds on the AI Feynman approach by exploiting graph modularity and Pareto-optimal search to discover symbolic expressions more efficiently and scalably.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / Mathematics (symbolic regression)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Improves on prior symbolic-regression results by recovering underlying mathematical relationships from data using modularity-aware search and multi-objective (Pareto) criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper references this as an advance in symbolic-regression technique but does not label the nature of discoveries (incremental vs transformational).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed in this review beyond referencing the work; original work evaluates via symbolic-regression benchmarks and Pareto-optimality of discovered formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in this review; original authors validate by checking recovered expressions against ground-truth benchmark equations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Cited as methodological improvement (graph modularity and Pareto optimization) enhancing recovery capabilities compared to previous symbolic-regression techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not specified in this review (original paper reports benchmark performance metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not specified in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>This review notes general limitations of deep-learning based discovery (e.g., interpretability) which may also apply; no system-specific limitations are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1222.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa / Distilling laws</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distilling free-form natural laws from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic-regression approach (Eureqa / related methods) that searches for human-readable mathematical expressions describing experimental data and has been applied to discover physical laws from measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distilling free-form natural laws from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eureqa / Distilling free-form natural laws</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Symbolic-regression frameworks that search over mathematical expression spaces to find concise formulas fitting experimental data, designed to recover interpretable physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / General scientific domains (mathematization of data)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Used to extract closed-form natural laws directly from experimental datasets by optimizing fit and formula simplicity; referenced as an influential example of automated equation discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper mentions these systems as examples of progress but does not categorize their discoveries as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarking on experimental and synthetic datasets; evaluation by fit quality and simplicity/interpretability of the recovered equations (as implied by the title and context).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison to known physical laws and ground-truth expressions in benchmark scenarios; validation is by checking recovered equations against expected analytic forms.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty judged by the ability to recover human-interpretable laws from raw data where previous methods failed or required more constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not enumerated in this review text; original work reports recovered-case counts and qualitative examples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review places these systems as automated analogues of human mathematization but does not provide direct human-vs-machine comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>General limits include dependence on data quality, choice of search grammars, and potential difficulty scaling to very complex systems; the review emphasizes interpretability challenges in other deep approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1222.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The Ramanujan Machine: automatically generated conjectures on fundamental constants</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated system that generates conjectures about fundamental mathematical constants by searching for closed-form continued fractions and series that match numeric constants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The ramanujan machine: automatically generated conjectures on fundamental constants</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An automated conjecture-generation engine that searches for analytic expressions (e.g., continued fractions) approximating mathematical constants and outputs conjectures for further scrutiny.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (number theory, constants)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Generates conjectured closed-form relationships involving fundamental constants by automated search; produces conjectures for human mathematicians to evaluate and attempt to prove.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper references the Ramanujan Machine as an example of automated conjecture generation but does not classify its outputs as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in the review; the referenced work's evaluation centers on generating plausible conjectures (numeric agreement) and presenting them as candidate identities for verification.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not detailed in this paper; typical validation would be mathematical proof or peer scrutiny, but the review simply cites the system as an automated conjecture generator.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty lies in automated production of nontrivial conjectures about constants; the review notes it as an example of automation in mathematical discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not given in this review (original work lists produced conjectures and whether subsequent proofs were found or not).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>No explicit human-machine comparison is given in this review for the Ramanujan Machine.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review does not detail limitations, though implicit limits include that conjectures still require human/mathematical validation and may be numerically plausible but unproven.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1222.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Towards Robot Scientists for autonomous scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early class of laboratory automation systems that design, execute, and interpret experiments autonomously to generate and test hypotheses in biology/chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards Robot Scientists for autonomous scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrated automated lab systems that combine hypothesis generation, experimental design, robotic execution, data collection, and analysis to perform cycles of autonomous discovery (noted in the review as exemplars of automated scientific discovery).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Biology / Chemistry / Laboratory sciences</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Systems that autonomously propose hypotheses and run experiments in wet labs to test them, thereby producing new experimental findings or refuting hypotheses without continuous human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review treats Robot Scientists as examples of automation but does not label their discoveries with incremental/transformational terminology.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in detail in the review; typical evaluation involves whether the system produces correct experimental conclusions, novel findings, or successfully automates hypothesis-experiment cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Implied validation by experimental execution and comparison of experimental outcomes to expected controls; the review does not detail specific validation protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty described qualitatively as autonomous experimental discovery capability; the review highlights the approach rather than quantitative novelty metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review references Robot Scientists as an example of automation in discovery but does not compare their output directly to human discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Automation in wet lab environments faces challenges in scaling, robustness to noisy experiments, and the complexity of designing appropriate experimental protocols autonomously.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1222.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lenat AM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AM: An artificial intelligence approach to discovery in mathematics as heuristic search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classic AI system (AM) that performs heuristic search to discover mathematical concepts and conjectures; historically seminal in computational discovery research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AM: An artificial intelligence approach to discovery in mathematics as heuristic search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AM</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Heuristic-search based system designed to generate mathematical concepts and proofs by exploring concept spaces guided by heuristics; an early computational-discovery exemplar.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (concept and theorem discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automatically searches for and proposes new mathematical concepts and conjectures via heuristic-driven exploration of the mathematical search space.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review cites AM historically but does not categorize its discoveries as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed in the review; historically evaluated by whether generated concepts were novel and useful to mathematicians.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>In original work, validation involved inspection by human experts and subsequent formalization/proof where possible; the review simply cites the system.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Historical novelty is implicit as early mechanized mathematical discovery; the review does not provide metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>No explicit comparison in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Early systems relied heavily on hand-crafted heuristics and domain knowledge; limited in creativity and handling noise compared to later approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1222.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EURISKO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EURISKO: a program that learns new heuristics and domain concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A program that learns and evolves heuristics and domain concepts to improve its problem-solving across domains; historically significant for automated heuristic learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EURISKO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Meta-learning system that adapts and invents heuristics and domain concepts to tackle diverse problems; demonstrated learning new problem-solving strategies automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>General heuristic discovery and concept invention (applied historically to multiple domains)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automatically learns and proposes new heuristics and representations that can be used to solve problems or generate novel concepts; cited as an early success in heuristic learning.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review references EURISKO's heuristic-learning capability but does not explicitly classify the nature of its discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in the review; historically evaluated by task performance improvements and the novelty/usefulness of invented heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Historically via observed improved problem-solving and human inspection of generated heuristics; not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty was judged by the ability to invent heuristics not present in initial knowledge, but the review does not quantify this.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Early heuristic-learning systems suffered from brittleness, dependence on initial encodings, and limited handling of noisy/real-world data.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1222.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zenil et al. causal deconvolution</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal deconvolution by algorithmic generative models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised, model-oriented approach using algorithmic probability, perturbation-based causal calculus and algorithmic complexity to infer algorithmic generative models that explain observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal deconvolution by algorithmic generative models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Algorithmic generative models (Zenil et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Unsupervised, parameter-free framework based on algorithmic probability and perturbation-based causal calculus to decompose observations into likely algorithmic generative mechanisms (works on bit strings, images, networks).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>General (systems analysis, causal inference across data types including images and networks)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Infers likely algorithmic generative models and attempts to deconvolve interacting mechanisms underlying observed data; presented as a tool for discovering mechanistic explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review presents this approach as a methodological contribution; it does not label its discoveries as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed in this review excerpt; original work demonstrates ability to deconvolve mechanisms across data types and likely evaluates via case studies.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in the review; original validation used demonstrations on synthetic and empirical datasets to show deconvolution ability.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty lies in using algorithmic probability and perturbation-based calculus for model inference across diverse data modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not listed in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>No direct comparisons provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes general obstacles in building representations and models of the world; specific limitations for algorithmic generative methods are not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1222.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Physicist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Toward an AI physicist for unsupervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed system aiming to discover physical laws in an unsupervised way, referenced as part of recent work applying machine learning to automatic discovery in physics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward an AI physicist for unsupervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Physicist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An unsupervised learning system designed to partition data into regimes and infer simple physical laws describing each regime, aiming to mimic aspects of physicists' discovery workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics (unsupervised discovery of governing equations)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Aims to discover interpretable physical laws and piecewise descriptions from raw data without supervision, as an example of applying ML to mathematization and law-finding.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review cites this as progress toward automated physics discovery but does not classify specific discoveries as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified here beyond being cited as relevant work; the original work evaluates via recovery of governing equations and interpretability on synthetic physics tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not detailed in the review; original validations compare recovered laws to known ground-truth physical equations in synthetic benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty described qualitatively as progressing unsupervised law-discovery; the review highlights it among recent promising directions.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in this review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Not provided in this review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review stresses broader challenges: building world models and interpretability; specific AI Physicist limitations are not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1222.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e1222.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous discovery (chemistry)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous discovery in the chemical sciences part I: Progress</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent survey and report on autonomous systems in chemical sciences that design, run, and analyze experiments to accelerate materials and molecule discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous discovery in the chemical sciences part I: Progress</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autonomous discovery systems (chemical sciences)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrated automated experimentation platforms combining robotics, ML-driven experimental planning, and analytics to autonomously explore chemical and materials spaces and discover new molecules/materials.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry / Materials science</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automated pipelines that perform cycles of experiment planning, robotic execution, and analysis to discover new molecules or materials; cited as an active, maturing domain of automation-enabled discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review notes progress but does not label the discoveries as incremental versus transformational within this text.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in this review excerpt; original literature evaluates via rate of discovery, throughput, novelty of synthesized compounds, and validation of predicted properties.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Typically experimental validation (synthesis and measurement), comparison to predicted properties, and benchmarking against human-designed experiments; not detailed in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty often assessed by whether new, previously-unknown compounds/materials with desired properties were found; the review references this field without giving concrete metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in this review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review cites the domain as complementing human scientists but does not give specific comparative statistics here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include experimental noise, transferring predictions to real-world synthesis, and integration of domain knowledge; the review highlights evaluation and validation challenges for automated discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward Building Science Discovery Machines', 'publication_date_yy_mm': '2021-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AI Feynman: a Physics-Inspired Method for Symbolic Regression <em>(Rating: 2)</em></li>
                <li>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity <em>(Rating: 2)</em></li>
                <li>Distilling free-form natural laws from experimental data <em>(Rating: 2)</em></li>
                <li>The ramanujan machine: automatically generated conjectures on fundamental constants <em>(Rating: 2)</em></li>
                <li>Towards Robot Scientists for autonomous scientific discovery <em>(Rating: 2)</em></li>
                <li>Autonomous discovery in the chemical sciences part I: Progress <em>(Rating: 2)</em></li>
                <li>Causal deconvolution by algorithmic generative models <em>(Rating: 2)</em></li>
                <li>Toward an AI physicist for unsupervised learning <em>(Rating: 2)</em></li>
                <li>AM: An artificial intelligence approach to discovery in mathematics as heuristic search <em>(Rating: 1)</em></li>
                <li>EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1222",
    "paper_id": "paper-232404596",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "AI Feynman",
            "name_full": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "brief_description": "A symbolic-regression system that combines neural-network fitting with physics-inspired techniques to recover closed-form equations from data; evaluated on benchmark sets of physics equations with large improvements over prior methods.",
            "citation_title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "mention_or_use": "mention",
            "system_name": "AI Feynman",
            "system_description": "Combines neural network fitting with a set of physics-inspired techniques to perform symbolic regression and recover analytic equations from observed data; designed to exploit separability, dimensional analysis, and other structure to reduce search complexity.",
            "discovery_domain": "Physics / Mathematics (symbolic regression, equation discovery)",
            "discovery_description": "Automatically discovers closed-form physical equations from numerical data. In the paper this system is reported to have been applied to benchmark problems drawn from the Feynman Lectures on Physics and other test sets, recovering underlying analytic expressions.",
            "discovery_type": null,
            "discovery_type_justification": "The paper does not explicitly characterize AI Feynman's discoveries using labels such as 'incremental' or 'transformational'; it reports empirical improvements in recovery success rates which imply an incremental methodological advance.",
            "evaluation_methods": "Benchmarks of equation-recovery from synthetic/physics-derived datasets (e.g., 100 equations from the Feynman lectures). Performance measured as exact recovery success rate (percentage of target equations exactly recovered) and comparison against prior state-of-the-art symbolic-regression algorithms.",
            "validation_approaches": "Comparison to known ground-truth equations in benchmark datasets (i.e., checking whether the algorithm returns the exact analytic form). The paper cites numerical success rates on those benchmark sets as validation.",
            "novelty_assessment": "Novelty is assessed by the ability to recover analytic forms that prior state-of-the-art methods could not; e.g., achieving full recovery on a 100-equation Feynman set where the prior state-of-the-art recovered 71/100, and large improvements on harder test sets.",
            "impact_metrics": "Success/recovery rates on benchmark equation sets (e.g., improvement from 71/100 to 100/100 on the Feynman set; improvement from 15% to 90% on a more difficult test set as reported).",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The paper reports comparisons to prior algorithmic state-of-the-art (numeric success rates) but does not explicitly compare AI Feynman's outputs to original human historical discoveries in terms of novelty or scientific impact.",
            "success_rate": "Reported examples: recovered 100/100 equations from a Feynman set (state-of-the-art previously 71/100); on a more difficult test set improved state-of-the-art success from 15% to 90% (as cited).",
            "challenges_limitations": "Paper notes limitations on interpretability of learned representations for other deep-learning based discovery approaches; for symbolic regression specifically, success hinges on the suitability of assumptions (e.g., separability, chosen grammars) and benchmark formulation.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.0",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "AI Feynman 2.0",
            "name_full": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",
            "brief_description": "An extension/advance in the AI Feynman family that uses graph modularity and Pareto optimization to further improve symbolic-regression performance and scalability.",
            "citation_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",
            "mention_or_use": "mention",
            "system_name": "AI Feynman 2.0",
            "system_description": "Builds on the AI Feynman approach by exploiting graph modularity and Pareto-optimal search to discover symbolic expressions more efficiently and scalably.",
            "discovery_domain": "Physics / Mathematics (symbolic regression)",
            "discovery_description": "Improves on prior symbolic-regression results by recovering underlying mathematical relationships from data using modularity-aware search and multi-objective (Pareto) criteria.",
            "discovery_type": null,
            "discovery_type_justification": "The paper references this as an advance in symbolic-regression technique but does not label the nature of discoveries (incremental vs transformational).",
            "evaluation_methods": "Not detailed in this review beyond referencing the work; original work evaluates via symbolic-regression benchmarks and Pareto-optimality of discovered formulas.",
            "validation_approaches": "Not specified in this review; original authors validate by checking recovered expressions against ground-truth benchmark equations.",
            "novelty_assessment": "Cited as methodological improvement (graph modularity and Pareto optimization) enhancing recovery capabilities compared to previous symbolic-regression techniques.",
            "impact_metrics": "Not specified in this review (original paper reports benchmark performance metrics).",
            "comparison_to_human_discoveries": null,
            "comparison_details": "Not provided in this review.",
            "success_rate": "Not specified in this review.",
            "challenges_limitations": "This review notes general limitations of deep-learning based discovery (e.g., interpretability) which may also apply; no system-specific limitations are provided here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.1",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Eureqa / Distilling laws",
            "name_full": "Distilling free-form natural laws from experimental data",
            "brief_description": "A symbolic-regression approach (Eureqa / related methods) that searches for human-readable mathematical expressions describing experimental data and has been applied to discover physical laws from measurements.",
            "citation_title": "Distilling free-form natural laws from experimental data",
            "mention_or_use": "mention",
            "system_name": "Eureqa / Distilling free-form natural laws",
            "system_description": "Symbolic-regression frameworks that search over mathematical expression spaces to find concise formulas fitting experimental data, designed to recover interpretable physical laws.",
            "discovery_domain": "Physics / General scientific domains (mathematization of data)",
            "discovery_description": "Used to extract closed-form natural laws directly from experimental datasets by optimizing fit and formula simplicity; referenced as an influential example of automated equation discovery.",
            "discovery_type": null,
            "discovery_type_justification": "The paper mentions these systems as examples of progress but does not categorize their discoveries as incremental or transformational.",
            "evaluation_methods": "Benchmarking on experimental and synthetic datasets; evaluation by fit quality and simplicity/interpretability of the recovered equations (as implied by the title and context).",
            "validation_approaches": "Comparison to known physical laws and ground-truth expressions in benchmark scenarios; validation is by checking recovered equations against expected analytic forms.",
            "novelty_assessment": "Novelty judged by the ability to recover human-interpretable laws from raw data where previous methods failed or required more constraints.",
            "impact_metrics": "Not enumerated in this review text; original work reports recovered-case counts and qualitative examples.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "The review places these systems as automated analogues of human mathematization but does not provide direct human-vs-machine comparisons.",
            "success_rate": null,
            "challenges_limitations": "General limits include dependence on data quality, choice of search grammars, and potential difficulty scaling to very complex systems; the review emphasizes interpretability challenges in other deep approaches.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.2",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Ramanujan Machine",
            "name_full": "The Ramanujan Machine: automatically generated conjectures on fundamental constants",
            "brief_description": "An automated system that generates conjectures about fundamental mathematical constants by searching for closed-form continued fractions and series that match numeric constants.",
            "citation_title": "The ramanujan machine: automatically generated conjectures on fundamental constants",
            "mention_or_use": "mention",
            "system_name": "Ramanujan Machine",
            "system_description": "An automated conjecture-generation engine that searches for analytic expressions (e.g., continued fractions) approximating mathematical constants and outputs conjectures for further scrutiny.",
            "discovery_domain": "Mathematics (number theory, constants)",
            "discovery_description": "Generates conjectured closed-form relationships involving fundamental constants by automated search; produces conjectures for human mathematicians to evaluate and attempt to prove.",
            "discovery_type": null,
            "discovery_type_justification": "The paper references the Ramanujan Machine as an example of automated conjecture generation but does not classify its outputs as incremental or transformational.",
            "evaluation_methods": "Not specified in the review; the referenced work's evaluation centers on generating plausible conjectures (numeric agreement) and presenting them as candidate identities for verification.",
            "validation_approaches": "Not detailed in this paper; typical validation would be mathematical proof or peer scrutiny, but the review simply cites the system as an automated conjecture generator.",
            "novelty_assessment": "Novelty lies in automated production of nontrivial conjectures about constants; the review notes it as an example of automation in mathematical discovery.",
            "impact_metrics": "Not given in this review (original work lists produced conjectures and whether subsequent proofs were found or not).",
            "comparison_to_human_discoveries": null,
            "comparison_details": "No explicit human-machine comparison is given in this review for the Ramanujan Machine.",
            "success_rate": null,
            "challenges_limitations": "The review does not detail limitations, though implicit limits include that conjectures still require human/mathematical validation and may be numerically plausible but unproven.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.3",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Robot Scientist",
            "name_full": "Towards Robot Scientists for autonomous scientific discovery",
            "brief_description": "An early class of laboratory automation systems that design, execute, and interpret experiments autonomously to generate and test hypotheses in biology/chemistry.",
            "citation_title": "Towards Robot Scientists for autonomous scientific discovery",
            "mention_or_use": "mention",
            "system_name": "Robot Scientist",
            "system_description": "Integrated automated lab systems that combine hypothesis generation, experimental design, robotic execution, data collection, and analysis to perform cycles of autonomous discovery (noted in the review as exemplars of automated scientific discovery).",
            "discovery_domain": "Biology / Chemistry / Laboratory sciences",
            "discovery_description": "Systems that autonomously propose hypotheses and run experiments in wet labs to test them, thereby producing new experimental findings or refuting hypotheses without continuous human intervention.",
            "discovery_type": null,
            "discovery_type_justification": "The review treats Robot Scientists as examples of automation but does not label their discoveries with incremental/transformational terminology.",
            "evaluation_methods": "Not specified in detail in the review; typical evaluation involves whether the system produces correct experimental conclusions, novel findings, or successfully automates hypothesis-experiment cycles.",
            "validation_approaches": "Implied validation by experimental execution and comparison of experimental outcomes to expected controls; the review does not detail specific validation protocols.",
            "novelty_assessment": "Novelty described qualitatively as autonomous experimental discovery capability; the review highlights the approach rather than quantitative novelty metrics.",
            "impact_metrics": "Not provided in the review.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The review references Robot Scientists as an example of automation in discovery but does not compare their output directly to human discoveries.",
            "success_rate": null,
            "challenges_limitations": "Automation in wet lab environments faces challenges in scaling, robustness to noisy experiments, and the complexity of designing appropriate experimental protocols autonomously.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.4",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Lenat AM",
            "name_full": "AM: An artificial intelligence approach to discovery in mathematics as heuristic search",
            "brief_description": "A classic AI system (AM) that performs heuristic search to discover mathematical concepts and conjectures; historically seminal in computational discovery research.",
            "citation_title": "AM: An artificial intelligence approach to discovery in mathematics as heuristic search",
            "mention_or_use": "mention",
            "system_name": "AM",
            "system_description": "Heuristic-search based system designed to generate mathematical concepts and proofs by exploring concept spaces guided by heuristics; an early computational-discovery exemplar.",
            "discovery_domain": "Mathematics (concept and theorem discovery)",
            "discovery_description": "Automatically searches for and proposes new mathematical concepts and conjectures via heuristic-driven exploration of the mathematical search space.",
            "discovery_type": null,
            "discovery_type_justification": "The review cites AM historically but does not categorize its discoveries as incremental or transformational.",
            "evaluation_methods": "Not detailed in the review; historically evaluated by whether generated concepts were novel and useful to mathematicians.",
            "validation_approaches": "In original work, validation involved inspection by human experts and subsequent formalization/proof where possible; the review simply cites the system.",
            "novelty_assessment": "Historical novelty is implicit as early mechanized mathematical discovery; the review does not provide metrics.",
            "impact_metrics": "Not provided in this review.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "No explicit comparison in this review.",
            "success_rate": null,
            "challenges_limitations": "Early systems relied heavily on hand-crafted heuristics and domain knowledge; limited in creativity and handling noise compared to later approaches.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.5",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "EURISKO",
            "name_full": "EURISKO: a program that learns new heuristics and domain concepts",
            "brief_description": "A program that learns and evolves heuristics and domain concepts to improve its problem-solving across domains; historically significant for automated heuristic learning.",
            "citation_title": "EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results",
            "mention_or_use": "mention",
            "system_name": "EURISKO",
            "system_description": "Meta-learning system that adapts and invents heuristics and domain concepts to tackle diverse problems; demonstrated learning new problem-solving strategies automatically.",
            "discovery_domain": "General heuristic discovery and concept invention (applied historically to multiple domains)",
            "discovery_description": "Automatically learns and proposes new heuristics and representations that can be used to solve problems or generate novel concepts; cited as an early success in heuristic learning.",
            "discovery_type": null,
            "discovery_type_justification": "The review references EURISKO's heuristic-learning capability but does not explicitly classify the nature of its discoveries.",
            "evaluation_methods": "Not specified in the review; historically evaluated by task performance improvements and the novelty/usefulness of invented heuristics.",
            "validation_approaches": "Historically via observed improved problem-solving and human inspection of generated heuristics; not detailed here.",
            "novelty_assessment": "Novelty was judged by the ability to invent heuristics not present in initial knowledge, but the review does not quantify this.",
            "impact_metrics": "Not provided in this review.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "Not provided in this review.",
            "success_rate": null,
            "challenges_limitations": "Early heuristic-learning systems suffered from brittleness, dependence on initial encodings, and limited handling of noisy/real-world data.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.6",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Zenil et al. causal deconvolution",
            "name_full": "Causal deconvolution by algorithmic generative models",
            "brief_description": "An unsupervised, model-oriented approach using algorithmic probability, perturbation-based causal calculus and algorithmic complexity to infer algorithmic generative models that explain observations.",
            "citation_title": "Causal deconvolution by algorithmic generative models",
            "mention_or_use": "mention",
            "system_name": "Algorithmic generative models (Zenil et al.)",
            "system_description": "Unsupervised, parameter-free framework based on algorithmic probability and perturbation-based causal calculus to decompose observations into likely algorithmic generative mechanisms (works on bit strings, images, networks).",
            "discovery_domain": "General (systems analysis, causal inference across data types including images and networks)",
            "discovery_description": "Infers likely algorithmic generative models and attempts to deconvolve interacting mechanisms underlying observed data; presented as a tool for discovering mechanistic explanations.",
            "discovery_type": null,
            "discovery_type_justification": "The review presents this approach as a methodological contribution; it does not label its discoveries as incremental or transformational.",
            "evaluation_methods": "Not detailed in this review excerpt; original work demonstrates ability to deconvolve mechanisms across data types and likely evaluates via case studies.",
            "validation_approaches": "Not specified in the review; original validation used demonstrations on synthetic and empirical datasets to show deconvolution ability.",
            "novelty_assessment": "Novelty lies in using algorithmic probability and perturbation-based calculus for model inference across diverse data modalities.",
            "impact_metrics": "Not listed in this review.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "No direct comparisons provided in the review.",
            "success_rate": null,
            "challenges_limitations": "Paper notes general obstacles in building representations and models of the world; specific limitations for algorithmic generative methods are not detailed here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.7",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "AI Physicist",
            "name_full": "Toward an AI physicist for unsupervised learning",
            "brief_description": "A proposed system aiming to discover physical laws in an unsupervised way, referenced as part of recent work applying machine learning to automatic discovery in physics.",
            "citation_title": "Toward an AI physicist for unsupervised learning",
            "mention_or_use": "mention",
            "system_name": "AI Physicist",
            "system_description": "An unsupervised learning system designed to partition data into regimes and infer simple physical laws describing each regime, aiming to mimic aspects of physicists' discovery workflows.",
            "discovery_domain": "Physics (unsupervised discovery of governing equations)",
            "discovery_description": "Aims to discover interpretable physical laws and piecewise descriptions from raw data without supervision, as an example of applying ML to mathematization and law-finding.",
            "discovery_type": null,
            "discovery_type_justification": "The review cites this as progress toward automated physics discovery but does not classify specific discoveries as incremental or transformational.",
            "evaluation_methods": "Not specified here beyond being cited as relevant work; the original work evaluates via recovery of governing equations and interpretability on synthetic physics tasks.",
            "validation_approaches": "Not detailed in the review; original validations compare recovered laws to known ground-truth physical equations in synthetic benchmarks.",
            "novelty_assessment": "Novelty described qualitatively as progressing unsupervised law-discovery; the review highlights it among recent promising directions.",
            "impact_metrics": "Not provided in this review excerpt.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "Not provided in this review excerpt.",
            "success_rate": null,
            "challenges_limitations": "The review stresses broader challenges: building world models and interpretability; specific AI Physicist limitations are not detailed here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.8",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        },
        {
            "name_short": "Autonomous discovery (chemistry)",
            "name_full": "Autonomous discovery in the chemical sciences part I: Progress",
            "brief_description": "A recent survey and report on autonomous systems in chemical sciences that design, run, and analyze experiments to accelerate materials and molecule discovery.",
            "citation_title": "Autonomous discovery in the chemical sciences part I: Progress",
            "mention_or_use": "mention",
            "system_name": "Autonomous discovery systems (chemical sciences)",
            "system_description": "Integrated automated experimentation platforms combining robotics, ML-driven experimental planning, and analytics to autonomously explore chemical and materials spaces and discover new molecules/materials.",
            "discovery_domain": "Chemistry / Materials science",
            "discovery_description": "Automated pipelines that perform cycles of experiment planning, robotic execution, and analysis to discover new molecules or materials; cited as an active, maturing domain of automation-enabled discovery.",
            "discovery_type": null,
            "discovery_type_justification": "The review notes progress but does not label the discoveries as incremental versus transformational within this text.",
            "evaluation_methods": "Not specified in this review excerpt; original literature evaluates via rate of discovery, throughput, novelty of synthesized compounds, and validation of predicted properties.",
            "validation_approaches": "Typically experimental validation (synthesis and measurement), comparison to predicted properties, and benchmarking against human-designed experiments; not detailed in the review text.",
            "novelty_assessment": "Novelty often assessed by whether new, previously-unknown compounds/materials with desired properties were found; the review references this field without giving concrete metrics.",
            "impact_metrics": "Not provided in this review excerpt.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The review cites the domain as complementing human scientists but does not give specific comparative statistics here.",
            "success_rate": null,
            "challenges_limitations": "Challenges include experimental noise, transferring predictions to real-world synthesis, and integration of domain knowledge; the review highlights evaluation and validation challenges for automated discovery.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1222.9",
            "source_info": {
                "paper_title": "Toward Building Science Discovery Machines",
                "publication_date_yy_mm": "2021-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "rating": 2,
            "sanitized_title": "ai_feynman_a_physicsinspired_method_for_symbolic_regression"
        },
        {
            "paper_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",
            "rating": 2,
            "sanitized_title": "ai_feynman_20_paretooptimal_symbolic_regression_exploiting_graph_modularity"
        },
        {
            "paper_title": "Distilling free-form natural laws from experimental data",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "The ramanujan machine: automatically generated conjectures on fundamental constants",
            "rating": 2,
            "sanitized_title": "the_ramanujan_machine_automatically_generated_conjectures_on_fundamental_constants"
        },
        {
            "paper_title": "Towards Robot Scientists for autonomous scientific discovery",
            "rating": 2,
            "sanitized_title": "towards_robot_scientists_for_autonomous_scientific_discovery"
        },
        {
            "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
            "rating": 2,
            "sanitized_title": "autonomous_discovery_in_the_chemical_sciences_part_i_progress"
        },
        {
            "paper_title": "Causal deconvolution by algorithmic generative models",
            "rating": 2,
            "sanitized_title": "causal_deconvolution_by_algorithmic_generative_models"
        },
        {
            "paper_title": "Toward an AI physicist for unsupervised learning",
            "rating": 2,
            "sanitized_title": "toward_an_ai_physicist_for_unsupervised_learning"
        },
        {
            "paper_title": "AM: An artificial intelligence approach to discovery in mathematics as heuristic search",
            "rating": 1,
            "sanitized_title": "am_an_artificial_intelligence_approach_to_discovery_in_mathematics_as_heuristic_search"
        },
        {
            "paper_title": "EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results",
            "rating": 1,
            "sanitized_title": "eurisko_a_program_that_learns_new_heuristics_and_domain_concepts_the_nature_of_heuristics_iii_program_design_and_results"
        }
    ],
    "cost": 0.01751475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Toward Building Science Discovery Machines</p>
<p>Abdullah Khalili a.m.khalili@outlook.com 
Department of Computing and Informatics
Bournemouth University
United Kingdom</p>
<p>Abdelhamid Bouchachia 
Department of Computing and Informatics
Bournemouth University
United Kingdom</p>
<p>Toward Building Science Discovery Machines
24833F0F9A27BC6897842EFF8E7911A0AIArtificial IntelligenceMachine LearningScience AutomationScientific Discovery
The dream of building machines that can do science has inspired scientists for decades.Remarkable advances have been made recently; however, we are still far from achieving this goal.In this paper, we focus on the scientific discovery process where a high level of reasoning and remarkable problem-solving ability are required.We review machine learning techniques used in scientific discovery with their limitations.We survey and discuss the main principles driving the scientific discovery process.These principles are used in different fields and by different scientists to solve problems and discover new knowledge.We provide many examples of the use of these principles in different fields such as physics, mathematics, and biology.We also review AI systems that attempt to implement some of these principles.We argue that building science discovery machines should be guided by these principles as an alternative to the dominant approach of current AI systems that focuses on narrow objectives.Building machines that fully incorporate these principles in an automated way might open the doors for many advancements.</p>
<p>Introduction</p>
<p>In [1][2] Penrose talked about the existence of three different worlds: the mental world, the physical world, and the mathematical world.The physical world is governed by laws that reside in the world of mathematics, our minds emerge from the physical world, and those minds are able to access the mathematical world by discovering mathematics, which is within the scope of reason.</p>
<p>In the mathematical world, Bourbaki [5] likened mathematics to a city, where the outlying districts and suburbs expand on the surrounding country.Plato believed that ideas or forms exist in some ideal world outside the physical world, which became later known as the 'Platonic world of forms' [3].If Plato's realm exists, it is very unlikely that different parts of such realm are disconnected and do not have links with each other, they would be beautifully connected and one can navigate between different parts of that realm, and discover new hidden structures.</p>
<p>Although on rare occasions, the intellect might break through into those worlds and get a limited glimpse of those realms as described by Penrose [1], and illustrated through many examples by Hadamard [6], still in most times we follow certain procedures and principles to reconstruct those realms.Similar to the mathematical and physical worlds, a curtail aspect of the mental world and hence artificial intelligence is to build the maps that represent other realms by using a set of principles to reconstruct these original worlds and discover new knowledge.Today these principles represent the major driving force of the scientific discovery process.We argue that these principles should be used as guiding principles for building science discovery machines.The landscape of AI is extremely vast, in this paper we will focus on the scientific discovery process [6-8, 33-37, 41-42, 54-55, 77, 81, 85, 87-91, 116-123, 149-150].</p>
<p>The paper is organized as follows: Section 2 reviews machine learning techniques used Other machine learning approaches such as logic-based approaches have remarkable representational power, logic is also crucial to achieve high-level functions such as reasoning.However, these approaches tend to be limited in learning and creativity, they are also limited in handling noise and uncertainty present in many applications.See [15,92] for recent advances and different attempts to combine logical AI and neural networks.There is also a growing interest recently in studying artificial general intelligence [9, 10, 16-18, 85, 146-147].Other important aspects of the scientific discovery process include explainable artificial intelligence to provide explanations of the discovery [128][129], and causal modeling [124] which is a key building block in the scientific discovery process.</p>
<p>The main principles driving the scientific discovery process</p>
<p>The dominant approach of current AI systems focus on solving specific narrow problems, this approach has key limitations in its generalization ability as discussed in earlier sections.The evolution-inspired path [83,[126][127] could provide an alternative way to build more general AI systems.However, the extremely large search space and the existence of many complex interacting parts still represent a major obstacle.In this study, we argue that the building of these systems should be guided by a set of principles as an alternative of narrow objectives or open-ended evolution.The use of these principles is backed by many historical examples of how different scientists made their discovery.Most scientific discoveries could be understood as instances of the use of one or more of these principles.These principles are the main approach used by scientists to solve problems and discover new knowledge.The use of these principles provides a way for machine learning systems to improve their generalization ability and to cut down the large search space of hypotheses by approaching the given problem using these principles in template ways as an alternative of the expensive random search.</p>
<p>In addition to logic, which plays an important role in the scientific discovery process, in reality, logic alone is not enough, we usually use more sophisticated principles and structures.In the literature, there is a focus on two main principles, concepts combination and analogies.However, other principles should be taken into account to build a comprehensive framework.Different problems in science can be solved using one or more of these principles by using these principles in template ways.For instance, some problems require finding the equation that fits the experimental data, some problems require finding the optimization criteria that give rise to the observed phenomenon, other problems require finding the rules or the program that gives rise to the observed phenomenon, many problems require combining different ideas, unifying ideas or finding analogy with other ideas, and so on.Each scientific problem comes with an objective to meet, the problem could be approached by these principles to find which principle best satisfy the objective.Proposing theoretical and computational frameworks that encapsulate these principles is beyond the scope of this paper.These principles can be summarized as follow</p>
<p>Mathematization</p>
<p>Mathematic is a very powerful tool in describing the natural world [30][31][32].Mathematic today is very effective in studying fields as diverse as physics, computer science, finance, and biology.Mathematic is not only able to describe the natural world, but this description on many occasions led us to predict and discover new aspects of the studied phenomena.On many occasions, testing the mathematical description in new extreme conditions led to new insights and sometimes to new theories.In 1915 for instance, General Relativity (GR) was at the frontier of the map of physics, many physicists used the mathematization principle to derive new knowledge from the GR equation, they were able to predict gravitational waves, and black holes as solutions to the GR equation, both of these phenomena were confirmed experimentally in the few recent years.</p>
<p>In AI, there are many attempts to build symbolic regression algorithms, which are automated tools to find the mathematical equation that fits the experimental data [33].Udrescu and Tegmark [34,148] developed an algorithm that combines neural network fitting with a set of physics-inspired techniques.They applied it to 100 equations from the Feynman lectures on physics.It was able to discover all of them; the state of the art algorithm was only able to discover 71.For a more difficult test set, the state of the art success rate was improved from 15% to 90%.Many researchers recently [35][36][37] started to use recent advances in deep learning such as generative adversarial networks to discover physical concepts from experimental data without being provided with any additional prior knowledge and then use the discovered representation to answer questions about the physical system.The main limitation of these approaches is that it is difficult to transform the learned representations into interpretable properties unless prior knowledge is available.The main purpose of the algorithm that encapsulates the mathematization principle would be to find the equations that describe the experimental data.</p>
<p>Optimization</p>
<p>Optimization is one of the most powerful and most used principles from the least action principle in physics, survival of the fittest in biology, and utility maximization in economics, see [134][135] for a long list of examples from different disciplines.Optimization is one of the most used principles in everyday life, we constantly try to minimize energy, cost, distance, time, etc.Some other notable uses of this principle in science include minimizing the energy and time that are required to distribute fuels to the cells, gives rise to the circulatory system networks [27].Optimizing the balance between the input and output energy gives rise to bird migration patterns [28].Increasing entropy drives matter to acquire life-like physical properties [29].The main purpose of the algorithm that encapsulates the optimization principle would be to find the optimization criteria and constraints that describe the studied problem.</p>
<p>Analogies</p>
<p>Many cognitive scientists [38] consider analogy to be one of the main building blocks of human cognition.There are many examples where analogy has played a crucial role in scientific discovery.Polya [39] observed that analogy has played a role in most mathematical discoveries.He provided many historical examples where analogy played the main role.See [40] for a long list of the use of analogy in scientific discovery.Nersessian [41][42] also gave a list of examples such as Newton's analogy between projectiles and the moon which gave rise to universal gravitation, Darwin's analogy between selective breeding and reproduction in nature which gave rise to natural selection, and the Rutherford-Bohr analogy between the structure of the solar system and the configuration of subatomic particles.Many algorithms in computer science have been inspired from biology to solve different problems such as the traveling salesman problem [43], [44].They took inspirations from ants, which are capable of finding the shortest path from the nest to a food source [45], [46], by using a chemical substance called pheromone.Other notable examples include genetic algorithms, see [47][48][49] for a list of bio-inspired algorithms.</p>
<p>Two of the most remarkable approaches to this principle are the High-Level Perception (HLP) theory of analogy [94] and the Structure Mapping Theory (SMT) [22,25], however; building representations and models of the world still represents a major obstacle for these approaches.Hill et al. [93] investigated the use of neural networks to solve analogical problems, they also took inspiration from both SMT and HLP, where they encouraged the models to compare inputs at the more abstract level of relations rather than the less abstract level of attributes.Zhang et al. [26] also took inspiration from the field of psychology and education where teaching new concepts by comparing with noisy examples is shown to be effective.They build a model that sets the new state-of-the-art on two major Raven's Progressive Matrices datasets.One key limitation of the deep learning approach is the lack of transparency where the biases in many of the used datasets often lead to finding shortcuts instead of finding the real analogy [115,132,133].See [22,25,[93][94][95][96]115] for different theoretical and computational frameworks for the analogy principle.The main purpose of the algorithm that encapsulates the analogy principle would be to find matching between the studied problem and similar problems.</p>
<p>Concepts Combination</p>
<p>Concepts Combination is a fundamental cognitive principle [50][51][52].Many scientific discoveries are based on conceptual combination, where new concepts arise by combining old ones [53][54][55].Concepts combination is also one of the main used themes in theoretical physics.In 1973 for instance, both general relativity and quantum mechanics were at the frontier of the map of physics, by combining ideas from these two fields, Hawking proposed that black holes emit thermal radiation.Moreover, by combining ideas from quantum mechanics and statistical mechanics, Bekenstein and Hawking proposed the formula that describes the black hole entropy, which later led to the holographic principle.Some of the most notable approaches include conceptual blending [50], amalgamation [23], and compositional adaptation [24].These techniques combine input concepts from a knowledge base and output novel concepts.See [23, 24, 50, 56-57, 113, 114] for different theoretical and computational frameworks.One major limitation of these techniques is that they require well-formed knowledge as input.Furthermore, without deeper representations and models of the world these approaches and other AI systems will keep operating at a very shallow level.</p>
<p>Emergence</p>
<p>Emergence is a powerful approach to explain complex behaviors by simple underlying rules.One notable example is birds flocking, some birds fly in coordinated flocks that show remarkable synchronization in movements.Heppner [60] showed that the coordinated movements could be the result of simple movement rules followed by each bird individually.Another example is the Game of Life [61], a two-dimensional cellular automaton with rules that avoid the formation of structures that grow freely or quickly disappear.Remarkable behaviors have been observed such as the glider, a small group of cells that moves like an independent emergent entity.Wolfram [62] used a cellular automaton with simple initial conditions and simple rules to produce highly complex behaviors.In [112] a new computational tool was introduced to model the emergence of more complex phenomena by allowing non-local and time-independent events to take place.More recently, Gregor et al. [125] proposed an artificial life framework to facilitate the emergence of intelligent organisms through evolutionary process.Graph neural networks could be more suitable than other techniques to model complex systems with multiple interacting parts.The main purpose of the algorithm that encapsulates the emergence principle would be to find the set of rules that gives rise to the emergent behavior.</p>
<p>Computability</p>
<p>Computation is a new paradigm that has revolutionized science and engineering [63,82], it has derived many advancements in science and changed the way it is done.Many biologists would agree that biology is information science.One of the most notable examples is the DNA, which gives rise to the whole biological system.A growing number of physicists would also agree that the interactions between physical systems are information processing [64][65].Zenil et al. [81] proposed a universal unsupervised and parameter-free model-oriented approach based on the concept of algorithmic probability to decompose an observation into its most likely algorithmic generative models.The approach uses a perturbation-based causal calculus and principles drawn from algorithmic complexity to infer model representations.They demonstrated the ability of the approach to deconvolve interacting mechanisms regardless of whether the resulted objects are bit strings, images, or networks.A related topic is using machine learning for code generation (see [98] for a recent survey).Finding the program, the rules, or the equation that underlies the studied phenomena would be an important step to improve the explainability of machine learning systems and to avoid shortcuts reported in many examples [132][133].The main purpose of the algorithm that encapsulates the computability principle would be to find the program that gives rise to the observed phenomenon.</p>
<p>Beauty</p>
<p>Aesthetic judgments play a guiding role in scientific discovery [66][67][68][69].Scientists often evaluate models and theories based on their aesthetic appeal.</p>
<p>The role of beauty in science has found some skepticism [71] because we still do not have a satisfactory theory that can exactly test the claims made by scientists about the beauty of a theory.Hume [108] argued that aesthetic appreciation is due to feelings.Baumgarten [109] took the view that aesthetic appreciation is objective.Kant argued that there is a universal aspect to aesthetic [110].Dirac argued that beauty in mathematics is objective and universal [69,70].Recent works on empirical aesthetics [111] show that there is a general agreement on what is considered beautiful.A recent interesting study about the nature of aesthetic in science by Zeki et al. [72] demonstrated that the aesthetic appreciation of mathematical equations corresponds to the same brain activity that corresponds to the appreciation of music and art.Zee [73] and Thuan [74] also argued that beauty's attributes such as simplicity and symmetry have universal values and that they should not be subject to revision in science [69].</p>
<p>Recent approaches for beauty assessments of visual contents [130][131] could shed new lights on how to assess different scientific models.Deep learning could be particularly interesting where promising results were reported.The main purpose of the algorithm that encapsulates the beauty principle would be to find a metric that evaluates the scientific model describing the observed phenomenon.</p>
<p>Universality</p>
<p>Universality means that a similar mathematical formulation can describe different phenomena across multiple fields.The spectral measurements of composite materials, such as sea ice and human bones, the time between the buses' arrival in the city of Cuernavaca in Mexico, the zeros of the Riemann zeta function, and many other phenomena have shown to have the same statistical distribution [58].Power laws are another example of universal laws that have been observed in a wide range of phenomena in fields as diverse as physics, biology, and computer science [59].Recently, Mocanu et al. [144] were able to significantly reduce the number of parameters of deep learning models with no decrease in performance by enforcing a power law distribution.</p>
<p>Unification</p>
<p>Unification [151][152] has played a key role in physics since Newton who unified celestial and terrestrial mechanics, Maxwell who unified electricity and magnetism, then the unification of the weak and the electromagnetic forces, and most recently the attempts to unify all the four fundamental forces.Unification has also played an important role in biology [140][141].In addition to several attempts to unify different machine learning approaches such as neuro-symbolic [15,92], neuro-evolution [143], and many others [10,14].</p>
<p>Symmetry</p>
<p>Symmetry has played an important role in science [75,[136][137][138][139] from Newton's laws to Maxwell's equations, and general relativity.Symmetry has also played a fundamental role in the development of quantum mechanics.Today, it is one of the most used principles in searching for the fundamental laws of physics and further unification.Convolutional neural networks represent an early use of the symmetry principle in deep learning.Recently, more advanced symmetry was used to significantly reduce the number of examples required to train deep learning models [142].</p>
<p>Many of these principles could operate at different levels, for instance, the circulatory system example in the optimization principle.By studying the literatures, one can find that the energy and time should be minimized; here the optimization principle is operating at the conceptual level.Then the principle could operate at the mathematical level by using a mathematical description of the optimization process.Similar reasoning could be applied for other principles such as concepts combination where the ideas are firstly combined at the conceptual level and then at the mathematical level.</p>
<p>The use of the above principles varies from field to field, some principles are still used in a limited fashion.For instant, using the computability principle is still very limited in physics, the use of mathematization principle is still very limited in social sciences, and the use of the beauty principle is more dominant in physics and mathematics than in biology.</p>
<p>There are many other domain-specific principles that are specific to certain fields.Finding new principles could be crucial to make new discoveries and revolutionize our understanding, for instance, the use of the symmetry and mathematization principles has revolutionized modern physics, and maybe we need new principles to see in new perspectives and solve current challenges.</p>
<p>Discussion and Conclusion</p>
<p>This paper has presented a review of different machine learning techniques used in scientific discovery with their limitations.It discussed and reviewed the main principles used by scientists to solve problems and discover new knowledge.We argue that a key step to improve the generalization ability of AI systems is to build systems guided by these principles rather than focusing on solving specific and narrow problems, or searching the extremely large space of the evolution-inspired approaches.The main challenge to build science discovery machines and automate the scientific discovery process is to build the theoretical and computational frameworks that encapsulate these principles.Although some principles are harder to automate where the challenge of building representation and models of the world is more dominant such as concepts combination and analogy.However, a lot of progress can be made in working on other principles such as mathematization, emergence, etc. Deep learning could be a very effective tool to implement some of these principles, it has shown promising results for the mathematization principle.However, it might be limited for other principles.In the literature, there is a focus on few principles, we believe that there are rooms for many interesting future contributions by working on the rest of the principles by building different theoretical and computational frameworks or by investigating the use of some existing AI techniques.Incorporating these principles fully in an automated scientific discovery framework might open the doors for many advancements.Pursuing this research direction holds a great promise to help scientist in their research and to speed up the scientific discovery process.</p>
<p>The emperor's new mind: Concerning computers, minds, and the laws of physics. R Penrose, N D Mermin, 1990</p>
<p>The road to reality: A complete guide to the physical universe. R Penrose, 2004Jonathan Cape</p>
<p>Plato's theory of ideas. D Ross, 1953</p>
<p>M Aigner, G M Ziegler, K H Hofmann, P Erdos, Proofs from the Book. BerlinSpringer2010274</p>
<p>The architecture of mathematics. N Bourbaki, The American Mathematical Monthly. 5741950</p>
<p>The mathematician's mind: The psychology of invention in the mathematical field. J Hadamard, 1996</p>
<p>Scientific thinking and reasoning. The Cambridge handbook of thinking and reasoning. K Dunbar, J Fugelsang, 2005</p>
<p>Towards Robot Scientists for autonomous scientific discovery. A Sparkes, W Aubrey, E Byrne, A Clare, M N Khan, M Liakata, . . Young, M , Automated Experimentation. 2112010</p>
<p>Future progress in artificial intelligence: A survey of expert opinion. V C Mller, N Bostrom, Fundamental issues of artificial intelligence. ChamSpringer2016</p>
<p>The master algorithm: How the quest for the ultimate learning machine will remake our world. P Domingos, 2015Basic Books</p>
<p>The limitations of deep learning in adversarial settings. N Papernot, P Mcdaniel, S Jha, M Fredrikson, Z B Celik, A Swami, 2016 IEEE European Symposium on Security and Privacy (EuroS&amp;P). IEEE2016, March</p>
<p>Adversarial examples: Attacks and defenses for deep learning. X Yuan, P He, Q Zhu, X Li, 2019</p>
<p>One pixel attack for fooling deep neural networks. J Su, D V Vargas, K Sakurai, IEEE Transactions on Evolutionary Computation. 2019</p>
<p>Unifying logical and statistical AI with Markov logic. P Domingos, D Lowd, Communications of the ACM. 6272019</p>
<p>&amp; de Penning, L. T R Besold, A D A Garcez, S Bader, H Bowman, P Domingos, P Hitzler, arXiv:1711.03902Neural-symbolic learning and reasoning: A survey and interpretation. 2017arXiv preprint</p>
<p>Mapping the landscape of human-level artificial general intelligence. S Adams, I Arel, J Bach, R Coop, R Furlan, B Goertzel, . . Shapiro, S C , AI magazine. 3312012</p>
<p>Artificial general intelligence: concept, state of the art, and future prospects. B Goertzel, Journal of Artificial General Intelligence. 512014</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and brain sciences. 402017</p>
<p>AM: An artificial intelligence approach to discovery in mathematics as heuristic search (No. STAN-CS-76-570). D B Lenat, STANFORD UNIV CA DEPT OF COMPUTER SCIENCE1976</p>
<p>EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results. D B Lenat, Artificial intelligence. 211-21983</p>
<p>Why AM and EURISKO appear to work. D B Lenat, J S Brown, Artificial intelligence. 2331984</p>
<p>The structure-mapping engine: Algorithm and examples. B Falkenhainer, K D Forbus, D Gentner, Artificial intelligence. 4111989</p>
<p>Amalgams: A formal approach for combining multiple case solutions. S Ontan, E Plaza, International Conference on Case-Based Reasoning. Berlin, HeidelbergSpringer2010, July</p>
<p>Techniques and knowledge used for adaptation during case-based problem solving. W Wilke, R Bergmann, International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Berlin, HeidelbergSpringer1998. June</p>
<p>Structure-mapping: A theoretical framework for analogy. D Gentner, Cognitive science. 721983</p>
<p>Learning perceptual inference by contrasting. C Zhang, B Jia, F Gao, Y Zhu, H Lu, S C Zhu, Advances in Neural Information Processing Systems. 2019</p>
<p>Toward a metabolic theory of ecology. J H Brown, J F Gillooly, A P Allen, V M Savage, G B West, Ecology. 8572004</p>
<p>Energy efficiency drives the global seasonal distribution of birds. M Somveille, A S Rodrigues, A Manica, Nature ecology &amp; evolution. 269622018</p>
<p>Statistical physics of self-replication. J L England, The Journal of chemical physics. 139122013</p>
<p>The unreasonable effectiveness of mathematics in the natural sciences. E P Wigner, Mathematics and Science. 1990</p>
<p>Is God a mathematician?. M Livio, 2010Simon and Schuster</p>
<p>Our mathematical universe: My quest for the ultimate nature of reality. M Tegmark, 2014Vintage</p>
<p>Distilling free-form natural laws from experimental data. science. M Schmidt, H Lipson, 2009324</p>
<p>S M Udrescu, M Tegmark, arXiv:1905.11481AI Feynman: a Physics-Inspired Method for Symbolic Regression. 2019arXiv preprint</p>
<p>Unsupervised learning of latent physical properties using perception-prediction networks. D Zheng, V Luo, J Wu, J B Tenenbaum, arXiv:1807.092442018arXiv preprint</p>
<p>R Iten, T Metger, H Wilming, L Del Rio, R Renner, arXiv:1807.10300Discovering physical concepts with neural networks. 2018arXiv preprint</p>
<p>Exploring galaxy evolution with generative models. K Schawinski, M D Turp, C Zhang, arXiv:1812.011142018arXiv preprint</p>
<p>Analogical problem solving. M L Gick, K J Holyoak, Cognitive psychology. 1231980</p>
<p>Mathematics and plausible reasoning volume 1, Induction and analogy in mathematics. G Polya, 1954Princeton University Press</p>
<p>Mental leaps: Analogy in creative thought. K J Holyoak, P Thagard, 1995MIT PressBradford BooksCambridge, MA</p>
<p>N J Nersessian, Creating Scientific Concepts. Cambridge, MAMIT Press2008</p>
<p>How do scientists think? Capturing the dynamics of conceptual change in science. Cognitive models of science. N J Nersessian, 199215</p>
<p>Ant colony optimization. M Dorigo, M Birattari, 2010Springer US</p>
<p>Distributed optimization by ant colonies. A Colorni, M Dorigo, V Maniezzo, Proceedings of the first European conference on artificial life. the first European conference on artificial life1992, December142</p>
<p>Self-organized shortcuts in the Argentine ant. S Goss, S Aron, J L Deneubourg, J M Pasteels, Naturwissenschaften. 76121989</p>
<p>Trail and U-turns in the Selection of the Shortest Path by the Ants. R Beckers, J L Deneubourg, S Gross, J. of Theoretical Biology. 1591992</p>
<p>A survey of bio inspired optimization algorithms. S Binitha, S S Sathya, International journal of soft computing and engineering. 222012</p>
<p>Nature-inspired optimization algorithms. X S Yang, 2014Elsevier</p>
<p>Handbook of bioinspired algorithms and applications. S Olariu, A Y Zomaya, 2005Chapman and Hall/CRC</p>
<p>The Way We Think. G Fauconnier, M Turner, 2003</p>
<p>The act of creation. A Koestler, 1967DellNew York</p>
<p>M Boden, The creative mind: Myths and mechanisms. LondonRoutledge20042nd ed.</p>
<p>The associate basis of the creative process. S A Mednick, Psychological Review. 691962</p>
<p>Computational philosophy of science. P Thagard, 1988MIT PressCambridge, MA</p>
<p>The AHA! experience: Creativity through emergent binding in neural networks. P Thagard, T C Stewart, Cognitive science. 3512011</p>
<p>Algorithmic aspects of theory blending. M Martinez, U Krumnack, A Smaill, T R Besold, A M Abdel-Fattah, M Schmidt, A Pease, International Conference on Artificial Intelligence and Symbolic Computation. ChamSpringer2014, December</p>
<p>R Confalonieri, A Pease, M Schorlemmer, T R Besold, O Kutz, E Maclean, Concept invention: Foundations, implementation, social aspects and applications. M Kaliakatsos-Papakostas, Springer2018</p>
<p>Universality for mathematical and physical systems. P Deift, math-ph/06030382006arXiv preprint</p>
<p>Power laws, Pareto distributions and Zipf's law. M E Newman, Contemporary physics. 4652005</p>
<p>A stochastic nonlinear model for coordinated bird flocks. The ubiquity of chaos. F Heppner, U Grenander, 1990238</p>
<p>The game of life. J Conway, Scientific American. 223441970</p>
<p>A new kind of science. S Wolfram, 2002Wolfram mediaChampaign, IL</p>
<p>Computational thinking in science. P J Denning, 2017</p>
<p>Programming the universe: a quantum computer scientist takes on the cosmos. S Lloyd, 2006Vintage</p>
<p>K Zuse, Rechnender raum. Springer-Verlag2013</p>
<p>Why is beauty a road to the truth?. P Thagard, Cognitive structures in scientific inquiry. RodopiBrill2005</p>
<p>Beauty, a Road to The Truth. T Kuipers, 2002131</p>
<p>A conceptual overview of the role of beauty and aesthetics in science and science education. M Girod, 2007</p>
<p>Aesthetic values in science. M Ivanova, Philosophy Compass. 1210e124332017</p>
<p>Paul Dirac. Obituary Notice, American Philosophical Society Yearbook for. F J Dyson, 1987. 1986</p>
<p>Beauty and Revolution in Science. Mcallister, 1996Cornell University PressIthaca, NY</p>
<p>The Experience of Mathamtical beauty and its Neural Correlates. S Zeki, J P Romaya, D M T Benincasa, M F Atiyah, Frontiers in Human Neuroscience. 82014</p>
<p>A Zee, Fearful Symmetry: the Search for Beauty in Modern Physics. PrincetonPrinceton University Press1999</p>
<p>Chaos and Harmony: Perspectives on Scientific Revolutions of the Twentieth Century. T Thuan, 2001Oxford University PressNew York</p>
<p>The role of symmetry in fundamental physics. D J Gross, Proceedings of the National Academy of Sciences. 93251996</p>
<p>K Xu, J Li, M Zhang, S S Du, K I Kawarabayashi, S Jegelka, arXiv:1905.13211What Can Neural Networks Reason About. 2019arXiv preprint</p>
<p>D Saxton, E Grefenstette, F Hill, P Kohli, arXiv:1904.01557Analysing mathematical reasoning abilities of neural models. 2019arXiv preprint</p>
<p>Raven: A dataset for relational and analogical visual reasoning. C Zhang, F Gao, B Jia, Y Zhu, S C Zhu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2019</p>
<p>D G Barrett, F Hill, A Santoro, A S Morcos, T Lillicrap, arXiv:1807.04225Measuring abstract reasoning in neural networks. 2018arXiv preprint</p>
<p>Rebooting AI: building artificial intelligence we can trust. E Davis, G Marcus, 2019Knopf Doubleday Publishing Group</p>
<p>Causal deconvolution by algorithmic generative models. H Zenil, N A Kiani, A A Zea, J Tegnr, Nature Machine Intelligence. 11582019</p>
<p>H Zenil, arXiv:1904.10258Compression is Comprehension, and the Unreasonable Effectiveness of Digital Computation in the Natural World. 2019arXiv preprint</p>
<p>G Marcus, arXiv:1801.00631Deep learning: A critical appraisal. 2018arXiv preprint</p>
<p>Toward an AI physicist for unsupervised learning. T Wu, M Tegmark, arXiv:1810.105252018arXiv preprint</p>
<p>AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence. J Clune, arXiv:1905.109852019arXiv preprint</p>
<p>Artificial Intelligence: A Guide for Thinking Humans. M Mitchell, 2019Farrar, Straus and Giroux</p>
<p>R Roscher, B Bohn, M F Duarte, J Garcke, arXiv:1905.08883Explainable Machine Learning for Scientific Insights and Discoveries. 2019arXiv preprint</p>
<p>Artificial intelligence and scientific creativity. S Colton, G Steel, Artificial Intelligence and the Study of Behaviour Quarterly. 1021999</p>
<p>Towards an explanatory and computational theory of scientific discovery. C Chen, Y Chen, M Horowitz, H Hou, Z Liu, D Pellegrino, Journal of Informetrics. 332009</p>
<p>How Artificial Intelligence Can Help Us Understand Human Creativity. F Gobet, G Sala, Frontiers in Psychology. 1014012019</p>
<p>Computational scientific discovery. P D Sozou, P C Lane, M Addis, F Gobet, Springer Handbook of Model-Based Science. ChamSpringer2017</p>
<p>A D A Garcez, M Gori, L C Lamb, L Serafini, M Spranger, S N Tran, arXiv:1905.06088Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning. 2019arXiv preprint</p>
<p>F Hill, A Santoro, D G Barrett, A S Morcos, T Lillicrap, arXiv:1902.00120Learning to make analogies by contrasting abstract relational structure. 2019arXiv preprint</p>
<p>High-level perception, representation, and analogy: A critique of artificial intelligence methodology. D J Chalmers, R M French, D R Hofstadter, Journal of Experimental &amp; Theoretical Artificial Intelligence. 431992</p>
<p>Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought. D R Hofstadter, 1995Basic books</p>
<p>Analogy-making as perception: A computer model. M Mitchell, 1993Mit Press</p>
<p>S Hu, Y Ma, X Liu, Y Wei, S Bai, arXiv:2002.06838Hierarchical Rule Induction Network for Abstract Visual Reasoning. 2020arXiv preprint</p>
<p>Automated Coding: The Quest to Develop Programs That Write Programs. M Campbell, Computer. 5322020</p>
<p>M Raghu, E Schmidt, arXiv:2003.11755A Survey of Deep Learning for Scientific Discovery. 2020arXiv preprint</p>
<p>. F Bacon, Novum Organum [Trans. and Ed.: P. Urbach, J. Gibson1620. 1994Court, Chicago and La Salle</p>
<p>Conjectures and refutations: The growth of scientific knowledge. K Popper, 1963routledge</p>
<p>Scientific discovery: Computational explorations of the creative processes. P Langley, H A Simon, G L Bradshaw, J M Zytkow, 1987MIT press</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, Nature. 55977152018</p>
<p>Machine learning and the physical sciences. G Carleo, I Cirac, K Cranmer, L Daudet, M Schuld, N Tishby, . . Zdeborov, L , Reviews of Modern Physics. 914450022019</p>
<p>Opportunities and obstacles for deep learning in biology and medicine. T Ching, D S Himmelstein, B K Beaulieu-Jones, A A Kalinin, B T Do, G P Way, . . Xie, W , Journal of The Royal Society Interface. 151412018. 20170387</p>
<p>From genotype to phenotype: Augmenting deep learning with networks and systems biology. Current opinion in systems biology. V H Gazestani, N E Lewis, 2019</p>
<p>Deep learning and process understanding for data-driven Earth system science. M Reichstein, G Camps-Valls, B Stevens, M Jung, J Denzler, N Carvalhais, Nature. 56677432019</p>
<p>Hume's aesthetics. T Gracyk, 2011Stanford encyclopedia of Philosophy</p>
<p>The German aesthetic tradition. K Hammermeister, 2002Cambridge University Press</p>
<p>Kant's aesthetics. Internet encyclopedia of philosophy. D Burnham, 2001</p>
<p>Beauty and the beholder: Highly individual taste for abstract, but not real-world images. E A Vessel, N Rubin, Journal of vision. 1022010</p>
<p>Dynamic Switching Networks. A M Khalili, Complex Systems. 1282019</p>
<p>Blend City, BlendVille. J Gonalves, P Martins, A Cardoso, ICCC. 2017</p>
<p>F C Pereira, Creativity and artificial intelligence: a conceptual blending approach. Walter de Gruyter20074</p>
<p>Abstraction and Analogy-Making in Artificial Intelligence. M Mitchell, arXiv:2102.107172021arXiv preprint</p>
<p>Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery. H Kitano, AI magazine. 3712016</p>
<p>Autonomous discovery in the chemical sciences part I: Progress. C W Coley, N S Eyke, K F Jensen, Angewandte Chemie International Edition. 59512020</p>
<p>Autonomous discovery in the chemical sciences part II: outlook. C W Coley, N S Eyke, K F Jensen, Angewandte Chemie International Edition. 59522020</p>
<p>Automating sciences: Philosophical and social dimensions. R D King, V S Costa, C Mellingwood, L N Soldatova, IEEE Technology and Society Magazine. 3712018</p>
<p>Towards a humanmachine scientific partnership based on semantically rich research objects. J M Gomez-Perez, R Palma, A Garcia-Silva, 2017 IEEE 13th International Conference on e-Science (e-Science. IEEE2017, October</p>
<p>Robot-scientists will lead tomorrow's biomaterials discovery. A Vasilevich, J De Boer, Current Opinion in Biomedical Engineering. 62018</p>
<p>Artificial intelligence and machine learning in science. R D King, S Roberts, 2018</p>
<p>2100 AI: Reflections on the mechanisation of scientific discovery. A Mannocci, A A Salatino, F Osborne, E Motta, 2017</p>
<p>The book of why: the new science of cause and effect. J Pearl, D Mackenzie, 2018Basic books</p>
<p>Self-Organizing Intelligent Matter: A blueprint for an AI generating algorithm. K Gregor, F Besse, arXiv-21012021arXiv e-prints</p>
<p>Abandoning objectives: Evolution through the search for novelty alone. J Lehman, K O Stanley, Evolutionary computation. 1922011</p>
<p>Why open-endedness matters. K O Stanley, Artificial life. 2532019</p>
<p>A B Arrieta, N Daz-Rodrguez, J Del Ser, A Bennetot, S Tabik, A Barbado, . . Herrera, F , Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion. 202058</p>
<p>G Vilone, L Longo, arXiv:2006.00093Explainable artificial intelligence: a systematic review. 2020arXiv preprint</p>
<p>A deep learning perspective on beauty, sentiment, and remembrance of art. E Cetinic, T Lipic, S Grgic, IEEE Access. 72019</p>
<p>An Information Theory Approach to Aesthetic Assessment of Visual Patterns. A Khalili, H Bouchachia, Entropy. 2321532021</p>
<p>Shortcut learning in deep neural networks. R Geirhos, J H Jacobsen, C Michaelis, R Zemel, W Brendel, M Bethge, F A Wichmann, Nature Machine Intelligence. 2112020</p>
<p>Five Points to Check when Comparing Visual Perception in Humans and Machines. C M Funke, J Borowski, K Stosio, W Brendel, T S A Wallis, M Bethge, ArXiv:2004.094062020arXiv preprintCs, q-Bio, Stat</p>
<p>The quest for optimality: A positive heuristic of science?. P J Schoemaker, Behavioral and Brain Sciences. 1421991</p>
<p>A central principle of science: Optimization. R F Bordley, Behavioral Science. 2811983</p>
<p>Symmetry at the Foundation of Science and. J Rosen, Nature. Symmetry. 112009</p>
<p>Symmetry as a Superprinciple of Science and Art. A V Voloshinov, 1996Leonardo</p>
<p>J P Elliott, P G Dawber, Symmetry in Physics. Macmillan19791</p>
<p>Symmetry. H Weyl, 2015Princeton University Press104</p>
<p>In the beat of a heart: life, energy, and the unity of nature. J Whitfield, 1922National Academies Press</p>
<p>Unifying biology: The evolutionary synthesis and evolutionary biology. V B Smocovitis, Journal of the History of Biology. 2511992</p>
<p>M Winkels, T S Cohen, arXiv:1804.046563D G-CNNs for pulmonary nodule detection. 2018arXiv preprint</p>
<p>Designing neural networks through neuroevolution. K O Stanley, J Clune, J Lehman, R Miikkulainen, Nature Machine Intelligence. 112019</p>
<p>Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. D C Mocanu, E Mocanu, P Stone, P H Nguyen, M Gibescu, A Liotta, Nature communications. 912018</p>
<p>G Raayoni, S Gottlieb, G Pisha, Y Harris, Y Manor, U Mendlovic, . . Kaminer, I , arXiv:1907.00205The ramanujan machine: automatically generated conjectures on fundamental constants. 2019arXiv preprint</p>
<p>Universal artificial intelligence: Sequential decisions based on algorithmic probability. M Hutter, 2004Springer Science &amp; Business Media</p>
<p>B Goertzel, arXiv:2103.15100The General Theory of General Intelligence: A Pragmatic Patternist Perspective. 2021arXiv preprint</p>
<p>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. S M Udrescu, A Tan, J Feng, O Neto, T Wu, M Tegmark, Advances in Neural Information Processing Systems. 202033</p>
<p>Thoughtful artificial intelligence: Forging a new partnership for data science and scientific discovery. Y Gil, Data Science. 11-22017</p>
<p>Nobel Turing Challenge: creating the engine for scientific discovery. H Kitano, Systems Biology and Applications. 712021</p>
<p>Two uses of unification. E Sober, The Vienna Circle and Logical Empiricism -Vienna Circle Institute Yearbook. F Stadler, Dordrecht Kluwer, 2003. 2002</p>
<p>Explanatory unification and the causal structure of the world. P Kitcher, Scientific Explanation. P Kitcher, W Salmon, MinneapolisUniversity of Min-nesota Press1989</p>            </div>
        </div>

    </div>
</body>
</html>