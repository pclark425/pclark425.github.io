<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2220 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2220</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2220</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-60.html">extraction-schema-60</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use proxy metrics, computational predictions, or surrogate objectives for scientific discovery, and how these compare to experimental or ground-truth validation, including quantitative measures of agreement or disagreement.</div>
                <p><strong>Paper ID:</strong> paper-277219384</p>
                <p><strong>Paper Title:</strong> Machine learning‐based risk prediction model for neuropathic foot ulcers in patients with diabetic peripheral neuropathy</p>
                <p><strong>Paper Abstract:</strong> ABSTRACT Background Diabetic peripheral neuropathy (DPN) is a common chronic complication of diabetes, marked by symptoms like hyperalgesia, numbness, and swelling that impair quality of life. Nerve conduction abnormalities in DPN significantly increase the risk of neuropathic foot ulcers (NFU), which can progress rapidly and lead to severe outcomes, including infection, gangrene, and amputation. Early prediction of NFU in DPN patients is crucial for timely intervention. Methods Clinical data from 400 DPN patients treated at the China–Japan Friendship Hospital (September 2022–2024) were retrospectively analyzed. Data included medical histories, physical exams, biochemical tests, and imaging. After feature selection and data balancing, the dataset was split into training and validation subsets (8:2 ratio). Six machine learning algorithms—random forest, decision tree, logistic regression, K‐nearest neighbor, extreme gradient boosting, and multilayer perceptron—were evaluated using k‐fold cross‐validation. Model performance was assessed via accuracy, precision, recall, F1 score, and AUC. The SHAP method was employed for interpretability. Results The multilayer perceptron model showed the best performance (accuracy: 0.875; AUC: 0.901). SHAP analysis highlighted triglycerides, high‐density lipoprotein cholesterol, diabetes duration, age, and fasting blood glucose as key predictors. Conclusions A machine learning‐based prediction model using a multilayer perceptron algorithm effectively identifies DPN patients at high NFU risk, offering clinicians an accurate tool for early intervention.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2220.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2220.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use proxy metrics, computational predictions, or surrogate objectives for scientific discovery, and how these compare to experimental or ground-truth validation, including quantitative measures of agreement or disagreement.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ML predictive pipeline (MLP/RF/DT/LR/K-NN/XGBoost)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning predictive pipeline for neuropathic foot ulcers (multilayer perceptron, random forest, decision tree, logistic regression, K-nearest neighbor, extreme gradient boosting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of supervised machine-learning models trained on 26 clinical features from 400 DPN patients (after SMOTE balancing and an 8:2 train/validation split) to predict presence of neuropathic foot ulcers; evaluated by fivefold cross-validation using accuracy, precision, recall, F1 and AUC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multimodel ML pipeline (MLP primary)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Supervised classifiers trained on clinical/demographic/lab/imaging features (26 features). Data balancing with SMOTE, random 80/20 train/validation split, fivefold cross-validation. Algorithms evaluated: multilayer perceptron (MLP), random forest (RF), decision tree (DT), logistic regression (LR), K-nearest neighbors (K-NN), extreme gradient boosting (XGBoost). Model selection based on average cross-validated metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Clinical predictive modeling / medical diagnosis (diabetic complications)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Model predictive performance metrics (AUC, accuracy, precision, recall, F1 score)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Metrics computed by comparing model predicted labels (probabilities or class predictions) to the EMR-derived ground-truth labels on validation folds: AUC from ROC of predicted probability vs label; accuracy = (TP+TN)/total; precision = TP/(TP+FP); recall = TP/(TP+FN); F1 = harmonic mean of precision and recall. Reported as means across fivefold cross-validation.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven ML prediction</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric</strong></td>
                            <td>Clinical diagnosis labels for neuropathic foot ulcer (NFU) status</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Retrospectively extracted binary labels (NFU present/absent) from the Electronic Medical Record and Laboratory Information System using clinical definitions: ulcers/infections/tissue destruction below ankle joint attributable to neuropathy, corroborated by history, exams and imaging per inclusion criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td>The paper treats model metrics as performance against ground-truth labels (no independent experimental/clinical prospective validation). Reported cross-validated metrics (mean): MLP — accuracy 0.8751, AUC 0.901, precision 0.7250, recall 0.8245, F1 0.7681; RF — accuracy 0.8575, AUC 0.886, precision 0.9778, recall 0.4344, F1 0.6008; DT — AUC 0.707; K-NN — accuracy 0.8575, recall 0.8514, F1 0.7461; XGBoost (GB) — accuracy 0.8531, precision 0.8086, recall 0.5328, F1 0.6386; LR — accuracy 0.7435, precision 0.4598, recall 0.2573, F1 0.3270. No explicit statistical gap metric (e.g., R² between proxy and independent experimental outcomes) was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>See quantitative_gap_measure: MLP (best): AUC 0.901, accuracy 0.8751, precision 0.7250, recall 0.8245, F1 0.7681 (means across fivefold CV).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td>Not reported as a separate independent validation; reported ML metrics are computed against the ground-truth labels from the same retrospective dataset, so numeric values equal the proxy_performance values above.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_characterization</strong></td>
                            <td>In-distribution / incremental: predictive modeling within a specific clinical cohort (single-center retrospective Chinese DPN patients); models predict an already-defined clinical outcome rather than discovering new biology.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_method</strong></td>
                            <td>Cross-validation, SMOTE class-balancing to reduce bias due to class imbalance, comparison across multiple algorithms to reduce model selection bias, and model interpretation (SHAP) to check feature consistency with clinical knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_effectiveness</strong></td>
                            <td>Not quantitatively attributed to gap reduction between proxy and independent experimental outcomes. Reported effect: SMOTE increased minority class count from 57 to 113 (see Table 2). Model selection: MLP achieved higher averaged metrics (AUC 0.901) than others, but no external validation to quantify reduction in real-world error.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_comparison</strong></td>
                            <td>Not discussed. No analysis comparing costs/resources of computational evaluation versus prospective clinical validation.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_validation</strong></td>
                            <td>None — no prospective or long-term outcome validation; only retrospective cross-validation on the same dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging-to-maturing: the paper states ML methods are increasingly used and can outperform traditional linear models in clinical prediction, but highlights limitations (single-center data, small sample, lack of external validation).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_correlation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>Simple computational validation cascade: data preprocessing → SMOTE oversampling → train/validation split (80/20) → fivefold cross-validation for model selection → evaluation via confusion matrix and ROC/AUC. There is no intermediate experimental stage or external prospective validation stage.</td>
                        </tr>
                        <tr>
                            <td><strong>publication_bias_discussion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Authors explicitly note small sample size, single-center cohort, retrospective design, absence of independent external validation dataset, and incomplete capture of some known risk features (e.g., eGFR, diabetic retinopathy history). They also note class imbalance (addressed by SMOTE) and that generalizability to other ethnic/geographic populations is untested.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Clinical label noise and heterogeneity (retrospective EMR-derived labels), limited feature set (26 features; some known risk factors missing), class imbalance (14.2% positives), potential overfitting due to single-center data, and patient population-specific factors that limit generalizability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2220.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2220.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use proxy metrics, computational predictions, or surrogate objectives for scientific discovery, and how these compare to experimental or ground-truth validation, including quantitative measures of agreement or disagreement.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMOTE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Synthetic Minority Oversampling Technique (SMOTE) for data balancing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An oversampling algorithm that generates synthetic minority-class samples by interpolating between existing minority samples and their k-nearest neighbors to mitigate class imbalance during model training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SMOTE for high-dimensional class-imbalanced data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SMOTE oversampling</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Applied to increase the number of NFU-positive samples in the dataset by creating synthetic minority-class examples via interpolation with nearest neighbors; the minority class was increased from 57 to 113 samples (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Data preprocessing / machine learning (clinical datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Synthetic sample generation as a surrogate for collecting additional positive clinical cases</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>SMOTE creates new synthetic feature vectors by selecting a minority-class example, choosing one of its k-nearest minority neighbors, and interpolating feature values along the line segment between them, producing augmented training data to reduce class imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>empirical surrogate (data augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric</strong></td>
                            <td>Actual patient records (real NFU-positive cases)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Original minority-class examples drawn from retrospective EMR/clinical records representing true NFU-positive patients (57 cases before SMOTE).</td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td>No quantitative evaluation of how well synthetic samples represent true clinical cases was provided. Reported concrete effect: minority count increased from 57 to 113 after SMOTE (Table 2). No metrics (e.g., distributional divergence, classifier performance delta attributable solely to SMOTE) were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Not reported as an independent performance metric. SMOTE was a preprocessing step; downstream model metrics (see ML pipeline) reflect its use but authors did not report ablation showing metrics with vs without SMOTE.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_characterization</strong></td>
                            <td>Method is standard/established for class imbalance; usage here is in-distribution augmentation (incremental).</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_method</strong></td>
                            <td>SMOTE itself is used to reduce proxy-model bias introduced by class imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_effectiveness</strong></td>
                            <td>Not quantitatively reported; only the post-SMOTE class counts (minority increased to 113) are provided; no direct before/after model performance comparison attributed solely to SMOTE.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_comparison</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_validation</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established and commonly used technique in ML preprocessing for imbalanced datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_correlation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>Used early in pipeline as data balancing step prior to model training and cross-validation; no further validation of synthetic-data fidelity reported.</td>
                        </tr>
                        <tr>
                            <td><strong>publication_bias_discussion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Authors do not quantify risks introduced by synthetic samples; potential challenge is that synthetic interpolation may not capture true clinical heterogeneity, and absence of external validation precludes testing whether models trained with SMOTE generalize to real-world unseen patients.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Clinical feature distributions may be complex and multi-modal; interpolated synthetic records may lie in low-density or unrealistic regions of clinical feature space, especially with small initial minority sample size (n=57), amplifying distributional mismatch risk.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2220.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2220.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use proxy metrics, computational predictions, or surrogate objectives for scientific discovery, and how these compare to experimental or ground-truth validation, including quantitative measures of agreement or disagreement.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SHAP analysis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SHapley Additive exPlanations (SHAP) feature attribution analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A game-theory-based interpretability method that assigns each feature a Shapley value representing its contribution to individual model predictions; used here to rank feature importance in the selected MLP model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SHAP (SHapley Additive exPlanations)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Computed Shapley values for features in the MLP model to quantify per-feature contribution to model outputs and produce feature-importance rankings and visualizations; the top-10 features were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Model interpretability / explainable AI in clinical prediction</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>SHAP feature importance (Shapley values)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Shapley value assigned to each feature quantifies its average marginal contribution to model predictions across permutations of features; used to identify and rank influential predictors (reported top features: triglycerides, HDL-C, diabetes duration, age, fasting blood glucose, glycated albumin, hypertension history, LDL-C, postprandial BG, diabetic nephropathy history).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven interpretability metric</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric</strong></td>
                            <td>Classical statistical significance testing of feature differences between NFU and non-NFU groups (P-values), and established clinical knowledge of risk factors</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Group-wise comparisons reported in Table 1 using Shapiro-Wilk, t-tests, Wilcoxon, chi-squared, etc.; features with statistically significant differences included diabetes duration (P=0.048), glycated hemoglobin (P=0.012), fasting blood glucose (P=0.002), postprandial blood glucose (P=0.036), triglycerides (P<0.001), and HDL-C (P=0.017).</td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td>No formal numeric concordance statistic is reported between SHAP importance scores and statistical significance. Qualitative agreement: SHAP top features (triglycerides, HDL-C, diabetes duration, age, fasting BG) overlap with features having significant p-values (triglycerides P<0.001, HDL-C P=0.017, diabetes duration P=0.048, fasting BG P=0.002). No Shapley value magnitudes or correlation coefficients vs statistical effect sizes are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>SHAP is a descriptive interpretation tool; the paper reports the ranked top-10 features but not numeric Shapley value aggregates in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td>Statistical test results for group differences: triglycerides median 1.35 vs 1.71 mmol/L (P<0.001); HDL-C 1.29 vs 1.54 mmol/L (P=0.017); diabetes duration medians 13 vs 20 years (P=0.048); fasting BG 6.64 vs 7.69 mmol/L (P=0.002). These are the ground-truth associations used to cross-check model explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_characterization</strong></td>
                            <td>In-distribution explanatory analysis — aligns model explanations with known/expected clinical risk factors (incremental confirmation).</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_method</strong></td>
                            <td>SHAP used to validate that model influential features are clinically plausible and overlap with statistically significant covariates (qualitative calibration of model explanations to ground-truth associations).</td>
                        </tr>
                        <tr>
                            <td><strong>gap_reduction_effectiveness</strong></td>
                            <td>Qualitative: SHAP top features largely overlap with features that are statistically different between groups (see p-values above), lending face validity; no quantitative calibration (e.g., correlation between SHAP scores and effect sizes) reported.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_comparison</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_validation</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>SHAP is an established interpretability method widely used in ML-for-health studies; authors use it as standard practice.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_correlation</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>SHAP applied to the final selected MLP model after cross-validation to interpret feature contributions; used as part of model QA rather than as an independent validation stage.</td>
                        </tr>
                        <tr>
                            <td><strong>publication_bias_discussion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Authors did not present numeric Shapley value distributions, significance testing of SHAP rankings, or correlation analyses between SHAP values and classical effect sizes; therefore, the strength and calibration of SHAP-derived attributions relative to epidemiological ground truth are not quantitatively assessed.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Clinical covariates may be correlated and confounded; SHAP attribution assumes model structure and data distribution — retrospective and potentially collinear features may complicate attribution and its concordance with causal/epidemiological ground truth.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>SMOTE for high-dimensional class-imbalanced data <em>(Rating: 2)</em></li>
                <li>Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP <em>(Rating: 2)</em></li>
                <li>A machine learning model for early detection of diabetic foot using thermogram images <em>(Rating: 1)</em></li>
                <li>Machine learning algorithm to evaluate risk factors of diabetic foot ulcers and its severity <em>(Rating: 1)</em></li>
                <li>Risk prediction of diabetic foot amputation using machine learning and explainable artificial intelligence <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2220",
    "paper_id": "paper-277219384",
    "extraction_schema_id": "extraction-schema-60",
    "extracted_data": [
        {
            "name_short": "ML predictive pipeline (MLP/RF/DT/LR/K-NN/XGBoost)",
            "name_full": "Machine learning predictive pipeline for neuropathic foot ulcers (multilayer perceptron, random forest, decision tree, logistic regression, K-nearest neighbor, extreme gradient boosting)",
            "brief_description": "A set of supervised machine-learning models trained on 26 clinical features from 400 DPN patients (after SMOTE balancing and an 8:2 train/validation split) to predict presence of neuropathic foot ulcers; evaluated by fivefold cross-validation using accuracy, precision, recall, F1 and AUC.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Multimodel ML pipeline (MLP primary)",
            "system_description": "Supervised classifiers trained on clinical/demographic/lab/imaging features (26 features). Data balancing with SMOTE, random 80/20 train/validation split, fivefold cross-validation. Algorithms evaluated: multilayer perceptron (MLP), random forest (RF), decision tree (DT), logistic regression (LR), K-nearest neighbors (K-NN), extreme gradient boosting (XGBoost). Model selection based on average cross-validated metrics.",
            "domain": "Clinical predictive modeling / medical diagnosis (diabetic complications)",
            "proxy_metric_name": "Model predictive performance metrics (AUC, accuracy, precision, recall, F1 score)",
            "proxy_metric_description": "Metrics computed by comparing model predicted labels (probabilities or class predictions) to the EMR-derived ground-truth labels on validation folds: AUC from ROC of predicted probability vs label; accuracy = (TP+TN)/total; precision = TP/(TP+FP); recall = TP/(TP+FN); F1 = harmonic mean of precision and recall. Reported as means across fivefold cross-validation.",
            "proxy_metric_type": "data-driven ML prediction",
            "ground_truth_metric": "Clinical diagnosis labels for neuropathic foot ulcer (NFU) status",
            "ground_truth_description": "Retrospectively extracted binary labels (NFU present/absent) from the Electronic Medical Record and Laboratory Information System using clinical definitions: ulcers/infections/tissue destruction below ankle joint attributable to neuropathy, corroborated by history, exams and imaging per inclusion criteria.",
            "has_both_proxy_and_ground_truth": true,
            "quantitative_gap_measure": "The paper treats model metrics as performance against ground-truth labels (no independent experimental/clinical prospective validation). Reported cross-validated metrics (mean): MLP — accuracy 0.8751, AUC 0.901, precision 0.7250, recall 0.8245, F1 0.7681; RF — accuracy 0.8575, AUC 0.886, precision 0.9778, recall 0.4344, F1 0.6008; DT — AUC 0.707; K-NN — accuracy 0.8575, recall 0.8514, F1 0.7461; XGBoost (GB) — accuracy 0.8531, precision 0.8086, recall 0.5328, F1 0.6386; LR — accuracy 0.7435, precision 0.4598, recall 0.2573, F1 0.3270. No explicit statistical gap metric (e.g., R² between proxy and independent experimental outcomes) was reported.",
            "proxy_performance": "See quantitative_gap_measure: MLP (best): AUC 0.901, accuracy 0.8751, precision 0.7250, recall 0.8245, F1 0.7681 (means across fivefold CV).",
            "ground_truth_performance": "Not reported as a separate independent validation; reported ML metrics are computed against the ground-truth labels from the same retrospective dataset, so numeric values equal the proxy_performance values above.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_characterization": "In-distribution / incremental: predictive modeling within a specific clinical cohort (single-center retrospective Chinese DPN patients); models predict an already-defined clinical outcome rather than discovering new biology.",
            "gap_varies_with_novelty": null,
            "gap_variation_details": "",
            "gap_reduction_method": "Cross-validation, SMOTE class-balancing to reduce bias due to class imbalance, comparison across multiple algorithms to reduce model selection bias, and model interpretation (SHAP) to check feature consistency with clinical knowledge.",
            "gap_reduction_effectiveness": "Not quantitatively attributed to gap reduction between proxy and independent experimental outcomes. Reported effect: SMOTE increased minority class count from 57 to 113 (see Table 2). Model selection: MLP achieved higher averaged metrics (AUC 0.901) than others, but no external validation to quantify reduction in real-world error.",
            "validation_cost_comparison": "Not discussed. No analysis comparing costs/resources of computational evaluation versus prospective clinical validation.",
            "temporal_validation": "None — no prospective or long-term outcome validation; only retrospective cross-validation on the same dataset.",
            "domain_maturity": "Emerging-to-maturing: the paper states ML methods are increasingly used and can outperform traditional linear models in clinical prediction, but highlights limitations (single-center data, small sample, lack of external validation).",
            "uncertainty_quantification": false,
            "uncertainty_calibration": "",
            "multiple_proxies": true,
            "proxy_correlation": "",
            "validation_cascade": "Simple computational validation cascade: data preprocessing → SMOTE oversampling → train/validation split (80/20) → fivefold cross-validation for model selection → evaluation via confusion matrix and ROC/AUC. There is no intermediate experimental stage or external prospective validation stage.",
            "publication_bias_discussion": false,
            "limitations_challenges": "Authors explicitly note small sample size, single-center cohort, retrospective design, absence of independent external validation dataset, and incomplete capture of some known risk features (e.g., eGFR, diabetic retinopathy history). They also note class imbalance (addressed by SMOTE) and that generalizability to other ethnic/geographic populations is untested.",
            "domain_specific_factors": "Clinical label noise and heterogeneity (retrospective EMR-derived labels), limited feature set (26 features; some known risk factors missing), class imbalance (14.2% positives), potential overfitting due to single-center data, and patient population-specific factors that limit generalizability.",
            "uuid": "e2220.0"
        },
        {
            "name_short": "SMOTE",
            "name_full": "Synthetic Minority Oversampling Technique (SMOTE) for data balancing",
            "brief_description": "An oversampling algorithm that generates synthetic minority-class samples by interpolating between existing minority samples and their k-nearest neighbors to mitigate class imbalance during model training.",
            "citation_title": "SMOTE for high-dimensional class-imbalanced data",
            "mention_or_use": "use",
            "system_name": "SMOTE oversampling",
            "system_description": "Applied to increase the number of NFU-positive samples in the dataset by creating synthetic minority-class examples via interpolation with nearest neighbors; the minority class was increased from 57 to 113 samples (Table 2).",
            "domain": "Data preprocessing / machine learning (clinical datasets)",
            "proxy_metric_name": "Synthetic sample generation as a surrogate for collecting additional positive clinical cases",
            "proxy_metric_description": "SMOTE creates new synthetic feature vectors by selecting a minority-class example, choosing one of its k-nearest minority neighbors, and interpolating feature values along the line segment between them, producing augmented training data to reduce class imbalance.",
            "proxy_metric_type": "empirical surrogate (data augmentation)",
            "ground_truth_metric": "Actual patient records (real NFU-positive cases)",
            "ground_truth_description": "Original minority-class examples drawn from retrospective EMR/clinical records representing true NFU-positive patients (57 cases before SMOTE).",
            "has_both_proxy_and_ground_truth": false,
            "quantitative_gap_measure": "No quantitative evaluation of how well synthetic samples represent true clinical cases was provided. Reported concrete effect: minority count increased from 57 to 113 after SMOTE (Table 2). No metrics (e.g., distributional divergence, classifier performance delta attributable solely to SMOTE) were reported.",
            "proxy_performance": "Not reported as an independent performance metric. SMOTE was a preprocessing step; downstream model metrics (see ML pipeline) reflect its use but authors did not report ablation showing metrics with vs without SMOTE.",
            "ground_truth_performance": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_characterization": "Method is standard/established for class imbalance; usage here is in-distribution augmentation (incremental).",
            "gap_varies_with_novelty": null,
            "gap_variation_details": "",
            "gap_reduction_method": "SMOTE itself is used to reduce proxy-model bias introduced by class imbalance.",
            "gap_reduction_effectiveness": "Not quantitatively reported; only the post-SMOTE class counts (minority increased to 113) are provided; no direct before/after model performance comparison attributed solely to SMOTE.",
            "validation_cost_comparison": "Not discussed.",
            "temporal_validation": "Not applicable.",
            "domain_maturity": "Established and commonly used technique in ML preprocessing for imbalanced datasets.",
            "uncertainty_quantification": false,
            "uncertainty_calibration": "",
            "multiple_proxies": false,
            "proxy_correlation": "",
            "validation_cascade": "Used early in pipeline as data balancing step prior to model training and cross-validation; no further validation of synthetic-data fidelity reported.",
            "publication_bias_discussion": false,
            "limitations_challenges": "Authors do not quantify risks introduced by synthetic samples; potential challenge is that synthetic interpolation may not capture true clinical heterogeneity, and absence of external validation precludes testing whether models trained with SMOTE generalize to real-world unseen patients.",
            "domain_specific_factors": "Clinical feature distributions may be complex and multi-modal; interpolated synthetic records may lie in low-density or unrealistic regions of clinical feature space, especially with small initial minority sample size (n=57), amplifying distributional mismatch risk.",
            "uuid": "e2220.1"
        },
        {
            "name_short": "SHAP analysis",
            "name_full": "SHapley Additive exPlanations (SHAP) feature attribution analysis",
            "brief_description": "A game-theory-based interpretability method that assigns each feature a Shapley value representing its contribution to individual model predictions; used here to rank feature importance in the selected MLP model.",
            "citation_title": "Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP",
            "mention_or_use": "use",
            "system_name": "SHAP (SHapley Additive exPlanations)",
            "system_description": "Computed Shapley values for features in the MLP model to quantify per-feature contribution to model outputs and produce feature-importance rankings and visualizations; the top-10 features were reported.",
            "domain": "Model interpretability / explainable AI in clinical prediction",
            "proxy_metric_name": "SHAP feature importance (Shapley values)",
            "proxy_metric_description": "Shapley value assigned to each feature quantifies its average marginal contribution to model predictions across permutations of features; used to identify and rank influential predictors (reported top features: triglycerides, HDL-C, diabetes duration, age, fasting blood glucose, glycated albumin, hypertension history, LDL-C, postprandial BG, diabetic nephropathy history).",
            "proxy_metric_type": "data-driven interpretability metric",
            "ground_truth_metric": "Classical statistical significance testing of feature differences between NFU and non-NFU groups (P-values), and established clinical knowledge of risk factors",
            "ground_truth_description": "Group-wise comparisons reported in Table 1 using Shapiro-Wilk, t-tests, Wilcoxon, chi-squared, etc.; features with statistically significant differences included diabetes duration (P=0.048), glycated hemoglobin (P=0.012), fasting blood glucose (P=0.002), postprandial blood glucose (P=0.036), triglycerides (P&lt;0.001), and HDL-C (P=0.017).",
            "has_both_proxy_and_ground_truth": true,
            "quantitative_gap_measure": "No formal numeric concordance statistic is reported between SHAP importance scores and statistical significance. Qualitative agreement: SHAP top features (triglycerides, HDL-C, diabetes duration, age, fasting BG) overlap with features having significant p-values (triglycerides P&lt;0.001, HDL-C P=0.017, diabetes duration P=0.048, fasting BG P=0.002). No Shapley value magnitudes or correlation coefficients vs statistical effect sizes are provided.",
            "proxy_performance": "SHAP is a descriptive interpretation tool; the paper reports the ranked top-10 features but not numeric Shapley value aggregates in the main text.",
            "ground_truth_performance": "Statistical test results for group differences: triglycerides median 1.35 vs 1.71 mmol/L (P&lt;0.001); HDL-C 1.29 vs 1.54 mmol/L (P=0.017); diabetes duration medians 13 vs 20 years (P=0.048); fasting BG 6.64 vs 7.69 mmol/L (P=0.002). These are the ground-truth associations used to cross-check model explanations.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_characterization": "In-distribution explanatory analysis — aligns model explanations with known/expected clinical risk factors (incremental confirmation).",
            "gap_varies_with_novelty": null,
            "gap_variation_details": "",
            "gap_reduction_method": "SHAP used to validate that model influential features are clinically plausible and overlap with statistically significant covariates (qualitative calibration of model explanations to ground-truth associations).",
            "gap_reduction_effectiveness": "Qualitative: SHAP top features largely overlap with features that are statistically different between groups (see p-values above), lending face validity; no quantitative calibration (e.g., correlation between SHAP scores and effect sizes) reported.",
            "validation_cost_comparison": "Not discussed.",
            "temporal_validation": "Not applicable.",
            "domain_maturity": "SHAP is an established interpretability method widely used in ML-for-health studies; authors use it as standard practice.",
            "uncertainty_quantification": false,
            "uncertainty_calibration": "",
            "multiple_proxies": false,
            "proxy_correlation": "",
            "validation_cascade": "SHAP applied to the final selected MLP model after cross-validation to interpret feature contributions; used as part of model QA rather than as an independent validation stage.",
            "publication_bias_discussion": false,
            "limitations_challenges": "Authors did not present numeric Shapley value distributions, significance testing of SHAP rankings, or correlation analyses between SHAP values and classical effect sizes; therefore, the strength and calibration of SHAP-derived attributions relative to epidemiological ground truth are not quantitatively assessed.",
            "domain_specific_factors": "Clinical covariates may be correlated and confounded; SHAP attribution assumes model structure and data distribution — retrospective and potentially collinear features may complicate attribution and its concordance with causal/epidemiological ground truth.",
            "uuid": "e2220.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "SMOTE for high-dimensional class-imbalanced data",
            "rating": 2
        },
        {
            "paper_title": "Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP",
            "rating": 2
        },
        {
            "paper_title": "A machine learning model for early detection of diabetic foot using thermogram images",
            "rating": 1
        },
        {
            "paper_title": "Machine learning algorithm to evaluate risk factors of diabetic foot ulcers and its severity",
            "rating": 1
        },
        {
            "paper_title": "Risk prediction of diabetic foot amputation using machine learning and explainable artificial intelligence",
            "rating": 2
        }
    ],
    "cost": 0.015349249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Machine learning-based risk prediction model for neuropathic foot ulcers in patients with diabetic peripheral neuropathy</p>
<p>Ge Shi 0009-0000-7247-254X
School of Clinical Medicine
Capital Medical University
BeijingChina-Japan Friendship, China</p>
<p>Zhenxuan Gao 
Graduate School of Peking Union Medical College
School of Clinical Medicine
Chinese Academy of Medical Sciences and Peking Union Medical College
BeijingChina, 3 China-Japan Friendship</p>
<p>Peking University
BeijingChina</p>
<p>Ze Zhang 
Quanyu Jin 
Graduate School of Peking Union Medical College
School of Clinical Medicine
Chinese Academy of Medical Sciences and Peking Union Medical College
BeijingChina, 3 China-Japan Friendship</p>
<p>Peking University
BeijingChina</p>
<p>Sitong Li 
Institute of Clinical Medical Sciences
Friendship Hospital
BeijingChina-Japan, China</p>
<p>Jiaxin Liu 
Institute of Clinical Medical Sciences
Friendship Hospital
BeijingChina-Japan, China</p>
<p>Lei Kou 
Abudurezhake Aerman 
Wenqiang Yang 
The Department of Neurosurgery
Friendship Hospital
BeijingChina-Japan, China,</p>
<p>Qi Wang 
The Department of Neurosurgery
Friendship Hospital
BeijingChina-Japan, China,</p>
<p>Furong Cai 
Chang Chun Institute of Applied Chemistry Chinese Academy of Sciences
Changchun City, Jilin ProvinceChina</p>
<p>Li Zhang 
The Department of Neurosurgery
Friendship Hospital
BeijingChina-Japan, China,</p>
<p>Machine learning-based risk prediction model for neuropathic foot ulcers in patients with diabetic peripheral neuropathy
5B045F95C7E2A48034CE3F9C1EBE2E8310.1111/jdi.70010Received 7 December 2024; revised 22 January 2025; accepted 4 February 2025Diabetic peripheral neuropathyMachine learningPrediction model
Background: Diabetic peripheral neuropathy (DPN) is a common chronic complication of diabetes, marked by symptoms like hyperalgesia, numbness, and swelling that impair quality of life.Nerve conduction abnormalities in DPN significantly increase the risk of neuropathic foot ulcers (NFU), which can progress rapidly and lead to severe outcomes, including infection, gangrene, and amputation.Early prediction of NFU in DPN patients is crucial for timely intervention.Methods: Clinical data from 400 DPN patients treated at the China-Japan Friendship Hospital (September 2022-2024) were retrospectively analyzed.Data included medical histories, physical exams, biochemical tests, and imaging.After feature selection and data balancing, the dataset was split into training and validation subsets (8:2 ratio).Six machine learning algorithms-random forest, decision tree, logistic regression, K-nearest neighbor, extreme gradient boosting, and multilayer perceptron-were evaluated using k-fold crossvalidation.Model performance was assessed via accuracy, precision, recall, F1 score, and AUC.The SHAP method was employed for interpretability.Results: The multilayer perceptron model showed the best performance (accuracy: 0.875; AUC: 0.901).SHAP analysis highlighted triglycerides, high-density lipoprotein cholesterol, diabetes duration, age, and fasting blood glucose as key predictors.Conclusions: A machine learning-based prediction model using a multilayer perceptron algorithm effectively identifies DPN patients at high NFU risk, offering clinicians an accurate tool for early intervention.</p>
<p>INTRODUCTION</p>
<p>With the continuous improvement in living standards, transportation methods, dietary habits, and lifestyle pressures have undergone significant transformations.According to data from the International Diabetes Federation (IDF) in 2013, the global prevalence of diabetes reached 382 million cases, with projections indicating a rise to 592 million by 2035 1 .Diabetic peripheral neuropathy (DPN), a prevalent complication of diabetes, affects approximately 30% of diabetic patients 2 .Early manifestations of DPN predominantly involve sensory disturbances, including hyperalgesia, numbness, pain, and swelling in the distal extremities 3 .As the condition progresses, patients may experience sensory deficits and motor nerve impairment, leading to a substantial decline in quality of life 4 .Similarly, diabetic foot ulcer (DFU) represents another frequent complication, impacting an estimated 26% of diabetic patients globally over the course of their lifetime 5 .DFU presents significant challenges in clinical management, imposes a substantial economic burden on healthcare systems globally, and profoundly diminishes patients' quality of life 6 .DFU can be classified etiologically into neuropathic, ischemic, and mixed (neuro-ischemic) foot ulcers 7 .Peripheral neuropathy has long been regarded as the primary factor contributing to the development of DFU 8 .Sensory nerve involvement in peripheral neuropathy leads to a loss of protective sensation in the feet, rendering patients unable to detect abnormal pressure 9 .This loss of sensation results in the development of insensitive feet, which, when subjected to repeated mechanical stress, undergo inflammatory and aseptic tissue autolysis, ultimately forming pressure ulcers 10 .These ulcers, commonly located on the plantar forefoot, are termed typical diabetic neuropathic ulcers.Research indicates that approximately half of DFU cases are neuropathic ulcers at the time of initial presentation, while the majority of the remaining cases are mixed ulcers, with purely ischemic ulcers being comparatively rare 11 .These findings underscore that peripheral neuropathy is the central cause of diabetic neuropathic foot ulcers, which represent an advanced stage of peripheral neuropathy.Consequently, preventing DFU necessitates targeted strategies aimed at mitigating the progression of diabetic peripheral neuropathy DPN into neuropathic ulcers.</p>
<p>Machine learning, as a critical branch of artificial intelligence, is transforming the healthcare sector through rapid, efficient, and accurate computations 12 .Currently, machine learning plays a significant role in the prediction of many common diseases.Numerous studies on DFU have demonstrated the exceptional predictive performance of machine learning algorithms.For instance, Khandakar et al. 13 utilized convolutional neural networks to develop a predictive model capable of diagnosing diabetic foot at an early stage of diabetes.In prognostic prediction, Nanda et al. 14 applied machine learning methods to identify risk factors for DFU in diabetic patients and developed related predictive models.Additionally, Chien Wei Oei and collaborators used multiple machine learning algorithms to construct a model predicting the risk of amputation within 180 days of hospital admission in DFU patients 15 .In summary, compared with traditional predictive models, machine learning not only enhances diagnostic and therapeutic efficiency but also optimizes the allocation of healthcare resources, ultimately reducing overall healthcare costs.</p>
<p>METHODS</p>
<p>Study population</p>
<p>This study included 400 patients with DPN who received treatment at the Department of Neurosurgery, China-Japan Friendship Hospital, between September 2022 and September 2024.Participants were categorized into two groups: those with neuropathic foot ulcers (N = 343) and those without neuropathic foot ulcers (N = 57).Neuropathic foot ulcers were defined as ulcers, infections, or tissue destruction in deep tissues below the ankle joint resulting from neuropathy.Comprehensive patient data were collected, encompassing demographic information, blood test results, imaging findings, and physical examination records.These variables were subsequently classified as categorical, continuous, or ordinal (details provided in Table S1).The entire research process, including feature selection, data balancing, model building, model evaluation, and model interpretation, is illustrated in Figure 1.</p>
<p>Data extraction</p>
<p>This study selected patients based on strict inclusion and exclusion criteria.The inclusion criteria required a clinical diagnosis of DPN and included the following: (1) a confirmed history of diabetes or evidence of glucose metabolism abnormalities; (2) neuropathy occurring at or after the diagnosis of diabetes; (3) for patients with typical DPN clinical symptoms (e.g., pain, numbness, or sensory abnormalities), at least one positive result from five tests (ankle reflex, pinprick sensation, vibration sense, pressure sense, and temperature sense) is required; and (4) for patients without typical DPN clinical symptoms, at least two positive results from the five tests are required.The exclusion criteria were (1) neuropathy caused by other etiologies and (2) severe arterial or venous vascular disease.</p>
<p>Feature selection</p>
<p>Initially, we identified 62 features across all patients in the dataset that were statistically available.Subsequently, through a review of previous relevant studies and consultation with medical experts, the number of features was reduced from 62 to 26 7,16 .Only features deemed highly relevant to the diagnosis of DPN were retained.These selected features include (1) general information-gender, age, height, weight, BMI, diabetes duration, alcohol history, smoking history, hypertension history, diabetic nephropathy history, and thyroid disorders history; (2) blood test results: glycated hemoglobin, fasting blood glucose, postprandial blood glucose, glycated albumin, total cholesterol, triglycerides, high-density lipoprotein cholesterol, low-density lipoprotein cholesterol, neutrophil count, lymphocyte count, and the neutrophil-to-lymphocyte ratio; (3) imaging examinations: lower limb arterial ultrasound, venous ultrasound, and nerve ultrasound; (4) physical examination: presence of bilateral lower limb edema.</p>
<p>Data balancing</p>
<p>In machine learning and data mining, class imbalance is a common and significant challenge.When one class has a substantially smaller sample size than others, traditional machine learning algorithms often exhibit a bias toward the majority class, resulting in a reduced ability to accurately identify the minority class.To address this issue, this study employed the Synthetic Minority Oversampling Technique (SMOTE) to mitigate data imbalance.SMOTE is an oversampling method that balances the dataset by generating synthetic samples for the minority class 17 .Unlike simple random oversampling, which duplicates existing minority class samples, SMOTE creates new samples through interpolation.Specifically, for each minority class sample, SMOTE selects one of its K-nearest neighbors and generates a new sample by interpolating along the line connecting the two points.This method not only increases the number of minority class samples but also diversifies their feature distribution, allowing the model to better learn minority class characteristics and enhancing overall classification performance.</p>
<p>Statistical analyses</p>
<p>Statistical analyses were performed using IBM SPSS Statistics for Windows, Version 27.0.The Shapiro-Wilk test was used to assess the normality of quantitative data.For normally distributed variables, comparisons were conducted using the independent samples t-test, with results expressed as meanstandard deviation.For non-normally distributed variables, the Wilcoxon rank-sum test was utilized, with results presented as median and interquartile range.For unordered categorical data, Pearson's chi-squared test was employed, and results were reported as counts with percentages.For ordered categorical data, the rank-sum test was applied, with results also expressed as counts and percentages.A P-value of &lt;0.05 was considered statistically significant.</p>
<p>Model building</p>
<p>The dataset was randomly divided into training and validation sets in an 8:2 ratio.To mitigate overfitting and develop a predictive model with strong generalization capabilities, fivefold cross-validation was employed for model evaluation.Specifically, the dataset was partitioned into five equal subsets, with one subset serving as the test set and the remaining four used for model training during each iteration.This process was repeated five times, with a different subset designated as the test set in each iteration.The performance metrics from all five iterations were averaged to derive the final evaluation results.Six machine learning algorithms were utilized during the modeling process: random forest (RF), decision tree (DT), logistic regression (LR), K-nearest neighbors (K-NN), extreme gradient boosting (XGBoost), and multilayer perceptron (MLP).The algorithm with the best predictive performance was selected for subsequent modeling and validation.</p>
<p>To comprehensively evaluate the model's performance, several metrics were calculated, including accuracy, precision, recall, F1 score, and area under the curve (AUC).The receiver operating characteristic (ROC) curve was also plotted to visually represent the model's discriminative capability.Further validation was performed using a confusion matrix (CM), which provided an intuitive summary of the relationship between predicted and actual values.In the CM, the number in the top-left corner represents the count of true-positives correctly predicted by the model, the top-right corner indicates false negatives, the bottom-left corner shows false-positives, and the bottom-right corner represents true negatives.As a critical evaluation tool in machine learning prediction analysis, the confusion matrix facilitated a detailed assessment of the model's performance.By integrating these evaluation metrics and visual analyses, we ensured the stability and reliability of the model for classification tasks.</p>
<p>Model interpretation</p>
<p>We utilized SHAP (SHapley Additive exPlanations) to interpret the optimal model developed through machine learning methods.SHAP, an interpretability tool grounded in Shapley values from game theory, quantifies the contribution of each feature to the prediction outcome in a clear and measurable manner 18 .Specifically, SHAP calculates the Shapley value for each feature and multiplies it by the feature value to determine its specific impact on the prediction result.A key advantage of SHAP is its ability to generate intuitive visualizations and quantitative explanations, such as feature importance plots and individual prediction contribution graphs.These tools enhance the understanding of the model's decision-making process and the influence of each feature on the predictions.In this study, we conducted model development, evaluation, and interpretation in a standard Python environment (Python 3.6.1),utilizing relevant machine learning libraries and the SHAP package.This approach ensured both the accuracy and interpretability of the results, providing robust insights into the model's predictive performance.</p>
<p>Ethical principle</p>
<p>All relevant examination results for this study were retrieved from the Laboratory Information System and the Electronic Medical Record System, eliminating the need for additional tests or measurements of related indicators.The data were used exclusively for this study and were rigorously protected to ensure patient privacy.This study was approved by the Clinical Research Ethics Committee of China-Japan Friendship Hospital (Approval No.: 2022-KY-200).Given the retrospective nature of the study, along with its non-invasive and anonymous characteristics, the Ethics Committee waived the requirement for patient informed consent.</p>
<p>RESULTS</p>
<p>Patient characteristics</p>
<p>Based on the inclusion and exclusion criteria, a total of 400 participants were included in this study.The participants were categorized into two groups based on their history of neuropathic foot ulcers: 343 DPN patients without neuropathic foot ulcers (85.5%) and 57 DPN patients with neuropathic foot ulcers (14.2%).</p>
<p>The study analyzed 26 features, comprising 16 quantitative and 10 qualitative attributes.A description of the general characteristics of the patients is provided in Table 1.Statistically significant differences were observed in the distribution of the following variables between the two groups: diabetes duration (P = 0.048), glycated hemoglobin (P = 0.012), fasting blood glucose (P = 0.002), postprandial blood glucose (P = 0.036), triglycerides (P &lt; 0.001), and high-density lipoprotein cholesterol (P = 0.017).</p>
<p>Data balancing</p>
<p>To address the issue of data imbalance, we employed the SMOTE technique.After applying SMOTE oversampling, the minority class samples were increased, resulting in a balanced dataset.Table 2 presents the data distribution before and after balancing.</p>
<p>Modeling and evaluation</p>
<p>We employed six machine learning algorithms-random forest, decision tree, logistic regression, K-nearest neighbor, extreme gradient boosting, and multilayer perceptron-to develop predictive models.The evaluation results of these six algorithms, based on fivefold cross-validation, are presented in Table 3.</p>
<p>The results indicate that MLP achieved the highest accuracy (0.8751) and F1 score (0.7681).RF exhibited the highest precision (0.9778), while K-NN demonstrated the highest recall (0.851); however, these models performed less favorably on other metrics.The confusion matrix, used to formally evaluate model performance, showed results consistent with those in Table 3.As shown in Figure 2, the sum of the numbers in the top-left and bottom-right corners of the confusion matrix for the MLP model is the largest among all models, indicating that it correctly classified the most samples, demonstrating its superior predictive performance compared to other models.Furthermore, the AUC values of the different algorithms in predicting DPN are presented in Figure 3. MLP achieved the highest AUC (0.901), followed by random forest (0.886), with decision tree recording the lowest AUC (0.707).Considering all evaluation metrics, MLP demonstrated superior accuracy, stability, and overall performance compared to the other models and was selected as the optimal model for predicting neuropathic foot ulcers.</p>
<p>SHAP analysis was employed to elucidate the relationship between features and predictive outcomes in the MLP model.As shown in Figure 4, the top 10 features influencing predictive outcomes were triglycerides, high-density lipoprotein cholesterol, duration of diabetes, age, fasting blood glucose, glycated albumin, history of hypertension, low-density lipoprotein cholesterol, postprandial blood glucose, and history of diabetic nephropathy.</p>
<p>DISCUSSION</p>
<p>In recent years, traditional linear regression models, such as logistic regression and Cox regression, have been widely utilized in clinical disease prediction and prognostic studies 19,20 .While these methods offer advantages in managing simple relationships and categorical variables, their limitations become increasingly evident when addressing complex pathological mechanisms and multidimensional data 21 .Specifically, their inability to capture nonlinear relationships can compromise predictive accuracy in real-world clinical scenarios.In contrast, with the rapid advancement of artificial intelligence and big data technologies, machine learning methods have emerged as a focal point of medical research 22 .A growing body of evidence demonstrates that machine learning algorithms not only excel in managing high-dimensional and complex datasets but also achieve superior accuracy and broader applicability in the diagnosis and prognostic prediction of diseases such as DFU [13][14][15] .Nevertheless, previous studies have predominantly focused on diabetic patients, with predictive outcomes centered on ulcer severity and the likelihood of amputation.</p>
<p>In comparison, our study specifically targets a distinct subgroup-patients with diabetic peripheral neuropathy-and further refines the predictive objective to identify individuals at high risk of developing neuropathic foot ulcers.This focused approach addresses a critical research gap while simultaneously offering opportunities for early intervention and personalized treatment strategies.By incorporating multiple machine learning algorithms and systematically comparing their performance, this study provides a comprehensive evaluation of the strengths and limitations of various algorithms in managing complex clinical datasets.Such insights contribute to advancing predictive analytics in precision medicine.</p>
<p>The multilayer perceptron is a feedforward artificial neural network and a foundational model in deep learning 23 .It consists of an input layer, one or more hidden layers, and an output layer, with each layer comprising multiple neurons.These neurons enable nonlinear transformations of data by leveraging inter-layer weights and activation functions, allowing MLP to model complex relationships effectively.Compared to traditional machine learning algorithms, MLP offers significant advantages in nonlinear modeling, flexibility, and adaptability 24 .It is particularly adept at managing complex, high-dimensional datasets and excels in feature extraction and pattern recognition.By optimizing its architecture-such as adjusting the number of layers, neurons, and activation functions-or integrating with advanced models like convolutional neural networks (CNNs) and recurrent neural networks (RNNs), MLP demonstrates substantial potential in applications such as medical image analysis, disease diagnosis, and treatment outcome prediction 25 .These capabilities highlight its vital role in advancing precision medicine and intelligent healthcare.</p>
<p>SHAP analysis identified triglycerides, high-density lipoprotein cholesterol, diabetes duration, age, and fasting blood glucose as the most significant contributors to the model's predictive performance.These findings are consistent with clinical observations and previous studies on the risk factors for DFU 19,26 .The substantial influence of these features underscores their critical role in predicting neuropathic foot ulcers, offering a reliable foundation for clinical risk assessments and targeted interventions.</p>
<p>Triglycerides (TG) are a major lipid component in the bloodstream and play a critical role in energy storage and supply 27 .Abnormal TG levels are strongly linked to various metabolic disorders 28 .Elevated TG levels can trigger microvascular complications and inflammatory responses, leading to impaired blood supply to neural tissues and subsequent disruption of the nervous system structure and function 29 .Studies indicate that high TG levels not only accelerate the onset and progression of peripheral neuropathy but also impair local blood circulation, causing tissue hypoxia in the foot and exacerbating the development of DFUs 30 .Furthermore, elevated TG levels are associated with delayed ulcer healing, thereby increasing clinical risks for patients and complicating disease management.High-density lipoprotein cholesterol (HDL-C), carried by high-density lipoproteins (HDL), possesses various protective functions, including anti-inflammatory and antioxidant effects, as well as facilitating reverse cholesterol transport 31 .Studies have shown that low HDL-C levels can indirectly contribute to the development of DFU by exacerbating microvascular complications and neuropathy.In a retrospective study, Chen et al. 32 found that lower HDL-C levels were strongly associated with an increased risk of foot ulcers in diabetic patients.Additionally, reduced HDL-C levels can delay ulcer wound healing, further increasing the clinical burden on patients.</p>
<p>Patients with a longer duration of diabetes face a significantly higher risk of developing DFU, primarily due to two key factors: First, prolonged hyperglycemia leads to sensory neuropathy, impairing the patient's ability to detect foot microtraumas and infections, which delays timely wound care 33 .Second, chronic diabetes is frequently accompanied by more severe vascular complications, including microvascular and macrovascular diseases, further contributing to the development and delayed healing of foot ulcers 34 .A multicenter cross-sectional study revealed that with each additional year of diabetes, the incidence of DFU increases by approximately 5-10% 35 .Additionally, these patients experience significantly prolonged ulcer healing times, complicating treatment and heightening the clinical and economic burden.Age is also a significant risk factor for the development of DFU, with underlying mechanisms partially overlapping those associated with prolonged diabetes duration.Older patients are more likely to experience severe peripheral neuropathy and microvascular complications, which result in diminished protective sensation in the feet and impaired blood circulation 36 .These conditions reduce the ability to detect foot injuries or pressure and increase the risk of tissue hypoxia, thereby facilitating the development of DFU 37 .Additionally, aging significantly impairs tissue repair capacity, leading to prolonged ulcer healing times and complicating treatment efforts.Elevated fasting blood glucose contributes to the development of DFU through multiple pathways.These include chronic hyperglycemia-induced accumulation of advanced glycation end products (AGEs) and activation of the polyol pathway, leading to nerve fiber damage 38,39 .Studies have confirmed that elevated fasting blood glucose is an independent risk factor for the occurrence of DFU in diabetic patients 40 .</p>
<p>In summary, triglycerides, high-density lipoprotein cholesterol, diabetes duration, age, and fasting blood glucose were identified as independent risk factors for DFU in this study.Consequently, clinical practice should leverage the advantages of machine learning in diagnostic processes to emphasize the assessment of lipid profiles, blood glucose levels, diabetes duration, and age in patients with diabetic peripheral neuropathy.This targeted approach will facilitate early diagnosis and intervention, thereby reducing the risk of DFU and improving patient outcomes.</p>
<p>Despite the development of an efficient predictive model, this study has several limitations.First, the relatively small sample size may affect the statistical robustness and generalizability of the model.Second, this study is based on single-center data and lacks an independent external validation dataset, which limits the generalizability of the findings.Third, the study population consisted solely of Chinese patients, necessitating further investigation to assess global generalizability.Finally, as this study is retrospective in nature, certain features previously proven to be associated with the occurrence of diabetic foot ulcers (e.g., eGFR and history of diabetic retinopathy) could not be collected in this study 41,42 .Future research will adopt a multicenter approach, include larger and more diverse sample sizes, and aim to develop a more robust and broadly applicable predictive model.</p>
<p>CONCLUSION</p>
<p>In this study, we applied six machine learning algorithms-random forest, decision tree, logistic regression, k-nearest neighbor, extreme gradient boosting, and multilayer perceptron-to develop predictive models for neuropathic foot ulcers in patients with diabetic peripheral neuropathy.Among these, the Multilayer Perceptron model achieved the highest performance, with an area under the receiver operating characteristic curve of 0.901 and was identified as the optimal model.SHAP analysis indicated that triglycerides, high-density lipoprotein cholesterol, diabetes duration, age, and fasting blood glucose were the most influential features contributing to the model's predictive accuracy.The findings demonstrated that, compared to traditional linear regression models, machine learning approaches offer superior accuracy and reliability in predictive tasks.Additionally, these models enable individualized analysis of patient risk factors, providing novel insights and methodologies for personalized risk assessment.These advantages underscore the significant potential of machine learning in advancing precision medicine.</p>
<p>Figure 1 |
1
Figure 1 | Study design for building a machine learning model to predict neuropathic foot ulcers.</p>
<p>Figure 2 |
2
Figure 2 | Model classification confusion matrix of fivefold cross-validation.</p>
<p>Figure 3 |
3
Figure 3 | ROC curves for different classification models.</p>
<p>Figure 4 |
4
Figure 4 | MLP model interpretation using SHAP.</p>
<p>Table 1 |
1
A description of the general characteristics of the patients
CharacteristicDPN without NFU DPN with NFUP valueAge (years)63.00 (56.00-68.00) 59.00 (55.00-66.00)0.185Height (m)1.70 (1.63-1.75)1.70 (1.65-1.76)0.089Weight (kg)69.00 (62.00-76.00) 69.00 (63.00-81.00)0.393BMI (kg/m 2 )24.22 (22.22-26.35) 24.57 (22.00-26.44)0.769Diabetes duration13.00 (8.00-20.00) 20.00 (8.00-23.50)0.048(year)Glycated6.80 (6.20-8.00)7.20 (6.80-8.25)0.012hemoglobin (%)Fasting blood6.64 (5.63-8.34)7.69 (6.29-9.37)0.002glucose (mmol/L)Postprandial blood10.20 (8.30-12.50) 11.60 (8.30-14.15)0.036glucose (mmol/L)Glycated albumin16.90 (15.50-19.50) 17.40 (15.40-19.65)0.491(%)Total cholesterol4.26 (3.60-5.08)4.56 (3.52-5.54)0.412(mmol/L)Triglycerides1.35 (0.94-1.91)1.71 (1.31-2.49)&lt;0.001(mmol/L)High-density1.29 (1.06-1.67)1.54 (1.13-1.99)0.017lipoproteincholesterol(mmol/L)Low-density2.29 (1.77-3.01)2.21 (1.66-3.19)0.574lipoproteincholesterol(mmol/L)Neutrophil count3.54 (2.84-4.74)3.56 (2.96-4.82)0.909(10 9 /L)Lymphocyte count1.89 (1.50-2.34)1.89 (1.54-2.49)0.798(10 9 /L)Neutrophil-1.93 (1.42-2.54)1.97 (1.55-2.38)0.973to-lymphocyteratioLower limb arterial ultrasound (%)T154 (15.7)3 (5.3)0.173T2226 (65.9)43 (75.4)T363 (18.4)11 (19.3)Lower limb venous ultrasound (%)T1333 (97.1)54 (94.7)0.355T210 (2.9)3 (5.3)Lower limb nerve ultrasound (%)T1153 (44.6)30 (52.6)0.884T2173 (50.4)23 (40.4)T317 (5.0)4 (7.0)Gender (%)Male229 (66.8)42 (73.7)0.301Female114 (33.2)15 (26.3)Thyroid disorders history (%)No337 (98.3)57 (100)0.314Yes6 (1.7)0 (0)Hypertension history (%)No181 (52.8)23 (40.4)0.082Yes162 (47.2)34 (59.6)</p>
<p>Table 1 .
1
(Continued)
CharacteristicDPN without NFU DPN with NFUP valueDiabetic nephropathy historyNo315 (91.8)54 (94.7)0.448Yes28 (8.2)3 (5.3)Alcohol history (%)No275 (80.2)44 (77.2)0.604Yes68 (19.8)13 (22.8)Smoking history (%)No246 (71.7)40 (70.2)0.811Yes97 (28.3)17 (29.8)Presence of bilateral lower limb edema (%)No323 (94.2)56 (98.2)0.201Yes20 (5.8)1 (1.8)Values in bold indicate statistically significant differences between twogroups (P &lt; 0.05).Table 2 | Comparison of positive and negative samples before andafter data balancingDPN with DFUDPN without DFUBefore sampling57343After sampling113343Table 3 | Comparison of classification results of different models(mean)AlgorithmAccuracyPrecisionRecallF1 scoreRF0.85750.97780.43440.6008DT0.74350.52550.39050.4355LR0.74350.45980.25730.3270KNN0.85750.66590.85140.7461GB0.85310.80860.53280.6386MLP0.87510.72500.82450.7681Values in bold indicate the best-performing results for each metricamong all models.
This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes.
J Diabetes Investig Vol. 16 No. 6 June 2025 ª 2025 The Author(s). Journal of Diabetes Investigation published by AASD and John Wiley &amp; Sons Australia, Ltd
O R I G I N A L A R T I C L E http://wileyonlinelibrary.com/journal/jdi ML prediction of NFU risk in DPN patient
ª 2025 The Author(s). Journal of Diabetes Investigation published by AASD and John Wiley &amp; Sons Australia, Ltd J Diabetes Investig Vol. 16 No. 6 June 2025
J Diabetes Investig Vol. 16 No. 6 June 2025 ª 2025 The Author(s). Journal of Diabetes Investigation published by AASD and John Wiley &amp; Sons Australia, Ltd O R I G I N A L A R T I C L E Shi et al. http://wileyonlinelibrary.com/journal/jdi
ACKNOWLEDGMENTSThis work was supported by the Beijing Natural Science Foundation (Grant No. L244029).DISCLOSUREThe authors declare no conflict of interest.Approval of the research protocol: N/A.Informed consent: N/A.Registry and the registration no. of the study/trial: N/A.Animal studies: N/A.SUPPORTING INFORMATIONAdditional supporting information may be found online in the Supporting Information section at the end of the article.TableS1.Explanation of features.
Global and regional diabetes prevalence estimates for 2019 and projections for 2030 and 2045: results from the international diabetes federation diabetes atlas. P Saeedi, I Petersohn, P Salpea, Diabetes Res Clin Pract. 1571078432019</p>
<p>Diabetic peripheral neuropathy: advances in diagnosis and strategies for screening and early intervention. D Selvarajah, D Kar, K Khunti, Lancet Diabetes Endocrinol. 72019</p>
<p>Diabetic neuropathies. K Patel, H Horak, E Tiryaki, Muscle Nerve. 632021</p>
<p>Diabetic neuropathy. E Zakin, R Abrams, D M Simpson, Semin Neurol. 392019</p>
<p>Diabetic foot ulcers and their recurrence. D G Armstrong, A Boulton, S A Bus, N Engl J Med. 3762017</p>
<p>Burden of diabetic foot ulcers for medicare and private insurers. J B Rice, U Desai, A K Cummings, Diabetes Care. 372014</p>
<p>Diabetic foot ulcers: a review. D G Armstrong, T W Tan, A Boulton, JAMA. 3302023</p>
<p>Clinical presentation and management of diabetic neuropathy and foot ulceration. A J Boulton, Diabet Med. 81991</p>
<p>Research development in the pathogenesis of neuropathic diabetic foot ulceration. A Piaggesi, Curr Diab Rep. 42004</p>
<p>Relationship of foot deformity to ulcer location in patients with diabetes mellitus. M J Mueller, S D Minor, J E Diamond, Phys Ther. 701990</p>
<p>Causal pathways for incident lower-extremity ulcers in patients with diabetes from two settings. G E Reiber, L Vileikyte, E J Boyko, Diabetes Care. 221999</p>
<p>Machine learning in medicine. R C Deo, Circulation. 1322015</p>
<p>A machine learning model for early detection of diabetic foot using thermogram images. A Khandakar, M Chowdhury, Ibne Reaz, M B , Comput Biol Med. 1371048382021</p>
<p>Machine learning algorithm to evaluate risk factors of diabetic foot ulcers and its severity. R Nanda, A Nath, S Patel, Med Biol Eng Comput. 602022</p>
<p>Risk prediction of diabetic foot amputation using machine learning and explainable artificial intelligence. C W Oei, Y M Chan, X Zhang, 10.1177/19322968241228606J Diabetes Sci Technol. 202419322968241228606</p>
<p>Risk factors for diabetic neuropathy and foot ulceration. A Adler, Curr Diab Rep. 12001</p>
<p>SMOTE for high-dimensional class-imbalanced data. R Blagus, L Lusa, BMC Bioinformatics. 141062013</p>
<p>Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP. K Wang, J Tian, C Zheng, Comput Biol Med. 1371048132021</p>
<p>Development and validation of a risk prediction model for foot ulcers in diabetic patients. J Lv, R Li, L Yuan, J Diabetes Res. 202311998852023</p>
<p>Study on risk factors of peripheral neuropathy in type 2 diabetes mellitus and establishment of prediction model. B Wu, Z Niu, F Hu, Diabetes Metab J. 452021</p>
<p>Healthcare analytics-a literature review and proposed research agenda. R Elragal, A Elragal, A Habibipour, Front Big Data. 612779762023</p>
<p>Ascent of machine learning in medicine. Nat Mater. 184072019</p>
<p>Extreme learning machine for multilayer perceptron. J Tang, C Deng, G B Huang, IEEE Trans Neural Netw Learn Syst. 272016</p>
<p>Cl erot F. A methodology to explain neural network classification. R Eraud, Neural Netw. 152002</p>
<p>Human chromosome classification using multilayer perceptron neural network. B Lerner, H Guterman, I Dinstein, Int J Neural Syst. 61995</p>
<p>Predicting the risk of diabetic foot ulcers from diabetics with dysmetabolism: a retrospective clinical trial. M Jiang, F Gan, M Gan, Front Endocrinol (Lausanne). 13929864</p>
<p>Triglycerides and cardiovascular disease. B G Nordestgaard, A Varbo, Lancet. 3842014</p>
<p>Discordance among apoB, non-high-density lipoprotein cholesterol, and triglycerides: implications for cardiovascular prevention. A D Sniderman, L Dufresne, K M Pencina, Eur Heart J. 452024</p>
<p>Lipopolysaccharide binding protein resists hepatic oxidative stress by regulating lipid droplet homeostasis. Q Zhang, X Shen, X Yuan, Nat Commun. 1532132024</p>
<p>The international consensus and practical guidelines on the management and prevention of the diabetic foot. N C Schaper, J Apelqvist, K Bakker, Curr Diab Rep. 32003</p>
<p>Etiology, epidemiology, and disparities in the burden of diabetic foot ulcers. K Mcdermott, M Fang, A Boulton, Diabetes Care. 462023</p>
<p>Association of high-density lipoprotein cholesterol and wound healing in patients with diabetic foot ulcers. L Chen, W Ma, D Chen, Chin Med J. 1352022</p>
<p>Influencing factors for the recurrence of diabetic foot ulcers: a meta-analysis. Q Guo, G Ying, O Jing, Int Wound J. 202023</p>
<p>Clinical and behavioral factors associated with management outcome in hospitalized patients with diabetic foot ulcer. Z Yekta, R Pourali, R Nezhadrahim, Diabetes Metab Syndr Obes. 42011</p>
<p>The global burden of diabetic foot disease. A J Boulton, L Vileikyte, G Ragnarson-Tennvall, Lancet. 3662005</p>
<p>Aging, metabolism, and Alzheimer disease: review and hypotheses. C E Finch, D M Cohen, Exp Neurol. 1431997</p>
<p>Peripheral neuropathies and aging. M Brisset, G Nicolas, Geriatr Psychol Neuropsychiatr Vieil. 162018</p>
<p>Glycemic control and diabetic foot ulcer outcomes: a systematic review and meta-analysis of observational studies. K L Lane, M S Abusamaan, B F Voss, J Diabetes Complicat. 341076382020</p>
<p>Early and intensive glycemic control for diabetic foot ulcer healing: a prospective observational nested cohort study. A Dutta, A Bhansali, A Rastogi, Int J Low Extrem Wounds. 222023</p>
<p>Phenotypes and outcomes in middle-aged patients with diabetic foot ulcers: a retrospective cohort study. T Tong, C Yang, W Tian, J Foot Ankle Res. 13242020</p>
<p>Renal function as risk factor for diabetic foot ulcers: a meta-analysis. L Jin, W Xu, Int Wound J. 21e144092024</p>
<p>Diabetic retinopathy relates to the incidence of foot ulcers and amputations in type 2 diabetes. G Borderie, N Foussard, A Larroumet, Diabetes Metab Res Rev. 39e36052023</p>            </div>
        </div>

    </div>
</body>
</html>