<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4420 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4420</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4420</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-100.html">extraction-schema-100</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-281277229</p>
                <p><strong>Paper Title:</strong> The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models</p>
                <p><strong>Paper Abstract:</strong> The rapid growth of scientific literature demands advanced methodologies to analyze and synthesize research trends efficiently. This paper explores the integration of complex network analysis and large language models (LLMs) to automate the generation of literature analyses, focusing on the field of wearable sensors for health monitoring. Using OpenAlex as a source of scientific papers in this field, paper citation networks were constructed and partitioned into thematic clusters, revealing key subtopics such as flexible graphene-based sensors, gait analysis, and machine learning applications. These clusters, characterized by their term importance and interconnectivity, served as input for LLMs (ChatGPT) to generate structured outlines and descriptive summaries. While LLMs produced coherent overviews, limitations emerged, including superficial analyses and inaccuracies in referenced literature. The study demonstrates the potential of combining network-based methodologies with LLMs to create scalable literature reviews, albeit with limitations to be addressed concerning depth and accuracy. The analyses highlight wearable sensors’ transformative role in healthcare, driven by advancements in materials science, artificial intelligence, and device integration, while also identifying critical gaps such as standardization, biocompatibility, and energy efficiency. This hybrid approach offers a promising framework for accelerating scholarly synthesis, though today human oversight remains essential to ensure rigor and relevance.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4420.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4420.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Network-LLM pipeline (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid pipeline combining citation-network community detection (method from ref 13) with Large Language Models and interactive visualization (Helios-web) for semi-automated literature review generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proof-of-concept pipeline that builds a citation network from OpenAlex, extracts cluster-defining keywords (KeyBERT + network-derived importance indices), and feeds cluster tokens and metadata to multiple LLMs (ChatGPT variants, Google Gemini) via structured, segmental prompting to produce outlines, cluster descriptions and draft review articles, with visualization and exploration provided by Helios-web.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Network-LLM pipeline (Klarák et al., this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The pipeline first retrieves papers from OpenAlex using targeted queries, constructs a citation network (nodes = papers, undirected edges for citations), applies the Louvain community detection algorithm (method of ref 13) to partition the network into thematic clusters, extracts and ranks cluster keywords using KeyBERT and a network-derived importance index I(w), and then supplies cluster tokens, sizes, and importance values (via .xnet file or structured prompts) to LLMs. Text generation is performed segmentally (one topic/cluster at a time) across multiple LLMs to produce outlines, per-cluster descriptive texts, and draft review manuscripts; outputs are integrated with an interactive visualization front-end (Helios-web) for inspection and human curation. The pipeline includes a step of reference validation using OpenAI's Scholar GPT and human expert oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Multiple ChatGPT variants (ChatGPT-o1, ChatGPT-o3-mini-high, ChatGPT-4o, ChatGPT-4o-mini-high) and Google Gemini; OpenAI's Scholar GPT used for reference validation</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Network-driven keyword extraction plus BERT-based keyword extraction (KeyBERT) on abstracts, calculation of per-cluster importance indices I(w) using intra-/extra-cluster relative frequencies, and selection of representative cluster tokens provided to LLMs via structured input files (.xnet) and prompts; segmentation of generation to respect model context limits.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Cluster-conditioned, segmental hierarchical summarization: LLMs produce cluster-specific descriptions and sectioned outlines which are then combined into a multi-section review draft; keyword clustering (agglomerative hierarchical clustering over topological distances) provides a scaffold for hierarchical organization of the synthesized review.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Input retrieval returned ≈60,000 papers (broad OpenAlex query); the citation network (giant component) used in experiments contained 36,021 nodes and 257,646 citation links.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Wearable sensors for health monitoring (materials and device engineering focus in this study); generalizable to other scientific topics.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured outlines, per-cluster descriptive summaries (~two-page cluster texts), a 1,000-word integrated summary, and draft review manuscripts (including figures generated by LLMs and lists of references).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative human expert assessment, reference validation via OpenAI Scholar GPT, checks of top-100 cited references; no automatic n-gram overlap metrics (e.g., ROUGE) or formal benchmark scores reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Qualitative: LLM outputs were coherent and thematically relevant and produced a broad overview spanning ~30 pages of cluster descriptions; notable shortcomings included superficial technical depth and instances of incorrect or fabricated references (hallucinations). No quantitative accuracy/ROUGE/factuality numbers were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared informally to human expert-driven reviews and conventional keyword-based outlines; multiple LLMs were used to reduce model-specific bias, but no formal baseline model or human baseline with quantitative scores was evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Informal/qualitative assessment: LLM-generated texts are useful starting points (good outlines and broad overviews) but are more superficial and less reliable (hallucinations, missing depth, fewer validated figures) than human-authored high-quality reviews; human oversight required to reach publication standards.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining citation-network community detection with LLMs enables scalable, cluster-focused literature synthesis across tens of thousands of papers; network-derived cluster tokens and importance indices provide an effective, structured scaffold for prompting LLMs; segmental generation helps to work around context-window constraints; however, LLM outputs tend to be shallow and can fabricate references, so validation and human curation remain necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Hallucination of references and factual errors, superficial analyses lacking deep methodological/quantitative detail, context-window limits necessitating segmented prompts, reliance on title/abstract (not full text) reduces depth, nondeterministic outputs across LLM runs/versions, LLM training cutoff bias toward older sources, and lack of validated figures from primary literature.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Pipeline processed a citation network of 36k papers and retrieved ~60k candidates; authors note network methods scale to tens of thousands of records and that LLM synthesis is constrained by context-window size and thus performed segmentally; authors recommend structured metadata and reference-validation tooling to improve scaling and accuracy but provide no quantitative scaling curves.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4420.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Helios-web</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Helios-web interactive platform for citation-network visualization and LLM-assisted literature exploration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A web-based visualization and exploration tool that displays citation networks and exposes cluster metadata (cluster tokens, sizes, importance values) to support interactive inspection and to feed data to LLM-driven summarization workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Helios-web (visualization + LLM integration)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Helios-web visualizes large citation networks (3D and separated-cluster views shown), highlights clusters and representative terms, allows uploading of .xnet files derived from the network method, and serves as the user-facing component of the pipeline enabling users to inspect clusters and trigger/consume LLM-generated outlines and summaries. The paper describes Helios-web as the interface that complements LLM-based text processing for exploration and semi-automated review generation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Used in conjunction with ChatGPT variants and Google Gemini (models run externally, Helios-web acts as visualization/integration layer); specific Helios-web internal LLMs not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Displays and exposes network-derived artifacts: community lists, representative keywords and importance indices, lists of node articles and centrality measures, and inter-community distances for LLM consumption.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Acts as a conduit: passes cluster metadata and prompts to external LLM endpoints to generate structured summaries which are then displayed/linked next to visual clusters; supports segmental generation workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Demonstrated visualization of a citation network of 36,021 articles in this study; designed to handle networks at least at this scale.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General-purpose bibliometric visualization; applied here to wearable sensors for health monitoring.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Interactive network visualizations, cluster-level summaries/outlines (LLM-generated), links to draft review sections.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Qualitative: provided useful exploratory views and facilitated human inspection of LLM outputs; no quantitative usability or throughput metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not compared formally to other visualization platforms in paper (VOSviewer, Gephi are discussed as context).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not evaluated quantitatively versus baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Integration of visualization and LLM outputs helps users focus LLM generation on meaningful clusters and supports interpretability of large-corpus summaries; coupling network metadata with LLM prompts improves topical focus of generated texts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Visualization alone cannot prevent LLM hallucinations; Helios-web relies on external LLMs and curated metadata for quality; no built-in automated reference validation beyond external Scholar GPT checks.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Shown to handle the 36k-node network; paper notes typical bibliometric tools usually operate on thousands of records and that Helios-web supports exploration at larger scales, but no quantitative performance vs. network size curves are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4420.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-based generation (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of ChatGPT family models to generate outlines, cluster descriptions, and draft review texts from network-derived inputs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ChatGPT variants were prompted with cluster sizes, representative keywords and importance values (from .xnet input) to produce structured outlines, ~two-page cluster descriptions, a 1,000-word summary, and a draft review paper for a selected cluster; outputs were qualitatively useful but often shallow and occasionally fabricated references.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChatGPT-guided literature synthesis (applied usage)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The authors uploaded .xnet network data and provided ChatGPT with cluster metadata (100 keyterms per cluster with importance values, cluster sizes, and desired textual structure) and prompted it to produce hierarchical outlines, cluster-specific descriptions, and draft review text. Generation was performed segmentally (one cluster/section at a time) across multiple ChatGPT model variants (o1, o3-mini-high, 4o, 4o-mini-high) to obtain different perspectives and reduce single-model bias.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>ChatGPT-o1, ChatGPT-o3-mini-high, ChatGPT-4o, ChatGPT-4o-mini-high (via OpenAI API).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Structured prompting using network-extracted cluster tokens and importance indices (i.e., supplying ranked keywords and cluster metadata as the extraction substrate), not direct full-text ingestion by the LLMs in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Segmental hierarchical summarization: produce cluster-level texts which are then combined into an overall survey structure; prompts requested outlines, subsections, and key references.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Cluster-level inputs reflected networks whose giant component had 36,021 papers; ChatGPT consumed cluster tokens derived from those papers rather than all full texts.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Wearable sensors for health monitoring (cluster-focused synthesis); generalizable to other literature topics.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Outlines, cluster descriptions (~two pages each), integrated 1,000-word summary, draft review manuscript for Cluster A (including LLM-generated figures and references).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Human expert review (qualitative), manual verification of top-100 cited references using Scholar GPT; no formal automated metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Produced coherent overviews and useful outlines; produced ~30 pages of cluster descriptions and a 1,000-word integrated summary; suffered from superficial technical depth and fabricated/incorrect references in some outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Human-written reviews and manual literature synthesis (qualitative comparison); multiple LLM variants used for comparison of outputs, but no quantitative baseline comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Inferior in depth and reference accuracy to human experts; useful as a scaffold but requires substantial human curation to reach publication quality.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Providing structured, network-derived keywords and importance values guides ChatGPT to produce coherent cluster-focused outputs; segmental prompting mitigates context limit constraints; cross-checking outputs across multiple LLMs reveals model-specific variation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Hallucinated/incorrect references, superficial analyses lacking specific literature details, and model nondeterminism; limitation from using only title/abstract-derived keywords rather than full-text content.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>LLM generation was applied to clusters derived from a 36k-node network by splitting tasks per cluster; authors note that full-text scaling would require more advanced ingestion and chunking strategies and reference-validation tooling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4420.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Google Gemini (usage)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google Gemini used as an alternative LLM for literature synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google Gemini was one of multiple LLMs employed to obtain alternative analyses of the same cluster metadata, with the intent of reducing single-model bias and comparing outputs across model families.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Google Gemini (applied usage)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Gemini received the same or similar structured inputs (cluster tokens, sizes, importance values) as other LLMs to produce outlines and descriptive texts; authors used multiple LLMs to obtain slightly different analyses due to different training methods and algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Google Gemini (specific size/version not specified).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Structured prompting with network-extracted cluster tokens and importance indices; segmental generation.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Cluster-conditioned summarization analogous to ChatGPT usage (hierarchical/segmental summarization).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Applied to cluster metadata derived from a 36,021-paper citation network; Gemini did not ingest all full texts directly.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Wearable sensors for health monitoring (this study).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Alternative outlines and cluster summaries to complement ChatGPT outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>No quantitative metrics reported; qualitative comparison across model outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Delivered alternative perspectives but subject to the same limitations noted for other LLMs (superficiality, occasional inaccuracies); no quantitative performance numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively to ChatGPT outputs and to human curation; no formal benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>No quantitative comparison; authors used multiple LLMs to mitigate single-model idiosyncrasies.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using multiple LLMs yields varied phrasings and occasionally different emphases, which can be useful for ensemble-style human selection; model-specific differences exist but were not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Same as other LLM usage: hallucinations, superficiality, context-window limitations; no specific Gemini-centric results reported.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>No Gemini-specific scaling data provided; operated on cluster-level inputs derived from tens of thousands of papers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4420.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI Scholar GPT (reference validation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI Scholar GPT used for automated verification of cited references</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialized OpenAI tool employed by the authors to verify the existence and correctness of the top-100 cited references produced or listed in the Supporting Information, as a mitigation step against LLM hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>OpenAI Scholar GPT (reference-checking step)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>After initial LLM generation produced some incorrect or nonexistent references, the authors used OpenAI's Scholar GPT to check and validate the 100 top-cited references included in the Supporting Information, as an automated validation assist prior to human curation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>OpenAI Scholar GPT (specific internal model/version not detailed).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Reference validation via querying Scholar GPT about the existence/metadata of cited works; cross-checking against OpenAlex entries (implicitly).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Not a synthesis system per se; used to validate bibliographic entries and flag likely hallucinations for correction.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Applied to the top-100 cited references from the LLM-generated outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Bibliographic validation for literature-review outputs (applied on wearable-sensors corpus).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Validated list of references or flags indicating missing/incorrect references.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified; used as an assistive verification step alongside human checks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Helped identify hallucinations among LLM-produced references; no quantitative precision/recall metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not compared to other automated bibliographic validators in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not evaluated quantitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Automated LLM-based reference validation is a practical mitigation against hallucinated citations but should be complemented with human verification and database checks (e.g., OpenAlex).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Scholar GPT itself is subject to model limitations and may not be a definitive arbiter; cross-checking against curated databases still required.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Applied at least to 100 references; scalability to thousands of references not evaluated in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4420.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VOSviewer (with NLP features)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VOSviewer bibliometric mapping tool with integrated NLP/LLM features (as discussed)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>VOSviewer is a widely used bibliometric mapping tool mentioned in the paper as having many NLP features and being commonly employed for large-scale literature analyses; the paper notes VOSviewer likely has LLM/NLP integrations in current practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>VOSviewer with NLP/LLM features (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The authors reference VOSviewer as a standard bibliometric visualization tool that offers NLP features for mapping keywords, co-occurrence, and themes; they note that many features based on LLMs and NLP are available in such bibliometric tools (particularly VOSviewer), although they do not detail a specific LLM-driven workflow performed inside VOSviewer in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Not specified in this paper (VOSviewer integrations vary by user/setup).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Bibliometric and NLP-based keyword extraction and co-occurrence mapping (tool-dependent); specifics not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Visualization-driven summarization and mapping (no detailed synthesis pipeline described in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Literature examples cited using VOSviewer ranged from thousands to tens of thousands of records in other studies discussed (e.g., 4,803; 7,416; 4,487 records cited).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Bibliometrics and literature mapping across domains; examples in the paper include NLP, hydrology, agricultural drought, and social network analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Bibliometric maps, keyword co-occurrence networks, cluster maps used to support exploratory analyses and sometimes feed into summarization workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Not evaluated quantitatively here; VOSviewer cited as commonly used and helpful for exploratory analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned alongside other visualization tools (Gephi, Helios-web) but not directly compared quantitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Bibliometric visualization tools are complementary to LLM-based summarization, and some (e.g., VOSviewer) already incorporate NLP features that can be combined with LLM workflows for large-scale literature analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Standalone visualization/NLP features do not eliminate LLM-specific problems (hallucinations, shallow analysis) and often operate primarily on metadata/abstracts rather than full text.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Typical studies using VOSviewer process thousands (often up to several thousand) records; analyses of 100k+ papers are rare according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4420.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-assisted systematic review (ref 7, cited)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited study that processed 3,785 studies from multiple bibliographic sources and selected 172 for in-depth analysis to characterize which review stages are automated by LLMs, proposed LLM types, metrics for evaluation, and related factors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-assisted systematic review (Scherbakov et al., ref 7)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited in this paper as a prior study that applied LLMs to systematic-review tasks: it processed a large corpus (3,785 records) from PubMed, Scopus, Dimensions and Google Scholar and selected a subset (172) for deeper analysis of automated stages, LLM types suggested, metrics used to evaluate LLMs in review tasks, and related considerations. The current paper references that study to situate LLM usage in literature reviews.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Not specified in Klarák et al.; the cited work analyzed a range of LLMs proposed for automation but specific model names/sizes are in the original ref.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Not detailed in Klarák et al.; the cited study characterizes extraction/automation strategies across reviewed works (see original paper).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Not detailed here; original work surveyed how LLMs are used across stages of the review pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>3,785 articles processed overall; 172 selected for in-depth analysis (as reported in Klarák et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Meta-research on use of LLMs in literature review workflows across biomedical and other domains (original paper published in J. Am. Med. Inf. Assoc. according to refs).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Systematic-review analysis and taxonomy of LLM use in review automation (original paper).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Klarák et al. report that the cited study documents what metrics are used in the literature (ROUGE, human ratings, etc.), but specific metrics used by that study are to be found in the original reference.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Not reported in Klarák et al.; see original paper for specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not reported in Klarák et al.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Klarák et al. cite this study as evidence that LLMs are increasingly explored for automating stages of literature reviews and that systematic characterization of LLM roles and evaluation metrics has been performed by others.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Klarák et al. use this citation to support general observations about limitations (superficiality, hallucinations) but specifics are in the cited study.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>The cited work processed thousands of records (3,785) and performed deeper analysis on a subset (172); exact scaling conclusions are in the original reference.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4420.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4420.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Network+LLM wound-healing study (Klarák et al. ref)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closely related (cited) study that applied network analysis together with LLMs to generate a literature landscape for dressing materials in wound healing, cited here as an example of combining network methods with LLMs in domain-specific literature synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Network + LLM landscape generation (dressing materials review)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as another example where citation-network methods were combined with LLM-generated summaries to produce a domain landscape; specifics (models, extraction/synthesis details, number of papers analyzed) are in the cited publication (Int. J. Biol. Macromol. 2025).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>Not specified in Klarák et al.; likely LLMs were used but exact models appear in the cited paper.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Network-driven community detection feeding LLM summarization (as described generally in Klarák et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Cluster-conditioned summarization via LLMs (specific synthesis workflow to be found in cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Not specified in Klarák et al.; see original cited article for quantities.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Dressing materials for wound healing (biomaterials literature).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Landscape-style literature review combining network clusters with LLM-generated descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not reported in this paper; consult the cited article.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Referenced as corroborating evidence that network + LLM combinations have been applied successfully in domain-specific literature mapping, reinforcing the approach used in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Not detailed here; readers are referred to the original cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Not described in Klarák et al.; see the cited wound-healing review for specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review <em>(Rating: 2)</em></li>
                <li>Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review <em>(Rating: 2)</em></li>
                <li>Using network science and text analytics to produce surveys in a scientific topic <em>(Rating: 2)</em></li>
                <li>Network Analysis and Natural Language Processing to Obtain a Landscape of the Scientific Literature on Materials Applications <em>(Rating: 2)</em></li>
                <li>AI-Assisted Tools for Scientific Review Writing: Opportunities and Cautions <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4420",
    "paper_id": "paper-281277229",
    "extraction_schema_id": "extraction-schema-100",
    "extracted_data": [
        {
            "name_short": "Network-LLM pipeline (this work)",
            "name_full": "Hybrid pipeline combining citation-network community detection (method from ref 13) with Large Language Models and interactive visualization (Helios-web) for semi-automated literature review generation",
            "brief_description": "A proof-of-concept pipeline that builds a citation network from OpenAlex, extracts cluster-defining keywords (KeyBERT + network-derived importance indices), and feeds cluster tokens and metadata to multiple LLMs (ChatGPT variants, Google Gemini) via structured, segmental prompting to produce outlines, cluster descriptions and draft review articles, with visualization and exploration provided by Helios-web.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Network-LLM pipeline (Klarák et al., this paper)",
            "system_description": "The pipeline first retrieves papers from OpenAlex using targeted queries, constructs a citation network (nodes = papers, undirected edges for citations), applies the Louvain community detection algorithm (method of ref 13) to partition the network into thematic clusters, extracts and ranks cluster keywords using KeyBERT and a network-derived importance index I(w), and then supplies cluster tokens, sizes, and importance values (via .xnet file or structured prompts) to LLMs. Text generation is performed segmentally (one topic/cluster at a time) across multiple LLMs to produce outlines, per-cluster descriptive texts, and draft review manuscripts; outputs are integrated with an interactive visualization front-end (Helios-web) for inspection and human curation. The pipeline includes a step of reference validation using OpenAI's Scholar GPT and human expert oversight.",
            "llm_model_used": "Multiple ChatGPT variants (ChatGPT-o1, ChatGPT-o3-mini-high, ChatGPT-4o, ChatGPT-4o-mini-high) and Google Gemini; OpenAI's Scholar GPT used for reference validation",
            "extraction_technique": "Network-driven keyword extraction plus BERT-based keyword extraction (KeyBERT) on abstracts, calculation of per-cluster importance indices I(w) using intra-/extra-cluster relative frequencies, and selection of representative cluster tokens provided to LLMs via structured input files (.xnet) and prompts; segmentation of generation to respect model context limits.",
            "synthesis_technique": "Cluster-conditioned, segmental hierarchical summarization: LLMs produce cluster-specific descriptions and sectioned outlines which are then combined into a multi-section review draft; keyword clustering (agglomerative hierarchical clustering over topological distances) provides a scaffold for hierarchical organization of the synthesized review.",
            "number_of_papers": "Input retrieval returned ≈60,000 papers (broad OpenAlex query); the citation network (giant component) used in experiments contained 36,021 nodes and 257,646 citation links.",
            "domain_or_topic": "Wearable sensors for health monitoring (materials and device engineering focus in this study); generalizable to other scientific topics.",
            "output_type": "Structured outlines, per-cluster descriptive summaries (~two-page cluster texts), a 1,000-word integrated summary, and draft review manuscripts (including figures generated by LLMs and lists of references).",
            "evaluation_metrics": "Qualitative human expert assessment, reference validation via OpenAI Scholar GPT, checks of top-100 cited references; no automatic n-gram overlap metrics (e.g., ROUGE) or formal benchmark scores reported.",
            "performance_results": "Qualitative: LLM outputs were coherent and thematically relevant and produced a broad overview spanning ~30 pages of cluster descriptions; notable shortcomings included superficial technical depth and instances of incorrect or fabricated references (hallucinations). No quantitative accuracy/ROUGE/factuality numbers were reported.",
            "comparison_baseline": "Compared informally to human expert-driven reviews and conventional keyword-based outlines; multiple LLMs were used to reduce model-specific bias, but no formal baseline model or human baseline with quantitative scores was evaluated.",
            "performance_vs_baseline": "Informal/qualitative assessment: LLM-generated texts are useful starting points (good outlines and broad overviews) but are more superficial and less reliable (hallucinations, missing depth, fewer validated figures) than human-authored high-quality reviews; human oversight required to reach publication standards.",
            "key_findings": "Combining citation-network community detection with LLMs enables scalable, cluster-focused literature synthesis across tens of thousands of papers; network-derived cluster tokens and importance indices provide an effective, structured scaffold for prompting LLMs; segmental generation helps to work around context-window constraints; however, LLM outputs tend to be shallow and can fabricate references, so validation and human curation remain necessary.",
            "limitations_challenges": "Hallucination of references and factual errors, superficial analyses lacking deep methodological/quantitative detail, context-window limits necessitating segmented prompts, reliance on title/abstract (not full text) reduces depth, nondeterministic outputs across LLM runs/versions, LLM training cutoff bias toward older sources, and lack of validated figures from primary literature.",
            "scaling_behavior": "Pipeline processed a citation network of 36k papers and retrieved ~60k candidates; authors note network methods scale to tens of thousands of records and that LLM synthesis is constrained by context-window size and thus performed segmentally; authors recommend structured metadata and reference-validation tooling to improve scaling and accuracy but provide no quantitative scaling curves.",
            "uuid": "e4420.0",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "Helios-web",
            "name_full": "Helios-web interactive platform for citation-network visualization and LLM-assisted literature exploration",
            "brief_description": "A web-based visualization and exploration tool that displays citation networks and exposes cluster metadata (cluster tokens, sizes, importance values) to support interactive inspection and to feed data to LLM-driven summarization workflows.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Helios-web (visualization + LLM integration)",
            "system_description": "Helios-web visualizes large citation networks (3D and separated-cluster views shown), highlights clusters and representative terms, allows uploading of .xnet files derived from the network method, and serves as the user-facing component of the pipeline enabling users to inspect clusters and trigger/consume LLM-generated outlines and summaries. The paper describes Helios-web as the interface that complements LLM-based text processing for exploration and semi-automated review generation.",
            "llm_model_used": "Used in conjunction with ChatGPT variants and Google Gemini (models run externally, Helios-web acts as visualization/integration layer); specific Helios-web internal LLMs not specified.",
            "extraction_technique": "Displays and exposes network-derived artifacts: community lists, representative keywords and importance indices, lists of node articles and centrality measures, and inter-community distances for LLM consumption.",
            "synthesis_technique": "Acts as a conduit: passes cluster metadata and prompts to external LLM endpoints to generate structured summaries which are then displayed/linked next to visual clusters; supports segmental generation workflows.",
            "number_of_papers": "Demonstrated visualization of a citation network of 36,021 articles in this study; designed to handle networks at least at this scale.",
            "domain_or_topic": "General-purpose bibliometric visualization; applied here to wearable sensors for health monitoring.",
            "output_type": "Interactive network visualizations, cluster-level summaries/outlines (LLM-generated), links to draft review sections.",
            "evaluation_metrics": "Not specified in the paper.",
            "performance_results": "Qualitative: provided useful exploratory views and facilitated human inspection of LLM outputs; no quantitative usability or throughput metrics reported.",
            "comparison_baseline": "Not compared formally to other visualization platforms in paper (VOSviewer, Gephi are discussed as context).",
            "performance_vs_baseline": "Not evaluated quantitatively versus baselines.",
            "key_findings": "Integration of visualization and LLM outputs helps users focus LLM generation on meaningful clusters and supports interpretability of large-corpus summaries; coupling network metadata with LLM prompts improves topical focus of generated texts.",
            "limitations_challenges": "Visualization alone cannot prevent LLM hallucinations; Helios-web relies on external LLMs and curated metadata for quality; no built-in automated reference validation beyond external Scholar GPT checks.",
            "scaling_behavior": "Shown to handle the 36k-node network; paper notes typical bibliometric tools usually operate on thousands of records and that Helios-web supports exploration at larger scales, but no quantitative performance vs. network size curves are provided.",
            "uuid": "e4420.1",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "ChatGPT-based generation (this work)",
            "name_full": "Use of ChatGPT family models to generate outlines, cluster descriptions, and draft review texts from network-derived inputs",
            "brief_description": "ChatGPT variants were prompted with cluster sizes, representative keywords and importance values (from .xnet input) to produce structured outlines, ~two-page cluster descriptions, a 1,000-word summary, and a draft review paper for a selected cluster; outputs were qualitatively useful but often shallow and occasionally fabricated references.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "ChatGPT-guided literature synthesis (applied usage)",
            "system_description": "The authors uploaded .xnet network data and provided ChatGPT with cluster metadata (100 keyterms per cluster with importance values, cluster sizes, and desired textual structure) and prompted it to produce hierarchical outlines, cluster-specific descriptions, and draft review text. Generation was performed segmentally (one cluster/section at a time) across multiple ChatGPT model variants (o1, o3-mini-high, 4o, 4o-mini-high) to obtain different perspectives and reduce single-model bias.",
            "llm_model_used": "ChatGPT-o1, ChatGPT-o3-mini-high, ChatGPT-4o, ChatGPT-4o-mini-high (via OpenAI API).",
            "extraction_technique": "Structured prompting using network-extracted cluster tokens and importance indices (i.e., supplying ranked keywords and cluster metadata as the extraction substrate), not direct full-text ingestion by the LLMs in this work.",
            "synthesis_technique": "Segmental hierarchical summarization: produce cluster-level texts which are then combined into an overall survey structure; prompts requested outlines, subsections, and key references.",
            "number_of_papers": "Cluster-level inputs reflected networks whose giant component had 36,021 papers; ChatGPT consumed cluster tokens derived from those papers rather than all full texts.",
            "domain_or_topic": "Wearable sensors for health monitoring (cluster-focused synthesis); generalizable to other literature topics.",
            "output_type": "Outlines, cluster descriptions (~two pages each), integrated 1,000-word summary, draft review manuscript for Cluster A (including LLM-generated figures and references).",
            "evaluation_metrics": "Human expert review (qualitative), manual verification of top-100 cited references using Scholar GPT; no formal automated metrics reported.",
            "performance_results": "Produced coherent overviews and useful outlines; produced ~30 pages of cluster descriptions and a 1,000-word integrated summary; suffered from superficial technical depth and fabricated/incorrect references in some outputs.",
            "comparison_baseline": "Human-written reviews and manual literature synthesis (qualitative comparison); multiple LLM variants used for comparison of outputs, but no quantitative baseline comparisons provided.",
            "performance_vs_baseline": "Inferior in depth and reference accuracy to human experts; useful as a scaffold but requires substantial human curation to reach publication quality.",
            "key_findings": "Providing structured, network-derived keywords and importance values guides ChatGPT to produce coherent cluster-focused outputs; segmental prompting mitigates context limit constraints; cross-checking outputs across multiple LLMs reveals model-specific variation.",
            "limitations_challenges": "Hallucinated/incorrect references, superficial analyses lacking specific literature details, and model nondeterminism; limitation from using only title/abstract-derived keywords rather than full-text content.",
            "scaling_behavior": "LLM generation was applied to clusters derived from a 36k-node network by splitting tasks per cluster; authors note that full-text scaling would require more advanced ingestion and chunking strategies and reference-validation tooling.",
            "uuid": "e4420.2",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "Google Gemini (usage)",
            "name_full": "Google Gemini used as an alternative LLM for literature synthesis",
            "brief_description": "Google Gemini was one of multiple LLMs employed to obtain alternative analyses of the same cluster metadata, with the intent of reducing single-model bias and comparing outputs across model families.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Google Gemini (applied usage)",
            "system_description": "Gemini received the same or similar structured inputs (cluster tokens, sizes, importance values) as other LLMs to produce outlines and descriptive texts; authors used multiple LLMs to obtain slightly different analyses due to different training methods and algorithms.",
            "llm_model_used": "Google Gemini (specific size/version not specified).",
            "extraction_technique": "Structured prompting with network-extracted cluster tokens and importance indices; segmental generation.",
            "synthesis_technique": "Cluster-conditioned summarization analogous to ChatGPT usage (hierarchical/segmental summarization).",
            "number_of_papers": "Applied to cluster metadata derived from a 36,021-paper citation network; Gemini did not ingest all full texts directly.",
            "domain_or_topic": "Wearable sensors for health monitoring (this study).",
            "output_type": "Alternative outlines and cluster summaries to complement ChatGPT outputs.",
            "evaluation_metrics": "No quantitative metrics reported; qualitative comparison across model outputs.",
            "performance_results": "Delivered alternative perspectives but subject to the same limitations noted for other LLMs (superficiality, occasional inaccuracies); no quantitative performance numbers provided.",
            "comparison_baseline": "Compared qualitatively to ChatGPT outputs and to human curation; no formal benchmark.",
            "performance_vs_baseline": "No quantitative comparison; authors used multiple LLMs to mitigate single-model idiosyncrasies.",
            "key_findings": "Using multiple LLMs yields varied phrasings and occasionally different emphases, which can be useful for ensemble-style human selection; model-specific differences exist but were not quantified.",
            "limitations_challenges": "Same as other LLM usage: hallucinations, superficiality, context-window limitations; no specific Gemini-centric results reported.",
            "scaling_behavior": "No Gemini-specific scaling data provided; operated on cluster-level inputs derived from tens of thousands of papers.",
            "uuid": "e4420.3",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "OpenAI Scholar GPT (reference validation)",
            "name_full": "OpenAI Scholar GPT used for automated verification of cited references",
            "brief_description": "A specialized OpenAI tool employed by the authors to verify the existence and correctness of the top-100 cited references produced or listed in the Supporting Information, as a mitigation step against LLM hallucinations.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "OpenAI Scholar GPT (reference-checking step)",
            "system_description": "After initial LLM generation produced some incorrect or nonexistent references, the authors used OpenAI's Scholar GPT to check and validate the 100 top-cited references included in the Supporting Information, as an automated validation assist prior to human curation.",
            "llm_model_used": "OpenAI Scholar GPT (specific internal model/version not detailed).",
            "extraction_technique": "Reference validation via querying Scholar GPT about the existence/metadata of cited works; cross-checking against OpenAlex entries (implicitly).",
            "synthesis_technique": "Not a synthesis system per se; used to validate bibliographic entries and flag likely hallucinations for correction.",
            "number_of_papers": "Applied to the top-100 cited references from the LLM-generated outputs.",
            "domain_or_topic": "Bibliographic validation for literature-review outputs (applied on wearable-sensors corpus).",
            "output_type": "Validated list of references or flags indicating missing/incorrect references.",
            "evaluation_metrics": "Not specified; used as an assistive verification step alongside human checks.",
            "performance_results": "Helped identify hallucinations among LLM-produced references; no quantitative precision/recall metrics reported.",
            "comparison_baseline": "Not compared to other automated bibliographic validators in the paper.",
            "performance_vs_baseline": "Not evaluated quantitatively.",
            "key_findings": "Automated LLM-based reference validation is a practical mitigation against hallucinated citations but should be complemented with human verification and database checks (e.g., OpenAlex).",
            "limitations_challenges": "Scholar GPT itself is subject to model limitations and may not be a definitive arbiter; cross-checking against curated databases still required.",
            "scaling_behavior": "Applied at least to 100 references; scalability to thousands of references not evaluated in this work.",
            "uuid": "e4420.4",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "VOSviewer (with NLP features)",
            "name_full": "VOSviewer bibliometric mapping tool with integrated NLP/LLM features (as discussed)",
            "brief_description": "VOSviewer is a widely used bibliometric mapping tool mentioned in the paper as having many NLP features and being commonly employed for large-scale literature analyses; the paper notes VOSviewer likely has LLM/NLP integrations in current practice.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "VOSviewer with NLP/LLM features (mentioned)",
            "system_description": "The authors reference VOSviewer as a standard bibliometric visualization tool that offers NLP features for mapping keywords, co-occurrence, and themes; they note that many features based on LLMs and NLP are available in such bibliometric tools (particularly VOSviewer), although they do not detail a specific LLM-driven workflow performed inside VOSviewer in this paper.",
            "llm_model_used": "Not specified in this paper (VOSviewer integrations vary by user/setup).",
            "extraction_technique": "Bibliometric and NLP-based keyword extraction and co-occurrence mapping (tool-dependent); specifics not provided.",
            "synthesis_technique": "Visualization-driven summarization and mapping (no detailed synthesis pipeline described in this paper).",
            "number_of_papers": "Literature examples cited using VOSviewer ranged from thousands to tens of thousands of records in other studies discussed (e.g., 4,803; 7,416; 4,487 records cited).",
            "domain_or_topic": "Bibliometrics and literature mapping across domains; examples in the paper include NLP, hydrology, agricultural drought, and social network analysis.",
            "output_type": "Bibliometric maps, keyword co-occurrence networks, cluster maps used to support exploratory analyses and sometimes feed into summarization workflows.",
            "evaluation_metrics": "Not specified in this paper.",
            "performance_results": "Not evaluated quantitatively here; VOSviewer cited as commonly used and helpful for exploratory analysis.",
            "comparison_baseline": "Mentioned alongside other visualization tools (Gephi, Helios-web) but not directly compared quantitatively.",
            "performance_vs_baseline": "Not quantified in this paper.",
            "key_findings": "Bibliometric visualization tools are complementary to LLM-based summarization, and some (e.g., VOSviewer) already incorporate NLP features that can be combined with LLM workflows for large-scale literature analysis.",
            "limitations_challenges": "Standalone visualization/NLP features do not eliminate LLM-specific problems (hallucinations, shallow analysis) and often operate primarily on metadata/abstracts rather than full text.",
            "scaling_behavior": "Typical studies using VOSviewer process thousands (often up to several thousand) records; analyses of 100k+ papers are rare according to the paper.",
            "uuid": "e4420.5",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "LLM-assisted systematic review (ref 7, cited)",
            "name_full": "The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review",
            "brief_description": "A cited study that processed 3,785 studies from multiple bibliographic sources and selected 172 for in-depth analysis to characterize which review stages are automated by LLMs, proposed LLM types, metrics for evaluation, and related factors.",
            "citation_title": "The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review",
            "mention_or_use": "mention",
            "system_name": "LLM-assisted systematic review (Scherbakov et al., ref 7)",
            "system_description": "Cited in this paper as a prior study that applied LLMs to systematic-review tasks: it processed a large corpus (3,785 records) from PubMed, Scopus, Dimensions and Google Scholar and selected a subset (172) for deeper analysis of automated stages, LLM types suggested, metrics used to evaluate LLMs in review tasks, and related considerations. The current paper references that study to situate LLM usage in literature reviews.",
            "llm_model_used": "Not specified in Klarák et al.; the cited work analyzed a range of LLMs proposed for automation but specific model names/sizes are in the original ref.",
            "extraction_technique": "Not detailed in Klarák et al.; the cited study characterizes extraction/automation strategies across reviewed works (see original paper).",
            "synthesis_technique": "Not detailed here; original work surveyed how LLMs are used across stages of the review pipeline.",
            "number_of_papers": "3,785 articles processed overall; 172 selected for in-depth analysis (as reported in Klarák et al.).",
            "domain_or_topic": "Meta-research on use of LLMs in literature review workflows across biomedical and other domains (original paper published in J. Am. Med. Inf. Assoc. according to refs).",
            "output_type": "Systematic-review analysis and taxonomy of LLM use in review automation (original paper).",
            "evaluation_metrics": "Klarák et al. report that the cited study documents what metrics are used in the literature (ROUGE, human ratings, etc.), but specific metrics used by that study are to be found in the original reference.",
            "performance_results": "Not reported in Klarák et al.; see original paper for specifics.",
            "comparison_baseline": "Not detailed here.",
            "performance_vs_baseline": "Not reported in Klarák et al.",
            "key_findings": "Klarák et al. cite this study as evidence that LLMs are increasingly explored for automating stages of literature reviews and that systematic characterization of LLM roles and evaluation metrics has been performed by others.",
            "limitations_challenges": "Klarák et al. use this citation to support general observations about limitations (superficiality, hallucinations) but specifics are in the cited study.",
            "scaling_behavior": "The cited work processed thousands of records (3,785) and performed deeper analysis on a subset (172); exact scaling conclusions are in the original reference.",
            "uuid": "e4420.6",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "Network+LLM wound-healing study (Klarák et al. ref)",
            "name_full": "Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review",
            "brief_description": "A closely related (cited) study that applied network analysis together with LLMs to generate a literature landscape for dressing materials in wound healing, cited here as an example of combining network methods with LLMs in domain-specific literature synthesis.",
            "citation_title": "Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review",
            "mention_or_use": "mention",
            "system_name": "Network + LLM landscape generation (dressing materials review)",
            "system_description": "Cited as another example where citation-network methods were combined with LLM-generated summaries to produce a domain landscape; specifics (models, extraction/synthesis details, number of papers analyzed) are in the cited publication (Int. J. Biol. Macromol. 2025).",
            "llm_model_used": "Not specified in Klarák et al.; likely LLMs were used but exact models appear in the cited paper.",
            "extraction_technique": "Network-driven community detection feeding LLM summarization (as described generally in Klarák et al.).",
            "synthesis_technique": "Cluster-conditioned summarization via LLMs (specific synthesis workflow to be found in cited work).",
            "number_of_papers": "Not specified in Klarák et al.; see original cited article for quantities.",
            "domain_or_topic": "Dressing materials for wound healing (biomaterials literature).",
            "output_type": "Landscape-style literature review combining network clusters with LLM-generated descriptions.",
            "evaluation_metrics": "Not reported in this paper; consult the cited article.",
            "performance_results": "Not reported here.",
            "comparison_baseline": "Not reported here.",
            "performance_vs_baseline": "Not reported here.",
            "key_findings": "Referenced as corroborating evidence that network + LLM combinations have been applied successfully in domain-specific literature mapping, reinforcing the approach used in this paper.",
            "limitations_challenges": "Not detailed here; readers are referred to the original cited work.",
            "scaling_behavior": "Not described in Klarák et al.; see the cited wound-healing review for specifics.",
            "uuid": "e4420.7",
            "source_info": {
                "paper_title": "The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models",
                "publication_date_yy_mm": "2025-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review",
            "rating": 2,
            "sanitized_title": "the_emergence_of_large_language_models_as_tools_in_literature_reviews_a_large_language_modelassisted_systematic_review"
        },
        {
            "paper_title": "Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review",
            "rating": 2,
            "sanitized_title": "using_network_analysis_and_largelanguage_models_to_obtain_a_landscape_of_the_literature_on_dressing_materials_for_wound_healing_the_predominance_of_chitosan_and_other_biomacromolecules_a_review"
        },
        {
            "paper_title": "Using network science and text analytics to produce surveys in a scientific topic",
            "rating": 2,
            "sanitized_title": "using_network_science_and_text_analytics_to_produce_surveys_in_a_scientific_topic"
        },
        {
            "paper_title": "Network Analysis and Natural Language Processing to Obtain a Landscape of the Scientific Literature on Materials Applications",
            "rating": 2,
            "sanitized_title": "network_analysis_and_natural_language_processing_to_obtain_a_landscape_of_the_scientific_literature_on_materials_applications"
        },
        {
            "paper_title": "AI-Assisted Tools for Scientific Review Writing: Opportunities and Cautions",
            "rating": 2,
            "sanitized_title": "aiassisted_tools_for_scientific_review_writing_opportunities_and_cautions"
        }
    ],
    "cost": 0.0213805,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models
September 10, 2025</p>
<p>Jaromir Klarák 
Vitor H B D Santi 
Luan F Moreira 
Robert Andok 
Maria Bardosova 
Maria Cristina 
F Oliveira 
Osvaldo N − Oliveira Jr
Carlos Sao 
Sao Carlos </p>
<p>sı Supporting Information</p>
<p>Institute of Physics
University of Sao Paulo
Saõ Carlos13566-590Brazil</p>
<p>Institute of Informatics
Slovak Academy of Sciences
845 07BratislavaSlovak Republic</p>
<p>Institute of Physics
University of Sao Paulo
Saõ Carlos13566-590Sao CarlosBrazil</p>
<p>Institute of Physics
University of Sao Paulo
Saõ Carlos13566-590Brazil</p>
<p>Institute of Informatics
Slovak Academy of Sciences
845 07BratislavaSlovak Republic</p>
<p>Institute of Informatics
Slovak Academy of Sciences
845 07BratislavaSlovak Republic</p>
<p>Institute of Mathematical Sciences and Computing
University of Sao Paulo
Saõ Carlos13566-590Sao PauloBrazil</p>
<p>The Landscape of Wearable Sensors and Automated Literature Analysis with Large-Language Models
September 10, 202551D083E0594CF69FC91FCFF9C47F1B2A10.1021/acsomega.5c04542Received: May 15, 2025 Revised: August 25, 2025 Accepted: September 3, 2025Metrics &amp; More Article Recommendations
The rapid growth of scientific literature demands advanced methodologies to analyze and synthesize research trends efficiently.This paper explores the integration of complex network analysis and large language models (LLMs) to automate the generation of literature analyses, focusing on the field of wearable sensors for health monitoring.Using OpenAlex as a source of scientific papers in this field, paper citation networks were constructed and partitioned into thematic clusters, revealing key subtopics such as flexible graphene-based sensors, gait analysis, and machine learning applications.These clusters, characterized by their term importance and interconnectivity, served as input for LLMs (ChatGPT) to generate structured outlines and descriptive summaries.While LLMs produced coherent overviews, limitations emerged, including superficial analyses and inaccuracies in referenced literature.The study demonstrates the potential of combining network-based methodologies with LLMs to create scalable literature reviews, albeit with limitations to be addressed concerning depth and accuracy.The analyses highlight wearable sensors' transformative role in healthcare, driven by advancements in materials science, artificial intelligence, and device integration, while also identifying critical gaps such as standardization, biocompatibility, and energy efficiency.This hybrid approach offers a promising framework for accelerating scholarly synthesis, though today human oversight remains essential to ensure rigor and relevance.</p>
<p>INTRODUCTION</p>
<p>Generative artificial intelligence (AI) based on large language models (LLMs) has the potential to transform academic publishing, including the possibility of machine-generated knowledge, e.g., with AI agents capable of writing scientific papers. 1 While this applies to various types of publications, surveys and review papers are likely to be the most immediately affected.Literature surveys are essential for scientific research, aiding topic selection, data analysis, and interpretation.Indeed, many journals are dedicated specifically to publishing reviews that provide a broad overview of a given research area.In the past, such an overview could be obtained by consulting a limited number of journals focused on specific topics.However, this is no longer feasible due to the substantial increase in both the number of journals and published articles, as well as the growing multidisciplinary nature of research. 2Various techniques now address the vast volume of scientific literature, 3 primarily through statistical and computational analyses combined with natural language processing (NLP). 4In the latter work, for example, the authors retrieved 4,712 arXiv articles using the query "natural language processing," visualized their relationships with NetworkX 5 and igraph, 6 and analyzed problem occurrences across the papers.A study on the use of large language models (LLMs) processed 3,785 studies from PubMed, Scopus, Dimensions, and Google Scholar; from these, 172 were selected for in-depth analysis, covering which stages of the review are automated, which LLM types are proposed for automation, the metrics used to evaluate LLMs, and related factors. 7omplex network analysis 8,9 and machine learning 10 have also been used.Complex networks are graphs with nontrivial topological characteristics�features absent in simple networks like lattices or random graphs.They employ 11,12 logical connections between papers, authors, and entities, enabling the identification of communities (i.e., clusters of densely connected elements) through their relationships.A citation network-based methodology was developed to analyze research areas and scientific journal content 13 and later applied to describe key topics in chemistry and materials science journals. 14A similar work to the present study is a review paper focused on the use of graph neural networks in soft sensor development, fault diagnosis, and process monitoring. 15n additional advantage of network-based methods is their visualization potential through tools such as Helios-web, 16,17 VOSviewer, 18,19 and Gephi, 20 which are helpful to support exploratory analysis.Many features based on LLMs and NLP are available in these tools�especially in VOSviewer, which is likely the most widely used.For example, social network analysis (SNA) has been conducted on 4,487 Scopus records. 21A hydrology-focused bibliometric mapping study used 45 research documents. 22A bibliometric analysis of NLP with VOSviewer included 4,803 records, 23 mapping countries, institutions, authors, and keyword co-occurrence.Another study on agricultural drought analyzed 7,416 studies in VOSviewer. 24In summary, with standard tools, most studies operate at the scale of thousands of records (rarely tens of thousands); analyses of 100,000+ papers are very rare.</p>
<p>The analysis of the literature with complex network methodologies can now be complemented with generative artificial intelligences, particularly those based on large language models (LLMs) 25 such as ChatGPT, Google Gemini, Windows Copilot, and LLaMA (Large Language Model Meta AI), which are capable of generating fluent and contextually relevant texts.This combination has been explored in determining the main materials and methods involved in dressings for wound healing. 26However, LLM tools have significant limitations.They tend to produce superficial analyses of complex topics and struggle to provide comprehensive views of highly specific areas.They are not effective when deep understanding of context is required.In this paper we propose a system capable of addressing some of these limitations toward automatically generating literature review articles for a given research topic.Our main contribution is to demonstrate�through a proof-of-concept example�that results from network analysis can be used as input to LLMs to generate a landscape of a given topic.The scientific topic chosen is related to wearable sensors and health monitoring.This field is relevant to many research areas, particularly materials and health, and the devices created are applicable to the Internet of Things and Artificial Intelligence.It is a fast-growing field as indicated in the analysis of the key areas in journals dedicated to applied materials. 14We also emphasize the limitations of the use of LLMs for dealing with the scientific literature.In fact, to address these limitations, we conducted this study to demonstrate that combining LLMbased text processing with an interactive web application (Helios-web) enables readers to visualize and explore large corpora of papers and automatically generate summaries for specific research areas.The results provide a practical way to cope with the rapid growth in scientific publications and research activity, supporting scalable analysis of large literature data sets.The outline of this paper is as follows.The methodology based on complex networks to yield a landscape of the field is presented in Section 2, along with the description of the system to generate surveys (review papers) autonomously.The landscape for wearable sensors is described in Section 3, while Section 4 discusses texts and analyses generated with LLMs.These texts are included as Supporting Information.Section 5 closes the paper with conclusions and perspectives, especially commenting on the present limitations of LLMs for machine-generated knowledge.</p>
<p>METHODOLOGY</p>
<p>The problem was addressed in a segmented manner, beginning with the retrieval of articles related to the chosen topic, and then the application of the method introduced in ref 13, responsible for generating citation networks and partitioning them into communities.After these steps, LLM tools were used to generate the paper outline and then review articles on the topic of interest, namely "wearable sensors for health monitoring".</p>
<p>2.1.Searches on OpenAlex.The selected topic "wearable sensors for health monitoring" has broad relevance to multiple research areas, such as materials and health.This area features a substantial number of articles, aligning with the goals of this paper and the chosen methodology.The search platform selected for this work was OpenAlex, 27,28 an open and free database providing information on academic publications, including journals, books and conference papers.OpenAlex offers an API and an interface that facilitates the extraction and use of academic data and citation analysis, along with search filters. 29Multiple searches were performed, varying term formulations and search operators (AND, OR, NOT) to maximize the set of articles related to the topic.All searches were conducted with a title and abstract filter ("title and abstract"), as only the contents from these sections of the articles were considered in the subsequent step of network generation.</p>
<p>2.2.Network Generation Using the Method from ref 13.The method introduced in ref 13 involves building a citation network from a corpus of scientific articles and applying a community detection algorithm to partition the network into clusters of densely connected articles.The network nodes are formed by the articles, and an edge is established between two articles if one cites the other.Notice that only articles cited by others are included in the network, thus not all retrieved articles will be part of the network, as it will be evident in the results section.Since the goal is to provide a general overview of the scientific topic, analyzing only the most impactful and relevant works within the network is acceptable.For purposes of community detection, we consider the network is undirected.The Louvain method 30 is applied to partition the network into clusters, which is a stochastic method that produces similar partitions across different runs.Clusters are then characterized by extracting relevant terms�including keywords, unigrams, and bigrams� from the article's abstracts postprocessed using the downloaded LLM model KeyBERT. 31,32Thus, clusters will be characterized by topics and their importance to the field.</p>
<p>A preprocessing step is necessary to remove terms with low semantic content and lemmatize words sharing the same canonical form.The importance of each term within the citation network is quantified by an index that calculates its relative frequency within its community compared to the rest of the network.To determine the frequency of a word (w) in a community (α), the total occurrences n α (w) of (w) within that community are counted.Then, the relative frequency within the community F ( ) in is given by eq 1:
= | | F (w) n (w) in (1)
where |α| is the number of articles within the community (α).Simultaneously, the relative frequency outside the community F w ( ) out is calculated as:
= | | F w N ( ) n (w) out (2)
Here, N is the total number of articles in the network.With the internal and external frequency relationships established, the importance I(w) defined in eq 3 of a word is quantified as the maximum difference between F w ( ) in and F w ( )
out : = [ ] I w max F w F w ( ) ( ) ( ) in out(3)
In the study from ref 13, keywords ranked by their importance indices are used to create a hierarchical tree that simulates the structure of a survey, generated using an agglomerative hierarchical clustering method. 33,34Articles are grouped into general topics, divided into sections and subsections.Keywords are grouped based on the average topological distance between articles containing them, using the average shortest path length l uv defined in eq 4 between keyword pairs (u,v):
= | × | × l l u v A A ( , ) ( ) uv u v A A ij i j ( , ) ( ) i j (4)
where A i and A j are abstracts of articles where keywords (u) and (v) are present, respectively, and (l ij ) is the shortest path between article pairs (i) and (j).This approach groups keywords based on their average topological distance.To address redundancy, unigrams are removed from the keyword set if they are part of a bigram with high I(w), prioritizing more specific keywords (bigrams).The final output of the method is a cluster-based grouping of words, providing insights into the proximity of concepts within the citation network.</p>
<p>Use of LLM Tools to Generate</p>
<p>Outlines and Articles.Large Language Model (LLM) tools can be employed in scientific research, for example, to summarize or describe the concepts covered in provided articles.One of the objectives of this paper is to inform the landscapes obtained using the method from ref 13 to an LLM, prompting the model to produce analyses of the literature and a proof-of-concept review article based on this information.To achieve this, simply providing the network and cluster data to an LLM is insufficient.As previously discussed, LLMs have limitations, such as their tendency to offer superficial analyses on complex topics and difficulty in providing comprehensive views of specific fields.To mitigate these limitations, several strategies were implemented.Multiple LLM tools (e.g., ChatGPT 35 and Google Gemini 36 ) were used to obtain slightly different analyses due to their distinct training methods and algorithms.Text generation was structured to provide input data, such as the cluster tokens with their respective importance indices and the desired textual structure for the review article.LLMs have constraints on text volume; their responses are usually not extensive.To address this, texts were generated segmentally, focusing on one topic at a time.Another issue encountered was related to references.Since we are dealing with a review article, generating content without proper scientific backing would be inappropriate.To resolve this, the tools were instructed to include references in their responses.</p>
<p>LANDSCAPE OF THE FIELD "WEARABLE SENSORS FOR HEALTH MONITORING"</p>
<p>One of the initial challenges in obtaining an overview of a research field is determining its scope.While this might seem straightforward by looking at the number of articles returned from keyword searches, the estimates are often imprecise due to dependence on the search terms used.For example, in the field of interest here�wearable sensors�a simple search using terms like "wearable sensor" or "wearable or sensors" could be unlikely to capture all relevant articles.This occurs because variations, such as "sensing," may not be included, and articles may discuss wearable sensors without explicitly using those terms.Using more generic searches like "sensor" or "sensing" combined with "wearable" or "wear" might yield a vast number of articles, many of which are irrelevant.Recent experiences using citation networks with the method from ref 13 suggest a potential solution for estimating the scope of the field.This strategy was employed here, using multiple searches to establish upper and lower bounds for the number of articles within the chosen topic.We performed several searches in the OpenAlex database to gather as many articles as possible related to wearable sensors and health monitoring.The broadest search aimed to investigate the fields of wearable sensors and health monitoring without specifying whether it was for human or animal health, nor requiring that monitoring be conducted with wearable sensors or that wearable sensors be used in health contexts.Using the terms "wearable sensors or health monitoring," the search returned almost 90,000 articles, of which around half were part of the giant component of the citation network (i.e., the largest subnetwork with no disconnected articles).Due to the broad scope, the clusters identified were highly diverse, with the largest cluster pertaining to the health of bridges, structures, and civil constructions.Therefore, many of the papers retrieved are not related to "human" health monitoring.More restrictive searches, using e.g., "wearable health monitoring" and "wearable medical devices", retrieved a much smaller number of articles (&lt;20,000), certainly missing relevant content.In these empirical attempts, we found that using the terms "wearable sensors" seemed the best option.It led to over 60,000 papers being retrieved, of which 36,021 belong to the giant component of the citation network (see below).Hence, we may conclude that the upper limit for the number of articles in the OpenAlex database is approximately 60,000.Contrary to the assumption that such a simple search would exclude many relevant articles, this does not seem to have occurred.</p>
<p>Figure 1 shows the citation network containing 36,021 nodes (articles) retrieved with the query "wearable sensors".The 10 most relevant clusters are indicated in Table 1, along their size in terms of number of papers and the titles created with ChatGPT 4o-mini-high 37 using the OpenAI API.This search did not specify whether the sensors were used for health monitoring.Yet almost all clusters relate to health monitoring.The network is better visualized in the Helios-Web platform, accessible at (http://server1.phys.eu:8080/docs/example/index.html?network=BR_vol2/wearable_sensors_top10_v5B).In another possible visualization, the clusters are deliberately separated from each other to facilitate inspection of individual clusters.This is presented in (http://server1.phys.eu:8080/docs/example/index.html?network=BR_vol2/wearable_ sensors_top10_v5).The largest cluster, A (in blue, with 13,986 articles), focuses on flexible and stretchable pressure and strain sensors, which are made mostly with graphene and other nanomaterials, in addition to polymer hydrogels.The second largest cluster, B (in orange, with 12,121 articles), relates to sensors for monitoring human activities, such as gait.In contrast to cluster A, which emphasizes materials for sensors, in Cluster B the major focus is on monitoring   technologies.This may explain why Clusters A and B appear at opposite sides in the 3D visualization.The other 8 clusters are much smaller in size, with Cluster C possessing 2,408 papers.Cluster C (in green), like Cluster B, is mostly related to monitoring technology.Cluster D (in red) is related to monitoring with neural networks and other machine learning methods.The monitoring of stress, depression and mental health using wearables is the topic of Cluster E (purple).Cluster F (brown) is associated with data security and communication, while Cluster J focuses on glucose monitoring and diabetes.Cluster G (pink) is completely detached from the other clusters, which is explainable because it is related to monitoring the "health" of tools and industrial processes and materials.</p>
<p>LITERATURE ANALYSIS USING LLMS</p>
<p>The methodology described can be applied to produce analysis and review articles for any area of knowledge.The flowchart in Figure 2 outlines the procedures for generating a review article in a semiautomated manner by combining the method from ref 13 with subsequent use of LLM tools.The first three steps in the flowchart consist in obtaining the citation network for a topic of interest via the method of ref 13.The resulting network can then be reviewed by the expert (human) requesting the review article.Highlighted in red are the types of information from the networks that can be utilized by LLM tools, including: List of communities (clusters): These represent the main subtopics within the field, defined by sets of terms whose relevance can be calculated.List of articles represented by nodes: These articles can be classified based on their centrality in the network.Centrality measures may include simple metrics like the connectivity degree (number of citations an article has received) or more complex metrics like the number of shortest paths passing through the node.</p>
<p>Interconnections between communities and nodes: Relative distances between nodes (articles) are defined, which can provide insight into their relationships.List of authors, journals, and institutions: This information can aid in analysis.We prompted the ChatGPT-o1 model to generate an outline for a review paper on wearable sensors considering information extracted from the citation network of Figure 1, which identified 10 major clusters of topics in the field.The network information was input by uploading the corresponding .xnetfile (as described in the Supporting Information).Three other types of information were provided to ChatGPT: i) the cluster sizes, in terms of number of papers in each one; ii) the list of 100 keyterms most representative of each cluster; iii) the importance value of each keyterm.Box 1 shows the outline produced by ChatGPT, with the two first sections expanded to indicate the contents suggested.For Section 3, in particular, specific contents were suggested for each cluster, as can be seen in the complete outline in the Supporting Information.While the entire outline may resemble a possible outline produced by human experts, it is based on a very broad perspective of the field.For it relied on a massive number of papers, rather than on tens or hundreds of papers which could be handled by humans.</p>
<p>It is also true that the contents of the outline generated by ChatGPT are rather generic; therefore, one could argue that similar outlines could be produced simply by employing important keywords from the field.We also asked ChatGPT to provide detailed descriptions of each cluster, using as input the .xnetfile for the network in Figure 1, the cluster titles, and 100 keywords with their corresponding importance values for each cluster.These descriptions, generated with ChatGPT o3-minihigh, 38 are presented in the Supporting Information.Each cluster is typically described in a two-page text, possibly including subsections and ending with a list of key references.Although these descriptions are brief and do not report specific results from the literature, together they offer a broad overview of the field.Some of the references introduced by ChatGPT o3-mini-high include incorrect or nonexistent entries.This limitation can potentially be addressed by incorporating additional tools or strategies to ensure that all references exist in a validated database such as OpenAlex.</p>
<p>Even without details on specific results, the cluster descriptions in the Supporting Information span over 30 pages.Since one of the objectives of our paper is to provide an analysis of the field�though without the intention of producing a fully fledged review�we asked ChatGPT-4o 39 to generate a 1,000-word summary of the clusters content.The texts obtained from this description of the clusters were quite informative.They were edited to produce the discussion below:</p>
<p>The cluster analysis clearly shows that wearable sensors are transforming healthcare by enabling continuous, real-time monitoring of physiological and biomechanical signals.These devices are designed to be lightweight, flexible, and comfortable for long-term wear, making them ideal for applications such as chronic disease management, rehabilitation, and early detection of health anomalies.Progress in this field has been driven by advances in materials science, sensor design, signal processing, and wireless connectivity, all aimed at improving the accuracy, usability, and clinical relevance of wearable health technologies.The sensing modalities discussed primarily include flexible and stretchable sensors made from materials such as graphene, carbon nanotubes (CNTs), and conductive polymers, often embedded in hydrogels or textiles.Other device types include accelerometers and gyroscopes for monitoring movement, as well as skin-adhered sensors for detecting heart rate, stress levels, and other physiological conditions.It is worth noting that the summaries produced by the LLM tools did not mention the integration of wearable sensors with biosensors.This omission is likely due to the relatively smaller number of publications on wearable biosensors, despite their importance for health monitoring.In fact, there is a significant imbalance in the literature when comparing biosensors and physical sensors.Wearable biosensors are underrepresented, a trend that is reflected in the landscape analysis presented in our work.</p>
<p>Regarding the techniques used to produce wearable sensors, additive manufacturing is prominently featured, with particular emphasis on methods such as inkjet printing, screen printing, and 3D printing, as well as laser patterning for the precise fabrication of conductive traces on flexible substrates.Since powering the sensors is a critical challenge, nanogenerators and energy-harvesting strategies have been employed in selfpowered devices.In terms of applications, particular emphasis is placed on the management of chronic diseases, such as diabetes and cardiovascular conditions, rehabilitation through physical condition monitoring, mental health and stress tracking, and elderly care.The growing use of machine learning and other AI methods is also reflected in some of the clusters, as effective health monitoring relies on advanced signal processing and data analysis.Several feature extraction and classification algorithms were identified, primarily based on machine learning, including deep learning approaches.These methods enable so-called multimodal fusion, which combines data from multiple sensors to improve the accuracy of health assessments.This is closely linked to wireless communication and Internet-of-Things (IoT) integration, allowing for continuous monitoring and real-time analysis.The brief description of the use of machine learning for processing data from wearable sensors clearly demonstrated the potential of this field�especially given that future health monitoring systems will likely rely entirely on the integration of machine learning and wearable devices.</p>
<p>As with any literature analysis, the summary produced by the LLM tools includes a discussion of the challenges and prospects of the field.For sensors, in particular, there is an ongoing effort to achieve long-term stability and biocompatibility.To this end, hypoallergenic materials and encapsulation techniques are being developed to improve compatibility with the human body.Another major challenge is the lack of standardized protocols for data collection and processing, which hinders cross-study comparisons.Energy efficiency is also a critical issue, with energy-harvesting technologies and ultralow-power designs being essential for enabling long-term operation.Also highlighted is the concept of personalized medicine, with increasing reliance on AI methodologies to tailor to individual needs.Finally, critical barriers to the widespread adoption of wearable sensors in medical applications include the need for clinical validation and regulatory compliance, along with ethical considerations that must be carefully addressed.</p>
<p>The analysis above does not allow one to determine whether an intelligent system could provide an in-depth, authoritative discussion of the field.In order to test this, we used ChatGPT to write a short review paper on Cluster A from Figure 1, including figures and references.The results can be seen in the Supporting Information.The title chosen by ChatGPT for the review paper was "Advances and Trends in Flexible and Wearable Sensor Technologies: A Network-Based Review", which is excellent for conveying the intended focus, also emphasizing the distinct nature of the review, based on network analysis.</p>
<p>The automatically generated review is an excellent starting point for a paper on wearable sensors made with graphene and other carbon materials.However, the strong focus on graphene may not be ideal, as Cluster A is broad and includes other relevant materials that should also be addressed.Nevertheless, the text does establish connections between graphene and these other materials.The abstract and outline of the generated paper are excellent, as the main topics are well covered.In fact, the review provides a comprehensive overview of flexible, graphene-based temperature and strain sensors for wearable electronics, detailing material innovations, fabrication strategies, sensing mechanisms, performance benchmarks, integration approaches, and key challenges.The significance of graphene in the field is justified by its unique properties.</p>
<p>The major topics are organized into eight distinct sections that discuss materials and fabrication techniques, sensing mechanisms, performance metrics, integration into wearable devices, applications, challenges, and future perspectives.While the selection of topics and the overall text are generally appropriate, there are notable stylistic and content-related shortcomings.First, the excessive use of itemization disrupts the text flow.More importantly, the descriptions are mostly superficial�an issue commonly found in texts generated by large language models.This superficiality is arguably the greatest hurdle in producing review papers suitable for prestigious journals.Another limitation is the small number of figures, all of which were generated by the LLM tool.Although these illustrations are appropriate, a high-quality review should ideally include several figures from published literature.A dedicated tool will be needed to address this limitation effectively.</p>
<p>CONCLUSIONS, LIMITATIONS, AND PERSPECTIVES</p>
<p>This study presents an analysis of the field of wearable sensors for health monitoring using a hybrid approach to automate literature reviews by combining complex network analysis with large language models (LLMs).By constructing citation networks from OpenAlex data and applying clustering algorithms, we identified major subtopics in the field and used LLMs to generate structured summaries and review drafts.This methodology offers a scalable framework for navigating vast scientific corpora and provides insights into the thematic structure and evolution of interdisciplinary domains.The main findings indicate that progress in wearable sensors has been largely driven by advances in materials science� particularly related to carbon materials and polymers�as well as in device engineering, including the development of selfpowered devices.Combined with the use of machine learning and other AI methodologies, these wearable sensors are increasingly applied to various aspects of health monitoring, such as chronic disease management and rehabilitation.The main contribution of our work lies in demonstrating that network analysis can be effectively combined with LLM tools to generate surveys on any given topic.Furthermore, the pipeline used for generating these surveys can be readily adopted by other authors to implement their own systems for machine-generated reviews and surveys.</p>
<p>Our analysis also highlights both the potential and current limitations of LLMs in scientific synthesis.While the generated texts were coherent and thematically relevant, they often lacked depth and included superficial analyses, particularly when describing technical details or contextualizing findings.Furthermore, the inclusion of inaccurate or fabricated references highlights the need for robust validation pipelines and integration with curated databases.These issues confirm that, at present, human oversight remains essential to ensure the accuracy, rigor, and interpretability of machine-generated content.Several limitations of this study must also be acknowledged.First, while the citation network methodology delineates thematic clusters, its performance depends on search term selection and database coverage, which may result in the omission of relevant subfields.Second, although multiple LLMs were used to reduce bias, they still struggle with contextdependent understanding and may reproduce errors or hallucinations.We also observed that the ChatGPT o3-minihigh model hallucinated references in the Supporting Information.To prevent further LLM hallucinations, we verified the 100 top-cited references (listed at the end of the Supporting Information) using OpenAI's Scholar GPT.LLMs are trained on data up to a fixed cutoff and can be biased toward more frequently occurring information�often older sources from three to five years ago�while underrepresenting newer findings.For this reason, human judgment remains essential to ensure the appropriateness and accuracy of content generated by LLMs.That is to say, domain expertise is still essential to interpret and polish the LLM-generated content.Third, the lack of figures derived from validated sources and the minimal incorporation of actual article content into the summaries are notable shortcomings when compared to conventional review articles.Another limitation is that we generated content using only keywords extracted from abstracts.Deeper insights could be achieved by analyzing the full text of the papers, as in a recent study. 40The reproducibility is also limited due to the "non-deterministic" nature of LLMs, which are updated constantly.</p>
<p>Despite these constraints, the approach opens new perspectives for accelerating scientific synthesis, especially in fast-growing or highly multidisciplinary fields.Future developments should focus on improving LLM accuracy through the incorporation of structured metadata, reference validation tools, and deeper integration with citation contexts.Tools capable of automatically extracting and summarizing quantitative results, figures, and methodological nuances from primary literature would further enhance the quality of reviews.Additionally, establishing community standards for the evaluation of AI-assisted reviews could facilitate broader adoption while preserving academic integrity.</p>
<p>While not yet a replacement for expert-driven reviews, the methodology presented here offers a valuable tool for augmenting scholarly work, informing research directions, and democratizing access to scientific overviews.The efficiency of deploying LLM-based methods in review processing can be improved at multiple levels.First, preparing high-quality metadata helps eliminate redundant operations.Second, setting realistic expectations for the outputs and choosing an appropriate model are essential to achieving the desired results.</p>
<p>■ ASSOCIATED CONTENT</p>
<p>Figure 1 .
1
Figure 1.Citation network with 36,021 articles and 257,646 citation connections obtained from the corpus retrieved using the search term "wearable sensors".</p>
<p>1 , 604 F-
1604
Advancements in Wireless Wearable Devices for Healthcare: Integrating IoT Technology for Real-Time Health Monitoring and Data Communication 1,596 G-Assessment of Wear and Movement in Carbon-Based Flexible Films for Real-Time Health Monitoring and Rehabilitation Applications 1,182 H-Enhancing Gesture Recognition Accuracy in Wearable Devices Through Machine Learning and Inertial Data Analysis 747 I-Design and Assessment of a Wireless Energy Harvesting Prototype for IoT Applications Using Carbon Nanotubes and Advanced Signal Processing Techniques 229 J-Development of a Smart Wearable Device for Remote Monitoring of Diabetes Patients Using ECG and Accelerometer Technologies 208 a Titles generated by ChapGPT with version gpt-4o-mini via OpenAI API, with prompt: "Generate only one best title for scientific papers with keywords including importance values:".</p>
<p>Figure 2 .
2
Figure 2. Flowchart for generating review articles using LLMs and thematic citation networks.The pipeline comprises three major blocks.On the left handside are the procedures to obtain a citation network with papers retrieved from a given search in a database such as OpenAlex.The preprocessing steps correspond to partitioning the network into clusters (communities) to identify topics and the representative papers in each topic.The procedures to produce review articles shown on the right involve the use of LLM tools.</p>
<p>Table 1 .
1
List of Clusters along with Their Titles and Size (Number of Papers)a Flexible Graphene-Based Sensors for Enhanced Temperature and Strain Sensing in Wearable Electronics 13,986 B-Enhanced Gait Analysis and Fall Detection in Elderly Patients Using Wearable Inertial Sensors for Accurate Activity Recognition 12,121 C-Advancements in Wearable ECG Technologies: A Study on Textile-Based Electrodes for Enhanced Health Monitoring and Signal Classification 2,408 D-Advancements in Neural Network Models for Monitoring Physiological Signals: A Comprehensive Study on Energy-Efficient Wearable Devices for
ClusterGenerated titlesize
http://pubs.acs.org/journal/acsodf Review https://doi.org/10.1021/acsomega.5c04542 ACS Omega 2025, 10, 42127−42134
https://doi.org/10.1021/acsomega.5c04542ACS Omega 2025, 10, 42127−42134
The authors declare no competing financial interest.■ ACKNOWLEDGMENTSThis work was supported by CAPES, CNPq and FAPESP (2018/22214-6).H2020-MSCA-RISE-2019-873123: Smart Wound Monitoring Restorative Dressings (SWORD), by the Slovak Research and Development Agency under the Contract no.APVV-23-0173, by the VEGA grant No. 2/0099/22, by EU NextGenerationEU through the Recovery and Resilience Plan for Slovakia under the project ENEFS in call 09I05-03-V02, and project M-Era.Net inline evaluation of Li-ion battery electrode porosity using machine learning algorithms� BattPor.The Article Processing Charge for the publication of this research was funded by the Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES), Brazil (ROR identifier: 00x0ma614).Notes
Materials Discovery With Machine Learning and Knowledge Discovery. O N Oliveira, Jr, M C F Oliveira, 10.3389/fchem.2022.930369Front. Chem. 109303692022</p>
<p>Rise in higher education researchers and academic publications. W M To, B T W Yu, 10.1108/EOR-03-2023-0008Emerald Open Res. 12020</p>
<p>. S Fortunato, C T Bergstrom, K Börner, J A Evans, D Helbing, S Milojevic, A M Petersen, F Radicchi, R Sinatra, B Uzzi, 10.1126/science.aao0185Science of Science. Science. 359eaao01852018</p>
<p>H Caseli, M G V Nunes, Processamento de Linguagem Natural: Conceitos, tećnicas E aplicacoẽs Em portugueŝ. essamento de Linguagem Natural: Conceitos, tećnicas E aplicacoẽs Em portugueŝ2024. 30 April 2025</p>
<p>Exploring network structure, dynamics, and function using Network X. A Hagberg, P J Swart, D A Schult, Proceedings of the 7th Python in Science. the 7th Python in ScienceU.S. Department of Energy2008</p>
<p>. G Csárdi, F Zanini, T Nepusz, V Traag, S Horvát, D Noom, 2005igraph Reference Manual</p>
<p>The emergence of large language models as tools in literature reviews: a large language model-assisted systematic review. D Scherbakov, N Hubig, V Jansari, A Bakumenko, L A Lenert, 10.1093/jamia/ocaf063J. Am. Med. Inf. Assoc. 322025</p>
<p>The structure and function of complex networks. M E J Newman, 10.1137/S003614450342480SIAM Rev. 452003</p>
<p>. L D F Costa, O N Oliveira, Jr, G Travieso, F Rodrigues, </p>
<p>Analyzing and modeling real-world phenomena with complex networks: a survey of applications. A Villas Boas, P R Antiqueira, L Viana, M P Correa Rocha, L E , 10.1080/00018732.2011.572452Adv. Phys. 602011</p>
<p>Data, measurement and empirical methods in the science of science. L Liu, B F Jones, B Uzzi, D Wang, 10.1038/s41562-023-01562-4Nat. Hum. Behav. 2023</p>
<p>The science of science: From the perspective of complex systems. A Zeng, Z Shen, J Zhou, J Wu, Y Fan, Y Wang, H E Stanley, 10.1016/j.physrep.2017.10.001Phys. Rep. 2017</p>
<p>Exploring complex networks. S H Strogatz, 10.1038/35065725Nature. 4102001</p>
<p>Using network science and text analytics to produce surveys in a scientific topic. F N Silva, D R Amancio, M Bardosova, L D F Costa, O N Oliveira, Jr, 10.1016/j.joi.2016.03.008J. Informetr. 102016</p>
<p>Network Analysis and Natural Language Processing to Obtain a Landscape of the Scientific Literature on Materials Applications. A C M Brito, M C F Oliveira, O N Oliveira, Jr, F N Silva, D R Amancio, 10.1021/ACSAMI.3C01632?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asACS Appl. Mater. Interfaces. 152023. 27437− 27446</p>
<p>Review on Graph Neural Networks for Process Soft Sensor Development, Fault Diagnosis, and Process Monitoring. M Jia, Y Yao, Y Liu, 10.1021/acs.iecr.5c00283?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asInd. Eng. Chem. Res. 642025</p>
<p>. F Battiston, E Amico, A Barrat, G Bianconi, De Arruda, </p>
<p>The physics of higher-order interactions in complex systems. F Franceschiello, B Iacopini, I Kéfi, S Latora, V Moreno, Y , 10.1038/s41567-021-01371-4Nat. Phys. 172021</p>
<p>Software survey: VOSviewer, a computer program for bibliometric mapping. Helios-Web -Filipi N, N J Silva ; Van Eck, L Waltman, 10.1007/s11192-009-0146-3Scientometrics. 841817 November 2023. 2010</p>
<p>. N J Van Eck, L Waltman, Manual Vosviewer, 2019Universiteit Leiden</p>
<p>Learn how to use Gephi. 2024. January 2024</p>
<p>Bibliometric and visualized analysis of social network analysis research on Scopus databases and VOSviewer. D Gandasari, D Tjahjana, D Dwidienawati, M Sugiarto, 10.1080/23311975.2024.2376899Cogent Bus. Manag. 23768992024</p>
<p>How Bibliometric Analysis Using VOSviewer Based on Artificial Intelligence Data (using ResearchRabbit Data): Explore Research Trends in Hydrology Content. S Rochman, N Rustaman, T R Ramalis, K Amri, A Y Zukmadini, I Ismail, A H Putra, 10.17509/ajse.v4i2.71567ASEAN J. Sci. Eng. 42023</p>
<p>Bibliometric analysis of natural language processing using CiteSpace and VOSviewer. X Chen, W Tian, H Fang, 10.1016/j.nlp.2024.100123Nat. Lang. Process. J. 101001232025</p>
<p>Agricultural drought research knowledge graph reasoning by using VOSviewer. F Xiao, Q Liu, Y Qin, D Huang, Y Liao, 10.1016/j.heliyon.2024.e276962024. e2769610</p>
<p>. M A K Raiaan, M S H Mukta, K Fatema, N M Fahad, S Sakib, M M J Mim, J Ahmad, M E Ali, S Azam, 10.1109/ACCESS.2024.3365742A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges. IEEE Access. 122024</p>
<p>Using network analysis and large-language models to obtain a landscape of the literature on dressing materials for wound healing: The predominance of chitosan and other biomacromolecules: A review. J Klarak, A C M Brito, L F Moreira, F N Silva, D R Amancio, R Andok, M C F Oliveira, M Bardosova, O N Oliveira, Jr, 10.1016/j.ijbiomac.2025.141565Int. J. Biol. Macromol. 1415652025</p>
<p>OpenAlex Snapshot -openalex API Documentation. 26 April 2023</p>
<p>OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts. J Priem, H Piwowar, R Orr, V D Blondel, J L Guillaume, R Lambiotte, E Lefebvre, 10.1088/1742-5468/2008/10/P10008Filter Works -OpenAlex API Documentation. 2022. June 2025. 20 November 2023. 2008. 200810008Fast unfolding of communities in large networks</p>
<p>/ Maartengr, Keybert, Minimal keyword extraction with BERT. November 2023</p>
<p>Self-Supervised Contextual Keyword and Keyphrase Retrieval with Self-Labelling. P Sharma, Y Li, 10.20944/preprints201908.0073.v12019</p>
<p>Shape Classification and Analysis: Theory and Practice. L D F Costa, R M Cesar, Jr, 2018CRC PressBoca Raton, USA2nd ed</p>
<p>. R O Duda, P Hart, D Stork, 2001Wiley-InterscienceNew York, NYPattern Classification</p>
<p>. | Chatgpt, Openai, 30 April 2025</p>
<p>Gemini -Google Deepmind, ) Model -OpenAI API. 30 April 2025. August 2025. August 2025. August 202513) Model -OpenAI API</p>
<p>AI-Assisted Tools for Scientific Review Writing: Opportunities and Cautions. J C M C Silva, R P Gouveia, K M C Zielinski, M C F Oliveira, D R Amancio, O M Bruno, O N Oliveira, Jr, 10.1021/ACSAMI.5C08837?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asACS Appl. Mater. Interfaces. 172025</p>            </div>
        </div>

    </div>
</body>
</html>