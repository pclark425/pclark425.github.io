<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-179 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-179</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-179</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-9.html">extraction-schema-9</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how instruction tuning and explicit prompting (e.g., chain-of-thought or step-by-step reasoning) affect theory-of-mind task performance, including baseline comparisons, evaluation methods, improvements, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-6c35bc9be105ed59faf920e9d0f05f6aaa67c2ef</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e179.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e179.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how instruction tuning and explicit prompting (e.g., chain-of-thought or step-by-step reasoning) affect theory-of-mind task performance, including baseline comparisons, evaluation methods, improvements, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SimToM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulation Theory of Mind</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework designed to enhance Theory of Mind (ToM) capabilities in large language models (LLMs) through perspective-taking prompts and dynamic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large language model developed by OpenAI, known for its advanced reasoning capabilities and instruction tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unknown</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>perspective-taking prompts</td>
                        </tr>
                        <tr>
                            <td><strong>instruction_tuning_method</strong></td>
                            <td>none specified</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Theory of Mind tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring understanding and simulating mental states such as beliefs, intentions, and emotions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_scaffold</strong></td>
                            <td>73.3% accuracy in multi-interaction tasks</td>
                        </tr>
                        <tr>
                            <td><strong>performance_baseline</strong></td>
                            <td>71.2% accuracy in multi-interaction tasks</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>zero-shot evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reported_improvements</strong></td>
                            <td>Improved performance in multi-interaction scenarios and tasks requiring deeper contextual reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>scaffolding_effects</strong></td>
                            <td>Explicitly encourages perspective-taking, enhancing the model's ability to track shifts in dialogue and situational context.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Performance drops in simple ToM tasks and increased susceptibility to hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>experiment_details</strong></td>
                            <td>Evaluated models with and without SimToM in a zero-shot setting using a custom dataset of 1,025 annotated scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_baseline</strong></td>
                            <td>Models still struggle with tasks requiring abstract reasoning and implicit social understanding compared to human performance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e179.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e179.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how instruction tuning and explicit prompting (e.g., chain-of-thought or step-by-step reasoning) affect theory-of-mind task performance, including baseline comparisons, evaluation methods, improvements, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain of Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting method that encourages large language models to break down tasks into sequential steps to enhance reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o Mini</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A smaller variant of GPT-4, optimized for efficiency while maintaining strong performance on various tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>unknown</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>step-by-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>instruction_tuning_method</strong></td>
                            <td>none specified</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Theory of Mind tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks that require understanding and simulating mental states.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_scaffold</strong></td>
                            <td>Improved performance on belief-tracking and inference-based tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_baseline</strong></td>
                            <td>Performance metrics not specified for baseline comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>zero-shot evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reported_improvements</strong></td>
                            <td>Reduced errors and self-contradictions in belief-tracking tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>scaffolding_effects</strong></td>
                            <td>Facilitates step-by-step reasoning, aiding in complex mental state inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Does not fully address multi-agent interactions or long-term belief tracking.</td>
                        </tr>
                        <tr>
                            <td><strong>experiment_details</strong></td>
                            <td>Evaluated in conjunction with SimToM to assess combined effects on ToM reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_baseline</strong></td>
                            <td>Not explicitly compared to human performance.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>TOMBENCH: Benchmarking Theory of Mind in Large Language Models <em>(Rating: 2)</em></li>
                <li>Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities <em>(Rating: 2)</em></li>
                <li>Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-179",
    "paper_id": "paper-6c35bc9be105ed59faf920e9d0f05f6aaa67c2ef",
    "extraction_schema_id": "extraction-schema-9",
    "extracted_data": [
        {
            "name_short": "SimToM",
            "name_full": "Simulation Theory of Mind",
            "brief_description": "A framework designed to enhance Theory of Mind (ToM) capabilities in large language models (LLMs) through perspective-taking prompts and dynamic tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_description": "A large language model developed by OpenAI, known for its advanced reasoning capabilities and instruction tuning.",
            "model_size": "unknown",
            "prompting_technique": "perspective-taking prompts",
            "instruction_tuning_method": "none specified",
            "task_name": "Theory of Mind tasks",
            "task_description": "Tasks requiring understanding and simulating mental states such as beliefs, intentions, and emotions.",
            "performance_with_scaffold": "73.3% accuracy in multi-interaction tasks",
            "performance_baseline": "71.2% accuracy in multi-interaction tasks",
            "evaluation_method": "zero-shot evaluation",
            "reported_improvements": "Improved performance in multi-interaction scenarios and tasks requiring deeper contextual reasoning.",
            "scaffolding_effects": "Explicitly encourages perspective-taking, enhancing the model's ability to track shifts in dialogue and situational context.",
            "counter_evidence": "Performance drops in simple ToM tasks and increased susceptibility to hallucinations.",
            "experiment_details": "Evaluated models with and without SimToM in a zero-shot setting using a custom dataset of 1,025 annotated scenarios.",
            "comparison_to_human_baseline": "Models still struggle with tasks requiring abstract reasoning and implicit social understanding compared to human performance.",
            "uuid": "e179.0"
        },
        {
            "name_short": "CoT",
            "name_full": "Chain of Thought",
            "brief_description": "A prompting method that encourages large language models to break down tasks into sequential steps to enhance reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4o Mini",
            "model_description": "A smaller variant of GPT-4, optimized for efficiency while maintaining strong performance on various tasks.",
            "model_size": "unknown",
            "prompting_technique": "step-by-step reasoning",
            "instruction_tuning_method": "none specified",
            "task_name": "Theory of Mind tasks",
            "task_description": "Tasks that require understanding and simulating mental states.",
            "performance_with_scaffold": "Improved performance on belief-tracking and inference-based tasks.",
            "performance_baseline": "Performance metrics not specified for baseline comparison.",
            "evaluation_method": "zero-shot evaluation",
            "reported_improvements": "Reduced errors and self-contradictions in belief-tracking tasks.",
            "scaffolding_effects": "Facilitates step-by-step reasoning, aiding in complex mental state inferences.",
            "counter_evidence": "Does not fully address multi-agent interactions or long-term belief tracking.",
            "experiment_details": "Evaluated in conjunction with SimToM to assess combined effects on ToM reasoning.",
            "comparison_to_human_baseline": "Not explicitly compared to human performance.",
            "uuid": "e179.1"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "TOMBENCH: Benchmarking Theory of Mind in Large Language Models",
            "rating": 2
        },
        {
            "paper_title": "Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities",
            "rating": 2
        },
        {
            "paper_title": "Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition",
            "rating": 1
        }
    ],
    "cost": 0.00255675,
    "model_str": null
}</code></pre>
        </div>

    </div>
</body>
</html>