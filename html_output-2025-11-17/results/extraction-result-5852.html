<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5852 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5852</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5852</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-119.html">extraction-schema-119</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or AI systems being used to extract, discover, or distill quantitative laws, mathematical relationships, or empirical equations from large collections of scientific or scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-265466599</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.16733v4.pdf" target="_blank">LLMs for Science: Usage for Code Generation and Data Analysis</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have been touted to enable increased productivity in many areas of today's work life. Scientific research as an area of work is no exception: the potential of LLM-based tools to assist in the daily work of scientists has become a highly discussed topic across disciplines. However, we are only at the very onset of this subject of study. It is still unclear how the potential of LLMs will materialise in research practice. With this study, we give first empirical evidence on the use of LLMs in the research process. We have investigated a set of use cases for LLM-based tools in scientific research, and conducted a first study to assess to which degree current tools are helpful. In this paper we report specifically on use cases related to software engineering, such as generating application code and developing scripts for data analytics. While we studied seemingly simple use cases, results across tools differ significantly. Our results highlight the promise of LLM-based tools in general, yet we also observe various issues, particularly regarding the integrity of the output these tools provide.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5852",
    "paper_id": "paper-265466599",
    "extraction_schema_id": "extraction-schema-119",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00287075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLMs for Science: Usage for Code Generation and Data Analysis
23 Apr 2024</p>
<p>Mohamed Nejjar 
School of Computation, Information and Technology
Technical University of Munich
MunichGermany</p>
<p>Luca Zacharias 
School of Computation, Information and Technology
Technical University of Munich
MunichGermany</p>
<p>Fabian Stiehle fabian.stiehle@tum.de 
School of Computation, Information and Technology
Technical University of Munich
MunichGermany</p>
<p>Ingo Weber 
School of Computation, Information and Technology
Technical University of Munich
MunichGermany</p>
<p>Fraunhofer Gesellschaft
MunichGermany</p>
<p>School of Computation, Information
Technical University of Munich</p>
<p>LLMs for Science: Usage for Code Generation and Data Analysis
23 Apr 20245B376D275C4201F0CE17A334A9619A37arXiv:2311.16733v4[cs.SE]Received <day> <Month>, <year>; Revised <day> <Month>, <year>; Accepted <day> <Month>, <year> DOI: xxx/xxxxLarge language modelsArtificial intelligenceResearch methodsCode generationData analysisLLMs4ScienceGenAI4Science
Large language models (LLMs) have been touted to enable increased productivity in many areas of today's work life.Scientific research as an area of work is no exception: the potential of LLM-based tools to assist in the daily work of scientists has become a highly discussed topic across disciplines.However, we are only at the very onset of this subject of study.It is still unclear how the potential of LLMs will materialise in research practice.With this study, we give first empirical evidence on the use of LLMs in the research process.We have investigated a set of use cases for LLM-based tools in scientific research, and conducted a first study to assess to which degree current tools are helpful.In this paper we report specifically on use cases related to software engineering, such as generating application code and developing scripts for data analytics.While we studied seemingly simple use cases, results across tools differ significantly.Our results highlight the promise of LLM-based tools in general, yet we also observe various issues, particularly regarding the integrity of the output these tools provide.</p>
<p>INTRODUCTION AND BACKGROUND</p>
<p>With the public release of ChatGPT in November 2022, large language models (LLMs) attracted widespread public attention.LLMs are machine learning models, often based on neural networks following a pre-trained transformer architecture, which have many parameters and have been trained on a large corpus of training data. 1 At the time of writing, hundreds of billions of model parameters are not a rare occurrence, as is training data with a trillion tokens. 1 Besides various other use cases, the ability of LLMs to generate meaningful textual answers to natural-language text queries has captivated the imagination of many, with productivity use cases at the forefront.The scientific research community is no different here.In their global survey on the work of postdocs, Nature found that 31% of postdocs are already using AI-assisted chatbots like ChatGPT.Of those who use it, the two most reported use cases are text refinement and generating or troubleshooting code. 2 Among disciplines, the potential (and dangers) of LLM-based tools has quickly become a highly discussed topic, and has given rise to many editorial, opinion, and commentary pieces, with most expecting high productivity gains as the most promising outcome of utilising these tools. 3,4,5,6cientific work comprises many text-based tasks, such as reading and synthesizing publications, writing laboratory logs, creating code for software prototypes, data analysis, writing papers, and creating slide decks for presentations.A recent paper from the information systems discipline further lists tasks like problem formulation, research design, and data collection. 3All of these tasks could in principle be supported by LLM-based tools.We refer to this direction of research as LLMs4Science.LLMs are part of a new generation of artificial intelligence (AI) artifacts and methods, called generative AI, which further comprises AI that is able to generate images, videos, speech, music, and more.For the use of generative AI in science, we propose the term GenAI4Science.However, the use of such tools is subject to many-not yet well understood-risks.One major problem is commonly referred to as "hallucination"-though a more precise term is "confabulation" 7 -where an LLM seemingly fills gaps in the information contained in the model with plausibly-sounding words.Given their mode of operation, i.e., predicting the most likely next word from a neural network that has commonly been trained with a large corpus of text, the occurrence of this effect can be explained well.For application areas like scientific writing, this causes a significant issue: factual correctness is of utmost importance, and writing that does not adhere to the rigorous standards of scientific integrity should not be considered part of the body of scientific knowledge (for a negative example of a confabulating LLM in science, see Galactica in Section 2).</p>
<p>Despite problems, challenges, and past setbacks, the potential of LLMs to achieve increased productivity in science appears very high.However, we are only at the very onset of this subject of study.It is still unclear how the potential of LLMs will materialise in research practice.With this study, we give first empirical evidence on the use of LLMs in the research process.To this end, we examined around 20 use cases.In this paper, we focus on tasks related to programming specifically, as motivated by the context of scientific work.Accordingly, we focus on three prevalent use cases that involve coding, namely (i) writing programs, e.g., for software prototypes, (ii) data analysis, and (iii) data visualization.For those use cases, we explored to which degree they are supported by a number of current LLM-based tools, and report our findings.In addition, we provide an outlook on the broader set of use cases.Following open science principles, and to support replicability, we publish a replication package, recording all our interactions with the tools and our evaluation criteria. 2he remainder of the paper is structured accordingly.After discussing related work in Section 2, we present the methodology and results of the coding scenarios in Section 3. Finally, we provide the outlook on the larger picture of LLMs for science in Section 4, and close with a summary in Section 5.</p>
<p>CURRENT AND RELATED RESEARCH</p>
<p>The potential of using LLMs in aiding the research process is currently a highly discussed topic.In an editorial, Susarla et al. 3 explore the potential of LLMs in information systems research.They explore research question formulation, data collection, data analysis, and writing-as tasks in which LLMs could add benefit.Kasneci et al. 6 discuss the opportunities and challenges of using LLMs for education.They also briefly touch on the potential of LLMs to assist in the writing process of research papers, by generating summaries or outlines, and providing guidance on orthography.This discussion also takes place across disciplines.For example, Grossmann et al. 5 share their perspective on LLM's transformative use for social science research practices and Li et al. 4 comment on the ethical concerns related to their use in medicine and medical research.In their global survey on postdocs, Nature found that 31% of postdocs are already using AI-assisted chatbots like ChatGPT.Of those who use it, the two most reported use cases are text refinement and generating or troubleshooting code. 2 Beyond proprietary models, several open source LLMs exist, such as GPT-Neo 8 or GPT-J. 3There is also work focusing on training LLMs specifically for the use in a research context.SciBert 9 and ScholarBert 10 are both pre-trained language models based on a corpus of scientific publications.These models are evaluated based on their performance executing automated tasks related to scientific practice, such as classification or relation extraction.Galactica, 11 another large language model trained on scientific corpi, is a cautionary tale.Galactica was accessible online and meant to assist researchers in performing research tasks.The tool was taken down only days after its publication, following criticism over its tendency to hallucinate and confabulate. 12his highlights the need for rigorous research and evaluation practices.The search for comprehensive evaluation systems for LLMs is ongoing research. 13here exists also a growing body of work on LLMs trained on code.However, we have to note here that LLMs of code is an emergent research field, and a review in this space inadvertently involves a high amount of grey literature.While we carefully selected these, it is essential to exercise caution with non-peer-reviewed studies.The arguably most widely deployed proprietary model is Codex, as it is integrated within GitHub Copilot. 14Open source alternatives such as CodeParrot4 , CodeBert 15 , or PolyCoder 16 exist; however, their functional correctness with regard to code completion tasks is significantly lower compared to Codex. 16To assess functional correctness of code generation, Chen et al. present an evaluation framework: HumanEval. 14umanEval includes a Python data set of hand-written programming problems and several unit tests.Generated code is considered correct when it passes the associated unit tests.The fraction of passed samples is reported as a quantitative measure.Other quantitative evaluation frameworks have since then proposed, such as MBPP 17 or DS-1000 18 .The latter specifically targeting code generation for data science.These frameworks are used in multiple studies investigating the functional correctness. 16,19eyond correctness, Ouyang et al. 20 study the high degree of non-determinism in ChatGPT and Huang et al. 21present an assessment framework to detect social biases in code generation.Vaithilingam et al. 22 perform a user study to investigate how GitHub Copilot affects programming task completion times compared to a regular code completion tool.Their findings are surprising: "Copilot did not necessarily reduce the task completion time or increase the success rate of solving programming tasks in a realworld setting." 22Beyond quantitative metrics, Vaithilingam et al. find that study participants still prefer to use Copilot over a regular code completion tool.Conversely, Peng et al. 23 report productivity gains using Copilot of around 50%.This highlights the need for research investigating factors besides functional correctness.</p>
<p>We present a use case-based evaluation, across a wide range of proprietary tools.Our evaluation assesses quantitative and qualitative aspects of the generated code.While our use cases are seemingly simple, meaningful differences in how they are handled by different tools are discovered.Our results also highlight the capabilities of this class of tools at large.</p>
<p>LLM TOOLS FOR CODE GENERATION</p>
<p>Methodology</p>
<p>We selected a wide range of available LLM-based tools: ChatGPT with GPT 3.5, ChatGPT with GPT 4, Google Bard, Bing Chat, YouChat, GitHub Copilot, and GitLab Duo. 5 ChatGPT and Bing Chat are based on the generative pre-trained transformer (GPT). 24Google Bard is based on PaLM 25 , the specifics of YouChat are not known.GitHub Copilot is based on Codex, a GPT model trained on GitHub repositories. 14GitLab Duo is based on Claude 2, a proprietary model offered by Anthropic. 6To assess their capabilities in assisting researchers with coding tasks, we selected the following use cases.</p>
<ol>
<li>
<p>Code generation: Matrix multiplication in Java, using multi-threading.A complex aspect of object-oriented programming but which can be solved in a succinct manner.</p>
</li>
<li>
<p>Data analysis: Given some data, generate Python code to analyze the data provided through different tasks and questions.</p>
</li>
</ol>
<p>Data visualization:</p>
<p>Given some data, generate R code to visualise it in different ways.</p>
<p>The full prompts can be found in our replication package (see Footnote 2).For each use case, we used two variants of prompts, which were input independently by the authors of this paper.For the data analysis and visualisation cases, we used multiple consecutive prompts, each building on the context of the previous one.We then assessed the generated code based on the following general criteria.With Correctness, we report whether the code produces correct results, and whether human intervention was required to obtain correct code -that is, when the initial generated code was incorrect, we asked the tools to correct the errors.With Efficiency, we report on run time performance.For data analysis and visualisation tasks, we also report on the quality of the analysis and visualisation.With Comprehension, we give a measure on how hard or easy the code is to comprehend.</p>
<p>Here, we focus on the quality of comments and documentation the tool generated.We also report on the length of the generated code, as we observed significant differences across different tools.The assessment was done using an assessment rubric (see our replication package in Footnote 2), with well defined criteria, and in discussions among all authors.</p>
<p>Results</p>
<p>Code Generation
✓ × × × Efficiency Appropriate &amp; Accurate Analysis ✓ ✓ × × ✓ Benchmark (s) &lt; 1 &lt; 1 &lt; 1 &lt; 1 &lt; 1 Comprehensibility Code Commentary ✓ ✓ ✓ ✓ × Helpful Documentation ✓ ✓ ✓ ✓ ✓ Succinct Code ✓ × ✓ × × Overall Rating ★★★★ ★★★★ ★★★ ★★ ★★★
implementation, consequently, we were not able to rate it.We also tested a range of edge cases.Here again, most tools were able to handle all edge cases. 7We also benchmarked the generated code.We have conducted ten runs per tool.As input for each run, we randomly generated matrices sized 1000x1000.The reported result is the average of those ten runs.The runs were conducted on a consumer grade machine with an AMD Ryzen 7 5700U processor with a clock rate of 1.8 GHz, 8 cores, and 16 GB of RAM.Additionally, we compared the generated code to a manually created single threaded reference implementation.Compared to that, all tools were able to achieve a significant speed up with their multi-threaded implementation.Here, YouChat generated the most performant code; while Bing Chat is notably slower than the other tools.When it comes to comprehension, GitHub Copilot, Bing Chat, and YouChat did not generate any commentary or documentation along the code.However, compared to other tools, they generated rather succinct code.With the exception of GitLab Duo, all tools generated solid results.Google Bard showed weaknesses with respect to correctness, and Bing Chat with respect to performance.</p>
<p>Data Analysis and Data Visualisation</p>
<p>Tables 2 and 3 summarise our results for the data analysis and visualisation use cases, respectively.A specific challenge that we encountered in these use cases is the correct interpretation of data format and data type.For GitHub Copilot and GitLab Duo, we were not able to design a prompt that would lead to the desired results.We were not able to give them sufficient information about data format (e.g., table structure, cell names, ...) due to their focus on code completion, which makes interactive human intervention difficult.They only allow basic queries (A few words or at most one sentence) which specify the behaviour of a function.While the other tools also produced data type mismatch errors, they were able to correct their errors after intervention.A notable exception is GPT-4, which did not require any intervention for both use cases.When it comes to the efficiency of TABLE 3 Results for the data visualisation use case.Based on different criteria, we provide an overall qualitative rating (see our replication package for more detail) from one (★) to five stars (★★★★★).</p>
<p>Data Visualisation
GPT-3.5 GPT-4.0 Bing Chat Google Bard YouChat Correctness Correct without Intervention ✓ ✓ × × × Efficiency Quality of Generated Graph ★★ ★★★★ ★ ★ ★ Benchmark (s) &lt; 1 &lt; 1 &lt; 1 &lt; 1 &lt; 1 Comprehensibility Code Commentary ✓ ✓ ✓ ✓ ✓ Helpful Documentation ✓ ✓ ✓ ✓ ✓ Succinct Code × ✓ × × ✓ Overall Rating ★★★★ ★★★★★ ★★ ★ ★★★
the generated analysis, Bing Chat and Google Bard generated misleading results.For example, both ignored that we wanted to analyse profitability by department, not overall profitability. 8or data visualisation, GPT-4.0 generated graphs of consistent good quality.GPT-3.5 and YouChat generated good graphs in the majority of cases.Bing Chat and Google Bard generated misleading visualisations.For example, generating a heatmap of performance by person, instead of performance by department, as asked.Only GPT-4.0 included additional helpful indicators, such as regression lines for showcasing trends.As performance for data analysis and visualisation is not as critical as in production code, we only tested whether tools performed within a reasonable upper bound for our mostly small data sets.Overall, there was no tool which generated unreasonably slow code.Also, across most tools, generated commentary and documentation was of good quality.Overall, GPT-4.0 performed best for both cases.For data visualisation, it performed considerably better.Bing Chat and Google Bard had notable issues in generating accurate and appropriate analysis or visualisation, often producing misleading results and visuals.Surprisingly, Google Bard was not able to produce running code for some of our visualisation prompts.</p>
<p>Limitations and Threats to Validity</p>
<p>The research described above is early work, investigating a new subject of study, without established standards.The search for comprehensive evaluation systems for LLMs is ongoing research. 13We proposed a method, but assume that over the coming years the research community will define and incrementally refine standards.A major issues regarding the assessment of LLMs revolve around non-determinism. 20To mitigate associated threads, our results are based on two authors using the tools independently from each other with varying prompts.Our replication package contains full logs of each interaction.Most of our qualitative assessments, such as the quality of the generated graphs, are subjective.To address this, we performed independent assessments based on an assessment rubric, with well defined criteria.</p>
<p>OUTLOOK: LLMS FOR SCIENCE</p>
<p>In the previous sections, we focused on use cases related to code generation.Here we provide a broader view on additional use cases relevant to research practice, albeit from a high level of abstraction due to space limitations.The additional use cases we study are:</p>
<p>• Text enhancement: detecting orthography errors or inconsistent terminology, suggestions on writing style and structure, expanding or shortening text;</p>
<p>• Generation of summaries and comparing introduction and conclusion text with the body of a paper;</p>
<p>• Finding and suggesting additional literature, based on a given paper or parts thereof;</p>
<p>• Conversational interface to literature, be it collections or individual publications;</p>
<p>• Providing reviewer-like feedback to authors;</p>
<p>• Checking reviews against reviewing guidelines;</p>
<p>• Generating presentation slides (including graphics) from papers, and generating paper drafts from presentation slides.</p>
<p>Across the investigated use cases, our early results underline the potential of these tools to aid in the scientific process -specifically, in the process of writing.However, it is imperative to approach the outputs of these tools with caution.We repeatedly encountered instances of inaccuracies and confabulation, particularly in listed references.It was also surprising to observe that some LLMs had significant difficulties in addressing supposedly simple tasks.For instance, Google Bard faced challenges in expanding the content to a specific word limit and expanded it by a factor of three, while YouChat exhibited a tendency to detect grammar or spelling errors where none existed.We aim to report on these case in more detail in future work.</p>
<p>SUMMARY, DISCUSSION, AND FUTURE WORK</p>
<p>LLM-tools are already used in scientific practice and beyond.Given the substantial potential for increased productivity, we believe LLMs4Science and GenAI4Science are research topics of very high relevance.We elicited about 20 use cases in this category, and described our findings from assessing the three use cases related to programming.While we studied seemingly simple use cases, results across tools were vastly different.With some tools generating efficient code while others not being able to produce code that compiles, even with human intervention.Overall most tools performed well for the matrix multiplication case.However, more creative and context-specific tasks, like performing data analysis and visualisation over multiple consecutive queries, yielded more diverse results.As such, some tools had difficulty to pick up on important details, which lead to wrong and misleading analysis results.This highlights the danger for the integrity of results.Detecting such misleading statements can be challenging, especially when the abilities of the tools exceed the skills of the person using them.For example, we encountered visuals were the graph was labeled in the expected way -but closer investigation revealed that the wrong data was displayed.For more complex data, this can constitute a major challenge.The tendency to confabulate can substantially undermine the promised productivity gains, when results can not be relied upon.</p>
<p>In this paper, we focused on LLM-based tools, since we believe this is how most scientists would use such tools currently.The last author of this paper introduced such an LLM-based tool, called FhGenie, in June 2023 at Fraunhofer. 26 Fraunhofer is a German research society with over 70 institutes and approx.30,000 staff.FhGenie is actively used by several thousand researchers at the time of writing, and the (unstructured) feedback has been positive.At Fraunhofer, all users of FhGenie (and researchers in particular) are personally and solely responsible for their use of the outputs, primarily since confabulation cannot be prevented by any technical means in the current system.We believe this attribution of responsibility to be the right one for the foreseeable future, even when the chance of confabulation gets reduced.</p>
<p>In future work, we plan to study the use cases in more detail and develop our methodology further, applying it to larger collections of existing evaluation frameworks, such as HumanEval.We aim to investigate, to which degree our methodology can be supported by automation.While we have presented a first set of criteria that goes beyond pure functional correctness, this is by no means exhaustive.Further dimensions of importance must be studied, such as the tendency of LLMs to perpetuate biases.Using such tools responsibly should be at the forefront of considerations for researchers and developers alike.</p>
<p>Table 1
1
summarises our results for the matrix multiplication use case.Most tools were able to generate correct executing code on first attempt.Google Bard required human intervention.More severely, GitLab Duo was only able to generate a single-threaded</p>
<p>TABLE 1
1
Results for the matrix multiplication use case.Based on different criteria, we provide an overall qualitative rating (see our replication package for more detail) from one (★) to five stars (★★★★★).
Matrix MultiplicationGPT-3.5 GPT-4.0Bing ChatGoogle BardYouChatGitHub CopilotGitLab DuoCorrectnessCorrect without Intervention Handles Edge Cases✓ ✓✓ ✓  <em>✓ ✓  </em>× ×✓ ✓✓ ×--EfficiencyBenchmark (ms)4715791,899648446515-Code Commentary×××✓××-ComprehensibilityHelpful Documentation✓✓×✓××-Succinct Code××✓×✓✓-Overall Rating★★★★★★★★★★ ★★★★★★★★★★
* With the exception of the empty matrices edge case.</p>
<p>TABLE 2
2
Results for the data analysis use case.Based on different criteria, we provide an overall qualitative rating (see our replication package for more detail) from one (★) to five stars (★★★★★).
Data Analysis
https://en.wikipedia.org/wiki/Large_language_model#List, accessed
-11-03 <br />
https://github.com/luuca78/LLMs4Science
GPT-J, https://github.com/kingoflolz/mesh-transformer-jax, accessed 2023-10-23.
CodeParrot, https://huggingface.co/codeparrot/codeparrot, accessed 2023-10-23.
See https://chat.openai.com, https://bard.google.com, https://www.bing.com/new, https://about.you.com/youchat/, https://github.com/features/copilot, https://about.gitlab.com/gitlab-duo/, all accessed 2023-11-10. For ChatGPT with GPT 3.5 and ChatGPT with GPT 4, we will write GPT 3.5 and GPT 4, respectively. We conducted our experiments with the tools from 2023-10-24 till 2023-11-10.
https://www.anthropic.com/index/claude-2, accessed 2023-11-10
The edge cases comprised: empty matrices, single element matrices (vector), matrices with large numbers, rectangular matrices (where one dimension is much larger than the other), matrices with negative numbers, identity matrices, and incompatible matrices.
We have compiled some examples of misleading results for both use cases at https://github.com/luuca78/LLMs4Science.</p>
<p>Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. B Min, H Ross, E Sulem, ACM Comput. Surv. 5622023</p>
<p>How ChatGPT is transforming the postdoc experience. F Le, Nature. 6226552023</p>
<p>The Janus Effect of Generative AI: Charting the Path for Responsible Conduct of Scholarly Activities in Information Systems. A Susarla, R Gopal, J Thatcher, S Sarker, Information Systems Research. 342023</p>
<p>Ethics of large language models in medicine and medical research. H Li, J T Moon, S Purkayastha, L A Celi, H Trivedi, J W Gichoya, The Lancet Digital Health. 562023</p>
<p>AI and the transformation of social science research. I Grossmann, M Feinberg, D C Parker, N A Christakis, P E Tetlock, W A Cunningham, Science. 38066502023</p>
<p>ChatGPT for good? On opportunities and challenges of large language models for education. E Kasneci, K Seßler, S Küchemann, Learning and individual differences. 1031022742023</p>
<p>Hallucination or Confabulation? Neuroanatomy as metaphor in Large Language Models. A L Smith, F Greaves, T Panch, PLOS Digital Health. 2112023</p>
<p>Gpt-neox-20b: An open-source autoregressive language model. S Black, S Biderman, E Hallahan, arXiv:2204.067452022arXiv preprint</p>
<p>SciBERT: A pretrained language model for scientific text. I Beltagy, K Lo, A Cohan, arXiv:1903.106762019arXiv preprint</p>
<p>The Diminishing Returns of Masked Language Models to Science. Z Hong, A Ajith, J Pauloski, E Duede, K Chard, I Foster, 2023ACL. Association for Computational LinguisticsToronto, Canada</p>
<p>R Taylor, M Kardas, G Cucurull, arXiv:2211.09085A large language model for science. 2022</p>
<p>Why Meta's latest large language model survived only three days online. MIT Technology Review. W D Heaven, 14-11-20232022</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, arXiv:2307.031092023preprint</p>
<p>Evaluating large language models trained on code. M Chen, J Tworek, H Jun, arXiv:2107.033742021</p>
<p>Codebert: A pre-trained model for programming and natural languages. Z Feng, D Guo, D Tang, arXiv:2002.081552020arXiv preprint</p>
<p>A Systematic Evaluation of Large Language Models of Code. F F Xu, U Alon, G Neubig, V J Hellendoorn, MAPS 2022. New York, NY, USAACM. Association for Computing Machinery2022</p>
<p>Program synthesis with large language models. J Austin, A Odena, M Nye, arXiv:2108.077322021preprint</p>
<p>DS-1000: A natural and reliable benchmark for data science code generation. Y Lai, C Li, Y Wang, PMLR. 2023</p>
<p>L2CEval: Evaluating Language-to-Code Generation Capabilities of Large Language Models. A Ni, P Yin, Y Zhao, arXiv:2309.174462023arXiv preprint</p>
<p>LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation. S Ouyang, J M Zhang, M Harman, M Wang, arXiv:2308.028282023arXiv preprint</p>
<p>D Huang, Q Bu, J Zhang, X Xie, J Chen, H Cui, arXiv:2309.14345Bias Assessment and Mitigation in LLM-based Code Generation. 2023arXiv preprint</p>
<p>Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models. P Vaithilingam, T Zhang, E L Glassman, CHI EA '22. New York, NY, USAACM. Association for Computing Machinery2022Expectation vs</p>
<p>S Peng, E Kalliamvakou, P Cihon, M Demirer, arXiv:2302.06590The impact of ai on developer productivity: Evidence from github copilot. 2023arXiv preprint</p>
<p>GPT-3: Its Nature, Scope, Limits, and Consequences. Minds and Machines. L Floridi, M Chiriatti, 202030</p>
<p>Palm: Scaling language modeling with pathways. A Chowdhery, S Narang, J Devlin, arXiv:2204.023112022arXiv preprint</p>
<p>FhGenie: The Fraunhofer-Gesellschaft launches an internal AI chatbot. 14-11-20232023Fraunhofer Gesellschaft Press Release</p>            </div>
        </div>

    </div>
</body>
</html>