<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2405 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2405</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2405</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-270063373</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.16230v1.pdf" target="_blank">Active oversight and quality control in standard Bayesian optimization for autonomous experiments</a></p>
                <p><strong>Paper Abstract:</strong> The fusion of experimental automation and machine learning has catalyzed a new era in materials research, prominently featuring Gaussian Process Bayesian Optimization (GPBO) driven autonomous experiments navigating complex experimental conditions for accelerated scientific discovery. In traditional GPBO-driven experiments, a predefined scalarizer function is often required to preprocess the experimental data, transforming non-scalar raw data into scalar descriptors for GP training. However, such predefined scalarizer functions have limitations, which likely fail to accommodate the diversity and complexity of real-world experimental data, potentially skewing experimental outcomes. Thus, oversight and quality control are necessitated over the process to avoid GPBO from being misled by low quality scalarizers. To address the limitation, we introduce a Dual-GP approach that enhances traditional GPBO by adding a secondary surrogate model to dynamically constrain the experimental space based on real-time assessments of the raw experimental data. This Dual-GP approach enhances the optimization efficiency of traditional GPBO by isolating more promising space for BO sampling and more valuable experimental data for primary GP training. We also incorporate a flexible, human-in-the-loop intervention method in the Dual-GP workflow to adjust for unanticipated results. We demonstrate the effectiveness of the Dual-GP model with synthetic model data and implement this approach in autonomous pulsed laser deposition experimental data. This Dual-GP approach has broad applicability in diverse GPBO-driven experimental settings, providing a more adaptable and precise framework for refining autonomous experimentation for more efficient optimization.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2405.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2405.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dual-GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual Gaussian Process (Dual-GP) Observer-Constrained Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-GP workflow that pairs a primary GP-based Bayesian optimization surrogate with a secondary GP 'observer' that predicts raw-data quality/compatibility scores (e.g., SSI or human-provided scores) and dynamically constrains BO exploration to regions expected to yield high-quality scalarizers/data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Dual-GP observer-constrained Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The system couples (1) a primary GPBO surrogate (here implemented as a structured GP in some experiments) that models scalarized experimental objectives and selects next experiments via acquisition functions (e.g., uncertainty-based acquisition or Expected Improvement) with (2) a secondary GP trained on a quality metric derived from raw experimental outputs (e.g., Structural Similarity Index (SSI) to a reference spectrum or human quality scores). The second GP predicts a quality score across the input space and imposes hard or soft constraints on the primary GP's acquisition (for example setting acquisition to zero where predicted quality < threshold). This focuses experimental sampling on subspaces likely to yield meaningful scalarizers and filters out regions with noisy, distorted, or incompatible raw data. The workflow supports periodic human-in-the-loop scoring to train the observer GP when predefining a metric is infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials synthesis and characterization (demonstrated on PLD thin-film synthesis and synthetic spectral models), broadly applicable to autonomous experiments that convert non-scalar raw data into scalar descriptors (spectroscopy, imaging, multi-modal outputs).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate experimental trials by first predicting raw-data quality across the domain using the observer GP, then zeroing or down-weighting acquisition in regions predicted to produce low-quality scalarizers; within the remaining feasible region the primary GPBO selects points using standard acquisition (uncertainty-maximization for surrogate-building or EI for optimization). Seed experiments initialize both models; periodic retraining updates both GPs. Human scores can be incorporated periodically to refine the observer GP where no pre-defined metric exists.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Primary acquisition functions: uncertainty (GP predictive variance) used as an information-seeking metric for surrogate-building; Expected Improvement (EI) used for pure optimization tasks. The observer GP uses SSI or human score predictions to measure expected utility of sampling in a region by estimating probability of obtaining usable scalarizers.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Dual mechanism: (a) constraining exploration by the observer GP (hard constraint: acquisition set to zero if predicted quality below threshold, e.g., SSI < 0.3), effectively reducing exploration into low-value regions; (b) within the constrained region the primary acquisition balances exploration vs exploitation via uncertainty-maximization for surrogate coverage or EI for optimization. Thresholds are user-defined (examples: SSI cutoff 0.3; human-score cutoffs >7 then >5 in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity-promoting operator is introduced beyond the use of uncertainty-driven acquisition which promotes sampling where predictive variance is high; the observer GP indirectly promotes diversity by removing poor-quality pockets and allowing uncertainty-driven exploration elsewhere.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experiment budget (limited number of physical experiments/samples); discretized parameter space in demonstrations (e.g., 15^4 grid, 50–200 total experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Conserves budget by preventing sampling in regions predicted to produce low-quality or unusable scalarizers (hard-threshold masking of acquisition), thereby reallocating limited experiments to more informative regions; uses a small number of seed points (10 in examples) and runs for a bounded number of steps (e.g., 50 or 200 iterations in studies).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not explicitly defined as a separate 'breakthrough' score; success measured by improved surrogate reconstruction accuracy (RMSE of ground-truth surface reconstruction), faster convergence of structured mean parameters to ground truth, and improved quality of collected scalarizers (higher SSI / human scores).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported/illustrated metrics include RMSE of ground-truth reconstruction vs sample number, convergence speed of sGP mean-function parameters to ground truth (parameter estimates over iterations), number of samples (seed=10, runs of 50 or 200 steps), and thresholds applied (SSI cutoff 0.3; human-score cutoffs >7 then >5). No explicit FLOP/monetary cost figures are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single-GP BO (traditional GPBO using the same acquisition strategies) and random sampling; in PLD case primary comparisons were uncertainty-based exploration (UE) single-GP, Dual-GP+human, and random sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative and plot-based results: Dual-GP produced more accurate surrogate reconstructions and faster parameter convergence than single GPBO under noisy/distorted subspaces; in the PLD simulation Dual-GP with human assessment produced lower RMSE of ground-truth reconstruction vs sample number and 'quickly outperforms' random sampling and traditional GPBO when using uncertainty-based exploration. No precise numeric percent gains are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Qualitative gains: faster convergence of parameter estimates and RMSE reduction for the same number of samples; demonstrated to sample more usefully within tight budgets (e.g., 200 experiments representing 0.4% of discretized space). No explicit percentage reductions in experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Discusses qualitative trade-offs: pure uncertainty-driven exploration in high-dimensional sparse-data regimes can waste budget on poor-quality samples (frivolous exploration), while pure optimization (EI) may over-exploit narrow optima; Dual-GP trades off by filtering low-quality regions (reducing wasted cost) while permitting uncertainty-based exploration within predicted high-quality regions. Human-in-the-loop intervention is argued necessary when no reliable pre-defined quality metric exists. No formal quantitative multi-objective tradeoff curves are presented.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendations: use a secondary model predicting data/metric quality to mask or down-weight low-value regions so limited experiments are spent where scalarizers are reliable; combine this with acquisition functions chosen to match goals (uncertainty for surrogate coverage, EI for optimization); incorporate human scoring when pre-defined observer metrics are infeasible; set and adapt quality thresholds to control exploration scope (examples provided: SSI cutoff 0.3, human-score cutoffs).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active oversight and quality control in standard Bayesian optimization for autonomous experiments', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2405.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2405.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Human-in-the-loop Dual-GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Human-in-the-loop Dual Gaussian Process Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Dual-GP workflow variant where human experts periodically score raw experimental outputs; those scores train the observer GP which constrains BO exploration to regions expected to produce high-quality, informative data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Human-in-the-loop Dual-GP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>When no trustworthy automatic quality metric exists, the system prompts human experts at regular intervals (example: every 9 experiments) to rank recent raw outputs (scores 1–10). These human scores are used as training labels for the secondary GP, which predicts where future samples will yield high-quality raw data compatible with the scalarizer. The primary GPBO then restricts acquisition to subspaces predicted to have scores above a user-defined threshold (e.g., >3 during synthetic demo; >7 then >5 in PLD demonstration). This lets human judgment guide budget allocation while retaining automated acquisition within the filtered domain.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials synthesis and other experimental domains with complex raw outputs lacking reliable automatic scalarizers (demonstrated on synthetic spectral model and PLD thin-film synthesis datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate budget by combining periodic human assessment to update an observer GP and masking / constraining the primary GPBO acquisitions to regions predicted to be high-scoring by humans; human scoring cadence and thresholds are tunable to manage annotation cost and exploration scope.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Primary information metric remains GP predictive uncertainty (used to select points within constrained region) or EI for optimization; human scores act as a proxy for expected quality/information content of raw outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration is constrained by the human-trained observer GP which prevents sampling in regions humans deem unlikely to yield valuable data; within allowed domain the primary GP can operate in exploration (uncertainty maximization) or exploitation (EI) modes depending on experiment goals.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit additional diversity mechanism beyond uncertainty-driven acquisition; human scoring can implicitly promote diversity by rewarding novel or interesting raw outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Limited human annotation budget (human time to score) and limited experimental sample budget (physical experiments); demonstrated with periodic scoring every N experiments (N=9 in synthetic demo).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Trade annotation frequency vs information: periodic scoring conserves human time while still providing labels for the observer GP; constraints derived from human scores reallocate experimental budget away from low-quality regions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>No explicit novelty/breakthrough metric; human scoring can be tuned to reward unexpected/unusual results enabling discovery potential, and success measured indirectly via improved surrogate accuracy and qualitative identification of interesting spectra.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same surrogate RMSE and parameter convergence metrics as Dual-GP; human scoring cadence and thresholds (every 9 samples; threshold >3 or >7/>5) reported as experimental design parameters. No numeric improvement percentages isolated for human-in-the-loop alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against single-GP uncertainty-based exploration and random sampling in synthetic and PLD simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Human-in-the-loop Dual-GP yields better reconstruction RMSE vs sample number and faster convergence of parameter estimates than single-GP and random sampling in presented simulations; results are shown qualitatively/graphically without exact numeric effect sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Qualitative: reduces wasted sampling in distorted/noisy subspaces identified by humans and improves surrogate-building efficiency under tight budgets. No explicit percent or factor reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Notes tradeoffs between human annotation cost and improved sample efficiency: periodic human scoring reduces labeling cost while improving allocation; human judgment fills gaps where automatic metrics cannot be defined. No formal cost-benefit analysis provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Practical guidance: solicit human quality scores periodically (cadence adjustable), train an observer GP on those labels to constrain BO, and tune score thresholds to control exploration breadth; this preserves automated selection within a human-curated feasible set.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active oversight and quality control in standard Bayesian optimization for autonomous experiments', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2405.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2405.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>sGP + Acquisition Policies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured Gaussian Process (sGP) surrogate with uncertainty-based acquisition and Expected Improvement (EI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of a structured GP surrogate (mean function parameterized by known functional form and priors on parameters) combined with acquisition functions: uncertainty maximization for representative surrogate-building and Expected Improvement for optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Structured GP (sGP) with uncertainty-driven and EI acquisition strategies</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Primary surrogate is a structured GP where the mean function embeds a parameterized model form and priors over its parameters; inference updates parameter estimates as data arrive. Acquisition functions used include (a) uncertainty-based acquisition selecting next experiments by maximum GP predictive variance to build a representative surrogate and (b) Expected Improvement (EI) to seek optima when the goal is maximization. These choices determine how experimental budget is allocated between exploration and exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Demonstrated on parameter inference from spectral-amplitude models and thin-film synthesis response surfaces; generally applicable to experimental design and active learning in materials science and other physical sciences.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>When the aim is to learn the response surface, allocate experiments to maximize predictive uncertainty (information gain) across the feasible space; when the aim is to find optima, allocate experiments to maximize expected improvement over current best. The Dual-GP framework can mask portions of the domain before these acquisitions are evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uncertainty (GP predictive variance) as an information-seeking metric; EI as expected utility for optimization. No mutual information or formal information-theoretic acquisition (e.g., BALD) is used in the presented experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit selection of acquisition function based on experimental goal: uncertainty for exploration (surrogate coverage) vs EI for exploitation (optimization). The Dual-GP observer imposes additional feasibility constraints that bias allocation away from low-quality regions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Uncertainty-based acquisition promotes sampling in high-variance regions which tends to increase hypothesis diversity; no other explicit diversity regularizers described.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed sample budget for physical experiments; demonstration used small budgets typical for PLD (tens to a few hundred samples).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Choose acquisition function to match goal (uncertainty to get representative surrogate with few samples, EI to find maxima) and use observer-based masking to avoid wasting samples on poor-quality regions, thereby improving information-per-sample.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Implicit via EI (for optimization) or via identifying regions of unexpected raw-data (via human or SSI) that may indicate novel phenomena; not formulated as an explicit novelty/breakthrough score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Parameter convergence plots for the sGP mean-parameters; surrogate RMSE vs sample number when comparing acquisition schemes; number of iterations to reach acceptable parameter estimates (plots shown but no absolute numeric thresholds provided).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to same acquisition strategies without the observer GP (single-GP) and to random sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>sGP combined with Dual-GP observer and uncertainty acquisition produces faster parameter convergence and lower RMSE than sGP with a single GPBO or random sampling, as shown in simulation and PLD reconstructions. Exact numeric advantages are not enumerated.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Demonstrated reductions in wasted sampling (qualitative) and faster approach to ground truth parameter values when observer masking applied; no explicit percent reductions provided.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper emphasizes choosing acquisition to match experimental aim and using observer masking to trade exploration within fewer high-quality regions vs wasted exploration in low-quality regions; no formal multi-objective optimization analysis presented.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When samples are scarce and the aim is model-building, prefer uncertainty-based acquisition within an observer-constrained domain; for pure optimization use EI but still constrain sampling by expected scalarizer/data quality to avoid wasted trials.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active oversight and quality control in standard Bayesian optimization for autonomous experiments', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bayesian Optimization for Adaptive Experimental Design: A Review <em>(Rating: 2)</em></li>
                <li>Bayesian active learning for scanning probe microscopy: From Gaussian processes to hypothesis learning <em>(Rating: 2)</em></li>
                <li>Self-driving laboratory for accelerated discovery of thin-film materials <em>(Rating: 2)</em></li>
                <li>Bayesian reaction optimization as a tool for chemical synthesis <em>(Rating: 2)</em></li>
                <li>Human-machine collaboration for improving semiconductor process development <em>(Rating: 2)</em></li>
                <li>Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2405",
    "paper_id": "paper-270063373",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "Dual-GP",
            "name_full": "Dual Gaussian Process (Dual-GP) Observer-Constrained Bayesian Optimization",
            "brief_description": "A two-GP workflow that pairs a primary GP-based Bayesian optimization surrogate with a secondary GP 'observer' that predicts raw-data quality/compatibility scores (e.g., SSI or human-provided scores) and dynamically constrains BO exploration to regions expected to yield high-quality scalarizers/data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Dual-GP observer-constrained Bayesian optimization",
            "system_description": "The system couples (1) a primary GPBO surrogate (here implemented as a structured GP in some experiments) that models scalarized experimental objectives and selects next experiments via acquisition functions (e.g., uncertainty-based acquisition or Expected Improvement) with (2) a secondary GP trained on a quality metric derived from raw experimental outputs (e.g., Structural Similarity Index (SSI) to a reference spectrum or human quality scores). The second GP predicts a quality score across the input space and imposes hard or soft constraints on the primary GP's acquisition (for example setting acquisition to zero where predicted quality &lt; threshold). This focuses experimental sampling on subspaces likely to yield meaningful scalarizers and filters out regions with noisy, distorted, or incompatible raw data. The workflow supports periodic human-in-the-loop scoring to train the observer GP when predefining a metric is infeasible.",
            "application_domain": "Materials synthesis and characterization (demonstrated on PLD thin-film synthesis and synthetic spectral models), broadly applicable to autonomous experiments that convert non-scalar raw data into scalar descriptors (spectroscopy, imaging, multi-modal outputs).",
            "resource_allocation_strategy": "Allocate experimental trials by first predicting raw-data quality across the domain using the observer GP, then zeroing or down-weighting acquisition in regions predicted to produce low-quality scalarizers; within the remaining feasible region the primary GPBO selects points using standard acquisition (uncertainty-maximization for surrogate-building or EI for optimization). Seed experiments initialize both models; periodic retraining updates both GPs. Human scores can be incorporated periodically to refine the observer GP where no pre-defined metric exists.",
            "computational_cost_metric": null,
            "information_gain_metric": "Primary acquisition functions: uncertainty (GP predictive variance) used as an information-seeking metric for surrogate-building; Expected Improvement (EI) used for pure optimization tasks. The observer GP uses SSI or human score predictions to measure expected utility of sampling in a region by estimating probability of obtaining usable scalarizers.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Dual mechanism: (a) constraining exploration by the observer GP (hard constraint: acquisition set to zero if predicted quality below threshold, e.g., SSI &lt; 0.3), effectively reducing exploration into low-value regions; (b) within the constrained region the primary acquisition balances exploration vs exploitation via uncertainty-maximization for surrogate coverage or EI for optimization. Thresholds are user-defined (examples: SSI cutoff 0.3; human-score cutoffs &gt;7 then &gt;5 in experiments).",
            "diversity_mechanism": "No explicit diversity-promoting operator is introduced beyond the use of uncertainty-driven acquisition which promotes sampling where predictive variance is high; the observer GP indirectly promotes diversity by removing poor-quality pockets and allowing uncertainty-driven exploration elsewhere.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed experiment budget (limited number of physical experiments/samples); discretized parameter space in demonstrations (e.g., 15^4 grid, 50–200 total experiments).",
            "budget_constraint_handling": "Conserves budget by preventing sampling in regions predicted to produce low-quality or unusable scalarizers (hard-threshold masking of acquisition), thereby reallocating limited experiments to more informative regions; uses a small number of seed points (10 in examples) and runs for a bounded number of steps (e.g., 50 or 200 iterations in studies).",
            "breakthrough_discovery_metric": "Not explicitly defined as a separate 'breakthrough' score; success measured by improved surrogate reconstruction accuracy (RMSE of ground-truth surface reconstruction), faster convergence of structured mean parameters to ground truth, and improved quality of collected scalarizers (higher SSI / human scores).",
            "performance_metrics": "Reported/illustrated metrics include RMSE of ground-truth reconstruction vs sample number, convergence speed of sGP mean-function parameters to ground truth (parameter estimates over iterations), number of samples (seed=10, runs of 50 or 200 steps), and thresholds applied (SSI cutoff 0.3; human-score cutoffs &gt;7 then &gt;5). No explicit FLOP/monetary cost figures are reported.",
            "comparison_baseline": "Single-GP BO (traditional GPBO using the same acquisition strategies) and random sampling; in PLD case primary comparisons were uncertainty-based exploration (UE) single-GP, Dual-GP+human, and random sampling.",
            "performance_vs_baseline": "Qualitative and plot-based results: Dual-GP produced more accurate surrogate reconstructions and faster parameter convergence than single GPBO under noisy/distorted subspaces; in the PLD simulation Dual-GP with human assessment produced lower RMSE of ground-truth reconstruction vs sample number and 'quickly outperforms' random sampling and traditional GPBO when using uncertainty-based exploration. No precise numeric percent gains are provided.",
            "efficiency_gain": "Qualitative gains: faster convergence of parameter estimates and RMSE reduction for the same number of samples; demonstrated to sample more usefully within tight budgets (e.g., 200 experiments representing 0.4% of discretized space). No explicit percentage reductions in experiments reported.",
            "tradeoff_analysis": "Discusses qualitative trade-offs: pure uncertainty-driven exploration in high-dimensional sparse-data regimes can waste budget on poor-quality samples (frivolous exploration), while pure optimization (EI) may over-exploit narrow optima; Dual-GP trades off by filtering low-quality regions (reducing wasted cost) while permitting uncertainty-based exploration within predicted high-quality regions. Human-in-the-loop intervention is argued necessary when no reliable pre-defined quality metric exists. No formal quantitative multi-objective tradeoff curves are presented.",
            "optimal_allocation_findings": "Recommendations: use a secondary model predicting data/metric quality to mask or down-weight low-value regions so limited experiments are spent where scalarizers are reliable; combine this with acquisition functions chosen to match goals (uncertainty for surrogate coverage, EI for optimization); incorporate human scoring when pre-defined observer metrics are infeasible; set and adapt quality thresholds to control exploration scope (examples provided: SSI cutoff 0.3, human-score cutoffs).",
            "uuid": "e2405.0",
            "source_info": {
                "paper_title": "Active oversight and quality control in standard Bayesian optimization for autonomous experiments",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Human-in-the-loop Dual-GP",
            "name_full": "Human-in-the-loop Dual Gaussian Process Bayesian Optimization",
            "brief_description": "A Dual-GP workflow variant where human experts periodically score raw experimental outputs; those scores train the observer GP which constrains BO exploration to regions expected to produce high-quality, informative data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Human-in-the-loop Dual-GP",
            "system_description": "When no trustworthy automatic quality metric exists, the system prompts human experts at regular intervals (example: every 9 experiments) to rank recent raw outputs (scores 1–10). These human scores are used as training labels for the secondary GP, which predicts where future samples will yield high-quality raw data compatible with the scalarizer. The primary GPBO then restricts acquisition to subspaces predicted to have scores above a user-defined threshold (e.g., &gt;3 during synthetic demo; &gt;7 then &gt;5 in PLD demonstration). This lets human judgment guide budget allocation while retaining automated acquisition within the filtered domain.",
            "application_domain": "Materials synthesis and other experimental domains with complex raw outputs lacking reliable automatic scalarizers (demonstrated on synthetic spectral model and PLD thin-film synthesis datasets).",
            "resource_allocation_strategy": "Allocate budget by combining periodic human assessment to update an observer GP and masking / constraining the primary GPBO acquisitions to regions predicted to be high-scoring by humans; human scoring cadence and thresholds are tunable to manage annotation cost and exploration scope.",
            "computational_cost_metric": null,
            "information_gain_metric": "Primary information metric remains GP predictive uncertainty (used to select points within constrained region) or EI for optimization; human scores act as a proxy for expected quality/information content of raw outputs.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration is constrained by the human-trained observer GP which prevents sampling in regions humans deem unlikely to yield valuable data; within allowed domain the primary GP can operate in exploration (uncertainty maximization) or exploitation (EI) modes depending on experiment goals.",
            "diversity_mechanism": "No explicit additional diversity mechanism beyond uncertainty-driven acquisition; human scoring can implicitly promote diversity by rewarding novel or interesting raw outputs.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Limited human annotation budget (human time to score) and limited experimental sample budget (physical experiments); demonstrated with periodic scoring every N experiments (N=9 in synthetic demo).",
            "budget_constraint_handling": "Trade annotation frequency vs information: periodic scoring conserves human time while still providing labels for the observer GP; constraints derived from human scores reallocate experimental budget away from low-quality regions.",
            "breakthrough_discovery_metric": "No explicit novelty/breakthrough metric; human scoring can be tuned to reward unexpected/unusual results enabling discovery potential, and success measured indirectly via improved surrogate accuracy and qualitative identification of interesting spectra.",
            "performance_metrics": "Same surrogate RMSE and parameter convergence metrics as Dual-GP; human scoring cadence and thresholds (every 9 samples; threshold &gt;3 or &gt;7/&gt;5) reported as experimental design parameters. No numeric improvement percentages isolated for human-in-the-loop alone.",
            "comparison_baseline": "Compared against single-GP uncertainty-based exploration and random sampling in synthetic and PLD simulations.",
            "performance_vs_baseline": "Human-in-the-loop Dual-GP yields better reconstruction RMSE vs sample number and faster convergence of parameter estimates than single-GP and random sampling in presented simulations; results are shown qualitatively/graphically without exact numeric effect sizes.",
            "efficiency_gain": "Qualitative: reduces wasted sampling in distorted/noisy subspaces identified by humans and improves surrogate-building efficiency under tight budgets. No explicit percent or factor reported.",
            "tradeoff_analysis": "Notes tradeoffs between human annotation cost and improved sample efficiency: periodic human scoring reduces labeling cost while improving allocation; human judgment fills gaps where automatic metrics cannot be defined. No formal cost-benefit analysis provided.",
            "optimal_allocation_findings": "Practical guidance: solicit human quality scores periodically (cadence adjustable), train an observer GP on those labels to constrain BO, and tune score thresholds to control exploration breadth; this preserves automated selection within a human-curated feasible set.",
            "uuid": "e2405.1",
            "source_info": {
                "paper_title": "Active oversight and quality control in standard Bayesian optimization for autonomous experiments",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "sGP + Acquisition Policies",
            "name_full": "Structured Gaussian Process (sGP) surrogate with uncertainty-based acquisition and Expected Improvement (EI)",
            "brief_description": "Use of a structured GP surrogate (mean function parameterized by known functional form and priors on parameters) combined with acquisition functions: uncertainty maximization for representative surrogate-building and Expected Improvement for optimization tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Structured GP (sGP) with uncertainty-driven and EI acquisition strategies",
            "system_description": "Primary surrogate is a structured GP where the mean function embeds a parameterized model form and priors over its parameters; inference updates parameter estimates as data arrive. Acquisition functions used include (a) uncertainty-based acquisition selecting next experiments by maximum GP predictive variance to build a representative surrogate and (b) Expected Improvement (EI) to seek optima when the goal is maximization. These choices determine how experimental budget is allocated between exploration and exploitation.",
            "application_domain": "Demonstrated on parameter inference from spectral-amplitude models and thin-film synthesis response surfaces; generally applicable to experimental design and active learning in materials science and other physical sciences.",
            "resource_allocation_strategy": "When the aim is to learn the response surface, allocate experiments to maximize predictive uncertainty (information gain) across the feasible space; when the aim is to find optima, allocate experiments to maximize expected improvement over current best. The Dual-GP framework can mask portions of the domain before these acquisitions are evaluated.",
            "computational_cost_metric": null,
            "information_gain_metric": "Uncertainty (GP predictive variance) as an information-seeking metric; EI as expected utility for optimization. No mutual information or formal information-theoretic acquisition (e.g., BALD) is used in the presented experiments.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explicit selection of acquisition function based on experimental goal: uncertainty for exploration (surrogate coverage) vs EI for exploitation (optimization). The Dual-GP observer imposes additional feasibility constraints that bias allocation away from low-quality regions.",
            "diversity_mechanism": "Uncertainty-based acquisition promotes sampling in high-variance regions which tends to increase hypothesis diversity; no other explicit diversity regularizers described.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed sample budget for physical experiments; demonstration used small budgets typical for PLD (tens to a few hundred samples).",
            "budget_constraint_handling": "Choose acquisition function to match goal (uncertainty to get representative surrogate with few samples, EI to find maxima) and use observer-based masking to avoid wasting samples on poor-quality regions, thereby improving information-per-sample.",
            "breakthrough_discovery_metric": "Implicit via EI (for optimization) or via identifying regions of unexpected raw-data (via human or SSI) that may indicate novel phenomena; not formulated as an explicit novelty/breakthrough score.",
            "performance_metrics": "Parameter convergence plots for the sGP mean-parameters; surrogate RMSE vs sample number when comparing acquisition schemes; number of iterations to reach acceptable parameter estimates (plots shown but no absolute numeric thresholds provided).",
            "comparison_baseline": "Compared to same acquisition strategies without the observer GP (single-GP) and to random sampling.",
            "performance_vs_baseline": "sGP combined with Dual-GP observer and uncertainty acquisition produces faster parameter convergence and lower RMSE than sGP with a single GPBO or random sampling, as shown in simulation and PLD reconstructions. Exact numeric advantages are not enumerated.",
            "efficiency_gain": "Demonstrated reductions in wasted sampling (qualitative) and faster approach to ground truth parameter values when observer masking applied; no explicit percent reductions provided.",
            "tradeoff_analysis": "Paper emphasizes choosing acquisition to match experimental aim and using observer masking to trade exploration within fewer high-quality regions vs wasted exploration in low-quality regions; no formal multi-objective optimization analysis presented.",
            "optimal_allocation_findings": "When samples are scarce and the aim is model-building, prefer uncertainty-based acquisition within an observer-constrained domain; for pure optimization use EI but still constrain sampling by expected scalarizer/data quality to avoid wasted trials.",
            "uuid": "e2405.2",
            "source_info": {
                "paper_title": "Active oversight and quality control in standard Bayesian optimization for autonomous experiments",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bayesian Optimization for Adaptive Experimental Design: A Review",
            "rating": 2,
            "sanitized_title": "bayesian_optimization_for_adaptive_experimental_design_a_review"
        },
        {
            "paper_title": "Bayesian active learning for scanning probe microscopy: From Gaussian processes to hypothesis learning",
            "rating": 2,
            "sanitized_title": "bayesian_active_learning_for_scanning_probe_microscopy_from_gaussian_processes_to_hypothesis_learning"
        },
        {
            "paper_title": "Self-driving laboratory for accelerated discovery of thin-film materials",
            "rating": 2,
            "sanitized_title": "selfdriving_laboratory_for_accelerated_discovery_of_thinfilm_materials"
        },
        {
            "paper_title": "Bayesian reaction optimization as a tool for chemical synthesis",
            "rating": 2,
            "sanitized_title": "bayesian_reaction_optimization_as_a_tool_for_chemical_synthesis"
        },
        {
            "paper_title": "Human-machine collaboration for improving semiconductor process development",
            "rating": 2,
            "sanitized_title": "humanmachine_collaboration_for_improving_semiconductor_process_development"
        },
        {
            "paper_title": "Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process",
            "rating": 2,
            "sanitized_title": "physics_makes_the_difference_bayesian_optimization_and_active_learning_via_augmented_gaussian_process"
        }
    ],
    "cost": 0.012175749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Active oversight and quality control in standard Bayesian optimization for autonomous experiments</p>
<p>Sumner B Harris 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTennesseeUnited States</p>
<p>Rama Vasudevan 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTennesseeUnited States</p>
<p>Yongtao Liu 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTennesseeUnited States</p>
<p>Active oversight and quality control in standard Bayesian optimization for autonomous experiments
8C54CF3A452BDDA615CE99845690A59F
The fusion of experimental automation and machine learning has catalyzed a new era in materials research, prominently featuring Gaussian Process Bayesian Optimization (GPBO) driven autonomous experiments navigating complex experimental conditions for accelerated scientific discovery.In traditional GPBO-driven experiments, a predefined scalarizer function is often required to preprocess the experimental data, transforming non-scalar raw data into scalar descriptors for GP training.However, such predefined scalarizer functions have limitations, which likely fail to accommodate the diversity and complexity of real-world experimental data, potentially skewing experimental outcomes.Thus, oversight and quality control are necessitated over the process to avoid GPBO from being misled by low quality scalarizers.To address the limitation, we introduce a Dual-GP approach that enhances traditional GPBO by adding a secondary surrogate model to dynamically constrain the experimental space based on real-time assessments of the raw experimental data.This Dual-GP approach enhances the optimization efficiency of traditional GPBO by isolating more promising space for BO sampling and more valuable experimental data for primary GP training.We also incorporate a flexible, human-in-theloop intervention method in the Dual-GP workflow to adjust for unanticipated results.We demonstrate the effectiveness of the Dual-GP model with synthetic model data and implement this approach in autonomous pulsed laser deposition experimental data.This Dual-GP approach has broad applicability in diverse GPBO-driven experimental settings, providing a more adaptable and precise framework for refining autonomous experimentation for more efficient optimization.</p>
<p>Introduction</p>
<p>The combination of experimental automation and machine learning techniques has ushered in a transformative era of autonomous experimentation, revolutionizing materials research by accelerating scientific discovery through high-throughput processes and data-driven decisionmaking. 1 Bayesian Optimization 2 (BO) plays a pivotal role in autonomous experiments for efficient optimization of target (objective) properties and exploration across extensive experimental conditions. 3,4BO starts by making a statistical approximation of the unknown objective function in the experimental space, called a surrogate model, based on results from previously conducted experiments.The surrogate model for BO could be a random forest 5 or neural network 6,7 but is most commonly a Gaussian Process (GP) 8 due to its non-parametric nature and built-in uncertainty quantification 9,10 .Once the surrogate model is constructed, a variety of acquisition functions 11 can be calculated to determine the next set of experimental conditions that potentially reduce the surrogate's uncertainty, approach the global optimum, or maximize understanding of the system.Through this process, GPBO efficiently navigates vast experimental spaces, optimizing a target property or enhancing understanding with a minimum number of costly experiments.</p>
<p>GPBO has demonstrated applications in many materials science areas from theoretical predictions and materials design, to materials synthesis and characterization.GPBO has been used for the prediction of crystal structures 12,13 and for theoretical design of materials [14][15][16] .Autonomous synthesis methods that employ GPBO to efficiently optimize a target property vary from carbon nanotube growth [17][18][19] , chemical synthesis 20,21 , physical vapor deposition [22][23][24] , and additive manufacturing [25][26][27][28] .It has enabled autonomous exploration and discovery in piezoresponse force microscopy (PFM) [29][30][31] , scanning tunneling microscopy 32,33 , and scanning transmission electron microscopy 34 .</p>
<p>In the examples discussed above, a GP is utilized to map the relationship between inputs (e.g., chemical compositions, synthesis parameters, and characterization parameters) and outputs (e.g., target material properties).When target properties are quantifiable through scalar measurements, the scalar descriptors of target properties can be directly employed with the corresponding input parameters for GP training.However, in many real-world experiments, material properties are characterized from non-scalar data like spectroscopy, images, hyperspectral images, or higher dimensional and multi-modal data.This necessitates the use of "scalarizer functions" that derive meaningful scalar descriptors from the non-scalar raw data; subsequently, these scalar descriptors, instead of the raw data, are employed along with the corresponding measurement or synthesis parameters for GP training.</p>
<p>Scalarizer functions can vary from simple functions like peak identification 35 to custom algorithms for specific physical attributes like the coercive field from polarization-voltage hysteresis loops in PFM 29,36,37 or even pre-trained neural networks designed to reduce highdimensional data into simpler physical descriptors.Typically, in a GPBO driven experiment, a scalarizer function is predefined before the experiment based on prior knowledge or expectation of experiment outcomes; then, the same scalarizer function is applied throughout the entire GPBO driven experiment.However, a predefined scalarizer function often does not suffice for all scenarios due to the complexity of experimental data and lacks the flexibility for discovering unanticipated results.For example, a scalarizer used to identify the maximum peak intensity in spectroscopic data will fail to discern distinct spectra with peaks at different frequency and consequently will assign the identical scalar descriptor to peaks with different meanings (e.g.peaks with the same amplitude but at a different frequency).These can distort the true relationship between experiment conditions and target properties.Therefore, we need a quality control of the raw experiment results to check their compatibility with the predefined scalarizer function, in doing so, ensure the quality of the converted scalarizers and the training dataset.</p>
<p>To tackle the above challenges and limitations of scalarizer functions used in GPBO driven experimentation, we propose to use a 2 nd GP in tandem with the primary GPBO, as a solution to dynamically constrain the exploration space to areas that potentially produce more valuable results.This Dual-GP approach maintains the target property optimization driven by the traditional GPBO process and adds a 2 nd GP to dynamically constrain the experimental space based on observation of raw experimental data.The constraint of the 2 nd GP can be according to the compatibility between raw experimental data and scalarizer function, or the quality of the raw data, or additional assessment of material properties, etc.We also add an interface that allows human-in-the-loop intervention to account for unanticipated results.We demonstrate the application of the Dual GP in synthetic model data and experimental pulsed laser deposition (PLD) synthesis data; however, this approach can be applied to any other GPBO driven experiments as well.</p>
<p>Results and Discussion</p>
<p>The Dual-GP workflow Traditionally, as shown in Figure 1a, a single GP within a BO framework starts by assessing seed experiment conditions.The seed conditions are selected either randomly or by human choice.</p>
<p>In this GPBO driven experiment loop, it is the scalar physical descriptor rather than raw experiment data that is used for GPBO analysis.Therefore, defining a scalarizer function, based on prior knowledge, is a crucial step for deriving physical descriptors from raw experimental data.As previously discussed, pre-defined scalarizer functions may fail to apply meaningful descriptors to certain data, resulting in irrelevant or meaningless scalar values that contaminate the dataset and mislead the GP approximation and BO selection.Failure of a scalarizer function can arise from various factors, such as large noise in the spectra, the presence of outliers, or the emergence of new physical phenomena not accounted for by the pre-defined scalarizer function.Additionally, it is virtually impossible to form a robust scalarizer to handle data that we cannot anticipate.which provides a collection of experimental and computational data on hybrid organic-inorganic compounds (HOI).These figures specifically present experimental photoluminescence (PL) spectroscopy results for HOI including hybrid organic-inorganic perovskites (HOIPs).An essential application of HOIPs lies in photovoltaic and light-emitting devices, where tuning the bandgap is crucial for either enhancing light absorption for photovoltaics or achieving emitting light of a specific color for light emitting devices.The bandgap can be inferred from the PL emission wavelength, thus it has been used as a valuable physical descriptor for optimizing HOIPs bandgap 35 .The PL emission wavelength can be extracted from the raw spectrum by identifying the PL peak position, which can be accomplished using the find_peaks function in SciPy. 39This function allows users to customize parameters like peak height and width, and returns details of the identified peaks, including peak positions.Thus, we use this find_peaks function as a scalarizer function to convert PL raw spectrum to physical descriptor of emission wavelength, details regarding the analysis of these PL spectra and scalar descriptors conversion can be found in the Supplementary Notebook II that is also publicly available on GitHub.As indicated by the vertical red dashed lines in Figures 1b-g, the scalarizer function effectively identifies the wavelength of the highest peak.However, the quality of these scalarizers varies significantly.For instance, the scalarizers in Figures 1b and 1c are of high quality, where the raw PL spectra predominantly contain a single major peak. 40,41In contrast, scalarizers from Figures 1d-f reveal significant limitations: the scalarizer only marks the highest emission peak, failing to account for additional phenomena in the spectra-e.g., a secondary broad peak appearing after 400 nm in Figure 1d, 41 significant asymmetry of the peak in Figure 1e, 42 and a secondary shoulder peak in Figure 1f and 1g. 43,44These features, which involve additional physics like broad emission 41 , self-trapped exciton 42 , and ligand-contributed emissions 43,44 , are critical for bandgap engineering but are overlooked by the predefined scalarizer function.Notably, it is virtually impossible to define a scalarizer function that can capture all known physical phenomena in the raw results, let alone unknown aspects.</p>
<p>Therefore, the quality of scalar physical descriptors can significantly vary due to complexities in the raw experimental data.Using these descriptors of varying quality in a training set could potentially mislead the GPBO driven experiment; for instance, although Figure 1e and 1f result in similar scalarizers (415 nm vs. 418 nm), the exact materials' properties, which can be examined from the raw spectra, are significantly different.To address this issue, we propose to use a 2 nd GP as an observer, as shown in Figure 2, which assesses the quality of the raw data or its compatibility with the predefined scalarizer function to predict the applicability of the scalarizer function in the experimental space.This approximation can be used to assign a quality score to the experimental space, which examines relevance of the acquired raw data and the predefined scalarizer function.Subsequently the quality score can be used as a dynamic constraint on the exploration space, constraining the BO to focus on the space where the scalarizer is likely of high quality.This dynamic constraint has the potential to further accelerate the BO workflow by filtering out the space with low probability of acquiring useful data and low quality scalarizers.</p>
<p>Figure 2.</p>
<p>The workflow of a Dual-GP driven experiment.A 2nd GP analyzes the quality of resultant scalarizer, this quality can be obtained via examining the compatibility of the scalarizer function and the raw data.This prediction is used to actively refine the exploration space and modify the acquisition values.In doing so, the aim is to make the primary GPBO (which is driving experiment) avoid noisy or infeasible space.</p>
<p>We propose to design an observer function by comparing the on-the-fly raw experimental spectral data against a reference spectrum, this reference spectrum embodies the expected outcomes and is highly compatible with the predefined scalarizer function.The reference spectrum can be from seed experiments or theory.This comparison can be quantified by metrics such as Structural Similarity Index (SSI), Mean Square Error (MSE), etc., to assess whether the real time raw spectrum is compatible with the predefined scalarizer function.The 2 nd GP is trained on the metric and refines the experimental space to focus on regions likely to yield spectra relevant to the predefined scalarizer function.This strategy dynamically adjusts the exploration space of the primary GPBO with insights from the 2 nd GP, increasingly focusing on the space predicted to align with experimental goals.Thus, the integration of a 2 nd GP enables a dynamic, goal-aligned refinement of the experimental landscape, ensuring a more streamlined and efficient exploration.</p>
<p>Comparing single GPBO and Dual-GP BO</p>
<p>To illustrate how Dual-GP can discern and prioritize the experimental space, we conducted a numerical experiment using a synthetic spectrum model with varying noise and compared the single GP and Dual-GP methods' ability to reconstruct the ground truth and determine the model's parameters based on limited observations.Each input x produces a spectrum with a single Gaussian peak whose amplitude is given by equation 1:
𝑦 = (𝐴 + 𝐵𝑥) sin(10𝑥) + 𝐶(1)
where A = 0.5; B = -1.2;and C = 0.5.We introduced higher noise to the spectra in the range x ∈[0.7, 1.0] to simulate "bad" experimental measurement conditions.Consequently, the amplitude extracted by the scalarizer function deviates from the true function within this range, as shown in Figure 3a, which can potentially mislead the GPBO optimization.A few examples of spectra are presented in Figure 3b.We implemented a structured GP (sGP) 45 for the primary GP in order to predict the model parameters.In sGP, we structured the mean function of the GP with the functional form of the amplitude model and placed a prior distribution on the parameters.We refer Ref [ 45 ] for further interest in sGP.The scalarizer function is constructed with find_peaks method to extract the peak amplitude as the scalar physical descriptor and the BO used an uncertaintybased acquisition function that selects the next point based on maximum GP uncertainty.The quality metric for 2 nd GP training is quantified via SSI between measured spectra and a reference spectrum; this reference spectrum is an example of a low noise spectrum that has a good compatibility with the predefined scalarizer function and results in a scalarizer of high quality.The SSI of all synthetic spectra is in Supplementary Notebook II that is also publicly available in GitHub; high noise spectrum generally led to low SSI.The 2 nd GP is trained by the SSI of measured spectra and predicts the SSI in the unexplored space.Thus, the predicted SSI of the unexplored space indicates the possibility of the unexplored space to produce high quality scalarizers.The acquisition function of the primary GPBO is set to zero where the predicted SSI score &lt; 0.3, in doing so, a constraint is applied to the primary GPBO to only explore the space where the SSI score is larger than 0.3, which has a larger potential to produce high quality results and scalarizers.</p>
<p>Results for the single GP and Dual-GP are shown in Figure 3c and 3d, respectively, after 50 exploration steps.The single GPBO selected many points within the high noise subspace which reduce the GP surrogate's reconstruction accuracy, hence hindering the optimization process.In comparison, the 2 nd GP in the Dual-GP effectively identified that the subspace with high noise is the region  ∈ [0.7, 1.0], and hence ensures the primary GPBO avoids this subspace.Throughout exploration, the parameters of the structured mean function are updated to capture the underlying system behavior.Thus, by comparing the evolution of mean function parameters with the ground truth parameters, we can gain insights into the optimization process of single GP and Dual-GP.As shown in Figure 3e-g, the predicted parameters approach the ground truth quicker in Dual-GP driven optimization, indicating a more efficient optimization with Dual-GP.</p>
<p>Human in the loop</p>
<p>Above we used a predefined metric (i.e., SSI of raw experimental spectra to a reference spectrum) to assess the quality of raw experimental data and its compatibility with the predefined scalarizer function, this metric is defined according to our prior knowledge and/or anticipation of the experimental results.In some cases of real experiments, it is not possible to anticipate how the real-time experimental results will look like, and hence the quality of raw results cannot be assessed via a predefined metric; in these cases, real time human evaluation becomes an invaluable metric for determining the quality of the raw data and if it can yield meaningful scalarizers.To integrate human in the GPBO loop using the Dual-GP approach, human experts can review the collected raw spectral data and assign a quality score to each spectrum according to knowledge and/or interest.These scores, reflecting the relevance and the quality of the spectra, are then used to train the 2 nd GP.Incorporating human assessment in this manner offers significant flexibility and adaptability, making it a universally applicable approach in scenarios where prior knowledge and reasonable anticipation about the material system is limited or unavailable.</p>
<p>To demonstrate how the human in loop Dual-GP model can prioritize the experimental domain, we generated another synthetic spectral dataset using equation ( 1) with peak amplitude parameters A = 0.3; B = -1; and C = 0.5 and, instead of increased noise as before, we introduced random distortions which alter the raw spectra in the region  ∈ [0.3, 0.6], this random distortion to raw data is to mimic the 'unexpected' scenario in real experiment.The true amplitude function is shown in Figure 4a and the examples of distorted spectra are shown in Figure 4b.The assumption is that these distortions are unknown prior to experiment and cannot be reasonably represented by a predefined metric, necessitating real-time human assessment of the quality of raw spectra and their compatibility with the scalarizer function.We used the same sGP scheme and acquisition function as the previous experiment to demonstrate the human-in-loop Dual GP exploration of this model data.For the 2 nd GP, after every 9 (this can be modified by users) exploration steps, the human expert is prompted to rank the last 9 spectra from 1-10 with 10 being "good" and this score was given to the 2 nd GP to predict where high score spectra may be.Based on the prediction, the next iteration sampling is constrained in the subspace where the predicted score is &gt;3, which is likely to lead to higher quality experimental data.</p>
<p>Results for the single GP and Dual-GP are shown in Figure 4c and 4d, respectively, after 50 exploration steps.Again, the single GPBO fails to reconstruct the true function in the distorted subspace.In contrast, the 2 nd GP in the Dual-GP again identified that the distorted space is  ∈ [0.3, 0.59], which is well aligned with the ground truth  ∈ [0.3, 0.6].Subsequently, the Dual-GP workflow filtered out the acquired data from this subspace and constrained the exploration space to avoid sampling in this subspace.Through this approach, the Dual-GP effectively identifies valuable data, ensuring the primary GP focuses on high-quality spectra for more accurate and</p>
<p>Human in the loop Dual-GP for Real Experimental Data</p>
<p>After demonstrating the principle of Dual GP, we implemented this methodology in an autonomous PLD experiment data to assess its effectiveness for real world application.The full details of the autonomous PLD experiment can be found in our previous work 22 .Briefly, WSe2 thin films of nominally monolayer thickness were grown by PLD using co-ablation of WSe2 and Se targets varying 4 growth parameters: pressure (P), substrate temperature (T), and laser energy on the WSe2 and Se targets E1 and E2, respectively.The scalarizer function that was used was derived from the Raman spectrum of each film after growth and calculated as the ratio of the primary WSe2 E2g+A1g Raman peak height and width -a high "score" is achieved from intense, narrow peaks.Traditional GPBO was used to explore the 4D parameter space to maximize the Raman score using the expected improvement (EI) acquisition function.While this experiment was successful, the GPBO directed the synthesis of many films in regions of the parameter space that continually produced poor quality samples.This is because a high dimensional space populated with only 10s of samples results in high GP uncertainty and the BO tended to favor exploration.Because the growth window was narrow in at least 1 of the parameters, prolonged exploration led to numerous poor-quality samples.This effect is expected in traditional GPBO but when the maximum budget for total samples is small, as it is with PLD experiments, it is highly undesirable.Further, pure optimization is not always of interest for synthesis science.</p>
<p>Experimentalists usually want to understand the synthesis response surface to determine mechanisms of film growth.In this case, uncertainty-based acquisition is desired to achieve a representative GP surrogate, but human guidance is needed to prevent frivolous exploration.</p>
<p>In the Dual-GP PLD experiment, we used the final GP surrogate from the initial study to act as the "experimental ground truth" to evaluate the reconstruction error from uncertainty-based exploration (UE) using single GPBO, Dual-GP, and random sampling.For the quality score of raw data in Dual-GP, we constructed it by ranking 108 Raman spectra from the experiment to make approximation with a GP.During the human in the loop Dual-GP experiment, the quality score was sampled to train the 2 nd GP.With UE, the primary GPBO selects the next point based on maximum uncertainty.For each scenario, the same 10 samples were used as seed points.In the Dual-GP case, the exploration is constrained in the subspace where the quality score is &gt;7 for the first 50 steps and &gt; 5 after that.The parameter space was discretized into 15x15x15x15 to have 50625 possible combinations of parameters.Each experiment was run for 200 steps, sampling 0.4% of the total space.It should be noted that the goal of this synthesis simulation was not to locate the maximum as quickly as possible but rather to quickly build an effective surrogate model for the synthesis space with sparse sampling.The role of the human in this scenario is to assess the raw experimental data, this assessment can be used to dynamically adjust the feasible space while still allowing for uncertainty-based exploration.These results indicate that Dual-GP with human assessment can lead to more efficient optimization in experiments.</p>
<p>Conclusions</p>
<p>In summary, we demonstrate that the Dual-GP approach represents an advancement in GPBO driven autonomous experimentation, addressing a key limitation inherent to GPBO applications in real world experiments.By introducing a 2 nd GP to dynamically constrain the experimental space based on the observation of raw experimental results, the Dual-GP approach mitigates the shortcomings of traditional GPBO optimization and enhances the adaptability and accuracy of the optimization process.This approach effectively isolates more promising experimental spaces for BO sampling and improves the quality of obtained data.Furthermore, we also developed a strategy for human-in-the-loop Dual GP optimization, allowing experts to assess and adjust experiments, ensuring that unanticipated scenarios in real world experiments are appropriately managed.It has also been shown that similar human-AI collaboration improves semiconductor process development efficiency 46 .The demonstrated application of the Dual-GP approach in both synthetic and real-world experimental settings indicate its potential in broad autonomous experiments across various domains.For materials developments that are expensive, time consuming, and difficult to automate, the Dual-GP approaches is an effective technique to rapidly understand quantitative trends of material properties vs. experimental conditions in large parameter spaces with a minimal number of samples by effectively infusing human expertise into the autonomous workflow.The Dual-GP approach can also be used to incorporate on-the-fly experimentation in autonomous platforms, offline in-depth investigation, and theory, etc., enabling cross-facilities, asynchronous co-optimization for accelerated research. 47</p>
<p>Figure</p>
<p>Figure 1b-g showcases the use of a scalarizer function to transform raw data into a scalar descriptor, illustrating the limitations of a predefined scalarizer function in analyzing experimental results.The raw spectral data displayed in Figure 1b-g are from the HybriD3 materials database, 38</p>
<p>Figure 1 .
1
Figure 1.The workflow of GPBO driven experiments.(a), The workflow for traditional GPBO driven experiments starts with a few seed experimental conditions; performing experiments followed by preprocessing of converting the raw experimental data to scalar physical descriptors using a predefined scalarizer function; then the experiment conditions and scalar descriptors form a trainset to train a GP (surrogate model); next acquisition function determines the next experimental conditions based on the GP prediction and uncertainty.(b-g), examples of raw experimental photoluminescence (PL) results of hybrid organic inorganic compounds and corresponding scalar descriptors.The find_peaks function in SciPy is used as a scalarizer function to convert raw PL to scalar descriptor of emission wavelength.(b-c) shows scalar descriptors of high quality, while the scalar descriptors (that only represent the wavelength of the highest PL peak) in (d-g) miss crucial information in the raw spectra.This variation in scalarizer quality can mislead the GPBO driven experiments.</p>
<p>Figure 3 .
3
Figure 3. Dual-GP driven exploration in a simulated scenario where a sub-space contains high noise.(a) amplitude of the synthetic peak model data for the Dual-GP test, here the noise quickly increases when x &gt; 0.7, leading to resultant scalarizers diverging from the true function.(b) Examples of a good raw spectrum and noisy spectra.(c) Single GP exploration result after 50 iterations, (d) Dual-GP exploration result after 50 iterations.(e-g) Show the sGP parameter prediction of Dual-GP approaches the true values more quickly than the single GP.</p>
<p>efficient optimization.A comparison of true function parameters predicted by the single GP and Dual-GP is shown in Figure 4e-g, with Dual-GP demonstrating better estimations of all three parameters, suggesting the potential of Dual-GP with human assessment for accelerated and efficient optimization.</p>
<p>Figure 4 .
4
Figure 4. Human in the loop of Dual-GP exploration.(a) Amplitude of the synthetic peak model data, random distortion is added in the raw data in the space  ∈ [0.3, 0.6], leading to resultant scalarizers diverging from the true function.(b) Examples of a good raw spectrum and distorted spectra.(c) Single GP exploration result after 50 iterations, (d) Dual-GP exploration result after 50 iterations, here human experts assess raw spectra every 9 iterations (this can be flexible) and assign</p>
<p>Figure 5 .
5
Figure 5. Simulated Dual-GP, human in the loop, uncertainty-based exploration in 4D space using experimental data from an autonomous PLD experiment.(a-b) The ground truth response surface projected into the P vs. T and E1 vs. E2 planes.(c-d) The Dual-GP reconstruction closely matches the ground truth.(e-f) Random sampling performs better than (e-f) pure uncertainty exploration with traditional GPBO.The points in each map represent sampled points, where red color indicates a high score.The axes of each map are normalized.(i) The root mean squared error of ground truth reconstruction vs sample number for all three cases shows that human in the loop Dual-GP quickly outperforms random sampling and traditional GPBO when using uncertainty-based exploration, which is attractive for synthesis science applications where pure optimization is not the goal of the experiment.</p>
<p>AcknowledgementsThis research was supported by the Center for Nanophase Materials Sciences (CNMS), which is a US Department of Energy, Office of Science User Facility at Oak Ridge National Laboratory.Data AvailabilityThe data and code of this study is provided in the https://github.com/yongtaoliu/dual-GP.git.The approach is built using GPax https://gpax.readthedocs.io/en/latest/.This manuscript has been authored by UT-Battelle, LLC, under Contract No. DE-AC0500OR22725 with the U.S. Department of Energy.The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, worldwide license to publish or reproduce the published form of this manuscript, or allow others to do so, for the United States Government purposes.The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (https://www.energy.gov/doe-public-access-plan).Conflict of InterestThe authors declare no conflict of interest.Authors ContributionY.L. conceived the idea.Y.L. performed the investigation.S.H. performed PLD experiment and data analysis.All authors contributed to discussions and manuscript editing.
Autonomous experimentation systems for materials development: A community perspective. E Stach, Matter. 42021</p>
<p>Bayesian Optimization for Adaptive Experimental Design: A Review. S Greenhill, S Rana, S Gupta, P Vellanki, S Venkatesh, 10.1109/ACCESS.2020.2966228IEEE Access. 82020</p>
<p>Bayesian active learning for scanning probe microscopy: From Gaussian processes to hypothesis learning. M Ziatdinov, Y Liu, K Kelley, R Vasudevan, S V Kalinin, ACS nano. 162022</p>
<p>Benchmarking the performance of Bayesian optimization across multiple experimental materials science domains. Q Liang, Computational Materials. 71882021</p>
<p>Rapid Data-Efficient Optimization of Perovskite Nanocrystal Syntheses through Machine Learning Algorithm Fusion. C Lampe, 10.1002/adma.202208772Advanced Materials. 3522087722023</p>
<p>Self-driving laboratory for accelerated discovery of thin-film materials. B P Macleod, 10.1126/sciadv.aaz8867Science Advances. 688672020</p>
<p>Artificial Chemist: An Autonomous Quantum Dot Synthesis Bot. R W Epps, 10.1002/adma.202001626Advanced Materials. 322001626. 2020</p>
<p>M Frean, P Boyle, AI 2008: Advances in Artificial Intelligence. Wayne Wobcke, &amp; Mengjie Zhang, Berlin HeidelbergSpringer</p>
<p>Autonomous materials discovery driven by Gaussian process regression with inhomogeneous measurement noise and anisotropic kernels. M M Noack, 10.1038/s41598-020-74394-1Scientific Reports. 10176632020</p>
<p>Gaussian processes for autonomous data acquisition at large-scale synchrotron and neutron facilities. M M Noack, 10.1038/s42254-021-00345-yNature Reviews Physics. 32021</p>
<p>A Taxonomy of Global Optimization Methods Based on Response Surfaces. D R Jones, 10.1023/A:1012771025575Journal of Global Optimization. 212001</p>
<p>Crystal structure prediction accelerated by Bayesian optimization. T Yamashita, 10.1103/PhysRevMaterials.2.013803Physical Review Materials. 2138032018</p>
<p>COMBO: An efficient Bayesian optimization library for materials science. T Ueno, T D Rhone, Z Hou, T Mizoguchi, K Tsuda, 10.1016/j.md.2016.04.001Materials Discovery. 42016</p>
<p>Multi-fidelity machine-learning with uncertainty quantification and Bayesian optimization for materials design: Application to ternary random alloys. A Tran, J Tranchida, T Wildey, A P Thompson, 10.1063/5.0015672The Journal of Chemical Physics. 153747052020</p>
<p>Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules. R Gómez-Bombarelli, 10.1021/acscentsci.7b00572ACS Central Science. 42018</p>
<p>Bayesian optimization for accelerated drug discovery. E O Pyzer-Knapp, 10.1147/JRD.2018.2881731IBM Journal of Research and Development. 6272018</p>
<p>Efficient Closed-loop Maximization of Carbon Nanotube Growth Rate using Bayesian Optimization. J Chang, 10.1038/s41598-020-64397-3Scientific Reports. 1090402020</p>
<p>Advanced machine learning decision policies for diameter control of carbon nanotubes. R Rao, 10.1038/s41524-021-00629-yComputational Materials. 71572021</p>
<p>Gaussian Process Surrogate Modeling Under Control Uncertainties for Yield Prediction of Carbon Nanotube Production Processes. C Park, R Rao, P Nikolaev, B Maruyama, 10.1115/1.4051915Journal of Manufacturing Science and Engineering. 1442021</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. B J Shields, 10.1038/s41586-021-03213-yNature. 5902021</p>
<p>Gaussian Process Regression for Materials and Molecules. V L Deringer, 10.1021/acs.chemrev.1c00022Chemical Reviews. 1212021</p>
<p>Autonomous Synthesis of Thin Film Materials with Pulsed Laser Deposition Enabled by In Situ Spectroscopy and Automation. S B Harris, 10.1002/smtd.202301763Small Methods. 823017632024</p>
<p>Autonomous materials synthesis by machine learning and robotics. R Shimizu, S Kobayashi, Y Watanabe, Y Ando, T Hitosugi, 10.1063/5.0020370APL Materials. 81111102020</p>
<p>Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission. D M Fébba, 10.1063/5.0159406APL Materials. 11711192023</p>
<p>Toward autonomous additive manufacturing: Bayesian optimization on a 3D printer. J R Deneault, 10.1557/s43577-021-00051-1MRS Bulletin. 462021</p>
<p>A Bayesian experimental autonomous researcher for mechanical design. A E Gongora, 10.1126/sciadv.aaz1708Science Advances. 617082020</p>
<p>K L Snapp, arXiv:2308.02315Autonomous Discovery of Tough Structures. 2023</p>
<p>Physics Constrained Multi-objective Bayesian Optimization to Accelerate 3D Printing of Thermoplastics. K Sattari, 2023</p>
<p>Experimental discovery of structure-property relationships in ferroelectric materials via active learning. Y Liu, 10.1038/s42256-022-00460-0Nature Machine Intelligence. 42022</p>
<p>Automated Experiments of Local Non-Linear Behavior in Ferroelectric Materials. Y Liu, 10.1002/smll.202204130Small. 1822041302022</p>
<p>Exploring the Relationship of Microstructure and Conductivity in Metal Halide Perovskites via Active Learning-Driven Automated Scanning Probe Microscopy. Y Liu, 10.1021/acs.jpclett.3c00223The Journal of Physical Chemistry Letters. 142023</p>
<p>Autonomous scanning probe microscopy investigations over WS2 and Au{111}. J C Thomas, 10.1038/s41524-022-00777-9Computational Materials. 8992022</p>
<p>Autonomous convergence of STM control parameters using Bayesian optimization. G Narasimha, S Hus, A Biswas, R Vasudevan, M Ziatdinov, 10.1063/5.0185362APL Machine Learning. 2161212024</p>
<p>Physics Discovery in Nanoplasmonic Systems via Autonomous Experiments in Scanning Transmission Electron Microscopy. K M Roccapriore, S V Kalinin, M Ziatdinov, 10.1002/advs.202203422Advanced Science. 922034222022</p>
<p>S L Sanchez, arXiv:2310.06583Physics-driven discovery and bandgap engineering of hybrid perovskites. 2023arXiv preprint</p>
<p>Learning the right channel in multimodal imaging: automated experiment in piezoresponse force microscopy. Y Liu, Computational Materials. 9342023</p>
<p>Explainability and human intervention in autonomous scanning probe microscopy. Y Liu, M A Ziatdinov, R K Vasudevan, S V Kalinin, Patterns. 42023</p>
<p>SciPy 1.0: fundamental algorithms for scientific computing in Python. P Virtanen, Nature methods. 172020</p>
<p>Structural, photophysical, and electronic properties of CH3NH3PbCl3 single crystals. H.-P Hsu, L.-C Li, M Shellaiah, K W Sun, Scientific reports. 9133112019</p>
<p>Two-dimensional lead (II) halide-based hybrid perovskites templated by acene alkylamines: crystal structures, optical properties, and piezoelectricity. K.-Z Du, Inorganic chemistry. 562017</p>
<p>Highly efficient white-light emission in a polar two-dimensional hybrid perovskite. S Wang, Chemical communications. 542018</p>
<p>Novel〈 110∟-Oriented Organic− Inorganic Perovskite Compound Stabilized by N-(3-Aminopropyl) imidazole with Improved Optical Properties. Y Li, Chemistry of materials. 182006</p>
<p>Stereochemically active lead chloride enantiomers mediated by homochiral organic cation. L.-L Zhu, Polyhedron. 1582019</p>
<p>Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process. M A Ziatdinov, A Ghosh, S V Kalinin, Machine Learning: Science and Technology. 3150032022</p>
<p>Human-machine collaboration for improving semiconductor process development. K J Kanarik, 10.1038/s41586-023-05773-7Nature. 6162023</p>
<p>Delocalized, asynchronous, closed-loop discovery of organic laser emitters. F Strieth-Kalthoff, Science. 38492272024</p>            </div>
        </div>

    </div>
</body>
</html>