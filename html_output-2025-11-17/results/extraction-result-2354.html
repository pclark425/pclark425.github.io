<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2354 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2354</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2354</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-3fb4c5ce7dcbd708776826a935aba10b7dc04bfc</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3fb4c5ce7dcbd708776826a935aba10b7dc04bfc" target="_blank">Deep learning of causal structures in high dimensions under data limitations</a></p>
                <p><strong>Paper Venue:</strong> Nature Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> A deep neural network approach combining convolutional and graph models intended for causal learning in high-dimensional biomedical problems is introduced, which supports the notion that deep learning approaches can be used to learn causal networks at large scale.</p>
                <p><strong>Paper Abstract:</strong> Causal learning is a key challenge in scientific artificial intelligence as it allows researchers to go beyond purely correlative or predictive analyses towards learning underlying cause-and-effect relationships, which are important for scientific understanding as well as for a wide range of downstream tasks. Here, motivated by emerging biomedical questions, we propose a deep neural architecture for learning causal relationships between variables from a combination of high-dimensional data and prior causal knowledge. We combine convolutional and graph neural networks within a causal risk framework to provide an approach that is demonstrably effective under the conditions of high dimensionality, noise and data limitations that are characteristic of many applications, including in large-scale biology. In experiments, we find that the proposed learners can effectively identify novel causal relationships across thousands of variables. Results include extensive (linear and nonlinear) simulations (where the ground truth is known and can be directly compared against), as well as real biological examples where the models are applied to high-dimensional molecular data and their outputs compared against entirely unseen validation experiments. These results support the notion that deep learning approaches can be used to learn causal networks at large scale. Learning causal relationships between variables in large datasets is an outstanding challenge in various scientific applications. Lagemann et al. introduce a deep neural network approach combining convolutional and graph models intended for causal learning in high-dimensional biomedical problems.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2354.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2354.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>D2CL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Discriminative Causal Learning (D^{2}CL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end deep neural architecture that learns binary indicators of causal relations between variable pairs by combining distributional features (CNN on KDE images) and structural features (GNN on local subgraphs), trained in a supervised way using available prior causal labels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Causal structure learning; biomedical genomics applications (gene regulatory effects)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Learn directed binary indicators of causal influence between pairs of observed variables (direct or indirect/ancestral causal edges) from high-dimensional observational data X together with partial prior causal knowledge Π; produce a global graph estimate spanning thousands of variables and validate against unseen interventional experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>High-dimensional observational data available; in simulations synthetic datasets of size e.g. p=1500 with n up to 1024 were used; real biological data comprised gene expression measurements with n≈706 and p up to 5535, plus a set of interventional experiments used only for validation. Prior causal labels Π are available for a subset of pairs (labels are supervised) and are disjoint from test pairs; data for test pairs are not provided as interventions during training. The paper also studies varying numbers of available interventions m and varying sample size n to probe data-efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional tabular multivariate data (n × p), transformed to: (1) pairwise 2D KDE images (bivariate density grid) fed to CNN; (2) graph-structured inputs (local 1-hop enclosing subgraphs) fed to a GNN. Data include observational measurements; interventional experiments exist for validation but are not used as training inputs for the test pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: dimensionality up to thousands of variables (p up to 5535), enormous number of ordered pairs K ≈ p^2, nonlinear generative mechanisms (mixture of linear, MLPs, tanh, leaky ReLU, polynomials), presence of noise (varied SNR), latent variables in real biological data, and combinatorially large search space for graphs; computationally intensive training (deep CNN and GNN; multi-GPU training over 100 epochs).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied domain (molecular biology / genomics) is mature with substantial prior knowledge available for subsets of relationships; however causal discovery in this domain remains challenging due to latent variables and complex nonlinear mechanisms. The paper leverages existing experimental datasets (gene-deletion studies) as gold-standard validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — the goal is causal/ mechanistic understanding (direct or indirect causal influences) rather than purely predictive black-box outputs; outputs are intended to be interpretable as directed causal indicators and are validated against laboratory interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>End-to-end deep neural architecture combining convolutional neural networks (CNN) and graph neural networks (GNN); supervised discriminative learning for causal link classification (D^{2}CL).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Architecture: two-tower model. CNN tower: takes bivariate kernel density estimate (KDE) images computed from the n×2 columns for each ordered pair (i,j) (asymmetric KDE for direction), with positional encodings concatenated channel-wise; a ResNet-like stem and five-stage ResNet-54-inspired network (with bottleneck 1×1 convs and PReLU activations, pre-activation blocks) produces an embedding. GNN tower: based on SEAL/GCNN ideas — for each pair (i,j) extract 1-hop enclosing subgraph from an initial graph estimate Ĝ_0, assign Double-Radius Node Labels (DRNL) and include per-node data features, process by 4 graph convolutional layers (tanh activation), SortPooling to fixed-size node set and 1D convolutions to produce an embedding. Embedding fusion: concatenation of CNN and GNN embeddings followed by fully connected layers producing log-likelihood (probability) of directed edge i→j. Training: supervised binary cross-entropy loss on pairs in Π, Adam optimizer (initial lr 1e-4, lr reduction on plateau, min lr 1e-8), regularization terms to prevent exploding weights, trained for 100 epochs on multi-GPU (Nvidia V100) with PyTorch and Deep Graph Library. Preprocessing: automated bivariate KDE (Silverman bandwidth selection). Variants: CNN-only, GNN-only, combined; GNN initial graphs from Pearson correlation or Lasso regression.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning (hybrid CNN+GNN, discriminative classification for causal link prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and appropriate for large-scale high-dimensional causal discovery where some prior causal labels are available; not appropriate for very small-p problems due to insufficient examples for deep learning; requires sufficient labeled pairs (Π) and ample pairwise examples as p grows. Modifications used to suit problem: KDE-to-image transform for distributional features, DRNL labelling for structural role, SortPooling to handle variable subgraph sizes, and combining CNN and GNN embeddings to capture complementary signals.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Simulation: on synthetic problems with p=1500 and nonlinear tanh transitions, D^{2}CL achieves AUCs e.g. direct-cause (Tanh) SNR=10 AUC≈0.854 (Table 1) and indirect/ancestral (Tanh) SNR=10 AUC≈0.947 (Table 2). Real data: on yeast gene-deletion experiments (p up to 5535, n≈706) D^{2}CL variants achieved higher causal AUC than baselines across ranges of m and n (figures report AUC curves; exact panel values vary by setting), and remained effective at genome scale (p=5535).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively effective: robust across linear and nonlinear SEMs, across a broad range of SNRs, and on large-scale biological data; CNN tower degrades slowly as prior causal inputs are reduced, GNN tower degrades faster, but combined model compensates when one tower weakens. Robust to ~10% corruption of prior causal inputs. Outperforms non-causal baselines (Pearson/Kendall correlations) and performs competitively or better than IDA/SCL in many settings; GIES was not effective in the biological setting (assumptions violated). Limitations: provides structural binary outputs only (not full generative/interventional distributions), theoretical guarantees not yet established, unsuitable for small-p regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential: enables scalable causal discovery in high-dimensional scientific problems (e.g., genomics) where prior causal knowledge for subsets exists, can produce experimentally testable directed hypotheses at genome scale, and can serve as a discriminative pre-filter to make subsequent generative causal modelling tractable; could accelerate discovery by predicting causal links amenable to laboratory verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared against Pearson/Kendall correlation baselines, IDA, LV-IDA, SCL (manifold-regularization-based causal learner), GIES (tested but ineffective in this real-data setting). D^{2}CL outperforms correlation baselines and is more robust than IDA in non-linear settings; for indirect/ancestral relationships D^{2}CL substantially outperforms Pearson and maintains high AUC where IDA degrades on nonlinear MLP-generated data. Comparisons caveated due to differing input/output expectations and assumptions of alternative methods.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Key factors: (1) leveraging a large number of ordered pairs as implicit training examples (blessing of dimensionality), (2) using KDE images to capture asymmetric bivariate distributions allowing CNNs to learn directional cues, (3) exploiting structural cues via GNN on local enclosing subgraphs (DRNL labels & SortPooling), (4) incorporating partial prior causal knowledge Π as supervised labels to guide learning, and (5) hybrid fusion of complementary distributional and structural embeddings improving robustness when one signal is weak.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>A supervised deep discriminative approach that fuses distributional (CNN on KDE images) and structural (GNN on local subgraphs) representations can effectively learn causal link indicators at genome scale when partial prior causal labels are available, benefiting from high dimensionality and complementary tower specializations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2354.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2354.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN tower (KDE→ResNet)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional Neural Network tower using KDE image inputs (ResNet-54-like)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A CNN module that converts bivariate pairwise data into 2D KDE images with positional encodings and applies a ResNet-inspired deep convolutional stack to learn distributional features informative for causal direction and presence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Feature extraction for pairwise causal inference in high-dimensional scientific data (genomics simulations and yeast expression data).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Extract asymmetric distributional signatures from observed pairs (Xi, Xj) that can indicate causal direction or presence, via image representation (KDE) and deep convolutional feature learning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Pairwise (n × 2) observations for each ordered pair; in real data n≈706 and many pairs due to large p; sufficient examples arise from large p to train deep CNN.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Bivariate continuous data per pair transformed to 2D numeric grids (KDE evaluations) — image-like inputs, with positional encoding concatenated channel-wise.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Learning directional features from possibly symmetric joint distributions; handling many pairwise images (K ≈ p^2) and diverse underlying SEM nonlinearities; requires deep CNN capacity to learn subtle asymmetries under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>CNNs are mature; the specific KDE→CNN application to causal discovery is a design introduced here for scientific causal inference.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium to high — CNN outputs are used as interpretable embeddings indicating asymmetric distributional cues for causal inference and were shown to produce direction-sensitive features.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional Neural Network (ResNet-54-style) applied to kernel-density estimate images</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Preprocess each ordered pair (i,j) by computing a bivariate KDE on the n×2 data columns, evaluate KDE on an equally spaced grid to produce an image, concatenate positional encoding channels, feed into a ResNet-54-inspired CNN with stages [3,4,6,3,3] bottleneck blocks, PReLU activations, pre-activation ordering, and fully connected layers to produce a latent embedding for fusion with GNN embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning (feature-learning CNN)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for extracting distributional asymmetries indicative of causal direction when sufficient pairwise data/examples exist; particularly effective in high-p settings where many pairs provide training signal; less applicable in small-p regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Performant in experiments: CNN tower alone often gives strong AUCs; e.g., in biological genome-scale experiments CNN-only variant performs particularly well (fig.3g-k panels), and in ablation it degrades slowly with fewer causal inputs; quantitative AUC values depend on setting but are reported in figures/tables alongside combined model.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked well across linear and nonlinear simulations and in real yeast data; produced direction-sensitive latent representations (Figure 4c). Strengths: captures asymmetric distributional cues. Limitations: cannot by itself exploit structural graph regularities; degrades when prior causal labels are very sparse but more gracefully than the GNN tower.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Provides a generic way to convert pairwise statistical relationships into features useful for causal classification across scientific domains with bivariate measurements; scalable and leverages existing CNN advances.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared as a tower within D^{2}CL to a GNN tower and to combined model; CNN-only often outperforms baselines and remains competitive, whereas combined model improves robustness by adding structural cues.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Asymmetric KDE representation, deep ResNet-style capacity, positional encodings, and availability of many ordered pairs for training.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Transforming pairwise empirical distributions into KDE images enables standard CNNs to learn asymmetric, direction-informative features that scale well with the number of variables.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2354.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2354.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GNN tower (SEAL-based GCNN)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Neural Network tower using SEAL/GCNN on enclosing subgraphs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GNN module that performs link-prediction-style learning on local 1-hop enclosing subgraphs around a node pair, using Double-Radius Node Labeling (DRNL) and graph convolutional layers to extract structural cues about putative causal links.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Structural feature learning for causal link prediction in high-dimensional variable networks (genomics).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Learn structural regularities in an initial graph estimate Ĝ_0 to predict directed causal relations by classifying enclosing subgraphs for each ordered pair (i,j).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires an initial graph estimate Ĝ_0 (e.g., from Pearson correlations or lightweight regression/Lasso) and observed node features; the subgraphs vary in size depending on Ĝ_0 and p (in large p the enclosing subgraphs become large).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Graph-structured data: local enclosing subgraphs extracted per pair, with per-node features including DRNL structural labels and individual data-derived features.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Complex due to variability in subgraph sizes as p grows (scales poorly with larger local neighborhoods), need to learn adaptive link-prediction heuristics rather than relying on fixed metrics; computational complexity tied to extracting many local subgraphs and running GCNNs over them.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>GNN and SEAL architectures are established in the link prediction literature; applying them to causal discovery in high-dim scientific domains is emerging.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — GNN embeddings capture structural roles of nodes and can be interpreted to some extent, but are less directly mechanistic than generative causal models; used together with CNN embeddings to improve causal interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Graph Convolutional Neural Network (SEAL-inspired) on enclosing subgraphs with DRNL labelling and SortPooling</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>For each ordered pair (i,j), extract 1-hop enclosing subgraph from initial graph Ĝ_0 (neighbors of i or j), reconstruct subgraph edges, shuffle node order, compute DRNL labels via distances to i and j and one-hot encode them, include per-node data features, process by 4 sequential graph convolutional layers (tanh activations), use SortPooling to select top k nodes and 1D convolutions to extract final embedding; fused with CNN embedding for final classification. Two variants of Ĝ_0 used: Pearson-correlation-based and Lasso-regression-based initial graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised deep learning on graphs (link prediction / graph classification)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable when an initial structural estimate Ĝ_0 is available and when local structural patterns are informative; less effective when Ĝ_0 is poor or when p is very large causing very large enclosing subgraphs. Combined with CNN helps robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Contributed to combined model AUC improvements in many settings; standalone GNN tower performance degrades faster than CNN when prior labels are sparse or p large (Figure 3 and ablation studies). Exact numeric AUCs vary by initialization and setting (Pearson vs Lasso Ĝ_0).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides structural regularity detection and improves performance when initial graph estimate is informative; in real-data experiments GNN-only degraded more rapidly with fewer prior labels and with greater p compared to CNN-only; combined model mitigated tower-specific failures.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables leveraging structural priors and graph motifs to improve causal link prediction, particularly when experimental priors and local graph structure are informative; can complement distributional approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared as a component versus CNN-only and combined; GNN-only underperforms CNN-only in some large-p / sparse-label regimes but adds complementary signal when informative Ĝ_0 is available.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of DRNL labeling to encode structural roles, SortPooling to handle variable subgraph sizes, and end-to-end learning of link-prediction heuristics (SEAL-inspired) rather than fixed heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Local structural patterns around node pairs, learned via a SEAL-style GCNN, provide complementary information to distributional features and improve causal link prediction when reliable initial graph estimates exist.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2354.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2354.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IDA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Estimating high-dimensional intervention effects from observational data (IDA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A statistical method for estimating intervention effects from observational data using causal graphical model assumptions (e.g., based on CPDAGs) and estimating possible intervention effects via adjustment sets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Estimating high-dimensional intervention effects from observational data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Causal effect estimation from observational data; compared in simulations and real-data experiments (genomics).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Baseline/alternative approach for estimating causal effects or inferring causal relationships from observational data, assuming graphical-model conditions (DAG/CPDAG) and using adjustment-based strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Assumes sufficient observational data; typically designed for settings without privileged supervised causal labels Π; less suitable when partial interventional priors are available in the way D^{2}CL uses them.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multivariate observational data with structure suitable for constraint-based or score-based causal discovery (tabular).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Works in high-dimensional settings but relies on assumptions (linearity/non-Gaussianity or faithfulness) and can struggle with nonlinear SEMs or complex noise models used in some simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established method in causal inference literature (Maathuis et al., 2009); widely used and well-studied.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — provides mechanistic/generative causal interpretations under model assumptions; used to estimate interventional effects.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Statistical causal inference algorithm (graphical-model-based method)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Not a deep learning method; uses causal graphical models (CPDAG) and adjustment sets to estimate intervention effects from observational data, typically under linear-Gaussian or specific assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Statistical causal inference (non-ML / model-based)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate for linear settings and when its model assumptions hold; less appropriate for complex nonlinear generative mechanisms (MLP nonlinearities) as evidenced by degradation in such simulations in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>In simulations: IDA performs well on linear SEMs but degrades on nonlinear MLP-generated data; specific AUCs in tables show IDA AUCs often lower than D^{2}CL for nonlinear cases (e.g., indirect/tanh SNR=10 IDA AUC≈0.903 vs D^{2}CL≈0.947 in Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Performs competitively in linear settings but not robust to complex nonlinear functions used in simulations; comparisons are caveated because D^{2}CL had access to partial causal labels Π.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Continues to be a useful baseline for causal estimation where assumptions hold, but deep discriminative approaches may outperform it on highly nonlinear, high-dimensional problems with supervised priors.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared directly in simulations and real-data experiments; IDA does well for linear SEMs but underperforms relative to D^{2}CL for nonlinear SEMs and indirect effect detection.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Good performance when its structural/parametric assumptions hold (linearity/faithfulness); struggles otherwise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2354.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2354.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GIES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy Interventional Equivalence Search (GIES)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A score-based method designed to learn causal graphs from a combination of observational and interventional data by characterizing interventional Markov equivalence classes and using greedy search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Causal structure learning with interventional data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Learn DAGs (up to interventional equivalence) by leveraging both observational and interventional data via a greedy search over graph space.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Requires explicit interventional data of the types/formats it expects; in the biological setting of this paper necessary inputs/assumptions were not satisfied, leading to poor performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Tabular multivariate observational plus interventional datasets aligned to known interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Computationally intensive search over graph space; assumptions include known intervention targets and compatibility with the greedy search scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established in causal discovery literature for settings with interventional data (Hauser & Bühlmann, 2012).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — yields structural/generative graph estimates under model assumptions enabling mechanistic interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Score-based causal discovery (greedy search over interventional Markov equivalence classes)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Not a deep-learning method; characterizes interventional Markov equivalence classes and applies a greedy algorithm to search for high-scoring DAGs consistent with observational and interventional data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Statistical causal discovery (model-based, score-based)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate when suitable interventional data and assumptions hold; in the yeast gene-deletion setting of this paper GIES was not effective (results not shown) because inputs and assumptions were likely violated.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported as not effective on the real biological data in this paper (results not shown); no numeric AUC provided here for GIES in that setting.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Underperforms when its required inputs/assumptions (type of interventional data, absence of many latent variables) are not met; contrasted with D^{2}CL which uses partial causal inputs Π and scales to high p.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High when experimental intervention data are available in the form required; limited in messy real-world biological datasets where interventions and latent confounding violate assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually and briefly empirically (not shown) with D^{2}CL; D^{2}CL outperforms in the biological experiment setting due to mismatched assumptions for GIES.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Success when intervention targets are known and interventional data align with model assumptions; fails when those conditions are not met.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2354.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2354.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semi-/Supervised Causal Learning (SCL) / related methods (e.g., MRCL references)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of methods (including manifold-regularization-based MRCL/SCL) that cast causal learning as a semi-supervised or supervised classification problem over variable pairs using geometric/manifold regularization or related strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal learning via manifold regularization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Causal link prediction via supervised/semi-supervised learning; applied as baseline/alternative in simulations and real data (genomics).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict binary causal relationship indicators between variable pairs using pairwise features and semi- or supervised learning with manifold regularization or related approaches; prior approaches include MRCL which is semi-supervised and SCL variants.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Typically assumes limited labeled causal pairs with many unlabeled pairs (semi-supervised setting); in this paper D^{2}CL is supervised and scaled better to high-p than MRCL/SCL in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Pairwise features derived from multivariate data (e.g., correlations, distributional summaries) treated as inputs to (semi-)supervised classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Challenging due to label scarcity for causal pairs, high dimensionality (many pairs), and nonlinear generative relationships; semi-supervised methods may struggle to scale to p in thousands.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application of semi-supervised learning ideas to causal discovery; MRCL and SCL are recent contributions in literature.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium to high — aims to produce interpretable causal pair predictions though methods are discriminative rather than generative.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Semi-/Supervised learning for causal pair classification (manifold-regularization, MRCL/SCL)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Approaches like MRCL use manifold regularization to leverage unlabeled pairs with a small labeled subset to propagate causal labels across a pairwise feature manifold; SCL is used as a baseline comparing discriminative classification approaches to causal discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Semi-supervised / supervised learning applied to causal link classification</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable when labeled pairs are scarce and unlabeled pairs can be exploited via geometric regularities; however MRCL reportedly does not scale well to very high-dimensional (p thousands) settings, motivating fully supervised deep approaches like D^{2}CL.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>In tables/figures SCL typically underperforms relative to D^{2}CL (e.g., Table 1/2 show lower AUCs for SCL across multiple SNRs and functional forms). Exact AUCs in simulations are provided in Tables 1 and 2 of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Semi-supervised manifold-based approaches can be effective in low-to-moderate dimensional settings but scale poorly; D^{2}CL (supervised deep approach) is designed to address scalability and nonlinearities and shows better empirical performance in high-p experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Useful for problems with few labels, but limited scalability reduces impact on genome-scale causal discovery compared to D^{2}CL.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared directly in simulations and real data; D^{2}CL generally outperforms SCL/MRCL in high-dimensional and nonlinear settings.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Exploiting manifold structure when present and reasonable label propagation; however scalability and nonlinear pattern learning are limiting factors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep learning of causal structures in high dimensions under data limitations', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Causal learning via manifold regularization <em>(Rating: 2)</em></li>
                <li>Link prediction based on graph neural networks <em>(Rating: 2)</em></li>
                <li>An end-to-end deep learning architecture for graph classification <em>(Rating: 2)</em></li>
                <li>Ancestral causal learning in high dimensions with a human genome-wide application <em>(Rating: 2)</em></li>
                <li>Evaluation of causal structure learning algorithms via risk estimation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2354",
    "paper_id": "paper-3fb4c5ce7dcbd708776826a935aba10b7dc04bfc",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "D2CL",
            "name_full": "Deep Discriminative Causal Learning (D^{2}CL)",
            "brief_description": "An end-to-end deep neural architecture that learns binary indicators of causal relations between variable pairs by combining distributional features (CNN on KDE images) and structural features (GNN on local subgraphs), trained in a supervised way using available prior causal labels.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Causal structure learning; biomedical genomics applications (gene regulatory effects)",
            "problem_description": "Learn directed binary indicators of causal influence between pairs of observed variables (direct or indirect/ancestral causal edges) from high-dimensional observational data X together with partial prior causal knowledge Π; produce a global graph estimate spanning thousands of variables and validate against unseen interventional experiments.",
            "data_availability": "High-dimensional observational data available; in simulations synthetic datasets of size e.g. p=1500 with n up to 1024 were used; real biological data comprised gene expression measurements with n≈706 and p up to 5535, plus a set of interventional experiments used only for validation. Prior causal labels Π are available for a subset of pairs (labels are supervised) and are disjoint from test pairs; data for test pairs are not provided as interventions during training. The paper also studies varying numbers of available interventions m and varying sample size n to probe data-efficiency.",
            "data_structure": "High-dimensional tabular multivariate data (n × p), transformed to: (1) pairwise 2D KDE images (bivariate density grid) fed to CNN; (2) graph-structured inputs (local 1-hop enclosing subgraphs) fed to a GNN. Data include observational measurements; interventional experiments exist for validation but are not used as training inputs for the test pairs.",
            "problem_complexity": "Very high: dimensionality up to thousands of variables (p up to 5535), enormous number of ordered pairs K ≈ p^2, nonlinear generative mechanisms (mixture of linear, MLPs, tanh, leaky ReLU, polynomials), presence of noise (varied SNR), latent variables in real biological data, and combinatorially large search space for graphs; computationally intensive training (deep CNN and GNN; multi-GPU training over 100 epochs).",
            "domain_maturity": "Applied domain (molecular biology / genomics) is mature with substantial prior knowledge available for subsets of relationships; however causal discovery in this domain remains challenging due to latent variables and complex nonlinear mechanisms. The paper leverages existing experimental datasets (gene-deletion studies) as gold-standard validation.",
            "mechanistic_understanding_requirements": "High — the goal is causal/ mechanistic understanding (direct or indirect causal influences) rather than purely predictive black-box outputs; outputs are intended to be interpretable as directed causal indicators and are validated against laboratory interventions.",
            "ai_methodology_name": "End-to-end deep neural architecture combining convolutional neural networks (CNN) and graph neural networks (GNN); supervised discriminative learning for causal link classification (D^{2}CL).",
            "ai_methodology_description": "Architecture: two-tower model. CNN tower: takes bivariate kernel density estimate (KDE) images computed from the n×2 columns for each ordered pair (i,j) (asymmetric KDE for direction), with positional encodings concatenated channel-wise; a ResNet-like stem and five-stage ResNet-54-inspired network (with bottleneck 1×1 convs and PReLU activations, pre-activation blocks) produces an embedding. GNN tower: based on SEAL/GCNN ideas — for each pair (i,j) extract 1-hop enclosing subgraph from an initial graph estimate Ĝ_0, assign Double-Radius Node Labels (DRNL) and include per-node data features, process by 4 graph convolutional layers (tanh activation), SortPooling to fixed-size node set and 1D convolutions to produce an embedding. Embedding fusion: concatenation of CNN and GNN embeddings followed by fully connected layers producing log-likelihood (probability) of directed edge i→j. Training: supervised binary cross-entropy loss on pairs in Π, Adam optimizer (initial lr 1e-4, lr reduction on plateau, min lr 1e-8), regularization terms to prevent exploding weights, trained for 100 epochs on multi-GPU (Nvidia V100) with PyTorch and Deep Graph Library. Preprocessing: automated bivariate KDE (Silverman bandwidth selection). Variants: CNN-only, GNN-only, combined; GNN initial graphs from Pearson correlation or Lasso regression.",
            "ai_methodology_category": "Supervised deep learning (hybrid CNN+GNN, discriminative classification for causal link prediction)",
            "applicability": "Applicable and appropriate for large-scale high-dimensional causal discovery where some prior causal labels are available; not appropriate for very small-p problems due to insufficient examples for deep learning; requires sufficient labeled pairs (Π) and ample pairwise examples as p grows. Modifications used to suit problem: KDE-to-image transform for distributional features, DRNL labelling for structural role, SortPooling to handle variable subgraph sizes, and combining CNN and GNN embeddings to capture complementary signals.",
            "effectiveness_quantitative": "Simulation: on synthetic problems with p=1500 and nonlinear tanh transitions, D^{2}CL achieves AUCs e.g. direct-cause (Tanh) SNR=10 AUC≈0.854 (Table 1) and indirect/ancestral (Tanh) SNR=10 AUC≈0.947 (Table 2). Real data: on yeast gene-deletion experiments (p up to 5535, n≈706) D^{2}CL variants achieved higher causal AUC than baselines across ranges of m and n (figures report AUC curves; exact panel values vary by setting), and remained effective at genome scale (p=5535).",
            "effectiveness_qualitative": "Qualitatively effective: robust across linear and nonlinear SEMs, across a broad range of SNRs, and on large-scale biological data; CNN tower degrades slowly as prior causal inputs are reduced, GNN tower degrades faster, but combined model compensates when one tower weakens. Robust to ~10% corruption of prior causal inputs. Outperforms non-causal baselines (Pearson/Kendall correlations) and performs competitively or better than IDA/SCL in many settings; GIES was not effective in the biological setting (assumptions violated). Limitations: provides structural binary outputs only (not full generative/interventional distributions), theoretical guarantees not yet established, unsuitable for small-p regimes.",
            "impact_potential": "High potential: enables scalable causal discovery in high-dimensional scientific problems (e.g., genomics) where prior causal knowledge for subsets exists, can produce experimentally testable directed hypotheses at genome scale, and can serve as a discriminative pre-filter to make subsequent generative causal modelling tractable; could accelerate discovery by predicting causal links amenable to laboratory verification.",
            "comparison_to_alternatives": "Compared against Pearson/Kendall correlation baselines, IDA, LV-IDA, SCL (manifold-regularization-based causal learner), GIES (tested but ineffective in this real-data setting). D^{2}CL outperforms correlation baselines and is more robust than IDA in non-linear settings; for indirect/ancestral relationships D^{2}CL substantially outperforms Pearson and maintains high AUC where IDA degrades on nonlinear MLP-generated data. Comparisons caveated due to differing input/output expectations and assumptions of alternative methods.",
            "success_factors": "Key factors: (1) leveraging a large number of ordered pairs as implicit training examples (blessing of dimensionality), (2) using KDE images to capture asymmetric bivariate distributions allowing CNNs to learn directional cues, (3) exploiting structural cues via GNN on local enclosing subgraphs (DRNL labels & SortPooling), (4) incorporating partial prior causal knowledge Π as supervised labels to guide learning, and (5) hybrid fusion of complementary distributional and structural embeddings improving robustness when one signal is weak.",
            "key_insight": "A supervised deep discriminative approach that fuses distributional (CNN on KDE images) and structural (GNN on local subgraphs) representations can effectively learn causal link indicators at genome scale when partial prior causal labels are available, benefiting from high dimensionality and complementary tower specializations.",
            "uuid": "e2354.0",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "CNN tower (KDE→ResNet)",
            "name_full": "Convolutional Neural Network tower using KDE image inputs (ResNet-54-like)",
            "brief_description": "A CNN module that converts bivariate pairwise data into 2D KDE images with positional encodings and applies a ResNet-inspired deep convolutional stack to learn distributional features informative for causal direction and presence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Feature extraction for pairwise causal inference in high-dimensional scientific data (genomics simulations and yeast expression data).",
            "problem_description": "Extract asymmetric distributional signatures from observed pairs (Xi, Xj) that can indicate causal direction or presence, via image representation (KDE) and deep convolutional feature learning.",
            "data_availability": "Pairwise (n × 2) observations for each ordered pair; in real data n≈706 and many pairs due to large p; sufficient examples arise from large p to train deep CNN.",
            "data_structure": "Bivariate continuous data per pair transformed to 2D numeric grids (KDE evaluations) — image-like inputs, with positional encoding concatenated channel-wise.",
            "problem_complexity": "Learning directional features from possibly symmetric joint distributions; handling many pairwise images (K ≈ p^2) and diverse underlying SEM nonlinearities; requires deep CNN capacity to learn subtle asymmetries under noise.",
            "domain_maturity": "CNNs are mature; the specific KDE→CNN application to causal discovery is a design introduced here for scientific causal inference.",
            "mechanistic_understanding_requirements": "Medium to high — CNN outputs are used as interpretable embeddings indicating asymmetric distributional cues for causal inference and were shown to produce direction-sensitive features.",
            "ai_methodology_name": "Convolutional Neural Network (ResNet-54-style) applied to kernel-density estimate images",
            "ai_methodology_description": "Preprocess each ordered pair (i,j) by computing a bivariate KDE on the n×2 data columns, evaluate KDE on an equally spaced grid to produce an image, concatenate positional encoding channels, feed into a ResNet-54-inspired CNN with stages [3,4,6,3,3] bottleneck blocks, PReLU activations, pre-activation ordering, and fully connected layers to produce a latent embedding for fusion with GNN embedding.",
            "ai_methodology_category": "Supervised deep learning (feature-learning CNN)",
            "applicability": "Highly applicable for extracting distributional asymmetries indicative of causal direction when sufficient pairwise data/examples exist; particularly effective in high-p settings where many pairs provide training signal; less applicable in small-p regimes.",
            "effectiveness_quantitative": "Performant in experiments: CNN tower alone often gives strong AUCs; e.g., in biological genome-scale experiments CNN-only variant performs particularly well (fig.3g-k panels), and in ablation it degrades slowly with fewer causal inputs; quantitative AUC values depend on setting but are reported in figures/tables alongside combined model.",
            "effectiveness_qualitative": "Worked well across linear and nonlinear simulations and in real yeast data; produced direction-sensitive latent representations (Figure 4c). Strengths: captures asymmetric distributional cues. Limitations: cannot by itself exploit structural graph regularities; degrades when prior causal labels are very sparse but more gracefully than the GNN tower.",
            "impact_potential": "Provides a generic way to convert pairwise statistical relationships into features useful for causal classification across scientific domains with bivariate measurements; scalable and leverages existing CNN advances.",
            "comparison_to_alternatives": "Compared as a tower within D^{2}CL to a GNN tower and to combined model; CNN-only often outperforms baselines and remains competitive, whereas combined model improves robustness by adding structural cues.",
            "success_factors": "Asymmetric KDE representation, deep ResNet-style capacity, positional encodings, and availability of many ordered pairs for training.",
            "key_insight": "Transforming pairwise empirical distributions into KDE images enables standard CNNs to learn asymmetric, direction-informative features that scale well with the number of variables.",
            "uuid": "e2354.1",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "GNN tower (SEAL-based GCNN)",
            "name_full": "Graph Neural Network tower using SEAL/GCNN on enclosing subgraphs",
            "brief_description": "A GNN module that performs link-prediction-style learning on local 1-hop enclosing subgraphs around a node pair, using Double-Radius Node Labeling (DRNL) and graph convolutional layers to extract structural cues about putative causal links.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Structural feature learning for causal link prediction in high-dimensional variable networks (genomics).",
            "problem_description": "Learn structural regularities in an initial graph estimate Ĝ_0 to predict directed causal relations by classifying enclosing subgraphs for each ordered pair (i,j).",
            "data_availability": "Requires an initial graph estimate Ĝ_0 (e.g., from Pearson correlations or lightweight regression/Lasso) and observed node features; the subgraphs vary in size depending on Ĝ_0 and p (in large p the enclosing subgraphs become large).",
            "data_structure": "Graph-structured data: local enclosing subgraphs extracted per pair, with per-node features including DRNL structural labels and individual data-derived features.",
            "problem_complexity": "Complex due to variability in subgraph sizes as p grows (scales poorly with larger local neighborhoods), need to learn adaptive link-prediction heuristics rather than relying on fixed metrics; computational complexity tied to extracting many local subgraphs and running GCNNs over them.",
            "domain_maturity": "GNN and SEAL architectures are established in the link prediction literature; applying them to causal discovery in high-dim scientific domains is emerging.",
            "mechanistic_understanding_requirements": "Medium — GNN embeddings capture structural roles of nodes and can be interpreted to some extent, but are less directly mechanistic than generative causal models; used together with CNN embeddings to improve causal interpretability.",
            "ai_methodology_name": "Graph Convolutional Neural Network (SEAL-inspired) on enclosing subgraphs with DRNL labelling and SortPooling",
            "ai_methodology_description": "For each ordered pair (i,j), extract 1-hop enclosing subgraph from initial graph Ĝ_0 (neighbors of i or j), reconstruct subgraph edges, shuffle node order, compute DRNL labels via distances to i and j and one-hot encode them, include per-node data features, process by 4 sequential graph convolutional layers (tanh activations), use SortPooling to select top k nodes and 1D convolutions to extract final embedding; fused with CNN embedding for final classification. Two variants of Ĝ_0 used: Pearson-correlation-based and Lasso-regression-based initial graphs.",
            "ai_methodology_category": "Supervised deep learning on graphs (link prediction / graph classification)",
            "applicability": "Applicable when an initial structural estimate Ĝ_0 is available and when local structural patterns are informative; less effective when Ĝ_0 is poor or when p is very large causing very large enclosing subgraphs. Combined with CNN helps robustness.",
            "effectiveness_quantitative": "Contributed to combined model AUC improvements in many settings; standalone GNN tower performance degrades faster than CNN when prior labels are sparse or p large (Figure 3 and ablation studies). Exact numeric AUCs vary by initialization and setting (Pearson vs Lasso Ĝ_0).",
            "effectiveness_qualitative": "Provides structural regularity detection and improves performance when initial graph estimate is informative; in real-data experiments GNN-only degraded more rapidly with fewer prior labels and with greater p compared to CNN-only; combined model mitigated tower-specific failures.",
            "impact_potential": "Enables leveraging structural priors and graph motifs to improve causal link prediction, particularly when experimental priors and local graph structure are informative; can complement distributional approaches.",
            "comparison_to_alternatives": "Compared as a component versus CNN-only and combined; GNN-only underperforms CNN-only in some large-p / sparse-label regimes but adds complementary signal when informative Ĝ_0 is available.",
            "success_factors": "Use of DRNL labeling to encode structural roles, SortPooling to handle variable subgraph sizes, and end-to-end learning of link-prediction heuristics (SEAL-inspired) rather than fixed heuristics.",
            "key_insight": "Local structural patterns around node pairs, learned via a SEAL-style GCNN, provide complementary information to distributional features and improve causal link prediction when reliable initial graph estimates exist.",
            "uuid": "e2354.2",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "IDA",
            "name_full": "Estimating high-dimensional intervention effects from observational data (IDA)",
            "brief_description": "A statistical method for estimating intervention effects from observational data using causal graphical model assumptions (e.g., based on CPDAGs) and estimating possible intervention effects via adjustment sets.",
            "citation_title": "Estimating high-dimensional intervention effects from observational data",
            "mention_or_use": "use",
            "scientific_problem_domain": "Causal effect estimation from observational data; compared in simulations and real-data experiments (genomics).",
            "problem_description": "Baseline/alternative approach for estimating causal effects or inferring causal relationships from observational data, assuming graphical-model conditions (DAG/CPDAG) and using adjustment-based strategies.",
            "data_availability": "Assumes sufficient observational data; typically designed for settings without privileged supervised causal labels Π; less suitable when partial interventional priors are available in the way D^{2}CL uses them.",
            "data_structure": "Multivariate observational data with structure suitable for constraint-based or score-based causal discovery (tabular).",
            "problem_complexity": "Works in high-dimensional settings but relies on assumptions (linearity/non-Gaussianity or faithfulness) and can struggle with nonlinear SEMs or complex noise models used in some simulations.",
            "domain_maturity": "Established method in causal inference literature (Maathuis et al., 2009); widely used and well-studied.",
            "mechanistic_understanding_requirements": "High — provides mechanistic/generative causal interpretations under model assumptions; used to estimate interventional effects.",
            "ai_methodology_name": "Statistical causal inference algorithm (graphical-model-based method)",
            "ai_methodology_description": "Not a deep learning method; uses causal graphical models (CPDAG) and adjustment sets to estimate intervention effects from observational data, typically under linear-Gaussian or specific assumptions.",
            "ai_methodology_category": "Statistical causal inference (non-ML / model-based)",
            "applicability": "Appropriate for linear settings and when its model assumptions hold; less appropriate for complex nonlinear generative mechanisms (MLP nonlinearities) as evidenced by degradation in such simulations in this paper.",
            "effectiveness_quantitative": "In simulations: IDA performs well on linear SEMs but degrades on nonlinear MLP-generated data; specific AUCs in tables show IDA AUCs often lower than D^{2}CL for nonlinear cases (e.g., indirect/tanh SNR=10 IDA AUC≈0.903 vs D^{2}CL≈0.947 in Table 2).",
            "effectiveness_qualitative": "Performs competitively in linear settings but not robust to complex nonlinear functions used in simulations; comparisons are caveated because D^{2}CL had access to partial causal labels Π.",
            "impact_potential": "Continues to be a useful baseline for causal estimation where assumptions hold, but deep discriminative approaches may outperform it on highly nonlinear, high-dimensional problems with supervised priors.",
            "comparison_to_alternatives": "Compared directly in simulations and real-data experiments; IDA does well for linear SEMs but underperforms relative to D^{2}CL for nonlinear SEMs and indirect effect detection.",
            "success_factors": "Good performance when its structural/parametric assumptions hold (linearity/faithfulness); struggles otherwise.",
            "uuid": "e2354.3",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "GIES",
            "name_full": "Greedy Interventional Equivalence Search (GIES)",
            "brief_description": "A score-based method designed to learn causal graphs from a combination of observational and interventional data by characterizing interventional Markov equivalence classes and using greedy search.",
            "citation_title": "Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs",
            "mention_or_use": "use",
            "scientific_problem_domain": "Causal structure learning with interventional data.",
            "problem_description": "Learn DAGs (up to interventional equivalence) by leveraging both observational and interventional data via a greedy search over graph space.",
            "data_availability": "Requires explicit interventional data of the types/formats it expects; in the biological setting of this paper necessary inputs/assumptions were not satisfied, leading to poor performance.",
            "data_structure": "Tabular multivariate observational plus interventional datasets aligned to known interventions.",
            "problem_complexity": "Computationally intensive search over graph space; assumptions include known intervention targets and compatibility with the greedy search scoring.",
            "domain_maturity": "Well-established in causal discovery literature for settings with interventional data (Hauser & Bühlmann, 2012).",
            "mechanistic_understanding_requirements": "High — yields structural/generative graph estimates under model assumptions enabling mechanistic interpretation.",
            "ai_methodology_name": "Score-based causal discovery (greedy search over interventional Markov equivalence classes)",
            "ai_methodology_description": "Not a deep-learning method; characterizes interventional Markov equivalence classes and applies a greedy algorithm to search for high-scoring DAGs consistent with observational and interventional data.",
            "ai_methodology_category": "Statistical causal discovery (model-based, score-based)",
            "applicability": "Appropriate when suitable interventional data and assumptions hold; in the yeast gene-deletion setting of this paper GIES was not effective (results not shown) because inputs and assumptions were likely violated.",
            "effectiveness_quantitative": "Reported as not effective on the real biological data in this paper (results not shown); no numeric AUC provided here for GIES in that setting.",
            "effectiveness_qualitative": "Underperforms when its required inputs/assumptions (type of interventional data, absence of many latent variables) are not met; contrasted with D^{2}CL which uses partial causal inputs Π and scales to high p.",
            "impact_potential": "High when experimental intervention data are available in the form required; limited in messy real-world biological datasets where interventions and latent confounding violate assumptions.",
            "comparison_to_alternatives": "Compared conceptually and briefly empirically (not shown) with D^{2}CL; D^{2}CL outperforms in the biological experiment setting due to mismatched assumptions for GIES.",
            "success_factors": "Success when intervention targets are known and interventional data align with model assumptions; fails when those conditions are not met.",
            "uuid": "e2354.4",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "SCL",
            "name_full": "Semi-/Supervised Causal Learning (SCL) / related methods (e.g., MRCL references)",
            "brief_description": "A class of methods (including manifold-regularization-based MRCL/SCL) that cast causal learning as a semi-supervised or supervised classification problem over variable pairs using geometric/manifold regularization or related strategies.",
            "citation_title": "Causal learning via manifold regularization",
            "mention_or_use": "use",
            "scientific_problem_domain": "Causal link prediction via supervised/semi-supervised learning; applied as baseline/alternative in simulations and real data (genomics).",
            "problem_description": "Predict binary causal relationship indicators between variable pairs using pairwise features and semi- or supervised learning with manifold regularization or related approaches; prior approaches include MRCL which is semi-supervised and SCL variants.",
            "data_availability": "Typically assumes limited labeled causal pairs with many unlabeled pairs (semi-supervised setting); in this paper D^{2}CL is supervised and scaled better to high-p than MRCL/SCL in experiments.",
            "data_structure": "Pairwise features derived from multivariate data (e.g., correlations, distributional summaries) treated as inputs to (semi-)supervised classifiers.",
            "problem_complexity": "Challenging due to label scarcity for causal pairs, high dimensionality (many pairs), and nonlinear generative relationships; semi-supervised methods may struggle to scale to p in thousands.",
            "domain_maturity": "Emerging application of semi-supervised learning ideas to causal discovery; MRCL and SCL are recent contributions in literature.",
            "mechanistic_understanding_requirements": "Medium to high — aims to produce interpretable causal pair predictions though methods are discriminative rather than generative.",
            "ai_methodology_name": "Semi-/Supervised learning for causal pair classification (manifold-regularization, MRCL/SCL)",
            "ai_methodology_description": "Approaches like MRCL use manifold regularization to leverage unlabeled pairs with a small labeled subset to propagate causal labels across a pairwise feature manifold; SCL is used as a baseline comparing discriminative classification approaches to causal discovery.",
            "ai_methodology_category": "Semi-supervised / supervised learning applied to causal link classification",
            "applicability": "Applicable when labeled pairs are scarce and unlabeled pairs can be exploited via geometric regularities; however MRCL reportedly does not scale well to very high-dimensional (p thousands) settings, motivating fully supervised deep approaches like D^{2}CL.",
            "effectiveness_quantitative": "In tables/figures SCL typically underperforms relative to D^{2}CL (e.g., Table 1/2 show lower AUCs for SCL across multiple SNRs and functional forms). Exact AUCs in simulations are provided in Tables 1 and 2 of the paper.",
            "effectiveness_qualitative": "Semi-supervised manifold-based approaches can be effective in low-to-moderate dimensional settings but scale poorly; D^{2}CL (supervised deep approach) is designed to address scalability and nonlinearities and shows better empirical performance in high-p experiments.",
            "impact_potential": "Useful for problems with few labels, but limited scalability reduces impact on genome-scale causal discovery compared to D^{2}CL.",
            "comparison_to_alternatives": "Compared directly in simulations and real data; D^{2}CL generally outperforms SCL/MRCL in high-dimensional and nonlinear settings.",
            "success_factors": "Exploiting manifold structure when present and reasonable label propagation; however scalability and nonlinear pattern learning are limiting factors.",
            "uuid": "e2354.5",
            "source_info": {
                "paper_title": "Deep learning of causal structures in high dimensions under data limitations",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Causal learning via manifold regularization",
            "rating": 2
        },
        {
            "paper_title": "Link prediction based on graph neural networks",
            "rating": 2
        },
        {
            "paper_title": "An end-to-end deep learning architecture for graph classification",
            "rating": 2
        },
        {
            "paper_title": "Ancestral causal learning in high dimensions with a human genome-wide application",
            "rating": 2
        },
        {
            "paper_title": "Evaluation of causal structure learning algorithms via risk estimation",
            "rating": 1
        }
    ],
    "cost": 0.01959675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Deep Learning of Causal Structures in High Dimensions</h1>
<p>Kai Lagemann<em>1, Christian Lagemann ${ }^{2}$, Bernd Taschler ${ }^{3}$, and Sach Mukherjee</em>1,4<br>${ }^{1}$ Statistics and Machine Learning, DZNE, Bonn, Germany<br>${ }^{2}$ Institute of Aerodynamics, RWTH Aachen University, Aachen, Germany<br>${ }^{3}$ Wellcome Centre for Integrative Neuroimaging, University of Oxford, Oxford, UK<br>${ }^{4}$ MRC Biostatistics Unit, University of Cambridge, Cambridge, UK<br>*corresponding emails: {kai.lagemann, sach.mukherjee}@dzne.de</p>
<h4>Abstract</h4>
<p>Recent years have seen rapid progress at the intersection between causality and machine learning. Motivated by scientific applications involving high-dimensional data, in particular in biomedicine, we propose a deep neural architecture for learning causal relationships between variables from a combination of empirical data and prior causal knowledge. We combine convolutional and graph neural networks within a causal risk framework to provide a flexible and scalable approach. Empirical results include linear and nonlinear simulations (where the underlying causal structures are known and can be directly compared against), as well as a real biological example where the models are applied to high-dimensional molecular data and their output compared against entirely unseen validation experiments. These results demonstrate the feasibility of using deep learning approaches to learn causal networks in large-scale problems spanning thousands of variables.</p>
<h2>1 Introduction</h2>
<p>Causality remains an important open area in machine learning, statistics and related fields [see e.g. Peters et al., 2017, Arjovsky et al., 2019] and the task of identifying causal relationships between variables is key in many scientific domains including in particular biomedicine [see e.g. Glymour et al., 2016, Hill et al., 2016]. The rich body of work in learning causal structures includes, among other methods, PC [Spirtes et al., 2000], LiNGAM [Shimizu et al., 2006], IDA [Maathuis et al., 2009], GIES [Hauser and Bühlmann, 2012], RFCI [Colombo et al., 2012], ICP [Peters et al., 2016] and MRCL [Hill et al., 2019]. However, learning causal structures from data remains challenging, particularly under conditions - such as high dimensionality, limited data sizes, presence of hidden variables etc. - seen in many real-world problems.</p>
<p>In this paper, we propose a deep architecture for causal learning that is motivated in particular by questions involving high-dimensional biomedical data. The approach we put forward operates within a paradigm that views causal questions through the lens of expected loss or risk (see below). The learners proposed allow for</p>
<p>the integration of partial knowledge concerning a subset of causal relationships and then seek to generalize beyond what is initially known to learn relationships between all observed variables. This corresponds to a common scientific use-case, in which some prior knowledge is available at the outset - from previous experiments or scientific background knowledge - but where the aim is to go beyond what is known to learn a model spanning all available variables.</p>
<p>Much of the literature in learning causal structures involves statistical formulations that allow explicit description of the relevant data-generating distributions (including both observational and interventional distributions) and are in that sense "generative" [see, e.g., Heinze-Deml et al., 2018, and references therein]. Taking a different approach, a number of recent papers, including Lopez-Paz et al. [2015], Mooij et al. [2016], Hill et al. [2019], Noè et al. [2019], have considered learning discrete indicators of causal relationships between variables (without necessarily learning full details of the underlying data-generating models) and this is related to notions of causal expected loss or risk [Eigenmann et al., 2020]. Such indicators may encode for example, whether, for a pair of variables $A$ and $B, A$ has a causal influence on $B, B$ on $A$, or neither.</p>
<p>The approach we propose, called "Deep Discriminative Causal Learning" ( $\mathrm{D}^{2} \mathrm{CL}$ ), is in the latter vein. We consider a version of the causal structure learning problem in which the desired output consists of binary indicators of causal relationships between observed variables [Hill et al., 2019, Eigenmann et al., 2020], which can be represented as a directed graph with nodes corresponding to the variables. Available multivariate data $X$ are transformed to provide inputs to a neural network whose outputs are estimates of the causal indicators. As detailed below, $\mathrm{D}^{2} \mathrm{CL}$ has several differences to classical causal structure learning (e.g. based on causal graphical models). First, the objective is different: rather than giving access to all interventional distributions, $\mathrm{D}^{2} \mathrm{CL}$ outputs indicators of causal links. Second, $\mathrm{D}^{2} \mathrm{CL}$ is highly non-parametric, relying on the learners to detect relevant regularities. Third, $\mathrm{D}^{2} \mathrm{CL}$ is demonstrably scalable to large numbers of variables (and is in fact unsuitable for small problems spanning only a few variables, see Discussion). The assumptions underlying the approach are also different in nature from the kinds of assumptions usually made in causal structure learning and concern higher-level regularities in the data-generating processes, as discussed further below.</p>
<p>The remainder of the paper is organized as follows. We first introduce the $\mathrm{D}^{2} \mathrm{CL}$ methodology. We then present empirical results, on both synthetic, gold-standard problems and on real molecular biological data. In the latter case, model results are systematically checked against entirely unseen interventional experiments. Finally, we discuss open questions and limitations.</p>
<h1>2 Methods</h1>
<p>We propose an end-to-end neural approach to learn causal networks from a combination of empirical data $X$ and prior causal knowledge $\Pi$. In this Section, we describe the proposed methodology, starting with notation and a problem statement and going on to present the learning scheme and architecture.</p>
<h3>2.1 Notation</h3>
<p>Observed variables with index set $V={1, \ldots, p}$ are denoted $X_{1}, \ldots, X_{p}$. The variables will be identified with vertices in a directed graph $G$ whose vertex and edge sets are denoted $V(G), E(G)$, respectively. We</p>
<p>occasionally overload $G$ to refer also to the corresponding binary adjacency matrix, using $G_{i j}$ to refer to the entry $(i, j)$ of the adjacency matrix, as will be clear from context. Where needed to make the distinction clear we will use $G^{*}$ to denote a true (unknown) graph and $\tilde{G}$ an estimate thereof. We use linear indexing of variable pairs to aid formulation as a machine learning problem. Specifically, an ordered pair $(i, j) \in V \times V$ has an associated linear index $k \in \mathcal{K}={1, \ldots, K}$, where $K$ is the total number of variable pairs of interest. Where useful we make the mapping explicit, denoting the linear index corresponding to a pair $(i, j)$ as $k(i, j)$ and the variable pair corresponding to a linear index $k$ as $(i(k), j(k))$. The linear indices of pairs whose causal relationships are unknown and of interest are $\mathcal{U} \subset \mathcal{K}$ and those pairs known in advance via input knowledge $\Pi$ are $\mathcal{T}(\Pi) \subset \mathcal{K}$ (the notation emphasizes the fact that the set $\mathcal{T}$ is, in general, determined by the input knowledge $\Pi$ ). In all experiments $\mathcal{T}(\Pi)$ and $\mathcal{U}$ are disjoint, i.e., no prior causal information is available on the pairs $\mathcal{U}$ of interest.</p>
<h1>2.2 Problem statement</h1>
<p>We focus on the setting in which available inputs are:
(I1) Empirical data: an $n \times p$ data matrix $X$ whose columns correspond to variables $X_{1}, \ldots, X_{p}$.
(I2) Causal background knowledge $\Pi$ providing information on a subset $\mathcal{T}(\Pi) \subset \mathcal{K}$ of causal relationships.</p>
<p>For (I2), we assume that the prior knowledge $\Pi$ can be viewed as information concerning the causal status of a subset of variable pairs. That is, for some variable pairs $\left(X_{i}, X_{j}\right)$ the correct binary indicator $G_{i j}^{*}$, representing the presence/absence of an edge in the target graphical object, is provided as an input. In terms of linear indexing, these can be viewed as available "labels" of causal status for the pairs $\mathcal{T}(\Pi) \subset$ $\mathcal{K}$. No specific assumption is made on the data $X$, but in line with our focus on generalizing to unseen causal relationships, it is assumed that it does not contain interventional data corresponding to the pairs in $\mathcal{U}$. Furthermore, in all experiments, not only are the sets $\mathcal{T}$ and $\mathcal{U}$ disjoint, but we enforce the stronger requirement that $u \in \mathcal{U} \Longrightarrow \nexists j: k(i(u), j) \in \mathcal{T}$, meaning all interventions on which models are tested are entirely novel, i.e. unrepresented in the inputs to the learner.</p>
<p>Thus, the learning task can be formulated as follows: given the inputs (I1) and (I2), the goal is to estimate for each ordered pair of variables $\left(X_{i}, X_{j}\right)$ with unknown causal relationship, whether or not $X_{i}$ has a causal influence on $X_{j}$, or equivalently to learn the underlying graph $G^{*}$.</p>
<h3>2.3 Summary of learning scheme</h3>
<p>With the notation above, the goal is to learn a graph whose nodes correspond to the variables $X_{1}, \ldots, X_{p}$ and edges represent causal relationships. To this end, we train a parameterized network $F_{\theta}$, i.e. a nonlinear function $F$ with a set of unknown, trainable parameters $\theta$. This is possible since we know for each pair $k \in \mathcal{T}$ the causal status $G_{i(k), j(k)}^{<em>}$ based on input information $\Pi$. The architecture we use as $F_{\theta}$ is detailed below, but for now assume this has been specified. Then, given the data $X$ and prior input $\Pi$, we learn parameters $\hat{\theta}(X, \Pi)$ under a loss that is supervised by the (causal) inputs/labels $Y_{k}=G_{i(k), j(k)}^{</em>}$ for all pairs $k \in \mathcal{T}(\Pi)$. In contrast to MRCL [Hill et al., 2019], which is semi-supervised and does not scale to high-dimensions, our approach is supervised and aimed at high-dimensional problems and unlike Noè et al. [2019] we use a deep</p>
<p>learning framework that learns causally-informed embeddings. We share with Eigenmann et al. [2020] an emphasis on causal risk, but our focus is on learning, rather than risk estimation.</p>
<p>At this stage, the trained network $F_{\hat{\theta}(X, \Pi)}$ allows assignment of causal status to any pair since it gives an estimate of the entire graph including those pairs whose causal status was unknown. Specifically, the output is given by:</p>
<p>$$
\hat{G}<em _hat_theta="\hat{\theta">{i j}(X, \Pi)= \begin{cases}F</em>
$$}(X, \Pi)}(i, j ; X) &amp; \text { if } k(i, j) \notin \mathcal{T}(\Pi) \ Y_{k(i, j)}(\Pi) &amp; \text { otherwise }\end{cases</p>
<p>where $(i, j)$ are ordered variable pairs. Note that the overall estimate depends solely on the data $X$ and causal information $\Pi$. By default, no change is made for pairs $\mathcal{T}$ whose status was known at the outset. Eigenmann et al. [2020] studied causal notions of risk based on loss functions of the form $L\left(\hat{G}, G^{<em>}\right)$ that compare a graph estimate $\hat{G}$ with ground-truth $G^{</em>}$. In our setting, we consider a classification-type loss on the variable pairs $k$, where the causal status of known pairs $\mathcal{T}(\Pi)$ provides the training "labels". We therefore use the corresponding binary cross-entropy loss, augmented by additional terms that, for instance, prevent exploding weights.</p>
<p>In the $\mathrm{D}^{2} \mathrm{CL}$ framework the notion of causal influence encoded by the edges is rooted in the application setting and input information $\Pi$, since causal semantics are inherited via the problem setting rather than specified by a generative model (see Hill et al. [2019] for related discussion). Indeed, in the experiments below we show examples in which $\mathrm{D}^{2} \mathrm{CL}$ is used to learn either direct or indirect/ancestral causal relationships, depending on the setting and inputs. We direct the interested reader to Appendix A for further discussion of assumptions.</p>
<h1>2.4 Architecture details</h1>
<p>CNN Tower: To capture distributional information from empirical data $X$, a preprocessing step is required. In principle, this could be done via a variety of multi-dimensional transformations of $X$. We consider the simplest possible case, namely for a pair $(i, j)$ to consider only the corresponding columns $i$ and $j$ in the data matrix $X$. Specifically, we use the $n \times 2$ submatrix $X_{[\cdot,[i j]]}$, to form a bivariate kernel density estimate $f_{i j}=\operatorname{KDE}\left(X_{[\cdot,[i j]]}\right)$. Note that this is in general asymmetric in the sense that $f_{i j} \neq f_{j i}$, which is important since we want to learn ordered/directed relationships. Evaluations of the KDE at equally spaced grid points on the plane (i.e. numerical values from the induced density function) are treated as the input to the CNN. The KDE itself is a standard bivariate approach using automated bandwidth selection following Silverman [1986], Turlach [1993]. This provides an "image" of the data and allows us to leverage standard tools from computer vision. Furthermore, we concatenate channelwise the numerical KDE values on the regularly spaced grid with a positional encoding of the grid points.</p>
<p>The specific network architecture of our CNN tower is inspired by a ResNet-54 architecture [He et al., 2016]. From a high level perspective, it consists of a stem, five stages with $[3,4,6,3,3]$ ResNet blocks and multiple fully connected layers that transform the high-level feature maps into a latent space that is merged with the output of the GNN tower. The first ResNet block at each stage downsamples the spatial dimensions of the output of the previous stage by a factor of two. To enhance the computational efficiency of the bottleneck layers in each ResBlock, channel down- and up-sampling exploiting $1 \times 1$ convolutions is performed before and after each feature extraction CNN layer [Szegedy et al., 2015]. We replaced ReLU activations by the parametric counterpart PReLU [He et al., 2015]. Following Xie et al. [2017], we chose a full pre-activation</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of the $\mathrm{D}^{2} \mathrm{CL}$ architecture, training and inference. $\mathrm{D}^{2} \mathrm{CL}$ combines empirical data with prior causal knowledge to learn causal relationships between variables. This is done using a neural architecture with two components: a CNN tower aimed at learning distributional features and a GNN tower that detects structural regularities. The CNN and GNN embeddings are then merged through multiple layers to estimate the probability of a directed causal relationship. During inference the network generalizes beyond the initial inputs to provide a global estimate spanning all variables of interest.
of the convolutional layers, normalization-activation-convolution.
GNN tower. The GNN tower leverages the SEAL architecture of Zhang and Chen [2018] and the resulting graph convolutional neural network (GCNN) for link prediction. The underlying notion is that a heuristic function predicts scores for the existence of a link. However, instead of employing predefined heuristics (such as the Katz coefficient or PageRank), an adaptive function is learned in an end-to-end fashion, which is formulated as a graph classification problem on enclosing subgraphs. Here, for a node pair of interest $(i, j)$, the GNN tower is intended to learn causally relevant node features and state embeddings based on a local 1-hop enclosing subgraph extracted from an initial input graph $\hat{G}<em 0="0">{0}$. This is done as follows. For node pair $(i, j)$, we first extract a set $\mathcal{N}$ of neighbouring nodes comprising all nodes connected to either $i$ or $j$ in $\hat{G}</em>$. The order of the nodes is shuffled for each subgraph. The node features in every input subgraph consist of structural node labels that are assigned by a Double-Radius Node Labeling (DRNL) heuristic [Zhang and Chen, 2018] and the individual data features. In a first step, the distances between node $i$ and all other nodes of the local subgraph except node $j$ are computed. The same is repeated for node $j$. A hashing function then transforms the two distance labels into a DRNL label that assigns the same label to nodes that are on the same "orbit" around the center nodes $i$ and $j$. During the training process the DRNL label is transformed into a one-hot encoded vector and passed to the first graph convolutional layer. In contrast to traditional CNNs, GCNNs do not benefit strongly from very deep}$. Then, the edge structure within the subgraph $G_{i j}$ is reconstructed by pulling out all edges from $\hat{G}_{0}$ for which the parent and child node are in $\mathcal{N</p>
<p>architecture design [Chen et al., 2019, Li et al., 2018]. Therefore, our GNN tower consists only of four sequentially stacked graph convolutional layers. The activation function is the hyperbolic tangent. Since the number of nodes in the enclosing subgraph for each pair of variables $(i, j)$ is different, a SortPooling layer [Zhang et al., 2018] is applied to select the top $k$ nodes according to their structural role within the graph. Afterwards, 1-dimensional convolutions extract features from the selected state embeddings.</p>
<p>Embedding Fusion. Each tower outputs an embedding; these are concatenated and further processed by multiple fully connected layers. Finally, the last layers output the log-likelihood of a directed edge from node $i$ to node $j$.</p>
<p>Implementation summary. All network architectures were implemented in the open source framework PyTorch [Paszke et al., 2019]. The GNN was implemented based on the deep graph library [Wang et al., 2019]. All modules were initialized using random weights. During training, we applied an Adam-Optimizer [Kingma and Ba, 2015] starting at an initial learning rate $\varepsilon_{0}=0.0001$. Furthermore, the learning rate was reduced by a factor of five once the evaluation metrics stopped improving for 15 consecutive epochs. The minimum learning rate was set to $\varepsilon_{\text {min }}=10^{-8}$. The training predictions were supervised on the binary cross entropy loss between estimated and ground truth edge labels. Every network architecture was trained for 100 epochs, using multiple GPU nodes simultaneously, each equipped with eight Nvidia Tesla V100s.</p>
<h1>3 Results</h1>
<p>We assess the proposed approaches in comparison to a range of existing methods, using both simulated data and real biological data. In the case of the simulations, we have access to the true, underlying causal graph, and hence can assess results by direct comparison with the ground truth. For the real data examples, we test the model output against the outcome of entirely unseen interventional experiments. In all experiments, simulated or real, model output is tested with respect to causal relationships that are entirely unseen in the sense that (i) the variable pairs on which the model output is tested are disjoint from those pairs whose causal relationships are provided as inputs during training, and (ii) no data used to define the gold-standard causal relationships against which the model output is tested appear in inputs to the models.</p>
<h3>3.1 Gold-standard simulated benchmark data.</h3>
<p>We first tested $\mathrm{D}^{2} \mathrm{CL}$ using linear and non-linear simulations. These involved generating data $X$ (and obtaining prior knowledge $\Pi$ ) from a (linear or non-linear) structural equation model (SEM) with noise, based on a known underlying causal graph $G^{<em>}$. The protocol is outlined in Figure 2a. In brief, data were generated via structural equations of the form $X_{i}=f_{i}\left(P a_{G^{</em>}}\left(X_{i}\right), U_{X_{i}}\right)$, for $i=1, \ldots, p$, where $p$ is the total number of variables, $P a_{G^{<em>}}\left(X_{i}\right)$ is the set of parents for node $i$ in the true graph $G^{</em>}$, the $U_{X_{i}}$ 's are noise variables (exogenous and jointly independent) and the $f_{i}$ 's functions unknown to the learners. Functional forms used include simple linear functions, multi-layer perceptrons (MLPs) with tangent hyperbolic activations, MLPs with leaky ReLU activation, leaky ReLU, a polynomial of order three and the tangent hyperbolic. Varying the magnitude of the noise terms allowed us to control the signal-to-noise ratio (SNR), while varying $p$ allowed us to understand the effect of dimensionality. Results were evaluated against the true, gold-standard causal structure $G^{*}$ and hence tested in causal (and not correlational or predictive) terms.</p>
<p>Figure 2 b shows results for a problem of dimension $p=1500$ using a nonlinear transition function (the</p>
<p>tangent hyperbolic; other functions/configurations are shown in Appendix B) and varying SNR. (For these first results, we restricted the dimension of the problem to facilitate comparison with approaches that may not scale to larger problems; higher dimensional examples appear below.) Overall, $\mathrm{D}^{2} \mathrm{CL}$ remains effective across a broad range of SNRs, as well as for a range of linear and nonlinear problems and problem sizes (Appendix B). These results support the notion that $\mathrm{D}^{2} \mathrm{CL}$ can learn direct causal edges in systems spanning many variables. We note that the comparison with existing approaches is not one-to-one, since in many cases methods differ in their expected inputs and outputs. For example, IDA is aimed at analysis of observational data, hence the comparison is unfair since our approach has access also to background causal information $\Pi$. GIES allows for interventional data, but requires different inputs. Due to these differences in input/output requirements, we emphasize that comparisons here are provided for completeness but with the caveat that the various methods are intended for different use-cases (and furthermore make assumptions that are likely not met in the real biological data below).</p>
<p>The graph $G^{*}$ in the above examples encodes direct causal relationships since there is an edge from one node to another if the former appears in the equation for the latter. However, in many real-world examples, interest focuses also on indirect effects, that may be mediated by other nodes. For example, if node $A$ has a direct effect on $B$, and $B$ on $C$, intervention on $A$ may change $C$, even though $A$ does not itself appear in the equation for $C$. To study the ability to identify such indirect effects, we next tested the various methods on the task of learning indirect edges. This was done in the same way as above, but with the inputs $\Pi$ being indirect edges and output tested against the true indirect graph.</p>
<p>Results appear in Figure 2c. $\mathrm{D}^{2} \mathrm{CL}$ performs well across a range of SNRs and also in other linear/nonlinear problem configurations (Appendix B). IDA performs well in case of a linear SEM but not for functions based on nonlinear MLPs. These results support the notion that $\mathrm{D}^{2} \mathrm{CL}$ can learn indirect causal edges over many variables under conditions of noise and nonlinearity.</p>
<h1>3.2 Large-scale biological data.</h1>
<p>Next, we sought to study performance in the context of real biological data. To this end, we leveraged a large set of gene deletion experiments in yeast [Kemmeren et al., 2014], which have previously been used for causal learning [Peters et al., 2016, Meinshausen et al., 2016, Hill et al., 2019]. These data involve measuring gene expression in yeast cells under each of a large number of interventional (gene deletion) experiments. To define causal status, we followed the approach of Hill et al. [2019], considering changes under intervention relative to the observational distribution.</p>
<p>In biological experiments, causal effects may be indirect and our goal in the analysis is to learn a directed graph with nodes corresponding to $p$ observed genes and edges representing (possibly indirect) causal influences. Such edges are scientifically interesting as they are relatively amenable to experimental verification [as noted in Zhang, 2008, Noè et al., 2019]. Cycles can arise in systems biology [see e.g. Alon, 2019] and we do not enforce acyclicity [see Hyttinen et al., 2012, and references therein, for discussion of cyclic causality]. A fuller discussion of the causal interpretation of laboratory experiments is beyond the scope of this paper, but relevant work includes Eberhardt and Scheines [2007], Hyttinen et al. [2012], Kocaoglu et al. [2017] and we direct the interested reader to these references for further discussion.</p>
<p>Since causal background knowledge is an input to our approach, it is relevant to consider performance as a function of the amount of such input. To this end, we fixed the problem size to $p=1000$ and varied the number of interventions $m$ whose effects were available to the learner. Since each experiment involves only</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Results, simulated data. (a) Overview. Data were simulated from known, gold-standard causal graphs with which the output of the learners was compared. Empirical data were generated using a directed causal graph of specified dimension $p$ using linear and nonlinear structural equation models with noise (see text). (b) Results for an illustrative nonlinear case (the tangent hyperbolic), at varying noise levels, for direct causal relationships. Causal area under the ROC-Curve (AUC; with respect to the causal ground truth graph) is shown as a function of signal-to-noise ratio (SNR) for an experiment with $p=1500$ variables and a sample size of $n=1024$. $\mathrm{D}^{2} \mathrm{CL}$ (blue) is compared with: Pearson correlations (yellow; this is a non-causal baseline); IDA (red); and SCL (green). (c) Results for indirect causal relationships, with other settings as in (b). Here, causal AUC is with respect to a graph encoding causal, but potentially indirect, relationships. (Results shown are averages over five data sets at each specified SNR.)
a subset of the entire yeast genome, latent variables are present by design. The input prior knowledge $\Pi$ is derived from the causal status, but, as in all experiments, is strictly disjoint with respect to any test edges.</p>
<p>Results are shown in Figure 3a-c, including the area under the ROC curve (AUC; computed with respect to an experimentally-determined gold-standard, as in Hill et al. [2019]). Interestingly, the two towers differ in some ways: the CNN tower degrades slowly with fewer causal inputs while the performance of the GNN tower degrades faster. GIES [Hauser and Bühlmann, 2012] was not effective in this setting (result not shown; findings are in line with Hill et al. [2019] using the same data); however, we note that GIES requires different inputs to our approach and its assumptions are likely violated in this setting. Next, to shed light on data efficiency we varied the sample size $n$ of the data matrix $X$. Results are shown in Figure 3d-f.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Results, biological data. Causal learning methods, including $\mathrm{D}^{2} \mathrm{CL}$, were applied to gene expression measurements from yeast cells. Performance was quantified using causal ROC curves (and the area under the curves, or AUC) computed with respect to a causal ground truth obtained from entirely unseen interventional experiments (see text). Panels (a)-(c): number of interventions whose effects are available to the learner varied as shown (with problem dimension fixed to $p=1000$ and sample size to $n=706$ ). Panels (d)-(f): sample size $n$ varied as shown (with problem dimension fixed to $p=1000$ and number of available interventions to $m=753$ ). Panels (g)-(k): $\mathrm{D}^{2} \mathrm{CL}$ results for a higher-dimensional setting spanning all available genes with $p=5535$ (with $n=706$ and $m=753$ ). [ $\mathrm{D}^{2} \mathrm{CL}$ variants shown include CNN tower alone, GNN tower alone and the combined architecture; methods compared against include IDA, LV-IDA, Kendall correlations (as a non-causal baseline) and SCL (see text). For $\mathrm{D}^{2} \mathrm{CL}$ variants with a GNN component two different initial graph estimates were used based respectively on Pearson correlation coefficients ("Pearson") and on a lightweight regression ("Lasso"; see text for details).]</p>
<p>Finally, we tested performance in a higher dimensional example spanning all $p=5535$ available genes (cf. Figure 3g-k) and found that $\mathrm{D}^{2} \mathrm{CL}$ remains effective at genome scale. Interestingly, while the CNN tower performs particularly well, the GNN tower degrades more. This may be because larger $p$ leads to a larger number of variable pairs (which is helpful for the CNN), but also to a (rapid) increase in the number of nodes and edges in the GNN subgraphs and hence a harder GNN learning task in practice.
$\mathrm{D}^{2} \mathrm{CL}$ leverages prior causal knowledge; however, in practice, available causal inputs $\Pi$ may be incorrect, e.g. due to flawed initial experiments or errors in the known science. To study sensitivity to flawed causal inputs we introduced errors into $\Pi$. This was done by perturbing $10 \%$ of the inputs (i.e. labelling causal pairs as non-causal and vice versa) at the outset. Figure 4a shows corresponding results; the networks seem reasonably robust in this sense. These experiments point also to a benefit of the dual network variants: when one tower underperforms, the combined network still performs well, as it (automatically) adapts to rely on the effective tower. This aspect is further investigated in Figure 4b. To test the impact of a failing tower on overall performance, the embedding of either tower was modified right before the fusion layer. We considered four different modifications: (i) setting the complete embedding of one tower to zero and hence effectively removing all information from this tower. In the other cases we applied Gaussian noise with magnitude (ii) $\sigma=1.0$, (iii) $\sigma=2.0$, and (iv) $\sigma=5.0$. The results support the notion that even when one</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Sensitivity to incorrect causal inputs and additional results on causal direction. (a) Robustness to incorrect causal inputs. Sensitivity of $\mathrm{D}^{2} \mathrm{CL}$ to errors in prior/input causal knowledge $\Pi$ was studied by artificially introducing errors into $\Pi$, with $10 \%$ of inputs corrupted (see text). Results quantified via causal AUC (with respect to the correct ground truth). (b) Ablation-like study in which failures of either the CNN (orange) or the GNN (blue) tower within $\mathrm{D}^{2} \mathrm{CL}$ are artificially introduced. The affected embedding is either set to zero or zero-mean Gaussian noise with varying scale is applied. The unaffected case is given as dashed black line. (c) Causal direction analysis. Low-dimensional representations of latent feature maps of the converged CNN tower at two different layer depths. Edges $A \rightarrow B$ shown as dots and reverse edges $B \rightarrow A$ as x -shaped markers. An edge and its corresponding reverse is indicated by the same color. For improved readability, ten (randomly chosen) pairs are highlighted in colors and larger markers. [ $\mathrm{D}^{2} \mathrm{CL}$ variants include: a CNN tower alone; a GNN tower for two different initial graph estimates; and the complete architecture. Initial graph estimates for the GNN and combined models either based on Pearson correlation coefficients ("Pearson") or a lightweight regression ("Lasso"; see text).]
tower fails, the second can compensate so that $\mathrm{D}^{2} \mathrm{CL}$ still provides useful output.
Causal relations are in general directed and asymmetric. Given an image representation, the CNN tower extracts feature maps for (ordered) node pairs. The two-dimensional convolutional operation $S(i, j)=$ $\sum_{m} \sum_{n} I(m, n) K(i-m, j-n)$ that convolves image $I$ with kernel $K$ would produce the same feature map for two causal images $I_{k \rightarrow l}$ and $I_{l \rightarrow k}$ if and only if $I_{k \rightarrow l}$ and $I_{l \rightarrow k}$ were identical. In other words, unless the probability distribution $P\left(X_{i}, X_{j}\right)$ is perfectly symmetrical around the center of the causal image, the CNN tower can extract causal features that differ depending on direction. Figure 4c shows a low-dimensional representation of the feature maps of the converged CNN tower; the feature maps differ by direction, supporting the notion that the representations learned are asymmetric.</p>
<h1>4 Conclusions</h1>
<p>Our model leverages deep learning tools to learn causal relationships between variables in a scalable manner. However, and in contrast to well established approaches based on causal graphical models, it provides only structural output rather than a probability model of the underlying system. It would therefore be interesting to consider coupling our approach, as a first learning step, with a graphical model based analysis in a second step. This would amount to using the flexible and scalable discriminative approach as a filter to render subsequent causal modelling more tractable.</p>
<p>Despite some initial ideas presented here (see also Appendix A), there remain open questions concerning the theoretical properties of the kind of approach studied here. In particular, precise conditions on the underlying system needed to ensure that the classification-type approach can guarantee recovery of specific causal structures remain to be elucidated. An interesting observation is that the proposed approach may benefit from a "blessing of dimensionality", since the learning problem will typically enjoy a larger number of examples as the dimension $p$ grows. Conversely, and in contrast to established statistical-causal models, our approach (at the current stage) cannot be used in the small- $p$ regime, since then the number of examples will be too small for deep learning.</p>
<h2>References</h2>
<p>Uri Alon. An introduction to systems biology: design principles of biological circuits. CRC press, 2019.
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint, 2019.</p>
<p>Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. Measuring and relieving the over-smoothing problem for graph neural networks from the topological view. Computing Research Repository (CoRR), 2019.</p>
<p>Diego Colombo, Marloes H. Maathuis, Markus Kalisch, and Thomas S. Richardson. Learning highdimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics, 40: 294-321, 2012.</p>
<p>Frederick Eberhardt and Richard Scheines. Interventions and causal inference. Philosophy of Science, 74 (5):981-995, 2007.</p>
<p>Marco Eigenmann, Sach Mukherjee, and Marloes Maathuis. Evaluation of causal structure learning algorithms via risk estimation. In Proceedings of Uncertainty in Artificial Intelligence 2020, UAI 2020, 2020.</p>
<p>Madelyn Glymour, Judea Pearl, and Nicholas P Jewell. Causal inference in statistics: A primer. John Wiley \&amp; Sons, 2016.</p>
<p>Alain Hauser and Peter Bühlmann. Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs. The Journal of Machine Learning Research, 13:2409-2464, 2012.</p>
<p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification. In 2015 IEEE International Conference on Computer Vision (ICCV), pages 1026-1034, 2015.</p>
<p>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016.</p>
<p>Christina Heinze-Deml, Marloes H. Maathuis, and Nicolai Meinshausen. Causal Structure Learning. Annual Review of Statistics and Its Application, 5:371-391, 2018.</p>
<p>Steven M. Hill, Laura Heiser, Thomas Cokelaer, et al. Inferring causal molecular networks: Empirical assessment through a community-based effort. Nature Methods, 13:310-318, 2016.</p>
<p>Steven M. Hill, Chris J. Oates, Duncan A. Blythe, and Sach Mukherjee. Causal learning via manifold regularization. The Journal of Machine Learning Research, 20:1-32, 2019.</p>
<p>Antti Hyttinen, Frederick Eberhardt, and Patrik O Hoyer. Learning linear cyclic causal models with latent variables. The Journal of Machine Learning Research, 13(1):3387-3439, 2012.</p>
<p>Patrick Kemmeren, Katrin Sameith, Loes AL van de Pasch, Joris J Benschop, Tineke L Lenstra, Thanasis Margaritis, Eoghan O Duibhir, Eva Apweiler, Sake van Wageningen, Cheuk W Ko, et al. Large-scale genetic perturbations reveal regulatory networks and an abundance of gene-specific repressors. Cell, 157 (3):740-752, 2014.</p>
<p>Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. Computing Research Repository (CoRR), abs/1412.6980, 2015.</p>
<p>Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for learning causal graphs with latent variables. In Advances in Neural Information Processing Systems 30, NIPS, 2017.</p>
<p>Qimai Li, Zhichao Han, and Xiao-Ming Wu. Deeper insights into graph convolutional networks for semisupervised learning. Computing Research Repository (CoRR), abs/1801.07606, 2018.</p>
<p>David Lopez-Paz, Krikamol Muandet, Bernhard Schölkopf, and Iliya Tolstikhin. Towards a learning theory of cause-effect inference. In International Conference on Machine Learning, 2015.</p>
<p>Marloes H. Maathuis, Markus Kalisch, and Peter Bühlmann. Estimating high-dimensional intervention effects from observational data. The Annals of Statistics, 37:3133-3164, 2009.</p>
<p>Nicolai Meinshausen, Alain Hauser, Joris M. Mooij, Jonas Peters, Philip Versteeg, and Peter Bühlmann. Methods for causal inference from gene perturbation experiments and validation. Proceedings of the National Academy of Sciences of the United States of America, 113(27):7361-7368, 2016.</p>
<p>Joris M. Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Schölkopf. Distinguishing cause from effect using observational data: Methods and benchmarks. The Journal of Machine Learning Research, 17:1-102, 2016.</p>
<p>Umberto Noè, Bernd Taschler, Joachim Täger, Peter Heutink, and Sach Mukherjee. Ancestral causal learning in high dimensions with a human genome-wide application. arXiv preprint arXiv:1905.11506, 2019.</p>
<p>Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.</p>
<p>Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(5):947-1012, 2016.</p>
<p>Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of Causal Inference: Foundations and Learning Algorithms. MIT Press, Cambridge, MA, USA, 2017.</p>
<p>Bernhard Schölkopf, Dominik Janzing, Jonas Peters, Eleni Sgouritsa, Kun Zhang, and Joris Mooij. On causal and anticausal learning. Proceedings of the 29th International Conference on Machine Learning, ICML 2012, 2, 2012.</p>
<p>Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvärinen, and Antti Kerminen. A linear non-Gaussian acyclic model for causal discovery. The Journal of Machine Learning Research, 7:2003-2030, 2006.</p>
<p>Bernard W. Silverman. Density Estimation for Statistics and Data Analysis. Chapman \&amp; Hall, 1986.
Peter Spirtes, Clark Glymour, and Richard Scheines. Causation, Prediction, and Search. MIT Press, Cambridge, second edition, 2000. With additional material by D. Heckerman, C. Meek, G.F. Cooper and T. Richardson.</p>
<p>Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.</p>
<p>Berwin A Turlach. Bandwidth selection in kernel density estimation: A review. In CORE and Institut de Statistique, 1993.</p>
<p>Minjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song, Jinjing Zhou, Chao Ma, Lingfan Yu, Yu Gai, Tianjun Xiao, Tong He, George Karypis, Jinyang Li, and Zheng Zhang. Deep graph library: A graph-centric, highly-performant package for graph neural networks. arXiv preprint arXiv:1909.01315, 2019.</p>
<p>Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.</p>
<p>Jiji Zhang. Causal reasoning with ancestral graphs. The Journal of Machine Learning Research, 9:14371474, 2008.</p>
<p>Muhan Zhang and Yixin Chen. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems 2018, NeurIPS 2018, 2018.</p>
<p>Muhan Zhang, Zhicheng Cui, M. Neumann, and Yixin Chen. An end-to-end deep learning architecture for graph classification. In AAAI, 2018.</p>
<h1>Appendix A: Causal interpretation of the learning scheme</h1>
<p>Here, we provide some intuition on why discriminative learning can be effective in the setting of interest here. We note that the following arguments are not intended to constitute a theory at this stage but rather to help gain understanding of the conditions under which discriminative causal structure learning as described in the Main Text may be expected to be effective.</p>
<p>We start with a general causal framework and then introduce assumptions for $\mathrm{D}^{2} \mathrm{CL}$ (MGA and DCSI, see below). Following Peters et al. [2017], Schölkopf et al. [2012], we assume decomposition of the underlying system into modular and independent mechanisms:</p>
<p>Independent Causal Mechanisms (ICMs): The causal generative process of a system's variables is composed of autonomous modules that do not inform or influence each other.</p>
<p>For variables $X_{i}$ assume a structural causal model with equations $X_{i}=f_{i}\left(P a_{G^{<em>}}\left(X_{i}\right), U_{X_{i}}\right), i=1, \ldots, p$, where $P a_{G^{</em>}}\left(X_{i}\right)$ denotes the set of parents in the ground truth graph $G^{*}$ for node $i$ and $f_{i}$ is a node-specific function. Exogenous noise terms $U_{X_{i}}$ are assumed jointly independent and distributed as $U_{X_{i}} \sim p_{i}$, where $p_{i}$ is a nodespecific density.</p>
<p>Our approach treats the $f_{i}$ 's and $p_{i}$ 's as unknown but assumes they are related at a higher level. This can be formalized as a meta-generator assumption as follows:</p>
<p>Meta-Generator Assumption (MGA): For a specific system $W$, the functions $f_{i}$ and noise distributions $p_{i}$ are (independently) generated as $f_{i} \sim \mathcal{F}<em i="i">{W}$ and $p</em>} \sim \mathcal{P<em W="W">{W}$, where $\mathcal{F}</em>$ a stochastic generator, that are specific to the applied problem setting $W$.}$ denotes a function generator, and $\mathcal{P}_{W</p>
<p>MGA is motivated by the notion that in any particular real-world system, underlying (biological, physical, social, etc.) processes tend to share some functional and stochastic aspects, which impart some higherlevel regularity. That is, MGA states that in a given applied context, functions $f_{i}$ and noise terms $U_{X_{i}}$ while unknown, varied and potentially complex, are nonetheless related at a "meta"-level. The generators $\mathcal{F}<em W="W">{W}, \mathcal{P}</em>}$ are random processes, representing respectively a "distribution over functions" and "distribution over distributions", whose role here is to capture the notion of relatedness among $f_{i}$ 's (respectively $p_{i}$ 's) in a given setting $W$. Note that $\mathcal{F<em W="W">{W}, \mathcal{P}</em>$ are treated as unknown and never directly estimated (see below).</p>
<p>As noted above, we focus on the causal status of variable pairs $\left(X_{i}, X_{j}\right)$ (rather than general tuples) which is the simplest possible case under MGA. Furthermore, in both our work and the majority of interventional studies in applications such as biology, single interventions (rather than joint interventions on multiple nodes) are the norm. Focusing on single interventions motivates the following additional assumption:</p>
<p>Dominant cause under single interventions (DCSI): A sufficiently large change in one of potentially multiple causes leads to a change w.r.t. the effect. Therefore, single interventions are sufficient to drive variation in the child distribution.</p>
<p>From MGA and DCSI to discriminative causal structure learning. Consider an applied problem $W$ with underlying causal graph $G_{W}^{*}$, treated as fixed but unknown. The associated functions and noise terms are also unknown but assumed to follow MGA. Then, under DCSI, we have that all pairs of the form $\left(X_{i}, X_{j}\right)$, have underlying relationships of the form $X_{j}=f_{j}\left(X_{i}, U_{X_{j}}\right)$ with components following the MGA (i.e. drawn from generators $\mathcal{F}<em W="W">{W}, \mathcal{P}</em>$ ). This in turn suggests that within the setting $W$, identification of causal pairs can be treated as a classification problem, since all pairs share the same generators. In other words, MGA restricts</p>
<p>the distribution over relations of variables and noise terms to system-specific distributions.
Note that no particular assumption is made on the individual functions $f_{i}$, only that they are mutually related on a higher level. Furthermore, the generators themselves need not to be known or are directly estimated, it is only important that they are shared across the applied setting $W$. Note that a model learned for setting $W$ will not in general be able to classify pairs in an entirely different applied setting $W^{\prime}$ (since the generators may then differ strongly), i.e. we do not seek to learn "universal" patterns that apply to all causal relations in any system whatsoever. The classification task of $\mathrm{D}^{2} \mathrm{CL}$ aims at telling apart causal relationships, related by the system-specific function generator $F_{W}$, from non-causal ones. We note that in real systems, $f_{i}$ 's may be coupled via constraints on global functionality, hence non-independent, however, the good performance seen in the Main Text empirically justifies the approach. We emphasize that while the ideas above provide some initial intuition, further work is needed to better understand the properties of the kind of approach studied here from a theoretical point of view.</p>
<h1>Appendix B: additional results</h1>
<h2>Simulated data: direct causal relationships</h2>
<p>Table 1: AUC values for direct cause-effect relations for $p=|V|=1500$.</p>
<p>| SNR | Linear |  |  |  | MLP(maly) |  |  |  | MLP(leaky ReLU) |  |  |  | Tanh |  |  |  | Leaky ReLU |  |  |  | Polynom 3 |  |  |  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ |
| 10.00 | 0.718 | 0.748 | 0.789 | 0.641 | 0.691 | 0.625 | 0.686 | 0.634 | 0.688 | 0.608 | 0.693 | 0.623 | 0.728 | 0.777 | 0.854 | 0.851 | 0.756 | 0.837 | 0.843 | 0.729 | 0.809 | 0.848 | 0.829 | 0.641 |
| 6.00 | 0.700 | 0.771 | 0.795 | 0.617 | 0.670 | 0.609 | 0.658 | 0.638 | 0.666 | 0.590 | 0.683 | 0.602 | 0.710 | 0.783 | 0.861 | 0.841 | 0.736 | 0.818 | 0.839 | 0.692 | 0.784 | 0.824 | 0.821 | 0.637 |
| 4.00 | 0.684 | 0.768 | 0.784 | 0.616 | 0.648 | 0.590 | 0.647 | 0.625 | 0.652 | 0.562 | 0.667 | 0.584 | 0.689 | 0.770 | 0.854 | 0.819 | 0.700 | 0.792 | 0.831 | 0.668 | 0.735 | 0.787 | 0.812 | 0.628 |
| 2.00 | 0.638 | 0.781 | 0.802 | 0.615 | 0.613 | 0.544 | 0.639 | 0.594 | 0.617 | 0.521 | 0.661 | 0.592 | 0.639 | 0.750 | 0.844 | 0.764 | 0.644 | 0.743 | 0.815 | 0.630 | 0.651 | 0.722 | 0.777 | 0.617 |
| 1.00 | 0.595 | 0.774 | 0.796 | 0.614 | 0.572 | 0.506 | 0.622 | 0.551 | 0.575 | 0.487 | 0.642 | 0.546 | 0.593 | 0.740 | 0.806 | 0.721 | 0.582 | 0.701 | 0.787 | 0.619 | 0.552 | 0.659 | 0.743 | 0.598 |
| 0.75 | 0.589 | 0.765 | 0.793 | 0.612 | 0.556 | 0.494 | 0.619 | 0.566 | 0.567 | 0.483 | 0.638 | 0.568 | 0.580 | 0.724 | 0.795 | 0.689 | 0.572 | 0.696 | 0.783 | 0.610 | 0.539 | 0.645 | 0.734 | 0.603 |
| 0.50 | 0.558 | 0.748 | 0.787 | 0.610 | 0.536 | 0.473 | 0.631 | 0.540 | 0.544 | 0.459 | 0.641 | 0.567 | 0.558 | 0.697 | 0.770 | 0.654 | 0.548 | 0.678 | 0.771 | 0.606 | 0.521 | 0.640 | 0.717 | 0.592 |
| 0.25 | 0.537 | 0.735 | 0.784 | 0.572 | 0.530 | 0.467 | 0.617 | 0.517 | 0.496 | 0.434 | 0.624 | 0.552 | 0.538 | 0.667 | 0.733 | 0.588 | 0.517 | 0.667 | 0.748 | 0.579 | 0.514 | 0.634 | 0.694 | 0.543 |
| 0.10 | 0.523 | 0.730 | 0.774 | 0.558 | 0.492 | 0.441 | 0.618 | 0.530 | 0.507 | 0.439 | 0.616 | 0.528 | 0.513 | 0.630 | 0.725 | 0.562 | 0.503 | 0.661 | 0.743 | 0.559 | 0.492 | 0.620 | 0.691 | 0.539 |</p>
<h2>Simulated data: indirect/ancestral relationships</h2>
<p>Table 2: AUC values for indirect cause-effect relations for $p=|V|=1500$.</p>
<p>| SNR | Linear |  |  |  | MLP(maly) |  |  |  | MLP(leaky ReLU) |  |  |  | Tanh |  |  |  | Leaky ReLU |  |  |  | Polynom 3 |  |  |  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ | Pearson | IDA | $\mathrm{D}^{2} \mathrm{CL}$ | $\mathrm{SCL}$ |
| 10.00 | 0.553 | 0.907 | 0.928 | 0.708 | 0.548 | 0.522 | 0.733 | 0.700 | 0.563 | 0.483 | 0.789 | 0.738 | 0.511 | 0.903 | 0.947 | 0.905 | 0.502 | 0.857 | 0.943 | 0.839 | 0.610 | 0.822 | 0.933 | 0.761 |
| 6.00 | 0.540 | 0.905 | 0.925 | 0.700 | 0.537 | 0.502 | 0.728 | 0.658 | 0.552 | 0.458 | 0.775 | 0.735 | 0.487 | 0.896 | 0.947 | 0.895 | 0.501 | 0.852 | 0.941 | 0.808 | 0.598 | 0.815 | 0.927 | 0.751 |
| 4.00 | 0.530 | 0.905 | 0.928 | 0.677 | 0.533 | 0.490 | 0.711 | 0.675 | 0.548 | 0.447 | 0.767 | 0.727 | 0.460 | 0.881 | 0.947 | 0.888 | 0.504 | 0.848 | 0.937 | 0.782 | 0.581 | 0.803 | 0.914 | 0.732 |
| 2.00 | 0.506 | 0.897 | 0.928 | 0.619 | 0.523 | 0.461 | 0.683 | 0.656 | 0.532 | 0.420 | 0.766 | 0.695 | 0.424 | 0.851 | 0.940 | 0.856 | 0.501 | 0.834 | 0.920 | 0.736 | 0.543 | 0.775 | 0.879 | 0.704 |
| 1.00 | 0.507 | 0.888 | 0.925 | 0.609 | 0.513 | 0.433 | 0.660 | 0.626 | 0.518 | 0.393 | 0.738 | 0.672 | 0.405 | 0.810 | 0.895 | 0.791 | 0.502 | 0.824 | 0.900 | 0.676 | 0.520 | 0.753 | 0.831 | 0.658 |
| 0.75 | 0.507 | 0.882 | 0.920 | 0.631 | 0.513 | 0.431 | 0.638 | 0.610 | 0.514 | 0.385 | 0.721 | 0.637 | 0.402 | 0.790 | 0.891 | 0.785 | 0.501 | 0.822 | 0.888 | 0.667 | 0.516 | 0.747 | 0.820 | 0.641 |
| 0.50 | 0.506 | 0.877 | 0.918 | 0.505 | 0.510 | 0.422 | 0.618 | 0.577 | 0.513 | 0.387 | 0.713 | 0.655 | 0.407 | 0.771 | 0.861 | 0.740 | 0.502 | 0.821 | 0.880 | 0.651 | 0.510 | 0.742 | 0.808 | 0.635 |
| 0.25 | 0.513 | 0.873 | 0.913 | 0.534 | 0.511 | 0.423 | 0.622 | 0.567 | 0.509 | 0.385 | 0.703 | 0.639 | 0.441 | 0.754 | 0.830 | 0.632 | 0.498 | 0.816 | 0.861 | 0.624 | 0.502 | 0.736 | 0.792 | 0.589 |
| 0.10 | 0.506 | 0.867 | 0.905 | 0.542 | 0.501 | 0.417 | 0.617 | 0.571 | 0.503 | 0.385 | 0.705 | 0.613 | 0.481 | 0.741 | 0.819 | 0.595 | 0.500 | 0.817 | 0.865 | 0.598 | 0.503 | 0.734 | 0.784 | 0.537 |</p>            </div>
        </div>

    </div>
</body>
</html>