<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2930 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2930</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2930</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-72.html">extraction-schema-72</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-268248196</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2403.02613v1.pdf" target="_blank">Large Language Models and Video Games: A Preliminary Scoping Review</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) hold interesting potential for the design, development, and research of video games. Building on the decades of prior research on generative AI in games, many researchers have sped to investigate the power and potential of LLMs for games. Given the recent spike in LLM-related research in games, there is already a wealth of relevant research to survey. In order to capture a snapshot of the state of LLM research in games, and to help lay the foundation for future work, we carried out an initial scoping review of relevant papers published so far. In this paper, we review 76 papers published between 2022 to early 2024 on LLMs and video games, with key focus areas in game AI, game development, narrative, and game research and reviews. Our paper provides an early state of the field and lays the groundwork for future research and reviews on this topic.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2930.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2930.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents (memory-synthesising agents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>LLM-based agents that accumulate episodic observations over time and synthesise those memories into higher-level reflections used to plan future behaviour and produce believable individual and social behaviours in a Sims-like environment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative agents: Interactive simulacra of human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents record episodic experiences and periodically synthesize those episodic memories into higher-level 'reflections' that guide planning and decision-making; the pipeline couples memory accumulation with reflection-based planning to produce emergent social behaviours.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>Sims-like environment (interactive simulated world)</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>A simulated, multi-agent social environment (Sims-like) used to evaluate emergence of believable individual and social behaviours over long horizons rather than a classic text-adventure benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory synthesized into higher-level reflections</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Stores time-stamped episodic observations of agent experiences which are later aggregated/synthesized into higher-level reflective summaries (meta-memories) used as inputs to planning; exact data structures and indexing not specified in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>Past episodic events/observations about agent actions and interactions, later condensed into higher-level reflections about salient experiences.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>Synthesising memories into high-level reflections supports believable individual and emergent social behaviours and planning in a Sims-like environment according to the reviewed paper.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models and Video Games: A Preliminary Scoping Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2930.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2930.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>diff History</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>diff History for Long-Context Language Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory/observation-compression mechanism that stores differences (diffs) between successive environment observations to provide compressed, structured input to LLM agents, yielding large score improvements in NetHack.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>diff History for Long-Context Language Agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Diff-History LLM Agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent uses a 'diff history' representation of environment observations (storing compressed differences across timesteps) as the observation/memory channel for the LLM, enabling longer effective context and abstraction of changes for planning and decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>NetHack</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>A complex, procedurally generated, roguelike game with long horizons, partial observability, many objects/attributes and hard planning/exploration challenges; commonly used as a text-based benchmark for embodied/text-agent evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>observational diff-history / compressed episodic observations</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Stores compressed 'diff' representations of successive environment observations (i.e., differences between frames/states) to provide an abstracted, compact history of changes; designed to reduce input length while preserving salient state transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>Diffs between successive environment observations (changes/events), serving as a compact history of recent environment dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reported ~7x improvement in game score relative to previous baseline (as stated in the review) and >40% higher performance compared to agents using visual observations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Baseline (prior approach or visual-observation agent) — implied baseline score much lower (7x smaller) and visual-observation agents ~40% lower than diff-history agent; exact numeric baselines not reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td>Approximately 7x increase in game score; over 40% improvement vs visual-observation agents (as reported in review).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>Using diff-history provides observational compression and abstraction that substantially improves performance in NetHack—both large multiplicative score gains and clear superiority over visual-observation agents.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models and Video Games: A Preliminary Scoping Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2930.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2930.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ghost in the Minecraft</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based agent framework that augments language-model-driven agents with text-based knowledge and memory to handle long-horizon, open-world tasks in Minecraft-like environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Ghost (LLM + text-memory agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent integrates LLM-driven planning with a text-based knowledge and memory component to handle long-horizon tasks and adapt to uncertainty in an open-world environment (Minecraft); review summarizes that text knowledge and memory were key elements but does not detail architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>Minecraft (text-based interface / open-world benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>Open-world sandbox environment with long-horizon tasks, rich object interactions and emergent goals; the referenced work used text-based knowledge and memory to enable generally capable agent behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>text-based knowledge and memory (unspecified subtype)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>Textual knowledge and memory related to environment state and agent experiences (details not specified in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>Incorporating text-based knowledge and memory contributed to the agent's ability to handle long-horizon complex tasks and adapt to uncertainties in open-world Minecraft, per the reviewed paper's conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models and Video Games: A Preliminary Scoping Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2930.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2930.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Voyager: An Open-Ended Embodied Agent with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-powered embodied lifelong learning agent for Minecraft that accumulates experience/in-context learning to improve performance over time; described as showing strong in-context lifelong learning capability and high proficiency at playing Minecraft.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Voyager: An Open-Ended Embodied Agent with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Voyager</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An embodied agent architecture that uses an LLM as a central planner and incorporates mechanisms for lifelong/in-context learning (experience accumulation) to iteratively improve behaviour in Minecraft; review does not specify exact memory data structures.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>Minecraft (open-world embodied environment)</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>A 3D sandbox open-world environment requiring long-horizon planning, tool use, crafting, and adaptation; Voyager was evaluated on these open-ended tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>lifelong learning / experience accumulation (implied episodic/working memory mechanisms)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>Experience/in-context learning traces (historical actions, learned procedures or scripts) to support lifelong improvement; specific stored contents not detailed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>The Voyager agent exhibited strong in-context lifelong learning capability and exceptional proficiency at playing Minecraft, suggesting that experience accumulation / memory mechanisms aid open-ended embodied performance.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models and Video Games: A Preliminary Scoping Review', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>diff History for Long-Context Language Agents <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory <em>(Rating: 2)</em></li>
                <li>Voyager: An Open-Ended Embodied Agent with Large Language Models <em>(Rating: 2)</em></li>
                <li>Selective Perception: Learning Concise State Descriptions for Language Model Actors <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2930",
    "paper_id": "paper-268248196",
    "extraction_schema_id": "extraction-schema-72",
    "extracted_data": [
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents (memory-synthesising agents)",
            "brief_description": "LLM-based agents that accumulate episodic observations over time and synthesise those memories into higher-level reflections used to plan future behaviour and produce believable individual and social behaviours in a Sims-like environment.",
            "citation_title": "Generative agents: Interactive simulacra of human behavior",
            "mention_or_use": "mention",
            "agent_name": "Generative Agents",
            "agent_description": "Agents record episodic experiences and periodically synthesize those episodic memories into higher-level 'reflections' that guide planning and decision-making; the pipeline couples memory accumulation with reflection-based planning to produce emergent social behaviours.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "Sims-like environment (interactive simulated world)",
            "text_game_description": "A simulated, multi-agent social environment (Sims-like) used to evaluate emergence of believable individual and social behaviours over long horizons rather than a classic text-adventure benchmark.",
            "uses_memory": true,
            "memory_type": "episodic memory synthesized into higher-level reflections",
            "memory_architecture": "Stores time-stamped episodic observations of agent experiences which are later aggregated/synthesized into higher-level reflective summaries (meta-memories) used as inputs to planning; exact data structures and indexing not specified in the review.",
            "memory_retrieval_mechanism": null,
            "memory_capacity": null,
            "what_is_stored_in_memory": "Past episodic events/observations about agent actions and interactions, later condensed into higher-level reflections about salient experiences.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_improvement_magnitude": null,
            "key_findings_about_memory": "Synthesising memories into high-level reflections supports believable individual and emergent social behaviours and planning in a Sims-like environment according to the reviewed paper.",
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "uuid": "e2930.0",
            "source_info": {
                "paper_title": "Large Language Models and Video Games: A Preliminary Scoping Review",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "diff History",
            "name_full": "diff History for Long-Context Language Agents",
            "brief_description": "A memory/observation-compression mechanism that stores differences (diffs) between successive environment observations to provide compressed, structured input to LLM agents, yielding large score improvements in NetHack.",
            "citation_title": "diff History for Long-Context Language Agents",
            "mention_or_use": "mention",
            "agent_name": "Diff-History LLM Agent",
            "agent_description": "Agent uses a 'diff history' representation of environment observations (storing compressed differences across timesteps) as the observation/memory channel for the LLM, enabling longer effective context and abstraction of changes for planning and decision-making.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "NetHack",
            "text_game_description": "A complex, procedurally generated, roguelike game with long horizons, partial observability, many objects/attributes and hard planning/exploration challenges; commonly used as a text-based benchmark for embodied/text-agent evaluation.",
            "uses_memory": true,
            "memory_type": "observational diff-history / compressed episodic observations",
            "memory_architecture": "Stores compressed 'diff' representations of successive environment observations (i.e., differences between frames/states) to provide an abstracted, compact history of changes; designed to reduce input length while preserving salient state transitions.",
            "memory_retrieval_mechanism": null,
            "memory_capacity": null,
            "what_is_stored_in_memory": "Diffs between successive environment observations (changes/events), serving as a compact history of recent environment dynamics.",
            "performance_with_memory": "Reported ~7x improvement in game score relative to previous baseline (as stated in the review) and &gt;40% higher performance compared to agents using visual observations.",
            "performance_without_memory": "Baseline (prior approach or visual-observation agent) — implied baseline score much lower (7x smaller) and visual-observation agents ~40% lower than diff-history agent; exact numeric baselines not reported in the review.",
            "has_ablation_study": null,
            "memory_improvement_magnitude": "Approximately 7x increase in game score; over 40% improvement vs visual-observation agents (as reported in review).",
            "key_findings_about_memory": "Using diff-history provides observational compression and abstraction that substantially improves performance in NetHack—both large multiplicative score gains and clear superiority over visual-observation agents.",
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "uuid": "e2930.1",
            "source_info": {
                "paper_title": "Large Language Models and Video Games: A Preliminary Scoping Review",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Ghost in the Minecraft",
            "name_full": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory",
            "brief_description": "An LLM-based agent framework that augments language-model-driven agents with text-based knowledge and memory to handle long-horizon, open-world tasks in Minecraft-like environments.",
            "citation_title": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory",
            "mention_or_use": "mention",
            "agent_name": "Ghost (LLM + text-memory agent)",
            "agent_description": "Agent integrates LLM-driven planning with a text-based knowledge and memory component to handle long-horizon tasks and adapt to uncertainty in an open-world environment (Minecraft); review summarizes that text knowledge and memory were key elements but does not detail architecture.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "Minecraft (text-based interface / open-world benchmark)",
            "text_game_description": "Open-world sandbox environment with long-horizon tasks, rich object interactions and emergent goals; the referenced work used text-based knowledge and memory to enable generally capable agent behaviour.",
            "uses_memory": true,
            "memory_type": "text-based knowledge and memory (unspecified subtype)",
            "memory_architecture": null,
            "memory_retrieval_mechanism": null,
            "memory_capacity": null,
            "what_is_stored_in_memory": "Textual knowledge and memory related to environment state and agent experiences (details not specified in the review).",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_improvement_magnitude": null,
            "key_findings_about_memory": "Incorporating text-based knowledge and memory contributed to the agent's ability to handle long-horizon complex tasks and adapt to uncertainties in open-world Minecraft, per the reviewed paper's conclusions.",
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "uuid": "e2930.2",
            "source_info": {
                "paper_title": "Large Language Models and Video Games: A Preliminary Scoping Review",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Voyager",
            "name_full": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "brief_description": "An LLM-powered embodied lifelong learning agent for Minecraft that accumulates experience/in-context learning to improve performance over time; described as showing strong in-context lifelong learning capability and high proficiency at playing Minecraft.",
            "citation_title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "mention_or_use": "mention",
            "agent_name": "Voyager",
            "agent_description": "An embodied agent architecture that uses an LLM as a central planner and incorporates mechanisms for lifelong/in-context learning (experience accumulation) to iteratively improve behaviour in Minecraft; review does not specify exact memory data structures.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "Minecraft (open-world embodied environment)",
            "text_game_description": "A 3D sandbox open-world environment requiring long-horizon planning, tool use, crafting, and adaptation; Voyager was evaluated on these open-ended tasks.",
            "uses_memory": true,
            "memory_type": "lifelong learning / experience accumulation (implied episodic/working memory mechanisms)",
            "memory_architecture": null,
            "memory_retrieval_mechanism": null,
            "memory_capacity": null,
            "what_is_stored_in_memory": "Experience/in-context learning traces (historical actions, learned procedures or scripts) to support lifelong improvement; specific stored contents not detailed in the review.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_improvement_magnitude": null,
            "key_findings_about_memory": "The Voyager agent exhibited strong in-context lifelong learning capability and exceptional proficiency at playing Minecraft, suggesting that experience accumulation / memory mechanisms aid open-ended embodied performance.",
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "uuid": "e2930.3",
            "source_info": {
                "paper_title": "Large Language Models and Video Games: A Preliminary Scoping Review",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "diff History for Long-Context Language Agents",
            "rating": 2,
            "sanitized_title": "diff_history_for_longcontext_language_agents"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory",
            "rating": 2,
            "sanitized_title": "ghost_in_the_minecraft_generally_capable_agents_for_openworld_environments_via_large_language_models_with_textbased_knowledge_and_memory"
        },
        {
            "paper_title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
            "rating": 2,
            "sanitized_title": "voyager_an_openended_embodied_agent_with_large_language_models"
        },
        {
            "paper_title": "Selective Perception: Learning Concise State Descriptions for Language Model Actors",
            "rating": 1,
            "sanitized_title": "selective_perception_learning_concise_state_descriptions_for_language_model_actors"
        }
    ],
    "cost": 0.01285075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models and Video Games: A Preliminary Scoping Review
5 Mar 2024</p>
<p>Penny Sweetser penny.kyburz@anu.edu.au 
The Australian National University
Australia</p>
<p>The Australian National University
CanberraAustralia</p>
<p>Large Language Models and Video Games: A Preliminary Scoping Review
5 Mar 2024781E47A74459DD6BBEDCD5B9ABF0D8E010.1145/nnnnnnn.nnnnnnnarXiv:2403.02613v1[cs.HC]Manuscript submitted to ACM Manuscript submitted to ACMlarge language modelsLLMsgamesvideogamesGPT
Large language models (LLMs) hold interesting potential for the design, development, and research of video games.Building on the decades of prior research on generative AI in games, many researchers have sped to investigate the power and potential of LLMs for games.Given the recent spike in LLM-related research in games, there is already a wealth of relevant research to survey.In order to capture a snapshot of the state of LLM research in games, and to help lay the foundation for future work, we carried out an initial scoping review of relevant papers published so far.In this paper, we review 76 papers published between 2022 to early 2024 on LLMs and video games, with key focus areas in game AI, game development, narrative, and game research and reviews.Our paper provides an early state of the field and lays the groundwork for future research and reviews on this topic.CCS Concepts: • Software and its engineering → Interactive games; • Computing methodologies → Natural language generation; • Applied computing → Computer games.</p>
<p>Theme Papers</p>
<p>Game AI and Agents [1, 9, 12, 14, 15, 18, 19, 21, 29, 30, 36, 37, 39-42, 47, 48, 50, 51, 73, 76-80, 88] Game Development and Play [4, 6, 8, 11, 13, 20, 27, 28, 31, 34, 44, 53-57, 59, 60, 65-67, 70, 71, 83, 87] Narrative, Story, and Dialogue [2,3,5,16,22,32,35,43,45,49,61,62,68,69,72,75,82] Game Research and Reviews [17,24,25,33,52,64,74] Recommendation [7,10,38,58,63,81,[84][85][86] Fig. 1.Percentage of relevant papers identified in search by theme.</p>
<p>that 27/76 (35.5%) of the papers related to game AI, 25/76 (32.9%) to game development, 17/76 (22.4%) to narrative, and 7/76 (9.2%) to game research and reviews.We additionally found another 9 papers that used game data sets as part of broader recommendation research.In this paper, we analyse the work conducted using LLMs for games research to date, providing a snapshot of the state of the field and a grounding for future research in this area.</p>
<p>SCOPING REVIEW</p>
<p>In order to carry out our scoping review, we conducted a Google Scholar search for papers related to LLMs and video games published between 2020 to 2023 (and very early 2024).We used Google Scholar as it includes a wide variety of sources and publication types and allows full text search.We conducted our search on 15 January 2024, using the search string "(LLM OR LLMs OR "large language model" OR "large language models") AND ("video game" OR "video games" OR videogame OR videogames)" for the period 2020 to 2024.We used a full text search (rather than title or abstract only).Our search returned 2260 results, which we sorted by relevance.We reviewed the first 500 returned records to identify relevant papers.We found that the majority (80%) of relevant papers were in the first 250 records, with relevance rapidly decreasing after this point.</p>
<p>To identify relevant papers, we reviewed the title and abstract of each paper, and searched the full text for "game"</p>
<p>and "large language model" to find the usage.Most papers mentioned games in previous work or as an example, but did Manuscript submitted to ACM not include games in their own research.Some papers used the acronym "LLM" for another meaning.We considered papers relevant if they reported on original research related to video games and LLMs, either with a focus on games or using games as a testbed.We excluded general reviews that mentioned games and broader work that could be applied to games but that had not been applied to games in the paper.Through our search, we identified 71 relevant papers from the 2260 results.We found an additional five relevant papers while reviewing the 71 identified papers, for a full set of 76 papers.The majority (68/76, 90.7%) of papers were published (including preprints) in 2023, with 2 (2.7%) in 2024 and 6 (8.0%) in 2022.This suggests that any future searches with the same focus could start from 2022.A search with the same search string from 2022 onwards returned 1860 records (400 fewer).</p>
<p>During our search, we coded our identified relevant papers into broad categories, so that we could further review the similar papers together and identify the key themes.Following the initial coding, we finalised 4 key themes that captured all papers and recoded all papers into these themes.The most common theme was "Game AI and Agents" with 27/76 (35.5%) of the papers.The second theme was "Game Development and Play" with 25/76 (32.9%) the papers.</p>
<p>The third theme was "Narrative, Story, and Dialogue" with 17/76 (22.4%).The fourth and final theme, "Game Research and Reviews", captured the remaining 7/76 (9.2%) of the papers.We additionally found another 9 papers that used game data sets as part of broader recommendation research.Although we did not consider this to fit the focus of our search, we believe this related topic is of interest and relevant to future work on games and LLMs, so we also captured these papers for analysis.</p>
<p>The final step in our scoping review was to read and analyse each of the relevant papers.The following sections present our analysis of the papers, grouped by each of our key themes.We summarise the focus of the research conducted under each of these themes, extract sub-themes, and discuss relevant findings.Across our key themes, we found that by far the most commonly used LLM was GPT (65/76, 85.5%), followed by LLaMA (7/76, 9.2%), and Codex and BERT (each 5/76, 6.6%), with some papers using multiple LLMs.</p>
<p>Game AI and Agents</p>
<p>Over a third (27/76, 35.5%) of the relevant papers identified in our search related to the theme of Game AI and Agents.</p>
<p>The papers within this theme related to game agent design and behaviours (11/27) [14,15,29,36,39,40,42,50,51,76,88], LLMs and reinforcement learning (9/27) [18,30,37,47,48,[77][78][79][80], and collaboration and coordination (7/27) [1,9,12,19,21,41,73].</p>
<p>The papers on game agent design and behaviours experimented with applying LLMs to different aspects of agents, including reasoning [29,39], playing games [40,42], embodied agents [51,76], goals and tasks [14,36], emotion simulation [15], believable agents [50], and general AI [88].The papers on reasoning tested LLM capabilities at logical reasoning via Minesweeper [39] and social reasoning in a custom multi-agent environment [29].Li et al. [39] found that LLMs possessed foundational abilities, but that they could not integrate these into a multi-step logical reasoning process to solve Minesweeper.Kaiya et al. [29] argued that their Lyfe Agents exhibited human-like self-motivated social reasoning, which could enrich human social experiences in virtual worlds.The papers on playing games applied GPT-4V(ision) to analyse video to predict next steps when playing a Mario video game [40] and to test the capabilities of LLMs to play StarCraft II (SC2) [42].Lin et al. [40] claimed that their agent displayed an understanding of the Mario game and generated reasonable action controls to play the game effectively.Ma et al. [42] concluded that LLMs possess the relevant knowledge and complex planning abilities to play SC2 (in their textual SC2 environment).The papers on embodied agents investigated the use of diff history for environment observations in NetHack [51] and an LLM-powered embodied lifelong learning agent (Voyager) in Minecraft [76].Piterbarg et al. [51] found that using diff history allowed Manuscript submitted to ACM observational compression and abstraction that yielded a 7x improvement in game score and outperformed agents that use visual observations by over 40%.Wang et al. [76] argued their their Voyager agent shows strong in-context lifelong learning capability and exceptional proficiency at playing Minecraft.The paper on tasks [36] presented an interactive task learning system (VAL) that uses LLMs only for specific tasks to support interactive learning of hierarchical task knowledge from natural language.They found that the acquired knowledge was human interpretable and generalised to support execution of novel tasks without additional training and that users could successfully teach VAL using natural language in the Overcooked-AI video game setting.The paper on goals [14] introduced an LLM-based agent to support the representation, generation and learning of diverse, abstract, human-relevant goals in a text-based environment, Cooking World.They found that their agent learned to master a large diversity of skills without reward functions, curriculum, or hand-coded goal representations.The remaining papers investigated using LLMs for agents to solve emotional intelligence tasks and to simulate emotions in a conversational RPG game [15], to synthesise memories over time into high-lever reflections used to plan behaviour in a Sims-like environment [50], and to create generally capable agents in Minecraft [88].Croissant et al. [15] concluded that their work provided a first step towards better affective agents represented in LLMs.Park et al. [50] argued that their generative agents produced believable individual and emergent social behaviors.Finally, Zhu et al. [88] concluded that their agent demonstrated the potential of LLMs in developing capable agents for handling long-horizon, complex tasks, and adapting to uncertainties in open-world environments.</p>
<p>The papers on reinforcement learning (RL) investigated combining LLMs with RL in game environments, focusing on state descriptions [47,48], exploration and intrinsic motivation [18,30], chain-of-thought reasoning [77,79], rewards [37], embodied agents [80], and adversarial play [78].The work focusing on state descriptions [47,48] proposed a method for automatically selecting concise state descriptions for LLM actors in NetHack.They found they could reduce the length of state descriptions by 87% and improve task success rates by 158% in NetHack.The research on exploration and intrinsic motivation used background knowledge from LLMs to shape exploration in the Crafter game environment (2D Minecraft) [18] and an LLM to construct intrinsic rewards in NetHack [30].Du et al. [18] found that their agents had better coverage of common-sense behaviours, while Klissarov et al. [30] found that their method significantly outperformed existing approaches.For rewards, Lee and Lee [37] investigated whether an LLM can postprocess reward signals for RL in MineDojo.They reported that LLMs can suggest a new combination of existing heuristic functions, but did not observe improved learning results.On adversarial play, Xu et al. [78] proposed a new framework for LLM-based agents with strategic thinking ability to play the language game Werewolf.They found that combining LLMs with the RL policy produced a variety of emergent strategies, achieved a higher win rate, and was robust against human players.</p>
<p>The chain-of-thought (CoT) papers found that LLMs prompted with CoT outperformed state-of-the-art RL baselines in Crafter [77] and benchmarks such as Overcooked and FourRoom [79].Finally, Yang et al. [80] introduced Octopus, a novel large vision-language model for embodied agents, tested in a custom experimental environment (OctoVerse).</p>
<p>The papers on collaboration and coordination focused on human-AI collaboration [9,19,21,41,73] and multiagent coordination [1,12,19].Gong et al. [19] proposed a new infrastructure, MindAgent, to evaluate planning and coordination capabilities in games for multi-agent systems and human-AI collaboration, and introduced a new test environment, Cuisineworld.Guan et al. [21] proposed using an LLM to develop an action plan to guide both humans and AIs by facilitating a clear understanding of tasks and responsibilities.Their experiments in the Overcooked-AI environment with a human proxy model and real humans found that their method outperformed existing learning-based approaches.Brawer et al. [9] proposed a preliminary design for a natural language interface for a task assignment system using an LLM, which they plan to evaluate in the Overcooked environment.Verma et al. [73] investigated using Manuscript submitted to ACM LLMs to serve as effective human proxies by capturing human preferences for collaborating with AI agents.They explored the ability of LLMs to model mental states and understand human reasoning processes in Overcooked.Liu et al. [41] proposed a hierarchical language agent for human-AI coordination in Overcooked to provide both strong reasoning abilities and real-time execution.They reported that their agent outperformed baseline agents, with stronger cooperation abilities, faster responses, and more consistent language communications.Agashe et al. [1] introduced the LLM-Coordination (LLM-Co) Framework, designed to enable LLMs to play coordination games, and assessed the effectiveness of LLM-based agents in different coordination scenarios in the Overcooked-AI benchmark.They reported that LLM-based agents can infer a partner's intention and reason actions, coordinate with an unknown partner in complex long-horizon tasks, and outperform RL baselines.Chen et al. [12] proposed a multi-agent framework that can collaboratively and dynamically adjust its composition as a greater-than-the-sum-of-its-parts system in Minecraft.They found that their framework can effectively deploy multi-agent groups that outperform a single agent and identified the emergence of social behaviours.</p>
<p>Game Development and Play</p>
<p>Almost a third ( The papers on content generation related to game level generation [6,31,44,54,59,60,67,71], game generation [11,13,55,57], and art generation [53].Papers on level generation investigated using LLMs to generate levels for the games Sokoban (2D puzzle game) [71], Super Marios Bros (tile-based game levels) [59,60], Metavoidal (2D-game rooms for an under-development game) [44], Future Worlds (strategy game focused on environmental sustainability education) [31], Minecraft (3D sandbox game) [6], VR Pong [54], and Science Birds (based on Angry Birds) [67].These papers focused on experimenting with controlling LLM level generators [71], human-in-the-loop fine-tuning [44],</p>
<p>developing an end-to-end procedural level generation framework [31], using bootstrapping to generate enough data for training [44], and establishing a competition environment for participants to compete at creating effective prompts for ChatGPT to generate game levels [67].Researchers found that the performance of LLMs in generating game levels scales dramatically with dataset size, which is consistent with other PCGML (Procedural Content Generation via Machine Learning) techniques, creating the same tension between the cost/benefits of data versus level creation [71].</p>
<p>They also found that LLMs can be text-prompted for controllable level generation, with varying performance across metrics, addressing a key challenge in current PCG techniques [59,71].Papers on game generation went beyond level generation to look at games holistically or larger game structures/systems.These papers introduced approaches to generate content and mechanics in a VR Pong game during development and play (Codex VR Pong) [54,55], a multi-agent collaborative framework (GameGPT) to automate game development [11], and a simulation game system (Infinitia) that uses generative image and language models at play time to reshape the game world (terrain, vegetation, buildings, inhabitants) analogous to the fictional Holodeck [57].Researchers found that LLMs could be used to generate non-deterministic and emergent gameplay [54,55] and their proposed/developed systems had potential in generating games [11,13,55,57], but that further work was needed to realise this potential and that human game developers still surpass AI models [55].The paper on art generation [53] aimed to create lifelike 3D avatars from text descriptions using a combination of large language and vision models.The researchers found that their system offered an intuitive Manuscript submitted to ACM approach for users to craft controllable, realistic, and fully-realised 3D characters within 2 minutes, showing potential for integration into a game art pipeline.</p>
<p>The papers on serious games and game-based learning related to using LLMs to support educators in developing games [4,28,70,83], as well as more specifically to role-playing game design [56], board game design [28,70], and level [31] and game generation [13] for serious games.A common goal of these papers was to support time-poor teachers in developing educational games for their classrooms in an expedited manner and without the need for expertise in game development [28,70,83].LLMs were used to support educators with brainstorming [28], choosing a game [70], personalising the game for constructive alignment and inclusion [70], suggesting game themes and mechanisms aligned with curriculum and learning goals [28], providing templates or exemplars of game components [28], tailoring strategies to address specific learning challenges [83], supporting teachers in crafting personalised learning blueprints [83], and offering feedback on game prototypes and identifying areas for improvement [70].One paper also explored the creation of games as a learning mechanisms in combination with playing the game, which was found to have "double impact" (first through design, then through play) [56].Overall, researchers found that generative AI offers great potential for supporting and enhancing (rather than replacing) designers and educators in the creation of serious games and game-based learning education [13,28,70].They also found that generative AI can be an effective design tool for diverse populations (e.g., educators, students, domain experts) [31].</p>
<p>Apart from the previously discussed papers on design of serious games and game-based learning, the game design papers focused on use of LLMs for game idea generation [34] and game mechanic design [27].The idea generation paper [34] presented a collaborative design framework that aimed to simulate the typical human design process.As part of this framework, LLMs were used for the recombination and variation of ideas.The game mechanic paper [27] used an LLM for an element synthesis game, where players can combine elements to create new content based on physical and chemical properties of the combined elements, conceptual association, combination principles, and other logical reasoning rules.The researchers found that their LLM-based framework was effective in simulating element synthesis in video games with high freedom, high logic, repeatable playability, and more content.However, they noted that the inherent uncertainty in text generated by LLMs can have adverse effects on game mechanics.</p>
<p>The role-playing game (RPG) papers [20,56,87] involved using LLMs to design RPGs [56], to aid in playing RPGs online [87], and act as game masters in RPGs [20].As previously discussed in relation to serious games, using LLMs to design RPGs was found to be an effective learning tool for children, particularly paired with the children also playing the games they designed [56].For aiding people to play RPGs (in this case Dungeons and Dragons, or DnD) online, researchers [87] collected a dataset with 25,000 unique DnD sessions from real games on Discord that used the Avrae bot, including language, game commands, and underlying game state information.They found that their dataset (FIREBALL) improved natural language generation according to both automated metrics and human judgements of quality.For modelling RPG game masters (GMs), researchers [20] evaluated three LLMs (ChatGPT, Bard, OpenAssistant)</p>
<p>as out-of-the-box GMs.Considering the skills needed by a GM (creating and managing a fictional world, tracking the game state, understanding the players' actions), they found that ChatGPT and Bard provided satisfying game experiences, although they struggled with commonsense reasoning.They found that OpenAssistant was unable to maintain the GM role during most tests.</p>
<p>Narrative, Story, and Dialogue</p>
<p>Most of the remaining papers (17/76, 22.4%) related to the theme of Narrative, Story, and Dialogue.The papers within this theme related to dialogue or conversation generation (11/17) [2,3,5,16,32,35,43,45,49,62,75], story generation Manuscript submitted to ACM and interactive story (6/17) [2,22,32,61,68,69,82], and quest generation (2/17) [5,72].Two papers related to both dialogue and story generation [2,32] and one paper to both dialogue and quest generation [5].Two papers considered both NPC dialogue and NPC actions/tasks [49,75].</p>
<p>The papers on dialogue generation mostly focused on non-player characters (NPCs) in games.However, there was one case where the dialogue was for an online streamer commentating matches in a fighting game (DareFightingICE) [45] and another where NPCs from a game were interacting with players in an online Discord community external to the game [62].Papers on dialogue generation focused on different dimensions of dialogue and NPCs, including context-awareness and in-context dialogue [5,16,43], style and personality [35,43], and story-focused dialogue [2,32].</p>
<p>Most papers performed an evaluation of their systems with human players or game developers.The reported results</p>
<p>were mixed, depending on the focus of the papers and the criteria for success.Some researchers reported on the difficulty of using LLMs to generate NPC dialogue [2] and evaluator preferences for game designer generated text compared to LLM-generated text [3].Others reported that the LLM-generated text enhanced the player experience generally [5,49,62] or within specific conditions (e.g., with context-aware NPCs [16]).Some papers reported on the success of the approach via other performance metrics [32,35,43,75].</p>
<p>The papers on story and quest generation investigated different aspects of game story endings [22,68,69], the use of LLMs for generating interactive story games [61,82], and quest description generation [5,35].Papers focusing on story endings explored the valence (positive/neutral/negative) [68] and bias of the generated endings [69] and the impact of generating stories with/without a prompted ending (along with inspiration keywords) [22].The interactive story generation papers studied players interacting with the commercial game AI Dungeon [82] and a custom game "1001</p>
<p>Nights" [61].Research related to story endings found that generated stories were biased towards positive endings [69],</p>
<p>that models classified stories into uninstructed endings [68], and that more detail in prompts led to higher coherence but less inspiration [22].The interactive story researchers observed that player's mental models shifted over the play session from assuming a linear-branching narrative to one with open possibilities, impacting their motivations for repeat engagement [82].One paper proposed the term "AI-Native games" for games where generative AI is fundamental to the game's mechanics [61], also noting that inconsistency, incoherence, and AI-transparency are key challenges in these games.One paper focused on quest generation found that LLM-generated quests approached hand-crafted quests in terms of fluency, coherence, novelty, and creativity according to human evaluation [5].Conversely, the other quest generation paper found that only 1 in 5 generated quests were deemed acceptable by a human critic, with a large variation in quality of the generated quests [35].</p>
<p>Game Research and Reviews</p>
<p>The remaining papers (7/76, 9.2%) related to LLMs for use in analysing or generating data about games, including research data and game reviews.The papers in this theme used LLMs to analyse game reviews [33,74] and interviews with video game players [17] and to generate synthetic data for hate speech in games [64], player responses to interview questions [24,25], and utterances about video games [52].Researchers found the LLMs to be effective for their research purposes in analysis and generation, including dealing with the complex and highly abbreviated lexicons related to games [64] and offering improvements in performance [74] and cost [24,25].However, researchers also noted some drawbacks, including variation in quality [24], lack of depth of content and flexibility [33], and potential for crowd-sourced participant data to become unreliable [25].</p>
<p>Manuscript submitted to ACM</p>
<p>Recommendation</p>
<p>During our search process, we found an additional 9 papers [7,10,38,58,63,81,[84][85][86] that used game data sets as part of broader LLM for recommendation (LLM4Rec) research.These papers did not fit the focus of our search, or of this preliminary scoping review.However, we felt it was important to capture them in this paper, given their proximity to the topic and their likely relevance to the games research community in future.Each of these papers made use of a games dataset (Amazon 7/9, Steam 3/9), alongside other datasets (e.g., movies, books).The LLM4Rec papers focused on performance of ranking-based recommendation [7,84], sequential recommendation [81], instruction following and tuning [85], interpretation and explanation [38], collaborative semantics [86], user alignment [58], intent-aware session recommendation [63], and game features [10].The LLM4Rec papers most frequently utilised LLaMA (4/9) and GPT (4/9), whereas the games-focused papers overwhelmingly made use of GPT.</p>
<p>CONCLUSIONS</p>
<p>We reviewed 76 papers on LLMs and video games, published between 2022 to 2024, in order to provide a first snapshot of the state of research on this topic and to lay the foundations for the rapidly moving ongoing and future work.We designed our review to be narrowly focused on the application of LLMs to video games.As noted earlier, we included papers that reported original research related to video games and LLMs.We excluded work that had not yet been applied to games (but that could be applied to games in future).We also did not explicitly search for areas related to games (e.g., gamification) or other types of generative models (e.g., image generation, multi-modal generation).</p>
<p>We found that research clustered around topics related to game AI (agents, RL, collaboration), game development LLMs, research will continue to move quickly on this topic.Our review aimed to provide a preliminary snapshot of the state of the work on LLMs and games, to help researchers to understand the key directions and findings so far, and to lay the foundation for future work.We expect that capturing the state of the field and keeping pace with new research will be an ongoing challenge, but it is exciting to see where LLMs will take the field of games research and development.
(</p>
<p>Table 1 .
1
Relevant papers on video games and LLMs by theme.</p>
<p>[4,27,28,34,56,70]0,83]pers related to the theme of Game Development and Play.The papers within this theme related to game and content generation (13/25)[6, 11, 13, 31, 44, 53-55, 57, 59, 60, 67, 71], serious games and game-based learning (8/25)[4,8,13,28,31,56,70,83], game design (6/25)[4,27,28,34,56,70], role-playing games</p>
<p>[65,66]87]56,87], and automated bug detection tools (2/25)[65,66].</p>
<p>content/game generation, serious games and game-based learning, game design, RPGs, bug detection), narrative (conversation/story/quest generation), and game research and reviews (analysing/generating game data).Much of the work reviewed constituted initial attempts at applying LLMs to different aspects of games.Researchers generally reported positive results or indicated promising future work related to their application of LLMs to games.Others reported success in combining LLMs with other approaches (e.g., RL) to outperform baselines.Some of the commonly reported highlights included human interpretability, social behaviours and experiences, foundational skills (e.g., can play games), and empowerment of non-developers to create games.Negatives included lack of logical reasoning ability and unpredictability (e.g., in the context of generating content in live games).Given the explosion of interest around</p>
<p>Manuscript submitted to ACM</p>
<p>Saaket Agashe, Yue Fan, Xin Eric, Wang , arXiv:2310.03903Evaluating Multi-Agent Coordination Abilities in Large Language Models. 2023. 2023arXiv preprint</p>
<p>Towards Grounded Dialogue Generation in Video Game Environments. Nader Akoury, Ronan Salz, Mohit Iyyer, 2023. 2023</p>
<p>A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games. Nader Akoury, Qian Yang, Mohit Iyyer, Findings of the Association for Computational Linguistics: EMNLP 2023. 2023</p>
<p>Integrating Reinforcement AI Into the Design of Educational Games. Ashish Amresh, Proceedings of the 17th European Conference on Game-Based Learning: ECGBL 2023. Academic Conferences and publishing limited. the 17th European Conference on Game-Based Learning: ECGBL 2023. Academic Conferences and publishing limited2023</p>
<p>Personalized Quest and Dialogue Generation in Role-Playing Games: A Knowledge Graph-and Language Model-Based Approach. Trevor Ashby, Braden K Webb, Gregory Knapp, Jackson Searle, Nancy Fulda, 10.1145/3544548.3581441Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. the 2023 CHI Conference on Human Factors in Computing SystemsYork, NY, USAAssociation for Computing Machinery2023290New Manuscript submitted to ACM</p>
<p>Wor (l) d-GAN: Towards Natural Language Based PCG in Minecraft. Maren Awiszus, Frederik Schubert, Bodo Rosenhahn, IEEE Transactions on Games. 2022. 2022</p>
<p>A bi-step grounding paradigm for large language models in recommendation systems. Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Fuli Feng, Xiangnaan He, Qi Tian, arXiv:2308.084342023. 2023arXiv preprint</p>
<p>Jubileo: An Immersive Simulation Framework for Social Robot Design. Augusto Jair, Bottega, Augusto Victor, Junior Kich, Raul Costa De Jesus, Steinmetz, Henrique Alisson, Ricardo Kolling, Rodrigo Bedin Grando, Silva Da, Daniel Guerra, Tello Fernando, Gamarra, Journal of Intelligent &amp; Robotic Systems. 109912023. 2023</p>
<p>Jake Brawer, Kayleigh Bishop, Bradley Hayes, Alessandro Roncone, arXiv:2311.00153Towards A Natural Language Interface for Flexible Multi-Agent Task Assignment. 2023. 2023arXiv preprint</p>
<p>Yash Charity, Daniel Bhartia, Ahmed Zhang, Julian Khalifa, Togelius, arXiv:2308.13538A Preliminary Study on a Conceptual Game Feature Generation and Recommendation System. 2023. 2023arXiv preprint</p>
<p>Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, Haoyang Zhang, arXiv:2310.08067Gamegpt: Multi-agent collaborative framework for game development. 2023. 2023arXiv preprint</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, arXiv:2308.10848Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. 2023. 2023arXiv preprint</p>
<p>Using new AI-driven techniques to ease serious games authoring. Iván J Pérez Colado, Víctor M Pérez, Antonio Colado, Rubén Calvo Morata, Santa Cruz Píriz, Baltasar Fernández Manjón, 2023 IEEE Frontiers in Education Conference (FIE). IEEE2023</p>
<p>Cédric Colas, Laetitia Teodorescu, Pierre-Yves Oudeyer, Xingdi Yuan, Marc-Alexandre Côté, arXiv:2305.12487Augmenting Autotelic Agents with Large Language Models. 2023. 2023arXiv preprint</p>
<p>An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language Model Game Agents. Maximilian Croissant, Madeleine Frister, Guy Schofield, Cade Mccall, arXiv:2309.050762023. 2023arXiv preprint</p>
<p>The Effect of Context-aware LLM-based NPC Conversations on Player Engagement in Role-playing Video Games. Lajos Matyas, Csepregi , 2021. 2021Unpublished manuscript</p>
<p>Performing an Inductive Thematic Analysis of Semi-Structured Interviews With a Large Language Model: An Exploration and Provocation on the Limits of the Approach. Stefano De, Paoli , Social Science Computer Review. 089443932312204832023. 2023</p>
<p>Guiding pretraining in reinforcement learning with large language models. Yuqing Du, Olivia Watkins, Zihan Wang, Cédric Colas, Trevor Darrell, Pieter Abbeel, Abhishek Gupta, Jacob Andreas, arXiv:2302.066922023. 2023arXiv preprint</p>
<p>Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, arXiv:2309.09971Mindagent: Emergent gaming interaction. 2023. 2023arXiv preprint</p>
<p>Skill Check: Some Considerations on the Evaluation of Gamemastering Models for Role-Playing Games. Santiago Góngora, Luis Chiruzzo, Gonzalo Méndez, Pablo Gervás, International Conference on Games and Learning Alliance. Springer2023</p>
<p>Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, Yang Yu, arXiv:2311.00416Efficient Human-AI Coordination via Preparatory Language-based Convention. 2023. 2023arXiv preprint</p>
<p>The Chronicles of ChatGPT: Generating and Evaluating Visual Novel Narratives on Climate Change Through ChatGPT. Pittawat Mustafa Can Gursesli, Febri Taveekitworachai, Abdullah, F Mury, Antonio Dewantoro, Andrea Lanata, Guazzini, Adrien Van Khôi Lê, Ruck Villars, Thawonmas, International Conference on Interactive Digital Storytelling. Springer2023</p>
<p>Rizwan Muhammad Usman Hadi, Abbas Qureshi, Muhammad Shah, Anas Irfan, Muhammad Zafar, Naveed Bilal Shaikh, Jia Akhtar, Seyedali Wu, Mirjalili, 10.36227/techrxiv.23589741.v4Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects. 2023. Nov. 2023</p>
<p>Neural Language Models as What If?-Engines for HCI Research. Perttu Hämäläinen, Mikke Tavast, Anton Kunnari, 27th International Conference on Intelligent User Interfaces. 2022</p>
<p>Evaluating large language models in generating synthetic hci research data: a case study. Perttu Hämäläinen, Mikke Tavast, Anton Kunnari, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. the 2023 CHI Conference on Human Factors in Computing Systems2023</p>
<p>Procedural content generation for games: A survey. Mark Hendrikx, Sebastiaan Meijer, Joeri Van Der, Alexandru Velden, Iosup, 10.1145/2422956.2422957ACM Trans. Multimedia Comput. Commun. Appl. 912013. feb 2013</p>
<p>Create Ice Cream: Real-time Creative Element Synthesis Framework Based on GPT3. 0. Lei Huang, Xing Sun, 2023 IEEE Conference on Games (CoG). IEEE2023</p>
<p>Laleh Behjat, and Marjan Eggermont. 2023. How ChatGPT can inspire and improve serious board game design. Wilian Gatti, Junior , Emily Marasco, Beaumie Kim, International Journal of Serious Games. 102023</p>
<p>Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, Andrew Ahn, arXiv:2310.02172Lyfe Agents: Generative agents for low-cost real-time social interactions. 2023. 2023arXiv preprint</p>
<p>Martin Klissarov, D' Pierluca, Shagun Oro, Roberta Sodhani, Pierre-Luc Raileanu, Pascal Bacon, Amy Vincent, Mikael Zhang, Henaff, arXiv:2310.00166Motif: Intrinsic motivation from artificial intelligence feedback. 2023. 2023arXiv preprint</p>
<p>End-to-End Procedural Level Generation in Educational Games with Natural Language Instruction. Dan Vikram Kumaran, Jonathan Carpenter, Bradford Rowe, James Mott, Lester, 2023 IEEE Conference on Games (CoG). IEEE2023Manuscript submitted to ACM</p>
<p>SCENECRAFT: automating interactive narrative scene generation in digital games with large language models. Jonathan Vikram Kumaran, Bradford Rowe, James Mott, Lester, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment202319</p>
<p>Game Reviews Reviewed: A Game Designer's Perspective on AI-generated Game Review Analyses. Michael Lankes, Andreas Stöckl, 2023 IEEE Conference on Games (CoG). IEEE2023</p>
<p>Chatgpt and other large language models as evolutionary engines for online interactive collaborative game design. Pier Luca, Lanzi , Daniele Loiacono, arXiv:2303.021552023. 2023arXiv preprint</p>
<p>Generating video game scripts with style. Gaetan Lopez Latouche, Laurence Marcotte, Ben Swanson, Proceedings of the 5th Workshop on NLP for Conversational AI. the 5th Workshop on NLP for Conversational AI2023. NLP4ConvAI 2023</p>
<p>VAL: Interactive Task Learning with GPT Dialog Parsing. Lane Lawley, Christopher J Maclellan, arXiv:2310.016272023. 2023arXiv preprint</p>
<p>. Juyong Lee, Doohyun Lee, n. d.</p>
<p>Can Language Models Postprocess Rewards for Reinforcement Learning?. </p>
<p>Yuxuan Lei, Jianxun Lian, Jing Yao, Xu Huang, Defu Lian, Xing Xie, arXiv:2311.10947RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability. 2023. 2023arXiv preprint</p>
<p>Assessing Logical Puzzle Solving in Large Language Models: Insights from a Minesweeper Case Study. Yinghao Li, Haorui Wang, Chao Zhang, arXiv:2311.073872023. 2023arXiv preprint</p>
<p>Kevin Lin, Faisal Ahmed, Linjie Li, Chung-Ching Lin, Ehsan Azarnasab, Zhengyuan Yang, Jianfeng Wang, Lin Liang, Zicheng Liu, Yumao Lu, arXiv:2310.19773Mm-vid: Advancing video understanding with gpt-4v (ision). 2023. 2023arXiv preprint</p>
<p>Jijia Liu, Chao Yu, Jiaxuan Gao, Yuqing Xie, Qingmin Liao, Yi Wu, Yu Wang, arXiv:2312.15224LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination. 2023. 2023arXiv preprint</p>
<p>Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, Jun Wang, arXiv:2312.11865Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach. 2023. 2023arXiv preprint</p>
<p>Chatter Generation through Language Models. Matthias Müller-Brockhausen, Giulio Barbero, Mike Preuss, 2023 IEEE Conference on Games (CoG). IEEE2023</p>
<p>U Muhammad, Julian Nasir, Togelius, arXiv:2305.18243Practical PCG Through Large Language Models. 2023. 2023arXiv preprint</p>
<p>Am I Fighting Well? Fighting Game Commentary Generation With ChatGPT. Chollakorn Nimpattanavong, Pittawat Taveekitworachai, Ibrahim Khan, Thai Van Nguyen, Ruck Thawonmas, Worawat Choensawat, Kingkarn Sookhanaphibarn, Proceedings of the 13th International Conference on Advances in Information Technology. the 13th International Conference on Advances in Information Technology2023</p>
<p>Procedural Content Generation in Games. J Mark, Nelson Noor, Julian Shaker, Togelius, 10.1007/978-3-319-42716-42016SpringerCham</p>
<p>Selective Perception: Learning Concise State Descriptions for Language Model Actors. Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, Pierre Lanier, Roy Baldi, Sameer Fox, Singh, NeurIPS 2023 Foundation Models for Decision Making Workshop. 2023</p>
<p>Selective perception: Optimizing state descriptions with reinforcement learning for language model actors. Kolby Nottingham, Yasaman Razeghi, Kyungmin Kim, Pierre Lanier, Roy Baldi, Sameer Fox, Singh, arXiv:2307.119222023. 2023arXiv preprint</p>
<p>Conversational Agents for Simulation Applications and Video Games. Ciprian Paduraru, Marina Cernat, Alin Stefanescu, 10.5220/0012060500003538Proceedings of the 18th International Conference on Software Technologies -ICSOFT. INSTICC. the 18th International Conference on Software Technologies -ICSOFT. INSTICCSciTePress2023</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>diff History for Long-Context Language Agents. Ulyana Piterbarg, Lerrel Pinto, Rob Fergus, arXiv:2312.075402023. 2023arXiv preprint</p>
<p>Angela Ramirez, Mamon Alsalihy, Kartik Aggarwal, Cecilia Li, Liren Wu, Marilyn Walker, arXiv:2302.03848Controlling Personality Style in Dialogue with Zero-Shot Prompt-Based Learning. 2023. 2023arXiv preprint</p>
<p>Jianqiang Ren, Chao He, Lin Liu, Jiahao Chen, Yutong Wang, Yafei Song, Jianfang Li, Tangli Xue, Siqi Hu, Tao Chen, arXiv:2312.15430Make-A-Character: High Quality Text-to-3D Character Generation within Minutes. 2023. 2023arXiv preprint</p>
<p>Steps towards prompt-based creation of virtual worlds. Jasmine Roberts, Andrzej Banburski-Fahey, Jaron Lanier, arXiv:2211.058752022. 2022arXiv preprint</p>
<p>Surreal vr pong: Llm approach to game design. Jasmine Roberts, Andrzej Banburski-Fahey, Jaron Lanier, 36th Conference on Neural Information Processing Systems. 2022. NeurIPS 2022</p>
<p>Double Impact: Children's Serious RPG Generation/Play with a Large Language Model for Their Deeper Engagement in Social Issues. Kenji Saito, Kayo Kobayashi, Waki Takekoshi, Atsuki Hashimoto, Nobukazu Hirai, Akifumi Kimura, Asuka Takahashi, Naoki Yoshioka, Asuto Mano, Joint International Conference on Serious Games. Springer2023</p>
<p>Ahad Shams, Douglas Summers-Stay, Vsevolod Metelsky, Arpan Tripathi, Karan Malhotra, arXiv:2308.13548Towards a Holodeck-style Simulation Game. 2023. 2023arXiv preprint</p>
<p>Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, Ning Gu, arXiv:2308.09904RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models. 2023. 2023arXiv preprint</p>
<p>Prompt-Guided Level Generation. Shyam Sudhakaran, Miguel González-Duque, Claire Glanois, Matthias Freiberger, Elias Najarro, Sebastian Risi, Proceedings of the Companion Conference on Genetic and Evolutionary Computation. the Companion Conference on Genetic and Evolutionary Computation2023</p>
<p>Shyam Sudhakaran, Miguel González-Duque, Claire Glanois, Matthias Freiberger, Elias Najarro, Sebastian Risi, arXiv:2302.05981[cs.AI]MarioGPT: Open-Ended Text2Level Generation through Large Language Models. 2023</p>
<p>Language as reality: a co-creative storytelling game experience in 1001 nights using generative AI. Yuqian Sun, Zhouyi Li, Ke Fang, Chang Hee Lee, Ali Asadipour, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment202319</p>
<p>Yuqian Sun, Hanyi Wang, Pok Man Chan, Morteza Tabibi, Yan Zhang, Huan Lu, Yuheng Chen, Chang Hee Lee, Ali Asadipour, arXiv:2309.11478Fictional Worlds, Real Connections: Developing Community Storytelling Social Chatbots through LLMs. 2023. 2023arXiv preprint</p>
<p>Large Language Models for Intent-Driven Session Recommendations. Zhu Sun, Hongyang Liu, Xinghua Qu, Kaidong Feng, Yan Wang, Yew-Soon Ong, arXiv:2312.075522023. 2023arXiv preprint</p>
<p>Harnessing Large Language Models for Effective and Efficient Hate Speech Detection. Arina Svetasheva, Keeheon Lee, 2024. 2024</p>
<p>GlitchBench: Can large multimodal models detect video game glitches?. Reza Mohammad, Tianjun Taesiri, Cor-Paul Feng, Anh Bezemer, Nguyen, arXiv:2312.052912023. 2023arXiv preprint</p>
<p>Reza Mohammad, Finlay Taesiri, Yihe Macklon, Hengshuo Wang, Cor-Paul Shen, Bezemer, arXiv:2210.02506Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors. 2022. 2022arXiv preprint</p>
<p>Pittawat Taveekitworachai, Febri Abdullah, Mury F Dewantoro, Ruck Thawonmas, Julian Togelius, Jochen Renz, arXiv:2303.15662[cs.AI]ChatGPT4PCG Competition: Character-like Level Generation for Science Birds. 2023</p>
<p>What Is Waiting for Us at the End? Inherent Biases of Game Story Endings in Large Language Models. Pittawat Taveekitworachai, Febri Abdullah, Mustafa Can Gursesli, Siyuan Mury F Dewantoro, Antonio Chen, Andrea Lanata, Ruck Guazzini, Thawonmas, International Conference on Interactive Digital Storytelling. Springer2023</p>
<p>Journey of ChatGPT from Prompts to Stories in Games: the Positive, the Negative, and the Neutral. Pittawat Taveekitworachai, Mustafa Can Gursesli, Febri Abdullah, Siyuan Chen, Federico Cala, Andrea Guazzini, Antonio Lanata, Ruck Thawonmas, 2023 IEEE 13th International Conference on Consumer Electronics-Berlin. IEEE2023</p>
<p>AI in board Game-Based Learning. Andrea Tinterri, Marilena Di Padova, Francesco Palladino, Giordano Vignoli, Anna Dipace, CEUR WORKSHOP PROCEEDINGS. 2024</p>
<p>Level Generation Through Large Language Models. Graham Todd, Sam Earle, Muhammad Umair Nasir, Michael Cerny Green, Julian Togelius, Proceedings of the 18th International Conference on the Foundations of Digital Games. the 18th International Conference on the Foundations of Digital Games2023</p>
<p>Generating role-playing game quests with gpt language models. Susanna Värtinen, Perttu Hämäläinen, Christian Guckelsberger, IEEE Transactions on Games. 2022. 2022</p>
<p>Preference Proxies: Evaluating Large Language Models in capturing Human Preferences in Human-AI Tasks. Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati, ICML 2023 Workshop The Many Facets of Preference-Based Learning. 2023</p>
<p>Leveraging the OPT Large Language Model for Sentiment Analysis of Game Reviews. Markos Viggiato, Cor-Paul Bezemer, IEEE Transactions on Games. 2023. 2023</p>
<p>Craft an iron sword: Dynamically generating interactive game characters by prompting large language models tuned on code. Ryan Volum, Sudha Rao, Michael Xu, Gabriel Desgarennes, Chris Brockett, Benjamin Van Durme, Olivia Deng, Akanksha Malhotra, William B Dolan, Proceedings of the 3rd Wordplay: When Language Meets Games Workshop. the 3rd Wordplay: When Language Meets Games Workshop2022. Wordplay 2022</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, arXiv:2305.16291[cs.AI]Voyager: An Open-Ended Embodied Agent with Large Language Models. 2023</p>
<p>Yue Wu, So Yeon Min, Shrimai Prabhumoye, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Tom Mitchell, Yuanzhi Li, arXiv:2305.15486SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning. 2023. 2023arXiv preprint</p>
<p>Language agents with reinforcement learning for strategic play in the werewolf game. Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu, arXiv:2310.189402023. 2023arXiv preprint</p>
<p>Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models. Xue Yan, Yan Song, Xinyu Cui, Filippos Christianos, Haifeng Zhang, David Henry Mguni, Jun Wang, arXiv:2310.181272023. 2023arXiv preprint</p>
<p>Octopus: Embodied vision-language programmer from environmental feedback. Jingkang Yang, Yuhao Dong, Shuai Liu, Bo Li, Ziyue Wang, Chencheng Jiang, Haoran Tan, Jiamu Kang, Yuanhan Zhang, Kaiyang Zhou, arXiv:2310.085882023. 2023arXiv preprint</p>
<p>Large language model can interpret latent space of sequential recommender. Zhengyi Yang, Jiancan Wu, Yanchen Luo, Jizhi Zhang, Yancheng Yuan, An Zhang, Xiang Wang, Xiangnan He, arXiv:2310.204872023. 2023arXiv preprint</p>
<p>From Playing the Story to Gaming the System: Repeat Experiences of a Large Language Model-Based Interactive Story. Qing Ru, Yong , Alex Mitchell, International Conference on Interactive Digital Storytelling. Springer2023</p>
<p>Combine DGBL With AI System: A Technical Guidance to Reduce Teacher's Burden in Digital Game-Based Learning. Lei Yue, Liang Guo, European Conference on Games Based Learning. Academic Conferences International Limited2023826</p>
<p>Zhenrui Yue, Sara Rabhi, Gabriel De Souza Pereira Moreira, Dong Wang, Even Oldridge, arXiv:2311.02089LlamaRec: Two-Stage Recommendation using Large Language Models for Ranking. 2023. 2023arXiv preprint</p>
<p>Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, Ji-Rong Wen, arXiv:2305.07001Recommendation as instruction following: A large language model empowered recommendation approach. 2023. 2023arXiv preprint</p>
<p>Adapting large language models by integrating collaborative semantics for recommendation. Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, Ji-Rong Wen, arXiv:2311.090492023. 2023arXiv preprint</p>
<p>Fireball: A dataset of dungeons and dragons actual-play with structured game state information. Andrew Zhu, Karmanya Aggarwal, Alexander Feng, Lara J Martin, Chris Callison-Burch, arXiv:2305.015282023. 2023arXiv preprint</p>
<p>Xizhou Zhu, Yuntao Chen, Chenxin Hao Tian, Weijie Tao, Chenyu Su, Gao Yang, Bin Huang, Lewei Li, Xiaogang Lu, Yu Wang, Zhaoxiang Qiao, Jifeng Zhang, Dai, arXiv:2305.17144[cs.AI]Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory. 2023</p>            </div>
        </div>

    </div>
</body>
</html>