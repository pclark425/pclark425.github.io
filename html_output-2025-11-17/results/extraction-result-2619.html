<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2619 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2619</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2619</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-89b2b8810704a7c14d03b5d56928ebbb30bc8063</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/89b2b8810704a7c14d03b5d56928ebbb30bc8063" target="_blank">A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.</a></p>
                <p><strong>Paper Venue:</strong> Journal of the American Chemical Society</p>
                <p><strong>Paper TL;DR:</strong> A graphical user interface (GUI) that can be accessed online through a web-based application and incorporated features such as condition modification on the fly and data visualization is developed, which enables chemists to integrate Bayesian optimization routines into their everyday laboratory practices.</p>
                <p><strong>Paper Abstract:</strong> We report the development of an open-source experimental design via Bayesian optimization platform for multi-objective reaction optimization. Using high-throughput experimentation (HTE) and virtual screening data sets containing high-dimensional continuous and discrete variables, we optimized the performance of the platform by fine-tuning the algorithm components such as reaction encodings, surrogate model parameters, and initialization techniques. Having established the framework, we applied the optimizer to real-world test scenarios for the simultaneous optimization of the reaction yield and enantioselectivity in a Ni/photoredox-catalyzed enantioselective cross-electrophile coupling of styrene oxide with two different aryl iodide substrates. Starting with no previous experimental data, the Bayesian optimizer identified reaction conditions that surpassed the previously human-driven optimization campaigns within 15 and 24 experiments, for each substrate, among 1728 possible configurations available in each optimization. To make the platform more accessible to nonexperts, we developed a graphical user interface (GUI) that can be accessed online through a web-based application and incorporated features such as condition modification on the fly and data visualization. This web application does not require software installation, removing any programming barrier to use the platform, which enables chemists to integrate Bayesian optimization routines into their everyday laboratory practices.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2619.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2619.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EDBO+</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Experimental Design via Bayesian Optimization Plus</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source multi-objective active-learning platform and web application that applies Bayesian optimization to chemical reaction optimization using Gaussian process surrogates, batch multi-objective acquisition (q-EHVI), flexible featurizations, and human-in-the-loop controls (condition-space editing, thresholds, batch sizing, visualization).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EDBO+</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EDBO+ is a multi-objective active-learning and experimental-design system for reaction optimization. Key components are: (1) a Gaussian process regression (GPR) surrogate model that predicts multiple objectives and supplies predictive uncertainties; (2) a q-Expected HyperVolume Improvement (q-EHVI) multi-objective acquisition function for ranking and selecting batches of candidate experiments to maximize expected Pareto hypervolume gain; (3) flexible featurization options for categorical variables (One-Hot, Mordred descriptors, DFT-derived descriptors); (4) initialization strategies (Centroidal Voronoi Tessellation (CVT), Latin Hypercube Sampling (LHS), random); (5) batch selection (user-selectable batch size) and stopping heuristics (small expected improvement); and (6) a web-based GUI (EDBOApp) with cloud-backed compute, visualization of predicted objectives and uncertainties, ability to edit condition space on-the-fly, apply objective thresholds, and import prior data to pretrain the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Synthetic chemistry — multi-objective reaction optimization (yield, selectivity, cost, enantioselectivity, etc.) and high-throughput experimentation.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>At each active-learning iteration the system ranks all untested conditions (or candidate batches) using a multi-objective acquisition function (q-EHVI) that scores expected improvement in Pareto hypervolume; it then selects the top-ranked batch of experiments (user-set batch size) to execute. Initialization methods (CVT/LHS/random) are used to allocate initial experimental budget to cover the space. Users can change batch size and alter the condition space (add/remove candidates) during the campaign.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>q-Expected HyperVolume Improvement (q-EHVI) for multi-objective allocation; Expected Improvement (EI) reported/visualized for single objectives; surrogate predictive mean and uncertainty (GPR) used to compute these expected-utility metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration vs exploitation is balanced by the acquisition function (q-EHVI/EI) which combines the surrogate's predictive mean and uncertainty to estimate expected increases in Pareto hypervolume (or expected improvement for single objectives). Initialization (CVT/LHS) provides initial exploratory coverage; subsequent rounds prioritize conditions with high expected hypervolume improvement, which can emphasize uncertain regions (exploration) or high-predicted-reward regions (exploitation) depending on predicted distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity is promoted implicitly by maximizing expected hypervolume (which rewards spread across objective space) and explicitly via initialization strategies (CVT, LHS) that produce space-filling initial samples; batch q-EHVI also selects sets of experiments with jointly high expected hypervolume improvement to encourage diverse Pareto coverage. Users can apply thresholds to focus on particular Pareto regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of experiments (experiment-count budget), parallel batch-size constraints, material/resource availability constraints (practical lab constraints), and human-set objective thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>The system supports selecting batch size to match lab throughput and material limits; initialization methods (CVT/LHS) are chosen to allocate initial budget for coverage; acquisition-guided selection maximizes expected utility per experimental batch; small expected improvement (EI) values are used as a stopping criterion to avoid wasted experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Pareto-front proximity and expansion (hypervolume increase), maximum observed objective values (e.g., yield, ee), and expected improvement values; hypervolume and Pareto 'knee' proximity are used to identify high-impact tradeoff solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Application metrics reported in the paper: in a 1,728-condition Ni/photoredox reaction space, EDBO+ reached improved conditions surpassing previously human-optimized results within 24 experiments (7 rounds of 3) for one substrate (improving yield from 63% to 80% at same 91% ee) and within 15 experiments (4 rounds) for another substrate (improving from 47% yield/75% ee to 59% yield/77% ee). On HTE benchmark datasets, q-EHVI + GPR achieved the highest rate of hypervolume expansion and required fewer experiments than UCB, ε-greedy and random sampling; CVT initialization with batch size 3 gave highest hypervolume and lowest MAE among tested initializers and batch sizes. DFT featurization showed slightly improved mean performance and lower variance compared to One-Hot Encoding and Mordred.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random sampling, Upper Confidence Bound (UCB), ε-greedy acquisition, One-Factor-At-A-Time (OFAT) human-driven optimization, and different featurizations (OHE, Mordred) and initialization strategies (random, LHS).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>q-EHVI + GPR outperformed UCB and ε-greedy and random sampling on hypervolume expansion and required fewer experiments to locate Pareto-optimal tradeoffs. DFT featurization outperformed OHE and Mordred in speed to high-performance regions and lower variance. CVT and LHS initialization outperformed random initialization; CVT with batch size 3 yielded highest hypervolume and lowest MAE.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Empirical case: EDBO+ located superior conditions in 24 experiments vs ~500 experiments used in the earlier human OFAT campaign for one substrate — roughly a ~95% reduction in experiments (≈20× fewer experiments) to surpass that benchmark. Similar dramatic reductions reported across HTE benchmarks (fewer experiments to reach comparable hypervolume than random/UCB/ε-greedy).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper analyzes the tradeoff between exploration and exploitation through acquisition function choice and initialization: q-EHVI provides a balance that drives hypervolume expansion; DFT featurization reduces variance (more reliable exploitation); initialization method and batch size influence early exploration and rate of hypervolume growth. It also explicitly addresses multi-objective tradeoffs (yield vs selectivity/ee vs cost) using Pareto front and hypervolume metrics, and uses expected improvement visualizations to indicate diminishing returns.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Across benchmark datasets, the combination of a Gaussian process surrogate, q-EHVI acquisition, DFT-based featurization (for ligands), CVT initialization (or LHS) and moderate batch sizes (three experiments per round) produced the best empirical performance (fastest hypervolume expansion, lowest MAE). The system also recommends monitoring average EI to decide termination when marginal gains diminish. The authors note these findings are empirically derived on their datasets and propose recommender-system extensions and autonomous optimization as future directions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2619.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>q-EHVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>q-Expected HyperVolume Improvement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch-capable multi-objective acquisition function that ranks candidate experiment batches by their expected improvement in Pareto hypervolume, enabling parallel selection of experiments that jointly maximize multi-objective utility.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>q-Expected HyperVolume Improvement (q-EHVI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>q-EHVI computes the expected increase in Pareto hypervolume resulting from evaluating a batch of experiments, using the surrogate model's joint predictive distribution over objectives; the q-prefix denotes batch (parallel) selection. It is differentiable (per cited implementation) and supports selection of experiment sets that maximize expected multi-objective utility.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective Bayesian optimization for experimental design — applied here to chemical reaction optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select batches of candidate experiments that maximize the expected gain in Pareto hypervolume; the batch selection jointly considers interactions among batch members to maximize total expected multi-objective benefit per iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected hypervolume improvement (an expected-utility measure over Pareto hypervolume).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>By integrating predictive mean and covariance from the surrogate, q-EHVI places value on both high predicted objective values (exploitation) and high uncertainty regions (exploration) insofar as they increase expected hypervolume.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit: hypervolume objective rewards coverage and spread of solutions across objective space, so maximizing expected hypervolume encourages diverse Pareto coverage; batch selection can be diversified because the joint expected hypervolume favors complementary candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch-size-limited parallel experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Designed to produce an optimal batch of size q for a given round; performance evaluated across different batch sizes (paper finds batch size 3 effective for some tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Increase in Pareto hypervolume and proximity to Pareto knee regions (minimum distance to high-tradeoff point tracked in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Found empirically to require fewer experiments and achieve higher hypervolume expansion than UCB, ε-greedy and random sampling across benchmark HTE datasets used in this study; specific numerical hypervolume curves are provided in SI (paper summary states q-EHVI achieves the highest rate of hypervolume expansion).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Upper Confidence Bound (UCB), ε-greedy acquisition, random sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>q-EHVI was consistently superior in these experiments: required fewer experiments to find optimal values and achieved the highest hypervolume expansion at the end of optimization campaigns.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Paper reports that q-EHVI 'requires fewer experiments' than alternatives on their datasets; exact multiplicative improvements vs each baseline are dataset-dependent and not crisply numerically listed in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Authors show q-EHVI effectively balances exploration/exploitation and is robust across featurizations and datasets; it is especially efficient for batch sampling in multi-objective settings.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>q-EHVI is recommended as the preferred acquisition function for batch multi-objective reaction optimization in the tested chemical datasets and outperforms UCB and ε-greedy in hypervolume-based metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2619.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPR surrogate</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Regression surrogate model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic regression model that provides predictive means and uncertainties for continuous objectives and is used as the surrogate in Bayesian optimization to drive acquisition calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian Process Regression (GPR) surrogate</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GPR models are fitted to experimental observations of objectives (e.g., yield, selectivity). They provide predictive distributions (means and variances) over untested conditions that feed acquisition functions (q-EHVI, EI, UCB) to compute expected utilities for experiment selection.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Surrogate modeling within Bayesian optimization for chemical reaction optimization and HTE datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Provides the predictive mean and uncertainty used by acquisition functions to prioritize experiments; thus it indirectly controls resource allocation by informing expected utility computations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Model epistemic uncertainty (predictive variance) and resultant expected utility (EI / q-EHVI) derived from the predictive distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Acquisition functions combine the GPR predictive mean and variance to trade off sampling in uncertain regions (exploration) versus high-predicted-value regions (exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity is induced via the acquisition function that uses the GPR uncertainty; GPR itself does not explicitly enforce diversity but contributes uncertainty estimates that acquisition functions leverage.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Experiment-count/batch constraints as dictated by acquisition selection.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>GPR predictions are recomputed each round using all observed data; acquisition uses those predictions subject to the chosen batch size.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>High predicted objective values with associated uncertainty leading to high expected improvement/hypervolume increase.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported as the surrogate paired with q-EHVI yielding best empirical optimization performance across tested datasets; MAE tracked and CVT initialization + batch 3 gave the lowest MAE.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Other acquisition functions (UCB, ε-greedy) and different featurizations/initializations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>GPR + q-EHVI combination outperformed other tested acquisition functions on hypervolume growth; exact GPR-only baseline not isolated.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>GPR uncertainties are central to acquisition-based tradeoffs; featurization quality (e.g., DFT) reduces surrogate variance and improves robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use of a GPR surrogate with q-EHVI was empirically optimal across the datasets in the study.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2619.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Initialization methods (CVT/LHS/random)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Centroidal Voronoi Tessellation (CVT), Latin Hypercube Sampling (LHS), Random sampling initializers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods for selecting the initial set of experiments to seed the surrogate model: CVT and LHS produce space-filling, stratified initial samples while random sampling selects initial points uniformly at random.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CVT / LHS / Random initialization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>These are strategies for allocating the initial experimental budget before iterative active learning: CVT partitions the candidate space and selects centroids to maximize coverage; LHS stratifies the sample space to ensure coverage across marginal distributions; random sampling picks initial configurations uniformly. The chosen initializer affects early exploration and variance across optimization runs.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Initial experimental allocation in Bayesian optimization workflows for reaction optimization and HTE datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate a limited initial budget to maximize space coverage (CVT/LHS) or by chance (random). CVT and LHS aim to spread initial experiments to produce informative priors for the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Initializers are exploration-focused: they prioritize coverage to supply diverse data points for the surrogate; subsequent acquisition-driven rounds perform exploitation/exploration tradeoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>CVT and LHS explicitly create diverse initial samples by design (space-filling and stratification).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed small initial experiment budget (number of seeds).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Different initializer choices allocate the fixed initial budget to maximize coverage (CVT/LHS) or sample randomly; empirically CVT with batch size 3 produced the best downstream performance on one dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Indirect: enables faster discovery by providing informative starting points; measured via downstream hypervolume growth and MAE.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On the Pd C–H arylation dataset, LHS and CVT showed higher hypervolume expansion rates than random; CVT with batch size 3 achieved the highest hypervolume and lowest MAE.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random initialization baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>CVT and LHS outperformed random sampling in hypervolume and MAE metrics; CVT + batch 3 was the best among tested options.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Authors note an exploratory initial phase (broad objective distributions) followed by exploitation (narrower distributions near optima); initializer choice influences speed of transition and variance across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use CVT or LHS over random initialization for better early coverage and improved downstream optimization metrics; CVT with batch size 3 empirically recommended for the tested dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2619.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DFT featurization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Density Functional Theory-derived molecular features</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Featurization approach that computes quantum-chemistry-derived descriptors (DFT-level properties) for categorical reaction components (e.g., ligands) to provide informative continuous inputs to the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DFT-based featurization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Ligand and component descriptors are computed from DFT calculations and used as continuous features in the surrogate model. This representation can capture physicochemical properties and reactivity-relevant information not present in sparse encodings like One-Hot.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Feature engineering for surrogate modeling in chemical reaction optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Improved featurization yields more informative surrogate predictions per experiment, effectively increasing information gain per experimental resource spent; does not itself perform allocation but affects acquisition efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>By improving surrogate accuracy and reducing variance, DFT features enable more reliable exploitation (and more targeted exploration), reducing variance across optimization runs.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Indirect: richer features allow the surrogate and acquisition to distinguish candidates, yielding broader (and more meaningful) Pareto exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Featurization has computational cost (not quantified) separate from experimental budget; trade-off between time to compute features and experimental savings.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Paper does not quantify DFT compute cost or handle it as part of budget; it is chosen when feasible because it improved optimization performance and robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Faster attainment of high-performing regions (e.g., >90% conversion/selectivity earlier in optimization) and lower variance across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>DFT-encoded features provided slightly improved hypervolume growth and earlier discovery of high conversion/selectivity (>90%) compared to OHE and Mordred; also exhibited lowest variance across seeded runs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>One-Hot Encoding (OHE) and Mordred chemical-informatics featurization.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>DFT featurization performed slightly better (faster to optimal regions, lower variance) than OHE and Mordred across the tested datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes DFT provides stronger, more robust performance but does not quantify the computational cost of computing DFT descriptors versus experimental savings.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When feasible, use DFT-derived descriptors for categorical components (e.g., ligands) to improve surrogate robustness and reduce variance in optimization outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2619.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EDBOApp</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>EDBO Web Application (EDBOWebApp)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cloud-backed web GUI for EDBO+ that enables non-expert users to run multi-objective Bayesian optimization experiments, visualize surrogate predictions/uncertainties, adjust condition spaces and thresholds, set batch sizes, and import prior data without local software installation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EDBOWebApp</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A browser-accessible user interface backed by cloud compute that exposes EDBO+ functionality: define reaction condition space, select featurization and initialization, run BO campaigns, visualize predicted objectives and uncertainty surfaces, change condition space on-the-fly, set batch sizes and thresholds, import prior experimental data, and view expected improvement traces to decide termination.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Tooling and human-in-the-loop orchestration for chemical reaction optimization and experimental planning.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Provides user controls to set batch size and thresholds; visualizes EI and predicted uncertainty so users can make resource-allocation decisions (e.g., stop when EI small, add/remove candidates).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Displays expected improvement (EI) and model uncertainty to inform decisions about expected information gain from additional experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Visual EI traces and uncertainty maps let the human operator decide when to pursue exploration (expand condition space, increase batch diversity) or exploitation (focus on top predicted conditions); acquisition function automates most decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Allows on-the-fly modification of condition space and batch-size selection; relies on q-EHVI and initialization to produce diverse experimental suggestions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>User-constrained batch size, experimental-material availability, and time-throughput constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>User selects batch size and can stop optimization based on low average EI; can import prior data to reduce experimental budget required.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Visualized EI and hypervolume traces; surrogate-predicted top objectives and Pareto front.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Enables the same experimental performance reported for EDBO+ (e.g., 15 and 24 experiments to beat prior human-optimized conditions) while lowering the programming barrier; no separate benchmarking of web-app overhead reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Manual / code-based EDBO+ use and human OFAT workflows; not a methodological baseline but an accessibility/UX comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Improves accessibility and enables human-in-the-loop decision-making (no numerical runtime/compute-cost comparison reported).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The app surfaces EI and uncertainty so users can balance additional computational/experimental cost against expected information return; no formal cost-utility optimization of compute vs experiment presented.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Provide human-directed controls (batch size, thresholds, editing condition space) plus automated acquisition (q-EHVI) so users can tailor allocation to experimental resource constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2619.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chimera</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-objective optimization package that uses hierarchical scalarization approaches to prioritize objectives for self-driving laboratory workflows; cited in the paper as prior art for multi-objective BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Chimera</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A framework combining a priori scalarizing and lexicographic methods to handle multiple objectives in autonomous laboratory optimization, enabling hierarchical prioritization of objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Autonomous laboratory optimization / multi-objective experiment planning.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Uses hierarchical scalarization to prioritize objectives and select experiments that satisfy higher-priority constraints before optimizing lower-priority objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2619.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gryffin</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian optimization algorithm tailored to categorical variables that can incorporate domain knowledge to guide search; cited as prior multi-objective/autonomous optimization work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gryffin</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Algorithm that performs Bayesian optimization over categorical spaces, optionally informed by expert-provided similarity kernels or descriptors to improve sampling efficiency on discrete variables.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Bayesian optimization for experimental design with categorical variables (chemical conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Ranks categorical candidates using a kernel/descriptor-informed surrogate and acquisition function; not used in this study but cited as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2619.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NEXTorch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A PyTorch-based toolkit implementing Bayesian optimization routines for chemical engineering problems; cited as prior art with multi-objective capabilities mostly demonstrated on continuous spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NEXTorch</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A toolkit built on PyTorch providing Bayesian optimization and experiment design tools for chemical sciences; in the cited work multi-objective application was shown for continuous-variable search spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Design and optimization in chemical sciences and engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2619.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2619.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recommender-systems (future)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recommender systems for expansion of reaction condition space</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed future direction to use recommender-system techniques to propose condition-space expansions and assist autonomous process optimization (mentioned as future work in the conclusions).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Recommender-system extension</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Authors propose exploring recommender-system approaches to suggest additions/edits to the reaction condition search space and to aid autonomous process optimization; this is noted as future work and not implemented in the present study.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Assistive suggestion and expansion of experimental candidate spaces for reaction optimization and autonomous labs.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Not implemented; proposed to automate expansion of the candidate space and potentially guide resource allocation by recommending promising new candidates to evaluate.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.', 'publication_date_yy_mm': '2022-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization <em>(Rating: 2)</em></li>
                <li>Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories <em>(Rating: 2)</em></li>
                <li>Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge <em>(Rating: 2)</em></li>
                <li>NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering <em>(Rating: 2)</em></li>
                <li>Bayesian Reaction Optimization as a Tool for Chemical Synthesis <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2619",
    "paper_id": "paper-89b2b8810704a7c14d03b5d56928ebbb30bc8063",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "EDBO+",
            "name_full": "Experimental Design via Bayesian Optimization Plus",
            "brief_description": "An open-source multi-objective active-learning platform and web application that applies Bayesian optimization to chemical reaction optimization using Gaussian process surrogates, batch multi-objective acquisition (q-EHVI), flexible featurizations, and human-in-the-loop controls (condition-space editing, thresholds, batch sizing, visualization).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "EDBO+",
            "system_description": "EDBO+ is a multi-objective active-learning and experimental-design system for reaction optimization. Key components are: (1) a Gaussian process regression (GPR) surrogate model that predicts multiple objectives and supplies predictive uncertainties; (2) a q-Expected HyperVolume Improvement (q-EHVI) multi-objective acquisition function for ranking and selecting batches of candidate experiments to maximize expected Pareto hypervolume gain; (3) flexible featurization options for categorical variables (One-Hot, Mordred descriptors, DFT-derived descriptors); (4) initialization strategies (Centroidal Voronoi Tessellation (CVT), Latin Hypercube Sampling (LHS), random); (5) batch selection (user-selectable batch size) and stopping heuristics (small expected improvement); and (6) a web-based GUI (EDBOApp) with cloud-backed compute, visualization of predicted objectives and uncertainties, ability to edit condition space on-the-fly, apply objective thresholds, and import prior data to pretrain the surrogate.",
            "application_domain": "Synthetic chemistry — multi-objective reaction optimization (yield, selectivity, cost, enantioselectivity, etc.) and high-throughput experimentation.",
            "resource_allocation_strategy": "At each active-learning iteration the system ranks all untested conditions (or candidate batches) using a multi-objective acquisition function (q-EHVI) that scores expected improvement in Pareto hypervolume; it then selects the top-ranked batch of experiments (user-set batch size) to execute. Initialization methods (CVT/LHS/random) are used to allocate initial experimental budget to cover the space. Users can change batch size and alter the condition space (add/remove candidates) during the campaign.",
            "computational_cost_metric": null,
            "information_gain_metric": "q-Expected HyperVolume Improvement (q-EHVI) for multi-objective allocation; Expected Improvement (EI) reported/visualized for single objectives; surrogate predictive mean and uncertainty (GPR) used to compute these expected-utility metrics.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration vs exploitation is balanced by the acquisition function (q-EHVI/EI) which combines the surrogate's predictive mean and uncertainty to estimate expected increases in Pareto hypervolume (or expected improvement for single objectives). Initialization (CVT/LHS) provides initial exploratory coverage; subsequent rounds prioritize conditions with high expected hypervolume improvement, which can emphasize uncertain regions (exploration) or high-predicted-reward regions (exploitation) depending on predicted distributions.",
            "diversity_mechanism": "Diversity is promoted implicitly by maximizing expected hypervolume (which rewards spread across objective space) and explicitly via initialization strategies (CVT, LHS) that produce space-filling initial samples; batch q-EHVI also selects sets of experiments with jointly high expected hypervolume improvement to encourage diverse Pareto coverage. Users can apply thresholds to focus on particular Pareto regions.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of experiments (experiment-count budget), parallel batch-size constraints, material/resource availability constraints (practical lab constraints), and human-set objective thresholds.",
            "budget_constraint_handling": "The system supports selecting batch size to match lab throughput and material limits; initialization methods (CVT/LHS) are chosen to allocate initial budget for coverage; acquisition-guided selection maximizes expected utility per experimental batch; small expected improvement (EI) values are used as a stopping criterion to avoid wasted experiments.",
            "breakthrough_discovery_metric": "Pareto-front proximity and expansion (hypervolume increase), maximum observed objective values (e.g., yield, ee), and expected improvement values; hypervolume and Pareto 'knee' proximity are used to identify high-impact tradeoff solutions.",
            "performance_metrics": "Application metrics reported in the paper: in a 1,728-condition Ni/photoredox reaction space, EDBO+ reached improved conditions surpassing previously human-optimized results within 24 experiments (7 rounds of 3) for one substrate (improving yield from 63% to 80% at same 91% ee) and within 15 experiments (4 rounds) for another substrate (improving from 47% yield/75% ee to 59% yield/77% ee). On HTE benchmark datasets, q-EHVI + GPR achieved the highest rate of hypervolume expansion and required fewer experiments than UCB, ε-greedy and random sampling; CVT initialization with batch size 3 gave highest hypervolume and lowest MAE among tested initializers and batch sizes. DFT featurization showed slightly improved mean performance and lower variance compared to One-Hot Encoding and Mordred.",
            "comparison_baseline": "Random sampling, Upper Confidence Bound (UCB), ε-greedy acquisition, One-Factor-At-A-Time (OFAT) human-driven optimization, and different featurizations (OHE, Mordred) and initialization strategies (random, LHS).",
            "performance_vs_baseline": "q-EHVI + GPR outperformed UCB and ε-greedy and random sampling on hypervolume expansion and required fewer experiments to locate Pareto-optimal tradeoffs. DFT featurization outperformed OHE and Mordred in speed to high-performance regions and lower variance. CVT and LHS initialization outperformed random initialization; CVT with batch size 3 yielded highest hypervolume and lowest MAE.",
            "efficiency_gain": "Empirical case: EDBO+ located superior conditions in 24 experiments vs ~500 experiments used in the earlier human OFAT campaign for one substrate — roughly a ~95% reduction in experiments (≈20× fewer experiments) to surpass that benchmark. Similar dramatic reductions reported across HTE benchmarks (fewer experiments to reach comparable hypervolume than random/UCB/ε-greedy).",
            "tradeoff_analysis": "The paper analyzes the tradeoff between exploration and exploitation through acquisition function choice and initialization: q-EHVI provides a balance that drives hypervolume expansion; DFT featurization reduces variance (more reliable exploitation); initialization method and batch size influence early exploration and rate of hypervolume growth. It also explicitly addresses multi-objective tradeoffs (yield vs selectivity/ee vs cost) using Pareto front and hypervolume metrics, and uses expected improvement visualizations to indicate diminishing returns.",
            "optimal_allocation_findings": "Across benchmark datasets, the combination of a Gaussian process surrogate, q-EHVI acquisition, DFT-based featurization (for ligands), CVT initialization (or LHS) and moderate batch sizes (three experiments per round) produced the best empirical performance (fastest hypervolume expansion, lowest MAE). The system also recommends monitoring average EI to decide termination when marginal gains diminish. The authors note these findings are empirically derived on their datasets and propose recommender-system extensions and autonomous optimization as future directions.",
            "uuid": "e2619.0",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "q-EHVI",
            "name_full": "q-Expected HyperVolume Improvement",
            "brief_description": "A batch-capable multi-objective acquisition function that ranks candidate experiment batches by their expected improvement in Pareto hypervolume, enabling parallel selection of experiments that jointly maximize multi-objective utility.",
            "citation_title": "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization",
            "mention_or_use": "use",
            "system_name": "q-Expected HyperVolume Improvement (q-EHVI)",
            "system_description": "q-EHVI computes the expected increase in Pareto hypervolume resulting from evaluating a batch of experiments, using the surrogate model's joint predictive distribution over objectives; the q-prefix denotes batch (parallel) selection. It is differentiable (per cited implementation) and supports selection of experiment sets that maximize expected multi-objective utility.",
            "application_domain": "Multi-objective Bayesian optimization for experimental design — applied here to chemical reaction optimization.",
            "resource_allocation_strategy": "Select batches of candidate experiments that maximize the expected gain in Pareto hypervolume; the batch selection jointly considers interactions among batch members to maximize total expected multi-objective benefit per iteration.",
            "computational_cost_metric": null,
            "information_gain_metric": "Expected hypervolume improvement (an expected-utility measure over Pareto hypervolume).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "By integrating predictive mean and covariance from the surrogate, q-EHVI places value on both high predicted objective values (exploitation) and high uncertainty regions (exploration) insofar as they increase expected hypervolume.",
            "diversity_mechanism": "Implicit: hypervolume objective rewards coverage and spread of solutions across objective space, so maximizing expected hypervolume encourages diverse Pareto coverage; batch selection can be diversified because the joint expected hypervolume favors complementary candidates.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch-size-limited parallel experiments.",
            "budget_constraint_handling": "Designed to produce an optimal batch of size q for a given round; performance evaluated across different batch sizes (paper finds batch size 3 effective for some tasks).",
            "breakthrough_discovery_metric": "Increase in Pareto hypervolume and proximity to Pareto knee regions (minimum distance to high-tradeoff point tracked in paper).",
            "performance_metrics": "Found empirically to require fewer experiments and achieve higher hypervolume expansion than UCB, ε-greedy and random sampling across benchmark HTE datasets used in this study; specific numerical hypervolume curves are provided in SI (paper summary states q-EHVI achieves the highest rate of hypervolume expansion).",
            "comparison_baseline": "Upper Confidence Bound (UCB), ε-greedy acquisition, random sampling.",
            "performance_vs_baseline": "q-EHVI was consistently superior in these experiments: required fewer experiments to find optimal values and achieved the highest hypervolume expansion at the end of optimization campaigns.",
            "efficiency_gain": "Paper reports that q-EHVI 'requires fewer experiments' than alternatives on their datasets; exact multiplicative improvements vs each baseline are dataset-dependent and not crisply numerically listed in the main text.",
            "tradeoff_analysis": "Authors show q-EHVI effectively balances exploration/exploitation and is robust across featurizations and datasets; it is especially efficient for batch sampling in multi-objective settings.",
            "optimal_allocation_findings": "q-EHVI is recommended as the preferred acquisition function for batch multi-objective reaction optimization in the tested chemical datasets and outperforms UCB and ε-greedy in hypervolume-based metrics.",
            "uuid": "e2619.1",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "GPR surrogate",
            "name_full": "Gaussian Process Regression surrogate model",
            "brief_description": "A probabilistic regression model that provides predictive means and uncertainties for continuous objectives and is used as the surrogate in Bayesian optimization to drive acquisition calculations.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Gaussian Process Regression (GPR) surrogate",
            "system_description": "GPR models are fitted to experimental observations of objectives (e.g., yield, selectivity). They provide predictive distributions (means and variances) over untested conditions that feed acquisition functions (q-EHVI, EI, UCB) to compute expected utilities for experiment selection.",
            "application_domain": "Surrogate modeling within Bayesian optimization for chemical reaction optimization and HTE datasets.",
            "resource_allocation_strategy": "Provides the predictive mean and uncertainty used by acquisition functions to prioritize experiments; thus it indirectly controls resource allocation by informing expected utility computations.",
            "computational_cost_metric": null,
            "information_gain_metric": "Model epistemic uncertainty (predictive variance) and resultant expected utility (EI / q-EHVI) derived from the predictive distribution.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Acquisition functions combine the GPR predictive mean and variance to trade off sampling in uncertain regions (exploration) versus high-predicted-value regions (exploitation).",
            "diversity_mechanism": "Diversity is induced via the acquisition function that uses the GPR uncertainty; GPR itself does not explicitly enforce diversity but contributes uncertainty estimates that acquisition functions leverage.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Experiment-count/batch constraints as dictated by acquisition selection.",
            "budget_constraint_handling": "GPR predictions are recomputed each round using all observed data; acquisition uses those predictions subject to the chosen batch size.",
            "breakthrough_discovery_metric": "High predicted objective values with associated uncertainty leading to high expected improvement/hypervolume increase.",
            "performance_metrics": "Reported as the surrogate paired with q-EHVI yielding best empirical optimization performance across tested datasets; MAE tracked and CVT initialization + batch 3 gave the lowest MAE.",
            "comparison_baseline": "Other acquisition functions (UCB, ε-greedy) and different featurizations/initializations.",
            "performance_vs_baseline": "GPR + q-EHVI combination outperformed other tested acquisition functions on hypervolume growth; exact GPR-only baseline not isolated.",
            "efficiency_gain": null,
            "tradeoff_analysis": "GPR uncertainties are central to acquisition-based tradeoffs; featurization quality (e.g., DFT) reduces surrogate variance and improves robustness.",
            "optimal_allocation_findings": "Use of a GPR surrogate with q-EHVI was empirically optimal across the datasets in the study.",
            "uuid": "e2619.2",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Initialization methods (CVT/LHS/random)",
            "name_full": "Centroidal Voronoi Tessellation (CVT), Latin Hypercube Sampling (LHS), Random sampling initializers",
            "brief_description": "Methods for selecting the initial set of experiments to seed the surrogate model: CVT and LHS produce space-filling, stratified initial samples while random sampling selects initial points uniformly at random.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "CVT / LHS / Random initialization",
            "system_description": "These are strategies for allocating the initial experimental budget before iterative active learning: CVT partitions the candidate space and selects centroids to maximize coverage; LHS stratifies the sample space to ensure coverage across marginal distributions; random sampling picks initial configurations uniformly. The chosen initializer affects early exploration and variance across optimization runs.",
            "application_domain": "Initial experimental allocation in Bayesian optimization workflows for reaction optimization and HTE datasets.",
            "resource_allocation_strategy": "Allocate a limited initial budget to maximize space coverage (CVT/LHS) or by chance (random). CVT and LHS aim to spread initial experiments to produce informative priors for the surrogate.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Initializers are exploration-focused: they prioritize coverage to supply diverse data points for the surrogate; subsequent acquisition-driven rounds perform exploitation/exploration tradeoffs.",
            "diversity_mechanism": "CVT and LHS explicitly create diverse initial samples by design (space-filling and stratification).",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed small initial experiment budget (number of seeds).",
            "budget_constraint_handling": "Different initializer choices allocate the fixed initial budget to maximize coverage (CVT/LHS) or sample randomly; empirically CVT with batch size 3 produced the best downstream performance on one dataset.",
            "breakthrough_discovery_metric": "Indirect: enables faster discovery by providing informative starting points; measured via downstream hypervolume growth and MAE.",
            "performance_metrics": "On the Pd C–H arylation dataset, LHS and CVT showed higher hypervolume expansion rates than random; CVT with batch size 3 achieved the highest hypervolume and lowest MAE.",
            "comparison_baseline": "Random initialization baseline.",
            "performance_vs_baseline": "CVT and LHS outperformed random sampling in hypervolume and MAE metrics; CVT + batch 3 was the best among tested options.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Authors note an exploratory initial phase (broad objective distributions) followed by exploitation (narrower distributions near optima); initializer choice influences speed of transition and variance across runs.",
            "optimal_allocation_findings": "Use CVT or LHS over random initialization for better early coverage and improved downstream optimization metrics; CVT with batch size 3 empirically recommended for the tested dataset.",
            "uuid": "e2619.3",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "DFT featurization",
            "name_full": "Density Functional Theory-derived molecular features",
            "brief_description": "Featurization approach that computes quantum-chemistry-derived descriptors (DFT-level properties) for categorical reaction components (e.g., ligands) to provide informative continuous inputs to the surrogate.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "DFT-based featurization",
            "system_description": "Ligand and component descriptors are computed from DFT calculations and used as continuous features in the surrogate model. This representation can capture physicochemical properties and reactivity-relevant information not present in sparse encodings like One-Hot.",
            "application_domain": "Feature engineering for surrogate modeling in chemical reaction optimization.",
            "resource_allocation_strategy": "Improved featurization yields more informative surrogate predictions per experiment, effectively increasing information gain per experimental resource spent; does not itself perform allocation but affects acquisition efficiency.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "By improving surrogate accuracy and reducing variance, DFT features enable more reliable exploitation (and more targeted exploration), reducing variance across optimization runs.",
            "diversity_mechanism": "Indirect: richer features allow the surrogate and acquisition to distinguish candidates, yielding broader (and more meaningful) Pareto exploration.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Featurization has computational cost (not quantified) separate from experimental budget; trade-off between time to compute features and experimental savings.",
            "budget_constraint_handling": "Paper does not quantify DFT compute cost or handle it as part of budget; it is chosen when feasible because it improved optimization performance and robustness.",
            "breakthrough_discovery_metric": "Faster attainment of high-performing regions (e.g., &gt;90% conversion/selectivity earlier in optimization) and lower variance across runs.",
            "performance_metrics": "DFT-encoded features provided slightly improved hypervolume growth and earlier discovery of high conversion/selectivity (&gt;90%) compared to OHE and Mordred; also exhibited lowest variance across seeded runs.",
            "comparison_baseline": "One-Hot Encoding (OHE) and Mordred chemical-informatics featurization.",
            "performance_vs_baseline": "DFT featurization performed slightly better (faster to optimal regions, lower variance) than OHE and Mordred across the tested datasets.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Paper notes DFT provides stronger, more robust performance but does not quantify the computational cost of computing DFT descriptors versus experimental savings.",
            "optimal_allocation_findings": "When feasible, use DFT-derived descriptors for categorical components (e.g., ligands) to improve surrogate robustness and reduce variance in optimization outcomes.",
            "uuid": "e2619.4",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "EDBOApp",
            "name_full": "EDBO Web Application (EDBOWebApp)",
            "brief_description": "A cloud-backed web GUI for EDBO+ that enables non-expert users to run multi-objective Bayesian optimization experiments, visualize surrogate predictions/uncertainties, adjust condition spaces and thresholds, set batch sizes, and import prior data without local software installation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "EDBOWebApp",
            "system_description": "A browser-accessible user interface backed by cloud compute that exposes EDBO+ functionality: define reaction condition space, select featurization and initialization, run BO campaigns, visualize predicted objectives and uncertainty surfaces, change condition space on-the-fly, set batch sizes and thresholds, import prior experimental data, and view expected improvement traces to decide termination.",
            "application_domain": "Tooling and human-in-the-loop orchestration for chemical reaction optimization and experimental planning.",
            "resource_allocation_strategy": "Provides user controls to set batch size and thresholds; visualizes EI and predicted uncertainty so users can make resource-allocation decisions (e.g., stop when EI small, add/remove candidates).",
            "computational_cost_metric": null,
            "information_gain_metric": "Displays expected improvement (EI) and model uncertainty to inform decisions about expected information gain from additional experiments.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Visual EI traces and uncertainty maps let the human operator decide when to pursue exploration (expand condition space, increase batch diversity) or exploitation (focus on top predicted conditions); acquisition function automates most decisions.",
            "diversity_mechanism": "Allows on-the-fly modification of condition space and batch-size selection; relies on q-EHVI and initialization to produce diverse experimental suggestions.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "User-constrained batch size, experimental-material availability, and time-throughput constraints.",
            "budget_constraint_handling": "User selects batch size and can stop optimization based on low average EI; can import prior data to reduce experimental budget required.",
            "breakthrough_discovery_metric": "Visualized EI and hypervolume traces; surrogate-predicted top objectives and Pareto front.",
            "performance_metrics": "Enables the same experimental performance reported for EDBO+ (e.g., 15 and 24 experiments to beat prior human-optimized conditions) while lowering the programming barrier; no separate benchmarking of web-app overhead reported.",
            "comparison_baseline": "Manual / code-based EDBO+ use and human OFAT workflows; not a methodological baseline but an accessibility/UX comparison.",
            "performance_vs_baseline": "Improves accessibility and enables human-in-the-loop decision-making (no numerical runtime/compute-cost comparison reported).",
            "efficiency_gain": null,
            "tradeoff_analysis": "The app surfaces EI and uncertainty so users can balance additional computational/experimental cost against expected information return; no formal cost-utility optimization of compute vs experiment presented.",
            "optimal_allocation_findings": "Provide human-directed controls (batch size, thresholds, editing condition space) plus automated acquisition (q-EHVI) so users can tailor allocation to experimental resource constraints.",
            "uuid": "e2619.5",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Chimera",
            "name_full": "Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories",
            "brief_description": "A multi-objective optimization package that uses hierarchical scalarization approaches to prioritize objectives for self-driving laboratory workflows; cited in the paper as prior art for multi-objective BO.",
            "citation_title": "Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories",
            "mention_or_use": "mention",
            "system_name": "Chimera",
            "system_description": "A framework combining a priori scalarizing and lexicographic methods to handle multiple objectives in autonomous laboratory optimization, enabling hierarchical prioritization of objectives.",
            "application_domain": "Autonomous laboratory optimization / multi-objective experiment planning.",
            "resource_allocation_strategy": "Uses hierarchical scalarization to prioritize objectives and select experiments that satisfy higher-priority constraints before optimizing lower-priority objectives.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2619.6",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Gryffin",
            "name_full": "Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge",
            "brief_description": "A Bayesian optimization algorithm tailored to categorical variables that can incorporate domain knowledge to guide search; cited as prior multi-objective/autonomous optimization work.",
            "citation_title": "Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge",
            "mention_or_use": "mention",
            "system_name": "Gryffin",
            "system_description": "Algorithm that performs Bayesian optimization over categorical spaces, optionally informed by expert-provided similarity kernels or descriptors to improve sampling efficiency on discrete variables.",
            "application_domain": "Bayesian optimization for experimental design with categorical variables (chemical conditions).",
            "resource_allocation_strategy": "Ranks categorical candidates using a kernel/descriptor-informed surrogate and acquisition function; not used in this study but cited as related work.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2619.7",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "NEXTorch",
            "name_full": "NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering",
            "brief_description": "A PyTorch-based toolkit implementing Bayesian optimization routines for chemical engineering problems; cited as prior art with multi-objective capabilities mostly demonstrated on continuous spaces.",
            "citation_title": "NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering",
            "mention_or_use": "mention",
            "system_name": "NEXTorch",
            "system_description": "A toolkit built on PyTorch providing Bayesian optimization and experiment design tools for chemical sciences; in the cited work multi-objective application was shown for continuous-variable search spaces.",
            "application_domain": "Design and optimization in chemical sciences and engineering.",
            "resource_allocation_strategy": null,
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2619.8",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        },
        {
            "name_short": "Recommender-systems (future)",
            "name_full": "Recommender systems for expansion of reaction condition space",
            "brief_description": "A proposed future direction to use recommender-system techniques to propose condition-space expansions and assist autonomous process optimization (mentioned as future work in the conclusions).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Recommender-system extension",
            "system_description": "Authors propose exploring recommender-system approaches to suggest additions/edits to the reaction condition search space and to aid autonomous process optimization; this is noted as future work and not implemented in the present study.",
            "application_domain": "Assistive suggestion and expansion of experimental candidate spaces for reaction optimization and autonomous labs.",
            "resource_allocation_strategy": "Not implemented; proposed to automate expansion of the candidate space and potentially guide resource allocation by recommending promising new candidates to evaluate.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": null,
            "diversity_mechanism": null,
            "uses_diversity_promotion": null,
            "budget_constraint_type": null,
            "budget_constraint_handling": null,
            "breakthrough_discovery_metric": null,
            "performance_metrics": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": null,
            "optimal_allocation_findings": null,
            "uuid": "e2619.9",
            "source_info": {
                "paper_title": "A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.",
                "publication_date_yy_mm": "2022-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization",
            "rating": 2
        },
        {
            "paper_title": "Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories",
            "rating": 2
        },
        {
            "paper_title": "Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge",
            "rating": 2
        },
        {
            "paper_title": "NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering",
            "rating": 2
        },
        {
            "paper_title": "Bayesian Reaction Optimization as a Tool for Chemical Synthesis",
            "rating": 2
        }
    ],
    "cost": 0.022226499999999996,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Multi-Objective Active Learning Platform and Web App for Reaction Optimization</h1>
<p>Jose A. Garrido Torres ${ }^{\dagger}$, Sii Hong Lau ${ }^{\dagger}$, Pranay Anchuri ${ }^{\dagger}$, Jason M. Stevens, Jose E. Tabora, Jun Li, Alina Borovika, Ryan P. Adams, and Abigail G. Doyle*<br>Department of Chemistry, Princeton University, Princeton, New Jersey 08544, United States<br>Department of Chemistry \&amp; Biochemistry, University of California, Los Angeles, California 90095, United States<br>Chemical Process Development, Bristol Myers Squibb, New Brunswick, New Jersey 08901, United States<br>Center of Information Technology Policy, Princeton University, Princeton, New Jersey 08544, United States<br>Department of Computer Science, Princeton University, Princeton, New Jersey 08544, United States</p>
<h2>Supporting Information Placeholder</h2>
<h4>Abstract</h4>
<p>We report the development of an open-source Experimental Design via Bayesian Optimization platform for multi-objective reaction optimization. Using high-throughput experimentation (HTE) and virtual screening datasets containing high-dimensional continuous and discrete variables, we optimized the performance of the platform by fine-tuning the algorithm components such as reaction encodings, surrogate model parameters and initialization techniques. Having established the framework, we applied the optimizer to real-word test scenarios for the simultaneous optimization of reaction yield and enantioselectivity in a $\mathrm{Ni} /$ photoredox-catalyzed enantioselective cross-electrophile coupling of styrene oxide with two different aryl iodide substrates. Starting with no previous experimental data, the Bayesian optimizer identified reaction conditions that surpassed the previously human-driven optimization campaigns within 15 and 24 experiments, for each substrate, among 1,728 possible configurations available in each optimization. To make the platform more accessible to nonexperts, we developed a Graphical User Interface (GUI) that can be accessed online through a web-based application and incorporated features such as conditions modification on-the-fly and data visualization. This web-application does not require software installation, removing any programming barrier to use the platform, which enables chemists to integrate Bayesian optimization routines into their everyday laboratory practices.</p>
<h2>INTRODUCTION</h2>
<p>Reaction optimization is essential to synthetic chemistry. Typically, an optimization campaign requires the exploration of reaction conditions consisting of multiple categorical and continuous reaction variables, such as catalyst, additive, solvent, temperature, etc. In a synthetic chemistry laboratory, a common optimization strategy involves searching the literature for similar reactions to select components that are anticipated to give a higher chance of success, testing one factor/variable at a time (OFAT or OVAT) to isolate the effect of a single component, and studying the structureactivity relationship to predict better conditions. This approach has served chemists well for reaction optimization, but it neglects interactions between variables which are essential in searching for the global optimum.</p>
<p>Another viable strategy to determine the optimal conditions is to evaluate all possible combinations of the search space. For example, recent advances in high-throughput experimentation (HTE) have allowed chemists to rapidly screen up to thousands of reactions in parallel. ${ }^{1,2}$ However, the number of possible reaction condition configurations scales exponentially as reaction variables vary from tens to
thousands of components. As a result, given limited time and material resources, evaluating the entire condition space is often inefficient from an economic and environmental standpoint.</p>
<p>The simultaneous improvement of multiple reaction objectives adds another layer of complexity to the existing multidimensional challenge in reaction optimization. ${ }^{3}$ In fact, many optimization problems in chemistry, both in academia and the chemical industry, require simultaneous optimization of two or more reaction objectives. ${ }^{4}$ Examples of these objectives are yield, selectivity (regio-, site-, enantio-, chemo-), cost, environmental sustainability, and properties of products. An example of a multi-objective optimization in chemistry is shown in Figure 1A. ${ }^{5}$ In many cases, there is no single solution to multi-objective optimizations such as this one. Instead, locating a set of non-dominated optimal conditions, or the Pareto front, requires balancing the tradeoffs in the objectives. ${ }^{6}$ In other words, the improvement of one objective is sometimes only possible at the expense of other objectives, which makes the identification of global maxima in a condition search space much more challenging.</p>
<p>In the past decade, data science and machine learning methods have been applied to address numerous</p>
<p>challenges in synthetic chemistry, such as multi-step synthetic planning, ${ }^{7-9}$ prediction of reaction outcomes, ${ }^{10,11}$ automated synthesis, ${ }^{12-14}$ and drug design and discovery. ${ }^{15,16}$ There have also been important advances in applying machine learning methods to reaction optimization, ${ }^{17,18}$ building off of data science tools such as partial or full factorial design of experiments (DOE). ${ }^{19-21,22}$ Recently, our group developed EDBO (Experimental Design via Bayesian Optimization), a platform for Bayesian reaction optimization for chemical synthesis (Figure 1B). ${ }^{18}$ Bayesian optimization (BO) is a global optimization algorithm that can interpolate response surfaces by evaluating only a small subset of total possible combinations, thus minimizing requirements to generate a large number of experimental observations. ${ }^{23,24}$</p>
<p>However, EDBO can only perform single-objective optimization and limited effort thus far has been reported for the application of active learning strategies like BO to the simultaneous optimization of multiple objectives in synthetic chemistry. ${ }^{25-27}$ Aspuru-Guzik and coworkers developed Chimera ${ }^{28}$ and Gryffin, ${ }^{29}$ packages for multi-objective optimization that combine the concepts of a priori scalarizing with lexicographic approaches. The same group, in collaboration with Hein, Sigman, and Merck, later
demonstrated its utility in an autonomous process optimization of a stereoselective Suzuki-Miyaura coupling. ${ }^{30}$ The group of Jensen and Jamison also applied multi-objective BO to a computer-proposed multistep synthesis of the small molecule sonidegib on an automated robotic flow platform. ${ }^{31}$ However, these tool are less accessible to non-experts and lack valuable functionality such as the ability to visualize output predictions and modify condition space during the course of an optimization campaign. Recently, the Vlacho group developed NEXTorch, ${ }^{32}$ a toolkit that implements BO routines through PyTorch. ${ }^{33}$ However, its application in multi-objective optimization was only demonstrated using a search space consisting of continuous variables.</p>
<p>These important advances notwithstanding, for these tools to be integrated with the current synthetic chemistry practices it is essential to develop machine learning surrogate models that are not only tuned, validated, and tested on synthetic experimental chemistry data, but also provide improved accessibility and functionality tailored to reaction optimization. For example, enhancements related to augmentation of the condition space on-the-fly (adding or removing reaction condition configurations), data
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. (A) Example of a multi-objective optimization problem in chemistry. $\mathrm{R}^{1}=$ pyrrole fragment, $\mathrm{R}^{2}=$ imidazole fragment, or $\mathrm{Br},{ }^{5}$ (B) Previous workflow: single-objective Experimental Design via Bayesian Optimization (EDBO). (C) Current workflow: multi-objective reaction optimization framework using EDBO+ through its web application.</p>
<p>visualization and access to the predictive estimates of the surrogate models can enable the adoption of Bayesian tools in chemistry. Furthermore, the requirement of prior coding knowledge is a major obstacle for most synthetic chemists to apply BO in their day-to-day laboratory activities.</p>
<p>Herein, we report EDBO+, an open-source multi-objective active-learning platform based on Bayesian theory and its accompanying web application (https://www.edbowebapp.com/ ) (Figure 1C). Several features have been incorporated into EDBO+ including the ability to modify the reaction conditions space during an optimization campaign and the inclusion of visualizations of model predictions and uncertainties. The online platform can be accessed through a web browser, removing a requirement for any software installation, which would allow users with limited programming experience to adopt sin-gle- and multi-objective BO. In this work, we use HTE and virtual screening datasets to optimize the performance of EDBO+ by fine-tuning the algorithm components such as reaction encodings, surrogate model parameters and initialization techniques. We then apply EDBO+ to a real-word test case - a Ni/photoredox-catalyzed enantioselective crosselectrophile coupling of styrene oxides with two different aryl iodide substrates.</p>
<h2>RESULT AND DISCUSSIONS</h2>
<p>General Workflow. The general workflow for EDBO+ begins with input from the synthetic chemist on identifying (a) the reaction conditions space (e.g., catalysts, temperatures and concentrations) that will be explored in the optimization campaign, (b) the featurization for categorical variables (i.e., mathematical representation of the reaction components), (c) the objectives and accompanying thresholds to be optimized, and (d) the number of experiments to be evaluated in parallel per round (batch size). This initial search space can be modified at any stage of the optimization (expanding or reducing the number of components to consider). Once these are defined, the algorithm will suggest an initial set of experimental conditions (following an initialization method, see Optimizer Development section). After completing the suggested experiments in the laboratory, the chemist introduces the outputs of these experiments (e.g., yields and selectivities) back into the platform. EDBO+ builds a regression model using the experimental data and predicts the target objectives for all the remaining untested conditions included in the reaction condition space. Next, an acquisition function ranks the untested conditions based on model predictions and recommends the next set of conditions for experimental evaluation to close the active-learning cycle. Iterations of the active learning cycle will increase the accuracy of the regression predictions by providing the algorithm with more experimental observations, ultimately improving the predictions of the surrogate model. This workflow can be executed through either a command-line interface or a web-based application for single- and multi- objective optimizations.</p>
<p>Optimizer Development. To optimize the performance of EDBO+ (e.g., initialization methods, featurization techniques, and acquisition function), we selected two high-dimensional screening datasets: (a) Pd-catalyzed Suzuki-</p>
<p>Miyaura coupling, ${ }^{34}$ and (b) Pd-catalyzed C-H arylation ${ }^{10}$ as ground truth. The condition space for these two datasets consists of a combination of continuous (e.g., temperature and concentration) and categorical variables (e.g., solvent, base and ligand). The Pd-catalyzed Suzuki-Miyaura cross coupling ${ }^{35,36}$ dataset involves the reaction of an indazolecontaining boronic acid and 6-bromoquinoline, in which the objectives are to maximize the conversion and selectivity simultaneously (Figure 2A). ${ }^{14}$ Heteroaromatic biaryls are attractive scaffolds due to their prevalence in bioactive molecules ${ }^{37,38}$ but their preparation via cross coupling is often accompanied by homocoupling, protodeboronation, and protodehalogenation, as captured in the selectivity objective. ${ }^{39-41}$ This dataset consists of 352 datapoints, including 11 ligands, 4 solvents, and 8 bases.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Overview of the Pd-catalyzed Suzuki-Miyaura coupling dataset. (A) Schematic representation of the reaction and its components along with the desired and side products. "conversion $=$ (total product)/(total product + remaining starting material)<em> $100 \%$, "selectivity $=$ (desired product)/(total products)</em> $100 \%$ (B) Ground truth scatter plots for the two objectives in this reaction (product conversion and selectivity) color-coded by (left) ligand and (right) solvent. The dashed gray lines show the connections for the set of 'non-inferior' solutions in the objective space (Pareto optimal solutions). (C) Experimental conditions for labeled experiments in B.</p>
<p>The second HTE dataset consists of 1,728 total conditions (12 ligands, 4 solvents, 4 bases, 3 temperatures, and 3 concentrations) for the Pd-catalyzed C-H arylation of N1-me-thyl-1H-imidazole-4-carbonitrile and 1-bromo-2-fluorobenzene (see Ref. 18). In this case, we set the optimization goal to be finding reaction conditions that maximize reaction yield while minimizing the overall cost of the reaction. To extend the range of applicability, we also tested the performance of $\mathrm{EDBO}+$ against a virtual-experimentation dataset built for nucleophilic substitution reactions ${ }^{42}$ which exclusively contains continuous variables (see SI).</p>
<p>Using all three datasets, we found that optimal optimization performance can be achieved using a Gaussian process surrogate model and q-Expected HyperVolume Improvement (q-EHVI) as the acquisition function (See SI). ${ }^{43} \mathrm{q}$-EHVI has been shown to maximize hypervolume of predicted experimental outputs with respect to the Pareto, and is intrinsically formulated to be efficient for batch sampling. Independent of the featurization methods used, q-EHVI is found to be optimal when compared to other common acquisition functions such as upper confidence bound (UCB) and $\varepsilon$ greedy (see SI). It requires fewer experiments to find the optimal values and achieves the highest rate of hypervolume expansion at the end of the optimization campaign. The hypervolume indicator is one of the most used set-quality indicators in multi-objective optimization problems since it allows evaluation of the performance of optimizers by considering the diversity, spread and proximity of the collected experimental values to the Pareto front.</p>
<p>Next, we compared the performance of $\mathrm{EDBO}+$ for the Su-zuki-Miyaura dataset using different featurization methods: (a) One-Hot Encoding (OHE) which creates a new variable for each categorical feature, (b) quantum mechanics-based features from Density Functional Theory (DFT) calculations, and (c) chemical informatics-based features using Mordred featurization ${ }^{44}$. To visualize the distribution of the objective values for this reaction, we color-coded the datapoints in Figure 2B according to the two categorical variables in this dataset: ligands (left panel) and solvents (right panel). Interestingly, we observe that no single ligand dominates the Pareto front (see Figure 2B, C). From an algorithm design standpoint, this allows us to test the performance of $\mathrm{EDBO}+$ on data that can be represented either as discrete or continuous depending on the featurization. On the other hand, methanol (MeOH) appeared to populate the Pareto front as the optimal solvent for this transformation.</p>
<p>For each of the three featurization methods, we completed five optimization campaigns starting from different initial experimental conditions. First, we analyzed the distribution of conversion and selectivity values at each step of the optimization campaigns (Fig. 3A). The left panels in Fig. 3A show the evolution of the objective values in each of the five optimization runs and the right panels indicate the density of the objective values after completing these campaigns (after 30 experiments). The density plots obtained using the random sampling (Fig. 3A, in green) show that, in absence of a predictive model, there is a high probability of finding low yield and selectivity values in this dataset. In contrast, the probability of obtaining optimal conditions (with higher yield and selectivity) is increased when using $\mathrm{EDBO}+$ and DFT featurization (see blue density plots in Fig. 3A). We observe this trend for all three featurization methods and in all three datasets (see SI).
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Optimizer performance as a function of the featurization method. (A) Conversion and selectivity values at each step of the optimization campaigns when using DFT featurization (in blue) and random sampling (in green) are shown in the left panels while the right panels show their corresponding distribution of conversion and selectivity over the 30 experiments collected for each run. Different color shades are used to distinguish the five different optimization campaigns. (B) Normalized hypervolume, minimum distance to trade-off experimental values, highest conversion and selectivity as a function of the collected experimental values, averaged over 5 runs with seeded initialization. The solid lines</p>
<p>indicate the average, and the shaded areas represent the upper and lower values at each stage of the optimization campaign.</p>
<p>In order to obtain a deeper understanding of the algorithm's performance when using different featurization methods, we measured the hypervolume covered by the collected experimental values at each optimization step (Figure 3B). In addition, we tracked the minimum distance from any collected experimental output to the high-tradeoff experimental value (in the knee region of the Pareto front, see Ref. 45) as well as the maximum values for conversion and selectivity collected at each step of the optimization. We found that DFT-encoded features provide slightly improved performance over other featurization methods, suggesting experimental conditions with optimal conversion and selectivity values (above 90\%) in earlier stages compared to the optimizations using OHE and Mordred featurization. This is consistent with the single-objective optimization results previously obtained with EDBO. ${ }^{18}$ We also note that the DFT featurization displays the lowest variance (difference
<img alt="img-3.jpeg" src="img-3.jpeg" />
between the upper and lower bounds at each step, highlighted by the shaded regions in Fig. 3B) showing its robustness against the selection of the initial experiments. ${ }^{46}$</p>
<p>Another important consideration in the success of an optimization is the choice of the initial conditions to start the optimization campaign. We illustrate the impact of the initialization method using the Pd-catalyzed C-H arylation dataset (see Ref. 18). The values for yield and cost for this HTE dataset are presented in Figure 4A. We tested the performance of the algorithm when the optimization campaigns are initialized using the Centroidal Voronoi Tessellation (CVT), Latin Hypercube sampling (LHS) and random sampling methods. We assessed the performance of the different methods and batch sizes using the dominated hypervolume metric (Figure 4B). On average, the LHS and CVT methods display a higher rate of hypervolume expansion than the random sampling method. In particular, the highest hypervolume value and lowest Mean Absolute Error (MAE) are achieved when using the CVT method and a batch size of three experiments per round (Figure 4B, C).</p>
<h2>D. Objective values (yield and cost) distribution in each round of the optimization campaigns ( 3 experiments per round)</h2>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4. Model performance for the Pd-catalyzed C-H arylation dataset. (A) Overview of the objectives (yield and cost) values, the dashed lines highlight the Pareto front. The different ligands are color-coded while and different symbols are used to distinguish between solvents. (B) Hypervolume covered by the experimental values collected at each stage of the optimization campaign when using different initialization methods and batch sizes. (C) Mean Absolute Error (MAE) for the different initialization methods and batch sizes. (D) the distribution of yield (in blue) and cost (in red) values at each optimization step when initializing the optimizations using the different sampling methods.</p>
<p>In Figure 4D, we show the distribution of the yield and cost values of the experimental conditions for the different initialization methods using three experiments per round. A similar sampling pattern is found for all initialization methods: (1) an exploratory phase in the first rounds of the optimizations, collecting a wide range of objective values, followed by (2) exploitation behavior, with a narrow distribution of objective values closer to the optimal regions (see Figure 4D). This indicates that the algorithm can suggest optimal values starting from a variety of initial experiments, showing that the combination of the qEHVI acquisition function with the GPR hyperparameters provide a good balance between exploration and exploitation.</p>
<p>Application of EDBO+. Having established an optimized framework for EDBO+ on the HTE datasets, we sought to apply EDBO+ to a real-world test case for the simultaneous optimization of multiple objectives. Recently, our lab developed an enantioselective cross-electrophile coupling of styrene oxides and aryl iodides via the merger of nickel and
photoredox catalysis. ${ }^{47}$ This transformation generates enantioenriched 2,2-diarylalcohols which could be readily derivatized into chiral 1,1-diarylalkanes, an important medicinally relevant motif found in pharmaceuticals such as tolterodine, sertraline, and podophyllotoxins. ${ }^{48-50}$ This reaction presented an ideal test case of EDBO+ for the optimization of both yield and enantioselectivity simultaneously as a yield-ee tradeoff presented a hurdle in our previous optimization campaign. In fact, the tradeoff between yield and stereoselectivity has been a longstanding challenge in enantioselective reactions, yet the two objectives must be optimized concertedly. In this study, we selected two examples to evaluate: the first example involves the model substrate, styrene oxide $\mathbf{1}$ and 4 -iodobenzoate $\mathbf{2}$, and the second is with a challenging heteroaryl iodide, 2-fluoro-5-iodopyridine 4, from the scope studies. The reaction conditions space that we selected comprised 3 nickel precatalysts, 16 bioxazoline and biimidazoline ligands, 2 additives, 3 solvents, 3 concentrations, and 2 light source to give a total space of 1,728 possible configurations.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 5. Applications of EDBO+: $\mathrm{Ni} /$ photoredox-catalyzed enantioselective cross-electrophile coupling of styrene oxides and aryl iodides. DFT featurization for ligand and OHE for other variables, CVT initialization and three experiments per round. Gray spots show datapoints collected using previously optimized condition, and the shades of the blue spots show the progress of the optimization (darker spots represents datapoints collected later in the campaign). The inset plot in A shows the average expected improvement values for yield and ee at each round of the optimization.</p>
<p>We carried out multi-objective Bayesian optimization using DFT encoded features for the ligands, running three experiments in parallel per batch, with initial experiments selected using CVT initialization. The optimizer surpassed the benchmark result within 7 rounds of optimization ( 24 reactions), affording an improved yield of $80 \%$ at the same enantioselectivity ( $91 \%$ ee, Figure 5A). In comparison, the previously reported conditions for the synthesis of $\mathbf{3}$ were identified via a one-factor-at-a-time (OFAT) method and afforded $63 \%$ yield and $91 \%$ ee after roughly 500 experiments. However, it is important to note that this comparison between the number of experiments to obtain the optimal result does not take into consideration that the optimal ligand $\mathbf{L 1 0}$ was not available during the earliest phases of our human-driven optimization campaign. Nevertheless, this example showcases the potential of EDBO+ to identify conditions close to or at the Pareto front and outperformed the previously human-drive optimization campaign by evaluating only a small subset of the total possible configurations.</p>
<p>In reaction discovery, the optimal conditions identified for the model substrate are often applied to a broad range of substrates to evaluate the generality of the method. However, the optimal conditions for one substrate do not always translate to more complex or different variants. In our previous study, the conditions optimized for the model reaction to generate $\mathbf{3}$ afforded $47 \%$ yield and $75 \%$ ee for the coupling between styrene oxide $\mathbf{1}$ and pyridyl iodide $\mathbf{4} .{ }^{69}$ Without pretraining EDBO+ with prior experimental data, we optimized the reaction of $\mathbf{2}$ within the same conditions space. We found that within 4 rounds of optimization ( 15 reactions), EDBO+ identified conditions that afforded higher yield and enantioselectivity ( $59 \%$ yield, $77 \%$ ee, Figure 5B). These conditions are unique in that they feature a different ligand (biimidazolines $\mathbf{L 1 0}$ and $\mathbf{L 1 1}$ feature the same isopropyl substituents but vary in the aniline moiety), solvent, nickel precatalyst, solvent, concentration, and light source when compared to the previously optimized condition. This presented a case where Bayesian optimization learned about interactions between variables that would not typically be identified in a OFAT optimization campaign.</p>
<p>Optimizer features and user interface. Given the potential utility of this multi-objective optimization tool for reaction development efforts, we wanted to make the algorithm more accessible to practicing synthetic chemists. To this end, we developed EDBOApp (www.edbowebapp.com), a web application supported by a cloud-computing platform. No prior programming or coding experience is required to use the web application.</p>
<p>We also incorporated a number of functions into the workflow to make EDBO+ amenable to human-in-the-loop intervention and decision-making. First, the ability to modify the condition space during an optimization campaign allows users to alter the search space by either adding or removing reaction components or dimensions. Second, we added a data visualization tool that shows the objective predictions and uncertainties across all conditions throughout the optimization. This function enables chemists to track the expected improvement (EI) of the target objectives at any stage of the optimization and informs when to terminate the optimization campaign. For instance, the small average EI of yield and ee $(\sim 1 \%)$ toward the end of the
optimization for the Ni/photoredox coupling with styrene oxide $\mathbf{1}$ and aryl iodide $\mathbf{2}$ indicates significant diminishing return to performing additional experiments (See Figure 5a inset).</p>
<p>To improve the functionality and adaptability of the framework, we also incorporated the ability to select different batch sizes based on constraints in experimental set up and accessibility of material resources. Thresholds can be applied to the objectives to prioritize one reaction objective over the others or to focus on specific regions of the pareto front. Finally, previous experimental data can be imported into EDBO+ to pretrain the surrogate model, giving the user a head start in the optimization process. These features, available in the EDBO+ package via command-line or graphic user interface, are intended to provide flexibility as each individual or process has distinct requirements.</p>
<h2>CONCLUSIONS</h2>
<p>We report the development of EDBO+, an open-source multi-objective optimization platform and an accompanying web application that allows chemists to apply Bayesian optimization methods into everyday synthetic chemistry practices. The framework relies on building a surrogate machine learning model by combining the predictive estimates with acquisition functions that balance the exploration/exploitation trade-off of single- and multi-objective optimizations. EDBO+ was tested on a selection of datasets that include both categorical and continuous reaction dimensions to identify surrogate model configurations that could be broadly applicable to optimization problems in synthetic chemistry. In a real-world test case of a Ni/photoredox-catalyzed enantioselective cross-electrophile coupling of styrene oxides with aryl iodides, the optimizer identified conditions that surpassed the originally reported conditions within 15 and 24 experiments (for two different aryl iodide substrates) among a total of 1,728 possible conditions. Further investigations will focus on exploring the use of recommender systems for the expansion of the reaction condition space and its application in autonomous process optimization.</p>
<h2>ASSOCIATED CONTENT</h2>
<h2>Code availability and implementation.</h2>
<p>The command-line interface of EDBO+ used to create and optimize reaction conditions presented in this work, along with the scripts to analyze the performance of the optimizer, are available in the following GitHub repository: https://github.com/doyle-lab-ucla/edboplus.</p>
<h2>Web application.</h2>
<p>We developed EDBOWebApp, a web application that makes the Bayesian optimizer more accessible to users with limited knowledge of programming languages. This web application can be accessed in https://www.edbowebapp.com/ through a web-browser. The back-end is supported by a cloud-computing platform to perform the computations required for creating and optimizing reaction conditions. This makes our routines accessible through any device that</p>
<p>enables web browsing without having to install any software or packages.</p>
<h2>Supporting Information</h2>
<p>The Supporting Information is available free of charge on the ACS Publications website.</p>
<p>Experimental details, optimization studies and characterization data (PDF)
R Source Code (TXT)</p>
<h2>AUTHOR INFORMATION</h2>
<h2>Corresponding Author</h2>
<p>Abigail G. Doyle - Department of Chemistry and Biochemistry, University of California, Los Angeles, California, 90095, United States; orcid.org/0000-0002-66410833; Email: agdoyle@chem.ucla.edu</p>
<h2>Authors</h2>
<p>Jose A. Garrido Torres - Department of Computer Science, Princeton University, Princeton, New Jersey 08544, United States; orcid.org/0000-0002-1727-0862
Sii Hong Lau - Department of Chemistry, Princeton University, Princeton, New Jersey 08544, United States; Department of Chemistry \&amp; Biochemistry, University of California, Los Angeles, California 90095, United States.
Pranay Anchuri - Center for Information Technology Policy, Princeton University, Princeton, New Jersey 08544, United States; orcid.org/0000-0003-4377-5036
Jason M. Stevens - Chemical Process Development, Bristol Myers Squibb, 556 Morris Ave, Summit, NJ 07901, United States; orcid.org/0000-0003-1671-1539
Jose E. Tabora - Chemical Process Development, Bristol Myers Squibb, New Brunswick, New Jersey 08903, United States.
Jun Li - Chemical Process Development, Bristol Myers Squibb, 1 Squibb Drive, New Brunswick, NJ 08903, United States; orcid.org/0000-0002-0594-7143
Alina Borovika - Chemical Process Development, Bristol Myers Squibb, 1 Squibb Drive, New Brunswick, NJ 08903, United States.
Ryan P. Adams - Department of Computer Science, Princeton University, Princeton, New Jersey 08544, United States; orcid.org/0000-0002-5704-6654</p>
<h2>Author Contributions</h2>
<p>${ }^{\dagger}$ These authors contributed equally.</p>
<h2>Funding</h2>
<p>The authors declare no competing financial interest.</p>
<h2>ACKNOWLEDGMENT</h2>
<p>This work was supported financially by NSF through the Center for Computer Assisted Synthesis C-CAS (CHE1925607), Bristol-Myers Squibb through the Princeton Catalysis Initiative, and the Dreyfus Program for Machine Learning in the Chemical Sciences and Engineering. J.A.G.T. and P.A. acknowledge support from the Schmidt DataX Fund at Princeton University made possible through a major gift from the Schmidt Futures Foundation. J.A.G.T and A.G.D. acknowledge support of Azure cloud computing credits at Princeton University made possible through a gift
from the Microsoft Corporation. The authors thank Neal Sach (Pfizer) and Paul Richardson (Pfizer) for kindly providing the Pd-catalyzed Suzuki-Miyaura HTE dataset included in this work.</p>
<h2>REFERENCES</h2>
<p>(1) Cernak, T.; Gesmundo, N. J.; Dykstra, K.; Yu, Y.; Wu, Z.; Shi, Z.-C.; Vachal, P.; Sperbeck, D.; He, S.; Murphy, B. A.; Sonatore, L.; Williams, S.; Madeira, M.; Verras, A.; Reiter, M.; Lee, C. H.; Cuff, J.; Sherer, E. C.; Kuethe, J.; Goble, S.; Perrotto, N.; Pinto, S.; Shen, D.-M.; Nargund, R.; Balkovec, J.; Devita, R. J.; Dreher, S. D. Microscale High-Throughput Experimentation as an Enabling Technology in Drug Discovery: Application in the Discovery of (Piperidinyl)Pyridinyl-1H-Benzimidazole Diacylglycerol Acyltransferase 1 Inhibitors. J. Med. Chem. 2017, 60, 3594-3605.
(2) Häse, F.; Roch, L. M.; Aspuru-Guzik, A. Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories. Chem. Sci. 2018, 9, 7642-7655.
(3) Mariette, A.; Rahul, K. Efficient Learning Machines: Theories, Concepts, and Applications for Engineers and System Designers; Springer Nature. 2015.
(4) Rangaiah, G. P.; Feng, Z.; Hoadley, A. F. Multi-Objective Optimization Applications in Chemical Process Engineering: Tutorial and Review. Processes 2020, 8, 508.
(5) Fox, R. J.; Cuniere, N. L.; Bakrania, L.; Wei, C.; Strotman, N. A.; Hay, M.; Fanfair, D.; Regens, C.; Beutner, G. L.; Lawler, M.; Lobben, P.; Soumeillant, M. C.; Cohen, B.; Zhu, K.; Skliar, D.; Rosner, T.; Markwalter, C. E.; Hsiao, Y.; Tran, K.; Eastgate, M. D. C-H Arylation in the Formation of a Complex Pyrrolopyridine, the Commercial Synthesis of the Potent JAK2 Inhibitor, BMS-911543. J. Org. Chem. 2019, 84, 4661-4669.
(6) Alessio, I.; Philippe, N. Multi-Criteria Decision Analysis: Methods and Software; John Wiley \&amp; Sons. 2013.
(7) Segler, M. H. S.; Preuss, M.; Waller, M. P. Planning Chemical Syntheses with Deep Neural Networks and Symbolic AI. Nature 2018, 555, 604-610.
(8) Coley, C. W.; Green, W. H.; Jensen, K. F. Machine Learning in Computer-Aided Synthesis Planning. Acc. Chem. Res. 2018, 51, 1281-1289.
(9) Szymkuć, S.; Gajewska, E. P.; Klucznik, T.; Molga, K.; Dittwald, P.; Startek, M.; Bajczyk, M.; Grzybowski, B. A. Com-puter-Assisted Synthetic Planning: The End of the Beginning. Angew. Chem. Int. Ed. 2016, 55, 5904-5937.
(10) Wei, J. N.; Duvenaud, D.; Aspuru-Guzik, A. Neural Networks for the Prediction of Organic Chemistry Reactions. ACS Cent. Sci. 2016, 2, 725-732.</p>
<p>(11) Coley, C. W.; Barzilay, R.; Jaakkola, T. S.; Green, W. H.; Jensen, K. F. Prediction of Organic Reaction Outcomes Using Machine Learning. ACS Cent. Sci. 2017, 3, 434-443.
(12) Steiner, S.; Wolf, J.; Glatzel, S.; Andreou, A.; Granda, J. M.; Keenan, G.; Hinkley, T.; Aragon-Camarasa, G.; Kitson, P. J.; Angelone, D.; Cronin, L. Organic Synthesis in a Modular Robotic System Driven by a Chemical Programming Language. Science 2019, 363.
(13) Kitson, P. J.; Marie, G.; Francoia, J.-P.; Zalesskiy, S. S.; Sigerson, R. C.; Mathieson, J. S.; Cronin, L. Digitization of Multistep Organic Synthesis in Reactionware for On-Demand Pharmaceuticals. Science 2018, 359, 314-319.
(14) Coley, C. W.; ThomasIII, D. A.; Lummiss, J. A. M.; Jaworski, J. N.; Breen, C. P.; Schultz, V.; Hart, T.; Fishman, J. S.; Rogers, L.; Gao, H.; Hicklin, R. W.; Plehiers, P. P.; Byington, J.; Piotti, J. S.; Green, W. H.; Hart, A. J.; Jamison, T. F.; Jensen, K. F. A Robotic Platform for Flow Synthesis of Organic Compounds Informed by AI Planning. Science 2019, 365.
(15) Ma, J.; Sheridan, R. P.; Liaw, A.; Dahl, G. E.; Svetnik, V. Deep Neural Nets as a Method for Quantitative StructureActivity Relationships. J. Chem. Inf. Model 2015, 55, 263274.
(16) Chen, H.; Engkvist, O.; Wang, Y.; Olivecrona, M.; Blaschke, T. The Rise of Deep Learning in Drug Discovery. Drug Discov. Today 2018, 23, 1241-1250.
(17) Zhou, Z.; Li, X.; Zare, R. N. Optimizing Chemical Reactions with Deep Reinforcement Learning. ACS Cent. Sci. 2017, 3, 1337-1344.
(18) Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.; Janey, J. M.; Adams, R. P.; Doyle, A. G. Bayesian Reaction Optimization as a Tool for Chemical Synthesis. Nature 2021, 590, 89-96.
(19) Weissman, S. A.; Anderson, N. G. Design of Experiments (DoE) and Process Optimization. A Review of Recent Publications. Org. Process Res. Dev. 2015, 19, 1605-1633.
(20) Lee, R. Statistical Design of Experiments for Screening and Optimization. Chem. Ing. Tech 2019, 91, 191-200.
(21) Murray, P. M.; Bellany, F.; Benhamou, L.; Bučar, D.-K.; Tabor, A. B.; Sheppard, T. D. The Application of Design of Experiments (DoE) Reaction Optimisation and Solvent Selection in the Development of New Synthetic Chemistry. Org. Biomol. Chem. 2015, 14, 2373-2384.
(22) Rolf, C.; E, C., Johan. Design and Optimization in Organic Synthesis; Elsevier. 2005.
(23) Snoek, J.; Larochelle, H.; Adams, R. P. Practical Bayesian Optimization of Machine Learning Algorithms. In Advances in Neural Information Processing Systems 2012, 2951-2959.
(24) Shahriari, B.; Swersky, K.; Wang, Z.; Adams, R. P.; Freitas, N. de. Taking the Human Out of the Loop: A Review of Bayesian Optimization. IEEE 2016, 104, 148-175.
(25) Jumbam, D. N.; Skilton, R. A.; Parrott, A. J.; Bourne, R. A.; Poliakoff, M. The Effect of Self-Optimisation Targets on the Methylation of Alcohols Using Dimethyl Carbonate in Supercritical CO2. J. Flow. Chem. 2012, 2, 24-27.
(26) McMullen, J. P.; Jensen, K. F. An Automated Microfluidic System for Online Optimization in Chemical Synthesis. Org, Process Res, Dev, 2010, 14, 1169-1176.
(27) Krishnadasan, S.; Brown, R. J. C.; deMello, A. J.; deMello, J. C. Intelligent Routes to the Controlled Synthesis of Nanoparticles. Lab on a Chip 2007, 7, 1434-1441.
(28) Häse, F.; Roch, L. M.; Aspuru-Guzik, A. Chimera: Enabling Hierarchy Based Multi-Objective Optimization for Self-Driving Laboratories. Chem. Sci. 2018, 9, 7642-7655.
(29) Häse, F.; Aldeghi, M.; Hickman, R. J.; Roch, L. M.; AspuruGuzik, A. Gryffin: An Algorithm for Bayesian Optimization of Categorical Variables Informed by Expert Knowledge. Appl. Phys. Rev. 2021, 8, 031406.
(30) Christensen, M.; Yunker, L. P. E.; Adedeji, F.; Häse, F.; Roch, L. M.; Gensch, T.; Gomes, G. dos P.; Zepel, T.; Sigman, M. S.; Aspuru-Guzik, A.; Hein, J. E. Data-Science Driven Autonomous Process Optimization. Commun. Chem. 2021, 4, 112 .
(31) Nambiar, A. M. K.; Breen, C. P.; Hart, T.; Kulesza, T.; Jamison, T. F.; Jensen, K. F. Bayesian Optimization of Com-puter-Proposed Multistep Synthetic Routes on an Automated Robotic Flow Platform. ACS Cent. Sci. 2022, 8, 825836.
(32) Wang, Y.; Chen, T.-Y.; Vlachos, D. G. NEXTorch: A Design and Bayesian Optimization Toolkit for Chemical Sciences and Engineering. J. Chem. Inf. Model 2021, 61, 5312-5319.
(33) Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.; Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.; Desmaison, A.; Köpf, A.; Yang, E.; DeVito, Z.; Raison, M.; Tejani, A.; Chilamkurthy, S.; Steiner, B.; Fang, L.; Bai, J.; Chintala, S. PyTorch: An Imperative Style, High-Performance Deep Learning Library. Arxiv 2019.
(34) Perera, D.; Tucker, J. W.; Brahmbhatt, S.; Helal, C. J.; Chong, A.; Farrell, W.; Richardson, P.; Sach, N. W. A Platform for Automated Nanomole-Scale Reaction Screening and Mi-cromole-Scale Synthesis in Flow. Science 2018, 359, 429434.
(35) Akira, S. Cross-Coupling Reactions Of Organoboranes: An Easy Way To Construct C-C Bonds (Nobel Lecture). Angew. Chem. Int. Ed. 2011, 50, 6722-6737.</p>
<p>(36) Blackmore, D. Suzuki-Miyaura Coupling. in Synthetic Methods in Drug Discovery: Volume 1, 2015.
(37) Vitaku, E.; Smith, D. T.; Njardarson, J. T. Analysis of the Structural Diversity, Substitution Patterns, and Frequency of Nitrogen Heterocycles among U.S. FDA Approved Pharmaceuticals. J. Med. Chem. 2014, 57, 10257-10274.
(38) Heravi, M.; Zadsirjan, V. Prescribed Drugs Containing Nitrogen Heterocycles: An Overview. RSC Adv. 2020, 10, $44247-44311$.
(39) Billingsley, K. L.; Buchwald, S. L. A General and Efficient Method for the Suzuki-Miyaura Coupling of 2-Pyridyl Nucleophiles. Angew. Chem. Int. Ed. 2008, 47, 4695-4698.
(40) Cox, P. A.; Reid, M.; Leach, A. G.; Campbell, A. D.; King, E. J.; Lloyd-Jones. Base-Catalyzed Aryl-B(OH)2 Protodeboronation Revisited: From Concerted Proton Transfer to Liberation of a Transient Aryl Anion. J. Am. Chem. Soc. 2017, 139, 13156-13165.
(41) Cox, P. A.; Leach, A. G.; Campbell, A. D.; Lloyd-Jones. Protodeboronation of Heteroaromatic, Vinyl, and Cyclopropyl Boronic Acids: PH-Rate Profiles, Autocatalysis, and Disproportionation. J. Am. Chem. Soc. 2016, 138, 9145-9157.
(42) Domagalski, N. R.; Mack, B. C.; Tabora, J. E. Analysis of Design of Experiments with Dynamic Responses. Org. Process Res. Dev. 2015, 19, 1667-1682.
(43) Daulton, S.; Balandat, M.; Bakshy, E. Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization. Arxiv 2020.</p>
<h2>TOC graphic:</h2>
<p><img alt="img-6.jpeg" src="img-6.jpeg" />
(44) Moriwaki, H.; Tian, Y.-S.; Kawashita, N.; Takagi, T. Mordred: A Molecular Descriptor Calculator. J. Cheminformatics 2018, 10, 4.
(45) Rachmawati, L.; Srinivasan, D. Multiobjective Evolutionary Algorithm with Controllable Focus on the Knees of the Pareto Front. IEEE T. Evolut. Comput. 2009, 13, 810824 .
(46) Pomberger, M.; Pedrina McCarthy, A. A.; Khan, A.; Sung, S.; Taylor, C. J.; Gaunt, M. J.; Colwell, L.; Walz, D.; Lapkin, A. A. The Effect of Chemical Representation on Active Machine Learning towards Closed-Loop Optimization. React. Chem. Eng. 2022, 7, 1368-1379.
(47) Lau, S. H.; Borden, M. A.; Steiman, T. J.; Wang, L. S.; Parasram, M.; Doyle, A. G. Ni/Photoredox-Catalyzed Enantioselective Cross-Electrophile Coupling of Styrene Oxides with Aryl Iodides. J. Am. Chem. Soc. 2021, 143, 1587315881.
(48) Hills, C. J.; Winter, S. A.; Balfour, J. A. Tolterodine. Drugs 1998, 55, 813-820.
(49) McRae, A. L.; Brady, K. T. Review of Sertraline and Its Clinical Applications in Psychiatric Disorders. Expert Opin. Pharmaco. 2005, 2, 883-892.
(50) Ameen, D.; Snape, T. J. Chiral 1,1-Diaryl Compounds as Important Pharmacophores. Medchemcomm 2013, 4, 893907.</p>            </div>
        </div>

    </div>
</body>
</html>