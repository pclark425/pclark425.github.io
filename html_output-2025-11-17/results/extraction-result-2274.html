<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2274 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2274</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2274</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-256627182</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2302.03258v1.pdf" target="_blank">Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles</a></p>
                <p><strong>Paper Abstract:</strong> The availability of training data remains a significant obstacle for the implementation of machine learning in scientific applications. In particular, estimating how a system might respond to external forcings or perturbations requires specialized labeled data or targeted simulations, which may be computationally intensive to generate at scale. In this study, we propose a novel solution to this challenge by utilizing a principle from statistical physics known as the Fluctuation-Dissipation Theorem (FDT) to discover knowledge using an AI model that can rapidly produce scenarios for different external forcings. By leveraging FDT, we are able to extract information encoded in a large dataset produced by Earth System Models, which includes 8250 years of internal climate fluctuations, to estimate the climate system's response to forcings. Our model, AiBEDO, is capable of capturing the complex, multi-timescale effects of radiation perturbations on global and regional surface climate, allowing for a substantial acceleration of the exploration of the impacts of spatially-heterogenous climate forcers. To demonstrate the utility of AiBEDO, we use the example of a climate intervention technique called Marine Cloud Brightening, with the ultimate goal of optimizing the spatial pattern of cloud brightening to achieve regional climate targets and prevent known climate tipping points. While we showcase the effectiveness of our approach in the context of climate science, it is generally applicable to other scientific disciplines that are limited by the extensive computational demands of domain simulation models. Source code of AiBEDO framework is made available at https://github.com/kramea/kdd_aibedo. A sample dataset is made available at https://doi.org/10.5281/zenodo.7597027. Additional data available upon request.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2274.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2274.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AiBEDO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AiBEDO (AI model guided by statistical physics principles)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid AI framework that trains data-driven emulators of lagged climate response to cloud/radiation perturbations and combines them using a Fluctuation-Dissipation-Theorem-like time-integration to rapidly estimate regional and global climate responses to Marine Cloud Brightening (MCB) forcings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>climate modeling / climate intervention (Marine Cloud Brightening) scenario analysis</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Rapidly generate and explore climate intervention scenarios (spatio-temporally heterogeneous cloud-brightening forcings) that would be computationally intractable to evaluate with full Earth System Model (ESM) runs, by estimating time-lagged climate responses to imposed radiation perturbations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant simulation data from ESMs: uses CESM2 Large Ensemble providing nearly 100,000 months of internal-variability samples and an asserted 8250 years-equivalent of internal fluctuations; additionally uses targeted CESM2 MCB perturbation simulations (fixed-SST and coupled) for evaluation. Data are labeled (inputs: radiation/cloud perturbation fields; outputs: climate response fields) and accessible to the authors; quality is high (ESM outputs) but availability to others may be constrained.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional spatio-temporal fields: monthly global gridded climate variables (resampled to an ~10k-point icosahedral sphere mesh), multichannel (7 input and 7 output climate variables), time-series with multi-month lags.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: global-scale, multiscale spatio-temporal dynamics, strong nonlinearity and teleconnections (e.g., ENSO), high dimensionality (~10242 spatial points × multi-channel), and multi-timescale lagged responses up to 48 months considered.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature domain with established Earth System Models and statistical-physics theory (FDT), but scenario/decision-analysis for geoengineering interventions (MCB) remains active research with significant uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — scientific interpretability and causal/teleconnection understanding are required for assessing tipping-point risks and to validate that emulated responses reflect physically plausible mechanisms (AiBEDO uses FDT guidance and visualization tools to support interpretability).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Hybrid physics-guided ML surrogate (AiBEDO): lagged emulators + FDT-like time-integration</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>AiBEDO trains supervised, lag-specific emulators A_tau that map input radiation/cloud anomaly fields x(t) to output climate anomaly fields y(t+tau) for tau in {0..6, 12, 24, 36, 48} months; models are trained on internal variability samples from a large ensemble (subsample N=480 months per perturbation calculation). The set of lagged emulators are combined in an FDT-inspired summation/integration (replacing linear FDT operator with learned nonlinear A_tau operators) to compute a time-integrated mean response to a constant forcing. Preprocessing includes ensemble-mean removal (to isolate internal variability), spherical icosahedral resampling, and use of fixed-SST ERF fields to compute perturbations for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>hybrid (physics-guided ML / supervised learning surrogate models)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate and applicable for fast scenario exploration where abundant simulation-derived internal-variability data exist; limitations include linear-FDT assumptions for integration (mitigated by using nonlinear learned lag operators), extrapolation/out-of-distribution risks for novel perturbation patterns, and degraded skill at high latitudes/over land.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Correlation of lag-integrated S-MLP AiBEDO response vs CESM2 coupled runs: temperature (tas) r=0.68, precipitation (pr) r=0.51, surface pressure (ps) r=0.47; AiBEDO reproduces ESM results with comparable RMSE and spatial correlation while producing outputs ~10^3 times faster than ESM runs (claimed 'three orders of magnitude' speed-up). Training costs: S-MLP ~1 min/epoch (15 epochs), S-Unet ~1.5 min/epoch (30 epochs), S-AFNO up to ~12 min/epoch (50 epochs) on a single NVIDIA V100 16GB GPU.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>AiBEDO (with S-MLP) captures complex multi-timescale and remote teleconnected responses (e.g., La Niña-like Pacific signals, regional drying/wetting teleconnections) and outperforms simple persistence baselines across lags; performance is best in tropics and over oceans and weaker at higher latitudes/over land; regional perturbation responses vary by target region (best for SEP, worse and overestimated for NEP), indicating some mode-mixing and sensitivity to dominant variability modes (e.g., ENSO).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential for enabling rapid, interactive exploration of climate-intervention scenarios (MCB), facilitating tipping-point risk assessment and optimization of spatial patterns of forcing; significant time/cost savings vs full ESM runs make many more what-if scenarios tractable and support decision-oriented workflows and visualization-based scientist-in-the-loop analysis. Generalizable to other domains limited by expensive simulations where large ensembles of internal variability exist.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to full CESM2 ESM coupled simulations (ground truth) and to persistence baseline: AiBEDO yields similar spatial pattern fidelity (correlations above) while being ~1000× faster; internally compared three ML architectures (S-MLP, S-Unet, S-AFNO) and selected S-MLP for downstream use due to superior empirical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large training dataset of internal variability from CESM2 LE, spherical resampling to reduce geometric bias, use of lagged supervised emulators combined by an FDT-like integration to capture multi-timescale response, and the use of a large-capacity fully connected S-MLP able to capture global long-range interactions; visualization and OOD checks aided interpretability and safe use.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining supervised lag-specific emulators trained on rich internal-variability ensembles with an FDT-inspired time-integration yields a hybrid physics-ML surrogate that can rapidly and plausibly reproduce ESM-scale climate responses, provided sufficient ensemble data and architectures that capture global long-range interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2274.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2274.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FDT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fluctuation-Dissipation Theorem (FDT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A statistical-physics principle that relates a system's response to external forcings to its internal (unforced) fluctuations via a linear response operator constructed from covariances; used here as conceptual/operational guidance to convert learned lagged emulator outputs into time-integrated mean responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>statistical physics applied to climate response estimation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Estimate the mean climate response to a constant external forcing by leveraging internal variability covariances (classical FDT) or replacing the linear operator with learned nonlinear lag operators to relax Gaussian/linearity assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Uses internal variability samples from a large ESM ensemble to compute covariance-like statistics and to train lagged emulators; data are abundant within the CESM2 LE used.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series of multivariate climate fields enabling covariance/lag-covariance computation; high-dimensional spatio-temporal data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Mathematically complex due to high-dimensional covariances, non-Gaussianity, nonlinearity, and structural instability of climate dynamics; classic FDT limited to linear/quasi-Gaussian responses.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established theoretical framework in statistical physics and climate dynamics (long literature), but practical application to full ESMs has known limitations requiring approximations and adaptations.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — FDT-based inference is interpretable and aimed at mechanistic understanding but relies on assumptions (linearity, Gaussianity) that limit its direct applicability without adjustments.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>FDT-guided integration of learned lagged emulators (physics-guided ML operator replacement)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Replace the linear FDT operator L with a series of learned nonlinear lag operators A_tau; compute time-integrated response via summation/integration over modelled lag responses applied to samples of internal variability (equation 2 in paper), thereby relaxing the Gaussian/linear assumptions of classic FDT.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>physics-guided ML / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable when large datasets of internal variability are available to learn lagged mappings; helps extend FDT to capture nonlinear components but will not fully address strongly nonlinear or rare-event responses without targeted training data.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Not given separately from AiBEDO; the hybrid FDT-like integration using learned A_tau contributed to the reported correlation scores (e.g., tas r=0.68) and enabled 6–48 month integrated responses.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides a principled way to combine lagged learned responses into a time-integrated estimate while acknowledging classical FDT limitations; effective in capturing time-integrated teleconnected responses in the studied application.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Extends applicability of FDT-style response estimation to settings where linearity/Gaussian assumptions fail by leveraging ML to model nonlinear lagged responses, enabling faster scenario evaluation in climate and potentially other domains with ensemble variability data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to classic linear FDT (cited) — the paper argues that replacing L with learned A_tau relaxes FDT assumptions and captures nonlinear responses better; no direct numerical comparison reported between classical covariance-based FDT operator and learned-A_tau integration within the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of abundant internal-variability data to train lagged mappings, and careful design of lag range and sample sizes; using many randomized internal-fluctuation samples to reduce sampling noise in integration.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Using ML to learn lag-resolved nonlinear response operators and integrating them in an FDT-like manner allows leveraging internal variability datasets to estimate forced responses beyond the linear/quasi-Gaussian scope of classical FDT.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2274.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2274.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>S-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spherical Multilayer Perceptron (S-MLP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully connected deep neural network applied to spherical-resampled climate fields (icosahedral grid) that maps multichannel radiation/cloud anomaly inputs to multichannel climate response outputs for specific time lags.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>spatio-temporal climate emulation / surrogate modeling</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Learn pixel-wise regression from spherical climate input fields to delayed climate response fields for different monthly lags to form components of a time-integrated response operator.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Trained on CESM2 Large Ensemble internal variability samples (nearly 100,000 months of data overall); per-lag models trained using the prepared dataset split (specific per-lag sample sizes not exhaustively enumerated beyond references to N=480-month samples for perturbation experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional multichannel vectors (resampled icosahedral 1D arrays length 10242) representing monthly climate variables; supervised input-output pairs for each lag.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional regression with long-range spatial dependencies and nonlinear teleconnections; model needs to map multi-channel inputs to multi-channel outputs and capture nonlocal interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Application of MLPs to climate emulation is a pragmatic engineering choice; variant integrating spherical sampling is specialized for geodesy-aware inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-high — the model is used for scientific scenario analysis so interpretability and physical plausibility matter; S-MLP is a black-box but used within a physics-guided integration and diagnostic visualization to aid interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Fully-connected deep multilayer perceptron on spherical mesh</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Architecture: four hidden fully-connected layers of 1024 nodes each, layer normalization, GeLU activation, AdamW optimizer (initial LR 2e-4 decayed exponentially), decoupled weight decay, ~108M trainable parameters, trained for 15 epochs with batch size 10 on V100 GPU. Each lag has a separate S-MLP trained to map inputs δx(t) to outputs y(t+τ).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (deep neural network surrogate)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable for this task when large training data exist; leverages global connectivity to capture long-range teleconnections but is parameter-heavy and may overfit if data are limited.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Empirically outperformed S-Unet and S-AFNO in downstream MCB scenario emulation; lag-integrated correlation vs CESM2: tas r=0.68, pr r=0.51, ps r=0.47. Training: ~1 minute per epoch, ~108M params.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Performed best at capturing global response patterns and teleconnections, especially for multi-month lagged responses; advantage attributed to fully-connected structure and large parameter count enabling modelling of long-range interactions; risk of overfitting and heavier compute per inference than lighter models but still vastly faster than ESMs.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables accurate and fast emulation of complex climate responses for scenario analysis and what-if exploration when adequate training data exist; its global attention properties are key for capturing teleconnections.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared directly to S-Unet and S-AFNO; S-MLP had comparable RMSE to S-AFNO for simultaneous mapping but substantially better qualitative and lagged performance, and better global pattern recovery than S-Unet (which lost long-range info during pooling).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Very large parameterization enabling modeling of global correlations, sufficient training data from large ensemble, spherical resampling removing projection biases, and careful per-lag supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>A high-capacity fully connected spherical MLP can better capture global, lagged climate response patterns than locality-biased architectures or transformer-based AFNOs when trained on a sufficiently large ensemble of internal variability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2274.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2274.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>S-Unet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spherical U-Net (S-Unet)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A spherical adaptation of the U-Net convolutional encoder-decoder architecture using Chebyshev graph convolutions on an icosahedral spherical mesh to predict climate response fields from input perturbation fields.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>spatio-temporal climate emulation / image-to-image prediction on the sphere</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Capture local spatial features of climate response fields and perform pixel-wise regression on spherical climate data for different lags.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Trained on the same CESM2 LE datasets as other models; training used full spherical resampled inputs and outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multichannel spherical graph signals (icosahedral mesh, 10242 nodes), monthly time steps.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Requires capturing both local fine-scale spatial patterns and global teleconnections; convolutional pooling operations may reduce ability to model long-range interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>U-Net-style architectures are well-established for image-to-image tasks and have been adapted to spherical domains (e.g., DeepSphere); their use in climate emulation is established but with known locality limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — U-Net is mainly a predictive model; interpretability depends on downstream analysis and visualization.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Graph-based spherical U-Net with Chebyshev graph convolutions</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Architecture: encoder-decoder U-Net with six Chebyshev graph convolutional layers, spherical Chebyshev pooling, encoder/decoder kernel sizes [64,128,256,512,512,512], softmax output processing, AdamW optimizer (initial LR 5e-4 decayed), ~5.8M parameters, trained 30 epochs, ~1.5 min/epoch on V100 GPU.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (graph convolutional / encoder-decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable to capturing local spatial structure and fine features; less suitable for tasks dominated by long-range teleconnections unless augmented with global attention mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Lower empirical performance than S-MLP in lagged response tasks; exact RMSE/correlation values were lower than S-MLP though RMSEs were sometimes comparable for short lags.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Captured some local aspects of responses (e.g., tropical Pacific features) but missed many key large-scale teleconnection patterns and performed worse in lagged settings, likely due to information loss from pooling and locality bias.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Useful for localized pattern emulation and where fine spatial features matter, but limited in estimating global teleconnected responses unless combined with global attention mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Directly compared to S-MLP and S-AFNO; underperformed both in capturing global lagged responses, with S-MLP significantly better overall.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Graph-based spherical convolution respects sphere geometry and captures local spatial detail; however, the locality assumption and pooling reduced its ability to capture global teleconnections needed for global climate response emulation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Locality-focused spherical convolutional architectures can capture fine spatial features but may underperform for global teleconnected climate response tasks that require modeling long-range interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2274.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2274.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>S-AFNO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spherical Adaptive Fourier Neural Operator (S-AFNO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A spherical adaptation of transformer/AFNO (Adaptive Fourier Neural Operator) architecture which tokenizes spherical inputs and applies AFNO layers for spatial mixing and MLPs for channel mixing to predict lagged climate responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>spatio-temporal climate emulation / operator learning for PDE-like climate dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Leverage transformer-like token mixing and AFNO spectral mixing to model spatio-temporal mappings from input radiation perturbations to delayed climate responses on a spherical domain.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Trained on the CESM2 LE internal variability dataset; authors note that transformer-based AFNOs typically require larger datasets than were available for the best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Spherically resampled 1D token sequence (10242 tokens) with multichannel embeddings, treated as a sequence for transformer/AFNO processing.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: modeling complex nonlocal interactions and high-dimensional spatio-temporal mappings; AFNO aims to efficiently approximate operator mappings but demands significant data and compute.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>AFNO and transformer-based operator learning are recent developments with growing application in weather/climate (e.g., FourcastNet) but are relatively new compared to convolutional and MLP approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — provides flexible operator learning but interpretability of transformer-based models can be limited; used here inside a physically-guided framework.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformer + Adaptive Fourier Neural Operator adapted to spherical 1D token sequence (S-AFNO)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Architecture: 4-layer transformer with AFNO spatial mixing per layer, token embedding size 384, GeLU activations, layer norm, MLP channel mixing; tokens formed from the spherical 1D resampled input rather than 2D patches; ~9M trainable parameters (paper reports variants with ~9M and training for up to 50 epochs), AdamW optimizer with initial LR 5e-4 decayed, training cost higher (~12 min/epoch reported for some runs).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (operator learning / transformer-based)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Promising for operator learning and spatial mixing in PDE-like systems; in this study underperformed S-MLP likely due to limited training data and higher computational cost, suggesting applicability increases with more data/compute.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Achieved comparable RMSE to S-MLP for simultaneous mappings but worse qualitative and lagged performance; training: up to ~12 min/epoch, ~9M parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Captured some response aspects and performed better than S-Unet in places, but overall underperformed S-MLP, particularly in lagged responses; authors attribute this to insufficient data for transformer-style models and higher per-epoch compute.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High potential if supplied with larger datasets and compute — transformer/AFNO architectures can model complex operator mappings and may scale better with more data for climate operator learning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Direct comparison showed S-AFNO > S-Unet in some metrics but < S-MLP overall for the available data regime; S-AFNO had comparable RMSE for simultaneous mapping but failed to match S-MLP's lagged pattern fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>AFNO/token-mixing strategy is theoretically well-suited for PDE/operator problems; success depends on ample training data and computational resources to fully exploit spectral mixing layers.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Transformer/AFNO-based operator learners hold promise for climate emulation but require more data/compute to outperform large fully-connected models in capturing long-range, lagged climate responses in this data regime.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2274.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2274.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spherical sampling (icosahedral resampling)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Geodesy-aware spherical sampling using level-5 icosahedral mesh</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A preprocessing technique converting latitude-longitude ESM gridded outputs to a uniform-density icosahedral spherical mesh (level-5 ~10242 points) via interpolation to remove projection biases and better represent rotational symmetry for ML models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>data preprocessing for geospatial ML / climate model emulation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Address the non-uniform area and rotational symmetry issues of lat-lon grids which bias ML models (e.g., CNNs) by resampling to a uniform spherical mesh to improve representation of global-scale patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Applied to available CESM2 lat-lon outputs prior to ML training; data are abundant and can be resampled as needed.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Transforms 2D gridded rectangular (lat-lon) arrays into 1D sequences corresponding to spherical icosahedral mesh nodes; retains multichannel per-node values.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate preprocessing complexity: graph construction (icosahedron levels), interpolation (bilinear), and alignment of lat-lon coordinates to mesh nodes; reduces downstream model difficulty in representing rotation-invariant patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Resampling to spherical meshes and graph-based spherical CNN techniques are established in recent literature (e.g., Defferrard et al. 'Deepsphere'), increasingly common in climate ML.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low — preprocessing step aimed at data geometry correctness rather than mechanistic interpretation; improves ML model fidelity to physics by avoiding grid distortion artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Icosahedral spherical resampling and graph representation (PyGSP, bilinear interpolation)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Create an icosahedral backbone (level parameter g) to generate N = 10×2^{2g} + 2 points; assign lat/lon to mesh nodes, bilinearly interpolate ESM lat-lon fields onto the mesh, produce uniform-density 1D vectors (~10242 length for level-5) used as tokens/inputs for ML models; uses PyGSP library.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>data preprocessing / representation engineering</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable to global geophysical datasets to remove lat-lon distortion and enable models that assume uniform spatial sampling or spherical graph structure; especially important when modeling global modes and rotational symmetries.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No standalone numeric metric provided, but authors report improved representation of rotational symmetry and that this preprocessing was used for all ML models leading to successful emulation results.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Enables fair representation of global patterns and removes pole-area distortions that would degrade CNN-like assumptions; supported downstream model performance and comparability across architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Crucial for generalization of ML models on global climate data, enabling architectures (MLP, AFNO, graph CNNs) to better capture physically relevant global patterns and teleconnections.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Implied improvement over using raw lat-lon grids for ML models such as CNNs/U-Nets that assume 2D Euclidean locality; authors cite Defferrard et al. as prior work motivating spherical resampling.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Uniform-area sampling that respects spherical geometry and rotational symmetry, combined with graph-based processing libraries enabling downstream spherical convolutions or tokenization.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Correcting geometric sampling biases via icosahedral spherical resampling is a low-level but necessary step to allow ML architectures to learn global climate patterns and teleconnections accurately.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fourcastnet: Accelerating global high-resolution weather forecasting using adaptive fourier neural operators <em>(Rating: 2)</em></li>
                <li>Efficient token mixing for transformers via adaptive fourier neural operators <em>(Rating: 2)</em></li>
                <li>Deepsphere: a graph-based spherical cnn <em>(Rating: 2)</em></li>
                <li>The fluctuation-dissipation theorem <em>(Rating: 2)</em></li>
                <li>Fluctuation dissipation theorem in a general circulation model: FDT IN A GENERAL CIRCULATION MODEL <em>(Rating: 1)</em></li>
                <li>Deep learning and process understanding for data-driven earth system science <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2274",
    "paper_id": "paper-256627182",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "AiBEDO",
            "name_full": "AiBEDO (AI model guided by statistical physics principles)",
            "brief_description": "A hybrid AI framework that trains data-driven emulators of lagged climate response to cloud/radiation perturbations and combines them using a Fluctuation-Dissipation-Theorem-like time-integration to rapidly estimate regional and global climate responses to Marine Cloud Brightening (MCB) forcings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "climate modeling / climate intervention (Marine Cloud Brightening) scenario analysis",
            "problem_description": "Rapidly generate and explore climate intervention scenarios (spatio-temporally heterogeneous cloud-brightening forcings) that would be computationally intractable to evaluate with full Earth System Model (ESM) runs, by estimating time-lagged climate responses to imposed radiation perturbations.",
            "data_availability": "Abundant simulation data from ESMs: uses CESM2 Large Ensemble providing nearly 100,000 months of internal-variability samples and an asserted 8250 years-equivalent of internal fluctuations; additionally uses targeted CESM2 MCB perturbation simulations (fixed-SST and coupled) for evaluation. Data are labeled (inputs: radiation/cloud perturbation fields; outputs: climate response fields) and accessible to the authors; quality is high (ESM outputs) but availability to others may be constrained.",
            "data_structure": "High-dimensional spatio-temporal fields: monthly global gridded climate variables (resampled to an ~10k-point icosahedral sphere mesh), multichannel (7 input and 7 output climate variables), time-series with multi-month lags.",
            "problem_complexity": "Very high: global-scale, multiscale spatio-temporal dynamics, strong nonlinearity and teleconnections (e.g., ENSO), high dimensionality (~10242 spatial points × multi-channel), and multi-timescale lagged responses up to 48 months considered.",
            "domain_maturity": "Mature domain with established Earth System Models and statistical-physics theory (FDT), but scenario/decision-analysis for geoengineering interventions (MCB) remains active research with significant uncertainties.",
            "mechanistic_understanding_requirements": "High — scientific interpretability and causal/teleconnection understanding are required for assessing tipping-point risks and to validate that emulated responses reflect physically plausible mechanisms (AiBEDO uses FDT guidance and visualization tools to support interpretability).",
            "ai_methodology_name": "Hybrid physics-guided ML surrogate (AiBEDO): lagged emulators + FDT-like time-integration",
            "ai_methodology_description": "AiBEDO trains supervised, lag-specific emulators A_tau that map input radiation/cloud anomaly fields x(t) to output climate anomaly fields y(t+tau) for tau in {0..6, 12, 24, 36, 48} months; models are trained on internal variability samples from a large ensemble (subsample N=480 months per perturbation calculation). The set of lagged emulators are combined in an FDT-inspired summation/integration (replacing linear FDT operator with learned nonlinear A_tau operators) to compute a time-integrated mean response to a constant forcing. Preprocessing includes ensemble-mean removal (to isolate internal variability), spherical icosahedral resampling, and use of fixed-SST ERF fields to compute perturbations for evaluation.",
            "ai_methodology_category": "hybrid (physics-guided ML / supervised learning surrogate models)",
            "applicability": "Appropriate and applicable for fast scenario exploration where abundant simulation-derived internal-variability data exist; limitations include linear-FDT assumptions for integration (mitigated by using nonlinear learned lag operators), extrapolation/out-of-distribution risks for novel perturbation patterns, and degraded skill at high latitudes/over land.",
            "effectiveness_quantitative": "Correlation of lag-integrated S-MLP AiBEDO response vs CESM2 coupled runs: temperature (tas) r=0.68, precipitation (pr) r=0.51, surface pressure (ps) r=0.47; AiBEDO reproduces ESM results with comparable RMSE and spatial correlation while producing outputs ~10^3 times faster than ESM runs (claimed 'three orders of magnitude' speed-up). Training costs: S-MLP ~1 min/epoch (15 epochs), S-Unet ~1.5 min/epoch (30 epochs), S-AFNO up to ~12 min/epoch (50 epochs) on a single NVIDIA V100 16GB GPU.",
            "effectiveness_qualitative": "AiBEDO (with S-MLP) captures complex multi-timescale and remote teleconnected responses (e.g., La Niña-like Pacific signals, regional drying/wetting teleconnections) and outperforms simple persistence baselines across lags; performance is best in tropics and over oceans and weaker at higher latitudes/over land; regional perturbation responses vary by target region (best for SEP, worse and overestimated for NEP), indicating some mode-mixing and sensitivity to dominant variability modes (e.g., ENSO).",
            "impact_potential": "High potential for enabling rapid, interactive exploration of climate-intervention scenarios (MCB), facilitating tipping-point risk assessment and optimization of spatial patterns of forcing; significant time/cost savings vs full ESM runs make many more what-if scenarios tractable and support decision-oriented workflows and visualization-based scientist-in-the-loop analysis. Generalizable to other domains limited by expensive simulations where large ensembles of internal variability exist.",
            "comparison_to_alternatives": "Compared to full CESM2 ESM coupled simulations (ground truth) and to persistence baseline: AiBEDO yields similar spatial pattern fidelity (correlations above) while being ~1000× faster; internally compared three ML architectures (S-MLP, S-Unet, S-AFNO) and selected S-MLP for downstream use due to superior empirical performance.",
            "success_factors": "Large training dataset of internal variability from CESM2 LE, spherical resampling to reduce geometric bias, use of lagged supervised emulators combined by an FDT-like integration to capture multi-timescale response, and the use of a large-capacity fully connected S-MLP able to capture global long-range interactions; visualization and OOD checks aided interpretability and safe use.",
            "key_insight": "Combining supervised lag-specific emulators trained on rich internal-variability ensembles with an FDT-inspired time-integration yields a hybrid physics-ML surrogate that can rapidly and plausibly reproduce ESM-scale climate responses, provided sufficient ensemble data and architectures that capture global long-range interactions.",
            "uuid": "e2274.0",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "FDT",
            "name_full": "Fluctuation-Dissipation Theorem (FDT)",
            "brief_description": "A statistical-physics principle that relates a system's response to external forcings to its internal (unforced) fluctuations via a linear response operator constructed from covariances; used here as conceptual/operational guidance to convert learned lagged emulator outputs into time-integrated mean responses.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "statistical physics applied to climate response estimation",
            "problem_description": "Estimate the mean climate response to a constant external forcing by leveraging internal variability covariances (classical FDT) or replacing the linear operator with learned nonlinear lag operators to relax Gaussian/linearity assumptions.",
            "data_availability": "Uses internal variability samples from a large ESM ensemble to compute covariance-like statistics and to train lagged emulators; data are abundant within the CESM2 LE used.",
            "data_structure": "Time series of multivariate climate fields enabling covariance/lag-covariance computation; high-dimensional spatio-temporal data.",
            "problem_complexity": "Mathematically complex due to high-dimensional covariances, non-Gaussianity, nonlinearity, and structural instability of climate dynamics; classic FDT limited to linear/quasi-Gaussian responses.",
            "domain_maturity": "Well-established theoretical framework in statistical physics and climate dynamics (long literature), but practical application to full ESMs has known limitations requiring approximations and adaptations.",
            "mechanistic_understanding_requirements": "High — FDT-based inference is interpretable and aimed at mechanistic understanding but relies on assumptions (linearity, Gaussianity) that limit its direct applicability without adjustments.",
            "ai_methodology_name": "FDT-guided integration of learned lagged emulators (physics-guided ML operator replacement)",
            "ai_methodology_description": "Replace the linear FDT operator L with a series of learned nonlinear lag operators A_tau; compute time-integrated response via summation/integration over modelled lag responses applied to samples of internal variability (equation 2 in paper), thereby relaxing the Gaussian/linear assumptions of classic FDT.",
            "ai_methodology_category": "physics-guided ML / hybrid",
            "applicability": "Applicable when large datasets of internal variability are available to learn lagged mappings; helps extend FDT to capture nonlinear components but will not fully address strongly nonlinear or rare-event responses without targeted training data.",
            "effectiveness_quantitative": "Not given separately from AiBEDO; the hybrid FDT-like integration using learned A_tau contributed to the reported correlation scores (e.g., tas r=0.68) and enabled 6–48 month integrated responses.",
            "effectiveness_qualitative": "Provides a principled way to combine lagged learned responses into a time-integrated estimate while acknowledging classical FDT limitations; effective in capturing time-integrated teleconnected responses in the studied application.",
            "impact_potential": "Extends applicability of FDT-style response estimation to settings where linearity/Gaussian assumptions fail by leveraging ML to model nonlinear lagged responses, enabling faster scenario evaluation in climate and potentially other domains with ensemble variability data.",
            "comparison_to_alternatives": "Compared implicitly to classic linear FDT (cited) — the paper argues that replacing L with learned A_tau relaxes FDT assumptions and captures nonlinear responses better; no direct numerical comparison reported between classical covariance-based FDT operator and learned-A_tau integration within the paper.",
            "success_factors": "Availability of abundant internal-variability data to train lagged mappings, and careful design of lag range and sample sizes; using many randomized internal-fluctuation samples to reduce sampling noise in integration.",
            "key_insight": "Using ML to learn lag-resolved nonlinear response operators and integrating them in an FDT-like manner allows leveraging internal variability datasets to estimate forced responses beyond the linear/quasi-Gaussian scope of classical FDT.",
            "uuid": "e2274.1",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "S-MLP",
            "name_full": "Spherical Multilayer Perceptron (S-MLP)",
            "brief_description": "A fully connected deep neural network applied to spherical-resampled climate fields (icosahedral grid) that maps multichannel radiation/cloud anomaly inputs to multichannel climate response outputs for specific time lags.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "spatio-temporal climate emulation / surrogate modeling",
            "problem_description": "Learn pixel-wise regression from spherical climate input fields to delayed climate response fields for different monthly lags to form components of a time-integrated response operator.",
            "data_availability": "Trained on CESM2 Large Ensemble internal variability samples (nearly 100,000 months of data overall); per-lag models trained using the prepared dataset split (specific per-lag sample sizes not exhaustively enumerated beyond references to N=480-month samples for perturbation experiments).",
            "data_structure": "High-dimensional multichannel vectors (resampled icosahedral 1D arrays length 10242) representing monthly climate variables; supervised input-output pairs for each lag.",
            "problem_complexity": "High-dimensional regression with long-range spatial dependencies and nonlinear teleconnections; model needs to map multi-channel inputs to multi-channel outputs and capture nonlocal interactions.",
            "domain_maturity": "Application of MLPs to climate emulation is a pragmatic engineering choice; variant integrating spherical sampling is specialized for geodesy-aware inputs.",
            "mechanistic_understanding_requirements": "Medium-high — the model is used for scientific scenario analysis so interpretability and physical plausibility matter; S-MLP is a black-box but used within a physics-guided integration and diagnostic visualization to aid interpretability.",
            "ai_methodology_name": "Fully-connected deep multilayer perceptron on spherical mesh",
            "ai_methodology_description": "Architecture: four hidden fully-connected layers of 1024 nodes each, layer normalization, GeLU activation, AdamW optimizer (initial LR 2e-4 decayed exponentially), decoupled weight decay, ~108M trainable parameters, trained for 15 epochs with batch size 10 on V100 GPU. Each lag has a separate S-MLP trained to map inputs δx(t) to outputs y(t+τ).",
            "ai_methodology_category": "supervised learning (deep neural network surrogate)",
            "applicability": "Highly applicable for this task when large training data exist; leverages global connectivity to capture long-range teleconnections but is parameter-heavy and may overfit if data are limited.",
            "effectiveness_quantitative": "Empirically outperformed S-Unet and S-AFNO in downstream MCB scenario emulation; lag-integrated correlation vs CESM2: tas r=0.68, pr r=0.51, ps r=0.47. Training: ~1 minute per epoch, ~108M params.",
            "effectiveness_qualitative": "Performed best at capturing global response patterns and teleconnections, especially for multi-month lagged responses; advantage attributed to fully-connected structure and large parameter count enabling modelling of long-range interactions; risk of overfitting and heavier compute per inference than lighter models but still vastly faster than ESMs.",
            "impact_potential": "Enables accurate and fast emulation of complex climate responses for scenario analysis and what-if exploration when adequate training data exist; its global attention properties are key for capturing teleconnections.",
            "comparison_to_alternatives": "Compared directly to S-Unet and S-AFNO; S-MLP had comparable RMSE to S-AFNO for simultaneous mapping but substantially better qualitative and lagged performance, and better global pattern recovery than S-Unet (which lost long-range info during pooling).",
            "success_factors": "Very large parameterization enabling modeling of global correlations, sufficient training data from large ensemble, spherical resampling removing projection biases, and careful per-lag supervision.",
            "key_insight": "A high-capacity fully connected spherical MLP can better capture global, lagged climate response patterns than locality-biased architectures or transformer-based AFNOs when trained on a sufficiently large ensemble of internal variability.",
            "uuid": "e2274.2",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "S-Unet",
            "name_full": "Spherical U-Net (S-Unet)",
            "brief_description": "A spherical adaptation of the U-Net convolutional encoder-decoder architecture using Chebyshev graph convolutions on an icosahedral spherical mesh to predict climate response fields from input perturbation fields.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "spatio-temporal climate emulation / image-to-image prediction on the sphere",
            "problem_description": "Capture local spatial features of climate response fields and perform pixel-wise regression on spherical climate data for different lags.",
            "data_availability": "Trained on the same CESM2 LE datasets as other models; training used full spherical resampled inputs and outputs.",
            "data_structure": "Multichannel spherical graph signals (icosahedral mesh, 10242 nodes), monthly time steps.",
            "problem_complexity": "Requires capturing both local fine-scale spatial patterns and global teleconnections; convolutional pooling operations may reduce ability to model long-range interactions.",
            "domain_maturity": "U-Net-style architectures are well-established for image-to-image tasks and have been adapted to spherical domains (e.g., DeepSphere); their use in climate emulation is established but with known locality limitations.",
            "mechanistic_understanding_requirements": "Medium — U-Net is mainly a predictive model; interpretability depends on downstream analysis and visualization.",
            "ai_methodology_name": "Graph-based spherical U-Net with Chebyshev graph convolutions",
            "ai_methodology_description": "Architecture: encoder-decoder U-Net with six Chebyshev graph convolutional layers, spherical Chebyshev pooling, encoder/decoder kernel sizes [64,128,256,512,512,512], softmax output processing, AdamW optimizer (initial LR 5e-4 decayed), ~5.8M parameters, trained 30 epochs, ~1.5 min/epoch on V100 GPU.",
            "ai_methodology_category": "supervised learning (graph convolutional / encoder-decoder)",
            "applicability": "Applicable to capturing local spatial structure and fine features; less suitable for tasks dominated by long-range teleconnections unless augmented with global attention mechanisms.",
            "effectiveness_quantitative": "Lower empirical performance than S-MLP in lagged response tasks; exact RMSE/correlation values were lower than S-MLP though RMSEs were sometimes comparable for short lags.",
            "effectiveness_qualitative": "Captured some local aspects of responses (e.g., tropical Pacific features) but missed many key large-scale teleconnection patterns and performed worse in lagged settings, likely due to information loss from pooling and locality bias.",
            "impact_potential": "Useful for localized pattern emulation and where fine spatial features matter, but limited in estimating global teleconnected responses unless combined with global attention mechanisms.",
            "comparison_to_alternatives": "Directly compared to S-MLP and S-AFNO; underperformed both in capturing global lagged responses, with S-MLP significantly better overall.",
            "success_factors": "Graph-based spherical convolution respects sphere geometry and captures local spatial detail; however, the locality assumption and pooling reduced its ability to capture global teleconnections needed for global climate response emulation.",
            "key_insight": "Locality-focused spherical convolutional architectures can capture fine spatial features but may underperform for global teleconnected climate response tasks that require modeling long-range interactions.",
            "uuid": "e2274.3",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "S-AFNO",
            "name_full": "Spherical Adaptive Fourier Neural Operator (S-AFNO)",
            "brief_description": "A spherical adaptation of transformer/AFNO (Adaptive Fourier Neural Operator) architecture which tokenizes spherical inputs and applies AFNO layers for spatial mixing and MLPs for channel mixing to predict lagged climate responses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "spatio-temporal climate emulation / operator learning for PDE-like climate dynamics",
            "problem_description": "Leverage transformer-like token mixing and AFNO spectral mixing to model spatio-temporal mappings from input radiation perturbations to delayed climate responses on a spherical domain.",
            "data_availability": "Trained on the CESM2 LE internal variability dataset; authors note that transformer-based AFNOs typically require larger datasets than were available for the best performance.",
            "data_structure": "Spherically resampled 1D token sequence (10242 tokens) with multichannel embeddings, treated as a sequence for transformer/AFNO processing.",
            "problem_complexity": "High: modeling complex nonlocal interactions and high-dimensional spatio-temporal mappings; AFNO aims to efficiently approximate operator mappings but demands significant data and compute.",
            "domain_maturity": "AFNO and transformer-based operator learning are recent developments with growing application in weather/climate (e.g., FourcastNet) but are relatively new compared to convolutional and MLP approaches.",
            "mechanistic_understanding_requirements": "Medium — provides flexible operator learning but interpretability of transformer-based models can be limited; used here inside a physically-guided framework.",
            "ai_methodology_name": "Transformer + Adaptive Fourier Neural Operator adapted to spherical 1D token sequence (S-AFNO)",
            "ai_methodology_description": "Architecture: 4-layer transformer with AFNO spatial mixing per layer, token embedding size 384, GeLU activations, layer norm, MLP channel mixing; tokens formed from the spherical 1D resampled input rather than 2D patches; ~9M trainable parameters (paper reports variants with ~9M and training for up to 50 epochs), AdamW optimizer with initial LR 5e-4 decayed, training cost higher (~12 min/epoch reported for some runs).",
            "ai_methodology_category": "supervised learning (operator learning / transformer-based)",
            "applicability": "Promising for operator learning and spatial mixing in PDE-like systems; in this study underperformed S-MLP likely due to limited training data and higher computational cost, suggesting applicability increases with more data/compute.",
            "effectiveness_quantitative": "Achieved comparable RMSE to S-MLP for simultaneous mappings but worse qualitative and lagged performance; training: up to ~12 min/epoch, ~9M parameters.",
            "effectiveness_qualitative": "Captured some response aspects and performed better than S-Unet in places, but overall underperformed S-MLP, particularly in lagged responses; authors attribute this to insufficient data for transformer-style models and higher per-epoch compute.",
            "impact_potential": "High potential if supplied with larger datasets and compute — transformer/AFNO architectures can model complex operator mappings and may scale better with more data for climate operator learning tasks.",
            "comparison_to_alternatives": "Direct comparison showed S-AFNO &gt; S-Unet in some metrics but &lt; S-MLP overall for the available data regime; S-AFNO had comparable RMSE for simultaneous mapping but failed to match S-MLP's lagged pattern fidelity.",
            "success_factors": "AFNO/token-mixing strategy is theoretically well-suited for PDE/operator problems; success depends on ample training data and computational resources to fully exploit spectral mixing layers.",
            "key_insight": "Transformer/AFNO-based operator learners hold promise for climate emulation but require more data/compute to outperform large fully-connected models in capturing long-range, lagged climate responses in this data regime.",
            "uuid": "e2274.4",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "Spherical sampling (icosahedral resampling)",
            "name_full": "Geodesy-aware spherical sampling using level-5 icosahedral mesh",
            "brief_description": "A preprocessing technique converting latitude-longitude ESM gridded outputs to a uniform-density icosahedral spherical mesh (level-5 ~10242 points) via interpolation to remove projection biases and better represent rotational symmetry for ML models.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "data preprocessing for geospatial ML / climate model emulation",
            "problem_description": "Address the non-uniform area and rotational symmetry issues of lat-lon grids which bias ML models (e.g., CNNs) by resampling to a uniform spherical mesh to improve representation of global-scale patterns.",
            "data_availability": "Applied to available CESM2 lat-lon outputs prior to ML training; data are abundant and can be resampled as needed.",
            "data_structure": "Transforms 2D gridded rectangular (lat-lon) arrays into 1D sequences corresponding to spherical icosahedral mesh nodes; retains multichannel per-node values.",
            "problem_complexity": "Moderate preprocessing complexity: graph construction (icosahedron levels), interpolation (bilinear), and alignment of lat-lon coordinates to mesh nodes; reduces downstream model difficulty in representing rotation-invariant patterns.",
            "domain_maturity": "Resampling to spherical meshes and graph-based spherical CNN techniques are established in recent literature (e.g., Defferrard et al. 'Deepsphere'), increasingly common in climate ML.",
            "mechanistic_understanding_requirements": "Low — preprocessing step aimed at data geometry correctness rather than mechanistic interpretation; improves ML model fidelity to physics by avoiding grid distortion artifacts.",
            "ai_methodology_name": "Icosahedral spherical resampling and graph representation (PyGSP, bilinear interpolation)",
            "ai_methodology_description": "Create an icosahedral backbone (level parameter g) to generate N = 10×2^{2g} + 2 points; assign lat/lon to mesh nodes, bilinearly interpolate ESM lat-lon fields onto the mesh, produce uniform-density 1D vectors (~10242 length for level-5) used as tokens/inputs for ML models; uses PyGSP library.",
            "ai_methodology_category": "data preprocessing / representation engineering",
            "applicability": "Highly applicable to global geophysical datasets to remove lat-lon distortion and enable models that assume uniform spatial sampling or spherical graph structure; especially important when modeling global modes and rotational symmetries.",
            "effectiveness_quantitative": "No standalone numeric metric provided, but authors report improved representation of rotational symmetry and that this preprocessing was used for all ML models leading to successful emulation results.",
            "effectiveness_qualitative": "Enables fair representation of global patterns and removes pole-area distortions that would degrade CNN-like assumptions; supported downstream model performance and comparability across architectures.",
            "impact_potential": "Crucial for generalization of ML models on global climate data, enabling architectures (MLP, AFNO, graph CNNs) to better capture physically relevant global patterns and teleconnections.",
            "comparison_to_alternatives": "Implied improvement over using raw lat-lon grids for ML models such as CNNs/U-Nets that assume 2D Euclidean locality; authors cite Defferrard et al. as prior work motivating spherical resampling.",
            "success_factors": "Uniform-area sampling that respects spherical geometry and rotational symmetry, combined with graph-based processing libraries enabling downstream spherical convolutions or tokenization.",
            "key_insight": "Correcting geometric sampling biases via icosahedral spherical resampling is a low-level but necessary step to allow ML architectures to learn global climate patterns and teleconnections accurately.",
            "uuid": "e2274.5",
            "source_info": {
                "paper_title": "Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles",
                "publication_date_yy_mm": "2023-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fourcastnet: Accelerating global high-resolution weather forecasting using adaptive fourier neural operators",
            "rating": 2,
            "sanitized_title": "fourcastnet_accelerating_global_highresolution_weather_forecasting_using_adaptive_fourier_neural_operators"
        },
        {
            "paper_title": "Efficient token mixing for transformers via adaptive fourier neural operators",
            "rating": 2,
            "sanitized_title": "efficient_token_mixing_for_transformers_via_adaptive_fourier_neural_operators"
        },
        {
            "paper_title": "Deepsphere: a graph-based spherical cnn",
            "rating": 2,
            "sanitized_title": "deepsphere_a_graphbased_spherical_cnn"
        },
        {
            "paper_title": "The fluctuation-dissipation theorem",
            "rating": 2,
            "sanitized_title": "the_fluctuationdissipation_theorem"
        },
        {
            "paper_title": "Fluctuation dissipation theorem in a general circulation model: FDT IN A GENERAL CIRCULATION MODEL",
            "rating": 1,
            "sanitized_title": "fluctuation_dissipation_theorem_in_a_general_circulation_model_fdt_in_a_general_circulation_model"
        },
        {
            "paper_title": "Deep learning and process understanding for data-driven earth system science",
            "rating": 2,
            "sanitized_title": "deep_learning_and_process_understanding_for_datadriven_earth_system_science"
        }
    ],
    "cost": 0.018455,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles
7 Feb 2023</p>
<p>Soo Kyung Kim 
Kalai Ramea 
Salva R Ühling Cachay 
University of California
San Diego 4 Excarta</p>
<p>Haruki Hirasawa 
University of Victoria</p>
<p>Subhashis Hazarika 
Dipti Hingmire 
University of Victoria</p>
<p>Peetak Mitra 
Philip J Rasch 
University of Washington</p>
<p>Hansi A Singh 
University of Victoria</p>
<p>Palo Alto Research Center 
Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles
7 Feb 202397FB971AB44250FF6F539B0BB37DE5EE10.5281/zenodo.7597027arXiv:2302.03258v1[cs.LG]Fluctuation-Dissipation TheoremPhysics guided MLClimate ChangeClimate Intervention modeling
The availability of training data remains a significant obstacle for the implementation of machine learning in scientific applications.In particular, estimating how a system might respond to external forcings or perturbations requires specialized labeled data or targeted simulations, which may be computationally intensive to generate at scale.In this study, we propose a novel solution to this challenge by utilizing a principle from statistical physics known as the Fluctuation-Dissipation Theorem (FDT) to discover knowledge using an AI model that can rapidly produce scenarios for different external forcings.By leveraging FDT, we are able to extract information encoded in a large dataset produced by Earth System Models, which includes 8250 years of internal climate fluctuations, to estimate the climate system's response to forcings.Our model, AiBEDO, is capable of capturing the complex, multi-timescale effects of radiation perturbations on global and regional surface climate, allowing for a substantial acceleration of the exploration of the impacts of spatially-heterogenous climate forcers.To demonstrate the utility of AiBEDO, we use the example of a climate intervention technique called Marine Cloud Brightening, with the ultimate goal of optimizing the spatial pattern of cloud brightening to achieve regional climate targets and prevent known climate tipping points.While we showcase the effectiveness of our approach in the context of climate science, it is generally applicable to other scientific disciplines that are limited by the extensive computational demands of domain simulation models.</p>
<p>INTRODUCTION</p>
<p>Machine learning has greatly benefited a variety of scientific disciplines through its ability to extract valuable insights from large datasets.Notable examples include the use of deep learning for numerical weather prediction Bochenek and Ustrnul (2022); Ren et al. (2021); Markovics and Mayer (2022), medical imaging diagnosis Shen et al. (2017); Razzak et al. (2018); Erickson et al. (2017); Chan et al. (2020); Litjens et al. (2017), classification of astronomical images Carrasco-Davis et al. (2019); Hansen and Takahashi (1984), and drug discovery with specific properties Chen et al. (2018); Stephenson et al. (2019); Dara et al. (2022); Patel et al. (2020).These applications involve direct application of machine learning algorithms on large datasets in order to achieve a specific goal.Additionally, we have seen a rise in the use of surrogate models, such as data-driven models trained on simulation data, which can instantaneously reproduce output for a given set of inputs, thereby significantly increasing process efficiency Bárkányi et al. (2021).Despite these achievements, these use cases still represent only a small subset of problems studied by scientists.</p>
<p>A commonly researched topic in systems analysis, science, and engineering is how a system responds to external forcing.This can encompass a wide range of questions, such as how a bridge or aircraft responds to wind Matsumoto et al. (1995); Siringoringo and Fujino (2012), how a certain material responds to electrical conductivity or magnetic forces Reyne et al. (1987); Zukoski (1993), or how a financial market responds to geopolitical instability Hoque and Zaidi (2020); Sohag et al. (2022).As these inquiries often fall outside of the training data distributions, they are typically addressed through targeted simulation scenario runs.However, the complexity of the domain simulation model can significantly impact the computational time required for a single simulation run, ranging from a few hours to several • Our AI framework maps the relationship between cloud perturbations and the climate response, including largescale circulation and regional climate patterns.To the best of our knowledge, this is a pioneering application of AI for scenario analysis of global-scale marine cloud brightening climate interventions.</p>
<p>• We have extensively evaluated the performance of AiBEDO against targeted simulation runs of ESMs and show that our model can reproduce the results with high fidelity, but three orders of magnitude faster than ESMs.</p>
<p>• We have developed an interactive post-hoc analysis platform to examine the results and facilitate rapid prototyping of MCB what-if scenarios for downstream decision-making.</p>
<p>The remainder of the paper is organized as follows.Section 2 introduces the problem statement and details of how FDT is applied in AiBEDO.In Section 3, we see the details of different components of the MCB climate intervention framework.In Section 4, we evaluate the performance of the data-driven emulation component of AiBEDO against ESM runs, and we demonstrate the utility of AiBEDO in an FDT-like approach to perform MCB intervention scenarios.Finally, in Section 5, we discuss our results, limitations, and future directions.</p>
<p>PROBLEM STATEMENT</p>
<p>The goal is to create a framework that one can use to rapidly generate MCB intervention impacts for a given spatial and temporal extent of cloud perturbations (external forcing).The problem will be addressed in two phases.In the first phase, we develop an AI emulator to map relationships between a set of designated input and output variables.This will involve the creation of a series of mappings that are performed at different time-lagged intervals.In the second phase, we sum them using an FDT operator to obtain a time-integrated outcome, which estimates the regional impact of the external forcing.</p>
<p>Phase 1: AI Emulator of simultaneous and time-lagged mappings</p>
<p>Let us denote an input field of cloud and clearsky radiation anomalies at time t as x(t) and denote the corresponding output field of surface climate anomalies after a time delay of τ as y(t + τ).Our task is then to develop a model A τ to predict y(t + τ) from x(t), i.e, y(t + τ) = A τ ( x(t)).Formally, the input tensor δ x(t) ∈ R d×c in , and output tensor y(t + τ) ∈ R d×c out consist of 1-D climate data of size d with corresponding channels of size c in and c out .Input channels, c in , are composed of 7 climate variables empirically selected to achieve best performance of the model A τ , and output channels, c out , are composed of 7 climate variables.The list of climate variables used for input and output is shown in Table 1.</p>
<p>Phase 2: Time-integrated output using Fluctuation-Dissipation theorem</p>
<p>One common method of applying FDT involves assuming the metrics of interest have Gaussian statistics and constructing an FDT operator L using the covariance matrix C(t) Cionni et al. (2004); Liu et al. (2018).The climate mean response δ y to a constant forcing δ f is then computed as
δ y = L −1 δ f = ∞ 0 C(τ)C(0) −1 dτ δ f (1)
Noting that FDT is limited to the linear component of the climate response, we use an AI model with the intention of capturing non-linear components of the response and loosening some of the conditions required by classical FDT (namely that the probability density function of the relevant climate statistics must be Gaussian or quasi-Gaussian Cionni et al. (2004); Majda et al. (2010)).Thus, replacing the linear FDT operator L with a set of AiBEDO operators, A τ , at a series of time-lags (τ), we construct an estimate of the response as
δ y(t) = T max ∑ τ=0 1 N N ∑ i=0 A τ ( x i + δ f (t − τ)) − A τ ( x i ) (2)
where x i are randomly sampled internal fluctuations of the input variables, N is the number of samples of internal fluctuations used, and T max is the upper lag limit set at the point when the response to a perturbation approximately converges to noise.For testing purposes we use the first 6 months and for the full lag integration we choose 48 months.</p>
<p>MCB CLIMATE INTERVENTION USING AIBEDO: DATA AND METHODS</p>
<p>The   2).Specifically, we use the 50-member ensemble of historical simulations with smoothed biomass burning emission between 1997 and 2014 at nominal 1 degree spatial resolution and at a monthly temporal resolution.Each simulation the large ensemble is identical to one others except in their initial conditions, meaning they differ only in the chaotic fluctuations internal to the climate system.Thus, this provides one of the largest data sets of simulations from a single CMIP6-generation ESM from which we can obtain internal variability to train and test our model on, as it provides a total of nearly 100,000 months of data.Additionally, we use a set of novel CESM2 simulations which estimate the climate response to MCB-like perturbations (described in Appendix 7.2.These are used to evaluate AiBEDO's ability to estimate the climate response to a forcing.</p>
<p>Spherical Sampling</p>
<p>Earth System Model data is typically stored on 2D latitude-longitude gridded meshes, which have non-uniform area over the globe with smaller areas at the poles and larger areas at the equator, complicating their use in ML.Specifically, the rotational symmetry of the Earth is difficult to represent using two-dimensional meshes, resulting in inaccurate representations of significant climate patterns in ML models that assume a two-dimensional format of data, such as Convolutional Neural Networks (CNNs) or U-Nets.To address this limitation, we have adopted a geodesy-aware spherical sampling technique that converts the 2D rectangular grid to a 1D spherical icosahedral mesh, following the strategy suggested in the recent work Defferrard et al. (2020).The icosahedral grids consist of equiangular triangles that form a convex polygon such that the triangles are formed by equally spaced grid points on a sphere.The number of grid points is defined by their level, with the level-0 grid being an icosahedron, and the number of grid points increasing as demonstrated in Equation 3:
N = 10 × 2 2g + 2 (3)
where g refers to the desired grid level, and N represents the number of points in the grid that form the icosahedron.This re-sampled icosahedral mesh provides data with uniform density across the sphere.In this study, we utilize a level-5 icosahedral grid, equivalent to a 1-D vector of size 10242 with a resolution of approximately 220 km.We employ the PyGSP library in Python to perform the grid transformation.This library is widely utilized for various graph operations in signal processing and social network analysis, such as the Erdős-Rényi network Rozemberczki et al. (2020).To convert to spherical grid, we first develop of a backbone structure for the icosahedral coordinate system, where the properties of the spherical coordinates (levels), are specified as inputs.At this stage, the coordinates are represented as graph networks.Next, latitude and longitude values are assigned to the graph network points (x, y) such that they can be expressed in a geographical coordinate system.Since the points in the icosahedral backbone do not exactly align with the positions in the 2D gridded Earth System Model data, we use bilinear interpolation to interpolate the ESM data with the icosahedral backbone, obtaining the final spherically-sampled data.Figure 2 shows a schematic of grid transformation in the icosahedral spherical sampling process.</p>
<p>Data-preprocessing</p>
<p>Prior to use by AiBEDO, the CESM2 LE input and output data are preprocessed by subtracting the ensemble mean for each month and grid point in the data set.This removes the seasonal cycle of the variables, such that we consider the month-to-month deviations from the climatology, and removes the secular trend effects due to external forcings, such that we only consider internal climate variability.As we are using a LE ensemble mean, we are able to filter out the forced signal across all time scales, including short-term fluctuations such as anthropogenic aerosol forcing and volcanic eruptions Rodgers et al. (2021).</p>
<p>Data-driven Models of AiBEDO</p>
<p>We develop a function A τ to map global perturbation of cloud at time t (input: δ f t ∈ R d×c in ) to corresponding climate response with time-lag l (output δ y t+l ∈ R d×c out ).To tackle this, we formulate the problem as a pixel-wise regression problem, learning a mapping from input to output, A l : R d×c in → R d×c out .We develop separate models for different time-lags from 0 (simultaneous) to 6 months at monthly intervals, and estimate climate response δ y using a truncated version of equation 2 with τ max = 6 months.</p>
<p>We utilize three machine learning methods to model A τ which are proven to be effective for spatio-temporal modeling of ESM data: ( 1 2021) and (3) Spherical Adaptive Fourier Neural Operator (S-AFNO) Kurth et al. (2022); Li et al. (2020).Then, we use S-MLP for our MCB application, since S-MLP performs best out of all three methods.We describe the three ML methods we employed further below.A schematic of the three methods is shown in Figure 3.All machine learning models in our work are trained on a single NVIDIA Tesla V100-SXM2 GPU using 16GB VRAM.</p>
<dl>
<dt>Spherical Multilayer Perceptron (S-MLP)</dt>
<dd>
<p>MLP is a representative structure of Deep Neural Networks (DNNs) consisting of input and output layer inter-connected with multiple hidden layers.Each node in a layer is fully connected with all nodes in previous layer.The connection between two nodes represents a weighted value that passes through the connection signal.Each node contains a non-linear activation function to represent non-linearity of correlation between two connected nodes.The operation between consecutive layers is defined as multiplication between nodes in previous layer and corresponding weight parameters, and applying activation function.</p>
</dd>
</dl>
<p>We combine our model architecture with spherical sampling described earlier to create Spherical Multilayer Perceptron (S-MLP).The S-MLP architecture has four hidden layers, each containing 1024 nodes.Layer normalization Ba et al. (2016) and Gaussian Error Linear Units (Gelu) activation Hendrycks and Gimpel (2016) were employed in each layer.The decoupled weight decay regularization optimization method, AdamW Loshchilov and Hutter (2017) was utilized to train our model in an iterative manner.The learning rate was initially set to 2 × 10 −4 and exponentially decayed at a rate of 1 × 10 −6 per epoch.We train model for 15 epochs with a batch size of 10.Our S-MLP models have ∼ 108M trainable parameters, and it takes around 1 minute per single epoch for training on the historical CESM2-LE dataset.</p>
<dl>
<dt>Spherical U-Net (S-Unet)</dt>
<dd>
<p>U-Net is a symmetric U-shaped convolutional neural network for image-to-image prediction, and consists of a encoder-decoder scheme structure.The encoder extracts visual features from the input by reducing dimensions in every layer, and the decoder increases the dimensions and predict output with same size as input.Encoder and decoder are connected with long skip-connections allowing high-resolution features from the encoder are combined with the input of the decoder for better localizing visual feature in prediction.We chose to explore U-net architecture as they are generally known to capture fine spatial features in images, and are proven to do well in biomedical image segmentation Yin et al.  2022), followed by spherical Chebyshev pooling, which performs spherical convolution on 1-D data considering the icosahedral geometry of the graph structure.The kernel size was set to [64,128,256,512,512,512] for the encoder and decoder, respectively.The output of the model was processed through a softmax activation.The S-Unet was trained using the AdamW optimization method Loshchilov and Hutter (2017), with a learning rate of 5 × 10 −4 that was exponentially decayed at a rate of 1 × 10 −6 per epoch.The model was trained for 30 epochs, and had approximately 5.8 million trainable parameters.The training of the S-Unet model took approximately 1.5 minutes per epoch in our computing environment.</p>
</dd>
</dl>
<p>Spherical Adaptive Fourier Neural Operator (S-AFNO):</p>
<p>Motivated by the recent successes of transformer-based architectures in climate domain, we adopt the FourcastNetKurth et al. ( 2022) employing Adaptive Fourier Neural Operator (AFNO) Guibas et al. (2021) to tackle our problem.Fourcast-Net is a weather forecasting model using the multi-layer transformer architecture employing AFNO inside.The input is first divided into multiple patches which are embedded in a higher dimensional space with larger number of latent 6/20 channels and corresponding positional embeddings.Then, positional embeddings are formulated as the sequence of tokens.Tokens are spatially mixed using AFNO followed by subsequent mixing of latent channels accordingly.Mixed embeddings are passed by MLP to learn higher level feature.We repeat this process for each transformer layer.After this process, a linear decoder reconstruct the patches from final embedding.</p>
<p>Instead of the token projection technique employed in ForecastNet, which involves the composition of tokens from a two-dimensional grid patch of climatic data, we project all elements of a spherically resampled one-dimensional input as tokens.These tokens, together with a positional encoding, are then inputted into a sequence of AFNO layers.Each layer, upon receiving an input tensor of tokens, performs spatial mixing followed by channel mixing.We name our model Spherical Adaptive Fourier Neural Operator (S-AFNO).For S-AFNO model, we used 4-layered transformer Vaswani et al. (2017), and set the size of embedding of token as 384.We use GeLu activationHendrycks and Gimpel (2016) for the output of MLP layers while applying layer normalization techniques Ba et al. (2016)</p>
<p>AiBEDO Marine Cloud Brightening Experiments</p>
<p>To evaluate how well AiBEDO estimates climate responses, we compare the impact of MCB-like forcing in the lag-integrated AiBEDO response to fully coupled CESM2 simulations Hirasawa et al. (2022).These simulations are summarized in Table 2 in the Appendix along with a description of how the MCB forcing perturbations are computed from CESM2 for AiBEDO.Our experiments focus on perturbing three main regions (shown in Figure 8) for MCB experiments: NEP (North East Pacific -0 to 30N and 150W to 110W), SEP (South East Pacific -30S to 0 and 110W to 70W) and SEA (South East Atlantic -30S to 0 and 15W to 25E) regions.Following equation 2, for each lag we calculate the AiBEDO response by taking the mean of the difference between the AiBEDO output for an N = 480-month sample of CESM2 internal variability perturbed with the MCB radiation anomalies Aswathy et al. (2015) minus the AiBEDO output for that same 480-month sample without perturbations.We use this protocol rather than simply running AiBEDO with the radiation anomaly fields, because the near-zero anomalies outside the perturbation regions cause artifacts in the AiBEDO output, as such a field is entirely unlike any fields the model is trained on.</p>
<p>RESULTS AND DISCUSSION</p>
<p>We evaluate model functionality through two phases of AiBEDO development.The first phase involves developing an AI emulator of simultaneous and time-lagged mappings.As described in the previous sections, we developed three AI models (S-MLP, S-UNet, S-AFNO) and compared their performance in how well they could emulate the mappings.The second phase encompasses an analysis of the results from MCB experiments conducted in selected regions on CESM2, along with the time-integrated outputs generated by AiBEDO through the application of an FDT-like function.We also compared the time-integrated results across the three AI models to analyze the performance of different model architectures.</p>
<p>Comparison between AiBEDO ML algorithms (Phase I)</p>
<p>Each machine learning model was trained individually with different monthly time-lags ranging from 0 to 6 months.The quantitative comparison of emulation performance of AiBEDO using different ML models are reported in Figure 4. We evaluate Root Mean Squared Error (RMSE) and spatial correlation score of prediction with ground truth of our models based on the persistence scores of the ground truth data.Persistence at a time-lag t is essentially the temporal deviation of the ground truth outputs at t months from the zero time-lag instances.The persistence curve at different time-lags is overlaid with performance curve from our model in Figure 4, which lets us evaluate the ML models performance over lagged duration.As shown in Figure 4, we can observe that as the time-lag increases, the predictive accuracy of the model decreases as anticipated.Notably, the model consistently outperforms persistence across all time-lags, implying that AiBEDO has learned the temporal dynamics patterns beyond the simple memory of 0-month temperature anomalies.</p>
<p>Figures 5 and 6 demonstrate the spatial correlation scores of the emulation of each ML model (S-MLP, S-Unet and S-AFNO) for simultaneous and one-month time-lagged model.The corresponding qualitative comparison of sample timesteps is shown in Figures 10 and 11 in the Appendix.Despite S-AFNO achieving comparable score to S-MLP in terms of RMSE and spatial correlation for simultaneous AiBEDO results, as demonstrated in Figures 5 and 10, S-MLP was found to outperform the other models in capturing global response patterns in all three variables.The quality deviation of output between the models becomes evident in the time-lagged response even after a single month (Figure 6), showing higher performance of S-MLP.The qualitative results with a time-lag demonstrate that S-MLP significantly outperforms the other two models, S-AFNO and S-Unet, even though RMSE scores are comparable across the models.</p>
<p>The superior performance of S-MLP model can be attributed to its significantly larger number of trainable parameters and its fully connected network structure.This allows the model to consider the correlation of each element in the input, thereby enhancing its ability to regress the results.The fully connected network structure enables the output to be regressed by multiplying the different weights of all input elements, which enhances its ability to capture long-range interactions between locations, potentially driven by the "butterfly effect".The subpar performance of the S-Unet can be attributed to the loss of important information regarding global climate patterns, particularly related to long-range interactions, during the spherical convolution and pooling processes.Consequently, machine learning models based on the assumption of spatial locality, such as the S-Unet, underperform models that allow for global attention.While S-AFNO performed better than S-Unet, the model still underperforms compared to S-MLP.The amount of training data used in this study may not be sufficient for training a transformer-based S-AFNO model, which typically requires a large amount of data.Moreover, the time taken to complete one epoch in S-AFNO was already significantly higher than time per epoch for S-MLP.Adding more parameters and/or data can only increase the computational requirement for S-AFNO.As a result, S-MLP was utilized in the subsequent experiments described in this paper.</p>
<p>Response to MCB perturbations (Phase II)</p>
<p>Here, we compare the impact of MCB-like forcing in three regions in the subtropics on the climate in CESM2 and lag-integrated AiBEDO.Figure 8 shows the spatial maps of the surface temperature anomalies for the response to each of the three regions (NEP, SEP, and SEA).The goal of comparing the response of the CESM2 model and the AiBEDO model to MCB-like perturbations is to determine if AiBEDO can accurately estimate the forced climate response.Figure 7 shows that the S-MLP model within AiBEDO has better performance compared to the other two models, reproducing the climate response pattern with a correlation score of 0.68 for temperature (tas), 0.51 for precipitation (pr), and 0.47 for pressure (ps).The correlation score improves with increased time-integration.However, there are differences in the magnitude of the responses, which is likely due to missing lags in the integration.</p>
<p>The S-MLP model successfully estimates remote teleconnected responses to MCB forcing, such as a La Niña-like temperature signal in the Pacific.It also captures drying in northeast Brazil, central Africa, and southern North America and Europe, and wetting in the Sahel, south and southeast Asia, Australia, and central America.The S-Unet and S-AFNO models capture some aspects of the responses, such as tropical Pacific drying and high pressure anomalies in the Pacific mid-latitudes.However, they miss many key aspects of the response patterns.These responses can be used to assess the risk of regional tipping points, such as Amazon dieback and Sahel region in North Africa greening McKay et al. (2022) or the reduction in the risk of coral dieoff due to cooling in the tropical oceans.However, due to the lower performance of AiBEDO at high latitudes, it may be challenging to evaluate key cryospheric tipping points such as permafrost loss in Eurasia and North America.The impact of MCB forcing on individual perturbation regions is also evaluated and compared to CESM2 simulations with similar regional forcing.Figure 8 shows the comparison of perturbation effects on temperature between CESM2 and S-MLP model of AiBEDO.In general, AiBEDO's performance is weaker when considering these regional perturbations compared to when all three regions are perturbed together.AiBEDO performs best for SEP, followed by SEA and NEP.The NEP response is overestimated substantially, which may indicate the model learns too heavily from the El Niño-Southern Oscillation climate pattern (variations in ocean temperatures in the Pacific Ocean) at the expense of over modes of variability.However, AiBEDO correctly identifies the climate responses to the different forcing regions in several key regions.For example, it correctly identifies that SEP forcing causes La Niña-like cooling (below-average sea surface temperatures in the central and eastern tropical Pacific Ocean) and that SEA forcing causes tropical Pacific warming and Amazon drying.Moreover, AiBEDO performs better in the tropics and over oceans compared to higher latitudes and over land.This aligns with the regions where AiBEDO has the highest emulation skill, indicating that the model's ability to correctly estimate climate responses to MCB forcing is closely linked to its ability to emulate internal variability.</p>
<p>Visualization Platform</p>
<p>We developed a front-end interactive visualization platform to facilitate downstream tasks and exploratory analyses using the suite of trained hybrid AI models.It allows climate scientists to interact directly with the trained models (described above) and recreate different MCB experiment scenarios.The multi-panel design lets the experts load different Earth System Model data, interactively run the trained hybrid model in the backend and visualize the model predictions and inputs using popular geospatial projection schemes.Figure 9 shows an overview of our visualization platform.The leftmost panel in Figure 9 is the general control panel which permits a subject matter expert to interact with the models and data source, as well as tune several experiment parameter for analysis.Figure 9(C 1 ) highlights the controls to specify the specific timestamp from the data and the general visualization projection scheme.Figure 9(C 2 ) corresponds to the hybrid model controls, which lets us run the trained AI models with specified data directly from this interface, as well as clear any previous model prediction results from memory.Figure 9(C 3 ) provides the main MCB experiment scenario controls.It helps to set the important parameters like which geospatial regions to apply MCB over, which input variable set to perturb and by what extend and running the perturbed data with the AI models.Figure 9(V 1 ) and (V 2 ) highlight the input and output visualization panels respectively.Using the set geospatial projection scheme (as set in C 1 ) the different input and output variables are visualized here.In addition, the output panel has the options to show the original AI model prediction results, results after MCB, and the net difference in results as well.This helps to qualitatively analyze the output predictions and their likely patterns.Since the perturbed input fields prepared as part of the MCB experiments may lie outside the scope of the input distribution with which the hybrid models were trained over, it is important to check the out-of-distribution cases.To address this, in Figure 9(V 3 ) we visualize the low-dimensional projection of the MCB perturbed fields over the input distribution to show how far off the perturbed fields are from the original data.Another important aspect of our analysis is to understand the impact of MCB on key regional tipping points.Figure 9(V 4 ) panel shows the seven regional climate tipping points that we are tracking with each MCB experiment scenarios.A red color on this sites indicates that the current MCB setting might trigger factors that are directly associated with the risk of tipping points in these sites.</p>
<p>SUMMARY AND FUTURE WORK</p>
<p>In this study, we introduce a novel methodology for utilizing the Fluctuation-Dissipation Theorem, a principle derived from statistical mechanics, in the context of knowledge discovery using AI model to predict the behavior of a system under external forcing.This approach is particularly useful in scenario analysis in scientific domains where traditional 12/20 models are computationally infeasible.We demonstrate the efficacy of this method through its application in Marine Cloud Brightening (MCB) climate intervention analysis, where the number of scenarios required is intractable using traditional computational models.This constitutes a challenging problem in climate science, where Earth System Models are employed to simulate changes in climate and require weeks to complete a single run, and assessing additional scenarios necessitates additional runs.Our method of training lagged emulation models of internal variability (noise) and producing time-integrated outputs using an FDT-like framework presents a viable alternative for fast prototyping of such scenarios in several scientific domains.In addition to the central contribution of our work, we also present various components of AiBEDO that is specific to climate intervention: preprocessing techniques for large climate datasets, a comparison of machine learning methods for time-integrated approach, and a user-friendly visualization interface that provides explainable insights that helps with model investigation and tipping point analysis, and allows for quick what-if scenario analysis.</p>
<p>Our next steps include expanding the MCB climate intervention framework into developing optimal pathways for selected tipping point scenarios.Figure 13 in Appendix shows some of the known tipping points in the climate system and the associated mitigating strategies that may be used to avoid them.An inverse search of AiBEDO output may be useful for creating MCB perturbations to achieve such mitigation measures.For example, to avoid the catastrophic retreat of the West Antarctic ice sheet, potential MCB perturbation sites could push the jet circulation equatorward.To achieve this, the user might query the model to create a forcing scheme to avoid selected tipping points, and the model would choose optimal spatiotemporal perturbation MCB sites that could lead to this outcome.We could also add additional constraints not to tip other climate tipping points in this process.This is a powerful tool that could help scientists and policymakers understand the climate system's teleconnections that could trigger unintended consequences and timely strategies to avoid catastrophic outcomes due to changing climate.</p>
<p>FUNDING AND ACKNOWLEDGEMENTS</p>
<p>The development of AiBEDO is funded under the DARPA AI-assisted Climate Tipping-point Modeling (ACTM) program under award DARPA-PA-21-04-02.The authors are grateful for the donation of computing credits and storage from AWS, which enabled the implementation of MCB scenarios utilizing CESM2 Earth Systems Model and the training of the AiBEDO model on the cloud.</p>
<p>13/20</p>
<p>Emulation of Climate Noise</p>
<p>AiBEDO emulation performance is evaluated by taking the difference AiBEDO outputs at a given lag to the corresponding preprocessed CESM2 output field at the same lag.Example emulation outputs for a single input time step are shown for the lag-0 (Figure 10) and lag-1 (Figure 11).2).MCB forcing is imposed by prescribing in-cloud liquid cloud droplet number concentrations (similar to (Rasch et al., 2009), (Jones et al., 2009) and (Stjern et al., 2018a)) to 600cm −3 in three selected regions in the northeast Pacific, southeast Pacific, and southeast Atlantic.We apply the MCB perturbations in the three regions separately and all together from 2015 to 2065 against a background Shared Socioeconomic Pathway 2 -4.5Wm −2 (SSP2-4.5)scenario.The CESM2 MCB climate response is thus computed as the difference between SSP2-4.5 plus MCB simulations minus baseline SSP2-4.5 (Shared Socioeconomic Pathway 2 -4.5Wm −2 forcing) simulations.</p>
<p>To compute the radiation perturbations for AiBEDO MCB responses, we use CESM2 "fixed-sea surface temperature" (fixed SST) simulations.In these simulations, a MCB forcing identical to that used in the coupled simulations is imposed in the model with SSTs held to climatological values.This allows the computation of the radiation anomalies in the absence of any radiative feedbacks due to surface temperature change, which is referred to as the effective radiative forcing (ERF).Thus, we can compare CESM2 and AiBEDO responses for the same perturbation fields.AiBEDO perturbation fields are thus calculated as the annual mean anomalies in cres, crel, cresSurf, crelSurf, netTOAcs, and netSurfcs anomaly fields (Figure 12) between the Y2000 MCB Perturbed minus Y2000 Control simulations.</p>
<p>MCB climate intervention framework consists of three main components: (1) datasets for training and verification, which includes a large ensemble of Earth System Model output data; (2) AiBEDO, which serves as the framework's central component is an AI model incorporating data-driven models; (3) an interactive visualization interface featuring dual functionality allowing users to execute rapid "what-if" scenarios and enabling modelers to inspect and provide explanations for the associated outcomes.A schematic of the AiBEDO framework is shown in Figure 1.</p>
<p>Figure 1 .
1
Figure 1.Schematic view of MCB Climate Intervention framework</p>
<p>Figure 2 .
2
Figure 2. Spherical sampling of ESM data following icosahedral grid.</p>
<p>) Spherical Multilayer Perceptron (S-MLP) Park et al. (2019); Wang et al. (2014), (2) Spherical U-Net (S-Unet) Mabaso et al. (2006); Ge et al. (2022); Dunham et al. (2022); Trebing et al. (</p>
<p>Figure 3 .
3
Figure 3. Schematic view of three machine learning methods utilized for AiBEDO model, A l : (a) Multilayer Perceptrons (MLPs), (b) U-Net, (c) Adaptive Fourier Neural Operator (AFNO).</p>
<p>(2022), and satellite image analysis McGlinchy et al. (2019).We built our S-Unet Autoencoder architecture based on the DeepSphere model proposed by Defferrard et al. (2020)Defferrard et al. (2020).The decoder and encoder of the S-Unet were comprised of six Chebyshev Graph Convolutional LayersBoyaci et al. (</p>
<p>to stabilize training.The S-AFNO model was trained using the AdamW optimizationLoshchilov and Hutter (2017), with a learning rate of 5 × 10 −4 that was exponentially decayed at a rate of 1 × 10 −6 per epoch.The model was trained for 50 epochs, and had approximately 9 million trainable parameters.The training of the S-AFNO model took approximately 12 minutes per epoch using CESM2-LE training data in our computing environment.</p>
<p>Figure 4 .Figure 5 .
45
Figure 4.The performance of AiBEDO in emulating CESM2-LE data using different ML models including S-MLP, S-Unet, S-AFNO.The persistence curve illustrates the temporal deviation of the reference output, quantified as the discrepancy between the ground-truth output at each lag compared with no lag (when lag = 0).</p>
<p>Figure 6 .
6
Figure 6.Time correlation scores of one-month lag AiBEDO S-MLP (left column), S-Unet (middle column), and S-AFNO (right column) emulation versus baseline CESM2 data for surface temperature (top row), precipitation (middle row), and surface pressure (bottom row).</p>
<p>Figure 7 .
7
Figure 7.Comparison of MCB Perturbation Responses in 6-month integrated S-MLP, S-Unet and S-AFNO Models to CESM2 coupled simulations.</p>
<p>Figure 8 .
8
Figure 8. CESM2 (left column) and lag-integrated AiBEDO (right column) surface temperature anomalies due to MCB-like forcing in the NEP (top row), SEP (middle row), and SEA (bottom row).AiBEDO responses are computed using Simpson's rule integration of anomalies from lag 1, 2, 3, 4, 5, 6, 12, 24, 36, and 48 month models.</p>
<p>Figure 9 .
9
Figure 9. High-level overview of our interactive visual analysis system to work with the trained hybrid models and drive post-hoc analysis for different MCB scenarios.[source code:https://github.com/subhashis/aibedoviz, demo video:https://youtu.be/3dmqYqkSLOo]</p>
<p>Figure 10 .
10
Figure 10.AiBEDO emulation results for a sample input time step with no time-lag (simultaneous run) for surface temperature (tas), precipitation (pr), and surface pressure (ps) compared with ground truth (first columns) and different ML models.</p>
<p>Figure 11 .
11
Figure 11.AiBEDO emulation results for a sample input time step with time-lag after one month (lag =1) for surface temperature (tas), precipitation (pr), and surface pressure (ps) compared with ground truth (first columns) and different ML models.</p>
<p>Figure 12 .
12
Figure 12.Annual mean radiation anomalies calculated from Fixed SST simulations and applied as MCB perturbations to AiBEDO.</p>
<p>Figure 13 .
13
Figure 13.Climate tipping points and mitigation strategies using AiBEDO framework</p>
<p>Table 1 .
1
CESM2 LE variables used in AiBEDO.TOA -top of atmosphere.All radiative and heat fluxes are positive down
VariableDescription
/20
/20
Source code of AiBEDO framework is made available at https://github.com/kramea/kdd_aibedo.A sample dataset is made available at https://doi.org/10.5281/zenodo.7597027.Additional data available upon request.
Deep learning and machine learning in hydrological processes climate change and earth systems a systematic review. S Ardabili, A Mosavi, M Dehghani, A R Várkonyi-Kóczy, Engineering for Sustainable Future: Selected papers of the 18th International Conference on Global Research and Education Inter-Academia-2019 18. Springer2020</p>
<p>Climate extremes in multi-model simulations of stratospheric aerosol and marine cloud brightening climate engineering. V N Aswathy, O Boucher, M Quaas, U Niemeier, H Muri, J Mülmenstädt, J Quaas, Atmospheric Chemistry and Physics. 15162015</p>
<p>Modelling for digital twins-potential role of surrogate models. J L Ba, J R Kiros, G E Hinton, Á Bárkányi, T Chovan, S Nemeth, J Abonyi, arXiv:1607.06450Processes. 934762016. 2021arXiv preprintLayer normalization</p>
<p>Machine learning in weather prediction and climate analyses-applications and perspectives. B Bochenek, Z Ustrnul, Atmosphere. 1321802022</p>
<p>Cyberattack detection in large-scale smart grids using chebyshev graph convolutional networks. O Boyaci, M R Narimani, K Davis, E Serpedin, 2022 9th International Conference on Electrical and Electronics Engineering (ICEEE). IEEE2022</p>
<p>Deep learning for image sequence classification of astronomical events. R Carrasco-Davis, G Cabrera-Vives, F Förster, P A Estévez, P Huijse, P Protopapas, I Reyes, J Martínez-Palomera, C Donoso, 2019. 1004Publications of the Astronomical Society of the Pacific131108006</p>
<p>Deep learning in medical image analysis. H.-P Chan, R K Samala, L M Hadjiiski, C Zhou, Deep Learning in Medical Image Analysis: Challenges and Applications. 2020</p>
<p>The rise of deep learning in drug discovery. H Chen, O Engkvist, Y Wang, M Olivecrona, T Blaschke, Drug discovery today. 2362018</p>
<p>Fluctuation dissipation theorem in a general circulation model: FDT IN A GENERAL CIRCULATION MODEL. I Cionni, G Visconti, F Sassi, Geophysical Research Letters. 3192004</p>
<p>Machine learning in drug discovery: a review. S Dara, S Dhamercherla, S S Jadav, C M Babu, M J Ahsan, Artificial Intelligence Review. 5532022</p>
<p>Deepsphere: a graph-based spherical cnn. M Defferrard, M Milani, F Gusset, N Perraudin, arXiv:2012.150002020arXiv preprint</p>
<p>High-throughput deep learning variant effect prediction with sequence unet. A S Dunham, P Beltrao, M Alquraishi, bioRxiv. 2022</p>
<p>Current problems in the mathematical theory of climate. V Dymnikov, A Gritsun, C/C Of Izvestiia-Rossiiskaia Akademiia Nauk Fizika Atmosfery I Oceanic, Okeana, IZVESTIIA-RUSSIAN ACADEMY OF SCIENCES ATMOSPHERIC AND. 4132662005</p>
<p>Machine learning for medical imaging. B J Erickson, P Korfiatis, Z Akkus, T L Kline, Radiographics. 3722017</p>
<p>Earth system models: an overview. G M Flato, Wiley Interdisciplinary Reviews: Climate Change. 20112</p>
<p>Improved semisupervised unet deep learning model for forest height mapping with satellite sar and optical data. S Ge, H Gu, W Su, J Praks, O Antropov, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 152022</p>
<p>Regional earth system modeling: review and future directions. F Giorgi, X.-J Gao, Atmospheric and Oceanic Science Letters. 1122018</p>
<p>Construction of the linear response operator of an atmospheric general circulation model to small external forcing. A Gritsoun, G Branstator, V Dymnikov, Russian Journal of Numerical Analysis and Mathematical Modelling. 1752002</p>
<p>Climate response using a three-dimensional operator based on the fluctuationdissipation theorem. A Gritsun, G Branstator, Journal of the atmospheric sciences. 6472007</p>
<p>Efficient token mixing for transformers via adaptive fourier neural operators. J Guibas, M Mardani, Z Li, A Tao, A Anandkumar, B Catanzaro, International Conference on Learning Representations. 2021</p>
<p>Climate processes and climate sensitivity. J E Hansen, T Takahashi, Washington DC American Geophysical Union Geophysical Monograph Series. 291984</p>
<p>Violation of the fluctuation-dissipation theorem in a protein system. K Hayashi, M Takano, Biophysical journal. 9332007</p>
<p>D Hendrycks, K Gimpel, H Hirasawa, D Hingmire, H Singh, P J Rasch, S Kim, S Hazarika, P Mitra, K Ramea, arXiv:1606.08415Gaussian error linear units (gelus). 2016. 2022arXiv preprintImpact of 14/20</p>
<p>Regional Marine Cloud Brightening Interventions on Climate Tipping Points. Preparation. </p>
<p>Global and country-specific geopolitical risk uncertainty and stock return of fragile emerging economies. M E Hoque, M A S Zaidi, Borsa Istanbul Review. 2032020</p>
<p>Protein folding as a physical stochastic process. K Huang, Biophysical Reviews and Letters. 301n022008</p>
<p>Climate change: Climate engineering through stratospheric aerosol injection. M Hulme, Progress in Physical Geography. 3652012</p>
<p>Climate impacts of geoengineering marine stratocumulus clouds. A Jones, J Haywood, O Boucher, Journal of Geophysical Research: Atmospheres. 114D102009</p>
<p>The geoengineering model intercomparison project phase 6 (geomip6): design and preliminary results. B Kravitz, A Robock, S Tilmes, O Boucher, J M English, P J Irvine, A Jones, M G Lawrence, M Maccracken, H Muri, 2015Geoscientific Model Development8</p>
<p>The fluctuation-dissipation theorem. R Kubo, Reports on Progress in Physics. 2912551966</p>
<p>T Kurth, S Subramanian, P Harrington, J Pathak, M Mardani, D Hall, A Miele, K Kashinath, A Anandkumar, arXiv:2208.05419Fourcastnet: Accelerating global high-resolution weather forecasting using adaptive fourier neural operators. 2022arXiv preprint</p>
<p>Marine cloud brightening. J Latham, K Bower, T Choularton, H Coe, P Connolly, G Cooper, T Craft, J Foster, A Gadian, L Galbraith, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences. 3702012a. 1974</p>
<p>Weakening of hurricanes via marine cloud brightening (mcb). J Latham, B Parkes, A Gadian, S Salter, Atmospheric Science Letters. 1342012b</p>
<p>A systematic review of the safety climate intervention literature: Past trends and future directions. J Lee, Y.-H Huang, J H Cheung, Z Chen, W S Shaw, Journal of occupational health psychology. 241662019</p>
<p>Machine learning structure preserving brackets for forecasting irreversible processes. K Lee, N Trask, P Stinis, Advances in Neural Information Processing Systems. 202134</p>
<p>Climate Response and Fluctuation Dissipation. C Leith, Journal of the Atmospheric Sciences. 321975</p>
<p>Z Li, N Kovachki, K Azizzadenesheli, B Liu, K Bhattacharya, A Stuart, A Anandkumar, arXiv:2010.08895Fourier neural operator for parametric partial differential equations. 2020arXiv preprint</p>
<p>A survey on deep learning in medical image analysis. G Litjens, T Kooi, B E Bejnordi, A A A Setio, F Ciompi, M Ghafoorian, J A Van Der Laak, B Van Ginneken, C I Sánchez, Medical image analysis. 422017</p>
<p>Sensitivity of Surface Temperature to Oceanic Forcing via q-Flux Green's Function Experiments. Part I: Linear Response Function. F Liu, J Lu, O Garuba, L R Leung, Y Luo, Wan , X , Journal of Climate. 3192018</p>
<p>I Loshchilov, F Hutter, arXiv:1711.05101Decoupled weight decay regularization. 2017arXiv preprint</p>
<p>Efficient surrogate modeling methods for large-scale earth system models based on machine-learning techniques. D Lu, D Ricciuto, Geoscientific Model Development. 201912</p>
<p>Spatio-temporal analysis of the role of climate in inter-annual variation of malaria incidence in zimbabwe. M L Mabaso, P Vounatsou, S Midzi, J Da Silva, T Smith, International Journal of Health Geographics. 512006</p>
<p>Coping with climate change: Three insights for research, intervention, and communication to promote adaptive coping to climate change. A Y Mah, D A Chapman, E M Markowitz, B Lickel, Journal of anxiety disorders. 751022822020</p>
<p>High skill in low-frequency climate response through fluctuation dissipation theorems despite structural instability. A J Majda, R Abramov, B Gershgorin, Proceedings of the National Academy of Sciences. 10722010</p>
<p>Comparison of machine learning methods for photovoltaic power forecasting based on numerical weather prediction. D Markovics, M J Mayer, Renewable and Sustainable Energy Reviews. 1611123642022</p>
<p>Response characteristics of rain-wind induced vibration of stay-cables of cable-stayed bridges. M Matsumoto, T Saitoh, M Kitazawa, H Shirato, T Nishizaki, Journal of Wind Engineering and Industrial Aerodynamics. 572-31995</p>
<p>Application of unet fully convolutional neural network to impervious surface segmentation in urban environment from high resolution satellite imagery. J Mcglinchy, B Johnson, B Muller, M Joseph, J Diaz, IGARSS 2019 -2019 IEEE International Geoscience and Remote Sensing Symposium. 2019</p>
<p>Exceeding 1.5°C global warming could trigger multiple climate tipping points. D I A Mckay, A Staal, J F Abrams, R Winkelmann, B Sakschewski, S Loriani, I Fetzer, S E Cornell, J Rockström, T M Lenton, Science. 37766112022</p>
<p>Quantum dissipation theory with application to electron transfer: Protein folding kinetics and thermodynamics: a mean-field ising model. Y Mo, 2006PhD thesis</p>
<p>Solar radiation management: a proposal for immediate polycentric governance. S Nicholson, S Jinnah, A Gillespie, Climate Policy. 1832018</p>
<p>Machine learning climate variability. J H Park, S Yoo, B Nadiga, Proceedings of the 33rd Conference on Neural Information Processing Systems (NeurIPS). the 33rd Conference on Neural Information Processing Systems (NeurIPS)Vancouver, BC, Canada2019</p>
<p>Machine learning methods in drug discovery. L Patel, T Shukla, X Huang, D W Ussery, S Wang, Molecules. 252252772020</p>
<p>Stratospheric aerosol particles and solar-radiation management. F D Pope, P Braesicke, R Grainger, M Kalberer, I Watson, P Davidson, R Cox, Nature Climate Change. 2102012</p>
<p>Cloud-radiative forcing and climate: Results from the earth radiation budget experiment. V Ramanathan, R Cess, E Harrison, P Minnis, B Barkstrom, E Ahmad, D Hartmann, Science. 24348871989</p>
<p>Geoengineering by cloud seeding: influence on sea ice and climate system. P J Rasch, J Latham, C.-C J Chen, Environmental Research Letters. 44451122009</p>
<p>Deep learning for medical image processing: Overview, challenges and the future. M I Razzak, S Naz, A Zaib, 2018Classification in BioApps: Automation of Decision Making</p>
<p>Deep learning and process understanding for data-driven earth system science. M Reichstein, G Camps-Valls, B Stevens, M Jung, J Denzler, N Carvalhais, Nature. 56677432019</p>
<p>Deep learning-based weather prediction: a survey. X Ren, X Li, K Ren, J Song, Z Xu, K Deng, X Wang, Big Data Research. 231001782021</p>
<p>A survey of the main aspects of magnetic forces and mechanical behaviour of ferromagnetic materials under magnetisation. G Reyne, J Sabonnadiere, J Coulomb, P Brissonneau, IEEE Transactions on magnetics. 2351987</p>
<p>Benefits and risks of stratospheric solar radiation management for climate intervention (geoengineering). A Robock, Bridge. 5012020</p>
<p>Ubiquity of human-induced changes in climate variability. K B Rodgers, S.-S Lee, N Rosenbloom, A Timmermann, G Danabasoglu, C Deser, J Edwards, J.-E Kim, I R Simpson, K Stein, M F Stuecker, R Yamaguchi, T Bódai, E.-S Chung, L Huang, W M Kim, J.-F Lamarque, D L Lombardozzi, W R Wieder, S G Yeager, Earth System Dynamics. 1242021</p>
<p>An api oriented open-source python framework for unsupervised learning on graphs. B Rozemberczki, O Kiss, R Sarkar, arXiv:2003.04819,10(3340531.34127572020arXiv preprint</p>
<p>Direct numerical simulation of the brownian motion of particles by using fluctuating hydrodynamic equations. N Sharma, N A Patankar, Journal of Computational Physics. 20122004</p>
<p>Deep learning in medical image analysis. D Shen, G Wu, H.-I Suk, Annual review of biomedical engineering. 192017</p>
<p>Observed along-wind vibration of a suspension bridge tower. D M Siringoringo, Y Fujino, Journal of wind engineering and industrial aerodynamics. 1032012</p>
<p>Stock market synchronization: the role of geopolitical risk. K Sohag, R Vasilyeva, A Urazbaeva, V Voytenkov, Journal of Risk and Financial Management. 1552042022</p>
<p>Survey of machine learning techniques in drug discovery. N Stephenson, E Shane, J Chase, J Rowland, D Ries, N Justice, J Zhang, L Chan, R Cao, Current drug metabolism. 2032019</p>
<p>Response to marine cloud brightening in a multi-model ensemble. C W Stjern, H Muri, L Ahlm, O Boucher, J N Cole, D Ji, A Jones, J Haywood, B Kravitz, A Lenton, Atmospheric Chemistry and Physics. 1822018a</p>
<p>C W Stjern, H Muri, L Ahlm, O Boucher, J N S Cole, D Ji, A Jones, J Haywood, B Kravitz, A Lenton, J C Moore, U Niemeier, S J Phipps, H Schmidt, S Watanabe, J E Kristjánsson, Response to marine cloud brightening in a multi-model ensemble. 2018b18</p>
<p>Smaat-unet: Precipitation nowcasting using a small attention-unet architecture. K Trebing, T Stanczyk, S Mehrkanoon, Pattern Recognition Letters. 1452021</p>
<p>Brownian motion of molecules: the classical theory. R Tsekov, arXiv:1005.14902010arXiv preprint</p>
<p>Goal orientation and mastery climate: a review of contemporary research and insights to intervention. N C Valentini, M E Rudisill, 2006Estudos de Psicologia23Campinas</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Ł Kaiser, I Polosukhin, Advances in neural information processing systems. 201730</p>
<p>A novel hybrid approach for wind speed prediction. J Wang, W Zhang, J Wang, T Han, L Kong, Information Sciences. 2732014</p>
<p>Deep learning for creating surrogate models of precipitation in earth system models. T Weber, A Corotan, B Hutchinson, B Kravitz, R Link, Atmospheric Chemistry and Physics. 2042020</p>
<p>Fluctuation-dissipation relations for stochastic gradient descent. S Yaida, X Yin, L Sun, Y Fu, R Lu, Y Zhang, arXiv:1810.00004Journal of healthcare engineering. 2018. 2022arXiv preprintU-net-based medical image segmentation</p>
<p>Building a machine learning surrogate model for wildfire activities within a global earth system model. Q Zhu, F Li, W J Riley, L Xu, L Zhao, K Yuan, H Wu, J Gong, J Randerson, 2022Geoscientific Model Development15</p>
<p>Material properties and the electrorheological response. C Zukoski, Annual Review of Materials Science. 2311993</p>            </div>
        </div>

    </div>
</body>
</html>