<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2701 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2701</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2701</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-70.html">extraction-schema-70</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <p><strong>Paper ID:</strong> paper-266690872</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.17653v1.pdf" target="_blank">LARP: Language-Agent Role Play for Open-World Games</a></p>
                <p><strong>Paper Abstract:</strong> Language agents have shown impressive problem-solving skills within defined settings and brief timelines. Yet, with the ever-evolving complexities of open-world simulations, there's a pressing need for agents that can flexibly adapt to complex environments and consistently maintain a long-term memory to ensure coherent actions. To bridge the gap between language agents and open-world games, we introduce Language Agent for Role-Playing (LARP), which includes a cognitive architecture that encompasses memory processing and a decision-making assistant, an environment interaction module with a feedback-driven learnable action space, and a postprocessing method that promotes the alignment of various personalities. The LARP framework refines interactions between users and agents, predefined with unique backgrounds and personalities, ultimately enhancing the gaming experience in open-world contexts. Furthermore, it highlights the diverse uses of language models in a range of areas such as entertainment, education, and various simulation scenarios. The project page is released at https://miao-ai-lab.github.io/LARP/.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2701.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2701.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LARP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language Agent for Role-Playing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A game-oriented language-agent framework for open-world role-playing that includes a cognitive architecture with long-term (semantic/episodic/procedural) and working memory, a memory-processing pipeline (encoding, storage, recall) using vector DBs and logic/probabilistic program representations, and an environment interaction module with an extensible action (API) space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LARP agent cluster</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A cluster-based language-agent architecture composed of multiple smaller fine-tuned language models (LoRAs and base models) specialized for modules such as intent analysis, reflection, and code generation; these models are orchestrated via a cognitive architecture (long-term memory, working memory, memory processing, decision-making). The system emphasizes modular memory processing and retrieval-augmented reasoning rather than a single monolithic LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>text-based / open-world games (general; related work mentions TextWorld and other text-game benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>Open-world and text-based game environments requiring interpretation of observations, long-horizon planning, role-coherent dialogue and actions, and continuous interaction with an environment (e.g., NPC behaviors, multi-step tasks). No single benchmark evaluation is reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>long-term (semantic, episodic, procedural) and working memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td>Hybrid: episodic memories stored in a vector database (embedding-based), semantic memory split between an external database and symbolic natural-language stores, procedural memories represented as APIs in an action space; working memory implemented as a short-term cache (sequential buffer) feeding prompt context.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td>Perceived observations, retrieved long-term memories (episodic QA pairs and natural-language memories), semantic game rules/worldview, procedural actions/skills as API descriptions, and processed reflections/summaries produced during encoding/reflection.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td>Multi-strategy retrieval: self-ask question generation used as queries for (1) logic-programming / predicate-logic search, (2) vector-similarity search over episodic QA pairs, and (3) keyword-based matching to natural-language memories; iterative retrieval until an answer is formed. Retrieval includes probabilistic programming and CoT reasoning over retrieved content.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Working memory collects recent observations and retrieved memory; when working memory exceeds a threshold, a reflection process filters ineffective memories and commits processed natural-language memories to episodic memory and symbolic memories to semantic storage. Episodic entries record retrieval counts; a decay/forgetting mechanism (Wickelgren's power law) marks forgetting probability and relevance over time.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td>To inform decision-making and planning (generate tasks/subtasks and action code), keep coherent role-playing behavior across long horizons, recall prior interactions/events, map tasks to personal/public APIs, and enable memory reconstruction during reasoning (influence observed facts by prior knowledge).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td>Qualitative claims: memory is necessary for interpreting complex open-world environments, memorizing long-term events, and maintaining coherent agent behavior; effective retrieval combines semantic (logic/program) and vector similarity queries using self-ask prompts; reflection and decay (forgetting) mechanisms help filter irrelevant memories. The paper also warns that memory reconstruction can produce distorted memories and that cumulative distortions across modular units are a risk to coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>No quantitative evaluation; reported conceptual limitations include memory distortion from reconstruction, forgetting/decay dynamics that may lose relevant info, unpredictability due to stochastic LM outputs causing cumulative distortion across modules, and the challenge of constructing high-quality fine-tuning data for persona/memory capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LARP: Language-Agent Role Play for Open-World Games', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2701.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2701.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Text-based game agents (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prior text-based game language agents (Urbanek et al. 2019; Dambekodi et al. 2020; Singh et al. 2021; Yao et al. 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Papers cited in related work that apply language-model-based agents to text-based games and discuss the need for semantics, memory, and common-sense knowledge in such environments; cited as prior art but not experimentally analyzed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reading and acting while blindfolded: The need for semantics in text game agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>various text-game agents (cited literature)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Referenced works include agents developed for text-based interactive fiction and benchmarks (e.g., TextWorld); LARP cites these to motivate the need for memory and semantic knowledge in game agents but does not reproduce or analyze their specific architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td>Text-based games / TextWorld (cited generically)</td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td>Interactive text-adventure style environments where agents must read descriptions, track state and objects, and act via text commands to accomplish goals.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LARP: Language-Agent Role Play for Open-World Games', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2701.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2701.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve text games, including details about the memory architecture, performance comparisons, and what makes memory effective or ineffective.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memory systems (related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank / ChatDB / Memory sandbox and other memory-augmentation works</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited works on augmenting language models with long-term memory or database-backed memory stores (vector DBs, transparent memory management) referenced as related memory approaches; LARP leverages similar concepts (vector DB episodic storage, external semantic DB).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>memory-augmented LM systems (cited literature)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Prior proposals that augment LLMs with external memory modules (vector stores, DB-backed symbolic memory) to support long-term retrieval; LARP builds on these ideas but applies them in a role-playing/open-world context.</td>
                        </tr>
                        <tr>
                            <td><strong>base_model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_structure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_content</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_usage_purpose</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_memory_ablation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_effectiveness_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>best_memory_configuration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LARP: Language-Agent Role Play for Open-World Games', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Reading and acting while blindfolded: The need for semantics in text game agents <em>(Rating: 2)</em></li>
                <li>Playing text-based games with common sense <em>(Rating: 2)</em></li>
                <li>Learning to speak and act in a fantasy text adventure game <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory <em>(Rating: 2)</em></li>
                <li>Memory sandbox: Transparent and interactive memory management for conversational agents <em>(Rating: 1)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2701",
    "paper_id": "paper-266690872",
    "extraction_schema_id": "extraction-schema-70",
    "extracted_data": [
        {
            "name_short": "LARP",
            "name_full": "Language Agent for Role-Playing",
            "brief_description": "A game-oriented language-agent framework for open-world role-playing that includes a cognitive architecture with long-term (semantic/episodic/procedural) and working memory, a memory-processing pipeline (encoding, storage, recall) using vector DBs and logic/probabilistic program representations, and an environment interaction module with an extensible action (API) space.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LARP agent cluster",
            "agent_description": "A cluster-based language-agent architecture composed of multiple smaller fine-tuned language models (LoRAs and base models) specialized for modules such as intent analysis, reflection, and code generation; these models are orchestrated via a cognitive architecture (long-term memory, working memory, memory processing, decision-making). The system emphasizes modular memory processing and retrieval-augmented reasoning rather than a single monolithic LLM.",
            "base_model_size": null,
            "game_benchmark_name": "text-based / open-world games (general; related work mentions TextWorld and other text-game benchmarks)",
            "game_description": "Open-world and text-based game environments requiring interpretation of observations, long-horizon planning, role-coherent dialogue and actions, and continuous interaction with an environment (e.g., NPC behaviors, multi-step tasks). No single benchmark evaluation is reported in this paper.",
            "uses_memory": true,
            "memory_type": "long-term (semantic, episodic, procedural) and working memory",
            "memory_structure": "Hybrid: episodic memories stored in a vector database (embedding-based), semantic memory split between an external database and symbolic natural-language stores, procedural memories represented as APIs in an action space; working memory implemented as a short-term cache (sequential buffer) feeding prompt context.",
            "memory_content": "Perceived observations, retrieved long-term memories (episodic QA pairs and natural-language memories), semantic game rules/worldview, procedural actions/skills as API descriptions, and processed reflections/summaries produced during encoding/reflection.",
            "memory_capacity": null,
            "memory_retrieval_strategy": "Multi-strategy retrieval: self-ask question generation used as queries for (1) logic-programming / predicate-logic search, (2) vector-similarity search over episodic QA pairs, and (3) keyword-based matching to natural-language memories; iterative retrieval until an answer is formed. Retrieval includes probabilistic programming and CoT reasoning over retrieved content.",
            "memory_update_strategy": "Working memory collects recent observations and retrieved memory; when working memory exceeds a threshold, a reflection process filters ineffective memories and commits processed natural-language memories to episodic memory and symbolic memories to semantic storage. Episodic entries record retrieval counts; a decay/forgetting mechanism (Wickelgren's power law) marks forgetting probability and relevance over time.",
            "memory_usage_purpose": "To inform decision-making and planning (generate tasks/subtasks and action code), keep coherent role-playing behavior across long horizons, recall prior interactions/events, map tasks to personal/public APIs, and enable memory reconstruction during reasoning (influence observed facts by prior knowledge).",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_memory_ablation": false,
            "memory_effectiveness_findings": "Qualitative claims: memory is necessary for interpreting complex open-world environments, memorizing long-term events, and maintaining coherent agent behavior; effective retrieval combines semantic (logic/program) and vector similarity queries using self-ask prompts; reflection and decay (forgetting) mechanisms help filter irrelevant memories. The paper also warns that memory reconstruction can produce distorted memories and that cumulative distortions across modular units are a risk to coherence.",
            "memory_limitations": "No quantitative evaluation; reported conceptual limitations include memory distortion from reconstruction, forgetting/decay dynamics that may lose relevant info, unpredictability due to stochastic LM outputs causing cumulative distortion across modules, and the challenge of constructing high-quality fine-tuning data for persona/memory capabilities.",
            "comparison_with_other_memory_types": false,
            "best_memory_configuration": null,
            "uuid": "e2701.0",
            "source_info": {
                "paper_title": "LARP: Language-Agent Role Play for Open-World Games",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Text-based game agents (related work)",
            "name_full": "Prior text-based game language agents (Urbanek et al. 2019; Dambekodi et al. 2020; Singh et al. 2021; Yao et al. 2021)",
            "brief_description": "Papers cited in related work that apply language-model-based agents to text-based games and discuss the need for semantics, memory, and common-sense knowledge in such environments; cited as prior art but not experimentally analyzed in this paper.",
            "citation_title": "Reading and acting while blindfolded: The need for semantics in text game agents",
            "mention_or_use": "mention",
            "agent_name": "various text-game agents (cited literature)",
            "agent_description": "Referenced works include agents developed for text-based interactive fiction and benchmarks (e.g., TextWorld); LARP cites these to motivate the need for memory and semantic knowledge in game agents but does not reproduce or analyze their specific architectures.",
            "base_model_size": null,
            "game_benchmark_name": "Text-based games / TextWorld (cited generically)",
            "game_description": "Interactive text-adventure style environments where agents must read descriptions, track state and objects, and act via text commands to accomplish goals.",
            "uses_memory": null,
            "memory_type": null,
            "memory_structure": null,
            "memory_content": null,
            "memory_capacity": null,
            "memory_retrieval_strategy": null,
            "memory_update_strategy": null,
            "memory_usage_purpose": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_memory_ablation": null,
            "memory_effectiveness_findings": null,
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "best_memory_configuration": null,
            "uuid": "e2701.1",
            "source_info": {
                "paper_title": "LARP: Language-Agent Role Play for Open-World Games",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Memory systems (related work)",
            "name_full": "MemoryBank / ChatDB / Memory sandbox and other memory-augmentation works",
            "brief_description": "Cited works on augmenting language models with long-term memory or database-backed memory stores (vector DBs, transparent memory management) referenced as related memory approaches; LARP leverages similar concepts (vector DB episodic storage, external semantic DB).",
            "citation_title": "Memorybank: Enhancing large language models with long-term memory",
            "mention_or_use": "mention",
            "agent_name": "memory-augmented LM systems (cited literature)",
            "agent_description": "Prior proposals that augment LLMs with external memory modules (vector stores, DB-backed symbolic memory) to support long-term retrieval; LARP builds on these ideas but applies them in a role-playing/open-world context.",
            "base_model_size": null,
            "game_benchmark_name": null,
            "game_description": null,
            "uses_memory": null,
            "memory_type": null,
            "memory_structure": null,
            "memory_content": null,
            "memory_capacity": null,
            "memory_retrieval_strategy": null,
            "memory_update_strategy": null,
            "memory_usage_purpose": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_memory_ablation": null,
            "memory_effectiveness_findings": null,
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "best_memory_configuration": null,
            "uuid": "e2701.2",
            "source_info": {
                "paper_title": "LARP: Language-Agent Role Play for Open-World Games",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Reading and acting while blindfolded: The need for semantics in text game agents",
            "rating": 2,
            "sanitized_title": "reading_and_acting_while_blindfolded_the_need_for_semantics_in_text_game_agents"
        },
        {
            "paper_title": "Playing text-based games with common sense",
            "rating": 2,
            "sanitized_title": "playing_textbased_games_with_common_sense"
        },
        {
            "paper_title": "Learning to speak and act in a fantasy text adventure game",
            "rating": 2,
            "sanitized_title": "learning_to_speak_and_act_in_a_fantasy_text_adventure_game"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Memory sandbox: Transparent and interactive memory management for conversational agents",
            "rating": 1,
            "sanitized_title": "memory_sandbox_transparent_and_interactive_memory_management_for_conversational_agents"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 1,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        }
    ],
    "cost": 0.009761249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LARP: LANGUAGE-AGENT ROLE PLAY FOR OPEN-WORLD GAMES
24 Dec 2023</p>
<p>Ming Yan mingyan@miao.company 
Ruihao Li 
Hao Zhang 
Hao Wang 
Zhilan Yang 
Ji Yan 
Miao 
LARP: LANGUAGE-AGENT ROLE PLAY FOR OPEN-WORLD GAMES
24 Dec 2023881DB5296F92FBFF5FD1D1E232A56E0AarXiv:2312.17653v1[cs.AI]
Language agents have shown impressive problem-solving skills within defined settings and brief timelines.Yet, with the ever-evolving complexities of open-world simulations, there's a pressing need for agents that can flexibly adapt to complex environments and consistently maintain a longterm memory to ensure coherent actions.To bridge the gap between language agents and openworld games, we introduce Language Agent for Role-Playing (LARP), which includes a cognitive architecture that encompasses memory processing and a decision-making assistant, an environment interaction module with a feedback-driven learnable action space, and a postprocessing method that promotes the alignment of various personalities.The LARP framework refines interactions between users and agents, predefined with unique backgrounds and personalities, ultimately enhancing the gaming experience in open-world contexts.Furthermore, it highlights the diverse uses of language models in a range of areas such as entertainment, education, and various simulation scenarios.The project page is released at https://miao-ai-lab.github.io/LARP/.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) are machine learning models capable of performing a variety of Natural Language Processing (NLP) tasks such as generating text, translating text from one language to another, and answering questions conversationally.The term large refers to the vast amount of parameters the language model can update during its learning process.With the development of pre-training generative model techniques and the construction of massive and comprehensive datasets, some top-performing large language models have up to hundreds of billions of parameters [Touvron et al., 2023, Radford et al., 2018, 2019, Brown et al., 2020, Ouyang et al., 2022, OpenAI, 2023].Furthermore, owing to the advancements in large language models, AI entities have become a hot topic in recent years.These artificial intelligence entities, often referred to as agents [Russell andNorvig, 2010, Wooldridge andJennings, 1995], are the fundamental components of large-scale artificial intelligence systems.Typically, in the realm of Artificial General Intelligence, an agent is an artificial entity that can perceive its surrounding environment through sensors, make decisions, and respond via actuators.With the development of large language models and agents, there is a new trend of combining them into a single entity called language agents.These language agents are designed by integrating large language models and agent design [Wang et al., 2023a, Xi et al., 2023, Sumers et al., 2023].</p>
<p>As a strongly related industry to computers, gaming has become increasingly intertwined with the development of general-purpose language agents.The application of LLMs and agents has grown more widespread.In related studies, there is considerable literature on the application of language agents in text-based games [Dambekodi et al., 2020, Singh et al., 2021, Yao et al., 2021, Urbanek et al., 2019] and adversarial games [OpenAI et al., 2019, Arulkumaran et al., 2019].Concurrently, with the enhanced capabilities of LLMs, open-world games have emerged as the frontier for language agent applications.This is due to the unique and challenging scenarios present in open-world games, which provides a fertile ground for general-purpose language agents.Open-world games present a rich, dynamic, and engaging environment, encompassing complex missions and storylines.They require the use of agents to equip non-player characters with diversified behaviors.Although numerous studies have proposed architectures for general language agents that could be applied in open-world games like Minecraft [Lin et al., 2023, Park et al., 2023], a gap still exists between the general-purpose agents and the overall requirements in an open-world gaming context.General-purpose language agents are created to address a variety of issues in realistic environments.Their primary requisites are universality and the simulation of human behavior.These agents can adapt to various environments and tasks, without being restricted to fixed roles.However, these general-purpose language agents face significant challenges in practical open-world environments.These challenges include but are not limited to interpreting complex environments, memorizing long-term events, generating expressions that cohere with character and environmental settings, and continuously learning from interactions with the environment.</p>
<p>Hence, in this work, we propose a game-oriented Role-Playing Agent framework, Language Agent for Role Play (LARP) toward open-world games.LARP focuses on blending the open-world games with language agents, utilizing a modular approach for memory processing, decision-making, and continuous learning from interactions.In the agent's internal depiction, we designed a complex cognitive architecture based on cognitive psychology, equipping agents under the LARP framework with high playability and uniquity.Aiming to yield more realistic role-playing experience, we regularized agents using the data and context of the open-world gaming environment, prior set personalities, knowledge, rules, memory, and post constraints, which can be seen as a specific case within the general-purpose language agents.As for the general agent architecture, it typically requires a large-scale language model.However, our architecture incorporates a cluster of smaller language models, each fine-tuned for different domains, to handle various tasks separately.This design contributes new experiences and perspectives to developing language agents for open-world role-playing games.</p>
<p>The rest of this work is organized as follows: Section 2 discusses the related works on agent framework and agent components.In Section 3, we present the cognitive architecture part of LARP.In Section 4, we highlight the environmental interaction module, and in Section 5, we introduce agents' alignment of diversified personalities.A discussion is presented in Section 6, followed by a conclusion of the entire paper in Section 7.</p>
<p>Related Work</p>
<p>The development and advancements in LLMs have brought opportunities and potential to various fields.These fields include but are not limited to, role-playing, gaming, and tool-using Agents, amongst others.At the same time, the definition of language agents is being continuously updated.We will share some related works on agent architecture in this section.</p>
<p>Agent Framework</p>
<p>Firstly, we will introduce some works related to language agents' role-playing and simulation, which are aimed at enhancing the LLM's ability in role-playing and highlighting distinct features.These works also aim to boost the interaction capability between the agents and users, making the agents appear more self-conscious [Wang et al., 2023b, Shao et al., 2023, Shanahan et al., 2023, Li et al., 2023a].Other studies focus on role-playing and interaction among multiple agents, which include scenarios such as collaboration to complete tasks [Li et al., 2023b, Chen et al., 2023a, Qian et al., 2023, Li et al., 2023c, Wu et al., 2023], simulating daily activities [Lin et al., 2023, Park et al., 2023, Wang et al., 2023c, Liu et al., 2023a], and promoting progress in debates [Liang et al., 2023, Du et al., 2023, Chan et al., 2023].</p>
<p>In addition to this, language agents are also applied in open-world environments.There are not only instances of application in text-based games [Urbanek et al., 2019, Côté et al., 2019, Hausknecht et al., 2020]but also exploration tasks in open-world environments such as Minecraft [Wang et al., 2023d,e, Zhu et al., 2023].</p>
<p>Agent Component</p>
<p>In this section, we will introduce some related works on the design of language agent components.An agent system is usually divided into three parts: memory, planning, and action (tool use) [Weng, 2023].Memory system serves as a repository for facts, reflections, etc., entailing abilities for storage and retrieval.Hence, efforts in memory primarily pertain to input/output functions, including memory compression [Hu et al., 2023], storage, and retrieval [Park et al., 2023, Zhong et al., 2023, Huang et al., 2023].</p>
<p>The planning component is responsible for the decision-making aspect related to the agent's behavior and language.The capability of agents largely depends on this part.Abilities for planning [Yao et al., 2023, Liu et al., 2023b, Yao et al., 2022, Shinn et al., 2023, Liu et al., 2023c, Wang et al., 2023f] and reasoning [Wei et al., 2022, Madaan et al., 2023] are realized in this component, and associated works typically revolve around these two abilities.</p>
<p>The last component is tool usage and actions, which signifies an augmentation in the capabilities of the intelligent entities, aiding them in conducting more complex and difficult tasks.Works in this section include tool-using [Nakano et al., 2021] and learning new actions [Schick et al., 2023].</p>
<p>Cognitive Architecture</p>
<p>Cognitive architecture is a fundamental component of role-playing language agents in open-world games.It provides a logical framework and enables self-recognition of agents.The cognitive architecture is shown in figure 2. It comprises four major modules: long-term memory, working memory, memory processing, and decision-making.The long-term memory module serves as the primary warehouse containing memories with substantial storage capacity.Working memory acts as a temporary cache with limited space for memory.The memory processing module is the most important unit of the cognitive architecture.The decision-making module then derives agents' subsequent actions based on the retrieved information.</p>
<p>Long-Term Memory</p>
<p>In cognitive science, long-term memory (LTM) is comprised of two types of memory: declarative memory and procedural memory.Declarative memory is further divided into semantic memory and episodic memory [Laird,Figure 2: Cognitive Workflow of LARP.This represents a cycle: Information from long-term memory and observation is processed in the memory processing module and transmitted to the working memory module.The information in the working memory module, together with the observed information, is inputted into the decision-making assistant, which finally generates a decision or dialogue.Memory processing has three main stages: encoding, storage, and recall.Encoding is the process of transforming information into a form that can be stored in memory.Storage is the process of maintaining information in memory.Recall is the process of retrieving information from memory.</p>
<p>2019, Tulving et al., 1972].Semantic memory refers to general knowledge memories acquired through conceptual and factual knowledge about the world.In the context of the open-world game, it can be considered the part that encapsulates the game rules and memories consistent with the relevant worldview.We divided semantic memory into two parts in the system.One is implemented with an external database, as its content is not frequently changed.Simultaneously, some semantic memories are stored in the long-term memory module in symbolic language.</p>
<p>Episodic memory refers to the memory of specific events that an individual experiences.These can be memories related to other players or Agents.In our memory system, we adopted a vector database in the long-term memory module for storing and retrieving these memories.Associated decay parameters are introduced as memories can be forgotten, with relevance scores decreasing over time.When reasoning with the LLM, such memory contents can be easily retrieved through vector queries.</p>
<p>Procedural memory refers to actions or skills that can be performed without conscious thought [Roediger, 1990], such as swimming, cycling, etc.These skills, with action properties, are represented as APIs in action space in our system.The action space is divided into public APIs and personal APIs.The personal APIs could be extended through learning [Sumers et al., 2023] which is mentioned in the section 4.</p>
<p>In the long-term memory module, we store all perceived memories in the semantic and episodic memory zones respectively.We propose a method named Question-based Query, which generates self-ask questions as queries that can be leveraged in search by vector similarity and predicate logic.This method facilitates the retrieval of semantic and episodic memories in the recall module, thereby improving the overall efficiency of memory utilization.</p>
<p>Working Memory</p>
<p>Working memory mainly holds the observational information and retrieved long-term memories needed for performing complex cognitive tasks (such as reasoning and learning) and interactive tasks [Baddeley, 2003, Miller et al., 2017].These pieces of information are typically obtained through agents' observation as natural language data provided by the game side.Short-term memory, as its name suggests, represents a stage of memory that retains information for brief periods of time, generally only lasting a few seconds to a minute [Atkinson and Shiffrin, 1968].To humans, the average capacity for retaining items in short-term memory is about 7±2, with a retention duration of roughly 20 to 30 seconds [Miller, 1956].In this work, the two concepts are implemented as the same module, collectively referred to as working memory.In our architecture, it exists as a data cache from which information is extracted and dropped into the prompt's context.Its extraction process is further explained in more detail in the memory processing and decision-making sections.</p>
<p>Memory Processing</p>
<p>The memory processing module primarily handles the processing of memories that have been stored and are about to be stored.The three main stages of memory are encoding, storage, and recall [Melton, 1963].Specifically, perceived input information is encoded and transformed into content in long-term memory, enabling it to be recalled in the space of long-term memory.In LARP, we simulate this procedure by processing all structured observational information provided in the game, combining it with retrieved content, and storing it in the working memory.This information serves as an input for a series of logic processing units in the decision-making module, continuously updating the content in the working memory.Once the length of working memory reaches a certain threshold, reflection is triggered, during which ineffective memories are filtered out, and the processed natural language memories and symbolic language memories are separately stored as episodic memory and semantic memory.</p>
<p>The core of memory encoding is the language transformation system.By aligning language models and probabilistic models, natural language is converted into a probabilistic programming language (PPL) [Wong et al., 2023] and logic programming language.PPL primarily handles probabilistic reasoning, while logic programming language pertains mainly to fact reasoning.Moreover, memory encoding should also be influenced by the consistency of prior knowledge, meaning that past knowledge will affect the current understanding [Bartlett, 1995].The storage of memory has already been elaborated in the long-term memory section.</p>
<p>To humans, recall refers to the psychological process of retrieving information from the past.While in our architecture, it is the process of retrieving information from long-term memory.It first involves compound retrieval from long-term memory, including search by vector similarity and predicate logic.First, we employed self-ask strategies to form the queries, prompting LLM to raise questions regarding agents' observations, personalities, and experiences.After obtaining the queries, we adopted 3 methods to perform the retrieval.For logic programming search, LLM generates a query in a logic programming language that answers the self-ask questions based on available rules and facts.For similarity search, two methods were available.One method is using self-ask questions as queries for vector similarity search, matching with question-answer pairs in the vector database of episodic memory.The other method is using keywords extracted from the self-ask questions to match with the natural language memories in the same database.This process will be repeated until a final answer is obtained, and this can also be considered semantic retrieval [Press et al., 2022].Figure 3 shows the detailed control flow.</p>
<p>Based on the recall capabilities, our architecture adopts CoT [Wei et al., 2022] to reason about the retrieved content and observed information and perform memory reconstruction, ie., using prior knowledge to influence observed facts to some extent [Loftus and Palmer, 1974] though the reconstructed memories might be distorted.In addition, we also simulated the process of human forgetting in the recall workflow.When the retrieval system operates, we introduce a decay parameter σ represented by Wickelgren's power law to mark the forgetting probability of this memory [Wixted and Carpenter, 2007].The calculation formula is as follows:
σ = αλN (1 + βt) −ψ (1)
Here, λ represents the importance level, given by a scoring model.N stands for the number of retrievals of this memory, and t is the elapsed time after the last retrieval.ψ is the rate of forgetting for each character.α and β are Figure 3: Detail control flow of recall psychological process.First conduct self-asking about the observation to get self-ask questions.Using the self-ask questions as queries, different methods of retrieval are undertaken.1. Generate predicate logic statements in logic programming language and probabilistic programming language based on queries.2. Conducting a vector similarity search after extracting keywords from the queries.3. Searching for question-answer pairs based on sentence similarity between queries and the questions of question-answer pairs.Q self −ask means the self-ask questions which were used as queries, Q logic stands for predicate logic query statements, Q key is the extracted keywords, Q ′ A stands for the question-answer pairs.the scaling parameters for importance and time, respectively.Through multiple rounds of memory reconstruction and forgetting processes, our cognitive architecture can ultimately simulate instances of memory distortion.</p>
<p>Decision Making</p>
<p>The decision-making module produces final decisions under the joint effect of observation and working memory.The core section of the decision-making module is an ordered cluster of programmable units.Each unit will process the content in working memory and context, updating the results to the working memory in real time.These units can be simple information processing units, such as those conducting affective computing, or complex units equipped with specifically fine-tuned LLM models, like intent analysis and output formatting.These units are infinitely scalable and can handle all types of memory processing tasks.As each unit communicates with working memory, it updates the working memory in real-time, allowing the agents to react timely when observation changes during the process.</p>
<p>The execution order of these units would be determined by a language model assistant.The final output of the decision-making module could be tasks or dialogue contents for the Non-Player Characters (NPCs).</p>
<p>Environment Interaction</p>
<p>For role-playing language agents in open-world games, generating tasks based on current observations through the cognitive architecture only accomplishes the objective within agents.However, in open-world games with free actions and rich gaming content, agents need to interact with the game environment by connecting the internal and the external.There are various works in employing language agents to interact with open-world game environments [Wang et al., 2023d, Zhu et al., 2023, Yang et al., 2023, Wang et al., 2023e].For instance, Voyager uses the concept of an automatic curriculum, obtaining objectives by feeding GPT4 the contents and states of environmental observations.Then, GPT4 is prompted to generate the functioning code to reach the objectives.The paper also presents the skill library method, which embeds the description of the generated code as a key and the code as a value, achieving high extensibility of incorporating new skills by adding key-value pairs.Octopus utilizes the Visual Language Model (VLM) to acquire observations.However, this approach can lead to high dimensions of data feature distribution, resulting in poor controllability.Moreover, the operational cost of the VLM is high, and it's challenging to collect the data set's prior knowledge within the game.</p>
<p>Figure 4 shows the fundamental interaction procedural.Interior refers to the working memory and the tasks that need to be executed based on the current situation, generated by the observation and cognitive architecture.The Action Space is the agent's executable action APIs in the game world, encompassing both public and personal APIs.The personal API library stores tasks-API pairs, while the public APIs are basic actions.A personal API can be a series of basic actions, facilitating quick decision-making and reuse of APIs.</p>
<p>Once we have generated the corresponding plans in the decision-making module, we initially attempt to break down the overall task goal into several subtask goals.These subtask goals present as strictly ordered sequence-sensitive arrangements.For each task goal or subtask goal, the whole system will integrate it with the working memory.Then, it will use a retriever to search separately in the personal API library and public API library.If the action corresponding to the task already exists in the personal API library, the action is instantly performed.Otherwise, the system completes the corresponding prompt with the entire action space and interior content to generate the structured code using a fine-tuned LLM.Upon the successful execution and verification of the generated code blocks, they are stored as a new interface in the personal API library in the form of (Task, API) for future use.If verification fails, the reflection unit is activated to generate new code blocks [Shinn et al., 2023].</p>
<p>Simultaneously, we also collect the paired prompt and generated code as a training set for fine-tuning code generation LLM [Patil et al., 2023].After the successful execution and verification, the results are fed back through RLHF to enhance the model's capabilities.</p>
<p>Personalities</p>
<p>The role of distinct personalities is vital in enhancing the cognitive capabilities of language agents in role-playing.</p>
<p>Aligning variable personalities permits language models to better comprehend different perspectives and portray various cultures and social groups.Language models acting out different roles in complex scenarios must deeply understand, respond, and express in their unique ways.This necessitates the models to human-like thought processes with a wide range of personalities.Understanding the generation of diverse language expressions, handling multicultural content, and exhibiting varied thoughts, perspectives, emotions, and attitudes -all demand the model to accommodate these distinct personalities.Therefore, this section will delve into its implementation.</p>
<p>LARP adopts the strategy of simulating a cluster of models fine-tuned with various alignments to tackle the agents' diversified viewpoints.These models might be applied in different modules.During the training phase, we pre-trained several base models of different scales.Our pretraining datasets contain perspectives of different cultures and groups.</p>
<p>After pre-training, these base models undergo supervised fine-tuning (SFT) on a series of instruction datasets of persona and character to enhance instruction-following and role-playing capabilities [Chen et al., 2023b, Dong et al., 2023].This instruction dataset was established through data distillation based on question-answer pairs generated by SOTA models.Then, the dataset was optimized via assessment, modification, and adjustment based on human feedback.</p>
<p>It is possible to create multiple datasets and fine-tune LoRAs (Low-Rank Adaption) for capabilities such as reflection, code generation, and intent analysis.These LoRAs can be dynamically integrated with base models of different scales, creating a model cluster with diverse capabilities and personalities.These capabilities cover tasks such as language style, emotion, action generation, reflection, memory reconstruction, and more.</p>
<p>However, one of the main challenges in fine-tuning language models to construct different LoRAs for role-playing is acquiring quality data.Successful fine-tuning requires custom datasets of high quality, which need to be carefully constructed to capture various aspects of characters, including their language style, behavior style, personality traits, idioms, backstories, and more.The construction of datasets requires extensive literary creativity, script compilation, and character research to ensure that the generated language not only fits the character's persona and features but also interacts with the user in an appropriate manner [Wang et al., 2023b].</p>
<p>To enrich the diversity of the agent, we set up several post-processing modules, including the action verification module and the conflict identification module.The action verification module is part of the environment interaction module, which checks whether the generated actions can be correctly executed in the game.Conversely, within the cognitive architecture, the conflict identification module checks whether the decisions and conversations encompass conflicts with character relationships, personalities, and game worldview.When such conflicts are detected, the module will undertake actions like rejecting the result or rewriting it to prevent the agent from going out of character.</p>
<p>6 Discussions</p>
<p>Multi-Agent Cooperation and Agent Socialization</p>
<p>A single Language Agent role-playing under the framework proposed in this work is insufficient to solve the issue of creating rich content in open-world games.To bring each character supported by an Agent to life, a robust social network needs to be established.One possible approach is to build suitable sociological mechanisms and behaviors atop the large language model-driven agents to ensure that NPCs can still maintain their rationality and logic after extensive role-playing reasoning.</p>
<p>Confidence of Model Clusters vs. Evaluation and Feedback System</p>
<p>Combining language models and cognitive science makes language agents align more closely with genuine human cognition.This method effectively mitigates the problem of a single large model's inability to enhance role-playing outcomes due to insufficient data.Simultaneously, since the cognitive system only consists of domain tasks, fine-tuned small-scale models can achieve satisfactory performance.It saves costs compared to fine-tuning large models.However, due to the randomness of language model output results, it's unpredictable how the cumulative distortion of the results produced by each task affects the distortion of the entire cognitive architecture.It's hard to say such a distorted agent could be called a human-believable agent.Therefore, a corresponding evaluation and a measurement framework are needed to impose constraints and convergence on the distortion of the cognitive system.Establishing a measurement and feedback mechanism for the entire system to measure the logical deviation of each logic unit can optimize system robustness and minimize the impact of single-system distortion on the overall system.</p>
<p>Conclusion</p>
<p>In this study, we present a language agent framework-oriented open-world games and elaborate on this framework from three aspects: cognitive architecture, environmental interaction, and alignment with diverse value perspectives.</p>
<p>Addressing cognitive architecture, we employ more intricate techniques from cognitive science to enable the agent to make more reasonable decisions, alongside implementing post-processing constraints to prevent undue freedom in the agent, thereby bringing them closer to real human behavior in role-playing contexts.We envisage that our work harbors tremendous potential within the open-world games, breathing new life into this traditional domain, and ultimately catering the experience akin to that of 'Westworld'.</p>
<p>Figure 1 :
1
Figure 1: Cognitive Architecture of LARP Overview.</p>
<p>Figure 4 :
4
Figure 4: Environment Interaction.</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>. OpenAI. Gpt-4 technical report. 2023</p>
<p>Artificial intelligence a modern approach. J Stuart, Peter Russell, Norvig, 2010London</p>
<p>Intelligent agents: Theory and practice. Michael Wooldridge, Nicholas R Jennings, The knowledge engineering review. 1021995</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, arXiv:2308.11432arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023a. 2023arXiv preprint</p>
<p>Shunyu Theodore R Sumers, Karthik Yao, Thomas L Narasimhan, Griffiths, arXiv:2309.02427Cognitive architectures for language agents. 2023arXiv preprint</p>
<p>Playing text-based games with common sense. Sahith Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, Mark O Riedl, arXiv:2012.027572020arXiv preprint</p>
<p>Pre-trained language models as prior knowledge for playing text-based games. Ishika Singh, Gargi Singh, Ashutosh Modi, arXiv:2107.084082021arXiv preprint</p>
<p>Reading and acting while blindfolded: The need for semantics in text game agents. Shunyu Yao, Karthik Narasimhan, Matthew Hausknecht, arXiv:2103.135522021arXiv preprint</p>
<dl>
<dt>Learning to speak and act in a fantasy text adventure game. Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rocktäschel, Douwe Kiela, Arthur Szlam, Jason Weston, arXiv:1903.030942019arXiv preprint</dt>
<dd>
<p>Openai, Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Debiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael Petrov, Henrique P D O Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan Zhang. Dota 2 with large scale deep reinforcement learning. 2019</p>
</dd>
</dl>
<p>Alphastar: An evolutionary computation perspective. Kai Arulkumaran, Antoine Cully, Julian Togelius, Proceedings of the genetic and evolutionary computation conference companion. the genetic and evolutionary computation conference companion2019</p>
<p>Agentsims: An open-source sandbox for large language model evaluation. Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, Qin Chen, arXiv:2308.040262023arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>Zekun Moore, Wang , Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, arXiv:2310.00746Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. 2023barXiv preprint</p>
<p>Character-llm: A trainable agent for role-playing. Yunfan Shao, Linyang Li, Junqi Dai, Xipeng Qiu, arXiv:2310.101582023arXiv preprint</p>
<p>Role play with large language models. Murray Shanahan, Kyle Mcdonell, Laria Reynolds, ; Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, M I Weishi, Yaying Fei, Xiaoyang Feng, Song Yan, Haosheng Wang, arXiv:2308.09597Reviving anime character in reality via large language model. 2023. 2023aarXiv preprint</p>
<p>Camel: Communicative agents for" mind" exploration of large scale language model society. Guohao Li, Hasan Abed, Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem ; Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, Haoyang Zhang, arXiv:2303.17760arXiv:2310.08067Gamegpt: Multi-agent collaborative framework for game development. 2023b. 2023aarXiv preprint</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 2023arXiv preprint</p>
<p>Yuan Li, Yixuan Zhang, Lichao Sun, Metaagents, arXiv:2310.06500Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents. 2023carXiv preprint</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation framework. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang, arXiv:2308.081552023arXiv preprint</p>
<p>Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Ji-Rong Wen, arXiv:2306.02552Recagent: A novel simulation paradigm for recommender systems. 2023carXiv preprint</p>
<p>Training socially aligned language models in simulated human society. Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge Zhang, Denny Zhou, Andrew M Dai, Diyi Yang, Soroush Vosoughi, arXiv:2305.169602023aarXiv preprint</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, arXiv:2305.191182023arXiv preprint</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu, arXiv:2308.07201Chateval: Towards better llm-based evaluators through multi-agent debate. 2023arXiv preprint</p>
<p>Textworld: A learning environment for text-based games. Marc-Alexandre Côté, Akos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada, Computer Games: 7th Workshop, CGW 2018, Held in Conjunction with the 27th International Conference on Artificial Intelligence, IJCAI 2018. Revised Selected Papers. Stockholm, SwedenSpringerJuly 13. 2018. 20197</p>
<p>Interactive fiction games: A colossal adventure. Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Côté, Xingdi Yuan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, Yitao Liang, arXiv:2302.015602023darXiv preprint</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, arXiv:2305.162912023earXiv preprint</p>
<p>Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory. Xizhou Zhu, Yuntao Chen, Chenxin Hao Tian, Weijie Tao, Chenyu Su, Gao Yang, Bin Huang, Lewei Li, Xiaogang Lu, Wang, arXiv:2305.171442023arXiv preprint</p>
<p>Llm-powered autonomous agents. lilianweng.github.io. Lilian Weng, Jun 2023</p>
<p>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao, Chatdb, arXiv:2306.03901Augmenting llms with databases as their symbolic memory. 2023arXiv preprint</p>
<p>Wanjun Zhong, Lianghong Guo, Qiqi Gao, Yanlin Wang, arXiv:2305.10250Memorybank: Enhancing large language models with long-term memory. 2023arXiv preprint</p>
<p>Memory sandbox: Transparent and interactive memory management for conversational agents. Ziheng Huang, Sebastian Gutierrez, Hemanth Kamana, Stephen Macneil, Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. 2023</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, Peter Stone, arXiv:2304.11477Llm+ p: Empowering large language models with optimal planning proficiency. 2023barXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Chain of hindsight aligns language models with feedback. Hao Liu, Carmelo Sferrazza, Pieter Abbeel, arXiv:2302.026762023c3arXiv preprint</p>
<p>Plan-andsolve prompting: Improving zero-shot chain-of-thought reasoning by large language models. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy , Ka-Wei Lee, Ee-Peng Lim, arXiv:2305.040912023farXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, arXiv:2303.176512023arXiv preprint</p>
<p>Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, arXiv:2112.09332Browser-assisted question-answering with human feedback. 2021arXiv preprint</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, arXiv:2302.04761Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. 2023arXiv preprint</p>
<p>The Soar cognitive architecture. John E , Laird , 2019MIT press</p>
<p>Episodic and semantic memory. Organization of memory, 1(381-403):1, 1972. Henry L Roediger. Implicit memory: Retention without remembering. Endel Tulving, American psychologist. 45910431990</p>
<p>Working memory: looking back and looking forward. Alan Baddeley, Nature reviews neuroscience. 4102003</p>
<p>Plans and the structure of behaviour. George A Miller, Eugene Galanter, Karl H Pribram, Systems Research for Behavioral Science. Routledge2017</p>
<p>Human memory: A proposed system and its control processes. C Richard, Richard M Atkinson, Shiffrin, Psychology of learning and motivation. Elsevier19682</p>
<p>The magical number seven, plus or minus two: Some limits on our capacity for processing information. George A Miller, Psychological review. 632811956</p>
<p>Implications of short-term memory for a general theory of memory. Arthur W Melton, Journal of verbal Learning and verbal Behavior. 211963</p>
<p>Lionel Wong, Gabriel Grand, Alexander K Lew, Noah D Goodman, K Vikash, Jacob Mansinghka, Joshua B Andreas, Tenenbaum, arXiv:2306.12672From word models to world models: Translating from natural language to the probabilistic language of thought. 2023arXiv preprint</p>
<p>Remembering: A study in experimental and social psychology. Frederic Charles, Bartlett , arXiv:2210.03350Measuring and narrowing the compositionality gap in language models. Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike LewisOfir Press1995. 2022arXiv preprint</p>
<p>Reconstruction of automobile destruction: An example of the interaction between language and memory. F Elizabeth, John C Loftus, Palmer, Journal of verbal learning and verbal behavior. 1351974</p>
<p>The wickelgren power law and the ebbinghaus savings function. T John, Shana K Wixted, Carpenter, Psychological Science. 1822007</p>
<p>Octopus: Embodied vision-language programmer from environmental feedback. Jingkang Yang, Yuhao Dong, Shuai Liu, Bo Li, Ziyue Wang, Chencheng Jiang, Haoran Tan, Jiamu Kang, Yuanhan Zhang, Kaiyang Zhou, arXiv:2310.085882023arXiv preprint</p>
<p>Tianjun Shishir G Patil, Xin Zhang, Joseph E Wang, Gonzalez, arXiv:2305.15334Gorilla: Large language model connected with massive apis. 2023arXiv preprint</p>
<p>Maybe only 0.5% data is needed: A preliminary exploration of low training data instruction tuning. Yiming Hao Chen, Qi Zhang, Hantao Zhang, Xiaomeng Yang, Xuetao Hu, Yifan Ma, Junbo Yanggong, Zhao, arXiv:2305.092462023barXiv preprint</p>
<p>How abilities in large language models are affected by supervised fine-tuning data composition. Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou, arXiv:2310.054922023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>