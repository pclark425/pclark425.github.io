<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2510 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2510</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2510</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-272101940</p>
                <p><strong>Paper Title:</strong> Artificial intelligence for geoscience: Progress, challenges, and perspectives</p>
                <p><strong>Paper Abstract:</strong> This paper explores the evolution of geoscientific inquiry, tracing the progression from traditional physics-based models to modern data-driven approaches facilitated by significant advancements in artificial intelligence (AI) and data collection techniques. Traditional models, which are grounded in physical and numerical frameworks, provide robust explanations by explicitly reconstructing underlying physical processes. However, their limitations in comprehensively capturing Earth’s complexities and uncertainties pose challenges in optimization and real-world applicability. In contrast, contemporary data-driven models, particularly those utilizing machine learning (ML) and deep learning (DL), leverage extensive geoscience data to glean insights without requiring exhaustive theoretical knowledge. ML techniques have shown promise in addressing Earth science-related questions. Nevertheless, challenges such as data scarcity, computational demands, data privacy concerns, and the “black-box” nature of AI models hinder their seamless integration into geoscience. The integration of physics-based and data-driven methodologies into hybrid models presents an alternative paradigm. These models, which incorporate domain knowledge to guide AI methodologies, demonstrate enhanced efficiency and performance with reduced training data requirements. This review provides a comprehensive overview of geoscientific research paradigms, emphasizing untapped opportunities at the intersection of advanced AI techniques and geoscience. It examines major methodologies, showcases advances in large-scale models, and discusses the challenges and prospects that will shape the future landscape of AI in geoscience. The paper outlines a dynamic field ripe with possibilities, poised to unlock new understandings of Earth’s complexities and further advance geoscience exploration.</p>
                <p><strong>Cost:</strong> 0.034</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2510.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2510.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VAE-geo-hypothesis-optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Autoencoder-based Geo-hypothesis Optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that maps discrete symbolic geo-hypotheses into a differentiable latent space using variational autoencoders to enable gradient-based optimization and screening of candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>VAE-based discrete geo-hypothesis optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses a variational autoencoder (VAE) to encode discrete symbolic representations of geoscientific hypotheses into a continuous differentiable latent space, enabling optimization (e.g., via gradient methods) and multi-objective screening of candidate hypotheses; described in the review as an approach to optimize discrete geo-hypotheses by mapping them into differentiable representations.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>neural-symbolic (VAE embedding of symbolic space)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>geoscience (general; hydrology and Earth system hypotheses mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Encodes discrete symbolic hypothesis candidates into a continuous latent space with a VAE, then explores/optimizes in that latent space (e.g., gradient-based or multi-objective optimization) to propose candidate hypotheses with desirable attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Only described conceptually in the review; no implementation details, benchmark results, or evaluation protocols provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2510.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Differentiable-modelling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Process-based Differentiable Modeling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach that makes process-based (physics) models differentiable and couples them with machine learning components, enabling gradient-based training, hypothesis testing, and discovery of previously unrecognized correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Process-based differentiable modeling</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines mechanistic (process-based) models with differentiable ML modules so that the entire system is end-to-end differentiable; allows ML components to be trained jointly with physics-based components and supports hypothesis testing by optimizing differentiable representations of processes.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>physics-informed / differentiable hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>geoscience (climate, hydrology, Earth system modeling)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enables automated exploration of model parameterizations and structural alternatives by allowing gradients to inform adjustments to physics-informed components and data-driven modules; can expose correlations via learned differentiable mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is supported by embedding physical constraints/mechanisms into model structure and loss functions (regularization toward physically plausible outputs), as described in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Approach aims to retain physical plausibility via embedded constraints while using ML flexibility to discover novel mappings; the review warns that AI components can overwrite physical interpretability if not carefully balanced.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Facilitates in-silico hypothesis verification via the differentiable hybrid model (model-data-driven testing); specific experimental validation protocols not provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Embedding physical laws/differential equations and physical constraints into loss functions to regularize outputs and reduce physically implausible predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>The review highlights risks: AI parameterizations can learn incorrect behaviors and overwrite physical interpretability; scaling hybrid models can magnify structural deficiencies in physics components.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2510.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Guess-and-Verify-AI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Guess-and-Verify AI Paradigm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-level AI approach where models propose candidate hypotheses (guesses) from data patterns and then verify them against data, simulations, or constraints (verify), enabling discovery in domains like protein structure or mathematics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Guess-and-verify AI paradigm</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An iterative methodology in which AI systems generate candidate scientific hypotheses (guesses) based on patterns learned from large datasets and then verify them using data-driven checks, simulations, or formal verification procedures; the review cites examples such as protein structure prediction and automated theorem proving as successes of this paradigm.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>general paradigm (can be LLM-based, generative + verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific discovery (protein structure, mathematics, geoscience hypothesis generation)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generative models (including large models) propose candidate hypotheses from learned distributions; generation is guided by reward/verification signals or constrained by domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Verification step: candidate hypotheses are tested against data, simulations, or domain constraints to assess plausibility (review-level description).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>The paradigm balances novelty (generation encourages novel candidates) and plausibility (verification filters candidates using data/physics), but explicit optimization trade-offs are not specified in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>In-silico verification using data consistency checks, simulations, or formal proof systems; the review cites this general approach but gives no unified validation protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Verification stage to filter implausible/hallucinated outputs using data/simulations/physical constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Review cites broad successes of the paradigm (e.g., protein structure prediction, automated theorem proving) but not specific geoscience-validated novel discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High-level paradigm described; specific implementations, failure modes, and quantitative evaluation methods are not detailed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2510.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RL-hypothesis-verification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforcement Learning for Hypothesis Verification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using reinforcement learning agents to empirically verify scientific hypotheses by interacting with environments or simulators and maximizing verification-oriented reward signals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Empirically verifying hypotheses using reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reinforcement learning hypothesis verifier</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An RL framework where agents explore hypothesis-space actions within an environment or simulator and receive rewards tied to verification outcomes, enabling automated empirical testing and selection of hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>reinforcement learning (experiment/simulation-in-the-loop)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general (method referenced as applicable to scientific hypothesis testing)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Exploration policy in RL generates candidate hypothesis-driven experiments/interventions; reward signals favor hypotheses that produce expected/verifiable outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical/simulation interactions that produce observations used to accept/reject hypotheses via reward feedback; details in referenced work rather than in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Referenced in review only; no implementation or empirical results provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2510.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepSymbolicRegression</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Symbolic Regression via Policy Gradients</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-symbolic method that recovers mathematical expressions from data using risk-seeking policy gradient reinforcement learning to search the space of symbolic formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep symbolic regression (policy-gradient based)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses neural policy-gradient optimization (risk-seeking variants) to search a space of symbolic expressions and fit data, effectively generating candidate governing equations or analytic hypotheses directly from data.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>neural-symbolic / reinforcement search over symbolic space</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general (equation discovery; applicable to geoscience dynamical systems)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Search/learn symbolic expressions via policy-gradient RL that proposes expressions and is rewarded by fit-to-data / complexity trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility judged by fit to data and parsimony (implicit via reward/cost); details in referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Typically uses error/fit metrics and expression complexity for selection (review references the method but does not list exact metrics here).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Validation by measuring data fit and (in original works) potentially cross-validation; review does not provide the protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Referenced as a method for converting data to interpretable analytic expressions; review does not provide domain-specific limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2510.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SINDy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse Identification of Nonlinear Dynamical Systems (SINDy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sparse-regression approach to discover governing differential equations from measurement data by selecting a sparse set of basis functions that explain dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discovering governing equations from data by sparse identification of nonlinear dynamical systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SINDy (sparse identification)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a library of candidate nonlinear terms and uses sparse regression to identify a small set of terms that accurately reconstruct observed dynamics, producing interpretable governing equations.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>sparse-regression / symbolic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>dynamical systems, geoscience (for discovering governing PDE/ODE forms)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate governing equations by selecting sparse combinations from a predefined function library fitted to dynamics data.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility supported by parsimonious selection and fit-to-data; physical interpretability arises from the functional terms chosen.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Fit-to-data error metrics and sparsity (number of terms) are used in the original method; review references the approach without detailed metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Model cross-validation and comparison to known physics where available (not detailed in this review).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on choice of function library and quality of measurements; review does not expand on limitations beyond citation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2510.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GraphCast</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GraphCast (Graph Neural Network Weather Forecaster)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph neural network based medium-range global weather forecasting model that learns spatiotemporal relationships to predict weather evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GraphCast</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A large-scale graph neural network architecture for global medium-range weather forecasting that captures spatial relationships via graph structures and temporal evolution to produce forecasts up to weeks; discussed as a leading large AI model in weather/climate.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>GNN-based large model</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / weather forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Model validation via forecast skill assessments against ground truth reanalyses/observations (implied in the review but not specified numerically).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Described qualitatively as able to accurately predict weather evolution on timescales of several days to a month; specific numeric metrics are not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Review notes that large data-driven models (including GraphCast) still face challenges for seasonal forecasts and extreme-event prediction; specific limitations are not quantified here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2510.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pangu-Weather</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pangu-Weather (Pangu / PanGu-Weather)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 3D Transformer-based global weather forecasting model providing fast, accurate medium-range forecasts, reported to be orders of magnitude faster than traditional numerical models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Pangu-Weather</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A 3D Earth-specific Transformer architecture trained on large-scale weather data to produce medium-range global forecasts with high timeliness and substantial computational acceleration relative to traditional numerical weather prediction systems.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>3D Transformer large model</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / weather forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Forecast skill evaluation against operational systems (review states comparative timing/efficiency with ECMWF).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Claimed in the review: predicts 7 days' weather in ~10 seconds and achieves timeliness 0.6 days earlier than ECMWF (as reported in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared qualitatively to ECMWF (operational numerical forecast); review asserts superior timeliness and competitive accuracy but does not provide detailed skill-score comparisons here.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Review cautions that large purely data-driven models may risk losing physical plausibility when scaling and that challenges remain for seasonal and extreme-event forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2510.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FourCastNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FourCastNet (Fourier Neural Operator based Forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-resolution global weather forecasting model that applies Fourier neural operators to provide fast and accurate short-to-medium range forecasts, with notable improvements on precipitation forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>FourCastNet</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FourCastNet</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Employs Fourier-based neural operators (Fourier Neural Operator style architectures) to learn spatiotemporal mappings for fast global weather prediction; designed for immediate accurate short-to-medium-range forecasts.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Fourier neural operator / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / weather forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Forecast skill comparison with existing forecasting systems (review states substantial advantages across multiple performance indicators).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Review reports FourCastNet's accuracy surpasses other models on precipitation by >20% (statement in review); exact metric names/values not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Reported to outperform comparable models on precipitation prediction by the review's summary (>20% improvement reported).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>As with other large data-driven models, limitations include challenges in longer time-scale forecasting and ensuring physical plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2510.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GenCast</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GenCast (Diffusion-based Generative Ensemble Forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A diffusion-model-based generative framework for global medium-range ensemble weather forecasting that samples ensembles of plausible future weather trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GenCast: Diffusion-based ensemble forecasting for medium-range weather</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GenCast</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses diffusion generative models to sample ensembles of possible future weather states, enabling ensemble forecasting up to ~15 days by drawing from learned distributions over trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>generative diffusion model (ensemble forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / ensemble weather forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility enforced by conditioning on past observations and sampling from the learned distribution of future trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Ensemble forecast evaluation comparing sampled ensembles to observed outcomes (implied; review does not give numeric metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Implicit via ensemble sampling from the diffusion model (provides probabilistic ensembles representing forecast uncertainty).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Review notes that ensemble and probabilistic forecasting are promising but that challenges remain for extreme event and long-term forecasts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2510.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetNet (Probabilistic Deep Neural Weather Model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic deep learning weather model (MetNet series) employing architectures like U-Net and Vision Transformers to produce high-resolution probabilistic precipitation and weather forecasts up to ~12-24 h or longer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetNet (MetNet-2 / MetNet-3)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Deep neural architectures combining U-Net and Transformer components trained to generate probabilistic forecasts of precipitation and other variables with high spatial/temporal resolution; explicitly probabilistic in outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic deep neural network (U-Net + ViT)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / short-term forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Probabilistic forecast evaluation (implied; review notes MetNet-2 forecasts precipitation probabilistically with exceptional resolution).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Probabilistic outputs (predictive distributions) enabling uncertainty quantification; referenced as probabilistic deep learning.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>MetNet-2 cited as forecasting precipitation up to 12 h ahead with exceptional resolution; MetNet-3 extends high-resolution predictions up to 24 h (review-level statements without numeric scores).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Primarily short-term probabilistic forecasting; seasonal and long-range uncertainty remain challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2510.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NowcastNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NowcastNet (Physics-Conditional Generative Nowcasting)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonlinear nowcasting model that unifies physical-evolution schemes and conditional generative learning in a neural network to skillfully nowcast extreme precipitation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NowcastNet</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NowcastNet</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A physics-conditional generative neural network that integrates physical evolution modeling with conditional generative learning to produce skillful nowcasts of extreme precipitation phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>physics-conditional generative network</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science / extreme precipitation nowcasting</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Incorporates physical-evolution schemes to keep outputs consistent with underlying dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Nowcasting skill evaluation against observations; review references NowcastNet's capability for advective/convective extremes.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Physical conditioning / embedding of evolution schemes to reduce implausible outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Effective for short-term extremes; long-range or seasonal forecasting challenges remain.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2510.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>K2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>K2 (Earth Science Language Model, LLaMA-7B-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7-billion-parameter Earth science language model constructed via pre-training on Earth science corpora and instruction fine-tuning with geosignal datasets to support geoscience knowledge understanding and utilization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>K2: A foundation language model for geoscience knowledge understanding and utilization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>K2 (Earth science LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A large language model (LLM) adapted for Earth science: two-stage process with pre-training on high-quality Earth science corpus followed by instruction fine-tuning on geosignal datasets to specialize model responses for geoscientific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based (foundation language model)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>geoscience / cross-domain Earth science tasks</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>LLM generative capabilities used to propose hypotheses, interpret data, and suggest research directions when prompted; review suggests foundation LLMs can help generate plausible hypotheses and research directions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human-in-the-loop expert review and downstream task evaluations (implied in review discussing human-in-loop and instruction fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Pre-trained on curated Earth science corpora and geosignal datasets (review-level description; no specific public benchmark named).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Development constrained by dataset access, compute resources, and risks of losing physical constraints if not properly guided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e2510.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HydroPML</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HydroPML (Physics-aware ML Platform for Hydrology)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hydrology foundation platform built on physics-aware machine learning to bridge large language/model approaches and process-based hydrology for applications such as rainfall-runoff and real-time flood forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>HydroPML</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HydroPML</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A physics-aware ML foundation aimed at hydrological applications; integrates process knowledge into ML workflows to support tasks like rainfall-runoff-inundation modeling, real-time flood forecasting, and improved water security decision support.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>physics-informed foundation model / platform</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>hydrology / flood forecasting / water resources</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Physical awareness (embedding process knowledge) intended to improve plausibility of ML outputs relative to purely data-driven models.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Application-specific evaluation (e.g., rainfall-runoff and flood forecasting skill assessments) implied; not detailed in review.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Embedding physics/process knowledge to regularize ML and reduce implausible results.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Challenges include dataset access, computing resources, and balancing ML flexibility with physical interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e2510.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SpectralGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SpectralGPT (Spectral Remote Sensing Foundation Model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large ViT-based foundation model customized for spectral remote sensing data, pre-trained for multi-objective spectral reconstruction and downstream remote sensing tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SpectralGPT</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SpectralGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A Vision-Transformer (ViT) style foundation model pre-trained on spectral remote sensing sequences (multi-objective reconstruction) with >600M parameters to support a range of downstream remote sensing tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>vision-transformer foundation model (multimodal remote sensing)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>remote sensing / Earth observation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Performance on downstream remote-sensing tasks (classification, segmentation, reconstruction) implied; no hypothesis-specific validation described.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Described as achieving state-of-the-art performance on various downstream tasks for spectral remote sensing (no numeric metrics provided in review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Designed for remote sensing tasks; not specifically a hypothesis-generation or scientific-reasoning system.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e2510.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DiffusionSat/CRS-Diff</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DiffusionSat / CRS-Diff (Diffusion-based Generative Remote Sensing Models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large diffusion-model-based generative systems for satellite data completion, multimodal generation, and controllable remote sensing image synthesis to fill gaps and enhance observational records.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DiffusionSat</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DiffusionSat / CRS-Diff</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Large diffusion generative models trained on satellite/remote sensing data to perform tasks like inpainting, multimodal generation, and controllable synthesis for data completion and enhancement in spatiotemporal and spectral dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>generative diffusion models</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>remote sensing / geoscience data reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility achieved by conditioning on observed modalities and multimodal constraints; specific mechanisms not detailed in review.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Qualitative and quantitative reconstruction/forecasting evaluation for data completion tasks (review cites cases such as reconstructing historical meteorological patterns).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Generative models can produce ensembles/samples representing uncertainty implicitly; review does not detail explicit UQ protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Examples include reconstruction of historical meteorological information (e.g., inpainting El Niño spatial patterns in historical records) cited in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Generative models may introduce plausible but unverified reconstructions (risk of hallucinated data) if not constrained by physical priors; review stresses need for careful application.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2510.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e2510.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Probabilistic-deep-learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Deep Learning for Geoscience Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of deep learning approaches that produce probabilistic predictive distributions (instead of point estimates) for variables such as precipitation and sea ice, enabling explicit uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Seasonal Arctic sea ice forecasting with probabilistic deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Probabilistic deep learning forecasting models</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Deep neural networks trained to output predictive probability distributions (e.g., via direct probabilistic modeling, ensembles, or generative sampling) for geoscientific variables, supporting quantification of forecast uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic deep learning / ensemble / generative</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>atmospheric science, cryosphere, hydrology</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Probabilistic forecast verification metrics (e.g., ensemble spread vs. error, calibration) are implied though not enumerated in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Explicit predictive distributions via probabilistic neural outputs, ensembles, or generative sampling; review cites MetNet-2 and probabilistic sea-ice forecasts as examples.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Probabilistic models help quantify uncertainty but challenges remain in calibration and long-range (seasonal/decadal) uncertainty representation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial intelligence for geoscience: Progress, challenges, and perspectives', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Empirically verifying hypotheses using reinforcement learning <em>(Rating: 2)</em></li>
                <li>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients <em>(Rating: 2)</em></li>
                <li>Discovering governing equations from data by sparse identification of nonlinear dynamical systems <em>(Rating: 2)</em></li>
                <li>Accurate medium-range global weather forecasting with 3D neural networks <em>(Rating: 2)</em></li>
                <li>FourCastNet: A global data-driven high-resolution weather model using adaptive Fourier neural operators <em>(Rating: 2)</em></li>
                <li>Differentiable modelling to unify machine learning and physical models for geosciences <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2510",
    "paper_id": "paper-272101940",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "VAE-geo-hypothesis-optimizer",
            "name_full": "Variational Autoencoder-based Geo-hypothesis Optimizer",
            "brief_description": "A method that maps discrete symbolic geo-hypotheses into a differentiable latent space using variational autoencoders to enable gradient-based optimization and screening of candidate hypotheses.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "VAE-based discrete geo-hypothesis optimizer",
            "system_description": "Uses a variational autoencoder (VAE) to encode discrete symbolic representations of geoscientific hypotheses into a continuous differentiable latent space, enabling optimization (e.g., via gradient methods) and multi-objective screening of candidate hypotheses; described in the review as an approach to optimize discrete geo-hypotheses by mapping them into differentiable representations.",
            "system_type": "neural-symbolic (VAE embedding of symbolic space)",
            "scientific_domain": "geoscience (general; hydrology and Earth system hypotheses mentioned)",
            "hypothesis_generation_method": "Encodes discrete symbolic hypothesis candidates into a continuous latent space with a VAE, then explores/optimizes in that latent space (e.g., gradient-based or multi-objective optimization) to propose candidate hypotheses with desirable attributes.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Only described conceptually in the review; no implementation details, benchmark results, or evaluation protocols provided here.",
            "uuid": "e2510.0",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Differentiable-modelling",
            "name_full": "Process-based Differentiable Modeling",
            "brief_description": "A hybrid approach that makes process-based (physics) models differentiable and couples them with machine learning components, enabling gradient-based training, hypothesis testing, and discovery of previously unrecognized correlations.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Process-based differentiable modeling",
            "system_description": "Combines mechanistic (process-based) models with differentiable ML modules so that the entire system is end-to-end differentiable; allows ML components to be trained jointly with physics-based components and supports hypothesis testing by optimizing differentiable representations of processes.",
            "system_type": "physics-informed / differentiable hybrid",
            "scientific_domain": "geoscience (climate, hydrology, Earth system modeling)",
            "hypothesis_generation_method": "Enables automated exploration of model parameterizations and structural alternatives by allowing gradients to inform adjustments to physics-informed components and data-driven modules; can expose correlations via learned differentiable mappings.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is supported by embedding physical constraints/mechanisms into model structure and loss functions (regularization toward physically plausible outputs), as described in the review.",
            "novelty_plausibility_balance": "Approach aims to retain physical plausibility via embedded constraints while using ML flexibility to discover novel mappings; the review warns that AI components can overwrite physical interpretability if not carefully balanced.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Facilitates in-silico hypothesis verification via the differentiable hybrid model (model-data-driven testing); specific experimental validation protocols not provided in the review.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Embedding physical laws/differential equations and physical constraints into loss functions to regularize outputs and reduce physically implausible predictions.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "The review highlights risks: AI parameterizations can learn incorrect behaviors and overwrite physical interpretability; scaling hybrid models can magnify structural deficiencies in physics components.",
            "uuid": "e2510.1",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Guess-and-Verify-AI",
            "name_full": "Guess-and-Verify AI Paradigm",
            "brief_description": "A high-level AI approach where models propose candidate hypotheses (guesses) from data patterns and then verify them against data, simulations, or constraints (verify), enabling discovery in domains like protein structure or mathematics.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Guess-and-verify AI paradigm",
            "system_description": "An iterative methodology in which AI systems generate candidate scientific hypotheses (guesses) based on patterns learned from large datasets and then verify them using data-driven checks, simulations, or formal verification procedures; the review cites examples such as protein structure prediction and automated theorem proving as successes of this paradigm.",
            "system_type": "general paradigm (can be LLM-based, generative + verifier)",
            "scientific_domain": "general scientific discovery (protein structure, mathematics, geoscience hypothesis generation)",
            "hypothesis_generation_method": "Generative models (including large models) propose candidate hypotheses from learned distributions; generation is guided by reward/verification signals or constrained by domain knowledge.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Verification step: candidate hypotheses are tested against data, simulations, or domain constraints to assess plausibility (review-level description).",
            "novelty_plausibility_balance": "The paradigm balances novelty (generation encourages novel candidates) and plausibility (verification filters candidates using data/physics), but explicit optimization trade-offs are not specified in the review.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "In-silico verification using data consistency checks, simulations, or formal proof systems; the review cites this general approach but gives no unified validation protocol.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Verification stage to filter implausible/hallucinated outputs using data/simulations/physical constraints.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": "Review cites broad successes of the paradigm (e.g., protein structure prediction, automated theorem proving) but not specific geoscience-validated novel discoveries.",
            "limitations": "High-level paradigm described; specific implementations, failure modes, and quantitative evaluation methods are not detailed in the review.",
            "uuid": "e2510.2",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "RL-hypothesis-verification",
            "name_full": "Reinforcement Learning for Hypothesis Verification",
            "brief_description": "Using reinforcement learning agents to empirically verify scientific hypotheses by interacting with environments or simulators and maximizing verification-oriented reward signals.",
            "citation_title": "Empirically verifying hypotheses using reinforcement learning",
            "mention_or_use": "mention",
            "system_name": "Reinforcement learning hypothesis verifier",
            "system_description": "An RL framework where agents explore hypothesis-space actions within an environment or simulator and receive rewards tied to verification outcomes, enabling automated empirical testing and selection of hypotheses.",
            "system_type": "reinforcement learning (experiment/simulation-in-the-loop)",
            "scientific_domain": "general (method referenced as applicable to scientific hypothesis testing)",
            "hypothesis_generation_method": "Exploration policy in RL generates candidate hypothesis-driven experiments/interventions; reward signals favor hypotheses that produce expected/verifiable outcomes.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Empirical/simulation interactions that produce observations used to accept/reject hypotheses via reward feedback; details in referenced work rather than in this review.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Referenced in review only; no implementation or empirical results provided in this review.",
            "uuid": "e2510.3",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "DeepSymbolicRegression",
            "name_full": "Deep Symbolic Regression via Policy Gradients",
            "brief_description": "A neural-symbolic method that recovers mathematical expressions from data using risk-seeking policy gradient reinforcement learning to search the space of symbolic formulas.",
            "citation_title": "Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients",
            "mention_or_use": "mention",
            "system_name": "Deep symbolic regression (policy-gradient based)",
            "system_description": "Uses neural policy-gradient optimization (risk-seeking variants) to search a space of symbolic expressions and fit data, effectively generating candidate governing equations or analytic hypotheses directly from data.",
            "system_type": "neural-symbolic / reinforcement search over symbolic space",
            "scientific_domain": "general (equation discovery; applicable to geoscience dynamical systems)",
            "hypothesis_generation_method": "Search/learn symbolic expressions via policy-gradient RL that proposes expressions and is rewarded by fit-to-data / complexity trade-offs.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility judged by fit to data and parsimony (implicit via reward/cost); details in referenced work.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Typically uses error/fit metrics and expression complexity for selection (review references the method but does not list exact metrics here).",
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Validation by measuring data fit and (in original works) potentially cross-validation; review does not provide the protocol.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Referenced as a method for converting data to interpretable analytic expressions; review does not provide domain-specific limitations.",
            "uuid": "e2510.4",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "SINDy",
            "name_full": "Sparse Identification of Nonlinear Dynamical Systems (SINDy)",
            "brief_description": "A sparse-regression approach to discover governing differential equations from measurement data by selecting a sparse set of basis functions that explain dynamics.",
            "citation_title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems",
            "mention_or_use": "mention",
            "system_name": "SINDy (sparse identification)",
            "system_description": "Constructs a library of candidate nonlinear terms and uses sparse regression to identify a small set of terms that accurately reconstruct observed dynamics, producing interpretable governing equations.",
            "system_type": "sparse-regression / symbolic discovery",
            "scientific_domain": "dynamical systems, geoscience (for discovering governing PDE/ODE forms)",
            "hypothesis_generation_method": "Generates candidate governing equations by selecting sparse combinations from a predefined function library fitted to dynamics data.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility supported by parsimonious selection and fit-to-data; physical interpretability arises from the functional terms chosen.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Fit-to-data error metrics and sparsity (number of terms) are used in the original method; review references the approach without detailed metrics.",
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Model cross-validation and comparison to known physics where available (not detailed in this review).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Relies on choice of function library and quality of measurements; review does not expand on limitations beyond citation.",
            "uuid": "e2510.5",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GraphCast",
            "name_full": "GraphCast (Graph Neural Network Weather Forecaster)",
            "brief_description": "A graph neural network based medium-range global weather forecasting model that learns spatiotemporal relationships to predict weather evolution.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "GraphCast",
            "system_description": "A large-scale graph neural network architecture for global medium-range weather forecasting that captures spatial relationships via graph structures and temporal evolution to produce forecasts up to weeks; discussed as a leading large AI model in weather/climate.",
            "system_type": "GNN-based large model",
            "scientific_domain": "atmospheric science / weather forecasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Model validation via forecast skill assessments against ground truth reanalyses/observations (implied in the review but not specified numerically).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Described qualitatively as able to accurately predict weather evolution on timescales of several days to a month; specific numeric metrics are not provided in this review.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Review notes that large data-driven models (including GraphCast) still face challenges for seasonal forecasts and extreme-event prediction; specific limitations are not quantified here.",
            "uuid": "e2510.6",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Pangu-Weather",
            "name_full": "Pangu-Weather (Pangu / PanGu-Weather)",
            "brief_description": "A 3D Transformer-based global weather forecasting model providing fast, accurate medium-range forecasts, reported to be orders of magnitude faster than traditional numerical models.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Pangu-Weather",
            "system_description": "A 3D Earth-specific Transformer architecture trained on large-scale weather data to produce medium-range global forecasts with high timeliness and substantial computational acceleration relative to traditional numerical weather prediction systems.",
            "system_type": "3D Transformer large model",
            "scientific_domain": "atmospheric science / weather forecasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Forecast skill evaluation against operational systems (review states comparative timing/efficiency with ECMWF).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Claimed in the review: predicts 7 days' weather in ~10 seconds and achieves timeliness 0.6 days earlier than ECMWF (as reported in the review).",
            "comparison_with_baseline": "Compared qualitatively to ECMWF (operational numerical forecast); review asserts superior timeliness and competitive accuracy but does not provide detailed skill-score comparisons here.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Review cautions that large purely data-driven models may risk losing physical plausibility when scaling and that challenges remain for seasonal and extreme-event forecasting.",
            "uuid": "e2510.7",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "FourCastNet",
            "name_full": "FourCastNet (Fourier Neural Operator based Forecasting)",
            "brief_description": "A high-resolution global weather forecasting model that applies Fourier neural operators to provide fast and accurate short-to-medium range forecasts, with notable improvements on precipitation forecasting.",
            "citation_title": "FourCastNet",
            "mention_or_use": "mention",
            "system_name": "FourCastNet",
            "system_description": "Employs Fourier-based neural operators (Fourier Neural Operator style architectures) to learn spatiotemporal mappings for fast global weather prediction; designed for immediate accurate short-to-medium-range forecasts.",
            "system_type": "Fourier neural operator / deep learning",
            "scientific_domain": "atmospheric science / weather forecasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Forecast skill comparison with existing forecasting systems (review states substantial advantages across multiple performance indicators).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Review reports FourCastNet's accuracy surpasses other models on precipitation by &gt;20% (statement in review); exact metric names/values not provided here.",
            "comparison_with_baseline": "Reported to outperform comparable models on precipitation prediction by the review's summary (&gt;20% improvement reported).",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "As with other large data-driven models, limitations include challenges in longer time-scale forecasting and ensuring physical plausibility.",
            "uuid": "e2510.8",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GenCast",
            "name_full": "GenCast (Diffusion-based Generative Ensemble Forecasting)",
            "brief_description": "A diffusion-model-based generative framework for global medium-range ensemble weather forecasting that samples ensembles of plausible future weather trajectories.",
            "citation_title": "GenCast: Diffusion-based ensemble forecasting for medium-range weather",
            "mention_or_use": "mention",
            "system_name": "GenCast",
            "system_description": "Uses diffusion generative models to sample ensembles of possible future weather states, enabling ensemble forecasting up to ~15 days by drawing from learned distributions over trajectories.",
            "system_type": "generative diffusion model (ensemble forecasting)",
            "scientific_domain": "atmospheric science / ensemble weather forecasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility enforced by conditioning on past observations and sampling from the learned distribution of future trajectories.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Ensemble forecast evaluation comparing sampled ensembles to observed outcomes (implied; review does not give numeric metrics).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Implicit via ensemble sampling from the diffusion model (provides probabilistic ensembles representing forecast uncertainty).",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Review notes that ensemble and probabilistic forecasting are promising but that challenges remain for extreme event and long-term forecasts.",
            "uuid": "e2510.9",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "MetNet",
            "name_full": "MetNet (Probabilistic Deep Neural Weather Model)",
            "brief_description": "A probabilistic deep learning weather model (MetNet series) employing architectures like U-Net and Vision Transformers to produce high-resolution probabilistic precipitation and weather forecasts up to ~12-24 h or longer.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "MetNet (MetNet-2 / MetNet-3)",
            "system_description": "Deep neural architectures combining U-Net and Transformer components trained to generate probabilistic forecasts of precipitation and other variables with high spatial/temporal resolution; explicitly probabilistic in outputs.",
            "system_type": "probabilistic deep neural network (U-Net + ViT)",
            "scientific_domain": "atmospheric science / short-term forecasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Probabilistic forecast evaluation (implied; review notes MetNet-2 forecasts precipitation probabilistically with exceptional resolution).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Probabilistic outputs (predictive distributions) enabling uncertainty quantification; referenced as probabilistic deep learning.",
            "benchmark_dataset": null,
            "performance_metrics": "MetNet-2 cited as forecasting precipitation up to 12 h ahead with exceptional resolution; MetNet-3 extends high-resolution predictions up to 24 h (review-level statements without numeric scores).",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Primarily short-term probabilistic forecasting; seasonal and long-range uncertainty remain challenging.",
            "uuid": "e2510.10",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "NowcastNet",
            "name_full": "NowcastNet (Physics-Conditional Generative Nowcasting)",
            "brief_description": "A nonlinear nowcasting model that unifies physical-evolution schemes and conditional generative learning in a neural network to skillfully nowcast extreme precipitation.",
            "citation_title": "NowcastNet",
            "mention_or_use": "mention",
            "system_name": "NowcastNet",
            "system_description": "A physics-conditional generative neural network that integrates physical evolution modeling with conditional generative learning to produce skillful nowcasts of extreme precipitation phenomena.",
            "system_type": "physics-conditional generative network",
            "scientific_domain": "atmospheric science / extreme precipitation nowcasting",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Incorporates physical-evolution schemes to keep outputs consistent with underlying dynamics.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Nowcasting skill evaluation against observations; review references NowcastNet's capability for advective/convective extremes.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Physical conditioning / embedding of evolution schemes to reduce implausible outputs.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Effective for short-term extremes; long-range or seasonal forecasting challenges remain.",
            "uuid": "e2510.11",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "K2",
            "name_full": "K2 (Earth Science Language Model, LLaMA-7B-based)",
            "brief_description": "A 7-billion-parameter Earth science language model constructed via pre-training on Earth science corpora and instruction fine-tuning with geosignal datasets to support geoscience knowledge understanding and utilization.",
            "citation_title": "K2: A foundation language model for geoscience knowledge understanding and utilization",
            "mention_or_use": "mention",
            "system_name": "K2 (Earth science LLM)",
            "system_description": "A large language model (LLM) adapted for Earth science: two-stage process with pre-training on high-quality Earth science corpus followed by instruction fine-tuning on geosignal datasets to specialize model responses for geoscientific tasks.",
            "system_type": "LLM-based (foundation language model)",
            "scientific_domain": "geoscience / cross-domain Earth science tasks",
            "hypothesis_generation_method": "LLM generative capabilities used to propose hypotheses, interpret data, and suggest research directions when prompted; review suggests foundation LLMs can help generate plausible hypotheses and research directions.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Human-in-the-loop expert review and downstream task evaluations (implied in review discussing human-in-loop and instruction fine-tuning).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Pre-trained on curated Earth science corpora and geosignal datasets (review-level description; no specific public benchmark named).",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Development constrained by dataset access, compute resources, and risks of losing physical constraints if not properly guided.",
            "uuid": "e2510.12",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "HydroPML",
            "name_full": "HydroPML (Physics-aware ML Platform for Hydrology)",
            "brief_description": "A hydrology foundation platform built on physics-aware machine learning to bridge large language/model approaches and process-based hydrology for applications such as rainfall-runoff and real-time flood forecasting.",
            "citation_title": "HydroPML",
            "mention_or_use": "mention",
            "system_name": "HydroPML",
            "system_description": "A physics-aware ML foundation aimed at hydrological applications; integrates process knowledge into ML workflows to support tasks like rainfall-runoff-inundation modeling, real-time flood forecasting, and improved water security decision support.",
            "system_type": "physics-informed foundation model / platform",
            "scientific_domain": "hydrology / flood forecasting / water resources",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Physical awareness (embedding process knowledge) intended to improve plausibility of ML outputs relative to purely data-driven models.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Application-specific evaluation (e.g., rainfall-runoff and flood forecasting skill assessments) implied; not detailed in review.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Embedding physics/process knowledge to regularize ML and reduce implausible results.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Challenges include dataset access, computing resources, and balancing ML flexibility with physical interpretability.",
            "uuid": "e2510.13",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "SpectralGPT",
            "name_full": "SpectralGPT (Spectral Remote Sensing Foundation Model)",
            "brief_description": "A large ViT-based foundation model customized for spectral remote sensing data, pre-trained for multi-objective spectral reconstruction and downstream remote sensing tasks.",
            "citation_title": "SpectralGPT",
            "mention_or_use": "mention",
            "system_name": "SpectralGPT",
            "system_description": "A Vision-Transformer (ViT) style foundation model pre-trained on spectral remote sensing sequences (multi-objective reconstruction) with &gt;600M parameters to support a range of downstream remote sensing tasks.",
            "system_type": "vision-transformer foundation model (multimodal remote sensing)",
            "scientific_domain": "remote sensing / Earth observation",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Performance on downstream remote-sensing tasks (classification, segmentation, reconstruction) implied; no hypothesis-specific validation described.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Described as achieving state-of-the-art performance on various downstream tasks for spectral remote sensing (no numeric metrics provided in review).",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Designed for remote sensing tasks; not specifically a hypothesis-generation or scientific-reasoning system.",
            "uuid": "e2510.14",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "DiffusionSat/CRS-Diff",
            "name_full": "DiffusionSat / CRS-Diff (Diffusion-based Generative Remote Sensing Models)",
            "brief_description": "Large diffusion-model-based generative systems for satellite data completion, multimodal generation, and controllable remote sensing image synthesis to fill gaps and enhance observational records.",
            "citation_title": "DiffusionSat",
            "mention_or_use": "mention",
            "system_name": "DiffusionSat / CRS-Diff",
            "system_description": "Large diffusion generative models trained on satellite/remote sensing data to perform tasks like inpainting, multimodal generation, and controllable synthesis for data completion and enhancement in spatiotemporal and spectral dimensions.",
            "system_type": "generative diffusion models",
            "scientific_domain": "remote sensing / geoscience data reconstruction",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility achieved by conditioning on observed modalities and multimodal constraints; specific mechanisms not detailed in review.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Qualitative and quantitative reconstruction/forecasting evaluation for data completion tasks (review cites cases such as reconstructing historical meteorological patterns).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Generative models can produce ensembles/samples representing uncertainty implicitly; review does not detail explicit UQ protocols.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Examples include reconstruction of historical meteorological information (e.g., inpainting El Niño spatial patterns in historical records) cited in the review.",
            "limitations": "Generative models may introduce plausible but unverified reconstructions (risk of hallucinated data) if not constrained by physical priors; review stresses need for careful application.",
            "uuid": "e2510.15",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Probabilistic-deep-learning",
            "name_full": "Probabilistic Deep Learning for Geoscience Forecasting",
            "brief_description": "A class of deep learning approaches that produce probabilistic predictive distributions (instead of point estimates) for variables such as precipitation and sea ice, enabling explicit uncertainty quantification.",
            "citation_title": "Seasonal Arctic sea ice forecasting with probabilistic deep learning",
            "mention_or_use": "mention",
            "system_name": "Probabilistic deep learning forecasting models",
            "system_description": "Deep neural networks trained to output predictive probability distributions (e.g., via direct probabilistic modeling, ensembles, or generative sampling) for geoscientific variables, supporting quantification of forecast uncertainty.",
            "system_type": "probabilistic deep learning / ensemble / generative",
            "scientific_domain": "atmospheric science, cryosphere, hydrology",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Probabilistic forecast verification metrics (e.g., ensemble spread vs. error, calibration) are implied though not enumerated in the review.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Explicit predictive distributions via probabilistic neural outputs, ensembles, or generative sampling; review cites MetNet-2 and probabilistic sea-ice forecasts as examples.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Probabilistic models help quantify uncertainty but challenges remain in calibration and long-range (seasonal/decadal) uncertainty representation.",
            "uuid": "e2510.16",
            "source_info": {
                "paper_title": "Artificial intelligence for geoscience: Progress, challenges, and perspectives",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Empirically verifying hypotheses using reinforcement learning",
            "rating": 2,
            "sanitized_title": "empirically_verifying_hypotheses_using_reinforcement_learning"
        },
        {
            "paper_title": "Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients",
            "rating": 2,
            "sanitized_title": "deep_symbolic_regression_recovering_mathematical_expressions_from_data_via_riskseeking_policy_gradients"
        },
        {
            "paper_title": "Discovering governing equations from data by sparse identification of nonlinear dynamical systems",
            "rating": 2,
            "sanitized_title": "discovering_governing_equations_from_data_by_sparse_identification_of_nonlinear_dynamical_systems"
        },
        {
            "paper_title": "Accurate medium-range global weather forecasting with 3D neural networks",
            "rating": 2,
            "sanitized_title": "accurate_mediumrange_global_weather_forecasting_with_3d_neural_networks"
        },
        {
            "paper_title": "FourCastNet: A global data-driven high-resolution weather model using adaptive Fourier neural operators",
            "rating": 2,
            "sanitized_title": "fourcastnet_a_global_datadriven_highresolution_weather_model_using_adaptive_fourier_neural_operators"
        },
        {
            "paper_title": "Differentiable modelling to unify machine learning and physical models for geosciences",
            "rating": 2,
            "sanitized_title": "differentiable_modelling_to_unify_machine_learning_and_physical_models_for_geosciences"
        }
    ],
    "cost": 0.0344465,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Artificial intelligence for geoscience: Progress, challenges, and perspectives
August 22, 2024</p>
<p>Tianjie Zhao 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Sheng Wang 
School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Chaojun Ouyang 
Institute of Mountain Hazards and Environment
State Key Laboratory of Mountain Hazards and Engineering Resilience
Chinese Academy of Sciences
610299ChengduChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Mountain Hazards and Environment
State Key Laboratory of Mountain Hazards and Engineering Resilience
Chinese Academy of Sciences
610299ChengduChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Min Chen 
Key Laboratory of Virtual Geographic Environment (Ministry of Education of PRC)
Nanjing Normal University
210023NanjingChina</p>
<p>Key Laboratory of Virtual Geographic Environment (Ministry of Education of PRC)
Nanjing Normal University
210023NanjingChina</p>
<p>Chenying Liu 
Data Science in Earth Observation
Technical University of Munich
80333MunichGermany</p>
<p>Data Science in Earth Observation
Technical University of Munich
80333MunichGermany</p>
<p>Jin Zhang 
The National Key Laboratory of Water Disaster Prevention
Yangtze Institute for Conservation and Development
Hohai University
210098NanjingChina</p>
<p>Long Yu 
School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Fei Wang 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Yong Xie 
School of Geographical Sciences
Nanjing University of Information Science and Technology
210044NanjingChina</p>
<p>School of Geographical Sciences
Nanjing University of Information Science and Technology
210044NanjingChina</p>
<p>Jun Li 
School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Fang Wang 
Institute of Soil Science
State Key Laboratory of Soil and Sustainable Agriculture
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Department of Chemistry
Technical University of Munich
85748MunichGermany</p>
<p>Sabine Grunwald 
Soil, Water and Ecosystem Sciences Department
University of Florida
PO Box 110290GainesvilleFLUSA</p>
<p>Soil, Water and Ecosystem Sciences Department
University of Florida
PO Box 110290GainesvilleFLUSA</p>
<p>Bryan M Wong 
Materials Science Engineering Program Cooperating Faculty Member
Department of Chemistry
Department of Physics Astronomy
University of California
92521California, RiversideCAUSA</p>
<p>Materials Science Engineering Program Cooperating Faculty Member
Department of Chemistry
Department of Physics Astronomy
University of California
92521California, RiversideCAUSA</p>
<p>Fan Zhang 
Institute of Remote Sensing and Geographical Information System
School of Earth and Space Sciences
Peking University
100871BeijingChina</p>
<p>Institute of Remote Sensing and Geographical Information System
School of Earth and Space Sciences
Peking University
100871BeijingChina</p>
<p>Zhen Qian 
Key Laboratory of Virtual Geographic Environment (Ministry of Education of PRC)
Nanjing Normal University
210023NanjingChina</p>
<p>Key Laboratory of Virtual Geographic Environment (Ministry of Education of PRC)
Nanjing Normal University
210023NanjingChina</p>
<p>Yongjun Xu 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Chengqing Yu 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Wei Han 
School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Tao Sun 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Zezhi Shao 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Tangwen Qian 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Zhao Chen 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Jiangyuan Zeng 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Huai Zhang 
Key Laboratory of Computational Geodynamics
University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>14 International Research Center of Big Data for Sustainable Development Goals
100094BeijingChina</p>
<p>Husi Letu 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Bing Zhang 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Lizhe Wang lizhe.wang@gmail.com 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>School of Computer Science
China University of Geosciences
430078WuhanChina</p>
<p>Lei Luo 
Chong Shi 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Hongjun Su 
College of Geography and Remote Sensing
Hohai University
211100NanjingChina</p>
<p>College of Geography and Remote Sensing
Hohai University
211100NanjingChina</p>
<p>Hongsheng Zhang 
Department of Geography
The University of Hong Kong
999077Hong Kong</p>
<p>SAR
China</p>
<p>Shuai Yin 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Ni Huang 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Wei Zhao 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Nan Li 
Jiangsu Key Laboratory of Atmospheric Environment Monitoring and Pollution Control
210044NanjingChina</p>
<p>School of Environmental Science and Engineering
Nanjing University of Information Science &amp; Technology
210044NanjingChina</p>
<p>Jiangsu Key Laboratory of Atmospheric Environment Monitoring and Pollution Control
210044NanjingChina</p>
<p>School of Environmental Science and Engineering
Nanjing University of Information Science &amp; Technology
210044NanjingChina</p>
<p>Chaolei Zheng 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Yang Zhou 
Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters
Ministry of Education
Key Laboratory of Meteorological Disaster
Nanjing University of Information Science and Technology
210044NanjingChina</p>
<p>Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters
Ministry of Education
Key Laboratory of Meteorological Disaster
Nanjing University of Information Science and Technology
210044NanjingChina</p>
<p>Changping Huang 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>Defeng Feng 
University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Qingsong Xu 
Data Science in Earth Observation
Technical University of Munich
80333MunichGermany</p>
<p>Data Science in Earth Observation
Technical University of Munich
80333MunichGermany</p>
<p>Yan Wu 
Institute of Vertebrate Paleontology and Paleoanthropology
Key Laboratory of Vertebrate Evolution and Human Origins of Chinese Academy of Sciences
Chinese Academy of Sciences
100044BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Institute of Vertebrate Paleontology and Paleoanthropology
Key Laboratory of Vertebrate Evolution and Human Origins of Chinese Academy of Sciences
Chinese Academy of Sciences
100044BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Danfeng Hong 
Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Aerospace Information Research Institute
Chinese Academy of Sciences
100094BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Zhenyu Wang 
Department of Catchment Hydrology
Helmholtz Centre for Environmental Research -UFZ
Saale) 06108HalleGermany</p>
<p>Department of Catchment Hydrology
Helmholtz Centre for Environmental Research -UFZ
Saale) 06108HalleGermany</p>
<p>Yinyi Lin 
Department of Geography
The University of Hong Kong
999077Hong Kong</p>
<p>SAR
China</p>
<p>Department of Geography
The University of Hong Kong
999077Hong Kong</p>
<p>SAR
China</p>
<p>Tangtang Zhang 
Key Laboratory of Land Surface Process and Climate Change in Cold and Arid Regions
Chinese Academy of Sciences
730000LanzhouChina</p>
<p>Key Laboratory of Land Surface Process and Climate Change in Cold and Arid Regions
Chinese Academy of Sciences
730000LanzhouChina</p>
<p>Prashant Kumar 
School of Sustainability, Civil and Environmental Engineering
Faculty of Engineering and Physical Sciences
Global Centre for Clean Air Research (GCARE)
University of Surrey
GU2 7XHGuildfordUK</p>
<p>Institute for Sustainability
University of Surrey
GU2 7XHGuildford, SurreyUK</p>
<p>School of Sustainability, Civil and Environmental Engineering
Faculty of Engineering and Physical Sciences
Global Centre for Clean Air Research (GCARE)
University of Surrey
GU2 7XHGuildfordUK</p>
<p>Institute for Sustainability
University of Surrey
GU2 7XHGuildford, SurreyUK</p>
<p>Antonio Plaza 
Hyperspectral Computing Laboratory
University of Extremadura
10003CaceresSpain</p>
<p>Hyperspectral Computing Laboratory
University of Extremadura
10003CaceresSpain</p>
<p>Jocelyn Chanussot 
University Grenoble Alpes
Inria</p>
<p>LJK
CNRS
Grenoble INP
38000GrenobleFrance</p>
<p>University Grenoble Alpes
Inria</p>
<p>LJK
CNRS
Grenoble INP
38000GrenobleFrance</p>
<p>Jiabao Zhang 
Institute of Soil Science
State Key Laboratory of Soil and Sustainable Agriculture
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Jiancheng Shi 
National Space Science Center
Chinese Academy of Sciences
100190BeijingChina</p>
<p>National Space Science Center
Chinese Academy of Sciences
100190BeijingChina</p>
<p>Jin Zhang 
The National Key Laboratory of Water Disaster Prevention
Yangtze Institute for Conservation and Development
Hohai University
210098NanjingChina</p>
<p>Fei Wang 
Institute of Computing Technology
Chinese Academy of Sciences
100190BeijingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Fang Wang 
Institute of Soil Science
State Key Laboratory of Soil and Sustainable Agriculture
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Department of Chemistry
Technical University of Munich
85748MunichGermany</p>
<p>Huai Zhang 
Key Laboratory of Computational Geodynamics
University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>14 International Research Center of Big Data for Sustainable Development Goals
100094BeijingChina</p>
<p>Hongsheng Zhang 
Department of Geography
The University of Hong Kong
999077Hong Kong</p>
<p>SAR
China</p>
<p>Jiabao Zhang 
Institute of Soil Science
State Key Laboratory of Soil and Sustainable Agriculture
Chinese Academy of Sciences
210008NanjingChina</p>
<p>University of Chinese Academy of Sciences
100049BeijingChina</p>
<p>Artificial intelligence for geoscience: Progress, challenges, and perspectives
August 22, 20245176EFAAACEDB6068C4EB839A1984DDC10.1016/j.xinn.2024.100691Received: January 15, 2024; Accepted: August 17, 2024; Received: January 15, 2024; Accepted: August 17, 2024;
What does AI bring to geoscience?AI has been accelerating and deepening our understanding of Earth Systems in an unprecedented way, including the atmosphere, lithosphere, hydrosphere, cryosphere, biosphere, anthroposphere and the interactions between spheres.-What are the noteworthy challenges of AI in geoscience?As we embrace the huge potential of AI in geoscience, several challenges arise including reliability and interpretability, ethical issues, data security, and high demand and cost.-What is the future of AI in geoscience?The synergy between traditional principles and modern AI-driven techniques holds immense promise and will shape the trajectory of geoscience in upcoming years.</p>
<p>INTRODUCTION</p>
<p>Geoscientists tackle the most significant environmental, scientific, and societal challenges related to Earth. 1,22][13] For instance, predicting geohazards necessitates considering not only the inherent complexities of the geosystem but also the significant influence of activities across multiple spatial scales. 14Moreover, the geosystem is an everevolving network characterized by non-linear processes of high dynamical instability, 15 where inherently stochastic features impose significant constraints on temporal analyses. 16In this context, while current weather forecasting can achieve relatively accurate predictions over several days, the challenge of making reliable predictions intensifies when extending the time frame to months or longer. 17Throughout history, geoscience has undergone a transition from the reliance on physics-based models to the utilization of data-driven machine learning (ML) approaches when tackling these challenges.This shift has been facilitated by remarkable advancements in artificial intelligence (AI), 18 data collection techniques, [19][20][21] and computing resources. 22</p>
<p>Physics-based models</p>
<p>Geoscientific research fundamentally relies on conceptual models that describe key processes and their interactions, 23 which are subsequently tested using physical and numerical models. 24Physical models simulate environmental conditions in a laboratory setting, 25 allowing researchers to manipulate variables in a controlled manner and investigate hypothetical scenarios within a large-scale and complicated geosystem. 24While physical models are effective in certain cases (e.g., using clay models to verify the orogenic theory 26 ), they also encounter discrepancies between the controlled virtual laboratory environment and real-world situations. 27Numerical models condense natural processes into mathematical representations. 28These equations, designed to mirror the intricate characteristics of the real geosystem, are too complex to be solved analytically 29 and are generally tackled by numerical simulations, such as numerical weather prediction models. 30Traditional physics-based models aim to uncover hidden mechanisms by reconstructing physical processes, and can provide robust explanations once successfully founded.However, the inherent complexity of the geosystem, coupled with our limited understanding, poses a significant challenge. 31Making comprehensive assumptions about related factors and their dependencies thus becomes difficult. 32,33The sophistication and uncertainty in optimizing such models greatly hinders their practical application. 34</p>
<p>Data-driven approaches</p>
<p>As the availability of geoscience data continues to expand, modern geoscientific challenges are increasingly centered around managing extensive datasets, often with limited or no underlying theoretical knowledge. 17,35,36In this context, AI demonstrates significant potential. 22,37,38ML, as a major subfield of AI, is deeply rooted in applied statistics and constructs computational models based on inference and pattern recognition rather than physical rules. 39,406][47] The success of these methods has sparked broad interest among geoscientists in employing ML to address Earth science challenges, allowing them to bypass the explicit modeling of physical processes. 44,48,49While conventional ML methods can effectively handle small-scale problems, they often encounter limitations in more complicated scenarios, particularly when dealing with large volumes of data and broader scales. 50In this case, deep learning (DL) has brought significant advances [51][52][53] since AlexNet decisively won the ImageNet challenge in 2012. 54Beyond applications of convolutional neural networks and Vision Transformers (ViTs), 55,56 densely/fully connected networks have proven useful in tasks such as soil mapping, 57 while recurrent neural networks, including long short-term memory (LSTM) networks, are particularly well suited for time series data and temporal problems. 58AI models hold promise for advancing modern geoscientific research by learning hidden features directly from data without requiring comprehensive physical prior knowledge.DL, as the primary data mining tool in the big data era, propels the application of AI to geoscience.However, AI techniques still face several challenges, including the notorious data-hungry characteristics, the increased demand for computational resources, and the inherent black-box nature of AI algorithms. 59,60ddressing these challenges is crucial to further explore the potential of AI in geoscience.</p>
<p>Advanced AI techniques</p>
<p>Solely relying on either physics-based or data-driven models proves insufficient for knowledge discovery in geoscience. 61Hybrid models or physics-guided/informed/aware ML offer a promising solution by integrating domain knowledge to refine AI models in geoscience. 62These models incorporate constraints derived from domain-specific insights, such as encoding differential equations from data 63 or imposing physical constraints on data-driven models. 64,65This integration allows for performance comparable with pure data-driven approaches but with the advantage of requiring less training data. 66Despite their potential to bridge interdisciplinary gaps between datadriven and physics-based models, the effective implementation of hybrid models remains an open question. 11,67In addition, the recent success of ChatGPT has emphasized the potential of foundation models to enhance a wide range of tasks. 68The vast expansion of data in geoscience provides a solid groundwork for the emergence of large geoscientific models. 69These large models offer new avenues for extracting new insights from data to enrich our understanding of the Earth.Nevertheless, their development is still in the early stage. 70,71Geodata possesses unique characteristics, such as geo-references, various attribute features, and temporal constraints, which make it challenging to directly apply prominent language-and image-processing techniques from other fields to geoscience.How to formulate foundation models tailored to geoscience, with implications for diverse downstream tasks, remains an underexplored area.Furthermore, humanity's quest for knowledge has increasingly extended beyond Earth into outer space. 72,735][76] For example, NASA's Artemis campaign aims to explore the Moon for scientific research and technological advancement in 2024, 77 alongside China's Chang'e program. 78,79The BepiColombo mission of European Space Agency targets perplexing questions about Mercury, aiming to unravel the history of the entire Solar System. 80With our knowledge of other planets still limited, advanced AI techniques play a crucial role in processing and analyzing the vast amounts of data collected from these missions.By deepening our comprehension of planetary processes, we cannot only enhance our understanding of these celestial bodies but also enrich Earth-based research by drawing insightful comparisons between fundamental geological mechanisms and planetary evolution. 81,82dvanced AI techniques, particularly emerging paradigms such as physicsinformed ML and large models, showcase unprecedented potential for advancing geoscience.These innovative approaches open new avenues for addressing complex challenges not only in Earth science but also in the exploration of outer space.However, current research in these promising domains remains relatively limited.This article aims to offer a comprehensive overview of the latest advancements in AI applications within geoscience.In addition, it discusses the associated challenges and identifies untapped opportunities in this field, providing guidance for future works.While several reviews have previously explored the application of AI in geoscience, offering valuable insights into the evolving landscape, 59,61,70,83 the rapid evolution of AI, up-to-date reviews to capture current trends and illuminate future research directions.Geoscience, in particular, requires special considerations for AI methodology design, given the unique characteristics of geo-data.Therefore, rather than revisiting fundamental concepts and exemplified applications of commonly used ML models, 59,70,83 our work highlights the latest achievements and prospects of AI, especially in handling big geoscience data.We will demonstrate how AI can overcome the trade-off between efficiency and accuracy, as well as make breakthroughs in other aspects, such as providing new plausible hypotheses and research directions.Furthermore, we summarize new emerging geoscientific questions and paradigms in the context of modern AI and contemporary space exploration to shed light on potential future avenues for geoscience researchers.</p>
<p>The rest of the paper is organized as follows.The section "geoscientific research paradigms" summarizes major geoscientific research paradigms, with a special focus on AI-related ones in section "AI-driven geoscience paradigms" and some typical application cases in section "typical cases".The latest progress of geoscientific large models is demonstrated in section "large models in geoscience".Then, we present some challenges and plausible future lines for contemporary AI geoscientific method design in section "challenges and outlooks in AI for geoscience", followed by some findings in the "conclusion" section.</p>
<p>GEOSCIENTIFIC RESEARCH PARADIGMS</p>
<p>Diverse approaches and paradigms have been developed to deepen our understanding of the dynamic Earth system. 84This section offers a comprehensive overview of the field, encompassing research paradigms ranging from traditional observational studies to advanced computational analyses.Four distinct yet interconnected methodologies have shaped contemporary geoscience: the observational-hypothesis-driven paradigm, the modeldriven paradigm, the data-driven paradigm, and the model-data-driven paradigm, 10,18 as illustrated in Figure 1.Each of these methodologies brings unique strengths from foundational theories to advanced simulations and analyses, contributing to our comprehension of the Earth's complex system through collaborative synergies.</p>
<p>Observational-hypothesis-driven paradigm</p>
<p>The observational-hypothesis-driven paradigm is foundational to Earth system science, playing a crucial role in understanding the complex interactions within our planet's interconnected systems. 19,85This approach involves systematic data collection and analysis to develop hypotheses about Earth's processes, dynamics, and derived consequences.Rooted in empirical evidence and scientific methods, this paradigm emphasizes objective observation and rigorous hypotheses testing. 86A seminal example of this paradigm is James Lovelock's Gaia hypothesis, 87 which suggests the Earth's biosphere functions as a self-regulating system, a concept that fundamentally requires extensive Earth system observations to be substantiated.Observations validate and refine hypotheses, providing insights into processes that may not be directly observable.For instance, the study of ocean circulation has greatly benefited from observations of sea surface temperatures and currents, which have been crucial in understanding the dynamics of events such as El Niño. 88In addition, using empirical observations and hypothesis testing in frameworks such as the Community Earth System Model has also been instrumental in assessing future climate scenarios and informing policy formulation. 89he advancement of technology has revolutionized our ability to collect data from various sources, including satellites, ground-based sensors, and remote sensing instruments. 90Acquiring high-quality observational data has allowed scientists to refine their hypotheses and models, leading to more accurate predictions and a deeper understanding of Earth's behavior.In climate science, the Intergovernmental Panel on Climate Change Assessment Reports exemplify this paradigm in action.Leveraging extensive observational data, these reports critically evaluate the current state of climate system, hypothesize about future climate trends, and predict potential global and societal impacts.This demonstrates the profound impact of systematic observations on both scientific and policy-oriented discourse. 91n summary, the observational-hypothesis-driven paradigm is a fundamental method that combines empirical observations and hypothesis testing to unravel the interactions within Earth's interconnected systems.Firmly rooted in the scientific method, this paradigm remains indispensable for deciphering the intricate operations of the Earth system and guiding our responsible stewardship of the planet.</p>
<p>Future work within this paradigm should focus on advancing the integration and resolution of sensor networks across diverse ecosystems.By enhancing data collection methodologies, researchers can improve the accuracy of environmental models, leading to a more refined understanding of Earth system dynamics and their implications for global climate patterns.This approach will enable more precise predictions and foster a deeper scientific understanding of interconnected planetary systems.</p>
<p>Model-driven paradigm</p>
<p>There has been a long-standing focus on deciphering the interactions between natural processes and human activities on the Earth's surface. 92This focus has driven the development of computational techniques and mathematical models, particularly process-based ones, 93 which simulate the physical, chemical, and biological processes of the Earth. 94These models vary in complexity, ranging from simple representations of single processes to intricate integrations of multiple systems.The crux of process-based modeling lies in its challenges to transform our conceptual understanding of Earth processes into quantifiable and replicable frameworks. 95By employing mathematical representations of natural phenomena, these models provide insights into the mechanisms driving Earth's systems. 96Examples of such models include the Soil and Water Assessment Tool 97 and Storm Water Management Model 98 for hydrological studies, and the Finite Volume Community Ocean Model 99 for oceanic processes.These models have significantly enhanced our understanding and predictive capabilities regarding natural phenomena.In atmospheric science, models such as the Weather Research and Forecasting model, 100 Community Multiscale Air Quality model, 101 and Model of Emissions of Gases and Aerosols from Nature 102 are particularly pivotal.The predictive power of process-based models is substantial, allowing scientists to explore "what-if" scenarios that inform decisionmaking in environmental management and policy. 103However, the efficacy of these models depends on their calibration and validation against empirical data. 104This iterative process of refinement and validation ensures the models' accuracy and relevance, highlighting the continuous evolution of our understanding of Earth's systems through scientific inquiry and computational innovation. 105,106uture efforts in the model-driven paradigm should concentrate on refining model scalability and resolution, particularly by incorporating adaptive algorithms that improve the fidelity of simulations under varying climatic and environmental conditions in current and future scenarios.This will expand our capacity to predict subtle changes within Earth's systems with greater precision.</p>
<p>Data-driven paradigm</p>
<p>The data-driven approach has revolutionized our understanding of Earth systems and human-environment interactions. 107Fueled by the vast availability of data and advancements in computing and sensing technologies, this paradigm allows researchers to gain deeper insights into the complex interplay between natural processes and human activities. 108In geoscience, this paradigm shift is exemplified by utilizing satellite imagery and all kinds of big geo-data. 109,1102][113] Data-driven methods have also transformed our understanding of urban environments. 114,115The analysis of transportation data, such as traces from global positioning systems and traffic flow data, has enabled researchers to model urban mobility patterns and reduce traffic congestion. 116In addition, social media data and geotagged content have provided insights into human behavior, sentiment, and urban cultural dynamics, shedding light on the social aspects of urban life. 117The data-driven paradigm has also facilitated the study of the human-environment nexus in urban areas.By integrating data on air quality, land use, and human activity, researchers can better comprehend how urbanization affects air pollution, public health, and carbon neutrality. 118,119This holistic approach has been instrumental in shaping policies aimed at improving urban air quality and reducing pollution-related health risks.Moreover, the integration of socioeconomic and environmental data has enhanced our understanding of urban resilience and vulnerability to natural disasters. 120,121For instance, by analyzing demographic data and flood risk maps, researchers can identify vulnerable populations in flood-prone areas and devise targeted disaster preparedness strategies. 122n summary, the data-driven approach has propelled our understanding of Earth systems and urban dynamics to new heights.By harnessing vast datasets and sophisticated computational techniques, researchers can now explore the intricate connections between natural processes and human activities, facilitating more informed decision-making in areas such as land use, climate adaptation, transportation planning, and disaster resilience.This paradigm shift advances our scientific knowledge and offers practical solutions to the challenges facing our planet and urbanized societies.</p>
<p>Future work in the data-driven paradigm should emphasize the development of real-time data processing and analytics frameworks.By enabling instantaneous analysis and application of Earth system data, researchers can deliver more timely responses to environmental changes and disasters, thereby enhancing decision-making processes in critical situations.</p>
<p>Model-data-driven paradigm</p>
<p>The integration of process-based and data-driven models, commonly referred to as hybrid models, leverages the strengths of both paradigms and advances our comprehension of Earth system dynamics. 17Hybrid modeling enhances simulation precision and computational efficiency. 123Process-based models, underpinned by equations of 171 motion, are particularly effective in capturing the processes of atmospheric and oceanic dynamics.However, they often struggle with complex areas such as biological processes and carbon cycling, where numerical methods fall short and semi-empirical methods lack the necessary details and accuracy. 124Hybrid models address this gap by employing ML to replace empirical sub-models, utilizing extensive observational data while maintaining process-based models for well-understood mechanisms. 125In addition, certain components of Earth system models are computationally expensive, particularly when handling large datasets involving complex partial differential equations 126 or high-dimensional problems. 127Despite the fact that ML emulators may incur high initial training costs, they offer a significant reduction in computation time once operational, outperforming traditional local process modules. 128This increase in computational efficiency not only accelerates model processing but also enhances sensitivity and uncertainty analyses.The data-driven aspects of these hybrid models afford the flexibility needed to adapt to evolving conditions, as seen in climate and vegetation dynamic modeling. 17Moreover, integrating physical principles into ML models enhances interpretability and extends their ability to extrapolate beyond observed datasets.For instance, domain-specific knowledge and models can be used to create synthetic data 129 or to select representative training samples, 130 which can train ML models that are both generalized and cost-effective.Unique neural network architectures that incorporate physical constraints, known as physics-informed neural networks, provide solutions to partial differential equations used in climate dynamics modeling. 131,132In addition, embedding physical laws into the cost functions of neural networks, traditionally optimized by statistical measures such as cross-entropy or mean-square error, introduces a regularization effect and inherently discards physically implausible outputs. 133The synergy between ML and physical modeling not only fortifies model credibility but also establishes a methodological evolution.</p>
<p>Future initiatives within the model-data-driven paradigm should concentrate on enhancing the scalability and integration of hybrid models across various scales and systems.This would include fine-tuning the interoperability between ML algorithms and process-based models to ensure seamless functionality in both regional and global-scale simulations.Such advancements could drastically improve the capability to simulate complex Earth system interactions and provide more accurate forecasts under changing climatic conditions.</p>
<p>This section has delved into the diverse paradigms and methodologies of geoscience, highlighting the multifaceted approaches to understanding our planet.The observational-hypothesis-driven paradigm forms the basis for empirical investigation, setting the stage for further inquiry, while the model-driven and data-driven approaches offer advanced simulation and in-depth analysis tools.In summary, the current landscape of research in geoscience has encountered limitations in effectively addressing complex global challenges. 59There is a need for a transformative shift toward insights that integrate advanced AI techniques with geoscientific knowledge. 123As geoscience continues to evolve, the interplay of these methodologies will be instrumental in driving forward our global efforts for environmental protection and sustainable development. 10</p>
<p>AI-DRIVEN GEOSCIENCE PARADIGMS</p>
<p>Earth science research has undergone a transition from the observational-hypothesis-driven paradigm (see Figure 2) to a joint process-data-driven paradigm, which exhibits the characteristics of the "four Vs" of big data: volume, variety, velocity, and value. 134Since the early 2010s, the performance of AI has improved dramatically 70 due to the availability of large-scale datasets, massive computer and storage hardware, and efficient distributed and parallel computing frameworks.The rise of AI has greatly accelerated the paradigm transition in geoscience research and driven various aspects of the application processes of big Earth data, from big Earth data collection and processing 135 to novel computational platforms, 136 hypothesis generation, 137 and geoscience prediction. 138In this section, we discuss how AI can contribute to geoscience research in these aspects and the unprecedented opportunities it presents.</p>
<p>AI-assisted Earth observation data collection, processing, and representation</p>
<p>Data collection and analysis form the foundation of Earth science discoveries, aiming to capture, process, and represent complex Earth data to mine valuable information to understand complex Earth systems. 17,84AI enhances and accelerates each stage of this process.AI accelerates and improves the efficiency of Earth observation data collection.The conventional satellite-to-ground data collection process typically includes multiple stages, requiring high time consumption and bandwidth. 139Edge computing with AI on satellites allows realtime data processing and selective transmission to ground stations, significantly improving efficiency and reducing the need for manual corrections.Similar applications include real-time geographic information services for mobile terminals, 140 high-precision monitoring of ground stations, 141,142 and UAV-based agricultural remote sensing. 143For example, Wang et al. 144 proposed a cloud-edgeend collaborative system for agricultural remote sensing, allowing AI to perform real-time data collection and processing on edge UAV devices.The processed data are then sent to the cloud, enhancing data transmission rates.In the future, integrated data collection and processing on edge sensors via AI 145 will be of great potential.</p>
<p>AI significantly contributes to data generation, completion, and enhancement.Earth observation data frequently encounter limitations in temporal, spatial, or spectral dimensions due to meteorological conditions, noise interference, and sensor issues, resulting in discontinuities across these dimensions. 109Generative AI's ability to process multi-modal data across time, space, and multiple spectra is essential for generating, completing, and enhancing geoscientific data. 146For instance, Kadow et al. 147 developed an AI model using inpainting technology to reconstruct meteorological data, restoring the missing spatial pattern of the El Niño event from July 1877.Moreover, large diffusion models such as DiffusionSat 148 and CRS-Diff 149 are capable of performing integrated tasks and addressing the issue of limited remote sensing samples in specific spatiotemporal scenarios.SpectralGPT 150 captures spectral sequence patterns through multi-objective reconstruction, providing a foundation model with over 600 million parameters for various downstream tasks.</p>
<p>AI enhances the flexibility and effectiveness of data representations by introducing geometry and structure to model the complex interrelations within the data. 59,151For example, graph networks 152,153 model directly underlying structures, facilitating the discovery of broader spatial correlation patterns in Earth science data.Self-supervised learning 154 allows capturing general features without relying on explicit labels.The Transformer architecture, 155 known for its powerful feature extraction and long-distance spatial dependency modeling capabilities, unifies data representations across various scenarios and modalities in Earth science.Recently, large AI models have revolutionized representation learning by facilitating deep interconnections between Earth science data to unearth new scientific discoveries.Examples include the single-modal large language model K2, 156 the meteorological time series graph network model GraphCast, 157 and the large multi-modal model SkySense, which integrates images, text, geographic coordinates, and site observations. 158Exemplified by digital twin Earth, unified and universal large Earth science models have become a future trend. 150,159heir embedding representations should not only consider the capabilities of multi-scale spatiotemporal data processing, multimodal data representation, and alignment with human understanding, but also provide a universal interface for decoders tailored to various downstream tasks, achieving comprehensive generalization across the domain.</p>
<p>AI promoting new computing tools or platforms for geoscience research</p>
<p>Numerous processes on and within the Earth are continuously monitored by various sensors globally, generating vast amounts of Earth data, with storage volumes exceeding 10 exabytes. 19,160These sensors capture various states, fluxes, and intensities, capturing time/space-integrated data from satellite remote sensing, in situ observations, and atmospheric monitoring devices. 19Traditionally, geoscientific systems have required the integration of decentralized decoders tailored to specific tasks to compute and simulate the diverse and spatiotemporally varied streams of observational data.This approach often complicates data sharing and model connectivity.However, the emergence of new AI tools and large models is poised to revolutionize the computation and simulation paradigms of geoscience big data platforms.</p>
<p>First, large AI models are driving the innovative construction of big data platforms that offer robust multi-task processing capabilities and efficient data integration mechanisms.For example, AI-Earth 161 introduced AI-Seg, a universal foundation model for object segmentation, capable of rapidly segmenting multisource remote sensing images and extracting spatiotemporal change information.The Open Geospatial Engine 162 incorporates LuojiaNet, a DL architecture tailored to geoscientific features, linking 55 downstream foundation models with 300 million parameters.This system also includes an embedded spatiotemporal knowledge graph to associate multimodal spatiotemporal data.</p>
<p>Second, AI agents, in collaboration with high-quality feedback from geoscience experts, can assist in solving complex geoscientific processes or problems.The "human-in-the-loop" process, which involves deep models and human experts, has proven effective in geoscientific data annotation with improved interpretation accuracy. 163For instance, Li et al. 164 have integrated large conversational models into robots, allowing humans to issue commands to robots via language for complex action-planning tasks.This advancement in AI's understanding of spatial intelligence is catalyzing robotic learning, approaching the goal of embodied intelligence. 165Moreover, the deep integration of large AI models with drones, autonomous vehicles, and mobile monitoring devices on the surface or underground, coupled with satellite data, is facilitating more efficient and automated complex actions in geoscience, including spatiotemporal data collection, processing, and transmission.</p>
<p>Finally, the integration and assimilation of Earth's big data through the digital twin Earth has ushered in a new era of experimentation and simulation in Earth science. 166By integrating remote sensing data, in situ observations, experimental analyses, societal perceptions, simulations, and reanalysis, AI-based digital twin systems or platforms are capable of accurately simulating various complex Earth processes, spanning atmospheric, hydrological, urban, geological, and other domains. 167Specifically, Earth digital twins, which integrate big Earth data and physics-based models within interactive computational frameworks, enable the monitoring and prediction of environmental changes and societal disruptions, 168 thereby driving a deeper understanding of Earth system processes and scientific cognition.</p>
<p>AI facilitating the generation and optimization of geoscientific hypotheses</p>
<p>Hypotheses are crucial research tools in Earth sciences, aiding scientists in comprehending the Earth system and its evolution through artificial observations and scientific conjectures. 169For instance, Kepler 170 formulated the laws governing planetary motion based on extensive observations of stars and planets.Geoscientific hypotheses appear in various forms, including mathematical expressions, molecular formulas in geochemistry, and genetic variation laws in biology.Traditional methods for generating and validating hypotheses have predominantly relied on theoretical assumptions and logical deduction, as well as computational modeling and simulation, 18 with limited ability to solve complex and nonlinear problems.In contrast, recent AI has learned patterns and rules in massive data through "guessing-and-verifying," with intelligence gradually emerging. 171This evolution has led to significant breakthroughs in scientific endeavors, such as predicting protein structures, 172 formally proving mathematical conjectures and theorems, 173 and simulating molecular dynamics in physics. 174his "guess-and-verify" type of AI has greatly contributed to the paradigm shift of geoscientific hypotheses generation and validation.</p>
<p>AI is transforming the generation of geoscientific hypotheses from predefined methods to data-driven discovery.Traditionally, hydrologists modeled rainfallrunoff processes using physical conceptual models based on potential influencing factors, 175,176 which tend to be non-unique, subjective, and limited. 177In contrast, AI treats multimodal data as inputs, enabling scientists to explore larger sets of hypotheses for more effective generation. 22,178Furthermore, screening a high-quality hypothesis from the candidates is usually framed as an optimization problem. 179AI prioritizes directions with higher values by maximizing reward signals for the candidate set, instead of using manually designed rules in the traditional approach. 180,181For example, a multi-objective optimization framework was constructed to consider the impacts of hydropower capacity on five environmental factors (sedimentation, river connectivity, flow regulation, biodiversity, and greenhouse gases) in the Amazon basin. 182AI also enables selective screening of candidate information with desirable attributes from highthroughput experimental data, reducing the interference of redundant observations. 183Another example is the optimization of discrete geo-hypotheses, where AI methods, such as variational autoencoders, map discrete symbolic representations into a differentiable latent space. 184Process-based differentiable modeling 63 combines physical mechanisms and ML techniques, facilitating hypothesis testing and uncovering previously unrecognized correlations in Earth science.</p>
<p>AI holds the potential to significantly contribute to the verification of geoscientific hypotheses.Various hypotheses in geoscience, such as Wegener's continental drift theory, Darwin's biological evolution hypothesis, and the historical climate change conjecture, present major scientific challenges.Correspondingly, researchers have leveraged AI's ability to model nonlinear complex systems to verify these hypotheses.For example, Stupp et al. 185 used coevolutionary ML to predict functionally relevant interactions between human genes, advancing the understanding of human coevolutionary processes.Kalra et al. 186 utilized artificial neural networks to model the complex association between global temperature and greenhouse gas concentrations.In addition, large AI models such as GraphCast 157 and PanGu 187 have revolutionized traditional weather forecasting methods and contributed to exploring the evolution of Earth's climate over deep time.AI also challenges the findings of traditional physical models. 17For example, ML estimates of global carbon flux data have indicated that traditional climate models may have overestimated the response of vegetation, such as tropical rainforests and grasslands, to climate changes. 188Data-driven carbon cycle estimates have also revealed potential mechanisms behind the enhanced seasonal cycle of atmospheric carbon dioxide concentration in high-latitude regions. 189</p>
<p>AI-driven solutions to geoscience inference and prediction</p>
<p>Geoscience prediction tools have undergone substantial evolution, improving our ability to comprehend complex Earth systems. 190Initially, Galileo, Kepler, and others studied planets through experimental methods of observation and induction. 191Alfred Lothar Wegener studied the Earth's plates through hypothesis and deduction. 192Subsequently, the simulation and modeling of complex phenomena, such as meteorological, hydrological, oceanic, and other physical processes, through physical computational models became the third paradigm of Earth science research.With the arrival of the big Earth data era and the continuous improvement of AI, scientists have made significant strides in spatiotemporal analysis. 151,193The data-intensive research paradigm has become a mainstream. 11Nowadays, large AI models have revolutionized the paradigms for geoscience inference and prediction, 17 exhibiting strong abilities to mine hidden relationships within vast data and enhanced model inference and prediction accuracy. 194,195I allows for more comprehensive and efficient geoscience inference and prediction.To enhance geoscience inference, AI implements trustworthy attentionbased models, enabling the extraction of spatial relationships across data from a global perspective. 196Physical embedded neural networks leverage their powerful numerical approximation capabilities to reduce the computational complexity of high-order differential equations. 197Spatiotemporal graph neural networks, which utilize the graph structures to accurately represent spatial relationships and factor correlations, enhance the reliability of reasoning. 195,198In terms of prediction, AI incorporates a broad range of historical information and efficient modeling strategies, such as pre-training 199 and generative decoders, 200 offering enhanced technical support for decision-making processes.With the deep integration of AI infrastructures (such as high-performance computing chips, storage media, rapid and lightweight large models) and edge sensors, real-time monitoring of the Earth's environment contributes to enhancing the predictive capabilities for rapid disturbances such as geological disasters, climate anomalies, and emergencies. 91,154Overall, AI facilitates more precise and reliable inference and prediction, reducing the computational complexity of high-order differential equations. 201,202ociety has witnessed many successes in this respect, although many challenges still exist.Weather prediction, a successful example in geoscience, has dramatically improved through integrating advanced AI models, increased computational power, and established observational systems with large amounts of data. 122Represented by PanGu 187 and GraphCast, 157 large AI models can accurately predict weather evolution on time scales ranging from several days to a month.However, challenges remain in seasonal weather forecasts, extreme event predictions (such as floods and wildfires), and long-term climate forecasts. 120,203In the biosphere, Klemmer et al. 204 trained a universal AI geolocation encoder to assist in monitoring biological population migration and number estimation.6][207] It is also essential to establish a comprehensive, integrated monitoring network in outer space, sky, surface land, and subsurface to provide more reliable data support.</p>
<p>TYPICAL CASES</p>
<p>AI, as a modern scientific research infrastructure that comprises rapidly evolving technologies, brings novel means to comprehend the Earth's systems, including the atmosphere, lithosphere, hydrosphere, cryosphere, biosphere, and anthroposphere, as well as their interactions.By leveraging rapidly advancing technologies, AI accelerates and deepens our understanding of the Earth at a variety of spatial and temporal scales, advancing the achievement of sustainable development goals (see Figure 3).The uniqueness of geoscience, showcasing a considerable amount of subdisciplines, a vast quantity of geographic knowledge, an extensive collection of observational data and spatial dependence, spatial heterogeneity, and nonlinearities among geographical elements, has led to novel advancements in AI technology.</p>
<p>Atmosphere</p>
<p>Clouds, aerosols, and gases are three of the most important components in the atmosphere.They affect the solar radiation received by the Earth system and exert distinct radiative forcing on the energy budget, which in turn has a substantial influence on the weather and climate on a regional or global scale. 18,208,209AI models the complex and nonlinear atmosphere system, predicting common surface and atmospheric variables, as well as enhancing our ability to retrieve atmospheric parameters with remarkable enhancement in the accuracy and granularity of atmospheric studies. 210,211tmospheric component detection and interactions.AI has revolutionized cloud identification, cloud type recognition, and even cloud dynamics prediction from satellites, 212 It has notably improved the accuracy of retrieving cloud microphysical and cloud top parameters [213][214][215] and has provided cloud bottom information that traditional physical-based algorithms often fail to estimate. 216These advancements enable the precise understanding of cloud formation in weather forecasting, 217 holding the promise of more accurate and efficient weather predictions.</p>
<p>In aerosol remote sensing, AI mainly contributes to improving the detection of aerosols, 218 building models to retrieve aerosol optical properties [219][220][221] and applying the aerosol products to wildfire detection, particulate matter (PM 2.5 ) monitoring, and other aerosol-related problems. 219][224] AI models, on the one hand, retrieve water vapor with high accuracy 216 and produce precipitation datasets with a high spatial and temporal resolution. 225n the other hand, AI techniques have been integrated with ground-and satellite-based observations to quantify and forecast air quality on a regional or global scale. 216Many factors (meteorology, geography, emissions, vegetation, etc.) Figure 3. Observation and simulation are the two main tools for understanding the Earth system AI helps in the observation of the Earth system, assisting in the discovery of knowledge from data.Besides, AI also supports Earth system simulation, generating data from models and knowledge.</p>
<p>][228][229] By advancing cloud analysis, improving aerosol monitoring, and exploring the relationships between complex gases, AI significantly enhances researchers' understanding of the dynamics of atmospheric components and captures their intricate interactions.</p>
<p>Solar radiation monitoring.The traditional radiative transfer (RT) model is a classic and widely used way to retrieve solar radiation.However, the forward RT simulation is a time-consuming process, which makes it inapplicable for direct use with satellite observations, particularly with geostationary satellite observations (the monitoring frequency in the order of minutes).Through the development of AI-based RT models in recent years, the computational efficiency of atmospheric RT has been greatly improved (by several orders of magnitude), 230 which enables near real-time monitoring of solar radiation from satellites with high accuracy. 231eather forecasting and climate prediction.Mainstream AI-based global weather/climate forecast models predominantly concentrate on short-and medium-term predictions, 151 such as Google DeepMind's GraphCast, 157 Huawei Cloud's Pangu-Weather, 187 Tsinghua University and China Meteorological Administration's NowcastNet, 232 Alibaba's SwinVRNN, 233 Fudan University's Fuxi, 234 Shanghai's AI Laboratory's Fengwu, 235 Microsoft and the University of Washington's Deep Learning Weather Prediction, 236 with exceptional capabilities in processing large datasets, performing real-time analysis, and predicting extreme weather events. 237AI-based global weather/climate forecasting models have high forecast timeliness and computational efficiency.Taking Pangu-Weather as an example, it predicts 7 days' weather in only 10 s, 0.6 days earlier than the world's leading weather forecasting system, the European Center for Medium-Range Weather Forecasts (ECMWF). 187It is of great significance for extreme weather forecasting.Based on the weather forecast assessment of China's National Ground Meteorological Stations in the first quarter of 2024, AI-based models such as Fuxi, GraphCast, and FourCastNet had higher accuracy in temperature and wind speed than traditional numerical predictions.</p>
<p>Atmospheric predictability revolution: From challenges to solutions.The atmosphere is an intricate and dynamic system, and myriad challenges originate from the subtle interaction among aerosols, clouds, gases, and radiations. 210Predicting weather patterns and understanding climate change accurately are paramount in atmospheric science.However, achieving these goals poses significant challenges, including the need for faster and more precise weather forecasting and climate projections.Nowadays, AI models have emerged as a powerful tool for tackling these challenges and advancing solutions across a wide array of applications in atmospheric sciences. 237It significantly promotes the development of related monitoring and prediction platforms, which produce massive data and information with high spatiotemporal resolution and improved accuracy. 10,234In the future, as AI continues to evolve and incorporate more spatial big data into its training, it will enhance the reliability and accuracy of weather and climate forecasts further.Consequently, it may even lead to the eventual replacement of traditional physics-based models with AIdriven approaches.In addition, AI will play an imperative role in constructing automated monitoring and warning systems for the atmosphere environment, enabling timely issuance of alerts and recommendations.In essence, AI's application in atmospheric science transcends traditional methods, providing innovative solutions to long-standing challenges.Its integration into timely and accurate monitoring and prediction systems not only advances our understanding of atmospheric processes but also empowers us to make well-informed decisions.</p>
<p>Lithosphere</p>
<p>Solid Earth science, aimed at comprehending the structure, materials, and dynamics of the Earth's interior, geological processes, and the evolutionary history of the Earth, 238 receives unprecedented opportunities from AI, 10 with dramatic developments in geological hazard monitoring and prediction, rock feature analysis, geological exploration, geological model construction, and analysis of soil characteristics. 10,239ological exploration and hazard prediction.AI approaches have made significant strides in their application to geological exploration, such as petroleum and natural gas exploration, 240 geophysical imaging, 241 as well as the processing of seismic, 242 magnetotelluric, 243 and gravity data, 244 enabling sophisticated analysis and interpretation.Techniques such as denoising, phase-picking, and weak signal enhancement can reduce human errors in the exploration process, enhance the quality of exploration data, and accelerate exploration time. 245By harnessing the power of AI, geoscientists can unlock new frontiers in exploration efficiency, accuracy, and cost-effectiveness, ultimately shaping the future of resource exploration and sustainability.</p>
<p>AI technology provides powerful tools in facilitating earthquake monitoring and prediction, including detection and phase identification, 246 early warning, 247 motion prediction, 248 as well as forecasting magnitudes, scales, and timing, 249 also in assessment of landslide susceptibility, 250 supporting the mitigation of risks.AI has also demonstrated great potential in the volcanic prediction process. 251lthough AI encountered grand challenges in operational earthquake prediction, forecasting of fault zone stress, and the occurrence of chained natural hazards attributed to their highly coupled and strongly non-linear dynamics, 252 it has exhibited tremendous progress in recent years. 253ock physics analysis.AI methods can be utilized for the analysis and classification of rock samples, 254 automatically identifying rock types, compositions, and physical characteristics, thus expediting the analysis of rock samples and providing more detailed information about rock features, so as to aid geologists in better understanding geological history and rock evolution. 255Recent evidence demonstrates that AI has successfully solved various problems in rock mechanics, outperforming conventional empirical or statistical methods. 254By using AI approaches, deeper insights can be gained for more accurate geological interpretations and predictive models.</p>
<p>Geological modeling.As the emerging paradigm of science and technology research, AI is modulating the world in a variety of science realms, including geology.AI is transforming the measures geologists analyze data and understand the mechanisms of deep Earth.During the construction of geological models, AI is capable of integrating vast amounts of geological data from various disciplines and fields, ranging from geophysics and geochemistry to hydrology and tectonics.This multidisciplinary approach generates predictive models that assist scientists in better comprehending subsurface structures, stratigraphic forms, and groundwater flow.7][258] AI's integration into deep Earth modeling enables geologists to identify previously unrecognized geological features and phenomena, thereby advancing our understanding of the deep Earth.</p>
<p>Soil characteristics monitoring.AI boosts new developments in soil monitoring, offering a holistic and data-driven approach to soil monitoring and management. 259AI-driven sensors and monitoring systems enable continuous and high-resolution monitoring of soil conditions, providing valuable insights into soil health and dynamics, including essential soil parameters such as moisture, 259 temperature, 260 and texture. 261By analyzing multispectral and hyperspectral imagery, AI models can accurately map soil types, nutrient levels, and organic matter content across large spatial scales.This new real-time ability assists farmers in making informed decisions, thereby improving farmland utilization efficiency and agricultural production quality. 262eep-time and deep-Earth discoveries: Scale and accuracy.To date, large AI models constitute the most cutting-edge and wisdom-intensive research regime; the integration of AI has indeed ushered in a new era of exploration and understanding.However, as we delve deeper into the complexities of lithospheric processes, it becomes apparent that simply scaling up large AI models without due consideration for their ability to accurately capture and resolve scientific intricacies may lead to deviations from fundamental physical laws and characteristics.While large AI models boast impressive computational power, their efficacy in accurately describing lithospheric phenomena may be limited by the uncertainties inherent to input labels and data.Therefore, a shift toward the development of numerous and accurate small-scale domain-oriented models tailored to specific scientific problems or application fields is warranted.In addition, the integration of high-quality observation, monitoring, and experimental data with completeness is crucial for training and validating AI models in lithospheric studies. 263Synthetic data derived from massive-scale numerical simulations can further enhance the robustness and generalizability of AI models.Essentially, it may be a reliable and feasible measure to promote the revolutionary engagement of AI in deep-time and deep-Earth discoveries.</p>
<p>Hydrosphere</p>
<p>The hydrosphere is the sum of all water, including atmospheric, land surface, oceanic, and underground water reserved on Earth. 264][267] Land surface water balance.AI benefits the closing of the land surface water balance by accounting for the individual surface water flux components (precipitation, evapotranspiration, streamflow) and expanding the mapping capabilities of key state variables (such as soil moisture).AI can improve the estimation and forecasting accuracy of precipitation and help better understand the causes of extreme rainfall. 268For example, generative adversarial networks have been used for precipitation nowcasting and proved to be of high reliability. 269The multi-layer perceptron model, integrating geostationary satellite infrared data and passive microwave-based retrievals, yields precise precipitation estimates. 270Probabilistic weather models such as deep neural networks (i.e., MetNet-2) forecast precipitation with exceptional resolution, up to 12 h ahead. 271oreover, AI empowers the generation of precipitation data with unparalleled precision, spatiotemporal resolution, and spatial coverage, enhancing our understanding of precipitation dynamics. 272In addition, AI methods analyze largescale circulation patterns associated with US Midwest extreme precipitation to better understand the physical causes of changing extremes. 273Despite the many successful cases of AI application, acquisition of high-quality and continuous atmospheric data is still challenging due to sensor limitations, and the implementation of hybrid models appears as an effective solution.</p>
<p>AI-based approaches have been extensively employed to estimate evapotranspiration, one of the most important components of the hydrological cycle.That is crucial for estimating irrigation water requirements, hydrological processes, and assessing agricultural systems at both regional 274 and global scales. 275Sitescale evapotranspiration observations can be upscaled to the regional scale using AI-based methods, 276 thus overcoming the limited spatial and temporal coverage of in situ observations.The ability of AI to forecast evapotranspiration is also highlighted in a recent study. 277These forecasts play a crucial role in agricultural planning and drought monitoring, contributing to improved resilience and sustainability in water management practices.A novel research direction is to estimate evapotranspiration at high resolution through the construction of hybrid models, 278 which combine the physical consistency and interpretability of physical models with the data-driven formulations of AI-based models, thereby revealing processes that are insufficiently understood.This interdisciplinary approach holds the potential to uncover the underlying mechanisms and diversity of evapotranspiration, thereby enabling more robust and insightful assessments of water cycle dynamics.</p>
<p>Streamflow, as a key aspect of sustainable water resource planning and management, can be estimated in real time 279 or forecasted at lead times of 1-7 days 280 AI-based approaches, successfully used in streamflow regionalization, 281,282 can help to reduce modeling errors in process-based hydrologic models to improve the accuracy of simulations, since process-based and AI approaches can complement each other with respect to their inherent strengths and limitations. 283Deep neural networks enable the accurate identification of spatial distribution and morphological features of water bodies, 284 understanding river evolution, and forecasting river dynamics, 285 performing water quality analyses on the catchment scale. 286Another significant contribution of AI is the creation of global water quality databases due to its powerful learning and data fusion capabilities, such as the Global Streamflow Indices and Metadata Archive, 287 global river discharge reanalysis, 288 Global River Chemistry Database, 289 and Global River Water Quality Archive. 290The integration of AI into streamflow estimation, forecasting, and water quality analysis offers transformative opportunities for strengthening our understanding of hydrological processes toward more sustainable and resilient water systems.</p>
<p>Soil moisture acts as a fundamental boundary condition in terrestrial hydrology. 178,291The integration of AI-based models into soil moisture mapping signifi-cantly advances our ability to accurately retrieve, downscale, and predict soil moisture dynamics across different spatial and temporal scales.By using AIbased models, soil moisture retrievals are obtained from the passive-only 292 and synergistic active-passive microwave observations 293,294 with improved accuracy and temporal resolution, which is challenging for traditional algorithms to separate and interpret the desired information accurately.AI techniques downscale soil moisture from coarse spatial resolution to fine resolution, [295][296][297][298][299] also establish long-term global daily surface soil moisture datasets from multi-frequency radiometers (AMSR-E/2 and FY-3 series) by transferring the Soil Moisture Active Passive L-band observations, offering extended records vital for climate monitoring and hydrological research. 300,301Moreover, with the help of AI algorithms, soil moisture can be predicted at deeper depth (e.g., root zone) from surface data 302,303 and in a seamless and efficient manner through AI-based data assimilation techniques. 304,305I provides a potential solution for avoiding closure errors by enhancing the estimation and prediction of individual water fluxes and state variables.It addresses challenges related to integrating diverse data sources to produce cohesive models, achieving fine-scale spatial and temporal resolution, and understanding the nonlinear nature of hydrological processes.</p>
<p>Terrestrial water storage.AI plays an important role in improving the spatial and temporal continuity and resolution of terrestrial water storage.AI approaches have been instrumental in reconstructing continuous total water storage, by filling the data gap between the Gravity Recovery and the Climate Experiment (GRACE) satellite mission and its successor, GRACE-FO. 306Similarly, AI-based models, such as the GTWS-MLrec, have been developed to reconstruct terrestrial water storage estimates spanning several decades from 1949 to 2022, using a set of ML models with a large number of predictors. 307AI was used to capture complex spatiotemporal patterns in water storage dynamics, facilitating comprehensive analyses of hydrological trends and variability over extended periods.In addition, AIbased approaches have been deployed to map soil water storage in Ghana at high spatial and temporal resolutions, facilitating the identification of areas with stable water availability for improved crop production and guiding drought adaptation strategies. 308Moreover, GRACE-derived terrestrial water storage anomalies are downscaled to 10 km spatial resolution by using a convolutional long short-term memory neural network 309 in Iran and convolutional neural network-based approaches in Canada. 310In essence, AI provides a new capability to overcome data gaps, improve spatial resolution, and enhance the continuity of water storage observations, ultimately contributing to more effective water resource management.</p>
<p>Ocean currents and salinity.Ocean currents and salinity are crucial for understanding global climate systems, marine ecosystems, and coastal environments.Ocean currents reflect the movement of ocean water and drive the distribution of heat, nutrients, and salinity, influencing weather patterns, climate regulation, and marine biodiversity.AI methods significantly improve the estimation and forecasting of ocean currents by enhancing computational efficiency and accuracy. 311Traditional methods often struggle with the complexity and volume of oceanographic data.AI models, such as those integrating sea surface height, temperature, and wind stress simulated from the ocean general circulation model, can accurately predict the ocean currents over most of the global ocean, 312 and successfully forecast the velocity.For structures of the loop current system, 313 AI techniques such as LSTM recurrent neural networks and the Transformer also enable real-time in situ prediction of ocean currents at any location, and overcome the problem of excessive computational complexity in traditional regional physics-based prediction models. 314I-based approaches, such as deep neural networks, generative adversarial networks, random forests, support vector regression, and multi-layer perceptrons promote the convenient and fast estimation of ocean salinity, from the Aquarius, 315 SMAP, 316 and the Geostationary Ocean Color Imager-II satellites. 317,318With the aid of AI-based methods, the ocean general circulation model (e.g., Hybrid Coordinate Ocean Model) is also able to achieve more reliable estimates of sea surface salinity. 319AI has demonstrated strong capabilities to reconstruct the high-precision and high-resolution three-dimensional (3D) ocean subsurface salinity on a daily scale in 12 depth levels (from 2 to 200 m) only relying on the ocean 3D temperature data. 315This is because AI, particularly the DL models, have flexible structures and can extract potential complex mappings of data by stacking only multiple nonlinear layers.</p>
<p>REVIEW ll</p>
<p>The Innovation 5(5): 100691, September 9, 2024 Extreme hydrological events: Pioneering solutions.The changing dynamics of global climate present two concerning trends in the hydrosphere: alterations in water circulation patterns and the increasing frequency and intensity of extreme hydrological events. 111,320In response to these challenges, it becomes imperative to strengthen monitoring efforts, enhance forecasting capabilities, and improve decision-making efficiency.AI provides important tools for monitoring, understanding, and forecasting extreme hydrological events such as drought, rainstorm, and flood. 122AI can integrate a large amount of data from various sources (e.g., satellites, meteorological stations, and other sensors) to provide more comprehensive and accurate monitoring results of extreme hydrological events. 321or example, for extreme events, Earth observation data and ML can significantly mitigate the scarce hydrological data.Satellite-based technologies, which encompass a wide array of sensors operating across different regions of the electromagnetic spectrum-such as visible, thermal, and microwave domains-offer considerable potential.Advanced sensors, including synthetic aperture radar (SAR), satellite-based precipitation measurements, and gravity measurements, are emerging as transformative tools for the forecasting and monitoring of extreme events. 322Concurrently, the robustness and transferability of ML techniques are proving instrumental in predicting floods in ungauged river basins. 122oreover, AI can analyze and learn from historical data and meteorological forcings (such as precipitation and temperature), and identify the interactions between different environmental factors, and thus help understand the causes and patterns of extreme hydrological events. 323Furthermore, by using AI, short-term forecast of hydrological events can be made based on real-time hydrological data, providing timely support for emergency response.Short-term flood forecasting, which spans from a few hours to several weeks, predominantly utilizes meteorological forecasts to enhance model prediction performance and ensure physical consistency.For example, Xu et al. 324 have summarized numerous hydrological forecast models in this context.The prevailing methods for short-term flood forecasting integrate meteorological inputs (such as precipitation and temperature) with optional historical data to predict runoff or flooding events.</p>
<p>Meanwhile, combining meteorological and hydrological models, AI can forecast the long-term trend of extreme hydrological events, helping decision-makers to make long-term plans. 325Long-term forecasting of extreme events, which includes sub-seasonal, annual, and decadal outlooks, remains a significant challenge due to inherent data and model uncertainties.Currently, hybrid learning approaches 324 that combine physical modeling with ML are being employed to reduce model uncertainties and mitigate the reliance of data-driven models on extensive data inputs.In addition, uncertainties in data (such as precipitation) can be addressed by integrating low-latency satellite observation data with reliable climate prediction models.In summary, AI has brought new opportunities for hydrological cycle research to better understand and cope with extreme hydrological events.With the rapid development of computer technology and the emergence of new interpretable AI methods, the role of AI in the hydrosphere (particularly in extreme hydrological events) will become more prominent in the future.</p>
<p>Cryosphere</p>
<p>The cryosphere refers to frozen components of the Earth system, 326 overlapping with the atmosphere, the hydrosphere, and the lithosphere over vast areas, exhibiting a sensitive response and holding a significant impact on climate change. 327,328Numerous scholars focused on developing AI methods for addressing the challenging geoscientific questions in cryosphere research, such as the AI for Cold Regions, bringing new perspectives and innovative solutions in element classification and automatic mapping, feature spotting, physical properties retrieval, and interpretation of the cryosphere changes. 329ryosphere element identification.AI overcomes ambiguity in the cryosphere element identification caused by feature similarity, superseding manual interpretation, and limited empirical approaches.One notable application of AI is that it enhances our comprehension of the spatiotemporal distribution of the cryosphere by better classifying its elements, such as distinguishing ice cover types, 330 especially debris-covered glaciers, 331 which were difficult for band ratios/indices.AI can overcome inherent complexities to generate high-resolution maps of permafrost, a critical component of the cryosphere. 332Kuter et al. 333 applied artificial neural networks to estimate areal snow cover extent with high accuracy, thus able to provide timely and reliable information on snow cover dynamics.Convolutional neural networks have proven effective in classifying sea ice types with higher accuracy and less sensitivity to noise in SAR images. 334oincidentally, AI achieves automatic and reliable iceberg detection in different environmental conditions and improves understanding of iceberg dynamics in polar regions. 335In essence, AI plays a significant role in spearheading our understanding of the cryosphere by overcoming traditional limitations in element identification.</p>
<p>Feature spotting.In addition to classifying the cryosphere elements, AI aids in the identification of specific features of these elements that were previously challenging to detect.Specifically, AI has advanced the identification of wet and dry snow, especially in vegetated and mountainous areas where traditional methods struggle to differentiate between snow types. 336AI enabled robust and automated detection of snow avalanches for enhancing safety measures in mountainous regions. 337In glaciological research, AI has been utilized to map glacier calving margins 338 as well as glacier termini 339 toward comprehensive assessments of glacier mass loss.Qayyum et al. developed a DL-based glacial lake extraction method with noteworthy benefits in monitoring glacial lakes, a key indicator of potential glacial lake outburst floods. 340In permafrost research, ML performed analysis on the distribution of retrogressive thaw slumps 341 and extraction of ice-wedge polygons. 342Beyond that, AI has been used to improve the quantification of sea ice surface coverage types, and also to extract Antarctic ice shelf fronts from Sentinel-1 Imagery 343 and to classify ice crystal habitats more precisely than traditional methods. 344Therefore, AI plays a key role in promoting frontiers in cryospheric research by enabling the detection and characterization of specific features within cryospheric elements.</p>
<p>Properties retrieval.Different from traditional and complex physical models, AI enables simplified yet accurate property retrieval by modeling multivariate nonlinear relationships between cryospheric element parameters and image characteristics.This paradigm shift has led to significant advancements in understanding cryospheric processes.For example, AI improves the retrieval accuracy of the cryosphere properties in coalition with conventional algorithms, such as retrieval of snow depth 345 and estimates of snow water equivalent, 346,347 providing new insights to hydrological processes in cold regions.AI helped to solve the problem of detecting each internal ice layer uniquely to estimate their thickness accurately, thus providing crucial insights for assessing the contributions of ice sheets to sea level rise. 348In permafrost research, AI has been applied to estimate mean annual ground temperature and active layer thickness and to estimate the thaw depth variations at seasonal scale. 349AI has achieved better performance in Arctic sea ice thickness estimation, a key indicator of Arctic climate change. 332In addition, AI has helped to reconstruct the winter glacier mass balance, a quantitative expression of glacier volume change through time, filling the gap in ground observations and providing valuable insights into long-term glacier volume changes. 350Therefore, AI has led the way in streamlined and accurate cryosphere property retrieval.</p>
<p>Trend projection.AI significantly improves trend forecasting across diverse and complex conditions by developing sophisticated models that enhance spatiotemporal scope and precision.AI facilitates the investigation of historical cryospheric changes of possible trends, such as improving the prediction sensitivity of arsenic or manganese in groundwater and identifying trends that may not be apparent through traditional methods alone. 351Similarly, AI was used to model the future responses of permafrost to climatic changes, 352 including permafrost degradation trends, 331 overcoming limitations of environmental conditions.In addition, AI was applied to estimate snow avalanche hazards for a better prediction of occurrence and magnitude. 353AI also advanced the range of accurate sea ice forecast. 354Regarding iceberg research, AI has been used to estimate the surface area and masses of icebergs, 334 which has operational difficulties in large-scale monitoring by observational and remote sensing methods.Therefore, AI-driven approaches significantly propel trend forecasting and predictive modeling within the cryosphere, providing valuable insights into historical changes, future projections, and operational challenges.</p>
<p>Cryospheric water storage dynamics and sea level rise.The cryosphere, a critical component of Earth's climatic system, is rapidly diminishing due to the effects of global warming.This trend is particularly evident in glaciers, including the massive Greenland and Antarctic ice sheets, which are experiencing accelerated mass loss.Moreover, sea ice coverage and snow extent are decreasing, while permafrost is undergoing significant degradation.This shrinking cryosphere is directly contributing to rising sea levels, posing imminent and long-term threats to low-lying coastal areas and small island nations.In addition, in mountainous regions and high plateaus, the reduction of cryospheric elements is causing fluctuations in river runoff, exacerbating water scarcity and increasing the risk of flooding in vulnerable areas.Cryospheric elements, such as glaciers, snowpacks, permafrost, sea ice, and ice caps, possess 3D or stereo characteristics.Traditional Earth observation methods often provide surface properties or limited-depth information, hindering comprehensive assessments of cryospheric elements.AI presents an opportunity to enhance our understanding of the 3D properties of cryospheric elements.For instance, AI can provide improved models of the active layer in permafrost and quantitatively assess the future conditions of permafrost. 349AI-enhanced algorithms can better align with field data of snow depth. 345Similarly, AI can improve sea ice thickness estimation algorithms to predict changes. 355Utilizing AI for assessing mass balance from ice sheet volumes has the ability to estimate its contribution in sea-level rise, offering a new methodology of climate change studies. 356In addition, AI has improved the precision of identifying each internal ice layer thickness in radar images, overcoming the limitations of traditional feature detection. 348By combining Earth observation technologies, physical modeling, and AI techniques, researchers can delve deeper into the interior of the cryosphere, gaining crucial insights into its formation, evolution, and distribution.This integrated approach not only improves our understanding of cryospheric stereoscopic characteristics, but also enhances climate change research, particularly concerning cryosphere melting and its implications for sea-level rise.</p>
<p>Biosphere</p>
<p>][359][360][361][362] Vegetation properties mapping.Utilizing automatic learning of relationships between hundreds of bands and target variables, ML techniques such as decision trees, neural networks, and support vector machines have demonstrated exceptional efficiency in mapping vegetation structural and biochemical properties, encompassing leaf chlorophyll content, vegetation nitrogen, canopy cover, and leaf area index.In addition, ML algorithms play a crucial role in upscaling carbon fluxes (e.g., gross primary production, net ecosystem exchange, and ecosystem respiration) at regional and global scales.</p>
<p>Extracting vegetation variables is essential for evaluating how vegetation responds dynamically to fluctuating environmental conditions. 12Utilizing automatic learning of relationships between hundreds of spectral bands and target variables, ML techniques such as decision trees, neural networks, and support vector machines have displayed outstanding performance in mapping vegetation structural and biochemical properties.These advanced algorithms effectively quantify parameters such as leaf chlorophyll content, 363,364 vegetation nitrogen, 365 canopy cover, 364,366,367 and leaf area index, [368][369][370] showcasing a substantial improvement over traditional empirical methods.][373] Ecological parameter retrieval.In addition to mapping the vegetation properties and carbon fluxes, AI has advanced the precise identification of critical ecological parameters that were previously challenging to detect quickly and widely in terms of fine scale.Specifically, AI has achieved better performance in 3D structural parameters of forests such as leaf morphology, 91 tree height, 374 tree diameter at breast height, 375 and ground vegetation canopy size. 39Similarly, AI techniques have also been employed in marine plankton structure. 376In addition, AI helped to solve the problem of detecting and monitoring ecological disturbance. 370Previous attempts have been based on laborious and complex handcrafted extraction of image features, but in recent years it has been shown that sophisticated convolutional neural networks can learn to extract relevant features automatically, 377 without human intervention.Automated image interpretation with convolutional neural networks performs very well for monitoring forest diseases and pests, close to human performance, and that makes professional field campaigns less costly. 225In agricultural monitoring research, AI promotes the identification of malnourished crops, thereby assisting in the precise management of farmland. 378Furthermore, AI has made significant progress in fine-scale geographic information simulation and prediction.Specifically, the rapid development of DL has notably enhanced the precision of urban character-istics simulating refined features more precisely than traditional methods. 379AI also advanced the refined simulation of surface temperature and addresses the previously unresolved issue of fine simulation of extreme urban heat island effects. 380ine-scale ecology analysis.On even finer scales, AI has achieved better performance in identifying ecological elements, promoting quantitative research on micro-ecosystems.In the research of diagnosing insects, AI techniques have reached 97% accuracy and outperformed a leading taxonomic expert. 381,382or the identification and classification of vegetation pollen, DL technology has achieved automated pollen analysis methods, 383 which greatly solves the labor cost of labor-intensive pollen analysis in the past and significantly improves analysis efficiency.In addition, as a crucial means of extracting geographic information, classification technology has evolved further with the aid of AI foundations. 367,384Currently, DL exhibits significant advantages in urban canopy detection 370 and tree species classification, 309 among others.By training with a large amount of data, DL-based models can achieve good prediction results for complex phenomena, such as crop element classification 385 and high-precision urban land element classification. 386Simultaneously, existing experimental results demonstrate the superiority of the proposed AI model for both road detection and centerline extraction tasks. 387Meanwhile, the integration of DL with high-resolution remote sensing images enables the refinement of ground feature statistics, which has advantages for separating and interpreting the desired information accurately over traditional remote sensing algorithms.For example, the U-Net neural network was employed to count trees in Africa, 377,388 which has operational difficulties in large-scale monitoring by observational and remote sensing methods.Overall, there is little doubt that there are many opportunities for trait-based ecology to benefit from the integration of computer vision and AI.</p>
<p>Global carbon budget.Accurate assessment of carbon dioxide uptakes and emissions of the terrestrial biosphere is critical to better understand the global carbon cycle, support the development of climate policies, and project future climate change. 93,384AI plays an extremely important role in integrating satellite remote sensing and carbon fluxes from in situ observations to achieve high-precision, high-resolution scientific data on carbon fluxes of terrestrial ecosystems at regional and global scales. 228,389For example, ML has been applied to estimated global plant gross primary production, net ecosystem exchange, ecosystem respiration, and soil respiration by integrating multi-source remote sensing data (i.e., various temperature, moisture, and plant production-related remote sensing products) and carbon fluxes data from ground observations. 390,391The comparative advantages of AI over traditional methods are primarily due to its ability to effectively incorporate nonlinear relationships between remote sensing data and carbon fluxes.Thus, AI could assist the global carbon budget by providing more accurate and higher-resolution global plant production and ecosystem respiration detection.</p>
<p>Other domains</p>
<p>In addition to the aforementioned five spheres, AI is also significantly involved in other domains such as anthroposphere and inter-/cross-spheres, along with the engagement in sustainable development, opening new perspectives for analysis, interpretation, and fostering a more balanced relationship between human society and Earth's systems. 392uman activities understanding.Al plays a crucial role in comprehending and managing Earth's complex systems and environments, serving as a formidable toolset to glean insights, anticipate trends, and devise effective strategies for sustainable development and resource management.AI's multifaceted applications are particularly evident in its utilization by scientists for the analysis of real-time video streams derived from surveillance cameras and satellite imagery.This analytical prowess enables behavior analysis and large-scale monitoring of human activities, thereby offering invaluable insights into lifestyle patterns and social dynamics. 393By harnessing AI-driven analytics, researchers can discern nuanced behavioral patterns, track movement trends, and identify emergent phenomena, facilitating a deeper understanding of human interactions with the environment and informing evidence-based decision-making processes.</p>
<p>Furthermore, AI serves as a cornerstone in the realm of urban development assessment, facilitating comprehensive analyses including diverse facets such as urban expansion, infrastructure changes, etc. 394 Leveraging AI-powered algorithms, urban planners and policymakers can assess the spatial dynamics of urban growth, anticipate infrastructure demands, optimize transportation</p>
<p>REVIEW ll</p>
<p>The Innovation 5(5): 100691, September 9, 2024 networks, and devise sustainable land-use strategies.By amalgamating geospatial data with advanced analytical techniques, AI empowers stakeholders to make informed decisions aimed at fostering resilient, inclusive, and environmentally sustainable urban environments.</p>
<p>In tandem with its applications in physical environment monitoring, AI assumes a pivotal role in unraveling the intricacies of human behavior and preferences in the digital sphere.Social media analysis augmented by AI algorithms offers a potent lens through which online behavior and preferences can be discerned, thereby facilitating targeted advertising, personalized recommendations, and sentiment analysis. 146,395By scrutinizing vast troves of user-generated content, AI-driven analytics can unveil latent trends, identify influencers, and gauge public sentiment, thereby enabling businesses and marketers to tailor their strategies to resonate with their target audience effectively.</p>
<p>In a word, AI's integration into Earth's complex systems and environments represents a paradigm shift in our ability to comprehend, monitor, and manage the multifaceted interplay between human activities and the natural world.By harnessing AI-driven analytics, researchers, policymakers, and businesses can unlock unprecedented insights, foster informed decision-making, and pave the way for a more sustainable and resilient future.However, it is imperative to acknowledge and address the ethical, privacy, and equity considerations inherent in the deployment of AI-powered systems, ensuring that these technologies are leveraged responsibly to serve the collective interests of humanity.</p>
<p>Spheres' interactions.AI has emerged as a powerful tool for capturing interlayer relationships and enhancing simulations of biogeochemical cycles. 393By leveraging AI techniques, such as DL, researchers can gain deeper insights into Earth's historical evolution and phenomena such as the snowball Earth event. 168One notable advantage of AI in this context is its ability to improve computational efficiency 396 and parameter optimization, 397 thereby facilitating more accurate and robust simulations.In addition, AI aids in predicting matter exchange patterns and developing effective adaptation strategies to manage environmental changes.</p>
<p>Furthermore, AI contributes to refining our understanding of Earth's energy budget by integrating DL algorithms with remote sensing applications and incorporating biogeophysical feedback into models of the water cycle. 398,399This interdisciplinary approach enables researchers to assess land surface changes and their impacts on energy budgets.Moreover, AI helps address the risks associated with over-parameterization in models, ensuring that simulations remain realistic and reliable.By identifying critical thresholds that trigger extreme events in Earth's systems, AI plays a crucial role in various applications, including volcano alerts, 400 groundwater mapping, 401 and studying climate-vegetation relationships. 402This capability is crucial for improving early warning systems and mitigating the impacts of natural disasters on human populations and ecosystems.</p>
<p>The potential of AI extends beyond individual applications to regulating interlayer dynamics and foreseeing thresholds that transform interactions at different scales.This proactive approach to exploring Earth's systems and managing its resources holds promise for sustainable Earth management.By leveraging AI technologies, researchers in geoscience can better anticipate and respond to environmental challenges, paving the way for more effective conservation efforts and informed policy decisions.</p>
<p>In conclusion, AI offers significant opportunities for advancing our understanding of Earth's complex systems and enhancing our ability to manage and protect the planet.By harnessing AI's capabilities in capturing inter-layer relationships, optimizing simulations, and identifying critical thresholds, researchers can contribute to proactive exploration and sustainable Earth management.However, realizing this potential requires continued interdisciplinary collaboration and the responsible deployment of AI technologies in geoscience research and environmental conservation efforts.</p>
<p>Sustainable development goals.The United Nations' 2030 Agenda outlines 17 interlinked goals that are set to solve development issues in economic, social, and environmental dimensions and realize sustainable development by 2030. 403These goals interrelate closely with the Earth's spheres (lithosphere, hydrosphere, atmosphere, biosphere, and anthroposphere), aiming to ensure their equilibrium for human well-being and environmental sustainability.The appeal of leveraging AI to advance social benefits and achieve sustainable development goals (SDGs) has captured the attention of numerous practitioners and researchers. 404,405For instance, in exploring the 169 targets outlined for the 17 goals, Vinuesa et al. 406 demonstrated that AI serves as an enabler for 134 targets while acting as an inhibitor for 59 targets.Gupta et al. 407 and Nasir et al. 408 delved into discussions about the implications of AI on the SDGs at the indicator level.</p>
<p>(1) Economic sustainable development goals.The technological benefits facilitated by AI also hold the potential to positively impact the attainment of several SDGs within the Economy group (SDGs 8, 9, 10, 11, and 12).Acemoglu and Restrepo indicate a net positive effect of AI-enabled technologies linked to increased productivity, highlighting potential negative consequences, particularly heightened inequalities. 409If future markets heavily rely on data analysis and these resources are not equitably available in low-and middle-income countries, it could significantly widen the economic gap, exacerbating inequality even within nations. 4102) Social sustainable development goals.For SDGs 1, 2, 3, 4, 5, 7, 16, and 17, in the social group, AI acts as an enabler for all the targets by supporting the provision of food, health, water, and energy services to the population, enhancing poverty mapping, identifying vulnerable populations, and optimizing resource allocation. 411,412AI-based applications, including smart traffic management, waste management, and energyefficient infrastructure, etc., contribute to developing sustainable and resilient urban developments. 413,4143) Environmental sustainable development goals.The potential of AI extends to the analysis of extensive interconnected databases for collaborative initiatives aimed at environmental preservation (SDGs 6, 13, 14, and 15). 411AI aids in water management through predictive analytics, monitoring water quality, and optimizing distribution networks. 415AI is also poised to create low-carbon energy systems with the integration of renewable energy and essential components in climate 800 change, such as detecting the forest changes in satellite images to support habitat monitoring and decision-making. 416,417</p>
<p>LARGE MODELS IN GEOSCIENCE</p>
<p>In this section, our principal objective is to elucidate the most recent developments associated with large models in geoscience, 418 alongside the presentation and summary of representative geoscience pre-trained foundation models.</p>
<p>Progress and application of large models in geoscience</p>
<p>The advent of large language models, prominently illustrated by ChatGPT, has significantly advanced diverse domains, concurrently empowering AI technologies to facilitate remarkable scientific progress, notably in geoscience.][428][429][430] Specifically, the remote sensing domain owns the most diverse data in the entire Earth science field. 431,432General applications such as object detection, semantic segmentation, scene classification, and change detection from various data sources promoted the development of large models in remote sensing, such as the largest spectral remote sensing foundation model, 433 with an effective method for expanding and fine-tuning ViT. 434Recently, AI Earth-based on a universal segmentation model (AIE-SEG) -was proposed by Alibaba to quickly extract any target in remote sensing images, achieving unified image segmentation tasks and rapid extraction of "zero samples of all things" without any labeled data.A new AI model called "segment anything model" from Meta AI can "cut out" any object in any image with zero-shot generalization to unfamiliar objects and images, without the need for additional training. 435IBM and NASA have also teamed up to develop an open-source, geospatial foundation model that will enable researchers and scientists to utilize AI to track the amount of satellite data. 436Furthermore, there is rapid development in multimodal remote sensing large models.For instance, SkySense 158 is a generic billion-scale model pre-trained on a curated multi-modal remote sensing imagery dataset with 21.5 million temporal sequences.In addition, large-scale vision-language models, such as EarthGPT, 437 have garnered significant attention in the remote sensing field, aiming to unify various remote sensing tasks and multi-sensor images.In a general sense, it can be observed that the utilization of large computer vision models and the efficient exploitation of vast remote sensing datasets to enhance the recognition of various targets represents a prominent trajectory in the evolution of large remote sensing models.</p>
<p>In the climate and weather domains, numerous large models with a great amount of data and parameters have been trained for predictions.For example, a Fourier forecasting neural network (FourCastNet) is proposed to provide immediate accurate short to medium-range global weather predictions. 438The predictive outcomes derived from the FourCastNet model have been meticulously juxtaposed with the findings of the integrated forecasting system.It has been ascertained that the FourCastNet model exhibits substantial advantages across a multitude of performance indicators, with a particular emphasis on its notable progress in the domain of precipitation forecasting.Notably, the accuracy of the FourCastNet model surpasses that of other ones by an impressive margin, exceeding 20%.Pangu-Weather, 187 which harnesses the power of the 3D Earth-specific Transformer, has been empirically demonstrated to yield superior results, accompanied by a remarkable acceleration of 10,000 times, in contrast to the ECMWF.The proposal of NowcastNet, 232 a nonlinear nowcasting model for extreme precipitation, signifies a novel approach that unifies physical-evolution schemes and conditional-learning methods within a neural network framework.This model has proven its capacity to skillfully forecast extreme precipitation events characterized by advective or convective processes, previously deemed challenging to predict.MetNet-3, 439 a collaborative development by Google and DeepMind, has enhanced high-resolution predictions of several weather variables, encompassing precipitation, surface temperature, wind speed, and wind direction, for a forecast horizon extending up to 24 h.GenCast 440 proposes a generative model for global medium-range ensemble weather forecasting up to 15 days ahead, utilizing a diffusion model to sample ensembles from future weather trajectories.In addition, the swift advancement of large language models has positively impacted climate-related endeavors.For example, ClimateGPT 441 serves as a specialized conversational agent for climate change and sustainability topics in English and Arabic.</p>
<p>Concurrently, there have been recent propositions in the development of general geoscientific large-scale models.In the context of hydrology, a foundation platform, HydroPML, 323 is proposed for hydrological applications based on physics-aware ML.It bridges the gap between large language models and process-based hydrology, offering a range of applications, including but not limited to rainfall-runoff-inundation modeling, 122 real-time flood forecasting, 321 and cutting-edge methods to enhance water security and foster resilient water management.The first-ever large language model in the ocean domain, OceanGPT, 429 is introduced as an expert in various ocean science tasks.In the domain of disaster management and response, Disaster Response GPT is proposed to provide a versatile and adaptive framework for addressing various types of disasters and their associated challenges. 442Furthermore, large models for time series forecasting, including variables such as wind and weather, have been proposed, leveraging a transformer backbone and zero-shot transfer. 443n summary, substantial advancements have been made in remote sensing and climate domains by deploying large models and effectively utilizing extensive datasets.However, widespread adoption of these methods on a broad scale remains challenging, particularly in extreme weather prediction.Progress in other geoscience areas, such as disaster prevention and hydrology, has been hindered by limited access to datasets and computing resources, slowing down the development of large language models.In the future, developing a unified, interpretable, and continuously learning large model to address the complexities and scales of geoscience will be a focus of ongoing exploration.</p>
<p>Pre-training of large geoscience models</p>
<p>Table 1 illustrates the schematic representation of the foundation of pretrained models in geoscience.In the realm of remote sensing, various approaches have emerged, for instance, MoCo-V2 with geographic location serving as an agent task in conjunction with contrast learning for base model training, 154 CSPT using knowledge migration and image mask learning to enhance the expressive capability of the pre-trained model, 444 SeCo constructing positivenegative sample pairs from different seasons to effectively utilize unlabeled multi-seasonal data. 445Wuhan University introduced the Billion Visual Transformer model, 446 exploiting a masking strategy for pre-processing, and achieved notable performance in image classification, target detection, and semantic segmentation.SatMAE, 447 proposed by Stanford University, adopts a grouped masking strategy for multi-temporal and multi-channel multispectral images.Recently, Hong et al. 433 designed the first and largest customized foundation model for spectral remote sensing data, i.e., SpectralGPT, achieving state-of-the-art performance in various downstream applications.Simultaneously, the work 448 combines SAR and multispectral images for a contrast learning approach.Another study 449 employs contrast learning, image filling, and deformation prediction as agent tasks to enhance the generalization of the pre-trained model.Researchers at the University of California, Berkeley focus on spatial scale information, modeling low-frequency and high-frequency details separately in the reconstruction layer. 450In addition, Hong et al. 451 explored multimodal fusion on various image types, including optical images, SAR images, digital elevation models, and MAP data, 452 which innovated a new paradigm of multimodal AI big models for Earth observation, unlocking the Earth observation capability of remote sensing big data. 453Presto reconstructs time series images through stacking and employing randomized masking strategies.Furthermore, GFM employs a teacher-student two-stream network on large-scale datasets, 454 excelling in scene classification, change detection, and semantic segmentation.Satvit explores the role of the MAE framework in analyzing satellite remote sensing data. 455n a distinct domain, ClimaX is pre-trained on the CMIP6 climate dataset, 428 offering versatility in weather and climate tasks.Notably, K2, 459 a 7 billion parameter Earth science language model from Shanghai Jiao Tong University, utilizes a two-stage construction involving pre-training on a high-quality Earth science corpus and instruction fine-tuning with a geosignal dataset.In contrast, general visual models such as Sky Eye and SenseEarth 3.0 improve remote sensing interpretation efficiency, leveraging Transformer-like backbones and self-supervised learning.</p>
<p>In summary, algorithms designed for processing remote sensing images exhibit variations in their emphasis on RGB, multispectral, or hyperspectral data, tailored for application to specific downstream tasks.Notably, contemporary climate and geoscience models such as K2 and ClimaX exemplify advancements in addressing challenges within these domains, showcasing enhanced efficiency and robustness for applications in Earth science.Despite the immense potential of large geoscience models, common research teams (usually small groups) encounter numerous impediments in embracing large-scale (pretrained) models.Chiefly, constraints in resources, encompassing limited funding and manpower, impede their capacity to conduct research and development effectively.In addition, the intricacy of large-scale models poses a formidable learning curve for small teams, who may grapple with acquiring expertise across diverse disciplines such as ML and natural language processing.In the long term, the absence of access to comprehensive datasets and formidable competition from large tech companies further impede their progress.Legal and ethical considerations also present challenges, as small teams may lack the resources to adeptly navigate intricate issues such as privacy and accountability.Overall, surmounting these hurdles will necessitate strategic investments, collaboration, and concerted efforts to address legal and ethical concerns.</p>
<p>Deep-time digital Earth</p>
<p>Delving into the deep-time history of Earth is seen as a promising avenue to unravel the mechanisms of Earth's evolution, expose climate change patterns, identify natural resources, and envisage the future of our planet. 171,460The advent of big data science in recent decades provides a valuable opportunity to tackle these questions.To expedite exploratory studies of Earth's evolution, there is a pressing need for an equitable, integrated database.To achieve this goal, the Deep Time Digital Earth (DDE) project is proposed as the inaugural "large-scale scientific project" by the International Union of Geological Sciences.This initiative aims to facilitate deep-time, data-driven discoveries through collaborative efforts across nations and disciplines. 461Moreover, it introduces an open data platform to establish connections between existing deep-time geocounts and integrated geological data.</p>
<p>(1) Earth's life evolution.The synergy of AI and data science has significantly advanced our comprehension of Earth's life evolution, particularly concerning early complex life and mass extinctions.For instance,</p>
<p>REVIEW</p>
<p>ML methods are employed to analyze deep-time marine Paleozoic data, unraveling the impact of environmental changes on biodiversity. 462The pulsed extinction of early complex life was further corroborated through network analysis of Ediacaran fossils. 463Furthermore, the DDE project aims to integrate and interconnect existing deep paleontological and stratigraphic databases, leveraging DL and other AI tools to expedite biological data-driven discoveries. 4642) Earth's material evolution.In the context of Earth's material evolution, current AI-driven approaches strive to propel the evolution and discovery of minerals, rocks, sediments, and fluids.Noteworthy examples encompass the evolution of minerals, 465 the cycling of sediments, 466 and the interpretation of plate tectonics. 467In addition, AI-driven discovery necessitates the integration of existing geomaterial databases by the DDE, enhancing spatial and temporal coverage as well as resolution in the discovery of geomaterials.(3) Geography's evolution.Geography's evolution holds paramount significance in various domains, including mineral and energy resource assessment, Earth hazard prediction, comprehending Earth's history, and forecasting the future.The correlation of deep Earth science databases with paleogeographic reconstruction databases is an important goal of DDE.Supported by big data analysis techniques, this combina-tion has been widely used in the field of paleontology, 468 paleoclimatology, 469 and geodynamics. 470(4) Paleoclimate's evolution.The exploration of paleoclimate assumes a crucial role in understanding the interaction between Earth and life in producing climate extremes and forecasting future climate changes. 471I's strengths in data processing, hypothesizing, and predicting within Earth science research substantially facilitate paleoclimate reconstruction. 472Assisted by AI, the DDE can reconstruct the history of paleoclimate and paleoatmosphere, relying on various minerals, rocks, and geochemical indicators preserved in Earth material. 473 summary, the establishment of a unified representation model to head the construction of an integrated Earth science knowledge map is one of the key programs of DDE, 474,475 and a series of knowledge graphs have emerged, such as the paleoclimate knowledge graph, 476 standard carbonate microfacies, 477 and academic knowledge graph. 478With the continued emergence of geoscientific macrolanguage models (such as K2 459 ), AI has dramatically changed the traditional paradigm of geoscientific research.By harmonizing and integrating deep Earth data, geological knowledge, and advanced techniques in data science and AI, DDE is poised to advance solutions for the significant challenges in Earth evolution research, understanding the past, present, and future of our planet.</p>
<p>CHALLENGES AND OUTLOOKS IN AI FOR GEOSCIENCE</p>
<p>The numerous cases and advanced techniques outlined in the previous sections solidly prove that AI is an expert technology at deciphering complex relationships in the Earth system and predicting environmental responses with unprecedented accuracy.However, this is not the end of the journey; there remain ongoing challenges and opportunities in the field of research.This section poses the challenges and future perspectives to promote the co-development of AI and geoscience.</p>
<p>Unsolved challenges of AI for geoscience</p>
<p>There are many unsolved challenges in AI for geoscience, particularly at the intersection of these two fields.These challenges arise from interdisciplinary complexities, making it difficult for scientists to identify and address the problems.</p>
<p>Ethical considerations play a crucial role across all stages of geoscience disciplines, encompassing data collection, analysis, and distribution. 479High-resolution data, for example, raise privacy concerns, 480 while socio-economic analyses can lead to stigmatization if not handled carefully. 481The demand for explainability grows as AI applications extend their reach into policy-making, requiring models to be both transparent and justifiable. 146Addressing these ethical challenges involves adhering to robust ethical frameworks and guidelines, promoting a culture of geoethical thinking and social responsibility among researchers.</p>
<p>Moreover, due to the biased learning knowledge by AI, the adeptness of AI in modeling complex relationships brings about vulnerabilities related to data security. 482,483The potential for data bias and tampering poses significant risks, potentially leading to misrepresentations of geographical features and misguided policy decisions.To mitigate these risks, a multifaceted approach, including robust data validation and enhancements in AI learning specifications, is essential.These strategies not only fortify data integrity but also improve the resilience of AI systems against malicious manipulations.</p>
<p>Despite the exceptional capabilities of AI, the demand for computing resources and the costs associated with data acquisition and processing present substantial challenges. 17The computational intensity required for models, such as predicting global climate 187 or global forest fire interactions, 484 necessitates substantial investment in computational and memory resources, often beyond the reach of many geoscientists.Moreover, the AI models should be energy efficient so that they can also contribute to the NetZero agenda.To optimize performance and reduce expenses, strategies such as leveraging cloud computing, applying transfer learning, and enhancing data management practices are vital. 284These approaches help in managing the high costs and logistical demands of extensive data processing, ensuring that AI applications remain both viable and effective.</p>
<p>Emerging challenges in new paradigm of hybrid models</p>
<p>Hybrid models, leveraging the strength of physics-based models and AI, are starting to show their charming potential as a new research paradigm in geoscience.Despite their potential, they present challenges in the development of the paradigm.</p>
<p>The first challenge is the uncertain interpretability within the model.While the structure of hybrid models seems to maintain physical plausibility, and the AI component can even effectively compensate for structural deficiency in physics-based counterpart, 485,486 there remains a critical concern.Often, the balance between physics-based and AI components in hybrid models may be overlooked due to a lack of integration knowledge within the "gray box."The work by Acuña Espinoza et al. 487 suggests that AI-based parameterization may learn incorrect behaviors and overwrite the physical interpretability in the hybrid hydrological models, despite enhancing performance.This compensatory capability of AI raises questions about the true hydrological interpretability of outputs from hybrid models.It also calls for a more cautious use of hybrid models in geoscience applications, particularly when the primary objective is to decipher geophysical processes rather than merely improve prediction accuracy.</p>
<p>Another challenge in advancing this paradigm is extending these hybrid models to accommodate large datasets and complex system interactions inherent in global geoscience applications.As these models scale, the structural deficiencies in the physics-based part of the hybrid model will be magnified, 485 and maintaining a balance between AI fitting capabilities and physical interpret-ability will become increasingly difficult.Therefore, large models currently applied in geoscience, such as the FourCastNet and Pangu-Weather models, are still predominantly in the data-driven paradigm and risk losing physical plausibility.This scaling issue highlights the need for a deep understanding of geophysical processes in hybrid models at the regional scale.</p>
<p>Outlook on AI for inter-spheres</p>
<p>While the application and knowledge of AI for intra-spheres are relatively comprehensive, exploring inter-spheres connection in geoscience reveals significant knowledge gaps. 488These gaps arise from the challenges of integrating fragmented knowledge across disciplines when enhancing Earth system models.The complexity of cross-system dynamics and feedback mechanisms complicates the encoding of multidisciplinary and multi-domain knowledge.For instance, the biochemical and biophysical processes within the hydrological cycle 489 and the atmospheric-ocean interaction 490 are crucial cases for understanding the hydrological cycle and predicting phenomena such as the Madden-Julian Oscillation and El Niño Southern Oscillation, respectively.Yet, they exhibit gaps in multidisciplinary integration.</p>
<p>Undoubtedly, AI has demonstrated the potential to bridge these interdisciplinary gaps, as demonstrated by its successful application within individual domains.Several studies have already started to apply AI to forge connections across multiple spheres.For example, AI-powered prediction models have been used to forecast hurricanes by analyzing the complex interplay between ocean temperatures, atmospheric conditions, and land surface characteristics. 491However, advancing AI development in the inter-sphere's context requires greater efforts, including more robust exchanges of expert knowledge and domain-specific insights.</p>
<p>Outlook of AI for exploring exoplanets</p>
<p>The lack of terrestrial data with viable and varied observational evidence represents a significant bottleneck in the development of geoscience.Terrestrial exoplanets, sharing similar geophysical processes, can complement the data gap.Planetary scientists suggest that the understanding of the cooling and transfer of heat from the interiors of terrestrial planets can help explain the geological evolution of Earth. 492Furthermore, studying tidal interaction on lowmass planets can aid in understanding atmospheric circulation and meteorological phenomena on Earth. 493This highlights the potential of exoplanet exploration to offer new insights into our own planet.</p>
<p>In contrast to knowledge transfer from exoplanets to Earth, there remain plenty of unknowns about the environment of exoplanets, frequently resulting in a less sophisticated understanding of their geophysical processes compared with Earth.Generally, discussions about exoplanet characteristics often simply rely on the knowledge of an exoplanet's mass, radius, or orbital distance.In this context, the power of AI can be used to decipher the high complexity of an exoplanet's system.Some works 494,495 suggest that AI approaches trained by biosignatures on Earth could be adapted for searching for life on terrestrial exoplanets.Interdisciplinary application of AI in geoscience, transferring from Earth to exoplanets, could enhance our understanding of these distant worlds' geophysical processes, thereby offering a fresh perspective on Earth in the future.</p>
<p>Future development of AI for geoscience</p>
<p>Our review demonstrates the necessity of advancing AI for geoscience research.Looking ahead, AI is poised to significantly enhance geoscience projects, supported by various government and authoritative endorsements.For example, the China Ministry of Science and Technology highlights AI as a pivotal tool for groundbreaking research across four strategic frontiers: deep space, deep sea, deep Earth, and "deep blue."Similarly, NASA regards AI as an essential component for future Earth explorations. 496onversely, our review also acknowledges the profound and dynamic impact of AI on our understanding of geoscience and on decision-making processes.However, there is limited consensus on the regulations governing AI development and usage.The United Nations Educational, Scientific and Cultural Organization 497 and the European Union's General Data Protection Regulation 498 underscore the importance of ethical considerations, such as privacy, interpretability, and security in AI applications, which indicates the need for a model-data-driven paradigm to enhance transparency in research.</p>
<p>REVIEW ll</p>
<p>The Innovation 5(5): 100691, September 9, 2024</p>
<p>CONCLUSION</p>
<p>The research paradigms in geoscience started with physics-based models, followed by data-driven approaches, and merged into hybrid models.This review strives to delineate these paradigms, emphasizing the unexplored frontiers where cutting-edge AI techniques intersect with geoscience.We put a special focus on hybrid models, which, leveraging domain knowledge to guide AI models, often require less training data while maintaining comparable accuracy, thus offering enhanced efficiency and performance.The potential of large-scale AI models in geoscience is vast, yet its realization faces challenges unique to the domain, impeding its widespread adoption and implementation.The dichotomy between these paradigms-space centered on explicit adherence to physical rules versus the extraction of insights from immense data volumes-underscores the need for a balanced approach in contemporary geoscience.</p>
<p>In essence, the quest to comprehend Earth's intricacies demands an amalgamation of diverse methodologies and approaches.The synergy between traditional principles and modern AI-driven techniques holds immense promise, yet it also presents a spectrum of challenges that require concerted efforts to overcome.As geoscientists navigate this dynamic terrain, a harmonized blend of methodologies stands poised to unlock profound insights into our planet's mysteries, shaping the trajectory of geoscience in the years to come.</p>
<p>Figure 1 .
1
Figure 1.Illustration of four research paradigms in geoscience</p>
<p>Figure 2 .
2
Figure 2. AI-assisted observations, hypotheses, and predictions of geoscience</p>
<p>Table 1 .
1
Representative pre-trained foundation models in geoscience
Application fieldModelPre-trained modelObjectivesRemote sensingCSPT 444ViTimproving the expressive ability of the pre-trained modelRingMo 456ViT/Swin Transformera remote sensing foundation model withmasked image modelingScale-MAE 450Transformera pre-trained framework that introduces scaleinvariance into encoders that are used for adiverse set of downstream tasksSatMAE 447Transformerpre-training Transformers for temporal andmulti-spectral satellite imagerypre-trained ViT 427ViTremote sensing foundation modelGFM 454ViTbuilding geospatial foundation models viacontinual pre-trainingSatViT 455ViTpre-training transformers for EarthobservationsMasked ViT 457ViTself-supervised masked image reconstructionto advance transformer models forhyperspectral remote sensing imagerySpectralGPT 433ViTthe first customized foundation modeldesigned explicitly for spectral remotesensing dataWeather and climateEarthformer 458Transformera space-time Transformer for Earth systemforecastingFourCastNet 438Fourier Neural Operatorprovide accurate short-to medium-rangeglobal predictionsGraphCast 157GNNmedium-range global weather forecastingNowcastNet 232physics-conditional generative networka nonlinear nowcasting model for extremeprecipitationMetNet 439U-Net + ViThigh-resolution predictions of several coreweather variablesPangu-weather 1873D Transformeraccurate medium-range global weatherforecastingClimateX 428ViTa foundation model for weather and climateOthersK2 459Generative model (LLaMA-7B)Earth science large language modelDisasterResponseGPT 442Generative modelprovide a versatile and adaptive framework fordisastersOceanGPT 429Generative modela large language model for oceanscience tasks
The Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovation www.the-innovation.org
The Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationwww.the-innovation.orgThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationwww.the-innovation.orgThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationwww.the-innovation.orgThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationwww.the-innovation.orgThe Innovation 5(5): 100691, September 9, 2024 www.cell.com/the-innovationwww.the-innovation.orgACKNOWLEDGMENTS This work was partially supported by National Natural Science Foundation of China (T2225019, 41925007, 62372470, U21A2013, 42201415, 42022054, 42241109, 42077156, 52121006, 42090014, and 42325107), the National Key R&amp;D Programme of China (2022YFF0 500), the Youth Innovation Promotion Association CAS (2023112), the Strategic Priority Research Program of CAS (XDA23090303), and the RECLAIM Network Plus (EP/W034034/1).AUTHOR CONTRIBUTIONSC.L., Y. Xie, and A.P. wrote the introduction.M.C., F.Z., and Z.Q.wrote the paradigms section.S.W., L.Y., C.Y., W.H., T.S., Z.S., T.Q., and Z.C. wrote the AI-driven geoscience paradigms section.C.S., S.Y., N.L., and Y.Z.wrote the atmosphere section.H.Z. wrote the lithosphere section.J. Zeng, H.S., C.Z., and J. Zhang wrote the hydrosphere section.T.Z.wrote the cryosphere section.L. Wang, N.H., and C.H. wrote the biosphere section.L.L., H.Z., and W.Z. wrote the other domains section.T.Z., H.L., J.S., and D.F. revised the typical cases section.C.O., Q.X., Y.W., S.W., and D.H. wrote the large models in geoscience section.J. Zhang, Z.W., Y.L., and T.Z.wrote the challenges and future perspectives in AI for geoscience section.A.P., Lizhe Wang, Y. Xu, F. Wang, B.Z., P.K., and J.L. revised the paper.DECLARATION OF INTERESTSThe authors declare no competing interests.LEAD CONTACT WEBSITEhttps://grzy.cug.edu.cn/LizheWang.
Geoscientists excluded. J Super, 10.1038/s41561-023-01152-zNat. Geosci. 1631942023</p>
<p>A Credit System to Solve Agricultural Nitrogen Pollution. Innovation. B Gu, H J Van Grinsven, S K Lam, 10.1016/j.xinn.2021.10007920212100079</p>
<p>Formation of the Earth. G W Wetherill, 10.1146/annurev.ea.18.050190.001225Annu. Rev. Earth Planet Sci. 1811990</p>
<p>How and Where Did Life on Earth Arise?. C Zimmer, 10.1126/science.309.5731.89Science. 3095731892005</p>
<p>Nitrogen Isotopic Composition and Density of the Archean Atmosphere. B A Marty, L Zimmermann, M Pujol, 10.1126/science.1240971Science. 34261542013</p>
<p>Evolutionary dichotomy for rocky planets. L T Elkins-Tanton, 10.1038/497570aNature. 49774512013</p>
<p>Casting stress shadows. A M Freed, Nat. Geosci. 562012</p>
<p>Milankovitch theory and monsoon. H Cheng, H Li, L Sha, 10.1016/j.xinn.2022.100338Innovation. 361003382022</p>
<p>Low-latitude forcing, A new insight into paleo-climate changes. P Wang, 10.1016/j.xinn.2021.100145Innovation. 231001452021</p>
<p>Machine learning for data-driven discovery in solid Earth geoscience. K J Bergen, P A Johnson, M V De Hoop, 10.1126/science.aau0323Science. 36364333232019</p>
<p>Geoscience-aware deep learning, A new paradigm for remote sensing. Y Ge, X Zhang, P M Atkinson, 10.1016/j.srs.2022.100047Sci. Remote Sens. 51000472022</p>
<p>Urban heat mitigation by green and blue infrastructure, Drivers, effectiveness, and future needs. P Kumar, S E Debele, S Khalili, 10.1016/j.xinn.2024.100588Innovation. 521005882024</p>
<p>. H Cheng, 10.1016/j.xinn.2020.100055Future Earth and Sustainable Developments. Innovation. 131000552020</p>
<p>Remote triggering of deep earthquakes in the 2002 Tonga se-quences. R Tibi, D A Wiens, H Inoue, 10.1038/nature01903Nature. 42469512003</p>
<p>Nonlinear Time Series Analysis in the Geosciences. R V Donner, S M Barbosa, 10.1007/978-3-540-78938-3Lect. Notes Earth Sci. 112372008. 2008</p>
<p>Complexity and Extreme Events in Geosciences, An Overview. A S Sharma, D N Baker, A Bhattacharyya, 10.1029/2012GM001233Geophys. Monogr. Ser. 1962012</p>
<p>Deep learning and process understanding for data-driven earth system science. M Reichstein, G Camps-Valls, B Stevens, 10.5194/egusphere-egu24-15874Nature. 5662019</p>
<p>Artificial intelligence, A powerful paradigm for scientific research. Y Xu, X Liu, X Cao, 10.1109/iiccit55816.2022.10010688Innovation. 241001792021</p>
<p>Penetrating remote sensing, Next-generation remote sensing for transparent earth. L Wang, B Zuo, Y Le, 10.1016/j.xinn.2023.100519Innovation. 461005192023</p>
<p>Toward a sustainable grassland ecosystem worldwide. J Sun, Y Wang, S Piao, 10.1016/j.xinn.2022.100265Innovation. 341002652022</p>
<p>Demonstration of 10 Gbps satellite-to-ground laser communications in engineering. Y Li, H Zhang, P Huang, 10.1016/j.xinn.2023.100557Innovation. 511005572024</p>
<p>Artificial intelligence for science-bridging data to wisdom. Y Xu, F Wang, Z An, 10.1016/j.xinn.2023.100525Innovation. 461005252023</p>
<p>Geoscience concept models. S M Richard, 10.1130/2006.2397(07Geoinformatics, Data to Knowledge. Geological Society of America2006</p>
<p>A Bokulich, N Oreskes, 10.1007/978-3-319-30526-4_41Models in Geosciences. Springer Handb. Model-Based Sci. 2017</p>
<p>. M S Bruno, 10.1007/1-4020-3880-1_245Physical Models. Encycl. Earth Sci. Ser. 2005</p>
<p>From Scaling to Simulation, Changing Meanings and Ambitions of Models in. N Oreskes, 10.1515/9780822390244-006Geology. 2020</p>
<p>Mathematical Modelling. A Fowler, 10.1007/978-0-85729-721-1Math. Geosci. 2011</p>
<p>T Gerya, 10.1017/9781316534243Introduction to Numerical Geodynamic Modelling. Cambridge University Press2019</p>
<p>E Winsberg, 10.1007/978-3-031-38647-3_2Computer Simulations in Science. E N Zalta, U Nodelman, 2015Stanford University</p>
<p>Numerical weather prediction. R Kimura, J. Wind Eng. Ind. Aerodyn. 90122002</p>
<p>Geology, environment, and life in the deepest part of the world's oceans. M Du, X Peng, H Zhang, 10.1016/j.xinn.2021.100109Innovation. 222021</p>
<p>Physical-statistical modeling in geophysics. L M Berliner, 10.1029/2002JD002865J. Geophys. Res. 108242003</p>
<p>Modelling Geomorphic Systems: Scaled Physical Models. D Green, 2014Geomorphol</p>
<p>Predicting the uncertainty of numerical weather forecasts: a review. M Ehrendorfer, 19976</p>
<p>Coupled deep-mantle carbon-water cycle: Evidence from lower-mantle diamonds. W Wang, O Tschauner, S Huang, 10.1016/j.xinn.2021.100117Innovation. 221001172021</p>
<p>Data-driven modeling of solar coronal magnetic field evolution and eruptions. C Jiang, X Feng, Y Guo, 10.1016/j.xinn.2022.100236Innovation. 331002362022</p>
<p>Machine learning in geosciences and remote sensing. D J Lary, A H Alavi, A H Gandomi, 10.1016/j.gsf.2015.07.003Geosci. Front. 712016</p>
<p>Editorial: Artificial intelligence and machine learning in Earth science. S.-A Ouadfeul, S D Jawak, A Shirzadi, 10.3389/feart.2022.1090016Front. Earth Sci. 102023</p>
<p>A comprehensive framework for seasonal controls of leaf abscission and productivity in evergreen broadleaved tropical and subtropical forests. X Yang, J Wu, X Chen, 10.1016/j.xinn.2021.100154Innovation. 241001542021</p>
<p>Deforestation in Latin America in the 2000s predominantly occurred outside of typical mature forests. Z Zhang, W Ni, S Quegan, 10.1016/j.xinn.2024.100610Innovation. 531006102024</p>
<p>A Statistical Approach to Some Mine Valuation and Allied Problems on the Witwatersrand. D G Krige, D.G. Krige, ed.1951Univ. of the Witwatersrand)</p>
<p>Kriging method application and traffic behavior profiles from local radar network database: A proposal to support traffic solutions and air pollution control strategies. J A Pinto, P Kumar, M F Alonso, 10.1016/j.scs.2020.102062Sustain. Cities Soc. 561020622020</p>
<p>Mapping spatial distribution of particulate matter using kriging and inverse distance weighting at supersites of megacity Delhi. K Shukla, P Kumar, G S Mann, 10.1016/j.scs.2019.101997Sustain. Cities Soc. 541019972020</p>
<p>E Mjolsness, D Decoste, 10.1126/science.293.5537.2051Machine Learning for Science: State of the Art and Future Prospects. 2001293</p>
<p>Principal component analysis and K-means clustering as tools during exploration for Zn skarn deposits and industrial carbonates. N F Jansson, R L Allen, G Skogsmo, 10.1016/j.gexplo.2021.106909J. Geochem. Explor. 2331069092022</p>
<p>Spectral-Spatial Hyperspectral Image Segmentation Using Subspace Multinomial Logistic Regression and Markov Random Fields. J Li, J M Bioucas-Dias, A Plaza, 10.1109/TGRS.2011.2162649IEEE Trans. Geosci. Remote Sens. 5032012</p>
<p>Integrating scientific knowledge into machine learning using interactive decision trees. G Sarailidis, T Wagener, F Pianosi, 10.1016/j.cageo.2022.105248Comput. Geosci. 1701052482022</p>
<p>Feature-Driven Active Learning for Hyperspectral Image Classification. C Liu, L He, Z Li, 10.1109/TGRS.2017.2747862IEEE Trans. Geosci. Remote Sens. 5612018</p>
<p>Artificial Intelligence in Geoscience and Remote Sensing. D J Lary, 10.5772/9104Geosci. Remote Sens. New Achiev. 2010</p>
<p>Towards full-stack deep learning-empowered data processing pipeline for synchrotron tomography experiments. Z Zhang, C Li, W Wang, Innovation. 511005392024</p>
<p>Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. X X Zhu, D Tuia, L Mou, 10.1109/MGRS.2017.2762307IEEE Geosci. Remote Sens. Mag. 542017</p>
<p>Particulate matter forecasting using different deep neural network topologies and wavelets for feature augmentation. S L J Galvão, J C O Matos, Y K L Kitagawa, 10.3390/atmos13091451Atmosphere-Basel. 13914512022</p>
<p>An intelligent optimized deep networkbased predictive system for wind power plant application. M A Baseer, A Almunif, I Alsaduni, 10.1007/s00202-024-02377-wElectr. Eng. 2024</p>
<p>ImageNet Classification with Deep Convolutional Neural Networks. A Krizhevsky, I Sutskever, G E Hinton, 10.1145/3065386NeurIPS. 252012</p>
<p>Unsupervised Spectral-Spatial Feature Learning via Deep Residual Conv-Deconv Network for Hyperspectral Image Classification. L Mou, P Ghamisi, X X Zhu, 10.1109/TGRS.2017.2748160IEEE Trans. Geosci. Remote Sens. 5612018</p>
<p>When CNNs Meet Vision Transformer: A Joint Framework for Remote Sensing Scene Classification. P Deng, K Xu, H Huang, 10.1109/LGRS.2021.3109061IEEE Geosci. Remote Sens. Lett. 192022</p>
<p>Multi-scale digital soil mapping with deep learning. T Behrens, K Schmidt, R A Macmillan, 10.1038/s41598-018-33516-6Sci. Rep. 81152442018</p>
<p>Learning Spectral-Spatial-Temporal Features via a Recurrent Convolutional Neural Network for Change Detection in Multispectral Imagery. L Mou, L Bruzzone, X X Zhu, 10.1109/TGRS.2018.2863224IEEE Trans. Geosci. Remote Sens. 5722019</p>
<p>Machine Learning for the Geosciences: Challenges and Opportunities. A Karpatne, I Ebert-Uphoff, S Ravela, 10.1109/TKDE.2018.2861006IEEE Trans. Knowl. Data Eng. 3182019</p>
<p>Deep Learning for Geophysics: Current and Future Trends. S Yu, J Ma, 10.1029/2021RG000742Rev. Geophys. 5932021</p>
<p>Application of machine learning, deep learning and optimization algorithms in geoengineering and geoscience: Comprehensive review and future challenge. W Zhang, X Gu, L Tang, 10.1016/j.gr.2022.03.015Gondwana Res. 1092022</p>
<p>Advancing AI for Earth science: A data systems perspective. M Maskey, H Alemohammad, K Murphy, 10.1029/2020eo151245ESA EO Phiweek. 2020</p>
<p>Differentiable modelling to unify machine learning and physical models for geosciences. C Shen, A P Appling, P Gentine, 10.1038/s43017-023-00450-9Nat. Rev. Earth Environ. 482023</p>
<p>Naive Gabor Networks for Hyperspectral Image Classification. C Liu, J Li, L He, 10.1109/TNNLS.2020.2978760IEEE Trans. Neural Netw. Learn. Syst. 3212021</p>
<p>Improving AI System Awareness of Geoscience Knowledge: Symbiotic Integration of Physical Approaches and Deep Learning. S Jiang, Y Zheng, D Solomatine, 10.1029/2020GL088229Geophys. Res. Lett. 47132020</p>
<p>Integrating physics-based modeling with machine learning: A survey. J Willard, X Jia, S Xu, 10.1145/1122445.11224562020Preprint at arXiv</p>
<p>Advancing deep learning for Earth sciences: From hybrid modeling to interpretability. G Camps-Valls, M Reichstein, X X Zhu, 10.1109/IGARSS39084.2020.932355820202020</p>
<p>ChatGPT and environmental research. J.-J Zhu, J Jiang, M Yang, 10.1021/acs.est.3c01818Environ. Sci. Technol. 57462023</p>
<p>SSL4EOS12: A large-scale multimodal, multitemporal dataset for self-supervised learning in Earth observation. Y Wang, N Ait Ali Braham, Z Xiong, 10.1109/MGRS.2023.3281651IEEE Geosci. Remote Sens. Mag. 1132023</p>
<p>Chapter One -70 years of machine learning in geoscience in review. J S Dramsch, 10.1016/bs.agph.2020.08.002Adv. Geophys. 612020</p>
<p>Self-supervised learning in remote sensing: A review. Y Wang, C M Albrecht, N N A A Ait Ali Braham, 10.1109/MGRS.2022.3198244IEEE Geosci. Remote Sens. Mag. 1042022</p>
<p>CHES: An astrometry mission searching for nearby habitable planets. J Ji, S Wang, H Li, 10.1016/j.xinn.2022.100270Innovation. 342022</p>
<p>J Ge, H Zhang, H Deng, 10.1016/j.xinn.2022.100271The ET mission to search for Earth 2.0s. Innovation. 20223100271</p>
<p>Exploring the universe and protecting the Earth: Young Chinese scientists in action. H Le, Z Rong, Y Wei, 10.1016/j.xinn.2023.100466Innovation. 441004662023</p>
<p>JWST's eyes on an alien world. X Zhang, 10.1016/j.xinn.2023.100428Innovation. 431004282023</p>
<p>Mars Exploration in 2020. Y C Zheng, 10.1016/j.xinn.2020.100036Innovation. 121000362020</p>
<p>. Artemis -Nasa , </p>
<p>China's Lunar and Deep Space Exploration. </p>
<p>New Lunar Samples Returned by Chang'e-5: Opportunities for New Discoveries and International Collaboration. W Yang, Y Lin, 10.1016/j.xinn.2020.100070Innovation. 211000702021</p>
<p>Overview of the LAMOST survey in the first decade. H Yan, H Li, S Wang, 10.1016/j.xinn.2022.100224Innovation. 321002242022</p>
<p>Go beyond Hubble and go deeper in the universe. H Li, 10.1016/j.xinn.2022.100305Innovation. 351003052022</p>
<p>A review of Earth Artificial Intelligence. Z Sun, L Sandoval, R Crystal-Ornelas, 10.1016/j.cageo.2022.105034Comput. Geosci. 1591050342022</p>
<p>The emergence and evolution of earth system science. W Steffen, K Richardson, J Rockström, 10.1038/s43017-019-0005-6Nat. Rev. Earth Environ. 112020</p>
<p>Earth system analysis and the second Copernican revolution. H J Schellnhuber, 10.1038/35011515Nature. 40267611999</p>
<p>Toward a collective agenda on AI for Earth science data analysis. D Tuia, R Roscher, J D Wegner, 10.1109/MGRS.2020.3043504IEEE Geosci. Remote Sens. Mag. 922021</p>
<p>Atmospheric homeostasis by and for the biosphere: The Gaia hypothesis. J E Lovelock, L Margulis, 10.3402/tellusa.v26i1-2.9731Tellus. 261-21974</p>
<p>Record-breaking global temperature and crises with strong El Niño in 2023-2024. K Li, F Zheng, L Cheng, 10.59717/j.xinn-geo.2023.100030Innovation Geosci. 121000302023</p>
<p>The Community Earth System Model: A framework for collaborative research. J W Hurrell, M M Holland, P R Gent, 10.1175/BAMS-D-12-00121.1Bull. Am. Meteorol. Soc. 9492013</p>
<p>Remote sensing of the environment: An earth resource perspective. J R Jensen, 10.1559/1523040200Cartogr. Geogr. Inf. Sci. 2743112009</p>
<p>Climate change: Strategies for mitigation and adaptation. F Wang, J D Harindintwali, K Wei, 10.59717/j.xinn-geo.2023.100015Innovation Geosci. 112023</p>
<p>The Sacred Balance: Rediscovering Our Place in Nature. D Suzuki, 10.2307/15222322022Greystone Books Ltd</p>
<p>Geographic modeling and simulation systems for geographic research in the new era: Some thoughts on their development and construction. M Chen, G Lv, C Zhou, 10.1007/s11430-020-9759-0Sci. China Earth Sci. 6482021</p>
<p>Earth system models of intermediate complexity: Closing the gap in the spectrum of climate system models. M Claussen, L Mysak, A Weaver, 10.1007/s00382-001-0200-1Clim. Dyn. 182002</p>
<p>Documentation strategy for facilitating the reproducibility of geo-simulation experiments. Z Zhu, M Chen, Z Qian, 10.1016/j.envsoft.2023.105687Environ. Model. Softw. 1631056872023</p>
<p>A dynamic TOPMODEL. K Beven, J Freer, 10.1002/hyp.252Hydrol. Process. 15102001</p>
<p>J Arnold, 10.1007/springerreference_62887SWAT-Soil and Water Assessment Tool. 1994</p>
<p>A new applications manual for the Storm Water Management Model (SWMM). J Gironás, L A Roesner, L A Rossman, 10.1016/j.envsoft.2009.11.009Environ. Modell. Softw. 2562010</p>
<p>C Chen, R C Beardsley, G Cowles, 10.23919/oceans.2009.5422441An Unstructured-Grid, Finite-Volume Community Ocean Model: FVCOM User Manual. 2012Massachusetts Institute of Technology Cambridge</p>
<p>The next generation of NWP: Explicit forecasts of convection using the Weather Research and Forecasting (WRF) model. J Done, C A Davis, M Weisman, 10.1002/asl.72Atmos. Sci. Lett. 562004</p>
<p>Models-3 Community Multiscale Air Quality (CMAQ) model aerosol component 1. Model description. F S Binkowski, Roselle , S J , 10.1029/2001JD001409J. Geophys. Res. 10862003</p>
<p>Estimates of global terrestrial isoprene emissions using MEGAN (Model of Emissions of Gases and Aerosols from Nature). A Guenther, T Karl, P Harley, 10.5194/acpd-6-107-2006Atmos. Chem. Phys. 6112006</p>
<p>Predicting the future of forests in the Mediterranean under climate change, with niche-and process-based models: CO2 matters. T Keenan, J M Serra, F Lloret, 10.1111/j.1365-2486.2010.02254.xGlob. Chang. Biol. 1712011</p>
<p>A review of current calibration and validation practices in land-change modeling. J Van Vliet, A K Bregt, D G Brown, 10.1016/j.envsoft.2016.04.017Environ. Model. Softw. 822016</p>
<p>Ten iterative steps in development and evaluation of environmental models. A J Jakeman, R A Letcher, J P Norton, 10.1016/j.envsoft.2006.01.004Environ. Model. Softw. 2152006</p>
<p>Activity-based process construction for participatory geo-analysis. Z Ma, M Chen, S Yue, 10.1080/15481603.2020.1868211GISci. Remote Sens. 5822021</p>
<p>Mapping global urban land for the 21st century with datadriven simulations and shared socioeconomic pathways. J Gao, B C Neill, 10.1038/s41467-020-15788-7Nat. Commun. 11123022020</p>
<p>The Fourth Paradigm (United States of America. T Hey, 10.1007/s00287-019-01215-92009</p>
<p>Geographic information science in the era of geospatial big data: A cyberspace perspective. X Liu, M Chen, C Claramunt, 10.1016/j.xinn.2022.100279Innovation. 351002792022</p>
<p>Geospatial remote sensing interpretation: From perception to cognition. S Wang, W Han, X Zhang, 10.59717/j.xinn-geo.2024.100056Innovation Geosci. 212024</p>
<p>The role of satellite remote sensing in climate change studies. J Yang, P Gong, R Fu, 10.1038/nclimate1908Nat. Clim. Chang. 3102013</p>
<p>Vectorized dataset of roadside noise barriers in China using street view imagery. Z Qian, M Chen, Y Yang, 10.5194/essd-2022-19Earth Syst. Sci. Data. 1492022</p>
<p>Progress toward the sustainable development of world cultural heritage sites facing land-cover changes. H Guo, F Chen, Y Tang, 10.1016/j.xinn.2023.100496Innovation. 451004962023</p>
<p>Vectorized rooftop area data for 90 cities in China. Z Zhang, Z Qian, T Zhong, 10.1038/s41597-022-01168-xSci. Data. 91662022</p>
<p>Nighttime light remote sensing in characterizing urban spatial structure. K Shi, J Ma, Z Chen, 10.59717/j.xinn-geo.2023.100043Innovation Geosci. 131000432023</p>
<p>Understanding individual human mobility patterns. M C Gonzalez, C A Hidalgo, A.-L Barabasi, 10.1038/nature07850Nature. 45371962008</p>
<p>Urban visual intelligence: Uncovering hidden city profiles with street view images. Z Fan, F Zhang, B P Y Loo, 10.1073/pnas.2220417120Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA2023120e2220417120</p>
<p>Air pollution lowers Chinese urbanites' expressed happiness on social media. S Zheng, J Wang, C Sun, 10.1038/s41562-018-0521-2Nat. Hum. Behav. 332019</p>
<p>Carbon mitigation potential afforded by rooftop photovoltaic in China. Z Zhang, M Chen, T Zhong, 10.1038/s41467-023-38079-3Nat. Commun. 14123472023</p>
<p>Reflections on the catastrophic 2020 Yangtze River Basin flooding in southern China. K Wei, C Ouyang, H Duan, 10.1016/j.xinn.2020.100038Innovation. 121000382020</p>
<p>Exploring disaster impacts on adaptation actions in 549 cities worldwide. D Nohrstedt, J Hileman, M Mazzoleni, 10.1038/s41467-022-31059-zNat. Commun. 13133602022</p>
<p>Deep learning for cross-region streamflow and flood forecasting at a global scale. B Zhang, C Ouyang, P Cui, 10.1016/j.xinn.2024.100617Innovation. 532024</p>
<p>Iterative integration of deep learning in hybrid earth surface system modelling. M Chen, Z Qian, N Boers, 10.1038/s43017-023-00452-7Nat. Rev. Earth Environ. 482023</p>
<p>Toward more realistic projections of soil carbon dynamics by earth system models. Y Luo, A Ahlström, S D Allison, 10.1002/2015gb005239Global Biogeochem. Cy. 3012016</p>
<p>Efficient surrogate modeling methods for large-scale earth system models based on machine-learning techniques. D Lu, D M Ricciuto, 10.5194/gmd-2018-327Geosci. Model Dev. (GMD). 1252019</p>
<p>Neural partial differential equations for chaotic systems. M Gelbrecht, N Boers, J Kurths, 10.5194/egusphere-egu21-8262New J. Phys. 234430052021</p>
<p>Solving high-dimensional partial differential equations using deep learning. J Han, A Jentzen, E , W , 10.1073/pnas.1718942115Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA2018115</p>
<p>Deep learning to represent subgrid processes in climate models. S Rasp, M S Pritchard, P Gentine, 10.5194/egusphere-egu2020-13982Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA2018115</p>
<p>Earth system modeling 2.0: A blueprint for models that learn from observations and targeted high-resolution simulations. T Schneider, S Lan, A Stuart, 10.1002/2017gl076101Geophys. Res. Lett. 44242017</p>
<p>Simultaneous extraction of spatial and attributional building information across large-scale urban landscapes from high-resolution satellite imagery. Z Qian, M Chen, Z Sun, Sustain. Cities Soc. 1061053932024</p>
<p>Physics-informed machine learning: Case studies for weather and climate modelling. K Kashinath, M Mustafa, A Albert, 10.1098/rsta.2020.0093Philos. T. R. Soc. A. 379202000932021. 2194</p>
<p>Quantum-chemical insights from deep tensor neural networks. K T Sch€ Utt, F Arbabzadah, S Chmiela, 10.1038/ncomms13890Nat. Commun. 81138902017</p>
<p>Physics-guided Neural Networks (PGNN): An Application in Lake Temperature Modeling. A Karpatne, W Watkins, J Read, 10.1201/9781003143376-152017Preprint at arXiv</p>
<p>Big earth data: A new challenge and opportunity for digital earth's development. H Guo, Z Liu, H Jiang, 10.1080/17538947.2016.1264490Int. J. Digit. Earth. 1012017</p>
<p>A survey on data collection for machine learning: A big data-AI integration perspective. Y Roh, G Heo, S E Whang, 10.1109/tkde.2019.2946162IEEE T. Knowl. Data En. 3342021</p>
<p>Google Earth Engine for geo-big data applications: A meta-analysis and systematic review. H Tamiminia, B Salehi, M Mahdianpari, 10.1016/j.isprsjprs.2020.04.001ISPRS J. Photogramm. Remote Sens. 1642020</p>
<p>Deep learning and process understanding for data-driven earth system science. M Reichstein, G Camps-Valls, B Stevens, Nature. 56677432019</p>
<p>L Xu, N Chen, Z Chen, 10.1016/j.earscirev.2021.103828Spatiotemporal forecasting in earth system science: Methods, uncertainties, predictability and future directions. 2021222103828</p>
<p>Nature-based solutions efficiency evaluation against natural hazards: Modelling methods, advantages and limitations. P Kumar, S E Debele, J Sahani, 10.1016/j.scitotenv.2021.147058Sci. Total Environ. 7841470582021</p>
<p>Intelligent sensing, communication, computation and caching for satellite-ground integrated networks. Y Gong, H Yao, A Nallanathan, 10.1109/mnet.2024.3413543IEEE Netw. 3842024</p>
<p>A review of space-air-ground integrated remote sensing techniques for atmospheric monitoring. B Zhou, S Zhang, R Xue, 10.1016/j.jes.2021.12.008J. For. Environ. 1232023</p>
<p>Assessing the disease burden of air pollution on children and adolescents in China from 1990 to 2019. G Feng, J Xia, X Wang, 10.59717/j.xinn-med.2024.100057Innovat. Med. 212024</p>
<p>UAV-based remote sensing in plant stress imaging using high-resolution thermal sensor for digital agriculture practices: A meta-review. M Awais, W Li, M J M Cheema, 10.1007/s13762-021-03801-5Int. J. Environ. Sci. Te. 2022</p>
<p>Trustworthy remote sensing interpretation: Concepts, technologies, and applications. S Wang, W Han, X Huang, 10.1016/j.isprsjprs.2024.02.003ISPRS J. Photogramm. Remote Sens. 2092024</p>
<p>Towards parallel intelligence: An interdisciplinary solution for complex systems. Y Zhao, Z Zhu, B Chen, 10.1016/j.xinn.2023.100521Innovation. 41005212023</p>
<p>Filling in missing pieces in the co-development of artificial intelligence and environmental science. Z Wang, J Zhang, P Hua, 10.59717/j.xinn-geo.2023.100007Innovation Geosci. 112023</p>
<p>Artificial intelligence reconstructs missing climate information. C Kadow, D M Hall, U Ulbrich, 10.5194/egusphere-egu21-16087Nat. Geosci. 1362020</p>
<p>DiffusionSat: A generative foundation model for satellite. S Khanna, P Liu, L Zhou, 2024</p>
<p>CRS-Diff: Controllable generative remote sensing foundation model. D Tang, X Cao, X Hou, 10.48550/arXiv.2403.116142024Preprint</p>
<p>Multimodal artificial intelligence foundation models: Unleashing the power of remote sensing big data in earth observation. M R S B Data, 10.59717/j.xinn-geo.2024.100055Innovation. 211000552024</p>
<p>AI-enhanced spatial-temporal data-mining technology: New chance for next-generation urban computing. F Wang, D Yao, Y Li, 10.1016/j.xinn.2023.100405Innovation. 421004052023</p>
<p>Three-dimensional structural geological modeling using graph neural networks. M Hillier, F Wellmann, B Brodaric, 10.5194/egusphere-egu21-12978Math. Geosci. 5382021</p>
<p>Dual learning-based graph neural network for remote sensing image super-resolution. Z Liu, R Feng, L Wang, 10.1109/tgrs.2022.3199750IEEE Trans. Geosci. Remote Sens. 602022</p>
<p>Geography-aware self-supervised learning. K Ayush, B Uzkent, C Meng, 10.1109/iccv48922.2021.01002ICCV: 10181-101902021</p>
<p>Multimodal fusion transformer for remote sensing image classification. S K Roy, A Deria, D Hong, 10.1109/tgrs.2023.3286826IEEE Trans. Geosci. Remote Sens. 612023</p>
<p>K2: A foundation language model for geoscience knowledge understanding and utilization. C Deng, T Zhang, Z He, 10.1145/3616855.3635772Proc. 17th ACM Int. Conf. Web Search Data Mining. 17th ACM Int. Conf. Web Search Data Mining2024</p>
<p>Learning skillful medium-range global weather forecasting. R Lam, A Sanchez-Gonzalez, M Willson, 10.1126/science.adi2336Science. 38266772023</p>
<p>Skysense: A multi-modal remote sensing foundation model towards universal interpretation for earth observation imagery. X Guo, J Lao, B Dang, 10.1109/lgrs.2009.20342482024</p>
<p>Ubiquitous geographic information for building digital twins of geographic environments. G Lu, S Yue, Z Yu, 10.59717/j.xinn-geo.2023.100023Innovation Geosci. 121000232023</p>
<p>X Ma, 10.31223/x55s4dData Science for Geoscience: Recent Progress and Future Trends from the Perspective of a Data Life Cycle. 2023</p>
<p>Resource description framework. J Z Pan, 10.1007/978-3-540-92673-3_3Handbook on Ontologies. 2009</p>
<p>OGEScript: An OGC-oriented interoperable script API for online geospatial analysis. K Wang, P Yue, D Yu, 10.1109/agro-geoinformatics59224.2023.102333172023 11th Int. Conf. Agro-Geoinformatics. 2023</p>
<p>COLOR: Cycling, offline learning, and online representation framework for airport and airplane detection using GF-2 satellite images. Y Zhong, Z Zheng, A Ma, 10.1109/tgrs.2020.2987907IEEE Trans. Geosci. Remote Sens. 58122020</p>
<p>Voxposer: Composable 3D value maps for robotic manipulation with language models. W Huang, C Wang, R Zhang, 10.48550/arXiv.2307.059732023Preprint at arXiv</p>
<p>Embodied intelligence via learning and evolution. A Gupta, S Savarese, S Ganguli, 10.1038/s41467-021-25874-zNat. Commun. 12157212021</p>
<p>The digital revolution of earth-system science. P Bauer, P D Dueben, T Hoefler, 10.1038/s43588-021-00023-0Nat. Comput. 122021</p>
<p>Big earth data science: An information framework for a sustainable planet. H Guo, S Nativi, D Liang, 10.1080/17538947.2020.1743785Int. J. Digit. Earth. 1372020</p>
<p>Big data in earth system science and progress towards a digital twin. X Li, M Feng, Y Ran, 10.1038/s43017-023-00409-wNat. Rev. Earth Environ. 452023</p>
<p>How to prevent malicious use of intelligent unmanned swarms?. Q Wang, T Li, Y Xu, 10.1016/j.xinn.2023.1003962023Innovation. 4(2</p>
<p>Kepler's laws of planetary motion: 1609-1666. J L Russell, 10.1017/s0007087400001813Brit. J. Hist. Sci. 211964</p>
<p>Large-scale generative simulation artificial intelligence: The next hotspot. Q Wang, Y Feng, J Huang, 10.1016/j.xinn.2023.100516Innovation. 461005162023</p>
<p>Improved prediction of protein-protein interactions using AlphaFold2. P Bryant, G Pozzati, A Elofsson, 10.21203/rs.3.rs-951605/v1Nat. Commun. 13112652022</p>
<p>Advancing mathematics by guiding human intuition with AI. A Davies, P Veli Ckovi C, L Buesing, 10.1038/s41586-021-04086-xNature. 60078872021</p>
<p>Deep potential molecular dynamics: A scalable model with the accuracy of quantum mechanics. L Zhang, J Han, H Wang, 10.1103/physrevlett.120.143001Phys. Rev. Lett. 120141430012018</p>
<p>Rainfall-runoff modeling-past, present and future. E Todini, 10.1016/0022-1694(88)90191-6J. Hydrol. X. 1001-31988</p>
<p>Towards a comprehensive physically-based rainfallrunoff model. Z Liu, E Todini, 10.5194/hess-6-859-2002Hydrol. Earth Syst. Sci. 652002</p>
<p>HESS opinions: Incubating deep-learningpowered hydrologic science advances as a community. C Shen, E Laloy, A Elshorbagy, 10.5194/hess-22-5639-2018Hydrol. Earth Syst. Sci. 22112018</p>
<p>High-resolution observations from space to address new applications in hydrology. L Brocca, W Zhao, H Lu, 10.1016/j.xinn.2023.100437Innovation. 431004372023</p>
<p>Scientific discovery in the age of artificial intelligence. H Wang, T Fu, Y Du, Nature. 62079722023</p>
<p>Empirically verifying hypotheses using reinforcement learning. K Marino, R Fergus, A Szlam, 10.48550/arXiv.2006.157622020Preprint at arXiv</p>
<p>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients. B K Petersen, M Landajuela, T N Mundhenk, 10.48550/arXiv.1912.048712019Preprint at arXiv</p>
<p>Reducing adverse impacts of Amazon hydropower expansion. A S Flecker, Q Shi, R M Almeida, 10.1126/science.abj4017Science. 37565822022</p>
<p>The use of high-performance and highthroughput computing for the fertilization of digital earth and global change studies. Y Xue, D Palmer-Brown, H Guo, 10.1080/17538947.2010.535569Int. J. Digit. Earth. 432011</p>
<p>Discovering governing equations from data by sparse identification of nonlinear dynamical systems. S L Brunton, J L Proctor, J N Kutz, 10.1073/pnas.1517384113Proc. Natl. Acad. Sci. USA. 113152016</p>
<p>Co-evolution based machine-learning for predicting functional interactions between human genes. D Stupp, E Sharon, I Bloch, 10.1038/s41467-021-26792-wNat. Commun. 12164542021</p>
<p>Machine learning based analysis for relation between global temperature and concentrations of greenhouse gases. S Kalra, R Lamba, M Sharma, 10.1080/02522667.2020.1715559J. Inf. Optim. Sci. 4112020</p>
<p>Accurate medium-range global weather forecasting with 3D neural networks. K Bi, L Xie, H Zhang, 10.1038/s41586-023-06185-3Nature. 61979702023</p>
<p>Terrestrial gross carbon dioxide uptake: Global distribution and covariation with climate. C Beer, M Reichstein, E Tomelleri, 10.1126/science.1184984Science. 32959932010</p>
<p>Enhanced seasonal CO2 exchange caused by amplified plant productivity in northern ecosystems. M Forkel, N Carvalhais, C Rödenbeck, 10.1126/science.aac4971Science. 35162742016</p>
<p>Modeling the COVID-19 outbreak in China through multi-source information fusion. L Wu, L Wang, N Li, 10.1016/j.xinn.2020.100033Innovation. 121000332020</p>
<p>The four hundred years of planetary science since Galileo and Kepler. J A Burns, 10.1038/nature09215Nature. 46673062010</p>
<p>M T Greene, 10.5860/choice.195372Alfred Wegener: Science, Exploration, and the Theory of Continental Drift. JHU Press2015</p>
<p>Divergent trends of open-surface water body area in the contiguous United States from 1984 to. Z Zou, X Xiao, J Dong, 10.1073/pnas.1719275115Proc. Natl. Acad. Sci. USA. 1152018. 2016</p>
<p>The global tree restoration potential. J F Bastin, Y Finegold, C Garcia, 10.1126/science.aaz0493Science. 36564482019</p>
<p>A multi-factor driven spatiotemporal wind power prediction model based on ensemble deep graph attention reinforcement learning networks. C Yu, G Yan, C Yu, 10.1016/j.energy.2022.126034Energy. 2631260342023</p>
<p>Attention mechanism is useful in spatio-temporal wind speed prediction: Evidence from China. C Yu, G Yan, C Yu, 10.1016/j.asoc.2023.110864Appl. Soft Comput. 1481108642023</p>
<p>Physics-embedded neural networks: Graph neural PDE solvers with mixed boundary conditions. M Horie, N Mitsume, 10.1299/jsmecmd.2022.35.16-16Adv. Neural Inf. Process. Syst. 352022</p>
<p>HistGNN: Hierarchical spatiotemporal graph neural network for weather forecasting. M Ma, P Xie, F Teng, 10.2139/ssrn.4455568Inf. Sci. 6481195802023</p>
<p>Pre-training enhanced spatial-temporal graph neural network for multivariate time series forecasting. Z Shao, Z Zhang, F Wang, 10.1145/3534678.3539396Proc. 28th ACM SIGKDD Conf. Knowl. Discov. Data Min. 28th ACM SIGKDD Conf. Knowl. Discov. Data Min2022</p>
<p>DSFormer: A double sampling transformer for multivariate time series long-term prediction. C Yu, F Wang, Z Shao, 10.1145/3583780.3614851Proc. 32nd ACM Int. Conf. Inf. Knowl. Manag. 32nd ACM Int. Conf. Inf. Knowl. Manag2023</p>
<p>Physics-aware downsampling with deep learning for scalable flood modeling. N Giladi, Z Ben-Haim, S Nevo, 10.5194/hess-2021-554Adv. Neural Inf. Process. Syst. 342021</p>
<p>Complex hazard cascade culminating in the Anak Krakatau sector collapse. T R Walter, M Haghshenas Haghighi, F M Schneider, 10.1038/s41467-019-12284-5Nat. Commun. 10143392019</p>
<p>Breathing in the new era: The global call against industrial air pollution. H Zahidi, I Fai, C M , 10.59717/j.xinn-med.2024.100049Innovation Med. 211000492024</p>
<p>Satclip: Global, general-purpose location embeddings with satellite imagery. K Klemmer, E Rolf, C Robinson, 10.1038/d41586-023-03983-72023Preprint at arXiv</p>
<p>Evolution of the Yangtze River and its biodiversity. F Chen, G Xue, Y Wang, Innovation. 431004172023</p>
<p>Marine mammal genomes: Important resources for unraveling adaptation and evolution in the marine environment. P Zhang, S J Goodman, S Bai, 10.59717/j.xinn-geo.2023.100022Innovation Geosci. 122023</p>
<p>The modification effect of ozone pollution on the associations between heat wave and cardiovascular mortality. J Qi, Y Wang, L Wang, 10.59717/j.xinn-med.2023.100043Innovation. 131000432023</p>
<p>Exposure to airborne PM2.5 chemical exposome increases heart rate of middle-and old-aged populations. Y Sun, M Wang, Y Wang, 10.59717/j.xinn-med.2023.1000422023Innovation Med. 1(10.59717</p>
<p>Biomedical microrobotics: Small sizes, large applications. J Du, X Feng, 10.59717/j.xinn-life.2024.100046Innovation Life. 211000462024</p>
<p>An advanced deep learning predictive model for air quality index forecasting with remote satellite-derived hydro-climatological variables. A A M Ahmed, S J J Jui, E Sharma, 10.1016/j.scitotenv.2023.167234Sci. Total Environ. 9061672342024</p>
<p>DeepSat4D: Deep learning empowers four-dimensional atmospheric chemical concentration and emission retrieval from satellite. S Li, J Xing, 10.59717/j.xinn-geo.2024.100061Innovation Geosci. 211000612024</p>
<p>Association between air pollution and telomere length: A study of 471,808 UK Biobank participants. Y Wu, D Gasevic, B Wen, 10.59717/j.xinn-med.2023.100017Innovat. Med. 121000172023</p>
<p>Spatio-temporal decomposition of satellitederived SST-SSH fields: Links between surface data and ocean interior dynamics in the Agulhas region. Le Goff, C Fablet, R Tandeo, P , 10.1109/jstars.2016.2605040IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 9112016</p>
<p>Machine learning reveals climate forcing from aerosols is dominated by increased cloud cover. Y Chen, J Haywood, Y Wang, 10.1038/s41561-022-01027-9Nat. Geosci. 1582022</p>
<p>Machine learning-based retrieval of day and night cloud macrophysical parameters over East Asia using Himawari-8 data. Y Yang, W Sun, Y Chi, 10.1016/j.rse.2022.112971Remote Sens. Environ. 2731129712022</p>
<p>Real-time water quality detection based on fluctuation feature analysis with the LSTM model. L Wang, H Dong, Y Cao, 10.2166/hydro.2023.127J. Hydroinform. 2512023</p>
<p>Cloud detection methodologies: Variants and development-a review. S Mahajan, B Fataniya, 10.1007/s40747-019-00128-0Complex Intell. Syst. 62020</p>
<p>Land water vapor retrieval for AMSR2 using a deep learning method. N Jiang, Y Xu, T Xu, 10.5194/egusphere-egu2020-17756IEEE Trans. Geosci. Remote Sens. 602022</p>
<p>Neural Networks and Support Vector Machines and Their Application to Aerosol and Cloud Remote Sensing: A Review. A Di Noia, O P Hasekamp, 10.1007/978-3-319-70796-9_4Springer Series in Light Scattering. 2018</p>
<p>Improved retrievals of aerosol optical depth and fine mode fraction from GOCI geostationary satellite data using machine learning over East Asia. Y Kang, M Kim, E Kang, 10.1016/j.isprsjprs.2021.11.016ISPRS J. Photogramm. Remote Sens. 1832022</p>
<p>Development of an algorithm to retrieve aerosol optical properties over water using an artificial neural network radiative transfer scheme: First result from GOSAT-2/CAI-2. C Shi, M Hashimoto, K Shiomi, 10.1109/tgrs.2020.3038892IEEE Trans. Geosci. Remote Sens. 59122020</p>
<p>Refining aerosol optical depth retrievals over land by constructing the relationship of spectral surface reflectances through deep learning: Application to Himawari-8. T Su, I Laszlo, Z Li, 10.1016/j.rse.2020.112093Remote Sens. Environ. 2511120932020</p>
<p>Urban-rural disparity of the short-term association of PM2.5 with mortality and its attributable burden. Innovation. T Liu, H Meng, M Yu, 10.1016/j.xinn.2021.10017120212100171</p>
<p>Tracking daily concentrations of PM2.5 chemical composition in China since. S Liu, G Geng, Q Xiao, 10.1021/acs.est.2c06510Environ. Sci. Technol. 56222022. 2000</p>
<p>Separating daily 1 km PM2.5 inorganic chemical composition in China since 2000 via deep learning integrating ground, satellite, and model data. J Wei, Z Li, X Chen, 10.1021/acs.est.3c00272Environ. Sci. Technol. 57462023</p>
<p>Mapping forest in the Swiss Alps treeline ecotone with explainable deep learning. T.-A Nguyen, B Kellenberger, D Tuia, 10.1016/j.rse.2022.1132172022Remote Sens. Environ. 281: 113217</p>
<p>A review and evaluation of intraurban air pollution exposure models. M Jerrett, A Arain, P Kanaroglou, 10.1038/sj.jea.7500388J. Expo. Sci. Environ. Epidemiol. 1522005</p>
<p>Estimation of surface-level NO2 and O3 concentrations using TROPOMI data and machine learning over East Asia. Y Kang, H Choi, J Im, 10.1016/j.envpol.2021.117711Environ. Pollut. 2881177112021</p>
<p>Emerging contaminants: A One Health perspective. Innovation. F Wang, L Xiang, K S Leung, .-Y , 10.1016/j.xinn.2024.10061220245</p>
<p>Real-time and dynamic estimation of CO2 emissions from China's lakes and reservoirs. K Sun, J Jia, S Wang, 10.59717/j.xinn-geo.2023.100031Innovation Geosci. 131000312023</p>
<p>Estimation of surface roughness in selective laser sintering using computational models. E Koç, S Zeybek, B Özbay Kısasöz, 10.21203/rs.3.rs-1638732/v1Int. J. Adv. Manuf. Technol. 1239-102022</p>
<p>Surface solar radiation compositions observed from Himawari-8/9 and Fengyun-4 series. H Letu, R Ma, T Y Nakajima, 10.1175/bams-d-22-0154.1Am Meteorol Soc. 104102023</p>
<p>Skilful nowcasting of extreme precipitation with NowcastNet. Y Zhang, M Long, K Chen, 10.1038/s41586-023-06184-4Nature. 61979702023</p>
<p>SwinVRNN: A data-driven ensemble forecasting model via learned distribution perturbation. Y Hu, L Chen, Z Wang, 10.1029/2022ms003211J. Adv. Model. Earth Syst. 1522023</p>
<p>FuXi: A cascade machine learning forecasting system for 15-day global weather forecast. L Chen, X Zhong, F Zhang, 10.1038/s41612-023-00512-1NPJ Clim. Atmos. Sci. 611902023</p>
<p>Fengwu: Pushing the skillful global medium-range weather forecast beyond 10 days lead. K Chen, T Han, J Gong, 10.48550/arXiv.2304.029482023Preprint at arXiv</p>
<p>A modified deep learning weather prediction using cubed sphere for global precipitation. M Singh, N Acharya, P Patel, 10.3389/fclim.2022.1022624Front. Clim. 410226242023</p>
<p>Tracking artificial intelligence in climate inventions with patent data. V Verendel, 10.1038/s41558-022-01536-wNat. Clim. Chang. 1312023</p>
<p>Seismic velocity structure and composition of the continental crust: A global view. N I Christensen, W D Mooney, 10.1029/94JB03148J. Geophys. Res. 100B61995</p>
<p>Morning twilight of crop breeding for sodic land. D Shi, Innov. Life. 122023</p>
<p>A systematic review of data science and machine learning applications to the oil and gas industry. Z Tariq, M S Aljawad, A Hasan, 10.1007/s13202-021-01302-2J. Pet. Explor. Prod. Technol. 12021</p>
<p>Deep learning 3D sparse inversion of gravity data. R Huang, S Liu, R Qi, 10.1029/2021jb022476JGR. Solid Earth. 126112021</p>
<p>Seismic inversion by hybrid machine learning. Y Chen, E Saygin, 10.1029/2020jb021589JGR. Solid Earth. 12692021</p>
<p>2D magnetotelluric inversion based on ResNet. L Xie, B Han, X Hu, 10.1016/j.aiig.2023.08.003Artif. Intell. Geosci. 42023</p>
<p>Deep learning for 3-D inversion of gravity data. L Zhang, G Zhang, Y Liu, 10.1109/tgrs.2021.3110606IEEE Trans. Geosci. Remote Sens. 602021</p>
<p>Applicability of denoising-based artificial intelligence to forecast the environmental externalities. D Cai, G Aziz, S Sarwar, 10.1016/j.gsf.2023.101740Geosci. Front. 1531017402024</p>
<p>Deep learning for seismic phase detection and picking in the aftershock zone of 2008 Mw 7.9 Wenchuan earthquake. L Zhu, Z Peng, J Mcclellan, 10.1016/j.pepi.2020.106261Phys. Earth Planet. Inter. 2931062612019</p>
<p>Toward earthquake early warning: A convolutional neural network for rapid earthquake magnitude estimation. F Meng, T Ren, Z Liu, 10.1016/j.aiig.2023.03.001Artif. Intell. Geosci. 42023</p>
<p>Machine learning in seismology: Turning data into insights. Q Kong, D T Trugman, Z E Ross, 10.1785/0220180259Seismol Res. Lett. 9012019</p>
<p>Machine learning for earthquake prediction: A review. N S Md Ridzwan, Md Yusoff, S H , 10.1007/s12145-023-00991-zEarth Sci. 2023. 2017-202116</p>
<p>Landslide susceptibility modeling by interpretable neural network. K Youssef, K Shao, S Moon, 10.1038/s43247-023-00806-5Commun. Earth Environ. 411622023</p>
<p>Application of machine learning to classification of volcanic deformation in routinely generated InSAR data. N Anantrasirichai, J Biggs, F Albino, 10.1029/2018jb015911JGR. Solid Earth. 12382018</p>
<p>Deep learning for laboratory earthquake prediction and autoregressive forecasting of fault zone stress. L Laurenti, E Tinti, F Galasso, 10.1016/j.epsl.2022.117825Earth Planet Sci. Lett. 5981178252022</p>
<p>The role of artificial intelligence and IoT in prediction of earthquakes. J Pwavodi, A U Ibrahim, P C Pwavodi, 10.1016/j.aiig.2024.100075Artif. Intell. Geosci. 41000752024</p>
<p>Application of artificial intelligence to rock mechanics: An overview. A I Lawal, S Kwon, 10.1016/j.jrmge.2020.05.010J. Rock Mech. Geotech. 1312021</p>
<p>Automated lithology classification from drill core images using convolutional neural networks. F Alzubaidi, P Mostaghimi, P Swietojanski, 10.1016/j.petrol.2020.107933J. Pet. Sci. Eng. 1971079332021</p>
<p>Recovering 3D basement relief using gravity data through convolutional neural networks. S He, H Cai, S Liu, 10.1029/2021jb022611JGR. Solid Earth. 126102021</p>
<p>Characterization of subsurface hydrogeological structures with convolutional conditional neural processes on limited training data. Z Cui, Q Chen, G Liu, 10.1029/2022wr033161Water Resour. Res. 58122022</p>
<p>A three-dimensional geological structure modeling framework and its application in machine learning. S Wang, Z Cai, X Si, 10.1007/s11004-022-10027-9Math. Geosci. 5522023</p>
<p>Machine learning and soil sciences: A review aided by machine learning tools. J Padarian, B Minasny, A B Mcbratney, 10.5194/soil-6-35-2020Soil. 612020</p>
<p>Global soil moisture data derived through machine learning trained with in-situ measurements. R Orth, 10.1038/s41597-021-00964-1Sci. Data. 8111702021</p>
<p>Estimation of soil texture by fusion of near-infrared spectroscopy and image data based on convolutional neural network. M K Vakilzadeh Ebrahimi, H Lee, J Won, 10.1016/j.compag.2023.108117Comput. Electron. Agric. 2121081172023</p>
<p>Artificially intelligent soil quality and health indices for 'next generation' food production systems. V H G Z De Andrade, M Redmile-Gordon, B H G Barbosa, 10.1016/j.tifs.2020.10.018Trends Food Sci. Technol. 1072021</p>
<p>The EPOS multi-disciplinary data portal for integrated access to solid earth science datasets. D Bailo, R Paciello, J Michalek, 10.1038/s41597-023-02697-9Sci. Data. 1017842023</p>
<p>Y N Araya, 10.1002/047147844x.me216Hydrosphere. 2015</p>
<p>Application of machine learning algorithms in hydrology. H Mosaffa, M Sadeghi, I Mallakpour, 10.1016/b978-0-323-89861-4.00027-0Comput. Earth Environ. 12022</p>
<p>Deep-sea microorganisms acquired during Jiaolong expedition. K Liu, W Gao, W Xu, Innov. Life. 121000292023</p>
<p>Lightweight AI-powered precipitation nowcasting. N Yang, X Li, 10.59717/j.xinn-geo.2024.100066The Innovation Geoscience. 221000662024</p>
<p>Experimental study on generative adversarial network for precipitation nowcasting. C Luo, X Li, Y Ye, 10.59717/j.xinn-geo.2024.100066IEEE Trans. Geosci. Remote Sens. 602022</p>
<p>A machine learning system for precipitation estimation using satellite and ground radar network observations. H Chen, V Chandrasekar, R Cifelli, 10.1109/tgrs.2019.2942280IEEE Trans. Geosci. Remote Sens. 5822019</p>
<p>Deep learning for twelve hour precipitation forecasts. L Espeholt, S Agrawal, C Sønderby, 10.1038/s41467-022-32483-xNat. Commun. 1312022</p>
<p>Data fusion of satellite imagery and downscaling for generating highly fine-scale precipitation. X Zhang, Y Song, W.-H Nam, 10.1016/j.jhydrol.2024.130665J. Hydrol. X. 6311306652024</p>
<p>Using machine learning to analyze physical causes of climate change: A case study of US Midwest extreme precipitation. F V Davenport, N S Diffenbaugh, 10.1029/2021GL093787Geophys. Res. Lett. 48152021</p>
<p>Nation-scale reference evapotranspiration estimation by using deep learning and classical machine learning models in China. J Dong, Y Zhu, X Jia, J. Hydrol. X. 6041272072022</p>
<p>Evaluation of global terrestrial evapotranspiration using state-of-the-art approaches in remote sensing, machine learning, and land surface modeling. S Pan, N Pan, H Tian, 10.5194/hess-2019-409-supplementHydrol. Earth Syst. Sci. 2432020</p>
<p>Evaluating different machine learning methods for upscaling evapotranspiration from flux towers to the regional scale. T Xu, Z Guo, S Liu, 10.1029/2018JD028447JGR. Atmospheres. 123162018</p>
<p>Forecasting daily potential evapotranspiration using machine learning and limited climatic data. A F Torres, W R Walker, M Mckee, 10.1016/j.agwat.2010.10.012Agric. Water Manag. 9842011</p>
<p>Forecasting evapotranspiration in different climates using ensembles of recurrent neural networks. F Granata, F Di Nunno, 10.1016/j.agwat.2021.107040Agric. Water Manag. 2551070402021</p>
<p>A simple machine learning approach to model real-time streamflow using satellite inputs: Demonstration in a data scarce catchment. A Kumar, R A A J Ramsankaran, L Brocca, 10.1016/j.jhydrol.2021.126046J. Hydrol. X. 5951260462021</p>
<p>Daily streamflow forecasting by machine learning methods with weather and climate inputs. K Rasouli, W W Hsieh, A J Cannon, 10.1016/j.jhydrol.2011.10.039J. Hydrol. X. 4144152012</p>
<p>Machine learning models for streamflow regionalization in a tropical watershed. R G Ferreira, D D Silva, A A Alden Elesbon, 10.1016/j.jenvman.2020.111713J. Environ. 2801117132021</p>
<p>Identifying major drivers of daily streamflow from large-scale atmospheric circulation with machine learning. J S Hagen, E Leblois, D Lawrence, 10.1016/j.jhydrol.2021.126086J. Hydrol. X. 5961260862021</p>
<p>Machine learning assisted hybrid models can improve streamflow simulation in diverse catchments across the conterminous US. G Konapala, S.-C Kao, S L Painter, 10.1088/1748-9326/aba927Environ. Res. Lett. 15101040222020</p>
<p>A novel water body extraction neural network (WBE-NN) for optical high-resolution multispectral imagery. Y Chen, L Tang, Z Kan, 10.1016/j.jhydrol.2020.125092J. Hydrol. 5881250922020</p>
<p>Global scale analysis on the extent of river channel belts. B Nyberg, G Henstra, R L Gawthorpe, 10.1038/s41467-023-37852-8Nat. Commun. 14121632023</p>
<p>A survey on river water quality modelling using artificial intelligence models: 2000-2020. Tung Tiyasha, T M Yaseen, Z M , 10.1016/j.jhydrol.2020.124670J. Hydrol. 5851246702020</p>
<p>The global streamflow indices and meta-data archive (GSIM)-Part 1: The production of a daily streamflow archive and metadata. H X Do, L Gudmundsson, M Leonard, 10.5194/essd-10-765-2018Earth Syst. Sci. Data. 1022018</p>
<p>GLOFAS-ERA5 operational global river discharge reanalysis 1979-present. S Harrigan, E Zsoter, L Alfieri, 10.5194/essd-12-2043-2020Earth Syst. Sci. Data. 1232020</p>
<p>A brief overview of the global river chemistry database. J Hartmann, R Lauerwald, N Moosdorf, 10.1016/j.proeps.2014.08.005GLORICH. Prog. Earth Planet. Sci. 102014</p>
<p>GRQA: Global river water quality archive. H Virro, G Amatulli, A Kmoch, 10.5194/egusphere-egu21-3865Earth Syst. Sci. Data. 13122021</p>
<p>The crucial role of soil moisture in the evolution of forest cover in Asia since the last glacial maximum. Y Cheng, H Liu, 10.1016/j.xinn.2024.100594Innovation. 531005942024</p>
<p>Soil moisture retrieval using neural networks: Application to SMOS. N Rodriguez-Fernandez, F Aires, P Richaume, 10.1109/tgrs.2015.2430845IEEE Trans. Geosci. Remote Sens. 532015</p>
<p>Soil moisture retrieval from AMSR-E and ASCAT microwave observation synergy. Part 2: Product evaluation. J Kolassa, P Gentine, C Prigent, 10.1016/j.rse.2017.04.020Remote Sens. Environ. 1952017</p>
<p>Retrieving soil moisture over continental US via multiview multi-task learning. L Ge, R Hang, Q Liu, 10.1109/lgrs.2019.2913100IEEE Geosci. Remote Sens. Lett. 16122019</p>
<p>Generating surface soil moisture at 30 m spatial resolution using both data fusion and machine learning toward better water resources management at the field scale. A S Abowarda, L Bai, C Zhang, 10.1016/j.rse.2021.112301Remote Sens. Environ. 2551123012021</p>
<p>Generating high-resolution daily soil moisture by using spatial downscaling techniques: A comparison of six machine learning algorithms. Y Liu, W Jing, Q Wang, 10.1016/j.advwatres.2020.103601Adv. Water Resour. 1411036012020</p>
<p>Downscaling SMAP soil moisture products with convolutional neural network. W Xu, Z Zhang, Z Long, 10.1109/jstars.2021.3069774IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 142021</p>
<p>A 21-year dataset (2000-2020) of gap-free global daily surface soil moisture at 1-km grid resolution. C Zheng, L Jia, T Zhao, 10.1038/s41597-023-01991-wSci. Data. 1011392023</p>
<p>Generating high-accuracy and cloud-free surface soil moisture at 1 km resolution by point-surface data fusion over the southwestern US. S Huang, X Zhang, N Chen, 10.1016/j.agrformet.2022.108985Agric. For. Meteorol. 3211089852022</p>
<p>P Yao, H Lu, J Shi, 10.1038/s41597-021-00925-8A long-term global daily soil moisture dataset derived from AMSR-E and AMSR2. 2021. 2002-20198143</p>
<p>A global daily soil moisture dataset derived from Chinese FengYun Microwave Radiation Imager (MWRI). P Yao, H Lu, T Zhao, 10.5194/egusphere-egu2020-311Sci. Data. 1011332023</p>
<p>Estimation of root zone soil moisture from ground and remotely sensed soil information with multisensor data fusion and automated machine learning. E Babaeian, S Paheding, N Siddique, 10.1016/j.rse.2021.112434Remote Sens. Environ. 2601124342021</p>
<p>Prediction of deep soil water content (0-5 m) with insitu and remote sensing data. Z Zhu, C Zhao, X Jia, 10.1016/j.catena.2022.106852Catena. 2221068522023</p>
<p>Comparison of the use of a physical-based model with data assimilation and machine learning methods for simulating soil water dynamics. P Li, Y Zha, L Shi, 10.1016/j.jhydrol.2020.124692J. Hydrol. X. 5841246922020</p>
<p>A dynamic data-driven method for dealing with model structural error in soil moisture data assimilation. Q Zhang, L Shi, M Holzman, 10.1016/j.advwatres.2019.103407Adv. Water Resour. 1321034072019</p>
<p>Reconstruction of GRACE total water storage through automated machine learning. A Y Sun, B R Scanlon, H Save, 10.5194/gstm2020-53Water Resour. Res. 5722021</p>
<p>LREC: Global terrestrial water storage reconstruction by machine learning from 1940 to present. J Yin, L J Slater, A Khouakhi, 10.5194/essd-2023-315-supplementEarth Syst. Sci. Data. 20232023</p>
<p>Temporal mapping of soil water storage in a semi-arid landscape of northern Ghana -a multi-tasked ensemble machinelearning approach. K A Nketia, S B Asabere, A Ramcharan, 10.1016/j.geoderma.2021.115691Geoderma. 4101156912022</p>
<p>Monitoring by downscaling GRACEderived terrestrial water storage anomalies: A deep learning approach. E Foroumandi, V Nourani, J J Huang, 10.1016/j.jhydrol.2022.128838J. Hydrol. 6161288382023</p>
<p>Learning approaches to spatial downscaling of GRACE terrestrial water storage products using EALCO model over Canada. H He, K Yang, S Wang, 10.1080/07038992.2021.1954498Can. J. Remote Sens. 4742021</p>
<p>Forecasting a water-surface wave train with artificial intelligence (Part 2)-Can the occurrence of freak waves be predicted with AI?. H Kagemoto, 10.1016/j.oceaneng.2022.111205Ocean Eng. 2521112052022</p>
<p>FathomNet: A global image database for enabling artificial intelligence in the ocean. K Katija, E Orenstein, B Schlining, 10.1038/s41598-022-19939-2Sci. Rep. 121159142022</p>
<p>Loop current attenuation after the mid-Pleistocene transition contributes to northern hemisphere cooling. C H€ Ubscher, D , 10.1016/j.margeo.2022.106976Mar. Geol. 4561069762023</p>
<p>An efficient oceanic eddy identification method with XBT data using transformer. H Zhang, B Huang, G Chen, 10.1109/jstars.2022.3221113IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 152022</p>
<p>Aquarius sea surface salinity retrieval in coastal regions based on deep neural networks. L Zhang, Y Zhang, X Yin, 10.1016/j.rse.2022.1133572023Remote Sens. Environ. 284: 113357</p>
<p>Improvement of SMAP sea surface salinity in riverdominated oceans using machine learning approaches. E Jang, Y J Kim, J Im, 10.1080/15481603.2021.1872228GISci. Remote Sens. 5812021</p>
<p>GOCI-II based sea surface salinity estimation using machine learning for the first-year summer. D.-W Kim, S.-H Kim, J.-Y Baek, 10.1080/01431161.2022.2142080Int. J. Remote Sens. 43182022</p>
<p>Reconstruction of three-dimensional temperature and salinity fields from satellite observations. L Meng, C Yan, W Zhuang, 10.1029/2021jc017605JGR. Oceans. 126112021</p>
<p>Global sea surface salinity via the synergistic use of SMAP satellite and HYCOM data based on machine learning. E Jang, Y J Kim, J Im, 10.1016/j.rse.2022.112980Remote Sens. Environ. 2731129802022</p>
<p>Global spatiotemporal trend of satellite-based soil moisture and its influencing factors in the early 21st century. C Peng, J Zeng, K.-S Chen, 10.1016/j.rse.2023.113569Remote Sens. Environ. 2911135692023</p>
<p>Artificial intelligence: A new era for spatial modelling and interpreting climate-induced hazard assessment. A Dikshit, B Pradhan, S S Matin, Geosci. Front. 151018152024</p>
<p>Large-scale flood modeling and forecasting with Floodcast. Q Xu, Y Shi, J Bamber, 10.1016/j.watres.2024.122162Water Res.. Preprint at arXiv. 2024</p>
<p>A review on interpretable and explainable artificial intelligence in hydroclimatic applications. H Başagao Glu, D Chakraborty, C Do Lago, 10.3390/w14081230Water. 14812302022</p>
<p>Physics-aware machine learning revolutionizes scientific paradigm for machine learning and process-based hydrology. Q Xu, Y Shi, J Bamber, 10.48550/arXiv.2310.052272023Preprint at arXiv</p>
<p>Hydro-Climatic Extremes in the Anthropocene. C Ndehedehe, 2023Springer Int. Publ. AG</p>
<p>Cryosphere remote sensing. Front. Remote Sens. G Zheng, S Muhammad, A Sattar, 10.3389/frsen.2023.1204667202341204667</p>
<p>O Slaymaker, R Kelly, 10.1111/j.1475-4762.2008.875_5.xThe cryosphere and global environmental change. John Wiley &amp; Sons2009</p>
<p>Shortened duration and reduced area of frozen soil in the northern hemisphere. T Li, Y.-Z Chen, L.-J Han, 10.1016/j.xinn.2021.100146Innovation. 231001462021</p>
<p>Remote sensing of the mountain cryosphere: Current capabilities and future opportunities for research. L S Taylor, D J Quincey, M W Smith, 10.1177/03091333211023690Prog. Phys. Geogr. Earth Environ. 4562021</p>
<p>Glacier facies mapping using a machinelearning algorithm: The Parlung Zangbo Basin case study. J Zhang, L Jia, M Menenti, 10.3390/rs11040452Remote Sens. 1144522019</p>
<p>Machine-learning classification of debris-covered glaciers using a combination of Sentinel-1/-2 (SAR/optical), Landsat 8 (thermal) and digital elevation data. H Alifu, J.-F Vuillaume, B A Johnson, 10.1016/j.geomorph.2020.107365Geomorphology. 3691073652020</p>
<p>Distribution of near-surface permafrost in Alaska: Estimates of present and future conditions. N J Pastick, M T Jorgenson, B K Wylie, 10.1016/j.rse.2015.07.019Remote Sens. Environ. 1682015</p>
<p>Completing the machine learning saga in fractional snow cover estimation from MODIS Terra reflectance data: Random forests versus support vector regression. S Kuter, 10.1016/j.rse.2021.1122942021Remote Sens. Environ. 255: 112294</p>
<p>Classification of sea ice types in Sentinel-1 SAR data using convolutional neural networks. H Boulze, A Korosov, J Brajard, 10.3390/rs12132165Remote Sens. 121321652020</p>
<p>An adaptive machine learning approach to improve automatic iceberg detection from SAR images. M M Barbat, C Wesche, A V Werhli, 10.1016/j.isprsjprs.2019.08.015ISPRS J. Photogramm. Remote Sens. 1562019</p>
<p>Wet and dry snow detection using Sentinel-1 SAR data for mountainous areas with a machine learning technique. Y.-L S Tsai, A Dietz, N Oppelt, 10.3390/rs11080895Remote Sens. 1188952019</p>
<p>Robust snow avalanche detection using supervised machine learning with infrasonic sensor arrays. T Th€ Uring, M Schoch, A Van Herwijnen, 10.1016/j.coldregions.2014.12.014Cold Reg. Sci. Technol. 1112015</p>
<p>Detection of glacier calving margins with convolutional neural networks: A case study. Y Mohajerani, M Wood, I Velicogna, 10.3390/rs11010074Remote Sens. 111742019</p>
<p>Calving front machine (CALFIN): Glacial termini dataset and automated deep learning extraction method for Greenland. D Cheng, W Hayes, E Larour, 10.5194/tc-15-1663-2021Cryosphere. 1532021</p>
<p>Glacial lakes mapping using multi-satellite PlanetScope imagery and deep learning. N Qayyum, S Ghuffar, H M Ahmad, 10.3390/ijgi9100560ISPRS Int. J. Geo-Inf. 9105602020</p>
<p>Using deep learning to map retrogressive thaw slumps in the Beiluhe region (Tibetan Plateau) from CubeSat images. L Huang, J Luo, Z Lin, 10.1016/j.rse.2019.111534Remote Sens. Environ. 2371115342020</p>
<p>Brief communication: Rapid machinelearning-based extraction and measurement of ice wedge polygons in high-resolution digital elevation models. C J Abolt, M H Young, A L Atchley, Cryosphere. 1312019</p>
<p>Automated extraction of antarctic glacier and ice shelf fronts from Sentinel-1 imagery using deep learning. C A Baumhoer, A J Dietz, C Kneisel, 10.3390/rs11212529Remote Sens. 112125292019</p>
<p>Classification of ice crystal habits observed from airborne cloud particle imager by deep transfer learning. H Xiao, F Zhang, Q He, 10.1029/2019ea000636Earth Space Sci. 6102019</p>
<p>Improving snow depth estimation by coupling hut-optimized effective snow grain size parameters with the random forest approach. J W Yang, L M Jiang, J Lemmetyinen, 10.1016/j.rse.2021.112630Remote Sens. Environ. 2641126302021</p>
<p>Improving snow water equivalent maps with machine learning of snow survey and lidar measurements. P D Broxton, W J D Van Leeuwen, J A Biederman, 10.1029/2018wr024146Water Resour. Res. 5552019</p>
<p>Measuring global snow water equivalent from passive microwave remote sensing: opportunities and challenges. S Gao, J Zeng, Z Li, 10.59717/j.xinn-geo.2024.100062The Innovation Geoscience. 221000622024</p>
<p>Combined IASI-NG and MWS observations for the retrieval of cloud liquid and ice water path: a deep learning artificial intelligence approach. P Mastro, G Masiello, C Serio, 10.1109/jstars.2022.3166992IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 152022</p>
<p>Estimation of soil temperatures with machine learning algorithms-Giresun and Bayburt stations in Turkey. D Guleryuz, 10.1007/s00704-021-03819-2Theor. Appl. Climatol. 1471-22022</p>
<p>Spatio-temporal reconstruction of winter glacier mass balance in the Alps. M Guidicelli, M Huss, M Gabella, 10.5194/tc-17-977-2023Cryosphere. 1722023. 1981-2019) using climate reanalyses and machine learning</p>
<p>Machine-learning predictions of high arsenic and high manganese at drinking water depths of the glacial aquifer system, northern continental United States. M L Erickson, S M Elliott, C J Brown, 10.1021/acs.est.0c06740Environ. Sci. Technol. 5592021</p>
<p>Simulation of the present and future projection of permafrost on the Qinghai-Tibet Plateau with statistical and machine learning models. J Ni, T Wu, X Zhu, 10.1029/2020jd033402J. Geophys. Res. Atmos. 12622021</p>
<p>Snow avalanche hazard prediction using machine learning methods. B Choubin, M Borji, A Mosavi, 10.1016/j.jhydrol.2019.123929J. Hydrol. X. 5771239292019</p>
<p>Seasonal Arctic sea ice forecasting with probabilistic deep learning. T R Andersson, J S Hosking, M Pérez-Ortiz, 10.1038/s41467-021-25257-4Nat. Commun. 12151242021</p>
<p>Arctic sea ice thickness estimation from CryoSat-2 satellite data using machine learning-based lead detection. S Lee, J Im, J Kim, 10.3390/rs8090698Remote Sens. 896982016</p>
<p>End-to-end classification network for ice sheet subsurface targets in radar imagery. Y Cai, S Hu, S Lang, 10.3390/app10072501Appl. Sci. 10725012020</p>
<p>An outlook for deep learning in ecosystem science. G L W Perry, R Seidl, A M Bellvé, 10.1007/s10021-022-00789-yEcosystems. 2582022</p>
<p>Applications for deep learning in ecology. S Christin, É Hervet, N Lecomte, 10.1111/2041-210x.13256Methods Ecol. Evol. 10102019</p>
<p>Unlocking the connection: Aging as a lens to examine the effects of climate warming. M Wang, B Sun, 10.59717/j.xinn-life.2023.100003Innovation Life. 111000032023</p>
<p>Automatic building extraction from high-resolution aerial images and LiDAR data using gated residual refinement network. J Huang, X Zhang, Q Xin, 10.1016/j.isprsjprs.2019.02.019ISPRS J. Photogramm. Remote Sens. 1512019</p>
<p>Simulating and mitigating extreme urban heat island effects in a factory area based on machine learning. S Liu, J Zhang, J Li, 10.1016/j.buildenv.2021.108051Build. Environ. 2021080512021</p>
<p>Impact of drought-induced forest mortality on terrestrial carbon cycle from remote sensing perspective. X Zhang, J Liu, J Zeng, 10.59717/j.xinn-geo.2024.100057Innovation Geosci. 211000572024</p>
<p>Toward a semiautomatic machine learning retrieval of biophysical parameters. J P Rivera Caicedo, J Verrelst, J Muñoz-Marí, 10.1109/jstars.2014.2298752IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 742014</p>
<p>The sensitivity of vegetation cover to climate change in multiple climatic zones using machine learning algorithms. Z Bao, J Zhang, G Wang, 10.1016/j.ecolind.2021.107443Ecol. Indic. 1241074432021</p>
<p>Intelligent sampling for vegetation nitrogen mapping based on hybrid machine learning algorithms. J Verrelst, K Berger, J P Rivera-Caicedo, 10.1109/lgrs.2020.3014676IEEE Geosci. Remote Sens. Lett. 18122020</p>
<p>Estimating the fractional cover of growth forms and bare surface in savannas: A multi-resolution approach based on regression tree ensembles. U Gessner, M Machwitz, C Conrad, 10.1016/j.rse.2012.10.026Remote Sens. Environ. 1292013</p>
<p>Global status of mangrove forests in resisting cyclone and tsunami. M Jia, Z Wang, L Luo, 10.59717/j.xinn-geo.2023.100024Innovation Geosci. 121000242023</p>
<p>Bayesian network modeling for improving forest growth estimates. Y T Mustafa, P E Van Laake, A Stein, 10.1109/tgrs.2010.2058581IEEE Trans. Geosci. Remote Sens. 4922010</p>
<p>Unsupervised plot-scale LAI phenotyping via UAV-based imaging, modelling, and machine learning. Q Chen, B Zheng, K Chenu, 10.34133/2022/9768253Plant Phenomics. 2022</p>
<p>China's current forest age structure will lead to weakened carbon sinks in the near future. R Shang, J M Chen, M Xu, Innovation. 461005152023</p>
<p>Comparison of different methods for corn LAI estimation over northeastern China. Y Fei, J Sun, H Fang, 10.1016/j.jag.2011.09.004Int. J. Appl. Earth Obs. Geoinf. 182012</p>
<p>Retrieval of spruce leaf chlorophyll content from airborne image data using continuum removal and radiative transfer. Z Malenovský, L Homolová, R Zurita-Milla, 10.1016/j.rse.2012.12.015Remote Sens. Environ. 1312013</p>
<p>Effects of the 2022 extreme droughts on avian influenza transmission risk in Poyang Lake. X Wang, X Xiao, C Zhang, 10.59717/j.xinn-life.2023.100044Innov. Life. 131000442023</p>
<p>Deep learning and citizen science enable automated plant trait predictions from photographs. C Schiller, S Schmidtlein, C Boonman, 10.1038/s41598-021-95616-0Sci. Rep. 111163952021</p>
<p>A high-resolution canopy height model of the Earth. N Lang, W Jetz, K Schindler, 10.1038/s41559-023-02206-6Nat. Ecol. Evol. 72023</p>
<p>A novel framework for stratified-coupled BLS tree trunk detection and DBH estimation in forests (BSTDF) using deep learning and optimization adaptive algorithm. H Zhang, H Zhang, K Xu, 10.3390/rs15143480Remote Sens. 151434802023</p>
<p>An unexpectedly large count of trees in the West African Sahara and Sahel. M Brandt, C J Tucker, A Kariryaa, 10.1038/s41586-020-2824-5Nature. 58778322020</p>
<p>Defoliation estimation of forest trees from groundlevel images. U K€ Alin, N Lang, C Hug, 10.1101/441733Remote Sens. Environ. 2232019</p>
<p>Delineation of agricultural fields in smallholder farms from satellite images using fully convolutional networks and combinatorial grouping. C Persello, V A Tolpekin, J R Bergado, 10.1016/j.rse.2019.111253Remote Sens. Environ. 2311112532019</p>
<p>Efficient, automated and robust pollen analysis using deep learning. O Olsson, M Karlsson, A S Persson, 10.1111/2041-210x.13575Methods Ecol. Evol. 1252021</p>
<p>Deep learning. Y Lecun, Y Bengio, G Hinton, 10.1017/9781108955652.016Nature. 52175532015</p>
<p>Automatic land cover classification of geotagged field photos by deep learning. G Xu, X Zhu, D Fu, 10.1016/j.envsoft.2017.02.004Environ. Model. Softw. 912017</p>
<p>Deep learning-based instance segmentation method of litchi canopy from UAV-acquired images. J Mo, Y Lan, D Yang, 10.3390/rs13193919Remote Sens. 131939192021</p>
<p>The deep-time digital earth program: Datadriven discovery in geosciences. C Wang, R M Hazen, Q Cheng, 10.1093/nsr/nwab027Natl. Sci. Rev. 89272021</p>
<p>Deep learning classification of land cover and crop types using remote sensing data. N Kussul, M Lavreniuk, S Skakun, 10.1109/lgrs.2017.2681128IEEE Geosci. Remote Sens. 1452017</p>
<p>Road detection and centerline extraction via deep recurrent convolutional neural network U-Net. X Yang, X Li, Y Ye, 10.1109/tgrs.2019.2912301IEEE Trans. Geosci. Remote Sens. 5792019</p>
<p>Deep learning-based tree species mapping in a highly diverse tropical urban setting. Urban For Urban Gree. G Barbosa Martins, La Cue, L E Rosa, P Nigri Happ, 10.1016/j.ufug.2021.127241202164127241</p>
<p>More than one quarter of Africa's tree cover is found outside areas previously classified as forest. F Reiner, M Brandt, X Tong, 10.1038/s41467-023-37880-4Nat. Commun. 14122582023</p>
<p>Technologies and perspectives for achieving carbon neutrality. F Wang, J D Harindintwali, Z Yuan, 10.1016/j.xinn.2021.100180Innovation. 241001802021</p>
<p>Scaling carbon fluxes from eddy covariance sites to globe: Synthesis and evaluation of the fluxcom approach. M Jung, C Schwalm, M Migliavacca, 10.5194/bg-17-1343-2020BG. 1752020</p>
<p>Spatial and temporal variations in global soil respiration and their relationships with climate and land cover. N Huang, L Wang, X.-P Song, 10.1126/sciadv.abb8508Sci. Adv. 64185082020</p>
<p>2030 is tomorrow: Transformative change for a mistreated mother earth. J G Richardson, W R Erdelen, 10.1108/fs-03-2020-0029Foresight. 2332021</p>
<p>Customer experiences in the age of artificial intelligence. N Ameen, A Tarhini, A Reppel, 10.1016/j.chb.2020.106548Comput. Hum. Behav. 1141065482021</p>
<p>Development of a digital twin of a local road network: A case study. W J Steyn, A Broekman, 10.1520/jte20210043J. Test. Eval. 5062022</p>
<p>Impact of AI and robotics in the tourism sector: A critical insight. N Samala, B S Katkam, R S Bellamkonda, 10.1108/jtf-07-2019-0065J. Tour. Futures. 812020</p>
<p>Artificial intelligence of things (AIoT) enabled virtual shop applications using self-powered sensor enhanced soft robotic manipulator. Z Sun, M Zhu, Z Zhang, 10.1002/advs.202100230Adv. Sci. 81421002302021</p>
<p>Cooperative highway work zone merge control based on reinforcement learning in a connected and automated environment. T Ren, Y Xie, L Jiang, 10.1177/0361198120935873Transp. Res. Rec. 2674102020</p>
<p>Joint Gaussian Processes for Biophysical Parameter Retrieval. D Heestermans Svendsen, L Martino, M Campos-Taberner, 10.1109/tgrs.2017.2767205IEEE Trans. Geosci. Remote Sens. 5632018</p>
<p>Prospects for direct air capture. S Li, Z Zhang, 10.59717/j.xinn-energy.2024.100010Innovation Energy. 111000102024</p>
<p>Guidelines for volcano-observatory operations during crises: Recommendations from the 2019 volcano observatory best practices meeting. J B Lowenstern, K Wallace, S Barsotti, 10.1186/s13617-021-00112-9J. Appl. Volcanol. 11132022</p>
<p>Groundwater budgeting of Nari and Gaj formations and groundwater mapping of Karachi. M T Sohail, A Hussan, M Ehsan, 10.1007/s13201-022-01795-0Pakistan. Appl. Water Sci. 12122672022</p>
<p>Vegetation responses to variations in climate: A combined ordinary differential equation and sequential Monte Carlo estimation approach. O A Bruzzone, D V Perri, M H Easdale, 10.1016/j.ecoinf.2022.101913Ecol. Inf. 731019132023</p>
<p>Res/70/1 Transforming our world: The 2030 agenda for sustainable development. A Resolution, 10.5040/9781509934058.002520152570th UNGA</p>
<p>Combining satellite imagery and machine learning to predict poverty. N Jean, M Burke, M Xie, 10.1126/science.aaf7894Science. 35363012016</p>
<p>Further promotion of sustainable development goals using science, technology, and innovation. H Guo, L Huang, D Liang, 10.1016/j.xinn.2022.1003252022Innovation. 3(6</p>
<p>The role of artificial intelligence in achieving the sustainable development goals. R Vinuesa, H Azizpour, I Leite, 10.1038/s41467-019-14108-yNat. Commun. 1112020</p>
<p>Assessing whether artificial intelligence is an enabler or an inhibitor of sustainability at indicator level. S Gupta, S D Langhans, S Domisch, 10.1016/j.treng.2021.100064J Transp Eng. 41000642021</p>
<p>Artificial intelligence and sustainable development goals nexus via four vantage points. O Nasir, R T Javed, S Gupta, 10.1016/j.techsoc.2022.102171Technol. Soc. 721021712023</p>
<p>Artificial intelligence, automation, and work (Econ. of AI: An Agenda). D Acemoglu, P Restrepo, 10.7208/chicago/9780226613475.003.00082018</p>
<p>The second machine age: Work, progress, and prosperity in a time of brilliant technologies. E Brynjolfsson, A Mcafee, 2014</p>
<p>Measuring and evaluating SDG indicators with big Earth data. H Guo, D Liang, Z Sun, 10.1016/j.scib.2022.07.015Sci. Bull. 67172022</p>
<p>Extreme impacts on electric power systems from noncatastrophic meteorological conditions. Y Cheng, C Li, Y Xu, 10.59717/j.xinn-energy.2024.100008Innovation Energy. 111000082024</p>
<p>Green and low-carbon energy-use. X Chen, 10.59717/j.xinn-energy.2024.100003Innovation Energy. 111000032024</p>
<p>Renewable electricity and 'green' feedstockbased chemicals will foster industrial sustainability. Y Deng, J Baeyens, H Liu, 10.59717/j.xinn-energy.2024.100016Innovation Energy. 121000162024</p>
<p>Sentinel-3 OLCI observations of water clarity in large lakes in eastern China: Implications for SDG 6.3.2 evaluation. Remote Sens. Environ. M Shen, H Duan, Z Cao, 10.1016/j.rse.2020.1119502020247111950</p>
<p>Eighteen years (2001-2018) of forest habitat loss across the Asian elephant's range and its drivers. L Luo, X Wang, H Guo, 10.1016/j.scib.2022.04.013Sci. Bull. 672022</p>
<p>Unlocking a 30 billion market opportunity with carbon dioxide utilization. J Luo, M Wu, Y Yang, 10.59717/j.xinn-energy.2024.100009Innovation. 111000092024</p>
<p>Interpretable foundation model as decryptor peering into Earth system. C Li, D Hong, B Zhang, 10.1016/j.xinn.2024.1006822024Innovation: 2666-6758</p>
<p>A review on large language models: Architectures, applications, taxonomies, open issues, and challenges. M A Khan Raiaan, M S Hossain Mukta, K Fatema, 10.1109/ACCESS.2024.3365742IEEE Acc. 122023</p>
<p>ChatGPT: Five priorities for research. E A M Van Dis, J Bollen, W Zuidema, 10.1038/d41586-023-00288-7Nature. 61479472023</p>
<p>Physics-aware training for the physical machine learning model building. X Sun, Y Yang, H Jia, 10.1016/j.xinn.2022.100287Innovation. 351002872022</p>
<p>Artificial intelligence for science-bridging data to wisdom. Y Xu, F Wang, Z An, 10.1016/j.xinn.2023.100525Innovation. 461005252023</p>
<p>ChatGPT in hydrology and Earth sciences: Opportunities, prospects, and concerns. E Foroumandi, H Moradkhani, X Sanchez-Vila, 10.1029/2023wr036288Water Resour. Res. 59102023</p>
<p>Single-pixel neutron imaging with artificial intelligence: Breaking the barrier in multi-parameter imaging, sensitivity, and spatial resolution. X Yuan, S Han, 10.1016/j.xinn.2021.100100Innovation. 221001002021</p>
<p>Casformer: Cascaded transformers for fusion-aware computational hyperspectral imaging. C Li, B Zhang, D Hong, 10.1016/j.inffus.2024.102408Inform. Fusion. 1081024082024</p>
<p>UCDformer: Unsupervised change detection using a transformer-driven image translation. Q Xu, Y Shi, J Guo, 10.1109/tgrs.2023.3305334IEEE Trans. Geosci. Remote Sens. 612023</p>
<p>A billion-scale foundation model for remote sensing images. K Cha, J Seo, T Lee, 10.1109/jstars.2024.3401772IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 2024</p>
<p>Climax: A foundation model for weather and climate. T Nguyen, J Brandstetter, A Kapoor, 10.48550/arXiv.2301.103432023Preprint at arXiv</p>
<p>Oceangpt: A large language model for ocean science tasks. Z Bi, N Zhang, Y Xue, 10.48550/arXiv.2310.020312024Preprint at arXiv</p>
<p>LRR-Net: An interpretable deep unfolding network for hyperspectral anomaly detection. C Li, B Zhang, D Hong, 10.1109/tgrs.2023.3279834IEEE Trans. Geosci. Remote Sens. 612023</p>
<p>Learning disentangled priors for hyperspectral anomaly detection: A coupling model-driven and data-driven paradigm. C Li, B Zhang, D Hong, 10.1109/tnnls.2024.3401589IEEE Trans. Neural Netw. Learn. Syst. 2024</p>
<p>SpectralMamba: Efficient Mamba for hyperspectral image classification. J Yao, D Hong, C Li, 10.48550/arXiv.2404.08489arXiv 42024Preprint at</p>
<p>SpectralGPT: Spectral remote sensing foundation model. D Hong, B Zhang, X Li, 10.1109/tpami.2024.33624752024IEEE46</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, 10.48550/arXiv.2010.119292020Preprint at arXiv</p>
<p>A Kirillov, E Mintun, N Ravi, 10.1109/iccv51070.2023.00371Segment Anything (ICCV). 2023</p>
<p>An Open-Source. Nasa Ibm, 2023Geospatial Foundational Model</p>
<p>EarthGPT: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain. W Zhang, M Cai, T Zhang, IEEE T. Geosci. Remote Sens. 622024</p>
<p>FourCastNet: A global data-driven high-resolution weather model using adaptive Fourier neural operators. J Pathak, S Subramanian, P Harrington, 10.48550/arXiv.2202.112142022Preprint at arXiv</p>
<p>Deep learning for day forecasts from sparse observations. M Andrychowicz, L Espeholt, D Li, 10.48550/arXiv.2306.060792023Preprint at arXiv</p>
<p>GenCast: Diffusion-based ensemble forecasting for medium-range weather. I Price, A Sanchez-Gonzalez, F Alet, 10.48550/arXiv.2312.157962023Preprint at arXiv</p>
<p>ClimateGPT: Towards AI synthesizing interdisciplinary research on climate change. D Thulke, Y Gao, P Pelser, 10.48550/arXiv.2401.096462024Preprint at arXiv</p>
<p>DisasterResponseGPT: Large language models for accelerated plan of action development in disaster response scenarios. V G Goecks, N R Waytowich, 10.48550/ARXIV.2306.172712023Preprint at arXiv</p>
<p>L N Darlow, Q Deng, A Hassan, 10.1037/e518442013-089DAM: Towards a Foundation Model for Forecasting (ICLR). 2024</p>
<p>Consecutive pre-training: A knowledge transfer learning strategy with relevant unlabeled data for remote sensing domain. T Zhang, P Gao, H Dong, 10.3390/rs14225675Remote Sens. 142256752022</p>
<p>O Manas, A Lacoste, X Giro-I Nieto, 10.1109/iccv48922.2021.00928Seasonal Contrast: Unsupervised Pretraining from Uncurated Remote Sensing Data (ICCV). 2021</p>
<p>Advancing plain vision transformer toward remote sensing foundation model. D Wang, Q Zhang, Y Xu, 10.1109/tgrs.2022.3222818IEEE Trans. Geosci. Remote Sens. 612022</p>
<p>SatMAE: Pre-training transformers for temporal and multi-spectral satellite imagery. Y Cong, S Khanna, C Meng, 10.48550/ARXIV.2207.08051NeurIPS. 352022</p>
<p>Multimodal contrastive learning for remote sensing tasks. U Jain, A Wilson, V Gulshan, 10.48550/arXiv.2209.023292022Preprint at arXiv</p>
<p>Semantic segmentation of remote sensing images with self-supervised multitask representation learning. W Li, H Chen, Z Shi, 10.1109/jstars.2021.3090418IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 142021</p>
<p>Scale-MAE: A scale-aware masked autoencoder for multiscale geospatial representation learning. C J Reed, R Gupta, S Li, 10.1109/iccv51070.2023.00378ICCV: 408-40992023</p>
<p>Cross-city matters: A multimodal remote sensing benchmark dataset for cross-city semantic segmentation using high-resolution domain adaptation networks. D Hong, B Zhang, H Li, 10.1016/j.rse.2023.113856Remote Sens. Environ. 2991138562023</p>
<p>Decoupled-and-coupled networks: Self-supervised hyperspectral image super-resolution with subpixel fusion. D Hong, J Yao, C Li, 10.1109/tgrs.2023.3324497IEEE Trans. Geosci. Remote Sens. 612023</p>
<p>Multimodal artificial intelligence foundation models: Unleashing the power of remote sensing big data in earth observation. D Hong, C Li, B Zhang, 10.59717/j.xinn-geo.2024.100055The Innovation Geoscience. 211000552024</p>
<p>Towards Geospatial Foundation Models via Continual Pretraining. M Mendieta, B Han, X Shi, 10.1109/iccv51070.2023.01541ICCV: 16760-167702023</p>
<p>SatVIT: Pretraining transformers for earth observation. A Fuller, K Millard, J R Green, 10.1109/lgrs.2022.3201489IEEE Geosci. Remote Sens. 192022</p>
<p>RingMo: A remote sensing foundation model with masked image modeling. X Sun, P Wang, W Lu, 10.1109/tgrs.2022.3194732IEEE Trans. Geosci. Remote Sens. 612022</p>
<p>Masked vision transformers for hyperspectral image classification. L Scheibenreif, M Mommert, D Borth, 10.1109/cvprw59228.2023.00210CVPR: 2165-21752023</p>
<p>EarthFormer: Exploring space-time transformers for earth system forecasting. Z Gao, X Shi, H Wang, 10.1109/lapc.2009.5352582NeurIPS. 352022</p>
<p>Learning a foundation language model for geoscience knowledge understanding and utilization. C Deng, T Zhang, Z He, 10.1145/3616855.36357722023Preprint at arXiv</p>
<p>Incorporate temporal topology in a deep-time knowledge base to facilitate data-driven discovery in geoscience. C Ma, S M Morrison, A D Muscente, 10.1002/gdj3.171Geosci. Data J. 1042022</p>
<p>Earth scientists plan a 'geological google. D Normile, 10.1126/science.363.6430.917Science. 3639172019</p>
<p>A high-resolution summary of Cambrian to early Triassic marine invertebrate biodiversity. J Fan, -X, S.-Z Shen, D H Erwin, 10.1126/science.aax4953Science. 36764752020</p>
<p>Ediacaran biozones identified with network analysis provide evidence for pulsed extinctions of early complex life. A D Muscente, N Bykova, T H Boag, 10.1038/s41467-019-08837-3Nat. Commun. 1019112019</p>
<p>The rise and fall of stromatolites in shallow marine environments. S E Peters, J M Husson, J Wilcots, 10.1130/g38931.1Geology. 4562017</p>
<p>Data-driven discovery in mineralogy: Recent advances in data resources, analysis, and visualization. R M Hazen, R T Downs, A Eleish, 10.1016/j.eng.2019.03.006Engineering. 532019</p>
<p>Sediment cycling on continental and oceanic crust. S E Peters, J M Husson, 10.1130/g38861.1Geology. 4542017</p>
<p>Geochemical and mineralogical evidence that Rodinian assembly was unique. C Liu, A H Knoll, R M Hazen, 10.1038/s41467-017-02095-xNat. Commun. 8119502017</p>
<p>Towards community-driven paleogeographic reconstructions: Integrating open-access paleogeographic and paleobiology data with plate tectonics. N Wright, S Zahirovic, R D Muller, 10.5194/bg-10-1529-2013Biogeosciences. 1032013</p>
<p>Oceanic crustal carbon cycle drives 26-million-year atmospheric carbon dioxide periodicities. R D Muller, A Dutkiewicz, 10.1126/sciadv.aaq0500Sci. Adv. 425002018</p>
<p>Subduction controls the distribution and fragmentation of Earth's tectonic plates. C Mallard, N Coltice, M Seton, 10.1038/nature17992Nature. 53576102016</p>
<p>Paleoclimate implications for future climate change. C Wang, T Wang, X Chen, 10.1007/978-3-642-79066-9_26Earth Sci. Front. 2412017</p>
<p>A new paleoclimate classification for deep time. L Zhang, C Wang, X Li, 10.1016/j.palaeo.2015.11.041Palaeogeogr. Palaeoclimatol. Palaeoecol. 4432016</p>
<p>On the use of evolutionary time series analysis for segmenting paleoclimate data. M Perez-Ortiz, A M Durán-Rosal, P A Gutiérrez, 10.1016/j.neucom.2016.11.101Neurocomputing. 3262019</p>
<p>Knowledge system, ontology, and knowledge graph of the deep-time digital Earth (DDE): Progress and perspective. X Hu, Y Xu, X Ma, 10.1007/s12583-023-1930-1J. Earth Sci. 3452023</p>
<p>One-stop sharing and service system for geoscience knowledge graph. Y Zhu, X Dai, J Yang, 10.1109/ickii.2018.8569149Geol. J. China Univ. 2933252023</p>
<p>Climate paleogeography knowledge graph and deep time paleoclimate classifications. C Yu, L Zhang, M Hou, 10.1016/j.gsf.2022.101450Geosci. Front. 1451014502023</p>
<p>A knowledge graph for standard carbonate microfacies and its application in the automatical reconstruction of the relative sea-level curve. H Wang, H Zhong, A Chen, 10.1016/j.gsf.2023.101535Geosci. Front. 1451015352023</p>
<p>GAKG: A multimodal geoscience academic knowledge graph. C Deng, Y Jia, H Xu, 10.1145/3459637.3482003Proc. 30th ACM Int. Conf. Inf. and Knowl. Manag. 30th ACM Int. Conf. Inf. and Knowl. Manag2021</p>
<p>Embedding ethics and trustworthiness for sustainable AI in Earth sciences: Where do we begin?. P Dias, D Lunga, 10.1109/igarss46834.2022IGARSS: 4639-46422022</p>
<p>Balancing privacy rights and the production of high-quality satellite imagery. M M Coffer, 10.1021/acs.est.0c02365Environ. Sci. Technol. 54112020</p>
<p>Using remote sensing to assess the relationship between crime and the urban layout. J E Patino, J C Duque, J E Pardo-Pascual, 10.1016/j.apgeog.2014.08.016Appl. Geogr. 552014</p>
<p>AI security for geoscience and remote sensing: Challenges and future trends. Y Xu, T Bai, W Yu, 10.1109/mgrs.2023.3272825IEEE Geosci. Remote Sens. Mag. 1122023</p>
<p>Backdoor attacks for remote sensing data with wavelet transform. N Dr€ Ager, Y Xu, P Ghamisi, 10.1109/tgrs.2023.3289307IEEE Trans. Geosci. Remote Sens. 612023</p>
<p>Extratropical forests increasingly at risk due to lightning fires. T A J Janssen, M W Jones, D Finney, 10.1038/s41561-023-01322-zNat. Geosci. 16122023</p>
<p>Towards hybrid modeling of the global hydrological cycle. B Kraft, M Jung, M Körner, 10.5194/hess-26-1579-2022Hydrol. Earth Syst. Sci. Discuss. 20212021</p>
<p>Distributed hydrological modeling with physicsencoded deep learning: A general framework and its application in the Amazon. C Wang, S Jiang, Y Zheng, 10.1029/2023wr036170Water Resour. Res. 6042024</p>
<p>To bucket or not to bucket? Analyzing the performance and interpretability of hybrid hydrological models with dynamic parameterization. Acuña Espinoza, E Loritz, R Álvarez Chaves, M , 10.5194/hess-28-2705-20242023EGUsphere</p>
<p>Integrating hydrology and biogeochemistry across frozen landscapes. J E Vonk, S E Tank, M A Walvoord, 10.1038/s41467-019-13361-5Nat. Commun. 10153772019</p>
<p>N L Hickmon, C Varadharajan, F M Hoffman, 10.2172/1888810Artificial intelligence for Earth system predictability (AI4ESP) (2021 workshop report. Argonne Natl. Lab.. 2022</p>
<p>Combining case-based reasoning systems and support vector regression to evaluate the atmosphere-ocean interaction. J F De Paz, J Bajo, Á González, 10.1007/s10115Knowl. Inf. Syst. 302012</p>
<p>An AI hybrid predictive tool for extreme hurricane forecasting. J Martinez Amaya, C Radin, V Nieves, 10.5194/egusphere-egu23-12333Copernicus Mtgs. EGU23-12333. 2023Technical report</p>
<p>Heat-pipe planets. W B Moore, J I Simon, A A G Webb, 10.1016/j.epsl.2017.06.015Earth Planet. Sci. Lett. 4742017</p>
<p>Atmospheric gravitational tides of Earthlike planets orbiting low-mass stars. T Navarro, T M Merlis, N B Cowan, 10.3847/psj/ac76cdPlanet. Sci. J. 371622022</p>
<p>Orbit-to-ground framework to decode and predict biosignature patterns in terrestrial analogues. K Warren-Rhodes, N A Cabrol, M Phillips, 10.1038/s41550-022-01882-xNat. Astron. 742023</p>
<p>A robust, agnostic molecular biosignature based on machine learning. H J Cleaves, G Hystad, A Prabhu, 10.1073/pnas.2307149120Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA2023120e2307149120</p>
<p>Artificial intelligence vis-à-vis data systems (IGARSS). M Maskey, R Ramachandran, I Gurung, 10.1109/igarss46834.2022.98836262022</p>
<p>First draft of the recommendation of the ethics of artificial intelligence. Ad Hoc Expert Group. 2020</p>
<p>European Union regulations on algorithmic decisionmaking and a "right to explanation. B Goodman, S Flaxman, 10.1609/aimag.v38i3.2741AI Mag. 3832017</p>            </div>
        </div>

    </div>
</body>
</html>