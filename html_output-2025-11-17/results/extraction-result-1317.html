<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1317 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1317</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1317</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-269042749</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2404.07988v2.pdf" target="_blank">Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer</a></p>
                <p><strong>Paper Abstract:</strong> . We explore the dexterous manipulation transfer problem by designing simulators. The task wishes to transfer human manipulations to dexterous robot hand simulations and is inherently difficult due to its intricate, highly-constrained, and discontinuous dynamics and the need to control a dexterous hand with a DoF to accurately replicate human manipulations. Previous approaches that optimize in high-fidelity black-box simulators or a modified one with relaxed constraints only demonstrate limited capabilities or are restricted by insufficient simulation fidelity. We introduce parameterized quasi-physical simulators and a physics curriculum to overcome these limitations. The key ideas are 1) balancing between fidelity and optimizability of the simulation via a curriculum of parameterized simulators, and 2) solving the problem in each of the simulators from the curriculum, with properties ranging from high task optimizability to high fidelity. We successfully enable a dex-terous hand to track complex and diverse manipulations in high-fidelity simulated environments, boosting the success rate by 11%+ from the best-performed baseline. The project website is available at QuasiSim</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1317.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1317.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QuasiSim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parameterized Quasi-Physical Simulator (QuasiSim)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of parameterized, differentiable quasi-physical simulators that relax articulated rigid-body dynamics into point-set dynamics, use a parameterized unconstrained spring-damper contact model, and include neural residual physics to approximate high-fidelity contact-rich dynamics; designed to enable a curriculum from highly-relaxed (easy-to-optimize) to high-fidelity simulators for dexterous manipulation transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Parameterized Quasi-Physical Simulator (QuasiSim)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Analytical+neural hybrid simulator: articulated multi-body relaxed as a mass point set, object represented with signed-distance fields (SDFs), contacts modeled by an unconstrained spring-damper penalty/contact model with tunable threshold and stiffness, and neural residual networks (local and global) to predict residual contact forces/torques; semi-implicit time-stepping and auto-differentiable.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / contact-rich robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>variable fidelity (curriculum): can be low-fidelity (soft contacts, relaxed articulated constraints) for optimization and progressively tightened to high-fidelity by reducing relaxation, increasing contact stiffness, enforcing articulated constraints, and activating residual physics networks to approximate realistic dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Specific fidelity controls include contact distance threshold (d_c), contact spring stiffness (k_n), damping coefficient (k_d), friction spring stiffness (k_f); point-set parameter α controls relaxation between point-set and rigid-body dynamics; includes friction modeled as penalty-based spring forces, SDF object geometry, semi-implicit integrator with dt=5e-4 and 100 substeps/frame; residual networks model local per-contact residual forces (PointNet encoder + MLP) and global residual force/torque on object CoM; can approximate black-box simulator behavior but analytical core remains dominant.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Optimized MPC controller + trajectory A; residual physics networks f_ψ_local and f_ψ_global (MLPs/PointNet encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Control trajectory A is optimized (gradient-based) in the differentiable simulator; residual physics are neural networks (local PointNet-based contact encoder + MLP predictor; global MLP predictor) trained jointly/alternately with control; final execution via MPC (gradient-based optimization over short horizon).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Trajectory/skill optimization for dexterous manipulation transfer: produce control trajectories for a dexterous hand to densely track human hand + object trajectories in contact-rich scenarios (tracking, tool use, large object re-orientations).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>During curriculum optimization the method boosts success rates over baselines (see transfer_performance). Analytical model dominates predictions while residuals compensate; ablations show residual networks improve fidelity and success (quantified in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Higher-fidelity black-box simulators (Bullet, Isaac Gym) and real robots (Allegro hand in a PyBullet→real direct sim-to-real experiment); also used to transfer between morphologies (human MANO → simulated robot hands).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Using curriculum + residual physics yields large improvements vs. baselines (e.g., overall success-rate improvements >11% relative to best baseline). Ablation: 'Ours' (full pipeline) vs 'Ours w/o Curriculum' R_err improved from 42.40 to 24.21 (Bullet), indicating much better transfer; residual physics ablation degrades performance (see paper Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>The curriculum from soft/relaxed simulators to tightened/high-fidelity simulators substantially improves optimization and final tracking: starting with high contact thresholds and low stiffness (soft) eases optimization, then progressively reducing thresholds and increasing stiffness (stiff) and enforcing articulated constraints yields a trajectory that works in high-fidelity targets; ablation 'Ours w/o Curriculum' performs much worse (e.g., R_err 42.40 vs 24.21 in Bullet). Residual networks are required to reach high fidelity approximation of target simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors argue a single simulator rarely provides both optimizability and fidelity; the curriculum shows minimal necessary structure: initial relaxations (point-set dynamics, soft contacts) are useful and not all high-fidelity contact detail is necessary initially, but final accuracy requires tightening contacts and residual physics to match realistic dynamics; they do not provide a single numeric minimal fidelity threshold but show that removing residual physics or skipping curriculum markedly degrades transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Limitations include the simplified spring-damper contact model (authors note it as a limitation); failures occur on tasks requiring extremely precise geometry interactions (e.g., threading a finger through a ring) and near-2D/very-thin objects; without residual physics or with no curriculum, transfer fails (quantified in ablations).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1317.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1317.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bullet / PyBullet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bullet Physics (PyBullet interface)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used rigid-body physics engine; in this paper Bullet (and its Python binding PyBullet) are treated as realistic black-box simulators and used as target high-fidelity environments for evaluating transfer of dexterous manipulation trajectories produced by QuasiSim.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pybullet, a python module for physics simulation for games, robotics and machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Bullet (PyBullet)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A general-purpose rigid-body dynamics and collision/contact simulator with penalty/contact models and PD-control adoption in robotics; used here as a realistic target simulator for evaluating transfer of optimized robot-hand trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / contact-rich robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>treated as a high-fidelity simulated physical environment in experiments (black-box target); captures discontinuous contact events and realistic contact responses compared to relaxed quasi-physical configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Accurate articulated rigid-body dynamics with PD controllers, discrete time-stepping; contact/penetration handled by engine-specific penalty/contact scheme; used here with recommended PD control; authors used Mesh2SDF for objects and tested with fine timestep (dt=5e-4 in quasi-sim conversions) when comparing.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Shadow hand controllers (PD control in Bullet) executed to evaluate tracking trajectories optimized in QuasiSim</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>PD control implementation in Bullet for robot hand joints; control signals converted from QuasiSim joint-forces/root velocities to PD targets via a learned control transformation module.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Evaluation/target environment for dexterous manipulation tracking tasks; not a scientific reasoning domain like thermodynamics, circuits, or biology but used for mechanics/control validation.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Not used as primary training environment for QuasiSim curriculum (QuasiSim trained to approximate it); final tracking errors reported when executing in Bullet: for the proposed method R_err = 24.21 (orientation error), T_err = 1.97 cm, MPJPE = 24.40 mm, and success rates under three thresholds 27.45% / 37.25% / 58.82% (see Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world robot (direct sim-to-real Allegro experiments) and as a target for Sim-to-Sim transfer (QuasiSim approximates Bullet dynamics via residuals).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>When optimizing QuasiSim to approximate Bullet, transferred trajectories executed in Bullet achieve substantially better success than baselines (see numbers above). Direct sim-to-real: transfers optimized in PyBullet led to 8/12 successful Allegro real-world trials (versus baseline 4/12).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>The paper uses Bullet as a target high-fidelity simulator but fidelity-level comparisons are performed in the parametrized QuasiSim curriculum rather than across multiple configurations of Bullet itself.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Bullet is considered 'realistic' and used as the objective to match; authors note that high-fidelity black-box simulators can be hard to optimize in directly due to discontinuous contacts, motivating the curriculum approach rather than insisting on training directly in Bullet.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Baselines trained directly in Bullet or that did not use the QuasiSim curriculum often failed on complex contact-rich tasks (examples showed objects bouncing out, lost tracking); QuasiSim approximations plus curriculum mitigate these failure modes. Direct transfer to real hardware still imperfect (4 of 12 baseline successes vs 8 of 12 for the method).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1317.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1317.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Isaac Gym</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Isaac Gym (NVIDIA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-performance GPU-based physics simulator for robot learning used as another realistic target environment in the paper to evaluate transfer of optimized dexterous manipulation trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Isaac gym: High performance gpu-based physics simulation for robot learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Isaac Gym</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>GPU-accelerated rigid-body physics simulator tailored for large-scale robot learning experiments; used here as a realistic black-box target simulator to evaluate whether trajectories found by QuasiSim curriculum transfer to another high-fidelity environment.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / contact-rich robotic manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>treated as high-fidelity target simulator comparable to Bullet; captures contact discontinuities and realistic rigid-body dynamics and used to validate generality of QuasiSim approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>GPU-based dynamics integration, PD control support, collision/contact handling consistent with high-fidelity rigid-body simulation; tested with recommended PD control in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Shadow hand controllers executed under PD control in Isaac Gym to evaluate performance of trajectories optimized in QuasiSim</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>PD-controlled articulated robot hand in Isaac Gym; trajectories optimized in QuasiSim are converted to PD targets via control transformation and evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Target evaluation environment for dexterous manipulation transfer (tracking human demonstrations) — again mechanics/control rather than thermodynamics/circuits/biology.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Final performance of QuasiSim-transferred trajectories in Isaac Gym reported: R_err = 25.97, T_err = 2.08 cm, MPJPE = 25.33 mm, and success rates under three thresholds 21.57% / 43.14% / 56.86% (see Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Used as a distinct high-fidelity evaluation environment (Sim-to-Sim transfer target) for trajectories produced by QuasiSim curriculum.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Trajectories produced via the QuasiSim curriculum generalize to Isaac Gym with large improvements over baselines; success rates and error metrics above demonstrate transfer effectiveness compared to model-free and model-based baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Paper does not perform a fidelity sweep of Isaac Gym itself; instead evaluates whether QuasiSim-trained trajectories transfer to Isaac Gym as another realistic target, showing positive results.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Isaac Gym serves as an independent realism check; success of transferred trajectories indicates QuasiSim + residuals can approximate different high-fidelity black-box simulators sufficiently for transfer, but no single minimal fidelity metric is defined.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Some sequences and precise manipulations remain challenging even after transfer (reported failure cases include extremely thin objects and tasks requiring very precise finger maneuvers).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Pybullet, a python module for physics simulation for games, robotics and machine learning <em>(Rating: 2)</em></li>
                <li>Isaac gym: High performance gpu-based physics simulation for robot learning <em>(Rating: 2)</em></li>
                <li>Tossingbot: Learning to throw arbitrary objects with residual physics <em>(Rating: 2)</em></li>
                <li>Neuralsim: Augmenting differentiable simulators with neural networks <em>(Rating: 2)</em></li>
                <li>Add: Analytically differentiable dynamics for multi-body systems with frictional contact <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1317",
    "paper_id": "paper-269042749",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "QuasiSim",
            "name_full": "Parameterized Quasi-Physical Simulator (QuasiSim)",
            "brief_description": "A family of parameterized, differentiable quasi-physical simulators that relax articulated rigid-body dynamics into point-set dynamics, use a parameterized unconstrained spring-damper contact model, and include neural residual physics to approximate high-fidelity contact-rich dynamics; designed to enable a curriculum from highly-relaxed (easy-to-optimize) to high-fidelity simulators for dexterous manipulation transfer.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Parameterized Quasi-Physical Simulator (QuasiSim)",
            "simulator_description": "Analytical+neural hybrid simulator: articulated multi-body relaxed as a mass point set, object represented with signed-distance fields (SDFs), contacts modeled by an unconstrained spring-damper penalty/contact model with tunable threshold and stiffness, and neural residual networks (local and global) to predict residual contact forces/torques; semi-implicit time-stepping and auto-differentiable.",
            "scientific_domain": "mechanics / contact-rich robotic manipulation",
            "fidelity_level": "variable fidelity (curriculum): can be low-fidelity (soft contacts, relaxed articulated constraints) for optimization and progressively tightened to high-fidelity by reducing relaxation, increasing contact stiffness, enforcing articulated constraints, and activating residual physics networks to approximate realistic dynamics.",
            "fidelity_characteristics": "Specific fidelity controls include contact distance threshold (d_c), contact spring stiffness (k_n), damping coefficient (k_d), friction spring stiffness (k_f); point-set parameter α controls relaxation between point-set and rigid-body dynamics; includes friction modeled as penalty-based spring forces, SDF object geometry, semi-implicit integrator with dt=5e-4 and 100 substeps/frame; residual networks model local per-contact residual forces (PointNet encoder + MLP) and global residual force/torque on object CoM; can approximate black-box simulator behavior but analytical core remains dominant.",
            "model_or_agent_name": "Optimized MPC controller + trajectory A; residual physics networks f_ψ_local and f_ψ_global (MLPs/PointNet encoder)",
            "model_description": "Control trajectory A is optimized (gradient-based) in the differentiable simulator; residual physics are neural networks (local PointNet-based contact encoder + MLP predictor; global MLP predictor) trained jointly/alternately with control; final execution via MPC (gradient-based optimization over short horizon).",
            "reasoning_task": "Trajectory/skill optimization for dexterous manipulation transfer: produce control trajectories for a dexterous hand to densely track human hand + object trajectories in contact-rich scenarios (tracking, tool use, large object re-orientations).",
            "training_performance": "During curriculum optimization the method boosts success rates over baselines (see transfer_performance). Analytical model dominates predictions while residuals compensate; ablations show residual networks improve fidelity and success (quantified in paper).",
            "transfer_target": "Higher-fidelity black-box simulators (Bullet, Isaac Gym) and real robots (Allegro hand in a PyBullet→real direct sim-to-real experiment); also used to transfer between morphologies (human MANO → simulated robot hands).",
            "transfer_performance": "Using curriculum + residual physics yields large improvements vs. baselines (e.g., overall success-rate improvements &gt;11% relative to best baseline). Ablation: 'Ours' (full pipeline) vs 'Ours w/o Curriculum' R_err improved from 42.40 to 24.21 (Bullet), indicating much better transfer; residual physics ablation degrades performance (see paper Table 2).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "The curriculum from soft/relaxed simulators to tightened/high-fidelity simulators substantially improves optimization and final tracking: starting with high contact thresholds and low stiffness (soft) eases optimization, then progressively reducing thresholds and increasing stiffness (stiff) and enforcing articulated constraints yields a trajectory that works in high-fidelity targets; ablation 'Ours w/o Curriculum' performs much worse (e.g., R_err 42.40 vs 24.21 in Bullet). Residual networks are required to reach high fidelity approximation of target simulators.",
            "minimal_fidelity_discussion": "Authors argue a single simulator rarely provides both optimizability and fidelity; the curriculum shows minimal necessary structure: initial relaxations (point-set dynamics, soft contacts) are useful and not all high-fidelity contact detail is necessary initially, but final accuracy requires tightening contacts and residual physics to match realistic dynamics; they do not provide a single numeric minimal fidelity threshold but show that removing residual physics or skipping curriculum markedly degrades transfer.",
            "failure_cases": "Limitations include the simplified spring-damper contact model (authors note it as a limitation); failures occur on tasks requiring extremely precise geometry interactions (e.g., threading a finger through a ring) and near-2D/very-thin objects; without residual physics or with no curriculum, transfer fails (quantified in ablations).",
            "uuid": "e1317.0",
            "source_info": {
                "paper_title": "Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Bullet / PyBullet",
            "name_full": "Bullet Physics (PyBullet interface)",
            "brief_description": "A widely used rigid-body physics engine; in this paper Bullet (and its Python binding PyBullet) are treated as realistic black-box simulators and used as target high-fidelity environments for evaluating transfer of dexterous manipulation trajectories produced by QuasiSim.",
            "citation_title": "Pybullet, a python module for physics simulation for games, robotics and machine learning",
            "mention_or_use": "use",
            "simulator_name": "Bullet (PyBullet)",
            "simulator_description": "A general-purpose rigid-body dynamics and collision/contact simulator with penalty/contact models and PD-control adoption in robotics; used here as a realistic target simulator for evaluating transfer of optimized robot-hand trajectories.",
            "scientific_domain": "mechanics / contact-rich robotic manipulation",
            "fidelity_level": "treated as a high-fidelity simulated physical environment in experiments (black-box target); captures discontinuous contact events and realistic contact responses compared to relaxed quasi-physical configurations.",
            "fidelity_characteristics": "Accurate articulated rigid-body dynamics with PD controllers, discrete time-stepping; contact/penetration handled by engine-specific penalty/contact scheme; used here with recommended PD control; authors used Mesh2SDF for objects and tested with fine timestep (dt=5e-4 in quasi-sim conversions) when comparing.",
            "model_or_agent_name": "Shadow hand controllers (PD control in Bullet) executed to evaluate tracking trajectories optimized in QuasiSim",
            "model_description": "PD control implementation in Bullet for robot hand joints; control signals converted from QuasiSim joint-forces/root velocities to PD targets via a learned control transformation module.",
            "reasoning_task": "Evaluation/target environment for dexterous manipulation tracking tasks; not a scientific reasoning domain like thermodynamics, circuits, or biology but used for mechanics/control validation.",
            "training_performance": "Not used as primary training environment for QuasiSim curriculum (QuasiSim trained to approximate it); final tracking errors reported when executing in Bullet: for the proposed method R_err = 24.21 (orientation error), T_err = 1.97 cm, MPJPE = 24.40 mm, and success rates under three thresholds 27.45% / 37.25% / 58.82% (see Table 1).",
            "transfer_target": "Real-world robot (direct sim-to-real Allegro experiments) and as a target for Sim-to-Sim transfer (QuasiSim approximates Bullet dynamics via residuals).",
            "transfer_performance": "When optimizing QuasiSim to approximate Bullet, transferred trajectories executed in Bullet achieve substantially better success than baselines (see numbers above). Direct sim-to-real: transfers optimized in PyBullet led to 8/12 successful Allegro real-world trials (versus baseline 4/12).",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "The paper uses Bullet as a target high-fidelity simulator but fidelity-level comparisons are performed in the parametrized QuasiSim curriculum rather than across multiple configurations of Bullet itself.",
            "minimal_fidelity_discussion": "Bullet is considered 'realistic' and used as the objective to match; authors note that high-fidelity black-box simulators can be hard to optimize in directly due to discontinuous contacts, motivating the curriculum approach rather than insisting on training directly in Bullet.",
            "failure_cases": "Baselines trained directly in Bullet or that did not use the QuasiSim curriculum often failed on complex contact-rich tasks (examples showed objects bouncing out, lost tracking); QuasiSim approximations plus curriculum mitigate these failure modes. Direct transfer to real hardware still imperfect (4 of 12 baseline successes vs 8 of 12 for the method).",
            "uuid": "e1317.1",
            "source_info": {
                "paper_title": "Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Isaac Gym",
            "name_full": "Isaac Gym (NVIDIA)",
            "brief_description": "A high-performance GPU-based physics simulator for robot learning used as another realistic target environment in the paper to evaluate transfer of optimized dexterous manipulation trajectories.",
            "citation_title": "Isaac gym: High performance gpu-based physics simulation for robot learning",
            "mention_or_use": "use",
            "simulator_name": "Isaac Gym",
            "simulator_description": "GPU-accelerated rigid-body physics simulator tailored for large-scale robot learning experiments; used here as a realistic black-box target simulator to evaluate whether trajectories found by QuasiSim curriculum transfer to another high-fidelity environment.",
            "scientific_domain": "mechanics / contact-rich robotic manipulation",
            "fidelity_level": "treated as high-fidelity target simulator comparable to Bullet; captures contact discontinuities and realistic rigid-body dynamics and used to validate generality of QuasiSim approximations.",
            "fidelity_characteristics": "GPU-based dynamics integration, PD control support, collision/contact handling consistent with high-fidelity rigid-body simulation; tested with recommended PD control in experiments.",
            "model_or_agent_name": "Shadow hand controllers executed under PD control in Isaac Gym to evaluate performance of trajectories optimized in QuasiSim",
            "model_description": "PD-controlled articulated robot hand in Isaac Gym; trajectories optimized in QuasiSim are converted to PD targets via control transformation and evaluated.",
            "reasoning_task": "Target evaluation environment for dexterous manipulation transfer (tracking human demonstrations) — again mechanics/control rather than thermodynamics/circuits/biology.",
            "training_performance": "Final performance of QuasiSim-transferred trajectories in Isaac Gym reported: R_err = 25.97, T_err = 2.08 cm, MPJPE = 25.33 mm, and success rates under three thresholds 21.57% / 43.14% / 56.86% (see Table 1).",
            "transfer_target": "Used as a distinct high-fidelity evaluation environment (Sim-to-Sim transfer target) for trajectories produced by QuasiSim curriculum.",
            "transfer_performance": "Trajectories produced via the QuasiSim curriculum generalize to Isaac Gym with large improvements over baselines; success rates and error metrics above demonstrate transfer effectiveness compared to model-free and model-based baselines.",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "Paper does not perform a fidelity sweep of Isaac Gym itself; instead evaluates whether QuasiSim-trained trajectories transfer to Isaac Gym as another realistic target, showing positive results.",
            "minimal_fidelity_discussion": "Isaac Gym serves as an independent realism check; success of transferred trajectories indicates QuasiSim + residuals can approximate different high-fidelity black-box simulators sufficiently for transfer, but no single minimal fidelity metric is defined.",
            "failure_cases": "Some sequences and precise manipulations remain challenging even after transfer (reported failure cases include extremely thin objects and tasks requiring very precise finger maneuvers).",
            "uuid": "e1317.2",
            "source_info": {
                "paper_title": "Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer",
                "publication_date_yy_mm": "2024-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Pybullet, a python module for physics simulation for games, robotics and machine learning",
            "rating": 2,
            "sanitized_title": "pybullet_a_python_module_for_physics_simulation_for_games_robotics_and_machine_learning"
        },
        {
            "paper_title": "Isaac gym: High performance gpu-based physics simulation for robot learning",
            "rating": 2,
            "sanitized_title": "isaac_gym_high_performance_gpubased_physics_simulation_for_robot_learning"
        },
        {
            "paper_title": "Tossingbot: Learning to throw arbitrary objects with residual physics",
            "rating": 2,
            "sanitized_title": "tossingbot_learning_to_throw_arbitrary_objects_with_residual_physics"
        },
        {
            "paper_title": "Neuralsim: Augmenting differentiable simulators with neural networks",
            "rating": 2,
            "sanitized_title": "neuralsim_augmenting_differentiable_simulators_with_neural_networks"
        },
        {
            "paper_title": "Add: Analytically differentiable dynamics for multi-body systems with frictional contact",
            "rating": 1,
            "sanitized_title": "add_analytically_differentiable_dynamics_for_multibody_systems_with_frictional_contact"
        }
    ],
    "cost": 0.014969,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer
21 Jul 2024</p>
<p>Xueyi Liu 
Tsinghua University</p>
<p>Kangbo Lyu 
Tsinghua University</p>
<p>Jieqiong Zhang 
Tsinghua University</p>
<p>Tao Du 
Tsinghua University</p>
<p>Shanghai AI Laboratory
3 Shanghai Qi Zhi Institute https://meowuu7.githubQuasiSim</p>
<p>Li Yi 
Tsinghua University</p>
<p>Shanghai AI Laboratory
3 Shanghai Qi Zhi Institute https://meowuu7.githubQuasiSim</p>
<p>Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer
21 Jul 202446D5479B721BB5205B0B338A4EC70BB1arXiv:2404.07988v2[cs.RO]</p>
<p>Abstract.We explore the dexterous manipulation transfer problem by designing simulators.The task wishes to transfer human manipulations to dexterous robot hand simulations and is inherently difficult due to its intricate, highly-constrained, and discontinuous dynamics and the need to control a dexterous hand with a DoF to accurately replicate human manipulations.Previous approaches that optimize in high-fidelity black-box simulators or a modified one with relaxed constraints only demonstrate limited capabilities or are restricted by insufficient simulation fidelity.We introduce parameterized quasi-physical simulators and a physics curriculum to overcome these limitations.The key ideas are 1) balancing between fidelity and optimizability of the simulation via a curriculum of parameterized simulators, and 2) solving the problem in each of the simulators from the curriculum, with properties ranging from high task optimizability to high fidelity.We successfully enable a dexterous hand to track complex and diverse manipulations in high-fidelity simulated environments, boosting the success rate by 11%+ from the best-performed baseline.The project website is available at QuasiSim.</p>
<p>Introduction</p>
<p>Advancing an embodied agent's capacity to interact with the world represents a significant stride toward achieving general artificial intelligence.Due to the substantial costs and potential hazards of setting up real robots to do trial and error, the standard approach for developing embodied algorithms involves learning in physical simulators [13,19,28,30,38,63,67] before transitioning to realworld deployment.In most cases, physical simulators are treated as black boxes, and extensive efforts have been devoted to developing learning and optimization methods for embodied skills within these black boxes.Despite the considerable progress [2, 10-12, 20, 24, 26, 36, 41, 44, 49, 52, 68, 70, 74, 76], the question like whether the simulators used are the most suitable ones is rarely discussed.In this work, we investigate this issue and illustrate how optimizing the simulator concurrently with skill acquisition can benefit a popular yet challenging task in robot manipulation -dexterous manipulation transfer.</p>
<p>The task aims at transferring human-object manipulations to a dexterous robot hand, enabling it to physically track the reference motion of both the hand and the object (see Fig. 1).It is challenged by 1) the complex, highly constrained, non-smooth, and discontinuous dynamics with frequent contact establishment and breaking involved in the robot manipulation, 2) the requirement of precisely controlling a dexterous hand with a high DoF to densely track the manipulation at each frame, and 3) the morphology difference.Some existing works rely on high-fidelity black-box simulators, where a small difference in robot control can result in dramatically different manipulation outcomes due to abrupt contact changes, making the tracking objective highly non-smooth and hard to optimize [4,10,12,49,52].In this way, their tasks are restricted to relatively simple goal-driven manipulations such as pouring and re-locating [12,49,52,76], in-hand re-orientation, flipping and spinning [4,10] with a fixed-root robot hand, or manipulating objects with simple geometry such as balls [41].Other approaches attempt to improve optimization by relaxing physical constraints, with a primary focus on smoothing out contact responses [3,29,43,62,63].However, their dynamics models may significantly deviate from real physics [43], hindering skill deployment.Consequently, we ask how to address the optimization challenge while preserving the high fidelity of the simulator.</p>
<p>Our key insight is that a single simulator can hardly provide both high fidelity and excellent optimizability for contact-rich dexterous manipulations.Inspired by the line of homotopy methods [16,33,34,69], we propose a curriculum of simulators to realize this.We start by utilizing a quasi-physical simulator to initially relax physical constraints and warm up the optimization.Subsequently, we transfer the optimization outcomes to simulators with gradually tightened physical constraints.Finally, we transition to a physically realistic simulator for skill deployment in realistic dynamics.</p>
<p>To realize this vision, we propose a family of parameterized quasiphysical simulators for contact-rich dexterous manipulation tasks.These simulators can be customized to enhance task optimizability while can also be tailored to approximate realistic physics.The parameterized simulator represents an articulated multi rigid body as a parameterized point set, models contact using an unconstrained parameterized spring-damper, and compensates for unmodeled effects via parameterized residual physics.Specifically, the articulated multi-body dynamics model is relaxed as the point set dynamics model.An articulated object is relaxed into a set of points, sampled from the ambient space surrounding each body's surface mesh.The resulting dynamics model combines the original articulated dynamics with the mass-point dynamics of each individual point.Parameters are introduced to control the point set construction and the dynamics model.The contact model is softened as a parameterized spring-damper model [3,23,40,43,58] with parameters introduced to control when to calculate contacts and contact spring stiffness.The residual physics network compensate for unmodeled effects from the analytical modeling [27].The parameterized simulator can be programmed for high optimizability by relaxing constraints in the analytical model and can be tailored to approximate realistic physics by learning excellent residual physics.We demonstrate that the challenging dexterous manipulation transfer task can be effectively addressed through curriculum optimization using a series of parameterized physical simulators.Initially, both articulated rigid constraints and the contact model stiffness are relaxed in the simulator.It may not reflect physical realism but provides a good environment where the manipulation transfer problem can be solved easily.Subsequently, the articulated rigid constraints and the contact model are gradually tightened.Task-solving proceeds iteratively within each simulator in the curriculum.Finally, the parameterized simulator is optimized to approximate realistic physics.Task optimization continues, yielding a dexterous hand trajectory capable of executing the manipulation in environments with realistic physics.</p>
<p>We demonstrate the superiority of our method and compare it with previous model-free and model-based methods on challenging manipulation sequences from three datasets, describing single-hand or bimanual manipulations with daily objects or using tools.We conduct dexterous manipulation transfer on two widely used simulators, namely Bullet [13] and Isaac Gym [38] to demonstrate the generality and the efficacy of our method and the capability of our quasi-physical simulator to approximate the unknown black-box physics model in the contact-rich manipulation scenario (Fig. 1).We can track complex manipulations involving non-trivial object motions such as large rotations and complicated tool-using such as using a spoon to bring the water back and forth.Our approach successfully surpasses the previous best-performed method both quantitatively and qualitatively, achieving more than 11% success rate than the previous best-performed method.Besides, optimizing through the physics curriculum can significantly enhance the performance of previously under-performed RL-based methods, almost completing the tracking problem from failure, as demonstrated in Fig. 1.This indicates the universality of our approach to embodied AI through optimization via a physics curriculum.Thorough ablations are conducted to validate the efficacy of our designs.</p>
<p>Our contributions are three-fold:</p>
<p>-We introduce a family of parameterized quasi-physical simulators that can be configured to relax various physical constraints, facilitating skill optimization, and can also be tailored to achieve high simulation fidelity.-We present a quasi-physics curriculum along with a corresponding optimization method to address the challenging dexterous manipulation transfer problem.</p>
<p>-Extensive experiments demonstrate the effectiveness of our method in transferring complex manipulations, including non-trivial object motions and changing contacts, to a dexterous robot hand in simulation.</p>
<p>Related Works</p>
<p>Dexterous manipulation transfer.Transferring human manipulations to dexterous robot-hand simulations is an important topic in robot skill acquisition [12,26,36,49,68,70,76,78]. Most approaches treat the simulator as black-box physics models and try to learn skills directly from that [4,10,12,49,52].However, their demonstrated capabilities are restricted to relatively simple tasks.Another trend of work tries to relax the physics model [42,43] to create a better environment for task optimization.However, due to the disparity between their modeling approach and realistic physics, successful trials are typically demonstrated only in their simulators, which can hardly complete the task under physically realistic dynamics.In this work, we introduce various parameterized analytical relaxations to improve the task optimizability while compensating for unmodeled effects via residual physics networks so the fidelity would not be sacrificed.Learning for simulation.Analytical methods can hardly approximate an extremely realistic physical world despite lots of smart and tremendous efforts made in developing numerical algorithms [23,28,31,32].Recently, data-driven approaches have attracted lots of interest for their high efficiency and strong approximation ability [14,15,27,45,46,57,71].Special network designs are proposed to learn the contact behaviour [27,46].We in this work propose to leverage an analytical-neural hybrid approach and carefully design network modules for approximating residual contact forces in the contact-rich manipulation scenario.Sim-to-Sim and Sim-to-Real transfer.The field of robot manipulation continues to face challenges in the areas of Sim2Sim and Sim2Real transferability [79].Considering the modeling gaps, the optimal strategy learned in a specific simulator is difficult to transfer to a different simulator or the real world.Therefore, many techniques for solving the problem have been proposed, including imitation learning [39,48,49,51,52,54], transfer learning [80], distillation [53,64], residual physics [21,75], and efforts on bridging the gap from the dynamics model aspect [27,77].Our parameterized simulators learn residual physics involved in contact-rich robot manipulations.By combining an analytical base with residual networks, we showcase their ability to approximate realistic physics.</p>
<p>Method</p>
<p>Given a human manipulation demonstration, composed of a human hand mesh trajectory and an object pose trajectory {H, O}, the goal is transferring the demonstration to a dexterous robot hand in simulation.Formally, we aim to optimize a control trajectory A that drives the dexterous hand to manipulate the object in a realistic simulated environment so that the resulting hand trajectory Ĥ and the object trajectory Ô are close to the reference motion {H, O}.The problem is challenged by difficulties from the highly constrained, discontinuous, and non-smooth dynamics, the requirement of controlling a high DoF dexterous hand for tracking, and the morphology difference.</p>
<p>Our method comprises two key designs to tackle the challenges: 1) a family of parameterized quasi-physical simulators, which can be programmed to enhance the optimizability of contact-rich dexterous manipulation tasks and can also be tailored to approximate realistic physics (Section 3.1), and 2) a physics curriculum that carefully adjusts the parameters of a line of quasi-physical simulators and a strategy that solves the difficult dexterous manipulation transfer task by addressing it within each simulator in the curriculum (Section 3.2).</p>
<p>Parameterized Quasi-Physical Simulators</p>
<p>Our quasi-physical simulator represents an articulated multi-body, i.e., the robotic dexterous hand, as a point set.The object is represented as a signed distance field.The base of the simulator is in an analytical form leveraging an unconstrained spring-damper contact model.Parameters are introduced to control the analytical relaxations on the articulated rigid constraints and the softness of the contact model.Additionally, neural networks are introduced to compensate for unmodeled effects beyond the analytical framework.We will elaborate on each of these design aspects below.Parameterized point set dynamics.Articulated multi-body represented in the reduced coordinate system [23,67] may require a large change in joint states to achieve a small adjustment in the Euclidean space.Moving the end effector from one point to a nearby point may require adjusting all joint states (Fig. 3).Besides, transferring the hand trajectory to a morphologically different hand requires correspondences to make the resulting trajectory close to the original one.Defining correspondences in the reduced coordinate or via sparse correspon-dences will make the result suffer from noise in the data, leading to unwanted results finally (Fig. 3).Hence, we propose relaxing an articulated multi-rigid body into a mass-point set sampled from the ambient space surrounding each body.Each point is considered attached to the body from which it is sampled and is capable of both self-actuation and actuation via joint motors.We introduce a parameter α to control the point set construction and the dynamics.This representation allows an articulated rigid object to behave similarly to a deformable object, providing a larger action space to adjust its state and thereby easing the control optimization problem.Specifically, for each body of the articulated object, we sample a set of points from the ambient space near the body mesh.The point set Q is constructed by concatenating all sampled points together.Each point p i ∈ Q is treated as a mass point with a finite mass m i and infinitesimal volume.The dynamics of the point set consist of articulated multi-body dynamics [18,35], as well as the mass point dynamics of each point p i .For each p i , we have:
m i ẍi = J i u + αf i + αa i ,(1)
where J i represents the Jacobian mapping from the generalized velocity to the point velocity ẋi , u denotes the generalized joint force, f i accounts for external forces acting on p i , and a i ∈ R 3 represents the actuation force applied to the point p i .Consequently, the point set is controlled by a shared control in the reduced coordinate space u and per-point actuation force a i .Parameterized spring-damper contact modeling.To ease the optimization challenges posed by contact-rich manipulations, which arise from contact constraints such as the non-penetration requirement and Coulomb friction law [3,7], as well as discontinuous dynamics involving frequent contact establishment and breaking, we propose a parameterized contact model for relaxing constraints and controlling the contact behavior.Specifically, we leverage a classical unconstrained spring-damper model [23,40,58,67,72] to model the contacts.This model allows us to flexibly adjust the contact behavior by tuning the contact threshold and the spring stiffness coefficients.Intuitively, a contact model with a high threshold and low spring stiffness presents "soft" behaviors, resulting in a continuous and smooth optimization space.This makes optimization through such a contact model relatively easy.Conversely, a model with a low threshold and large stiffness coefficients will produce "stiff" behaviors, increasing the discontinuity of the optimization space due to frequent contact establishment and breaking.However, it also becomes more physically realistic, meaning contact forces are calculated only when two objects collide, and a large force is applied to separate them if penetrations are observed, thus better satisfying the nonpenetration condition.Therefore, by adjusting the contact distance threshold and spring stiffness coefficients, we can modulate the optimizability and fidelity of the contact model.The parameter set of the contact model comprises a distance threshold d c and spring stiffness coefficients.Next, we will delve into the details of the contact establishment, breaking, and force calculations processes.Contacts are established between points in the manipulator's point set Q and the object.A point p ∈ Q is considered to be in "contact" with the object if its signed distance to the object sd(p) is smaller than the contact distance threshold d c .Subsequently, the object surface point nearest to p is identified as the corresponding contact point on the object, denoted as p o .The normal direction of the object point p o is then determined as the contact normal direction, denoted as n o .The contact force f c applied from the manipulator point p to p o is calculated as follows:
f c = −(k n d − k d d ḋ)n o ,(2)
where, k n represents the spring stiffness coefficient, k d denotes the damping coefficient, and d = d c − sd(p) is always positive.To enhance the continuity of f c [72], k d d ḋ is used as the magnitude of the damping force, rather than k d ḋ.</p>
<p>Friction forces are modeled as penalty-based spring forces [3,73].Once a point p is identified as in contact with the object, with the object contact point denoted as p o , the contact pair is stored.Contact forces between them are continually calculated until the contact breaking conditions are met.In more detail, the static friction force from p to p o is calculated using a spring model:
f f s = k f T n (p − p o ),(3)
where k f is the friction spring stiffness coefficient, T n = I−n o n oT is a tangential projection operator.When the static friction satisfies ∥f f s ∥ ≤ µ∥f c ∥, f f s is applied to the object point p o .Otherwise, the dynamic friction force is applied, and the contact breaks:
f f d = −µ∥f f s ∥ T n v p←p o ∥T n v p←p o ∥ ,(4)
where v p←p o is the relative velocity between p and p o .Parameterized residual physics.The analytical designs facilitate relaxation but may limit the use of highly sophisticated and realistic dynamics models, deviating from real physics.To address this, the final component of our quasiphysical simulator is a flexible neural residual physics model [1,27,46].Specifically, we propose to employ neural networks to learn and predict residual contact forces and friction forces based on contact-related information.For detailed residual contact force prediction, we introduce a local contact network f ψ local that utilizes contact information identified in the parameterized contact model and predicts residual forces between each contact pair.To address discrepancies in contact region identification between the parameterized contact model and real contact region, we also incorporate a global residual network f ψ global that predicts residual forces and torques applied directly to the object's center of mass.In more detail, for a given contact pair (p, p o ), the local contact network utilizes contact-related features from the local contact region, comprising geometry, per-point velocity, and per-object point normal.It then maps these features to predict the residual contact force and residual friction force between the two points in the contact pair.Additionally, the global residual network incorporates contact-related information from the global contact region, including geometry, per-point velocity, and per-object point normal, as input.It then predicts a residual force and residual torque to be applied to the object's center of mass.Details such as contact region identification and network architectures are deferred to the Supp.We denote the optimizable parameters in the residual physics network as ψ = (ψ global , ψ local ).Through optimization of the residual physics network, we unlock the possibility of introducing highly non-linear dynamics to align our parametrized quasi-physical simulator with any realistic black-box physical simulator.</p>
<p>Semi-implicit time-stepping is leveraged to make the simulation auto differentiable and easy to combine with neural networks [27].</p>
<p>Dexterous Manipulation Transfer via a Physics Curriculum</p>
<p>Building upon the family of parameterized quasi-physical simulators, we present a solution to the challenging dexterous manipulation transfer problem through a physics curriculum.This curriculum consists of a sequence of parameterized simulators, ranging from those with minimal constraints and the softest contact behavior to increasingly realistic simulators.We address the problem by transferring the manipulation demonstration to the dexterous hand within each simulator across the curriculum progressively.To elaborate further, the optimization process begins within the parameterized simulator where articulated rigid constraints are removed and the contact model is tuned to its softest level.Additionally, the residual physics networks are deactivated.This initial simulator configuration offers a friendly environment for optimization.Subsequently, the physics constraints are gradually tightened as we progress through each simulator within the curriculum.The task is solved iteratively within each simulator.After reaching the most tightened analytical model, the analytical part is fixed and residual networks are activated.The simulator is gradually optimized to approximate the dynamics in a realistic physical environment.Concurrently, the control trajectory A continues to be refined in the quasi-physical simulator.Finally, we arrive at a simulator optimized to be with high fidelity and a trajectory A capable of guiding the dexterous hand to accurately track the demonstration within a realistically simulated physical environment.Additionally, since object properties as well as system parameters are unknown from the kinematics-only demonstration, we set them optimizable and identify them (denoted S) together with optimizing the hand control trajectory.Next we'll illustrate this in detail.</p>
<p>Transferring human demonstration via point set dynamics.To robustly transfer the human demonstration to a morphologically different dexterous robot hand in simulation and to overcome noise in the kinematic trajectory, we initially relax the articulated rigid constraints and transfer the kinematics human demonstration to the control trajectory of the point set.Specifically, the point set representation with the relaxation parameter α for the dynamic human hand [12] is constructed.The shared control trajectory A and per-point per-frame actions are optimized so that the resulting trajectory of the point set can manipulate the object according to the demonstration.After that, a point set with the same parameter α is constructed to represent the dexterous robot hand.Subsequently, the shared control trajectory A and per-point per-frame actions are optimized to track the manipulation accordingly.</p>
<p>Transferring through a contact model curriculum.After that, the articulated rigid constraint is tightened by freezing the point set parameter α to zero.The following optimization starts from a parameterized simulator with the softest contact model.We then gradually tighten the contact model by adjusting its distance threshold, contact force spring stiffness, etc.By curriculum optimizing the trajectory A and parameters S in each of the quasi-physical simulators, we finally arrive at the control trajectory that can drive a dexterous hand to accomplish the tracking task in the parameterized simulator with the most tightened analytical model.Optimizing towards a realistic physical environment.Subsequently, the residual physics network is activated and the parameterized simulator is optimized to approximate the dynamics in a realistic physical environment.We continue to optimize the hand trajectory in the quasi-physical simulator.Specifically, we leverage the successful trial in model-based human tracking literature [20,74] and iteratively optimize the control trajectory A and the parameterized simulator.In more detail, the following two subproblems are iteratively solved: 1) optimizing the quasi-physical simulator to approximate the realistic dynamics, and 2) optimizing the control trajectory A to complete the manipulation in the quasi-physical simulator.Gradient-based optimization is leveraged taking advantage of the differentiability of the parameterized simulator.</p>
<p>After completing the optimization, the final control trajectory is yielded by model predictive control (MPC) [22] based on the optimized parameterized simulator and the hand trajectory A. Specifically, in each step, the current and the following controls in several subsequent frames are optimized to reduce the tracking error.More details are deferred to the Supp.</p>
<p>Experiments</p>
<p>We conduct extensive experiments to demonstrate the effectiveness of our method.The evaluation dataset is constructed from three HOI datasets with both singlehand and bimanual manipulations (with rigid objects), with complex manipulations with non-trivial object movements, and rich and changing contacts involved (see Section 4.1).We use Shadow hand [55] and test in two simulators widely used in the embodied AI community: Bullet [13] and Isaac Gym [38].We compare our method with both model-free approaches and model-based strategies and demonstrate the superiority of our method both quantitatively and qualitatively.We can track complex contact-rich manipulations with large object rotations, back-and-forth object movements, and changing contacts successfully in both of the two simulators, while the best-performed baseline fails (see Section 4.2, Fig. 4).On average, we boost the tracking success rate by 11%+ from the previous best-performed (see Section 4.2).We make further analysis and discussions and show that the core philosophy of our work, optimizing through a quasi-physics curriculum, is potentially general and can help improve the performance of a model-free baseline (see Section 4.3).</p>
<p>Experimental Settings</p>
<p>Datasets.Our evaluation dataset is compiled from three distinct sources, namely GRAB [60], containing single-hand interactions with daily objects, TACO [37], containing humans manipulating tools, and ARCTIC [17] with bimanual manipulations.For GRAB, we randomly sample a manipulation trajectory for each object.If its manipulation is extremely simple, we additionally sample one trajectory for it.The object is not considered if its corresponding manipulation is bimanual such as binoculars, involves other body parts such as bowl, or with detailed part movements such as the game controller.The number of manipulation sequences from GRAB is 27.For TACO [37], we acquire data by contacting authors.We randomly select one sequence for each right-hand tool object.Sequences with very low quality like erroneous object motions are excluded.14 trajectories in total are selected finally.For ARCTIC [17], we randomly select one sequence for each object from its available manipulation trajectories, resulting in 10 sequences in total.More details are deferred to the Supp.</p>
<p>Metrics.We introduce three distinct metrics to assess the quality of object tracking, the accuracy of hand tracking, and the overall success of the tracking task: 1) Per-frame average object rotation error:
R err = 1 N N n=1 (1 − (q n • qn ))
, where q n is the ground-truth orientation and qn is the tracked result, represented in quaternion.2) Per-frame average object translation error: T err = 1 N N n=1 ∥t n − tn ∥, where t and t n are ground-truth and tracked translations respectively.3) Mean Per-Joint Position Error 50,65], where J n and Ĵn are keypoints of GT human hand and the simulated robot hand respectively.We manually define the keypoints and the correspondences to the human hand keypoints for the Shadow hand.4) Per-frame average hand Chamfer Distance: CD = 1 N N n=1 Chamfer-Distance(H n − Ĥn ), for evaluating whether the Shadow hand can "densely" track the demonstration.5) Success rate: a tracking is regarded as successful if the object rotation error R err , object translation error T err , and the hand tracking error MPJPE are smaller than their corresponding threshold.Three success rates are calculated using three different thresholds, namely 10
(MPJPE) = 1 N N n=1 ∥J n − Ĵn ∥ [24,• − 10cm − 10cm, 15 • − 15cm − 15cm.
Baselines.We compare with two trends of baselines.For model-free approaches, since there is no prior work with exactly the same problem setting as us, we try to modify and improve a goal-driven rigid object manipulation method DGrasp [12] into two methods for tracking: 1) DGrasp-Base, where the method is almost kept with same with the original DGrasp.We use the first frame where the hand and the object are in contact with each other as the reference frame.Then the policy is trained to grasp the object according to the reference hand and object goal at first.After that, only the root is guided to complete the task.2) DGrasp-Tracking, where we divide the whole sequence into several subsequences, each of which has 10 frames, and define the end frame of the subsequence as the reference frame.Then the grasping policy is used to guide the hand and gradually track the object according to the hand and the object pose of each reference frame.We improve the DGrasp-Tracking by optimizing the policy through the quasiphysical curriculum and creating "DGrasp-Tracking (w/ Curriculum)" trying to improve its performance.For model-based methods, we compare with Control-VAE [74] and traditional MPC approaches.For Control-VAE, we modify its implementation for the manipulation tracking task.We additionally consider three differentiable physics models to conduct model-predictive control for solving the task.Taking the analytical model with the most tightened contact model as the base model ("MPC (w/ base sim.)"),we further augment it with a general state-of-the-art contact smoothing for robot manipulation [59] and create "MPC (w/ base sim.w/ soften)".Details of baseline models are deferred to the Supp.</p>
<p>Training and evaluation settings.The physics curriculum is composed of three stages.In the first stage, the parameter α varies from 0.1 to 0.0 and the contact model stiffness is relaxed to the softest level.In the second stage, α is fixed and the contact model stiffness varies from the softest version to the most tightened level gradually through eight stages.Details w.r.t.parameter settings are deferred to the Supp.In the first two stages, we alternately optimize the trajectory A and parameters S. In each optimization iteration, the A is optimized for 100 steps while S is optimized for 1000 steps.In the third stage, A and ψ are optimized for 256 steps in each iteration.For time-stepping, dt is set to 5 × 10 −4 in the parameterized and the target simulators.The articulated multi-body is controlled by joint motors and root velocities in the parameterized quasi-physical simulator while PD control [61] is leveraged in the target simulators.</p>
<p>Dexterous Manipulating Tracking</p>
<p>We conducted thorough experiments in two widely used simulators [13,38].We treat them as realistic simulated physical environments with high fidelity and wish to track the manipulation in them.In summary, we can control a dexterous hand to complete a wide range of the manipulation tracking tasks with nontrivial object movements and changing contacts.As presented in Table 1, we can achieve significantly higher success rates calculated under three thresholds than the best-performed baseline in both tested simulators.Fig. 4 showcases qualitative examples and comparisons.Please check out our website and video for animated results.Complex manipulations.For examples shown in Fig. 4, we can complete the tracking task on examples with large object re-orientations and complicated tool-using (Fig. (a,b,c)).However, DGrasp-Tracking fails to establish sufficient contact for correctly manipulating the object.In more detail, in Fig. 4(b), the bunny gradually bounced out from its hand in Bullet, while our method does not suffer from this difficulty.In Fig. 4(c), the spoon can be successfully picked up and waved back-and-forth in our method, while DGrasp-Tracking loses the track right from the start.Bimanual manipulations.We are also capable of tracking bimanual manipulations.As shown in the example in Fig. 4(d), where two hands collaborate to relocate the object, DGrasp-Tracking fails to accurately track the object, while our method significantly outperforms it.</p>
<p>Further Analysis and Discussions</p>
<p>Could model-free methods benefit from the physics curriculum?In addition to the demonstrated merits of our quasi-physical simulators, we further explore whether model-free strategies can benefit from them.We introduce the "DGrasp-Tracking (w/ Curriculum)" method and compare its performance with the original DGrasp-Tracking model.As shown in Table 1 and the visual comparisons in Fig. 6, the DGrasp-Tracking model indeed benefits from a well-designed physics curriculum.For example, as illustrated in Fig. 6, the curriculum can significantly improve its performance, enabling it to nearly complete challenging tracking tasks where the original version struggles.We conduct a wide range of ablation studies to validate the effectiveness of some of our crucial designs, including the parameterized analytical physics model, the parameterized residual physics, the role of the local force network, the necessity of introducing a physics curriculum into the optimization, and how the design on the curriculum stages affects the result.Parameterized analytical model.The skeleton of the quasi-physical simulator is an analytical physics model.The intuition is that the parameterized simulator with such physical bias can be optimized towards a realistic simulator more easily than training pure neural networks for approximating.To validate this, we ablate the analytical model and use neural networks to approximate physics in Bullet directly (denoted as "Ours w/o Analytical Sim.").The quantitative (Table 2) and qualitative (Fig. 5) results indicate that the physical biases brought by the analytical model could help the parameterized simulator to learn better physics in the contact-rich scenario.For instance, in the example demonstrated in Fig. 5, the ablated version fails to guide the robot hand to successfully pinch the object in the second figure.Parameterized residual physics.To validate the necessity of introducing residual force networks to close the gap between the physics modeled in the parameterized analytical simulator and that of a realistic simulator, we ablate the parameterized force network and create a version named "Ours w/o Residual Physics".Table 2 demonstrated its role in enabling the parameterized simulator to approximate realistic physics models.</p>
<p>Ablation Study</p>
<p>Local residual force network.To adequately leverage state and contactrelated information for predicting residual contact forces, we propose to use two types of networks: 1) a local force network for per contact pair residual forces and 2) a global network for additionally compensating.The local network is introduced for fine-grained approximation.We ablate this design and compare the result with our full model to validate this (see Fig. 5 and Table 1).</p>
<p>Optimizing through an analytical physics curriculum.We further investigate the effectiveness of the analytical curriculum design and how its design influences the result.Specifically, we create two ablated versions: 1) "Ours w/o Curriculum", where the optimization starts directly from the parameterized analytical model with articulated rigid constraints tightened and the stiffest contact model, and 2) "Ours w/ Curriculum II", where we move some stages out from the original curriculum.Table 2 and Fig. 5 demonstrate that both the curriculum and the optimization path will affect the model's performance.</p>
<p>Conclusion and Limitations</p>
<p>In this work, we investigate creating better simulators for solving complex robotic tasks involving complicated dynamics where the previous best-performed optimization strategy fails.We present a family of parameterized quasi-physical simulators that can be both programmed to relax various constraints for task optimization and can be tailored to approximate realistic physics.We tackle the difficult manipulation transfer task via a physics curriculum.Limitations.The method is limited by the relatively simple spring-damper model for contact constraint relaxation.Introducing delicate analytical contact models to parameterized simulators is an interesting research direction.Overview.The appendix contains a list of supplementary materials to support the main paper.</p>
<p>-Additional Technical Explanations (Section A).We provide additional explanations to complement the main paper.</p>
<p>• Dexterous Manipulation Transfer (Section A.1).We provide a more formal task definition, outlining its objectives and the involved functions.• Parameterized Quasi-Physical Simulators (Section A.2). Detailed explanations of the parameterized point set dynamics, including its full dynamic equations, and the parameterized residual physics, covering network designs, features, input, and output details. • Dexterous Manipulation Transfer via a Physics Curriculum (Section A.3).</p>
<p>We include comprehensive illustrations of the transfer process based on point sets, the iterative optimization procedure for approximating realistic dynamics, and detailed MPC procedure.-Additional Experiments (Section B).We present further experimental results to demonstrate the effectiveness of our method, along with discussions, analyses, additional comparisons, a user study and insights into failure cases and limitations.</p>
<p>• Discussions on Sim-to-Real and Real Robot Experiments (Section B.1).</p>
<p>Additional discussions on sim-to-real and real robot experiments.• Transferred Dexterous Manipulations (Section B.2).Additional qualitative results showcasing intricate manipulations to highlight our method's capability.</p>
<p>• Further Discussions and Analysis (Section B.3).We delve deeper into the role of MPC in our method, the question of does the residual physics module really compensates for the estimation other than taking the main role, the intermediate optimization processes in the quasi-physical simulator curriculum, and experiments on a different simulated robot hand whose morphology is significantly different from the human hand to demonstrate our method's capability in such cases.• Additional Comparisons (Section B.4).In addition to comparisons with previous Reinforcement Learning (RL) methods, we compare approaches that incorporate human demonstrations into policy learning for acquiring skills.• Failure Cases (Section B.5). Analysis of failure cases to gain insights into limitations and areas for improvement.• User Study (Sec.B.6).We additionally include a user study to further assess effectiveness of our method.-Experimental Details (Section C).We illustrate details of datasets, metrics, baselines, models, evaluation settings, and running time as well as the complexity analysis.-Potential Negative Societal Impact (Section D).We discuss the potential negative social impacts of the work.</p>
<p>We include a website and a video to introduce our work.The website and the video contain animated transferred dexterous manipulations.We highly recommend exploring these resources for an intuitive understanding of the task, difficulties, the effectiveness of our model, and its superiority over prior approaches.We include source code in the supplemental material.We will publicly release the code and data upon acceptance of the paper.</p>
<p>A Additional Technical Explanations</p>
<p>We include a figure providing a comprehensive overview of the method (see Fig. 7).</p>
<p>Transferring Human Demonstration via Point Set Dynamics Optimizing Through a Contact Curriculum</p>
<p>A.1 Dexterous Manipulation Transfer</p>
<p>Given a human manipulation demonstration, composed of a human hand mesh trajectory and an object pose trajectory {H = {H n } N n=1 , O = {O n } N n=1 } with N frames, the goal is transferring the demonstration to a dexterous robot hand in simulation.Formally, we aim to optimize a control trajectory A that drives the dexterous hand to manipulate the object in a realistic simulated environment so that the resulting hand trajectory Ĥ = { Ĥn } N n=1 and the object trajectory Ô = { Ôn } N n=1 are close to the reference motion {H, O}.Since the object properties and the system parameters are unknown from the kinematics-only trajectory, we estimate such parameters, denoted as set S, along with the hand control optimization.</p>
<p>Optimization objective.The task aims at optimizing a hand control trajectory A so that the resulting hand trajectory Ĥ and the object trajectory Ô are close to the reference motions {H, O}.Formally, the objective is:
minimize A,S w o f O (O, Ô) + w h f H (H, Ĥ),(5)
where w o and w h are object tracking weight and the hand tracking weight respectively, f O measures the difference between two object pose trajectories, and f H calculates the difference between two hand trajectory.Specifically,
f O (O, Ô) = 1 N N n=1 ((1 − q n • qn ) + ∥t n − tn ∥)(6)f H (H, Ĥ) = 1 N N n=1 ∥P h n − P r n ∥,(7)
where q n is the orientation of the n-th frame reference object pose, represented in quaternion, t n ∈ R 3 is the translation of the n-th frame reference object pose, qn and tn are the quaternion and the translation of the n-th frame estimated object pose, P h n is the reference human hand keypoint at the n-th frame, and P r n is the estimated robot hand keypoint at the n-th frame correspondingly.Keypoints consist of five fingertips and three points on the hand wrist.We manually defined them (Fig. 8).Weights w o and w h are set to 1.0, 1.0 in our method.</p>
<p>A.2 Parameterized Quasi-Physical Simulators</p>
<p>Parameterized point set dynamics.Each point p i in the point set Q is treated as a mass point with a finite mass m i and infinitesimal volume.The action space of the point set is composed of the joint forces u ∈ R nr in the reduced coordinate system, alongside a 3 degrees of freedom free force a i ∈ R 3 applied to each point p i ∈ Q.A point is considered to be "attached" to the body it was sampled from and can undergo articulated transformations, as illustrated in the example shown in Figure 9.The dynamics of the point set encompass articulated multi-body dynamics [18,35], along with the mass point dynamics of each individual point p i .Specifically,
M r qr = fr + (1 − α)J T mr f m + f QV V + u,(8)m i ẍi = J i u + αf i + α, ∀p i ∈ Q,(9)
where M r ∈ R nr×nr is the generalized inertia matrix in reduced coordinates, n r is the number of freedom of the articulated object, q r ∈ R nr is the reduced state vector of the articulated object, fr is the reduced force vector generated by joint-space such as joint damping and stiffness, J mr is the Jacobian mapping generalized velocity qr to its maximal coordinate counterpart qm , f m is the maximal wrench vector including force and torque generated in maximal coordinate system, f QV V is the quadratic velocity vector, u denotes the generalized joint force, J i represents the Jacobian mapping from the generalized velocity to the point velocity ẋi , f i accounts for external forces acting on p i , and a i ∈ R 3 represents the actuation force applied to the point p i .Consequently, the point set is controlled by a shared control in the reduced coordinate space u and per-point actuation force a i .</p>
<p>(a) Initial state (b) Transformed</p>
<p>A point in the point set Fig. 9: A point in the point set is regarded as "attached" to the body it sampled from and is affected by joint actions accordingly.</p>
<p>Parameterized residual physics.We introduce two residual contact force networks to compensate for the inherent limitations of the spring-damper based contact modeling.For detailed residual contact force prediction, we introduce a local contact network f ψ local that utilizes contact information identified in the parameterized contact model and predicts residual forces between each contact pair.For each point pair in contact (p, p o ), the local contact region is composed of N l c object surface points and N l c hand surface points.For the contact point in the object surface p o , we identify a region which contains object surface points whose distance to point p o is not larger than a threshold d l thres = 0.05 (5cm) (point p o is not included in the region).After that, N l c − 1 points are sampled from such points via farthest point sampling.These points, together with p o are taken as the object local contact surface points.N l c hand points are sampled in the same way.We set N l c to 100 in experiments.After that, the local contact information consists of the geometry of the local contact region
P l c ∈ R 2N l c ×3 , per-point velocity V l c ∈ R 2N l c ×3
, and per-object point normal N l c ∈ R N l c ×3 .A PointNet is used to encode the contact region feature.The feature of each point is composed of the point type embedding vector (128 dimension), point position, point velocity, point normal (all zeros for hand points).The hidden dimensions are [128,256,512,1024].After that, we calculate the global feature via a 'maxpool' operation.Then the global features is fed into the contact force prediction module for local residual contact force prediction.The prediction network is an MLP with hidden dimensions [512,256,128].ReLU is leveraged as the activation layer.</p>
<p>To address discrepancies in contact region identification between the parameterized contact model and real contact region, we also incorporate a global residual network f ψ global that predicts residual forces and torques applied directly to the object's center of mass.To identify a global contact region, we adopt a similar way that first identifies a region on the object, containing object surface points whose distance to the nearest object contact point are smaller than the global contact distance threshold d g thres = 0.1 (10cm).After that, global contact region points are sampled for both the object and the hand in the same way as sampling the local contact region points described above.The number of global contact points on for the object and the hand is N g c = 500.Subsequently, the global contact region feature is encoded from the global contact region in the same way as does for local contact region feature.Then, the global contact feature is fed to a prediction network for predicting residual force and residual torque.The network architecture is the same as that for local residual force, but with a different output dimension (3 for force, 3 for torque, and 6 dimension in total).</p>
<p>A.3 Dexterous Manipulation Transfer via a Physics Curriculum</p>
<p>Transferring human demonstration via point set dynamics.The articulated rigid constraints are relaxed initially to facilitate robust manipulation transfer between two morphologically different robot hands and to overcome noise in the kinematic trajectory.After we have optimized the control trajectory of the point set constructed from the dynamic MANO hand [12], the next goal is optimizing the control trajectory of the point set constructed from the simulated robot hand.Reliable correspondences between points are required to complete the transfer.Therefore, we first optimize the kinematics-only trajectory of the simulated robot hand based on coarse correspondences defined on keypoints (Fig. 8).The objective is to track the MANO hand trajectory.After that, we define single directional point-point correspondence from the point set of the MANO hand to the point set of the simulated robot hand via the nearest neighbor.That is, for each point in the point set of the MANO hand, we find its nearest point in the point set of the simulated robot hand as its correspondence.After that, the hand tracking objective between the point set of the MANO hand and that of the simulated robot hand becomes the average distance between point-point in correspondence.Subsequently, the control trajectory of the point set is optimized so that the manipulated object pose trajectory can track the reference object pose trajectory, and the trajectory of the simulated robot hand's point set can track the trajectory of the MANO hand's point set.The control trajectory of the point set is first initialized via the kinematic trajectory of the point set via differentiable forward dynamics and optimization.Optimizing towards a realistic physical environment.When transferring to a realistic physical environment, we iteratively optimize the control trajectory A and the parameterized simulator.In more detail, in each iteration, the following steps are executed:</p>
<p>-Sample the replay buffer B from the interested realistic simulated environment.</p>
<p>-Optimize the quasi-physical simulator to approximate realistic dynamics by ensuring that the simulated trajectory closely tracks the trajectory stored in the replay buffer.-Optimize the control trajectory A to accomplish the manipulation task within the quasi-physical simulator.</p>
<p>Tracking via closed-loop MPC.After completing the optimization, the final control trajectory is yielded by model predictive control (MPC) [22] based on the optimized parameterized simulator and the hand trajectory A. Specifically, in each step n, the current A n and the following controls in several subsequent frames {A n+1 , ..., A n+q−1 } are optimized to reduce the tracking error.Denote the simulated object pose trajectory as Ôq n = { Ôn+1 , ..., Ôn+q }, the corresponding reference object pose trajectory as O q n = {O n+1 , ..., O n+q }, the simulated hand trajectory as Ĥq n = { Ĥn+1 , ..., Ĥn+q } with the corresponding keypoint trajectory {P r n+1 , ..., P r n+1 } and reference hand keypoint trajectory {P h n+1 , ..., P h n+1 } the objective at each step n is as follows:
minimize A w o f O ( Ôq n , O q n ) + w h f H ({P r n+1 , ..., P r n+1 }, {P h n+1 , ..., P h n+1 }). (10)
We update the control trajectory to minimize the objective via 10 steps gradient descent with a learning rate 10 −4 .</p>
<p>B Additional Experiments</p>
<p>In this section, we present additional experimental results that delve into more qualitative results on challenging cases (see Section B.2), further analysis and discussions (see Section B.3), additional comparisons (see Section B.4), failure case analysis (see Section B.5), and a user study (see Section B.6).Initially, we present additional experimental results achieved by our approach to further demonstrate its effectiveness.Subsequently, we delve into further discussions, including the role of MPC in our method, further investigations in the residual physics module, the intermediate optimization processes in the quasi-physical simulator curriculum, and experiments conducted on a different simulated robot hand that suffers from a significant morphology difference from the human hand.</p>
<p>Then we present additional comparisons to the literature where human demonstrations are incorporated into policy learning.After that, we discuss failure cases and analyze our limitations.At last, we present a toy user study as an additional evaluation.Sim-to-real challenges and possible solutions.Sim-to-real gaps primarily stem from differences in physics and system parameters between simulators and the real world.A straightforward strategy is "direct sim-to-real", i.e., optimizing in a realistic simulator and directly transferring results to a real robot.A more promising way is to train the quasi-physical simulator using real robot trajectories, acquired using offline policies, to approximate the real physics, followed by planning within it.Another approach is iterative quasi-physical simulator optimization and real robot executions.It can possibly learn real physics better but is expensive and faces safety issues.Real robot experiments.Due to the high cost of Shadow hand hardware, we conducted experiments on a real Allegro hand and 3D printed objects to demonstrate real robot effectiveness.We adopt the "direct sim-to-real" for its simplicity, which transfers Allegro trajectories optimized in PyBullet to the real robot.We compared our method with DGrasp-Tracking on 12 well-tracked trajectories in the simulator, some with complex contacts and large object movements.Our method succeeded in 8 out of 12 trajectories without dropping the object (Fig. 10), while the baseline only succeeded in 4.This suggests the poten-tial value of our method for real robot applications.Using advanced strategies proposed above may further improve the performance.</p>
<p>B.1 Discussions on Sim-to-Real and Real Robot Experiments</p>
<p>B.2 Transferred Dexterous Manipulations</p>
<p>Figure 11 showcases supplementary experimental results obtained through our method.We highly encourage readers to explore our website and view the accompanying supplementary video for animated demonstrations.</p>
<p>B.3 Further Discussions and Analysis</p>
<p>Robustness of MPC.Fig. 12 shows an example demonstrating tracking robustness.In this challenging example where rich contacts between fingers and the palm with the mouse are frequently established and broken, the control sequence optimized in an open-loop manner struggles with keep contacting the mouse, and the tracking is lost finally.However, with the optimized model, the trajectories produced by MPC can successfully maintain enough contact with the object and track the sequence naturally.Role of residual physics in quasi-physical simulators.We evaluate the role of the residual physics on a small subset of our data from the GRAB dataset.We assess the impact of residual physics on a limited subset of our data from the GRAB dataset.This subset comprises 60 ten-step transitions involving manipulation sequences with objects such as bunny, mouse, stapler, pyramid, cylinder, flashlight, watch, waterbottle, hammer, and clockarlam.</p>
<p>To investigate whether the residual physics compensates for prediction while the analytical simulation remains predominant, we utilize two types of models: one comprising only the analytical part, and the other incorporating both the analytical part and the residual physics network.These models are tasked with predicting the object rotation and translation for each ten-step transition based on the object's initial state and hand action sequence.Let R denote the object rotation predicted by the analytical part, and R tot represent the rotation predicted by the analytical part with the residual model.Similarly, let t and t tot denote the object translation predicted by the analytical part and the analytical part with the residual model, respectively.Therefore, the residual rotation is calculated as R res = R tot R T , and the residual translation is calculated as t res = t tot − R res t.Let V init denote the initial object vertices, V represent the transformed vertices, and V tot denote the transformed vertices predicted by the analytical part with the residual model.The average per-vertex position difference from the transformed object to the initial object is calculated as
p diff = 1 N v ∥V − V init ∥.(11)
Similarly, the average per-vertex position difference from the transformed object predicted by the total model to the initial object is computed as
p tot diff = 1 N v ∥V tot − V init ∥.(12)
X. Liu et al.Finally, the average per-vertex position difference from the transformed object predicted by the total model to the object predicted by the analytical part is calculated as:
p res diff = 1 N v ∥V tot − V∥.(13)
For each 10-step transition, we calculate the relative quantities of the three types predicted by the residual physics, including the object rotation (measured by angles) angle(Rres) angle(Rtot) , object translation tres ttot , and the object per-point difference p res diff p diff , compared to the overall predicted values by the quasi-physical simulator.</p>
<p>As depicted in the bar chart shown in Figure 13, it is evident that the analytical model plays the primary role in predicting state transitions, while the information predicted by the residual module compensates for the prediction.A visual example is depicted in Figure 13.The bunny undergoes rotation by a certain angle in the 10-step transition.The predicted result by the analytical part only is close to the ground-truth transformed object already.This alignment can be readily observed by examining the angle between the two ears of the bunny and the vertical/horizontal line, respectively.The residual physics compensate for unmodeled effects.Hence the object predicted by the full model is closer to the ground-truth transition observed in Bullet.</p>
<p>The optimization process in the quasi-physical simulator curriculum.</p>
<p>The quasi-physical simulator curriculum initially relaxes various constraints within the simulator to alleviate the optimization problem.Subsequently, the physics constraints are gradually tightened to enable the optimization to converge towards a solution in a more realistic physics model.Fig. 15 illustrates the intermediate optimization process.</p>
<p>During the first optimization iteration, articulated rigid constraints are relaxed, and the articulated rigid dexterous hand is represented and driven as a point set.Then, articulated constraints are imposed.The optimization continues in the simulator with an increasing contact stiffness (the following three lines in Fig. 15).</p>
<p>Since the articulated dexterous hand is initially represented as a point set, comprised of points sampled from the ambient space of the surface mesh, contact between the hand and the object may not necessarily be established immediately.This is because contact can occur between points that are distant from each other, and these points can still act as manipulators.However, even with the articulated constraints removed during the initial optimization stages, the optimization process can still be effectively solved due to the softness of the contact model at the beginning.</p>
<p>As the optimization progresses, we gradually transition towards the final quasi-physical simulator with articulated rigid constraints and the stiffest contact model.In Fig. 15, we use orange red color to represent the "activated manipulators" -surface points where contact can be established between them and the object.Transferred to a robot hand with a significant morphological difference from the human hand.Utilizing the point set representation, we can facilitate the transfer of manipulation skills to a morphologically different hand.We conducted additional experiments aimed at transferring manipulation from a human hand to a morphologically different robot hand obtained from Diff-Hand [72].As shown in Fig. 18 (c), the thumb of the dexterous hand is obviously shorter than the human hand.Intuitively, completing manipulations using this hand is difficult.Directly transferring the manipulation via sparse correspondences defined between such two hands (e.g., finger and wrist correspondences as we have defined between the Shadow hand and the human hand (Fig. 8)) is not sufficient, leading to missing contacts and unwanted penetrations shown in Fig. 16.However, as shown in Fig. 17, our method can still effectively control it to complete the box rotation manipulation.Experiments are conducted in the last quasi-physical simulator from the curriculum.</p>
<p>B.4 Additional Comparisons</p>
<p>The main paper includes comparisons with both model-based and model-free approaches for solving the manipulation transfer task.For model-free methods, we compare with the DGrasp series models.The DGrasp series employs a carefully designed RL-based method for grasping, incorporating well-devised rewards containing position-to-goal information and contact information.Notably, DGrasp's methodology serves as the foundation for their recent work, ArtiGrasp [76].ArtiGrasp extends the manipulation capabilities to articulated objects and introduces learning techniques such as a gravity curriculum to han- dle complex relocate-and-articulate task settings.Given the meticulous reward design, stage-wise learning approach, and subsequent improvements, we consider DGrasp as a robust RL-based baseline.However, DGrasp is not explicitly designed for the tracking task, as it relies solely on sparse reference frames obtained from human demonstrations.Therefore, we introduce the improved version of DGrasp-Tracking as our baseline.</p>
<p>Many works have explored the combination of RL and imitation learning to leverage human demonstrations for learning robotic manipulation skills [6,8,9,25,47,49,56].In these approaches, human demonstrations are utilized either as dense information for the robot to imitate or as sparse reward signals, such as grasp affordances [6].However, these methods often struggle with the imbalance between human-likeness and task completion, leading to biases towards RLpreferred trajectories.</p>
<p>For the sake of experimental completeness and to showcase the effectiveness of our strategy in contrast to this trend, we compare our approach with DexMV [49].Among its follow-ups and related works [5,6,47], DexMV shares the most similar setting to ours.In DexMV, human demonstrations provide dense references to shape the reward space for their RL algorithm.Furthermore, DexMV is openly available, making it conducive for comparative evaluation 1 .</p>
<p>We compare our method with DexMV (DAPG) on a subset, containing manipulation sequences from the GRAB dataset, in the Bullet simulator.presents the average quantitative results over the tested sequences.Fig. 19 further leverages some examples to give an intuitive evaluation.In the challenging example shown in Fig. 19 (a) with rich and changing contacts, our method can perform well.However, DexMv struggles to give satisfactory results.In the example shown in Fig. 19 (b), we can track the object in a human-like way.However, though DexMV can complete the object tracking task to some extent, the resulting hand trajectory significantly deviates from the human hand demonstration.</p>
<p>B.5 Failure Cases</p>
<p>In this section, we delve into the failure cases encountered by our method despite its effectiveness on many sequences.Our method may falter in controlling a simulated robot hand to track manipulation demonstrations in the following scenarios:</p>
<p>-Manipulations requiring highly precise control, such as threading fingers through a ring for future actions (Fig. 20 (a)); -Interactions with a nearly two-dimensional, very thin object (Fig. 20 (b)).</p>
<p>As depicted in Fig. 20  a significant challenge.Presently, our method struggles to provide satisfactory solutions for such cases, possibly due to morphological disparities between the human hand and the robot hand.These differences make it difficult to replicate human-like actions with the robot hand.Additionally, we encounter difficulties achieving desirable outcomes when interacting with extremely thin objects, especially when one dimension of the object scales down to near-zero, as illustrated in Fig. 20 (b).Such challenging object shapes make it challenging to devise an effective lifting strategy.</p>
<p>B.6 User Study</p>
<p>We conduct a supplementary user study to complement the quantitative and qualitative evaluations presented in the main paper, website, and supplementary video, aiming to comprehensively assess and compare the quality of our transferred manipulations with those of the baseline method, DGrasp-Tracking.</p>
<p>Our user study is hosted on a website, where the results of our method and DGrasp-Tracking on 10 sequences are presented in a randomly permuted order.Ten participants, regardless of their familiarity with the task or expertise in computer science, are asked to rate each clip on a scale from 1 to 5 to indicate their preferences.Specifically, "1" indicates a significant difference between the transferred motion and the reference motion, "3" represents the manipulation task is completed to some extent but the hand motion deviates obviously from the reference motion, "5" indicates a delicately controlled motion with a good task completeness and human-likeness.Intermediate values of "2" and "4" represent in-between assessments.</p>
<p>For each clip, we calculate the average score achieved by our method and DGrasp-Tracking.The average and median scores across all clips are summarized in Table 4.The results show the significant superiority of our method over the baseline method.</p>
<p>C Experimental Details</p>
<p>C.1 Datasets</p>
<p>Evaluation data comes from three datasets, namely GRAB [60], containing single-hand interactions with daily objects, TACO [37], containing humans manipulating tools, and ARCTIC [17] with bimanual manipulations.We'll publicly release the dataset for future research.GRAB [60].We randomly randomly sample a manipulation trajectory for each object.If its manipulation is extremely simple, we additionally sample one trajectory for it.The object is not considered if its corresponding manipulation is bimanual such as binoculars, involves other body parts such as bowl, or with detailed part movements such as the game controller.Finally, manipulations with the following objects are included in our dataset: mouse, flashlight, stapler, hammer, torus, stanfordbunny, pyramid, cylinder, airplane, train, mouse (resampled), cube, watch, waterbottle, phone, sphere, mug, alarmclock, knife, fryingpan, cup, duck, elephant, lightbulb, scissors, toothbrush, toothpaste.</p>
<p>For each sequence, we take the first approach-action clip with the length of 60 frames.The number of manipulation sequences from GRAB is 27.TACO [37].For TACO, we acquire data by contacting authors.We randomly select one sequence for each right-hand tool object, a few snapshots are presented in Fig. 21.Sequences with very low quality like erroneous object motions are excluded.For each trajectory, we take the first approach-action clip with the maximal length set to 150 frames.14 trajectories in total are selected finally.ARCTIC [17].For ARCTIC, we randomly select one sequence for each object from its available manipulation trajectories, resulting in 10 sequences in total.</p>
<p>For each trajectory, we take the first approach-action clip with the maximal length set to 150 frames.The object names and the corresponding subject indexes are summarized in Table 5. Please note that subject s08 and s09 only have "use" actions.Besides, some "grab" sequences are missing in a specific subject's manipulation sequences.For instance, both s01 and s06 do not have "grab" manipulations with box.Fig. 22: Grasping frame.We leverage a simple strategy to find the first grasping frame from the sequence.A valid grasping frame should have at least two contact points.The contact force directions should be able to stabilize the object, i.e., there exists a solution for their magnitudes so that zero force and zero torque are applied to the object.</p>
<p>C.2 Baseline</p>
<p>DGrasp-Base [12].We use the official code provided by authors2 .We adapt the codebase to two simulated environments used in our evaluation, Bullet [13] and Isaac Gym [38].Using DGrasp's method to complete the tracking task requires us to define reference grasping frames.We leverage a heuristic method and take the first grasp frame as the reference frame, illustrated in Fig. 22.Specifically, the first grasp is the first frame in the sequence satisfying the following conditions: 1) at least two contacts are detected between the hand and the object, 2) all contact force directions can form a force closure, that is there exists a solution for their magnitudes so that the object is stable under such contact forces.Having defined the reference grasping frame, we train the manipulation policy using the original DGrasp's method.Initially, only the grasping policy is activated.The grasping module guides the hand towards the object to find a stable grasp according to the defined reference frame.After that, the grasping policy and the control policy cooperate to move the object to the final 6D pose.Our method can find a successful policy on DGrasp's "021_bleach_dexycb" example in two simulated environments using the dynamic MANO hand [12].DGrasp-Tracking (improved from DGrasp [12]).We set a series of reference frames from the sequence, where every two reference frames are separated by 10 frames.We use the grasping policy to guide the hand toward each reference frame.</p>
<p>DGrasp-Tracking (w/ curric.).We gradually train DGrasp-Tracking in each of the simulators from the quasi-physical simulators, finally in the tested simulator.The curriculum setting is the same as that listed in Table 6.ControlVAE [74].We adapt the official release3 to the manipulation scenario.The world model approximates state transitions.It takes the current state, composed of the articulated dexterous robot hand joint state (including the first 6-DoF global rotations and translations), the object state, including the 4-dim object orientation represented as a quaternion, and the 3-DoF object translation, and control signals, including the velocity and position controls for each hand joint, as input.It outputs the predicted delta hand joint states and the predicted object delta rotations (3-DoF) as well as the delta translations (3-DoF).</p>
<p>Following ControlVAE [74], the world model is an MLP.We increase the network depth, resulting in an MLP with 9 layers in total.The first hidden dimension is 256, followed by 6 layers with the hidden dimension of 512, 1 layer with the hidden dimension of 256, and the output layer.ReLU is used as the activation function between each hidden layer.The policy network takes the current state, including the hand joint state, object orientation as well as object rotation, and the target state, including the target hand joint states, target object orientation as well as the target object rotation as input.It predicts control signals for the articulated hand, including the position and velocity controls for each hand joint.The policy network is an MLP.The number of layers and the hidden dimension settings are the same as the world model.Length of the replay buffer</p>
<p>C.3 Experimental Settings</p>
<p>The quasi-physical simulator curriculum.By default, the curriculum is composed of ten parameterized quasi-physical simulators.We summarize their parameter settings in Table 6.The contact distance threshold d c , contact spring stiffness k n , friction spring stiffness k f , and contact damping coefficient k d are set empirically.</p>
<p>For the ablated version ("Ours w/ Curriculum II" in the ablation study), we remove some stages from the original curriculum.The setting is summarized in Table 7. Quasi-physical simulators.We use Python to implement each component of the simulator and the simulation processes, including the articulated rigid dynamics, the point set dynamics, the spring-damper contact modeling, and the residual physics modules.Semi-implicit time-stepping is leveraged.Time stepping is set to 5×10 −4 with 100 substeps per frame.In this way, we can easily introduce neural network components into the simulator.Besides, one can easily integrate it into a deep learning framework for further applications.Moreover, we can calculate gradients automatically taking advantage of the auto-grading feature of the framework.The overall efficiency, though has a large improvement space, is acceptable in our task.Converting meshes to SDFs.We use Mesh2SDF [66] in this process.Parameters set S. The parameter set S includes object properties, i.e., object mass and object inertia, and some unknown system parameters, i.e., linear velocity sampling coefficient and angular velocity damping coefficient.For the friction coefficient, we set it to a fixed value, i.e., µ = 10.The value is set under the consideration of the important role friction forces play in the manipulation task.Controlling the hand in Bullet and Isaac Gym.In our quasi-physical simulator, the hand is controlled via joint forces and root linear and angular velocities.In Bullet and Isaac Gym, people commonly use PD controls, which are also recommended officially [13].Therefore, to convert controls in joint forces and root velocities to PD controls in the them, we additionally add a control transformation module.</p>
<p>For each timestep 1 ≤ n ≤ N − 1, it takes root positions at the timestep n and n + 1, joint states, velocities, joint forces, and the object state at step n and outputs the residual position and velocity controls at step n.The predicted residual PD controls added to the root positions, root velocities (calculated via finite differences), joint states, and velocities are treated as PD controls in the target simulator.The control transformation module is composed of a hand point feature extraction layer, an object feature extraction layer, and a prediction layer.The current hand and object geometry is firstly encoded in latent features.Subsequently, the original joint control related information and the encoded latent features are fed into an MLP for residual position and velocity control prediction.The feature extraction layer is a 3-layer MLP with hidden dimensions [128,128,128] and ReLU as the activation layer.After per-point feature extraction, a maxpool function operates on point features to extract global features for the hand and the object.Then the global features of the hand and the object are concatenated together and passed through a two-layer MLP with hidden dimension 128 and the output dimension 128 as well.The output feature is then concatenated with the object control related information and passed through an MLP for the residual control prediction.The prediction network is a 3-layer MLP with hidden dimension [128,64].The control transformation module is optimized together with the residual physics module introduced in the parameterized quasi-physical simulator.World model-style training.Rollout lengths for both the trajectory optimization and the model training are set to 19.In each iterative training iteration, the trajectory is optimized for 256 steps.The residual physics module is optimized for 256 steps.The replay buffer length is 1024.Evaluation process.Our method is a multi-stage optimization-based strategy.The overall optimization process can be roughly divided into three stages, as illustrated in the following:</p>
<p>-Transferring via point dynamics.This stage involves three processes:</p>
<p>• Optimize a dynamics MANO [12] trajectory that can track the input kinematics-only trajectory; • Optimize the control trajectory for the point set of the MANO hand that can track the hand trajectory and the object trajectory; • Optimize a kinematics-only trajectory for the simulated robot hand so that it can track the kinematic hand trajectory via sparse correspondences; • Optimize the control trajectory for the point set of the simulated robot hand so that it can track the trajectory of the MANO's point set.-Optimizing through a contact curriculum.In this stage, the control trajectory of the simulated robot hand is optimized in each simulator from the curriculum.The objective is to track the hand trajectory and the object trajectory.-Transferring to a realistic simulated environment.In this stage, the quasi-physical simulator and the control trajectory for the simulated robot hand are iteratively optimized.By default, the number of iterations is set to 30,000.</p>
<p>In each optimization iteration, excluding the kinematics trajectory-only optimization, the parameter set S and the control trajectory are optimized alternately.If we cannot inherit a control trajectory from the previous stage, we first optimize the it with the parameters S either inherited from previous stages or set to default values.After that, the parameters ∫ are further refined with controls fixed.Subsequently, we continue to optimize controls based on the identified parameters.If the control trajectory can be inherited from previous stages at the beginning of the iteration, the parameters S are identified with controls fixed.Then we further refine controls with parameters fixed.Typically, the number of optimization steps for the parameters is 1000, while the number is 100 for the control trajectory.Both hand controls and parameters are optimized via gradient descent.Learning rate is set to 5×10 −4 for both control optimization and parameters identification.We use Adam optimizer.No learning rate scheduler is used.</p>
<p>In the third stage, we follow the training framework in ControlVAE [74].The optimizer is RAdam, with the learning rate 10 −4 for the quasi-physical simulator and 10 −4 for control trajectory optimization.</p>
<p>C.4 Running Time and Complexity</p>
<p>Complexity.The time complexity is related to the number of frames in the manipulation sequence and the number of optimization passes.Denote the number of frames as N and the number of total optimization passes as K, the time complexity is O(KN ).</p>
<p>Running time.Taking a sequence with 60 frames as an example, the first stage (see evaluation process stated in the previous section) costs about 7 hours in total.Using the default curriculum setting (Table 6), the second stage would cost about 22 hours.Early termination logic in each optimization iteration will shorten the time.Therefore, the actual time is per-sequence dependent.Taking transferring to the Bullet simulator as an example, the third stage takes about 20 hours to complete.Reducing the number of simulators in the curriculum or using a smaller number of iterations in the third stage can improve the time efficiency.</p>
<p>D Potential Negative Societal Impact</p>
<p>Our approach has the potential to expedite the advancement of robotic dexterous manipulation skills.However, in the future, the emergence of highly developed robots proficient in performing various tasks may lead to the replacement of certain human labor, thus potentially impacting society.</p>
<p>Fig. 1 :
1
Fig. 1: By optimizing through a quasi-physical simulator curriculum, we successfully transfer human demonstrations to dexterous robot hand simulations.We enable accurate tracking of complex manipulations with changing contacts (Fig. (a)), nontrivial object motions (Fig. (b)) and intricate tool-using (Fig. (c,d)).Besides, our physics curriculum can substantially improve a failed baseline (Fig. (e,f )).</p>
<p>Fig. 2 :
2
Fig.2: The parameterized quasi-physical simulator relaxes the articulated multi rigid body dynamics as the parameterized point set dynamics, controls the contact behavior via an unconstrained parameterized spring-damper contact model, and compensates for unmodeled effects via parameterized residual physics networks.We tackle the difficult dexterous manipulation transfer problem via a physics curriculum.</p>
<p>Wish to change the contact point from A to B Result: adjust two joint states to achieve this A B Wish to change the contact point from A to B A B Result: adjust one joint state and a few point states Articulated Multi-Body Point Set Noise in data Transfer w/o Point set Transfer w/ Point set</p>
<p>Fig. 3 :
3
Fig.3: Point Set can flexibly adjust its states, avoid overfitting to data noise, and ease the difficulty brought by the morphology difference.</p>
<p>Fig. 4 :
4
Fig. 4: Qualitative comparisons.Please refer to our website and the accompanying video for animated results.</p>
<p>Qualitative comparisons on the stapler example (b) Training loss comparisons (c) Tracking loss comparisons</p>
<p>Fig. 5 :Fig. 6 :
56
Fig. 5: (a) Qualitative comparisons between our full method and the ablated models; (b) Training loss curve comparisons; (c) Tracking loss curve comparisons.Human Demo</p>
<p>Fig. 7 :
7
Fig. 7: Detailed Method Overview.The parameterized quasi-physical simulator relaxes the articulated multi rigid body dynamics as the parameterized point set dynamics, controls the contact behavior via an unconstrained parameterized springdamper contact model, and compensates for unmodeled effects via parameterized residual physics networks.We tackle the difficult dexterous manipulation transfer problem via a physics curriculum.</p>
<p>(a) Shadow hand with keypoints [front view] [back view] (b) MANO hand with keypoints [front view] [back view]</p>
<p>Fig. 8 :
8
Fig. 8: Hands with keypoints (keypoints are drawn as large pink and blue purple points).</p>
<p>Fig. 10 :
10
Fig. 10: Qualitative results on a real Allegro hand.Please visit our website for animated demonstrations.</p>
<p>Fig. 11 :Fig. 12 :
1112
Fig. 11: Transferred manipulations.We provide additional examples to demonstrate the effectiveness of our method.Our approach successfully tracks complex manipulations involving subtle object movements, such as gently shaking a brush for cleaning (Fig. (a)), employing non-trivial functional tools (Fig. (b) (c) (e)), and executing bimanual cooperation tasks (Fig. (d)).For animated demonstrations, please visit our website and refer to the accompanying video.</p>
<p>Fig. 13 :
13
Fig.13: Analysis on the residual physics module.In this 10-step transition, the transformed bunny predicted by the analytical part of the quasi-physical simulator (purple bunny) only is already close to the GT one (green bunny).The residual physics can compensate for some unmodeled effects.Hence the result (red bunny) yielded by the quasi-physical simulator with both the analytical part and the residual physics module gets closer to the observation in Bullet.</p>
<p>Fig. 14 :
14
Fig. 14: Quantitative analysis on the residual physics module.</p>
<p>TimestampFig. 15 :
15
Fig.15: Example of the optimization process in the quasi-physical simulator curriculum.Initially, both the contact constraints and the articulated rigid constraints are relaxed and the object is represented as a point set (the first line).Then the articulated rigid constraints are imposed and the contact model is gradually tightened.The optimization is solved in each of the simulators in the curriculum.We use orange red color to represent the "activated manipulators".</p>
<p>Fig. 16 :Fig. 17 :
1617
Fig. 16: Functionally implausible transferred poses via sparse correspondences defined by keypoints.</p>
<p>Table</p>
<p>3
3</p>
<p>Fig. 18 :
18
Fig. 18: Comparisons between the dynamic MANO hand (Fig. (a)) and two simulated robot hands (Fig. (b) (c)) we considered in this work.Compared to the hand shown in Fig. (c), the Shadow hand is more similar to the human hand, but still with morphology differences that cannot be ignored.For fine-grained manipulation tasks, such morphological difference poses significant challenges for transferring.The hand in Fig. (c) is featured by its extremely short thumb and four other fingers longer than the human hand.Transferring human demonstrations to this hand is therefore very difficult.Our flexible point set representation, however, can still work in this case.</p>
<p>Fig. 19 :
19
Fig. 19: Visual comparisons between our method and DexMV.We can complete the tracking in a human-like way.However, DexMV cannot fulfill this vision.Its resulting trajectory may deviate from the human demonstration obviously, as observed in both Fig.(a) and (b).Besides, it struggles with the challenging example shown in Fig.(a) with rich and changing contacts.</p>
<p>Manipulating the watch (b) Interaction with a thin plank</p>
<p>Fig. 20 :
20
Fig. 20: Failure cases analysis.Fig. (a): The hand fails to grasp the wristwatch, which requires us to control several fingers to pass through the ring of the wristwatch.Fig. (b): The hand fails to find a good strategy for lifting the thin plank.</p>
<p>Fig. 21 :
21
Fig. 21: Snapshots from the TACO dataset.</p>
<p>An invalid grasping frame (b) A valid grasping frame</p>
<p>Table 1 :
1
Quantitative evaluations and comparisons to baselines.Bold red numbers for best values and italic blue values for the second best-performed ones.
Simulator Rerr ( Bullet Method Model Free DGrasp-Base 44.24 DGrasp-Tracking 44.45 DGrasp-Tracking (w/ curric.) 33.86 Model Control-VAE 42.455.82 5.04 4.60 2.7340.55 37.56 30.47 25.2116.37 14.72 13.53 10.940/13.73/15.69 0/15.69/15.69 7.84/23.53 /37.25 0/15.68/23.53BasedMPC (w/ base sim.)32.563.6724.6210.800/15.68/31.37MPC (w/ base sim. w/ soften) 31.893.6328.2611.310/21.57/37.25Ours24.211.9724.409.8527.45/37.25/58.82Model FreeDGrasp-Base DGrasp-Tracking DGrasp-Tracking (w/ curric,)36.41 44.71 38.754.56 5.57 5.1350.97 41.53 40.0918.78 16.72 16.260/7.84 /7.84 0/0/7.84 0/23.53 /31.37Isaac GymModel BasedControl-VAE MPC (w/ base sim.) MPC (w/ base sim. w/ soften) 36.40 35.40 37.234.61 4.73 4.4627.63 23.19 23.2713.17 9.75 10.340/13.73/29.41 0/15.69/31.37 0/9.80/23.53Ours25.972.0825.3310.3121.57/43.14/56.86
• , ↓) Terr (cm, ↓) MPJPE (mm, ↓) CD (mm, ↓) Success Rate (%, ↑)</p>
<p>Table 2 :
2
Ablation studies.Bold red numbers for best values and italic blue values for the second best-performed ones.The simulation environment is Bullet.
Ours w/o Analytical Sim.44.274.3929.8412.910/13.73/25.49Ours w/o Residual Physics 33.693.8126.5710.345.88/23.53/41.18Ours w/o Local Force NN35.982.9032.8712.440/19.61/35.29Ours w/o Curriculum42.404.8732.6113.370/17.64/29.41Ours w/ Curriculum II29.582.3331.6110.2911.76 /27.45 /50.98Ours24.211.9724.409.8527.45/37.25/58.82
MethodRerr ( • , ↓) Terr (cm, ↓) MPJPE (mm, ↓) CD (mm, ↓) Success Rate (%, ↑)</p>
<p>31.Lan, L., Yang, Y., Kaufman, D., Yao, J., Li, M., Jiang, C.: Medial ipc: accelerated incremental potential contact with medial elastics.ACM Transactions on Graphics 40(4) (2021) 4 32.Li, M., Ferguson, Z., Schneider, T., Langlois, T.R., Zorin, D., Panozzo, D., Jiang, C., Kaufman, D.M.: Incremental potential contact: intersection-and inversion-free, large-deformation dynamics.ACM Trans.Graph.39(4),49(2020) 4 33.Liao, S.: On the homotopy analysis method for nonlinear problems.Applied mathematics and computation 147(2), 499-513 (2004) 2 34.Lin, X., Yang, Z., Zhang, X.,Zhang, Q.: Continuation path learning for homotopy optimization (2023) 2 35.Liu, C.K., Jain, S.: A quick tutorial on multibody dynamics.Online tutorial, June p.7 (2012) 6, 23 36.Liu, X., Pathak, D., Kitani, K.M.: Herd: Continuous human-to-robot evolution for learning from human demonstration.arXiv preprint arXiv:2212.04359(2022) 2, 4 37. Liu, Y., Yang, H., Si, X., Liu, L., Li, Z., Zhang, Y., Liu, Y., Yi, L.: Taco: Benchmarking generalizable bimanual tool-action-object understanding.arXiv preprint arXiv:2401.08399(2024) 10, 35, 36 38.Makoviychuk, V., Wawrzyniak, L., Guo, Y., Lu, M., Storey, K., Macklin, M., Hoeller, D., Rudin, N., Allshire, A., Handa, A., et al.: Isaac gym: High performance gpu-based physics simulation for robot learning.arXiv preprint arXiv:2108.10470(2021) 2, 3, 9, 12, 37 39.Mandikal, P., Grauman, K.: Dexvip: Learning dexterous grasping with human hand pose priors from video.In: Conference on Robot Learning.pp.651-661.PMLR (2022) 4 40.Marcucci, T., Gabiccini, M., Artoni, A.: A two-stage trajectory optimization strategy for articulated bodies with unscheduled contact sequences.IEEE Robotics and Automation Letters 2(1), 104-111 (2016) 3, 6 41.Mordatch, I., Popović, Z., Todorov, E.: Contact-invariant optimization for hand manipulation.In: Proceedings of the ACM SIGGRAPH/Eurographics symposium on computer animation.pp.137-144 (2012) 2 42.Pang, T., Suh, H.T., Yang, L., Tedrake, R.: Global planning for contact-rich manipulation via local smoothing of quasi-dynamic contact models.IEEE Transactions on Robotics (2023) 4 43.Pang, T., Tedrake, R.: A convex quasistatic time-stepping scheme for rigid multibody systems with contact and friction.In: 2021 IEEE International Conference on Robotics and Automation (ICRA).pp.6614-6620.IEEE (2021) 2, 3, 4 44.Peng, X.B., Abbeel, P., Levine, S., Van de Panne, M.: Deepmimic: Example-guided deep reinforcement learning of physics-based character skills.ACM Transactions On Graphics (TOG) 37(4), 1-14 (2018) 2 45.Pfaff, T., Fortunato, M., Sanchez-Gonzalez, A., Battaglia, P.W.: Learning meshbased simulation with graph networks.arXiv preprint arXiv:2010.03409(2020) 4 46.Pfrommer, S., Halm, M., Posa, M.: Contactnets: Learning discontinuous contact dynamics with smooth, implicit representations.In: Conference on Robot Learning.
pp. 2279-2291. PMLR (2021) 4, 747. Qin, Y., Huang, B., Yin, Z.H., Su, H., Wang, X.: Dexpoint: Generalizable pointcloud reinforcement learning for sim-to-real dexterous manipulation. In: Conferenceon Robot Learning. pp. 594-605. PMLR (2023) 3248. Qin, Y., Su, H., Wang, X.: From one hand to multiple hands: Imitation learningfor dexterous manipulation from single-camera teleoperation. IEEE Robotics andAutomation Letters 7(4), 10873-10881 (2022) 4</p>
<p>Table 3 :
3
Additional Comparisons.Quantitative comparisons between our method and DexMV.Experiments are conducted on sequences from the GRAB dataset in the Bullet simulator.Bold red numbers for best values.
ObjectHandOverallMethod Rerr ( DexMV 28.362.4241.5318.0911.11/18.52/48.15Ours22.381.7635.0213.6225.93/37.04/62.96
• , ↓) Terr (cm, ↓) MPJPE (mm, ↓) CD (mm, ↓) Success Rate (%, ↑)</p>
<p>Table 4 :
4
User study.
OursDGrasp-TrackingAverage Score 4.002.06Median Score3.952.10</p>
<p>Table 5 :
5
Default parameter settings of the quasi-physical simulator curriculum.
Subject ID 1567415742
Objectbox capsulemachine espressomachine ketchup laptop microwave mixer phone scissors waffleiron</p>
<p>DexMV's GitHub Repository Link
DGrasp's GitHub Repository.
ControlVAE's GitHub Repository.
AcknowledgementWe thank Prof. Rui Chen, Yixuan Guan, and Taoran Jiang for their valuable support in providing the Allegro hardware and setting up the environment setup during the rebuttal period.6for the setting of this simulator.MPC (w/ base sim.w/ soften).Based on the base simulator, we introduce the soften strategy present in Bundled Gradients[59].Penalty-based contacts are smoothed by sampling contact spring coefficients, as stated in Section IV.B[59].The sampling range for each coefficient is defined as the [-10%, +10%] interval of the original value.
Augmenting physical simulators with stochastic neural networks: Case study of planar pushing and bouncing. A Ajay, J Wu, N Fazeli, M Bauza, L P Kaelbling, J B Tenenbaum, A Rodriguez, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2018. 20187</p>
<p>Solving rubik's cube with a robot hand. I Akkaya, M Andrychowicz, M Chociej, M Litwin, B Mcgrew, A Petron, A Paino, M Plappert, G Powell, R Ribas, arXiv:1910.0711320192arXiv preprint</p>
<p>Contact and friction simulation for computer graphics. S Andrews, K Erleben, Z Ferguson, ACM SIGGRAPH 2022 Courses. 202227</p>
<p>Learning dexterous in-hand manipulation. O M Andrychowicz, B Baker, M Chociej, R Jozefowicz, B Mcgrew, J Pachocki, A Petron, M Plappert, G Powell, A Ray, The International Journal of Robotics Research. 39142020</p>
<p>Dexterous imitation made easy: A learning-based framework for efficient dexterous manipulation. S P Arunachalam, S Silwal, B Evans, L Pinto, 2023 ieee international conference on robotics and automation (icra). IEEE202332</p>
<p>Affordances from human videos as a versatile representation for robotics. S Bahl, R Mendonca, L Chen, U Jain, D Pathak, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition202332</p>
<p>An introduction to physically based modeling: rigid body simulation ii-nonpenetration constraints. D Baraff, SIGGRAPH course notes pp. 19976</p>
<p>Towards generalizable zero-shot manipulation via translating human interaction plans. H Bharadhwaj, A Gupta, V Kumar, S Tulsiani, arXiv:2312.00775202332arXiv preprint</p>
<p>G Chen, T Cui, T Zhou, Z Peng, M Hu, M Wang, Y Yang, Y Yue, arXiv:2312.02419Human demonstrations are generalizable knowledge for robots. 202332arXiv preprint</p>
<p>Visual dexterity: In-hand reorientation of novel and complex object shapes. T Chen, M Tippur, S Wu, V Kumar, E Adelson, P Agrawal, 10.1126/scirobotics.adc9244Science Robotics. 88492442023</p>
<p>T Chen, J Xu, P Agrawal, A system for general in-hand object re-orientation. Conference on Robot Learning. 20212</p>
<p>D-grasp: Physically plausible dynamic grasp synthesis for hand-object interactions. S Christen, M Kocabas, E Aksan, J Hwangbo, J Song, O Hilliges, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022) 2, 4, 8, 11, 243740</p>
<p>Pybullet, a python module for physics simulation for games, robotics and machine learning. E Coumans, Y Bai, 2016239</p>
<p>Learning vortex dynamics for fluid inference and prediction. Y Deng, H X Yu, J Wu, B Zhu, arXiv:2301.1149420234arXiv preprint</p>
<p>Deep learning for physics simulation. T Du, ACM SIGGRAPH 2023 Courses. 20234</p>
<p>Homotopy optimization methods for global optimization. D M Dunlavy, D P O'leary, Ca . Livermore, Sandia National Laboratories (SNL). Albuquerque, NM20052Tech. rep</p>
<p>ARCTIC: A dataset for dexterous bimanual hand-object manipulation. Z Fan, O Taheri, D Tzionas, M Kocabas, M Kaufmann, M J Black, O Hilliges, Proceedings IEEE Conference on Computer Vision and Pattern Recognition (CVPR. IEEE Conference on Computer Vision and Pattern Recognition (CVPR20231036</p>
<p>Rigid body dynamics algorithms. R Featherstone, 200723</p>
<p>C D Freeman, E Frey, A Raichuk, S Girgin, I Mordatch, O Bachem, arXiv:2106.13281Brax-a differentiable physics engine for large scale rigid body simulation. 20212arXiv preprint</p>
<p>Supertrack: Motion tracking for physically simulated characters using supervised learning. L Fussell, K Bergamin, D Holden, ACM Transactions on Graphics (TOG). 40692021</p>
<p>J Gao, M Y Michelis, A Spielberg, R K Katzschmann, arXiv:2402.01086Sim-to-real of soft robots with learned residual physics. 20244arXiv preprint</p>
<p>Model predictive control: Theory and practice-a survey. C E Garcia, D M Prett, M Morari, Automatica. 253251989</p>
<p>Add: Analytically differentiable dynamics for multi-body systems with frictional contact. M Geilinger, D Hahn, J Zehnder, M Bächer, B Thomaszewski, S Coros, ACM Transactions on Graphics (TOG). 39662020</p>
<p>Doc: Differentiable optimal control for retargeting motions onto legged robots. R Grandia, F Farshidian, E Knoop, C Schumacher, M Hutter, M Bächer, ACM Transactions on Graphics (TOG). 424112023</p>
<p>Learning multi-step manipulation tasks from a single human demonstration. D Guo, arXiv:2312.15346202332arXiv preprint</p>
<p>Learning dexterous manipulation for a soft robotic hand from human demonstrations. A Gupta, C Eppner, S Levine, P Abbeel, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2016. 201624</p>
<p>Neuralsim: Augmenting differentiable simulators with neural networks. E Heiden, D Millard, E Coumans, Y Sheng, G S Sukhatme, 2021 IEEE International Conference on Robotics and Automation (ICRA). 2021</p>
<p>T A Howell, Le Cleac'h, S Kolter, J Z Schwager, M Manchester, Z , arXiv:2203.00806Dojo: A differentiable simulator for robotics. 202294arXiv preprint</p>
<p>Trajectory optimization with optimization-based dynamics. T A Howell, Le Cleac'h, S Singh, S Florence, P Manchester, Z Sindhwani, V , IEEE Robotics and Automation Letters. 7322022</p>
<p>Per-contact iteration method for solving contact dynamics. J Hwangbo, J Lee, M Hutter, IEEE Robotics and Automation Letters. 3222018</p>
<p>Dexmv: Imitation learning for dexterous manipulation from human videos. Y Qin, Y H Wu, S Liu, H Jiang, R Yang, Y Fu, X Wang, European Conference on Computer Vision. Springer2022232</p>
<p>Anyteleop: A general vision-based dexterous robot arm-hand teleoperation system. Y Qin, W Yang, B Huang, K Van Wyk, H Su, X Wang, Y W Chao, D Fox, arXiv:2307.04577202311arXiv preprint</p>
<p>State-only imitation learning for dexterous manipulation. I Radosavovic, X Wang, L Pinto, J Malik, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE20214</p>
<p>Learning complex dexterous manipulation with deep reinforcement learning and demonstrations. A Rajeswaran, V Kumar, A Gupta, G Vezzani, J Schulman, E Todorov, S Levine, arXiv:1709.10087201724arXiv preprint</p>
<p>. A A Rusu, S G Colmenarejo, C Gulcehre, G Desjardins, J Kirkpatrick, R Pascanu, V Mnih, K Kavukcuoglu, R Hadsell, arXiv:1511.0629520154Policy distillation. arXiv preprint</p>
<p>Reinforcement learning with videos: Combining offline observations with interaction. K Schmeckpeper, O Rybkin, K Daniilidis, S Levine, C Finn, arXiv:2011.0650720204arXiv preprint</p>
<p>. ShadowRobot: Shadowrobot dexterous hand. 2005</p>
<p>Videodex: Learning dexterity from internet videos. K Shaw, S Bahl, D Pathak, Conference on Robot Learning. PMLR202332</p>
<p>A Siahkoohi, M Louboutin, F J Herrmann, arXiv:1910.00925Neural network augmented waveequation simulation. 20194arXiv preprint</p>
<p>Comparing effectiveness of relaxation methods for warm starting trajectory optimization through soft contact. H Suh, Y Wang, 201936</p>
<p>Bundled gradients through contact via randomized smoothing. H J T Suh, T Pang, R Tedrake, IEEE Robotics and Automation Letters. 72382022</p>
<p>Grab: A dataset of wholebody human grasping of objects. O Taheri, N Ghorbani, M J Black, D Tzionas, Computer Vision-ECCV 2020: 16th European Conference. Glasgow, UKSpringerAugust 23-28, 2020. 20201035Proceedings, Part IV 16</p>
<p>Advances in PID control. K K Tan, Q G Wang, C C Hang, 2012Springer Science &amp; Business Media12</p>
<p>R Tedrake, the Drake Development Team: Drake: Model-based design and verification for robotics. 2019</p>
<p>Mujoco: A physics engine for model-based control. E Todorov, T Erez, Y Tassa, IEEE/RSJ international conference on intelligent robots and systems. 2012. 20122</p>
<p>Continual reinforcement learning deployed in real-life using policy distillation and sim2real transfer. R Traoré, H Caselles-Dupré, T Lesort, T Sun, N Díaz-Rodríguez, D Filliat, arXiv:1906.0445220194arXiv preprint</p>
<p>Contact-aware retargeting of skinned motion. R Villegas, D Ceylan, A Hertzmann, J Yang, J Saito, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision202111</p>
<p>Mesh2sdf: Converts an input mesh to a signed distance field. P S Wang, 2022</p>
<p>Redmax: Efficient &amp; flexible approach for articulated dynamics. Y Wang, N J Weidner, M A Baxter, Y Hwang, D M Kaufman, S Sueda, ACM Transactions on Graphics (TOG). 38462019</p>
<p>Physhoi: Physics-based imitation of dynamic human-object interaction. Y Wang, J Lin, A Zeng, Z Luo, J Zhang, L Zhang, arXiv:2312.04393202324arXiv preprint</p>
<p>Modern homotopy methods in optimization. L T Watson, R T Haftka, Computer Methods in Applied Mechanics and Engineering. 74321989</p>
<p>Learning generalizable dexterous manipulation from human grasp affordance. Y H Wu, J Wang, X Wang, Conference on Robot Learning. 202324</p>
<p>Neural vortex method: from finite lagrangian particles to infinite dimensional eulerian dynamics. S Xiong, X He, Y Tong, Y Deng, B Zhu, Computers &amp; Fluids. 25842023</p>
<p>J Xu, T Chen, L Zlokapa, M Foshey, W Matusik, S Sueda, P Agrawal, arXiv:2107.07501An end-to-end differentiable framework for contact-aware robot design. 2021631arXiv preprint</p>
<p>Stable penalty-based model of frictional contacts. K Yamane, Y Nakamura, Proceedings 2006 IEEE International Conference on Robotics and Automation. 2006 IEEE International Conference on Robotics and Automation2006. 2006. 20067</p>
<p>Controlvae: Model-based learning of generative controllers for physics-based characters. H Yao, Z Song, B Chen, L Liu, ACM Transactions on Graphics (TOG). 26412022</p>
<p>Tossingbot: Learning to throw arbitrary objects with residual physics. A Zeng, S Song, J Lee, A Rodriguez, T Funkhouser, IEEE Transactions on Robotics. 36442020</p>
<p>Artigrasp: Physically plausible synthesis of bi-manual dexterous grasping and articulation. H Zhang, S Christen, Z Fan, L Zheng, J Hwangbo, J Song, O Hilliges, arXiv:2309.038912023231arXiv preprint</p>
<p>Model-based reparameterization policy gradient methods: Theory and practical algorithms. S Zhang, B Liu, Z Wang, T Zhao, Advances in Neural Information Processing Systems. 3642024</p>
<p>Learning to transfer in-hand manipulations using a greedy shape curriculum. Y Zhang, A Clegg, S Ha, G Turk, Y Ye, Computer Graphics Forum. 4242023Wiley Online Library</p>
<p>Sim-to-real transfer in deep reinforcement learning for robotics: a survey. W Zhao, J P Queralta, T Westerlund, IEEE symposium series on computational intelligence (SSCI). IEEE2020. 20204</p>
<p>A comprehensive survey on transfer learning. F Zhuang, Z Qi, K Duan, D Xi, Y Zhu, H Zhu, H Xiong, Q He, Proceedings of the IEEE. 109142020</p>            </div>
        </div>

    </div>
</body>
</html>