<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-962 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-962</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-962</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-cdc04b748e440f43547c0516f77480ffb8bf5cda</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/cdc04b748e440f43547c0516f77480ffb8bf5cda" target="_blank">Causal Discovery from Heterogeneous/Nonstationary Data</a></p>
                <p><strong>Paper Venue:</strong> Journal of machine learning research</p>
                <p><strong>Paper TL;DR:</strong> A framework for causal discovery from heterogeneous/NOnstationary Data to find causal skeleton and directions and estimate the properties of mechanism changes, and finds that data heterogeneity benefits causal structure identification even with particular types of confounders.</p>
                <p><strong>Paper Abstract:</strong> It is commonplace to encounter heterogeneous or nonstationary data, of which the underlying generating process changes across domains or over time. Such a distribution shift feature presents both challenges and opportunities for causal discovery. In this paper, we develop a framework for causal discovery from such data, called Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and directions and estimate the properties of mechanism changes. First, we propose an enhanced constraint-based procedure to detect variables whose local mechanisms change and recover the skeleton of the causal structure over observed variables. Second, we present a method to determine causal orientations by making use of independent changes in the data distribution implied by the underlying causal model, benefiting from information carried by changing distributions. After learning the causal structure, next, we investigate how to efficiently estimate the `driving force' of the nonstationarity of a causal mechanism. That is, we aim to extract from data a low-dimensional representation of changes. The proposed methods are nonparametric, with no hard restrictions on data distributions and causal mechanisms, and do not rely on window segmentation. Furthermore, we find that data heterogeneity benefits causal structure identification even with particular types of confounders. Finally, we show the connection between heterogeneity/nonstationarity and soft intervention in causal discovery. Experimental results on various synthetic and real-world data sets (task-fMRI and stock market data) are presented to demonstrate the efficacy of the proposed methods.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e962.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e962.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CD-NOD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonparametric, constraint-based framework for causal discovery from heterogeneous or nonstationary observational data that (i) detects which variables' causal mechanisms change, (ii) recovers the causal skeleton using a surrogate domain/time index, and (iii) orients edges by exploiting independent changes of causal modules via kernel embeddings and an HSIC-based dependence measure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CD-NOD (Algorithms 1–3)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CD-NOD is a three-phase, nonparametric causal discovery pipeline tailored for heterogeneous/nonstationary data. Key components: (1) Introduce a surrogate variable C (domain or time index) that captures distribution shifts, augment the variable set with C, and run constraint-based conditional independence testing (Algorithm 1) to detect changing causal modules (edges V_i—C) and recover the skeleton over observed variables; this step uses a general kernel-based conditional independence test (KCI) to capture arbitrary nonlinear dependence on C. (2) Orient edges by exploiting invariance and independent-change principles (Algorithms 2 and 3): (a) use generalized invariance tests P(V_i | S, C=c) = P(V_i | S, C=c') implemented as conditional independence tests V_i ⟂ C | S to orient unshielded triples involving a C-specific node; (b) when both endpoints are C-specific, represent changing conditional modules by a novel window-free kernel embedding of constructed joint distributions ~tilde{P}(_Y,X|C=c)=P(Y|X,C=c)P(X) and compute Gram matrices without sliding windows (Proposition 1); (c) extend HSIC to measure dependence between sequences of embedded modules (normalized HSIC between module-gram matrices) to test independence between P(cause) and P(effect|cause) vs the reverse; decide direction by comparing ̂Delta_{X->Y} and ̂Delta_{Y->X}, with a threshold α to flag pseudo-confounding. (3) For multivariate cases, the algorithm defines minimal deconfounding and potential deconfounding sets and conditions on them (Algorithm 3) to remove common-cause effects before applying the module-independence test. The method assumes pseudo causal sufficiency (confounders are deterministic/smooth functions of C), Markov + faithfulness on an augmented graph, and uses kernel hyperparameters learned (where applicable) via marginal-likelihood or empirical settings.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Heterogeneous / nonstationary observational data (synthetic simulations, task-fMRI, stock market time series)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets collected across domains or over time where distributions shift; C is either a discrete domain index or a continuous time index. Not an interactive or active-experiment virtual lab — no experimental interventions are selected by the algorithm (observational/soft-intervention interpretation only).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Represent shared/changing hidden factors as functions of the surrogate index C (pseudo confounders) and (i) detect them via conditional independence tests with C, (ii) remove spurious skeleton edges by conditioning on C in constraint-based tests, and (iii) detect pseudo-confounders between variable pairs by checking whether conditional independencies require C in the conditioning set; in orientation, use deconfounding/potential deconfounding sets to condition away common causes before applying module-independence tests.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Pseudo confounders (latent factors that are deterministic or smooth functions of domain/time index), distribution shift-induced spurious edges, nonstationary changes in local mechanisms, stationary confounders discussed (but not fully represented by C), and spurious correlations caused by merging heterogeneous datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Conditional independence testing between each variable and the surrogate C (using a nonparametric KCI-test) to flag changing modules; conditional independence tests among variables with C included in conditioning sets to remove spurious edges; detection of dependent changing modules via kernel embeddings of constructed joint distributions and a normalized HSIC statistic between module-gram matrices (̂Delta measures) indicating dependence between P(cause) and P(effect|cause).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Spurious causal relationships are refuted (or left undetermined) by: (a) removing edges that become independent when conditioning on appropriate subsets including C (Algorithm 1); (b) declaring pseudo-confounding when both directional module-dependence statistics exceed a threshold α (i.e., neither direction shows module independence), and leaving direction unresolved; (c) using orientation rules (v-structure tests with C) and module-independence comparisons (extended HSIC) to prefer directions where P(cause) and P(effect|cause) vary independently, thereby refuting the reverse direction where modules are dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CD-NOD demonstrates that distributional heterogeneity/nonstationarity can be exploited to both recover the correct causal skeleton and orient edges that would be unidentifiable under stationary assumptions. Adding the surrogate index C restores conditional independence relations that would otherwise be distorted by shared changing factors, resulting in asymptotically correct skeleton recovery (Theorem 1). Kernel embeddings of constructed joint distributions enable window-free representation of changing conditional modules, and an HSIC-based dependence measure between module embeddings can distinguish causal direction by preferring independence between P(cause) and P(effect|cause). The method explicitly detects pseudo confounders (when both module pairs are dependent) and leaves such edges unoriented rather than producing spurious orientations; the framework follows a minimal-change principle because faithfulness on the augmented graph yields minimal edges to C. CD-NOD is nonparametric and handles nonlinear, non-Gaussian changes, but relies on the assumption that confounders that cause module dependencies are representable as functions of C (pseudo confounders); stationary confounders that do not vary with C are not resolved by the C-based surrogate and may limit identifiability unless additional assumptions or methods are applied.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Causal Discovery from Heterogeneous/Nonstationary Data', 'publication_date_yy_mm': '2019-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bayesian Online Changepoint Detection <em>(Rating: 2)</em></li>
                <li>Kernel-based Conditional Independence Test <em>(Rating: 2)</em></li>
                <li>Causal Inference by Using Invariant Prediction: Identification and Confidence Intervals <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-962",
    "paper_id": "paper-cdc04b748e440f43547c0516f77480ffb8bf5cda",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CD-NOD",
            "name_full": "Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD)",
            "brief_description": "A nonparametric, constraint-based framework for causal discovery from heterogeneous or nonstationary observational data that (i) detects which variables' causal mechanisms change, (ii) recovers the causal skeleton using a surrogate domain/time index, and (iii) orients edges by exploiting independent changes of causal modules via kernel embeddings and an HSIC-based dependence measure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "CD-NOD (Algorithms 1–3)",
            "method_description": "CD-NOD is a three-phase, nonparametric causal discovery pipeline tailored for heterogeneous/nonstationary data. Key components: (1) Introduce a surrogate variable C (domain or time index) that captures distribution shifts, augment the variable set with C, and run constraint-based conditional independence testing (Algorithm 1) to detect changing causal modules (edges V_i—C) and recover the skeleton over observed variables; this step uses a general kernel-based conditional independence test (KCI) to capture arbitrary nonlinear dependence on C. (2) Orient edges by exploiting invariance and independent-change principles (Algorithms 2 and 3): (a) use generalized invariance tests P(V_i | S, C=c) = P(V_i | S, C=c') implemented as conditional independence tests V_i ⟂ C | S to orient unshielded triples involving a C-specific node; (b) when both endpoints are C-specific, represent changing conditional modules by a novel window-free kernel embedding of constructed joint distributions ~tilde{P}(_Y,X|C=c)=P(Y|X,C=c)P(X) and compute Gram matrices without sliding windows (Proposition 1); (c) extend HSIC to measure dependence between sequences of embedded modules (normalized HSIC between module-gram matrices) to test independence between P(cause) and P(effect|cause) vs the reverse; decide direction by comparing ̂Delta_{X-&gt;Y} and ̂Delta_{Y-&gt;X}, with a threshold α to flag pseudo-confounding. (3) For multivariate cases, the algorithm defines minimal deconfounding and potential deconfounding sets and conditions on them (Algorithm 3) to remove common-cause effects before applying the module-independence test. The method assumes pseudo causal sufficiency (confounders are deterministic/smooth functions of C), Markov + faithfulness on an augmented graph, and uses kernel hyperparameters learned (where applicable) via marginal-likelihood or empirical settings.",
            "environment_name": "Heterogeneous / nonstationary observational data (synthetic simulations, task-fMRI, stock market time series)",
            "environment_description": "Observational datasets collected across domains or over time where distributions shift; C is either a discrete domain index or a continuous time index. Not an interactive or active-experiment virtual lab — no experimental interventions are selected by the algorithm (observational/soft-intervention interpretation only).",
            "handles_distractors": true,
            "distractor_handling_technique": "Represent shared/changing hidden factors as functions of the surrogate index C (pseudo confounders) and (i) detect them via conditional independence tests with C, (ii) remove spurious skeleton edges by conditioning on C in constraint-based tests, and (iii) detect pseudo-confounders between variable pairs by checking whether conditional independencies require C in the conditioning set; in orientation, use deconfounding/potential deconfounding sets to condition away common causes before applying module-independence tests.",
            "spurious_signal_types": "Pseudo confounders (latent factors that are deterministic or smooth functions of domain/time index), distribution shift-induced spurious edges, nonstationary changes in local mechanisms, stationary confounders discussed (but not fully represented by C), and spurious correlations caused by merging heterogeneous datasets.",
            "detection_method": "Conditional independence testing between each variable and the surrogate C (using a nonparametric KCI-test) to flag changing modules; conditional independence tests among variables with C included in conditioning sets to remove spurious edges; detection of dependent changing modules via kernel embeddings of constructed joint distributions and a normalized HSIC statistic between module-gram matrices (̂Delta measures) indicating dependence between P(cause) and P(effect|cause).",
            "downweighting_method": null,
            "refutation_method": "Spurious causal relationships are refuted (or left undetermined) by: (a) removing edges that become independent when conditioning on appropriate subsets including C (Algorithm 1); (b) declaring pseudo-confounding when both directional module-dependence statistics exceed a threshold α (i.e., neither direction shows module independence), and leaving direction unresolved; (c) using orientation rules (v-structure tests with C) and module-independence comparisons (extended HSIC) to prefer directions where P(cause) and P(effect|cause) vary independently, thereby refuting the reverse direction where modules are dependent.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "CD-NOD demonstrates that distributional heterogeneity/nonstationarity can be exploited to both recover the correct causal skeleton and orient edges that would be unidentifiable under stationary assumptions. Adding the surrogate index C restores conditional independence relations that would otherwise be distorted by shared changing factors, resulting in asymptotically correct skeleton recovery (Theorem 1). Kernel embeddings of constructed joint distributions enable window-free representation of changing conditional modules, and an HSIC-based dependence measure between module embeddings can distinguish causal direction by preferring independence between P(cause) and P(effect|cause). The method explicitly detects pseudo confounders (when both module pairs are dependent) and leaves such edges unoriented rather than producing spurious orientations; the framework follows a minimal-change principle because faithfulness on the augmented graph yields minimal edges to C. CD-NOD is nonparametric and handles nonlinear, non-Gaussian changes, but relies on the assumption that confounders that cause module dependencies are representable as functions of C (pseudo confounders); stationary confounders that do not vary with C are not resolved by the C-based surrogate and may limit identifiability unless additional assumptions or methods are applied.",
            "uuid": "e962.0",
            "source_info": {
                "paper_title": "Causal Discovery from Heterogeneous/Nonstationary Data",
                "publication_date_yy_mm": "2019-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bayesian Online Changepoint Detection",
            "rating": 2
        },
        {
            "paper_title": "Kernel-based Conditional Independence Test",
            "rating": 2
        },
        {
            "paper_title": "Causal Inference by Using Invariant Prediction: Identification and Confidence Intervals",
            "rating": 2
        }
    ],
    "cost": 0.0121085,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Causal Discovery from Heterogeneous/Nonstationary Data with Independent Changes</h1>
<p>Biwei Huang <em><br>Kun Zhang </em><br>Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA 15213<br>Jiji Zhang<br>JIJIZHANG@LN.EDU.HK<br>Department of Philosophy, Lingnan University, Tuen Mun, Hong Kong<br>Joseph Ramsey<br>JDRAMSEY@ANDREW.CMU.EDU<br>Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA 15213<br>Ruben Sanchez-Romero<br>RUBEN.SARO@RUTGERS.EDU<br>Center for Molecular and Behavioral Neuroscience, Rutgers University, Newark, NJ 07102<br>Clark Glymour<br>CG09@ANDREW.CMU.EDU<br>Department of Philosophy, Carnegie Mellon University, Pittsburgh, PA 15213<br>Bernhard Schölkopf BERNHARD.SCHOELKOPF@TUEBINGEN.MPG.DE<br>Max Planck Institute for Intelligent Systems, Tübingen 72076, Germany</p>
<p>Editor: Jon McAuliffe</p>
<h4>Abstract</h4>
<p>It is commonplace to encounter heterogeneous or nonstationary data, of which the underlying generating process changes across domains or over time. Such a distribution shift feature presents both challenges and opportunities for causal discovery. In this paper, we develop a framework for causal discovery from such data, called Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and directions and estimate the properties of mechanism changes. First, we propose an enhanced constraintbased procedure to detect variables whose local mechanisms change and recover the skeleton of the causal structure over observed variables. Second, we present a method to determine causal orientations by making use of independent changes in the data distribution implied by the underlying causal model, benefiting from information carried by changing distributions. After learning the causal structure, next, we investigate how to efficiently estimate the "driving force" of the nonstationarity of a causal mechanism. That is, we aim to extract from data a low-dimensional representation of changes. The proposed methods are nonparametric, with no hard restrictions on data distributions and causal mechanisms, and do not rely on window segmentation. Furthermore, we find that data heterogeneity benefits causal structure identification even with particular types of confounders. Finally, we show the connection between heterogeneity/nonstationarity and soft intervention in causal discovery. Experimental results on various synthetic and real-world data sets (task-fMRI and stock market data) are presented to demonstrate the efficacy of the proposed methods.</p>
<p>Keywords: causal discovery, heterogeneous/nonstationary data, independent-change principle, kernel distribution embedding, driving force estimation, confounder</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>1. Introduction</h1>
<p>Many tasks across several disciplines of empirical sciences and engineering rely on the underlying causal information. As it is often difficult, if not impossible, to carry out randomized experiments, inferring causal relations from purely observational data, known as the task of causal discovery, has drawn much attention in machine learning, philosophy, statistics, and computer science. Traditionally, for causal discovery from observational data, under appropriate assumptions, so-called constraint-based approaches recover some information of the underlying causal structure based on conditional independence relationships of the variables (Spirtes et al., 1993). Alternatively, approaches based on functional causal models infer the causal structure by exploiting the fact that under certain conditions, the independence between the noise and the hypothetical cause only holds for the correct causal direction but not for the wrong direction (Shimizu et al., 2006; Hoyer et al., 2009; Zhang and Hyvärinen, 2009a,b).</p>
<p>Over the last few years, with the rapid accumulation of huge volumes of data of various types, causal discovery is facing exciting opportunities but also great challenges. One feature such data often exhibit is distribution shift. Distribution shift may occur across data sets, which may be obtained under different interventions or with different data collection conditions, or over time, as featured by nonstationary data. For an example of the former kind, consider remote sensing imagery data. The data collected in different areas and at different times usually have different distributions due to varying physical factors related to ground, vegetation, illumination conditions, etc. As an example of the latter kind, fMRI recordings are usually nonstationary: information flows in the brain may change with stimuli, tasks, attention of the subject, etc. More specifically, it is believed that one of the basic properties of neural connections is their time-dependence (Havlicek et al., 2011). In these situations many existing approaches to causal discovery may fail, as they assume a fixed causal model and hence a fixed joint distribution underlying the observed data. For example, if changes in local mechanisms of some variables are related, one can model the situation as if there exists some unobserved quantity which influences all those variables and, as a consequence, the conditional independence relationships in the distribution-shifted data will be different from those implied by the true causal structure.</p>
<p>In this paper, we assume that mechanisms or parameters, associated with the causal model, may change across data sets or over time (we allow mechanisms to change in such a way that some causal links in the structure may vanish or appear in some domains or over some time periods). We aim to develop a principled framework to model such situations as well as practical methods, called Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD), to address the following questions:</p>
<ol>
<li>How can we efficiently identify variables with changing local mechanisms and reliably recover the skeleton of the causal structure over observed variables?</li>
<li>How can we take advantage of the information carried by distribution shifts for the purpose of identifying causal directions?
After identifying the causal structure, it is then appealing to ask how causal mechanisms change across domains or over time, which raises the question:</li>
<li>How can we extract from data a low-dimensional and potentially interpretable representation of changes, the so-called "driving force" of changing causal mechanisms?</li>
</ol>
<p>Furthermore, we extend our approach to deal with more general scenarios, e.g., dynamic systems which involve both time-varying instantaneous and lagged causal relations and the case of stationary confounders.</p>
<p>In answering these questions, we make use of the following properties of causal systems. (i) Causal models and distribution shifts are heavily coupled: causal models provide a compact description of how data-generating processes, as well as data distributions, change, and distribution shifts exhibit such changes. (ii) From a causal perspective, the distribution shift in heterogeneous/nonstationary data is usually constrained - it may be due to the changes in the data-generating processes (i.e., the local causal mechanisms) of a small number of variables. (iii) From a latent variable modeling perspective, heterogeneous/nonstationary data are generated by some quantities that change across domains or over time, which gives hints as to how to understand distribution shift and estimate its underlying driving forces. (iv) Suppose that there are no confounders for cause and effect. Then $P$ (cause) and $P($ effect $/$ cause $)$ are either fixed or change independently, also known as the modularity property of causal systems (Pearl, 2000). Such an independence helps identify causal directions in the presence of distribution shifts.</p>
<p>To reliably estimate the skeleton of the causal structure and detect changing causal mechanisms from heterogeneous/nonstationary data (Problem 1), we make use of property (i), (ii), and (iii) listed above. Specifically, we introduce a surrogate variable $C$ into the causal system to characterize hidden quantities that lead to the changes across domains or over time. The variable $C$ can be a domain or time index. Including $C$ in the causal system provides a convenient way to unpack distribution shifts to causal representations. We show that given $C$, (conditional) independence relationships between observed variables are the same as those implied by the true causal structure. We, additionally, show that variables that are adjacent to the surrogate variable $C$ have changing causal mechanisms. We make the assumption of faithfulness on the graph involving $C$, and it is known that faithfulness implies a minimality condition on the edges (Zhang and Spirtes, 2016); as a consequence, the graphical representation produced by our procedure naturally enjoys a "minimal change" principle - the representation explains the conditional independence relations and changeability of the distribution with a minimal number of changing conditional distributions.</p>
<p>Regarding Problem 2, as a sub-problem of causal discovery, we show that distribution shift provides additional information for causal direction identification. it is known that with functional causal model-based approaches, there are cases where causal directions are not identifiable, e.g., the linear-Gaussian case and the case with a general functional class (Hyvärinen and Pajunen, 1999; Zhang et al., 2015b). This restricts the causal direction identification to certain functional classes, e.g., additive (Shimizu et al., 2006; Hoyer et al., 2009; Zhang and Hyvärinen, 2009a) or post-nonlinear models (Zhang and Chan, 2006; Zhang and Hyvärinen, 2009b). We show that using information carried by distribution shifts does not suffer from these restrictions - the method applies to general causal mechanisms.</p>
<p>Specifically, we take advantage of property (iv) for causal direction determination: if there is no confounder for $V_{i}$ and $V_{j}$, then the causal mechanisms, represented by the conditional distributions $P\left(V_{i} \mid \mathrm{PA}^{i}\right)$ and $P\left(V_{j} \mid \mathrm{PA}^{j}\right)$, change independently across data sets or over time. However, independence typically no longer holds for wrong directions. This gives rise to causal asymmetry. To exploit this asymmetry, we develop a kernel embedding</p>
<p>of nonstationary conditional distributions to represent changing causal mechanisms and accordingly propose a dependence measure to determine causal directions. Furthermore, it is worth noting that although our method can been seen as an extension of constraint-based methods such as PC (Spirtes et al., 2001), unlike the original ones, it can find the causal direction between even two variables, thanks to the surrogate variable $C$ in the system or more generally, the independent change property implied by a causal system.</p>
<p>Regarding Problem 3, traditionally, one may use Bayesian change point detection to detect change points of observed time series (Adams and MacKay, 2007) or use sliding windows and then estimate the causal model within each segment separately. However, Bayesian change point detection can only be applied to detect changes in marginal or joint distributions, whereas causal mechanisms are represented by conditional distributions. Moreover, neither of them is appropriate when causal mechanisms change continuously over time. More recently, a window-free method has been proposed, by extending Gaussian process regression (Huang et al., 2015). However, it requires the assumption of linearity, and it fails to handle the case when nonstationarity results from the change of noise distributions. In this paper, by leveraging property (iii), we propose a nonparametric method to recover a low-dimensional and interpretable representation of mechanism changes, which does not rely on window segmentation.</p>
<p>This paper is organized as follows. ${ }^{1}$ In Section 2 we define and motivate the problem in more detail and review related work. Section 3 proposes an enhanced constraint-based method to recover the causal skeleton over observed variables and identify variables with changing causal mechanisms. Section 4 develops a method for determining causal directions by exploiting distribution shifts. It makes use of the property that in a causal system, causal modules change independently if there are no confounders. Section 5 proposes a method, termed Kernel Nonstationary Visualization (KNV), to visualize a low-dimensional and interpretable representation of changing mechanisms, the so-called "driving force". In Section 6 , we extend CD-NOD to the case that allows both time-varying lagged and instantaneous causal relationships, and we discuss whether distribution shifts also help for causal discovery when there exist stationary confounders. In addition, we give a procedure to leverage both CD-NOD and approaches based on constrained functional causal models. In Section 7, we show the connection between heterogeneity/nonstationarity and soft intervention in causal</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>discovery. Section 8 reports experimental results tested on both synthetic and real-world data sets, including task-fMRI data, Hong Kong stock data, and US stock data.</p>
<h1>2. Problem Definition and Related Work</h1>
<p>In this section, we first review causal discovery approaches with fixed causal models. Then we give examples to show that if the underlying causal model changes, directly applying approaches with fixed causal models may result in spurious edges or wrong causal directions, which motivates our work in causal discovery with changing causal models.</p>
<h3>2.1 Causal Discovery of Fixed Causal Models</h3>
<p>Most causal discovery methods assume that there is a fixed causal model underlying the observed data and aim to estimate it from the data. Classic approaches to causal discovery divide roughly into two types. In the late 1980's and early 1990's, it was noted that under appropriate assumptions, one could recover a Markov equivalence class of the underlying causal structure based on conditional independence relationships among the variables (Spirtes et al., 1993). This gave rise to the constraint-based approach to causal discovery, and the resulting equivalence class may contain multiple DAGs (or other graphical objects to represent causal structures), which entail the same conditional independence relationships. The required assumptions include the causal Markov condition and the faithfulness assumption, which entail a correspondence between d-separation properties in the underlying causal structure and statistical independence properties in the data. The so-called score-based approach (see, e.g., Chickering, 2003; Heckerman et al., 1995) searches for the equivalence class which gives the highest score under some scoring criteria, such as the Bayesian Information Criterion (BIC), the posterior of the graph given the data (Heckerman et al., 2006), and the generalized score functions (Huang et al., 2018).</p>
<p>Another set of approaches is based on constrained functional causal models, which represent the effect as a function of the direct causes together with an independent noise term. The causal direction implied by the constrained functional causal model is generically identifiable, in that the model assumptions, such as the independence between the noise and cause, hold only for the true causal direction and are violated for the wrong direction. Examples of such constrained functional causal models include the linear non-Gaussian acyclic model (LiNGAM, Shimizu et al., 2006), the additive noise model (Hoyer et al., 2009; Zhang and Hyvärinen, 2009a), and the post-nonlinear causal model (Zhang and Chan, 2006; Zhang and Hyvärinen, 2009b).</p>
<h3>2.2 With Changing Causal Models</h3>
<p>Suppose that we are given a set of observed variables $\mathbf{V}=\left{V_{i}\right}<em i="i">{i=1}^{m}$ whose causal structure is represented by a DAG $G$. For each $V</em>$ factorizes according to $G$ :}$, let $P A^{i}$ denote the set of parents of $V_{i}$ in $G$. Suppose that at each time point or in each domain, the joint probability distribution of $\mathbf{V</p>
<p>$$
P(\mathbf{V})=\prod_{i=1}^{m} P\left(V_{i} \mid \mathrm{PA}^{i}\right)
$$</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An illustration on how ignoring changes in the causal model may lead to spurious edges by constraint-based methods. (a) The true causal graph (including confounder $g(C)$, which is hidden). (b) The estimated causal skeleton on the observed data in the asymptotic case given by constraint-based methods, e.g., PC or FCI.</p>
<p>We call each $P\left(V_{i} \mid \mathrm{PA}^{i}\right)$ a causal module (the same meaning with "causal mechanism" in previous sections). If there are distribution shifts (i.e., $P(\mathbf{V})$ changes across domains or over time), at least some causal modules $P\left(V_{k} \mid \mathrm{PA}^{k}\right), k \in \mathcal{N}$ must change. We call those causal modules changing causal modules. Their changes may be due to changes of the involved functional models, causal strengths, noise levels, etc. We assume that those quantities that change across domains or over time can be written as functions of a domain or time index, and denote by $C$ such an index.</p>
<p>If the changes in some modules are related, one can treat the situation as if there exists some unobserved quantity (confounder) which influences those modules and, as a consequence, the conditional independence relationships in the distribution-shifted data will be different from those implied by the true causal structure. Therefore, standard constraintbased algorithms such as PC or FCI (Spirtes et al., 1993) may not be able to reveal the true causal structure. As an illustration, suppose that the observed data were generated according to Fig. 1(a), where $g(C)$, a function of $C$, is involved in the generating processes for both $V_{2}$ and $V_{4}$; the causal skeleton over the observed data then contains spurious edges $V_{1}-V_{4}$ and $V_{2}-V_{4}$, as shown in Fig. 1(b), because there is only one conditional independence relationship, $V_{3} \Perp V_{1} \mid V_{2}$.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: An illustration of a failure of using the approach based on functional causal models for causal direction determination when the causal model changes. (a) Scatter plot of $V_{1}$ and $V_{2}$ on data set 1. (b) Scatter plot of $V_{1}$ and $V_{2}$ on data set 2. (c) Scatter plot of $V_{1}$ and $V_{2}$ on merged data (both data sets). (d) Scatter plot of $V_{1}$ and the estimated regression residual $\hat{E}$ on merged data by regressing $V_{2}$ on $V_{1}$.</p>
<p>Moreover, when one fits a fixed functional causal model (e.g., a linear, non-Gaussian model, Shimizu et al., 2006) to distribution-shifted data, the estimated noise may not be independent of the cause. Consequently, the approach based on constrained functional causal models, in general, cannot infer the correct causal structure either. Figure 2 gives an illustration of this point. Suppose that we have two data sets for variables $V_{1}$ and $V_{2}$ : $V_{2}$ is generated from $V_{1}$ according to $V_{2}=0.3 V_{1}+E$ in the first data set and according to $V_{2}=0.7 V_{1}+E$ in the second one, and in both data sets $V_{1}$ and $E$ are mutually independent and follow a uniform distribution. Figure 2(a-c) show the scatter plots of $V_{1}$ and $V_{2}$ on data set 1 , on data set 2 , and on merged data, respectively. Figure 2(d) shows the scatter plot of $V_{1}$, the cause, and the estimated regression residual on the merged data set by regressing $V_{2}$ on $V_{1}$; they are not independent anymore, although on either data set the regression residual is independent of $V_{1}$. Thus, we cannot correctly determine the causal direction.</p>
<p>To tackle the issue of changing causal models, one may try to find causal models in each domain, for data from multiple domains, or in each sliding window, for nonstationary data, separately, and then compare and merge them. For instance, regarding the former type of data from multiple domains, in particular, multiple data sets obtained by external interventions where it is unknown what variables are manipulated, He and Geng (2016) considered two settings, depending on the sample size of each data set-in the setting with a large sample size for each data set, they proposed a graph-merging method after learning a causal network in each domain separately; in the setting with a relative small sample size, they proposed to pool together the data to learn a network structure and then use a re-sampling approach to evaluate the edges of the learned network. Regarding nonstationary data, improved versions include the online change point detection method (Adams and MacKay, 2007), the online undirected graph learning (Talih and Hengartner, 2005), and the locally stationary structure tracker algorithm (Kummerfeld and Danks, 2013). Such methods may suffer from high estimation variance due to sample scarcity, large type II errors, or multiple testing problems from a large number of statistical tests. Some methods aim to estimate the time-varying causal model by making use of certain types of smoothness of the change (Huang et al., 2015), but they do not explicitly locate the nonstationary causal modules. Several methods aim to model time-varying time-delayed causal relations (Xing et al., 2010; Song et al., 2009), which can be reduced to online parameter learning because the direction of causal relations is given (i.e., the past influences the future). Compared to them, learning changing instantaneous causal relations, with which we are concerned in this paper, is generally more difficult. Recently, several methods have been proposed to tackle time-varying or domain-varying instantaneous causal relations (Ghassami et al., 2018; Huang et al., 2019a,b, 2020). However, they assume linear causal models, limiting their applicability to complex problems with nonlinear causal relations.</p>
<p>In contrast, we develop a nonparametric and computationally efficient method that can identify changing causal modules and reliably recover the causal structure. We show that distribution shifts actually contain useful information for the purpose of determining causal directions and develop practical algorithms accordingly. After identifying the causal structure, we propose a method to estimate a low-dimensional and interpretable representation of changes.</p>
<h1>3. CD-NOD Phase I: Changing Causal Module Detection and Causal Skeleton Estimation</h1>
<p>In this section, we first formalize the assumptions that will be used in CD-NOD. Specifically, we allow a particular type of confounders-pseudo confounders, and we do not put hard restrictions on functional forms of causal mechanisms and data distributions. Accordingly, we propose an approach to efficiently detect changing causal modules and identify the causal skeleton; we call this step CD-NOD phase I. We show that the proposed approach is guaranteed to asymptotically recover the true graph as if unobserved changing factors were known.</p>
<h3>3.1 Assumptions</h3>
<p>In this paper, we allow changes in causal modules and some of the changes to be related; the related changes can be explained by positing particular types of confounders. Intuitively, such confounders may refer to some high-level background variables. For instance, for fMRI data, they may be the subject's attention or some unmeasured background stimuli; for the stock market, they may be related to economic policies. Thus, we do not assume causal sufficiency for the set of observed variables. Instead, we assume pseudo causal sufficiency as stated below.</p>
<p>Assumption 1 (Pseudo Causal Sufficiency) We assume that the confounders, if any, can be written as functions of the domain index or smooth functions of time ${ }^{2}$. It follows that in each domain or at each time instance, the values of these confounders are fixed.</p>
<p>To clearly express our basic idea in the presence of distribution shift, we focus on DAGs and assume pseudo causal sufficiency. Note that our approach is flexible enough to be extended to cover other types of graphs, e.g., graphs with confounders and graphs with cycles. Later in Section 6.2, we will discuss how nonstationarity helps when there exist stationary confounders. In table 1, we summarize descriptions of different types of confounders (latent common causes) that will be used in this paper, including pseudo confounders, stationary confounders, and nonstationary confounders.</p>
<p>We start with contemporaneous causal relations; the mechanisms and parameters associated with the causal model are allowed to change across data sets or over time, or even vanish or appear in some domains or over some time periods. However, it is natural to generalize our framework to incorporate time-delayed causal relations (Section 6.1).</p>
<p>Denote by $\left{g_{l}(C)\right}<em i="i">{l=1}^{L}$ the set of pseudo confounders (which may be empty). We further assume that for each $V</em>$, its local causal process can be represented by the following structural equation model (SEM):</p>
<p>$$
V_{i}=f_{i}\left(\mathrm{PA}^{i}, \mathbf{g}^{i}(C), \theta_{i}(C), \epsilon_{i}\right)
$$</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Confounder type</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Pseudo confounder</td>
<td style="text-align: left;">It can be represented as functions of domain index or <br> smooth functions of time index.</td>
</tr>
<tr>
<td style="text-align: left;">Stationary confounder</td>
<td style="text-align: left;">Its distribution is fixed and it cannot be represented as <br> functions of domain index or smooth functions of time.</td>
</tr>
<tr>
<td style="text-align: left;">Nonstationary confounder</td>
<td style="text-align: left;">Its distribution changes across domains or over time and <br> it cannot be represented as functions of domain index or <br> smooth functions of time index, respectively.</td>
</tr>
</tbody>
</table>
<p>Table 1: Descriptions of different types of confounders (latent common causes).
where $\mathbf{g}^{i}(C) \subseteq\left{g_{l}(C)\right}<em i="i">{l=1}^{L}$ denotes the set of confounders that influence $V</em>(C)$ for $i \neq j$. The variable $C$ can be the domain or time index. In special cases, e.g., the case with multiple domains and all of which have nonstationarity, $C$ has two dimensions: one is the domain index and the other is the time index. The SEM given in Eq. 2 does not have any restrictions on data distributions or functional classes.}$ (it is an empty set if there is no confounder behind $V_{i}$ and any other variable), $\theta_{i}(C)$ denotes the effective parameters in the model that are also assumed to be functions of $C$, and $\epsilon_{i}$ is a disturbance term that is independent of $C$ and $\mathrm{PA}^{i}$ and has a non-zero variance (i.e., the model is not deterministic). We also assume that the $\epsilon_{i}$ 's are mutually independent. Note that $\theta_{i}(C)$ is specific to $V_{i}$ and is independent of $\theta_{j</p>
<p>In this paper we treat $C$ as a random variable, and so there is a joint distribution over $\mathbf{V} \cup\left{g_{l}(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>(C)\right}<em l="l">{i=1}^{m}$. We assume that this distribution is Markov and faithful to the graph resulting from the following additions to $G$ (which, recall, is the causal structure over $\mathbf{V})$ : add $\left{g</em>(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>(C)\right}<em i="i">{i=1}^{m}$ to $G$, and for each $i$, add an arrow from each variable in $\mathbf{g}^{i}(C)$ to $V</em>$. Specifically, the assumption is summarized below.}$ and add an arrow from $\theta_{i}(C)$ to $V_{i}$. We refer to this augmented graph as $G^{\text {aug }}$. Obviously, $G$ is simply the induced subgraph of $G^{\text {aug }}$ over $\mathbf{V</p>
<p>Assumption 2 The joint distribution over $\mathbf{V} \cup\left{g_{l}(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>$. In addition, there is no selection bias; i.e., the observed data are perfect random samples from the populations implied by the causal model.}(C)\right}_{i=1}^{m}$ is Markov and faithful to the augmented graph $G^{\text {aug }</p>
<p>The distribution change across domains or over time can be considered in the following way. In the case when $C$ is the domain index, $C$ follows a uniform distribution over all possible values, and we have a particular way to generate its value: all possible values are generated once, resulting in domain indices. In the case when $C$ is the time index, we take time to be a special random variable which follows a uniform distribution over the considered time period, with the corresponding data points evenly sampled at a certain sampling frequency. Correspondingly, the generating process of nonstationary data can be considered as follows: we generate random values from $C$, and then we generate data points over $\mathbf{V}$ according to the SEM in (2). The generated data points are then sorted in ascending order according to the values of $C$. In other words, we observe the distribution $P(\mathbf{V} \mid C)$, where $P(\mathbf{V} \mid C)$ may change across different values of $C$, resulting in non-identical distributions of data.</p>
<h1>3.2 Detection of Changing Modules and Recovery of Causal Skeleton</h1>
<p>In this section, we propose a method to detect variables whose causal modules change and infer the skeleton of $G$. The basic idea is simple: we use the (observed) variable $C$ as a surrogate for the unobserved $\left{g_{l}(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>(C)\right}<em l="l">{i=1}^{m}$, or in other words, we take $C$ to capture $C$-specific information. We now show that given the assumptions in Section 3.1, we can apply conditional independence tests to $\mathbf{V} \cup C$ to detect variables with changing modules and recover the skeleton of $G$. We consider $C$ as a surrogate variable (it itself is not a causal variable, it is always available, and confounders and changing parameters are its functions): by adding only $C$ to the variable set $\mathbf{V}$, the skeleton of $G$ and the changing causal modules can be estimated as if $\left{g</em>(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>$ were known. This is achieved by Algorithm 1 and supported by Theorem 1.}(C)\right}_{i=1}^{m</p>
<p>Algorithm 1 Detection of Changing Modules and Recovery of Causal Skeleton</p>
<ol>
<li>Build a complete undirected graph $U_{\mathcal{G}}$ on the variable set $\mathbf{V} \cup C$.</li>
<li>(Detection of changing modules) For each $i$, test for the marginal and conditional independence between $V_{i}$ and $C$. If they are independent given a subset of $\left{V_{k} \mid k \neq i\right}$, remove the edge between $V_{i}$ and $C$ in $U_{\mathcal{G}}$.</li>
<li>(Recovery of causal skeleton) For every $i \neq j$, test for the marginal and conditional independence between $V_{i}$ and $V_{j}$. If they are independent given a subset of $\left{V_{k} \mid k \neq\right.$ $i, k \neq j} \cup{C}$, remove the edge between $V_{i}$ and $V_{j}$ in $U_{\mathcal{G}}$.</li>
</ol>
<p>The procedure given in Algorithm 1 outputs an undirected graph $U_{\mathcal{G}}$ that contains $C$ as well as $\mathbf{V}$. In Step 2, whether a variable $V_{i}$ has a changing module is decided by whether $V_{i}$ and $C$ are independent conditional on some subset of other variables. The justification for one side of this decision is trivial. If $V_{i}$ 's module does not change, that means $P\left(V_{i} \mid \mathrm{PA}^{i}\right)$ remains the same for every value of $C$, and so $V_{i} \Perp C \mid \mathrm{PA}^{i}$. Thus, if $V_{i}$ and $C$ are not independent conditional on any subset of other variables, $V_{i}$ 's module changes with $C$, which is represented by an edge between $V_{i}$ and $C$. Conversely, we assume that if $V_{i}$ 's module changes, which entails that $V_{i}$ and $C$ are not independent given $\mathrm{PA}^{i}$, then $V_{i}$ and $C$ are not independent given any other subset of $\mathbf{V} \backslash\left{V_{i}\right}$. If this assumption does not hold, then we only claim to detect some (but not necessarily all) variables with changing modules.</p>
<p>Step 3 aims to discover the skeleton of the causal structure over $\mathbf{V}$. It leverages the results from Step 2: if neither $V_{i}$ nor $V_{j}$ is adjacent to $C$, then $C$ does not need to be involved in the conditioning set. In practice, one may apply any constraint-based search procedures on $\mathbf{V} \cup C$, e.g., SGS and PC (Spirtes et al., 1993). Its (asymptotic) correctness is justified by the following theorem:</p>
<p>Theorem 1 Given Assumptions 1 and 2, for every $V_{i}, V_{j} \in \mathbf{V}, V_{i}$ and $V_{j}$ are not adjacent in $G$ if and only if they are independent conditional on some subset of $\left{V_{k} \mid k \neq i, k \neq j\right} \cup{C}$.</p>
<p>Basic idea of the proof. For a complete proof see Appendix A. The "only if" direction is proved by making use of the weak union property of conditional independence repeatedly, the fact that all $g_{l}(C)$ and $\theta_{i}(C)$ are deterministic functions of $C$, some implications of the</p>
<p>SEMs Eq. 2, the assumptions in Section 3.1, and the properties of mutual information given in Madiman (2008). The "if" direction is shown based on the faithfulness assumption on $G^{\text {aug }}$ and the fact that $\left{g_{l}(C)\right}<em i="i">{l=1}^{L} \cup\left{\theta</em>$ is a deterministic function of $C$.}(C)\right}_{i=1}^{m</p>
<p>Furthermore, for any pair of nonadjacent variables $V_{i}$ and $V_{j}$ with $V_{i}-C$ and $V_{j}-C$, we can easily detect whether there are pseudo confounders behind $V_{i}$ and $V_{j}$ from the independence test results derived from Algorithm 1:</p>
<ol>
<li>If $\forall \mathbf{V}<em i="i">{k} \subseteq \mathbf{V} \backslash\left{V</em>}, V_{j}\right}, V_{i} \Perp V_{j} \mid \mathbf{V<em k_prime="k^{\prime">{k}$, and $\exists \mathbf{V}</em>}} \subseteq \mathbf{V} \backslash\left{V_{i}, V_{j}\right}$, so that $V_{i} \Perp V_{j} \mid\left{\mathbf{V<em i="i">{k^{\prime}}, C\right}$, then there exist pseudo confounders behind $V</em>$.}$ and $V_{j</li>
<li>If $\exists \mathbf{V}<em i="i">{k} \subseteq \mathbf{V} \backslash\left{V</em>}, V_{j}\right}$, so that $V_{i} \Perp V_{j} \mid \mathbf{V<em i="i">{k}$, then there is no pseudo confounder behind $V</em>$.
Note that in Algorithm 1, it is crucial to use a general, nonparametric conditional independence test, for how variables depending on $C$ is unknown and usually very nonlinear. In this work, we use the kernel-based conditional independence test (KCI-test, Zhang et al., 2011) to capture the dependence on $C$ in a nonparametric way. By contrast, if we use, for example, tests of vanishing partial correlations, as is widely used in the neuroscience community, the proposed method may not work well.}$ and $V_{j</li>
</ol>
<p>Moreover, it is worth noting that the estimated graphical representation by Algorithm 1 naturally follows the principle of minimal changes, which was explicitly formulated by Ghassami et al. (2018). This is because faithfulness on the augmented graph implies the edge minimality condition in the graphical representation. Any variable adjacent to $C$ in the augmented graph has a changing mechanism, and the estimated graph by Algorithm 1 has as few edges involving $C$ as possible; hence it has the smallest number of changing causal mechanisms (or conditional distributions).</p>
<h1>4. CD-NOD Phase II: Distribution Shifts Benefit Causal Direction Determination</h1>
<p>We now show that introducing the additional variable $C$ as a surrogate not only allows us to infer the skeleton of the causal structure but also facilitates the determination of some causal directions. Let us call those variables that are adjacent to $C$ in the output of Algorithm 1 " $C$-specific variables", which are actually the effects of changing causal modules. For each $C$-specific variable $V_{k}$, it is possible to determine the direction of every edge which has an endpoint on $V_{k}$. Let $V_{l}$ be any variable adjacent to $V_{k}$ in the output of Algorithm 1. Then there are two possible scenarios to consider:
$\mathrm{S}<em l="l">{1} . V</em>$ (Spirtes et al., 1993; Pearl, 2000). There are two possible situations:
1.a If $V_{l}$ and $C$ are independent given a set of variables excluding $V_{k}$, then the triple is a V-structure, and we have $V_{k} \leftarrow V_{l}$.
1.b Otherwise, if $V_{l}$ and $C$ are independent given a set of variables including $V_{k}$, then the triple is not a V-structure, and we have $V_{k} \rightarrow V_{l}$.}$ is not adjacent to $C$. Then $C-V_{k}-V_{l}$ forms an unshielded triple. For practical purposes, we take the direction between $C$ and $V_{k}$ as $C \rightarrow V_{k}$ (though we do not claim $C$ to be a cause in any substantial sense). Then we can use standard orientation rules for unshielded triples to orient the edge between $V_{k}$ and $V_{l</p>
<p>$\mathrm{S}<em l="l">{2} . V</em>}$ is also adjacent to $C$. This case is more complex than $\mathrm{S<em k="k">{1}$, but it is still possible to identify the causal direction between $V</em>$, based on the principle that $P$ (cause) and $P($ effect $/$ cause $)$ change independently; a heuristic method is given in Section 4.2.}$ and $V_{l</p>
<p>The procedure in $\mathrm{S}<em 2="2">{1}$, which will be further discussed in Section 4.1, contains the methods proposed in Hoover (1990); Tian and Pearl (2001); Peters et al. (2016) for causal discovery from changes as special cases. It may also be interpreted as special cases of the principle underlying the method for $\mathrm{S}</em>$ : if one of $P$ (cause) and $P$ (effect/cause) changes while the other remains invariant, they are clearly independent.</p>
<h1>4.1 Causal Direction Identification by Generalization of Invariance</h1>
<p>There exist methods for causal discovery from differences among multiple data sets (Hoover, 1990; Tian and Pearl, 2001; Peters et al., 2016) that explore invariance of causal mechanisms. They used linear models to represent causal mechanisms and, as a consequence, the invariance of causal mechanisms can be assessed by checking whether the involved parameters change across data sets or not. Actually, $\mathrm{S}<em i="i">{1 . b}$ above provides a nonparametric way to achieve this in light of nonparametric conditional independence tests. For any variable $V</em>\right)$ is invariant across different values of $C$ if and only if}$ and a set of variables $\mathbf{S}$, the conditional distribution $P\left(V_{i} \mid \mathbf{S</p>
<p>$$
P\left(V_{i} \mid \mathbf{S}, C=c_{1}\right)=P\left(V_{i} \mid \mathbf{S}, C=c_{2}\right), \forall c_{1} \text { and } c_{2}
$$</p>
<p>This is exactly the condition under which $V_{i} \Perp C \mid \mathbf{S}$. In other words, testing for invariance (or homogeneity) of the conditional distribution is naturally achieved by performing a conditional independence test on $V_{i}$ and $C$ given the set of variables $\mathbf{S}$, for which there exist off-the-shelf algorithms and implementations. When $\mathbf{S}$ is the empty set, this reduces to a test of marginal independence between $V_{i}$ and $C$, or a test of homogeneity of $P\left(V_{i}\right)$.</p>
<p>In $\mathrm{S}<em l="l">{1 . a}$, we have the invariance of $P\left(V</em>}\right)$ (i.e., $P$ (cause)) when the causal mechanism, represented by $P\left(V_{k} \mid V_{l}\right)$ (i.e., $P($ effect/cause $)$ ), changes, which is complementary to the invariance of causal mechanisms in $\mathrm{S<em i="i">{1 . b}$. The (conditional) independence test results between $V</em>$. The procedure is summarized in Algorithm 2.}$ and $C$ are readily available from Algorithm 1 and can be applied to determine causal directions between variables which satisfy $\mathrm{S}_{1</p>
<p>Algorithm 2 Causal Direction Identification by Generalization of Invariance</p>
<ol>
<li>Input: causal skeleton $U_{\mathcal{G}}$ from Algorithm 1.</li>
<li>Orient $C \rightarrow V_{k}$, for any variable which is adjacent to $C$.</li>
<li>For any unshielded triple with $C \rightarrow V_{k}-V_{l}$, where $V_{l}$ is not adjacent to $C$,
a. if $V_{l} \Perp C \mid \mathbf{S}$, with $\mathbf{S} \subseteq \mathbf{V}$ and $\mathbf{S} \wedge V_{k}=\emptyset$, orient $V_{k} \leftarrow V_{l}$;
b. if $V_{l} \Perp C \mid \mathbf{S}$, with $\mathbf{S} \subseteq \mathbf{V}$ and $V_{k} \in \mathbf{S}$, orient $V_{k} \rightarrow V_{l}$.</li>
<li>Output: partially oriented graph $U_{\mathcal{G}}$ using the property of generalization of invariance.</li>
</ol>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: An illustration of a two-variable case: $V_{1} \rightarrow V_{2}$ with corresponding parameters $\theta_{1}(C)$ and $\theta_{2}(C)$ changing independently.</p>
<p>Naturally, both invariance properties above are particular cases of the principle of independent changes of causal modules underlying the method for $\mathrm{S}_{2}$ : if one of $P$ (cause) and $P$ (effect $\mid$ cause) changes while the other remains invariant, they are clearly independent. Usually, there is no reason why only one of them could change, so the above invariance properties are rather restrictive. The property of independent changes holds in rather generic situations, e.g., when there is no confounder behind cause and effect. Below we will propose an algorithm for causal direction determination based on independent changes of causal modules.</p>
<h1>4.2 Causal Direction Identification by Independently Changing Modules</h1>
<p>We now develop a method to handle $\mathrm{S}<em 1="1">{2}$ above. To clearly express the idea, let us start with a two-variable case: suppose $V</em>$.}$ and $V_{2}$ are adjacent and are both adjacent to $C$. We aim to identify the causal direction between them, which, without loss of generality, we assume to be $V_{1} \rightarrow V_{2</p>
<p>Figure 3 shows the case where the involved changing parameters, $\theta_{1}(C)$ and $\theta_{2}(C)$, are independent, i.e., $P\left(V_{1} ; \theta_{1}\right)$ and $P\left(V_{2} \mid V_{1} ; \theta_{2}\right)$ change independently (we dropped the argument $C$ in $\theta_{1}$ and $\theta_{2}$ to simplify notation).</p>
<p>For the reverse direction, one can decompose the joint distribution of $\left(V_{1}, V_{2}\right)$ according to</p>
<p>$$
P\left(V_{1}, V_{2} ; \theta_{1}^{\prime}, \theta_{2}^{\prime}\right)=P\left(V_{2} ; \theta_{2}^{\prime}\right) P\left(V_{1} \mid V_{2} ; \theta_{1}^{\prime}\right)
$$</p>
<p>where $\theta_{1}^{\prime}$ and $\theta_{2}^{\prime}$ are assumed to be sufficient for the corresponding distribution modules $P\left(V_{2}\right)$ and $P\left(V_{1} \mid V_{2}\right)$. Generally speaking, $\theta_{1}^{\prime}$ and $\theta_{2}^{\prime}$ are not independent, because they are determined jointly by $\theta_{1}$ and $\theta_{2}$.</p>
<p>Now we face the problem of how to compare the dependence between $\theta_{1}$ and $\theta_{2}$ with that between $\theta_{1}^{\prime}$ and $\theta_{2}^{\prime}$. Since $\theta$ is assumed to be sufficient for the corresponding distribution module, it is equivalent to compare the dependence between $P\left(V_{1}\right)$ and $P\left(V_{2} \mid V_{1}\right)$ with that between $P\left(V_{2}\right)$ and $P\left(V_{1} \mid V_{2}\right)$.</p>
<p>The idea that causal modules are independent is not new (Pearl, 2000), but note that in a stationary situation where each module is fixed, such independence is very difficult, if not impossible, to test. By contrast, in the situation we are considering presently, both $P\left(V_{1}\right)$ and $P\left(V_{2} \mid V_{1}\right)$ are changing, and we can try to measure the extent to which variation in $P\left(V_{1}\right)$ and variation in $P\left(V_{2}\right)$ are dependent (and similarly for $P\left(V_{2}\right)$ and $P\left(V_{1} \mid V_{2}\right)$ ). This is the sense in which distribution change actually helps in the identification of causal directions,</p>
<p>and as far as we know, this is the first time that such an advantage is exploited in the case where both $P$ (cause) and $P$ (effect $\mid$ cause) change.</p>
<p>We extend the Hilbert Schmidt Independence Criterion (HSIC, Gretton et al., 2008) to measure the dependence between causal modules. To do so, we first develop a novel kernel embedding of nonstationary conditional distributions which does not rely on sliding windows and estimate their corresponding Gram matrices in Section 4.2.1, which will be used in the extended HSIC and the causal direction determination rule in Section 4.2.2. In Section 4.2.3, we propose an algorithm for causal direction determination in multi-variable cases by taking advantage of independent changes.</p>
<h1>4.2.1 Kernel Embedding of Constructed Joint Distributions</h1>
<p>Notation Throughout this section, we use the following notation. Let $X$ be a random variable on domain $\mathcal{X}$, and $(\mathcal{H}, k)$ be a Reproducing Kernel Hilbert Space (RKHS) with a measurable kernel on $\mathcal{X}$. Let $\phi(x) \in \mathcal{H}$ represent the feature map for each $x \in \mathcal{X}$, with $\phi$ : $\mathcal{X} \rightarrow \mathcal{H}$. We assume integrability: $E_{X}[k(X, X)] \leq \infty$. Similar notations are for variables $Y$ and $C$. The cross-covariance operator $C_{Y X}: \mathcal{H} \rightarrow \mathcal{G}$ is defined as $C_{Y X}:=E_{Y X}\left[\phi(X) \otimes \psi(Y)\right]$, where $\mathcal{G}$ is the RKHS associated with $Y$.</p>
<p>We represent causal modules $P\left(V_{i} \mid \mathrm{PA}^{i}, C\right)$ by kernel embedding. Intuitively, to represent the kernel embedding of changing causal modules, we need to consider $P\left(V_{i} \mid \mathrm{PA}^{i}, C\right)$ for each value of $C$ separately. If $C$ is a domain index, for each value of $C$ we have a dataset of $\left(V_{i}, \mathrm{PA}^{i}\right)$. If $C$ is a time index, one may use a sliding window to use the data of $\left(V_{i}, \mathrm{PA}^{i}\right)$ in the window of length $L$ centered at $C=c$. However, in some cases, it might be hard to find an appropriate window length $L$, especially when the causal module changes fast. In the following, we propose a way to estimate the kernel embedding of changing causal modules on the whole dataset, avoiding window segmentation. For the sake of conciseness, below we use $Y$ and $X$ to denote $V_{i}$ and $\mathrm{PA}^{i}$, respectively.</p>
<p>Suppose that there are $N$ samples for each variable. Instead of working with $P(Y \mid X, C=$ $\left.c_{n}\right)(n=1, \cdots, N)$ directly, we "virtually" construct a particular distribution $\tilde{P}(\underline{Y}, X \mid C=$ $\left.c_{n}\right)$ as follows: ${ }^{3}$</p>
<p>$$
\tilde{P}\left(\underline{Y}, X \mid C=c_{n}\right)=P\left(Y \mid X, C=c_{n}\right) P(X)
$$</p>
<p>The embedding of this "joint distribution" of $X$ and $Y$ is simpler than that of the conditional of $Y$ given $X$. Since $P(X)$ does not depend on $C$ and its support is rich enough to contain that of $P\left(X \mid C=c_{n}\right)$, one can see that whenever there are changes in $P\left(Y \mid X, C=c_{n}\right)$ across different values of $c_{n}$, there must be changes in $\tilde{P}\left(\underline{Y}, X \mid C=c_{n}\right)$, and vice versa. In other words, the constructed distribution $\tilde{P}\left(\underline{Y}, X \mid C=c_{n}\right)$ captures changes in $P(Y \mid X, C=c_{n})$ across different $c_{n}$. We let $\tilde{P}\left(\underline{Y}, X, C=c_{n}\right)=P\left(Y \mid X, C=c_{n}\right) P(X) P\left(C=c_{n}\right)$.</p>
<p>Proposition 1 shows that the kernel embedding of the distribution $\tilde{P}\left(\underline{Y}, X \mid C=c_{n}\right)$ can be estimated on the whole data set, without window segmentation.</p>
<p>Proposition 1 Let $X$ represent the direct causes of $Y$, and suppose that they have $N$ observations. The kernel embedding of distribution $\tilde{P}\left(\underline{Y}, X \mid C=c_{n}\right)$ can be represented as</p>
<p>$$
\hat{\tilde{\mu}}<em n="n">{\underline{Y}, X \mid C=c</em>}}=\frac{1}{n} \boldsymbol{\Phi<em _mathbf_x="\mathbf{x">{\mathbf{y}}\left(\mathbf{K}</em>}} \odot \mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{c}}+\lambda I\right)^{-1} \operatorname{diag}\left(\mathbf{k}</em>}, c_{n}}\right) \mathbf{K<em _mathbf_x="\mathbf{x">{\mathbf{x}} \boldsymbol{\Phi}</em>
$$}}^{\boldsymbol{\tau}</p>
<ol>
<li>Here we use $\underline{Y}$ instead of $Y$ to emphasize that in this constructed distribution $Y$ and $X$ are not symmetric.</li>
</ol>
<p>where $\boldsymbol{\Phi}<em 1="1">{\mathbf{y}}:=\left[\phi\left(y</em>}\right), \ldots, \phi\left(y_{N}\right)\right], \boldsymbol{\Phi<em 1="1">{\mathbf{x}}:=\left[\phi\left(x</em>}\right), \ldots, \phi\left(x_{N}\right)\right], \mathbf{k<em n="n">{\mathbf{c}, c</em>}}:=\left[k\left(c_{1}, c_{n}\right), \ldots, k\left(c_{N}, c_{n}\right)\right]^{\top}$, $\mathbf{K<em t="t">{\mathbf{x}}\left(x</em>}, x_{t^{\prime}}\right)=\left\langle\phi\left(x_{t}\right), \phi\left(x_{t^{\prime}}\right)\right\rangle, \mathbf{K<em t="t">{\mathbf{c}}\left(c</em>\right)\right\rangle$, and $\odot$ represents point-wise product.}, c_{t^{\prime}}\right)=\left\langle\phi\left(c_{t}\right), \phi\left(c_{t^{\prime}</p>
<p>The detailed proof of proposition 1 is given in Appendix B. Next we estimate the $N \times N$ Gram matrix of $\hat{\tilde{\mu}}<em _underline_Y="\underline{Y">{\underline{Y}, X \mid C=c}$. We consider different kernels for the estimation of Gram matrix. Let $M</em>}, X}^{l}$ represent the Gram matrix of $\hat{\tilde{\mu}<em _underline_Y="\underline{Y">{\underline{Y}, X \mid C=c}$ with a linear kernel, and $M</em>$ with a Gaussian kernel.}, X}^{Q}$ the Gram matrix of $\hat{\tilde{\mu}}_{\underline{Y}, X \mid C=c</p>
<p>If we use a linear kernel, the $\left(c, c^{\prime}\right)$ th entry of the Gram matrix $M_{\underline{Y}, X}^{l}$ is the inner product between $\hat{\tilde{\mu}}<em _underline_Y="\underline{Y">{\underline{Y}, X \mid C=c}$ and $\hat{\tilde{\mu}}</em>$ :}, X \mid C=c^{\prime}</p>
<p>$$
\begin{aligned}
M_{\underline{Y}, X}^{l}\left(c, c^{\prime}\right) &amp; \triangleq \operatorname{tr}\left(\hat{\tilde{\mu}}<em _underline_Y="\underline{Y">{\underline{Y}, X \mid C=c}^{\top} \hat{\tilde{\mu}}</em>\right) \
&amp; =\frac{1}{N^{2}} \mathbf{k}}, X \mid C=c^{\prime}<em _mathbf_x="\mathbf{x">{\mathbf{c}, c}^{\top}\left[\mathbf{K}</em>}}^{3} \odot\left(\left(\mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{x}} \odot \mathbf{K}</em>}}+\lambda I\right)^{-1} \mathbf{K<em _mathbf_x="\mathbf{x">{\mathbf{y}}\left(\mathbf{K}</em>}} \odot \mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{c}}+\lambda I\right)^{-1}\right)\right] \mathbf{k}</em>
\end{aligned}
$$}, c^{\prime}</p>
<p>which is the $\left(c, c^{\prime}\right)$ th entry of the matrix</p>
<p>$$
\mathbf{M}<em _mathbf_c="\mathbf{c">{\underline{Y}, X}^{l}=\frac{1}{N^{2}} \mathbf{K}</em>}}\left[\mathbf{K<em _mathbf_x="\mathbf{x">{\mathbf{x}}^{3} \odot\left(\left(\mathbf{K}</em>}} \odot \mathbf{K<em _mathbf_y="\mathbf{y">{\mathbf{c}}+\lambda I\right)^{-1} \mathbf{K}</em>}}\left(\mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{x}} \odot \mathbf{K}</em>
$$}}+\lambda I\right)^{-1}\right)\right] \mathbf{K}_{\mathbf{c}</p>
<p>If we use a Gaussian kernel with kernel width $\sigma_{2}$, the Gram matrix is given by</p>
<p>$$
\begin{aligned}
M_{\underline{Y}, X}^{Q}\left(c, c^{\prime}\right) &amp; =\exp \left(-\frac{\left|\tilde{\mu}<em _underline_Y="\underline{Y">{\underline{Y}, X \mid C=c}-\tilde{\mu}</em>\right|}, X \mid C=c^{\prime}<em 2="2">{F}^{2}}{2 \sigma</em>\right) \
&amp; =\exp \left(-\frac{M_{\underline{Y}, X}^{l}(c, c)+M_{\underline{Y}, X}^{l}\left(c^{\prime}, c^{\prime}\right)-2 M_{\underline{Y}, X}^{l}\left(c^{\prime}, c\right)}{2 \sigma_{2}^{2}}\right)
\end{aligned}
$$}^{2}</p>
<p>where $|\cdot|_{F}$ denotes the Frobenius norm. This can be represented in matrix notation as</p>
<p>$$
\mathbf{M}<em _underline_Y="\underline{Y">{\underline{Y}, X}^{Q}=\exp \left(-\frac{\operatorname{diag}\left(\mathbf{M}</em>}, X}^{l}\right) \cdot \mathbf{1<em N="N">{N}+\mathbf{1}</em>} \cdot \operatorname{diag}\left(\mathbf{M<em _underline_Y="\underline{Y">{\underline{Y}, X}^{l}\right)-2 \mathbf{M}</em>\right)
$$}, X}^{l}}{2 \sigma_{2}^{2}</p>
<p>where $\operatorname{diag}(\cdot)$ sets all off-diagonal entries zero, and $\mathbf{1}_{N}$ is an $N \times N$ matrix with all entries being 1 .</p>
<p>Excitingly, we can see that with our methods, we do not need to explicitly learn the high-dimensional kernel embedding $\tilde{\mu}_{\underline{Y}, X \mid C=c}$ for each $c$. With the kernel trick, the final Gram matrix can be represented by $N \times N$ kernel matrices directly.</p>
<p>There are several hyperparameters to set. The hyperparameters associated with $\mathbf{K}<em _mathbf_c="\mathbf{c">{\mathbf{x}}, \mathbf{K}</em>}}$, and the regularization parameter $\lambda$ in equation (6) are learned through a Gaussian process regression framework: they are learned by maximizing the marginal likelihood of $Y$. For the hyperparameters associated with $\mathbf{K<em 2="2">{\mathbf{y}}$ and the kernel with $\sigma</em>$ in equation (7), we set them with empirical values; please refer to Zhang et al. (2011) for details.</p>
<p>Change in marginal distributions. As a special case, when we are concerned with how the marginal distribution of $Y$ changes with $C$, i.e., when $X=\emptyset$, we directly make use of</p>
<p>$$
\mu_{Y \mid C=c_{n}}=\mathcal{C}<em C="C">{Y C} \mathcal{C}</em>\right)
$$}^{-1} \phi\left(c_{n</p>
<p>This can also be obtained by constraining $X$ in $\hat{\mu}<em n="n">{\underline{Y}, X \mid C=c</em>$ to take a fixed value. Its empirical estimate is}</p>
<p>$$
\begin{aligned}
\hat{\mu}<em n="n">{Y \mid C=c</em>}} &amp; =\frac{1}{N} \boldsymbol{\Phi<em _mathbf_c="\mathbf{c">{\mathbf{y}} \boldsymbol{\Phi}</em>}}^{\dagger}\left(\frac{1}{n} \boldsymbol{\Phi<em _mathbf_c="\mathbf{c">{\mathbf{c}} \boldsymbol{\Phi}</em> \
&amp; =\boldsymbol{\Phi}}}^{\top}+\lambda I\right)^{-1} \phi_{c_{n}<em _mathbf_c="\mathbf{c">{\mathbf{y}}\left(\mathbf{K}</em>}}+\lambda I\right)^{-1} \mathbf{k<em n="n">{\mathbf{c}, c</em>
\end{aligned}
$$}</p>
<p>Then $\left(c, c^{\prime}\right)$ entry of the Gram matrix with a linear kernel is:</p>
<p>$$
\begin{aligned}
M_{Y}^{l}\left(c, c^{\prime}\right) &amp; \triangleq \hat{\mu}<em C="c^{\prime" Y="Y" _mid="\mid">{Y \mid C=c}^{\top} \hat{\mu}</em> \
&amp; =\mathbf{k}}<em _mathbf_c="\mathbf{c">{\mathbf{c}, c}^{\top}\left(\mathbf{K}</em>}}+\lambda I\right)^{-1} \boldsymbol{\Phi<em _mathbf_y="\mathbf{y">{\mathbf{y}}^{\top} \boldsymbol{\Phi}</em>}}\left(\mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{c}}+\lambda I\right)^{-1} \mathbf{k}</em> \
&amp; =\mathbf{k}}, c^{\prime}<em _mathbf_c="\mathbf{c">{\mathbf{c}, c}^{\top}\left(\mathbf{K}</em>}}+\lambda I\right)^{-1} \mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{y}}\left(\mathbf{K}</em>
\end{aligned}
$$}}+\lambda I\right)^{-1} \mathbf{k}_{\mathbf{c}, c^{\prime}</p>
<p>which is the $\left(c, c^{\prime}\right)$ th entry of</p>
<p>$$
\mathbf{M}<em _mathbf_c="\mathbf{c">{Y}^{l}=\mathbf{K}</em>}}\left(\mathbf{K<em _mathbf_y="\mathbf{y">{\mathbf{c}}+\lambda I\right)^{-1} \mathbf{K}</em>}}\left(\mathbf{K<em _mathbf_c="\mathbf{c">{\mathbf{c}}+\lambda I\right)^{-1} \mathbf{K}</em>
$$}</p>
<p>For a Gaussian kernel with kernel with $\sigma_{2}$, the Gram matrix is</p>
<p>$$
\mathbf{M}<em X="X" Y="Y">{Y}^{G}=\exp \left(-\frac{\operatorname{diag}\left(\mathbf{M}</em>}^{l}\right) \cdot \mathbf{1<em N="N">{N}+\mathbf{1}</em>} \cdot \operatorname{diag}\left(\mathbf{M<em X="X" Y="Y">{Y X}^{l}\right)-2 \mathbf{M}</em>\right)
$$}^{l}}{2 \sigma_{2}^{2}</p>
<h1>4.2.2 Two-Variable Case</h1>
<p>In this section, we extend HSIC to measure the dependence between causal modules, based on which we determine causal directions.</p>
<p>For simplicity, let us start with the two-variable case: suppose that $X$ and $Y$ are adjacent and both are adjacent to $C$. We aim to identify the causal direction between them, which, without loss of generality, we assume to be $X \rightarrow Y$. The guiding idea is that distribution shift may carry information that confirms the independence of causal modules, which, in the simple case we are considering, is the independence between $P(X)$ and $P(Y \mid X)$. If $P(X)$ and $P(Y \mid X)$ are independent but $P(Y)$ and $P(X \mid Y)$ are not, then the causal direction is inferred to be from $X$ to $Y$.</p>
<p>The dependence between $P(X)$ and $P(Y \mid X)$ can be measured by extending the HSIC (Gretton et al., 2008).</p>
<p>HSIC Given a set of observations $\left{\left(u_{1}, v_{1}\right),\left(u_{2}, v_{2}\right), \ldots,\left(u_{N}, v_{N}\right)\right}$ for variables $U$ and $V$, HSIC provides a measure of dependence and a statistic for testing their statistical independence. Roughly speaking, it measures the squared covariances between feature maps of $U$ and feature maps of $V$. Let $\mathbf{M}<em V="V">{U}$ and $\mathbf{M}</em>$ be the Gram matrices for $U$ and $V$ calculated on the sample, respectively. An estimator of HSIC is given by Gretton et al. (2008):</p>
<p>$$
\operatorname{HSIC}<em U="U">{U V}=\frac{1}{(N-1)^{2}} \operatorname{tr}\left(\mathbf{M}</em> H\right)
$$} H \mathbf{M}_{V</p>
<p>where $H$ is used to center the features, with entries $H_{i j}:=\delta_{i j}-N^{-1}$.</p>
<p>In what follows, we will use a normalized version of the estimated HSIC, which is invariant to the scale in $\mathbf{M}<em V="V">{U}$ and $\mathbf{M}</em>$ :</p>
<p>$$
\begin{aligned}
\operatorname{HSIC}<em U="U" V="V">{U V}^{N} &amp; =\frac{\operatorname{HSIC}</em>}}{\frac{1}{N-1} \operatorname{tr}\left(\mathbf{M<em V="V">{U} H\right) \cdot \frac{1}{N-1} \operatorname{tr}\left(\mathbf{M}</em> \
&amp; =\frac{\operatorname{tr}\left(\mathbf{M}} H\right)<em V="V">{U} H \mathbf{M}</em>} H\right)}{\operatorname{tr}\left(\mathbf{M<em V="V">{U} H\right) \operatorname{tr}\left(\mathbf{M}</em>
\end{aligned}
$$} H\right)</p>
<p>Dependence between Changing Modules In our case, we aim to check whether $P(Y \mid X)$ and $P(X)$ change independently along with $C$. We work with the estimate of their embeddings. Then we can think of $\left{\left(\hat{\mu}<em n="n">{X \mid C=c</em>}}, \hat{\bar{\mu}<em n="n">{\underline{Y}, X \mid C=c</em>$ as the observed data pairs and measure their dependence from the data pairs.}}\right)\right}_{n=1}^{N</p>
<p>This can be done by applying (the normalized version of) the estimate of HSIC given in Eq. 15 to the above data pairs. The expression then involves $\mathbf{M}<em C="C" X="X" _mid="\mid">{X}$, the Gram matrix of $\hat{\mu}</em>}$ at $C=c_{1}, c_{2}, \ldots, c_{N}$, and $\mathbf{M<em _underline_Y="\underline{Y">{\underline{Y} X}$, the Gram matrix of $\hat{\bar{\mu}}</em>$. In particular, the dependence between $P(Y \mid X)$ and $P(X)$ on the given data can be estimated by} X \mid C}$ at $C=c_{1}, c_{2}, \ldots, c_{N</p>
<p>$$
\hat{\Delta}<em X="X">{X \rightarrow Y}=\frac{\operatorname{tr}\left(\mathbf{M}</em>} H \mathbf{M<em X="X">{\underline{Y} X} H\right)}{\operatorname{tr}\left(\mathbf{M}</em>
$$} H\right) \operatorname{tr}\left(\mathbf{M}_{\underline{Y} X} H\right)</p>
<p>Similarly, for the hypothetical direction $Y \rightarrow X$ the dependence between $P(X \mid Y)$ and $P(Y)$ on the data is estimated by</p>
<p>$$
\hat{\Delta}<em Y="Y">{Y \rightarrow X}=\frac{\operatorname{tr}\left(\mathbf{M}</em>} H \mathbf{M<em Y="Y">{X Y} H\right)}{\operatorname{tr}\left(\mathbf{M}</em>
$$} H\right) \operatorname{tr}\left(\mathbf{M}_{X Y} H\right)</p>
<p>We then have the following rule to determine the causal direction between $X$ and $Y$.
Causal Direction Determination Rule Suppose that $X$ and $Y$ are two random variables with $N$ observations. We assume that $X$ and $Y$ are adjacent and both are adjacent to $C$ and assume no pseudo confounders behind them. The causal direction between $X$ and $Y$ is then determined according to the following rule:</p>
<ul>
<li>if $\hat{\Delta}<em X="X" Y="Y" _rightarrow="\rightarrow">{X \rightarrow Y}&lt;\hat{\Delta}</em>$, output $X \rightarrow Y$;</li>
<li>if $\hat{\Delta}<em X="X" Y="Y" _rightarrow="\rightarrow">{X \rightarrow Y}&gt;\hat{\Delta}</em>$, output $X \leftarrow Y$.</li>
</ul>
<p>In practice, there may exist pseudo confounders. In such a case, we set a threshold $\alpha$ on $\hat{\Delta}$. If $\hat{\Delta}<em X="X" Y="Y" _rightarrow="\rightarrow">{X \rightarrow Y}&gt;\alpha$ and $\hat{\Delta}</em>&gt;\alpha$, we conclude that there are pseudo confounders which influence both $X$ and $Y$ and leave the direction undetermined.</p>
<h1>4.2.3 With More Than Two Variables</h1>
<p>The causal direction determination rule in the two-variable case can be extended to learn causal directions in multi-variable cases. Suppose that we have $m$ observed random variables $\left{V_{i}\right}<em _mathcal_G="\mathcal{G">{i=1}^{m}$ and a partially oriented graph $U</em>}}$ derived from Algorithms 1 and 2. Let $\mathbf{V<em i="i">{S}$ be the subset of $\left{V</em>\right}<em i="i">{i=1}^{m}$, such that $V</em>} \in \mathbf{V<em i="i">{S}$ if and only if $V</em>$ 's causal module changes.</p>
<p>Note that generally speaking, different from the unconfounded two-variable case, when identifying the causal direction between an unoriented pair of adjacent variables, we need to remove the effect from their common causes. Thus, before moving forward, we first define deconfounding set and potential deconfounding set of a pair of adjacent variables in $U_{\mathcal{G}}$.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: An illustration of the definitions of minimal deconfounding set and minimal potential deconfounding set on a partially oriented graph.</p>
<p>Definition 1 (Deconfounding Set) $A$ set of variables $\mathbf{Z} \subseteq \mathbf{V} \backslash\left{V_{l}, V_{k}\right}$ is the deconfounding set of a pair of adjacent variables $\left(V_{l}, V_{k}\right)$, if
(i) no node in $\mathbf{Z}$ is a descendant of $V_{l}$ or $V_{k}$,
(ii) and $\mathbf{Z}$ blocks every path between $V_{l}$ and $V_{k}$ that contains arrows into $V_{l}$ and $V_{k}$.</p>
<p>Furthermore, a set of variables $\mathbf{Z}$ is the minimal deconfounding set of a pair of adjacent variables $\left(V_{l}, V_{k}\right)$, if any $\mathbf{Z}_{s} \subset \mathbf{Z}$ is not a deconfounding set.</p>
<p>Definition 2 (Potential Deconfounding Set) $A$ set of variables $\mathbf{Z} \subseteq \mathbf{V} \backslash\left{V_{l}, V_{k}\right}$ is the potential deconfounding set of a pair of adjacent variables $\left(V_{l}, V_{k}\right)$, if
(i) no node in $\mathbf{Z}$ is a descendant of $V_{l}$ or $V_{k}$,
(ii) $\mathbf{Z}$ blocks every path between $V_{l}$ and $V_{k}$ that does not contain an arrow out of $V_{l}$ or $V_{k}$,
(iii) and any $Z \in \mathbf{Z}$ is not in the deconfounding set.</p>
<p>Similarly, a set of variables $\mathbf{Z}$ is the minimal potential deconfounding set of a pair of adjacent variables $\left(V_{l}, V_{k}\right)$, if any subset $\mathbf{Z}_{s} \subset \mathbf{Z}$ is not a potential deconfounding set.</p>
<p>In Figure 4, for example, the set $\mathbf{Z}=\left{V_{3}\right}$ is a minimal deconfounding set of $\left(V_{1}, V_{2}\right)$, and the set $\mathbf{Z}=\left{V_{5}\right}$ is a minimal potential deconfounding set of $\left(V_{1}, V_{2}\right)$.</p>
<p>We take advantage of the independence between causal modules to identify directions. To efficiently identify causal directions using independent changes when there are multiple variables, we propose Algorithm 3, with the main procedure as follows. For each undirected pair $V_{l}, V_{k} \in \mathbf{V}<em k="k" l="l">{S}$, we denote their minimal deconfounding set by $\mathbf{Z}</em>}^{(1)}$ and their minimal potential deconfounding set by $\mathbf{Z<em k="k" l="l">{l k}^{(2)}$. Note that there may be multiple minimal deconfounding sets and multiple minimal potential deconfounding sets; to search for such sets more efficiently, in our implementation, we only consider those ones with every variable in $\mathbf{Z}</em>}^{(1)}$ and $\mathbf{Z<em l="l">{l k}^{(2)}$ being adjacent to $V</em>}$. Let $\mathbf{Z<em k="k" l="l">{l k}^{(2, n)}$ be a subset of $\mathbf{Z}</em>}^{(2)}$, where $n$ is the total cardinality of $\mathbf{Z<em k="k" l="l">{l k}^{(1)}$ and $\mathbf{Z}</em>}^{(2, n)}$; i.e., $\left|\mathbf{Z<em k="k" l="l">{l k}^{(1)}\right|+\left|\mathbf{Z}</em>}^{(2, n)}\right|=n$. We evaluate the dependence between $P\left(V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and $P\left(V_{l} \mid V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$, and that between $P\left(V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and $P\left(V_{k} \mid V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$. If we find that $P\left(V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \Perp P\left(V_{k} \mid V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and that $P\left(V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \Perp P\left(V_{l} \mid V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$, we output $V_{l} \rightarrow V_{k}$, and if there are unoriented edges from variables in $\mathbf{Z<em k="k">{l k}^{(2, n)}$ to $V</em>$, then we consider those variables as}$ or $V_{l</p>
<p>parents. Similarly, if we find that $P\left(V_{k}, \mathbf{Z}<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \Perp P\left(V_{l} \mid V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and that $P\left(V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \Perp P\left(V_{k} \mid V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>$, instead. Similar to the search procedure of PC, we start from $n=0$, evaluate the dependence between corresponding modules for each undirected pair, and then let $n=n+1$ and repeat the procedure until no unoriented pairs have the total cardinality of minimal deconfounding set and minimal potential deconfounding set greater than or equal to $n$.}^{(2, n)}\right)$, we output $V_{k} \rightarrow V_{l</p>
<p>Note that in Algorithm 3, we use dependence measures in (16) and (17) to determine the independence between causal modules. Particularly, we set a threshold $\alpha$. If the dependence measure $\hat{\Delta} \leq \alpha$, then the corresponding modules are independent; otherwise, they are dependent. For a pair of adjacent variables $V_{k}, V_{l} \in \mathbf{V}<em k="k">{S}$, if their direction is undetermined by Algorithm 3 and all their measured modules are dependent, then there exist pseudo confounders behind $V</em>$.}$ and $V_{l</p>
<p>Furthermore, for variables whose causal modules are stationary and which are adjacent only to variables with stationary modules, the causal directions between them cannot be determined by Algorithm 2 or 3. In such a case, one may further infer some causal directions by making use of Meek's orientation rules (Meek, 1995) used in PC.</p>
<p>To better illustrate the algorithm, we go through a simple example, for which the true graph and brief orientation procedures are given in Figure 5. Below is the precise orientation procedure.</p>
<ol>
<li>In step 1, we have observed variables $\left{V_{i}\right}<em i="i">{i=1}^{4}$, with $V</em>} \in \mathbf{V<em _mathcal_G="\mathcal{G">{S}$ for any $i$, and an unoriented graph $U</em>$ after Algorithms 1 and 2. Since all causal modules are changing, there is no invariance property that can be used for orientation determination in Algorithm 2.}}$ over $\left{V_{i}\right}_{i=1}^{4</li>
<li>In step 2, we start from $n=0$. For example, for the unoriented pair of adjacent variables $\left(V_{1}, V_{2}\right), \mathbf{Z}<em 12="12">{12}^{(1)}={\emptyset}$ and $\mathbf{Z}</em>$.
Then let $n=1$. For the unoriented pair $\left(V_{1}, V_{2}\right), \mathbf{Z}}^{(2, n)}={\emptyset}$. In this case, we have $P\left(V_{1}\right) \Perp P\left(V_{2} \mid V_{1}\right)$ and $P\left(V_{2}\right) \Perp P\left(V_{1} \mid V_{2}\right)$, and thus we cannot determine the direction between $V_{1}$ and $V_{2}$. Similarly, we cannot determine the direction between $V_{2}$ and $V_{4}$. For the unoriented pair $\left(V_{1}, V_{3}\right)$, we have that $P\left(V_{3}\right) \Perp P\left(V_{1} \mid V_{3}\right)$ and that $P\left(V_{1}\right) \Perp P\left(V_{3} \mid V_{1}\right)$, and thus we output $V_{3} \rightarrow V_{1}$. Similarly, we can determine the direction between $V_{3}$ and $V_{4}$ and output $V_{3} \rightarrow V_{4<em 12="12">{12}^{(1)}={\emptyset}$ and $\mathbf{Z}</em>}^{(2, n)}=\left{V_{3}\right}$. We then have that $P\left(V_{1}, V_{3}\right) \Perp P\left(V_{2} \mid V_{1}, V_{3}\right)$ and that $P\left(V_{2}, V_{3}\right) \Perp P\left(V_{1} \mid V_{2}, V_{3}\right)$, and thus we output $V_{1} \rightarrow V_{2}$. For the unoriented pair $\left(V_{2}, V_{4}\right), \mathbf{Z<em 3="3">{24}^{(1)}=\left{V</em>}\right}$ and $\mathbf{Z<em 4="4">{24}^{(2, n)}={\emptyset}$. We then have that $P\left(V</em>$.}, V_{3}\right) \Perp P\left(V_{2} \mid V_{4}, V_{3}\right)$ and that $P\left(V_{2}, V_{3}\right) \Perp P\left(V_{4} \mid V_{2}, V_{3}\right)$, and thus output $V_{4} \rightarrow V_{2</li>
<li>We output the fully identified causal graph.</li>
</ol>
<h1>4.3 Identifiability Conditions of CD-NOD</h1>
<p>In this section, we first give identifiability conditions of CD-NOD, and then we define the equivalence class that CD-NOD can identify if corresponding conditions do not hold.</p>
<p>We make use of independent changes and orientation rules, including discovering Vstructures and using orientation propagation, to determine causal directions. To fully identify the DAG, we ought to make some assumption on the change property of the distribution in wrong directions. In particular, we have the following assumption.</p>
<h1>Algorithm 3 Causal Direction Identification by Independent Changes of Causal Modules</h1>
<ol>
<li>Input: observations of $\left{V_{i}\right}<em S="S">{i=1}^{m}$, a subset $\mathbf{V}</em>} \subseteq \mathbf{V}\left(\forall V \in \mathbf{V<em _mathcal_G="\mathcal{G">{S}\right.$, $V$ has a changing causal module), a partially oriented causal graph $U</em>$ from Algorithms 1 and 2.}</li>
<li>$n=0$</li>
</ol>
<p>Repeat
Repeat
i. Select an unoriented pair of adjacent variables $\left(V_{l}, V_{k}\right)$, with $V_{l}, V_{k} \in \mathbf{V}<em k="k" l="l">{S}$.
A. Let $\mathbf{Z}</em>}^{(1)}$ be the set of minimal deconfounding set of $V_{k}$ and $V_{l}$; any $Z \in \mathbf{Z<em l="l">{l k}^{(1)}$ is adjacent to $V</em>$.
B. Let $\mathbf{Z}<em k="k" l="l">{l k}^{(2)}$ be the set of minimal potential deconfounding set; any $Z \in \mathbf{Z}</em>$.
ii. If $\left|\mathbf{Z}}^{(2)}$ is adjacent to $V_{l<em k="k" l="l">{l k}^{(1)}\right|+\left|\mathbf{Z}</em>\right| \geq n$, repeat
A. Take $\mathbf{Z}}^{(2)<em k="k" l="l">{l k}^{(2, n)} \subseteq \mathbf{Z}</em>}^{(2)}$, with $\left|\mathbf{Z<em k="k" l="l">{l k}^{(2, n)}\right|=n-\left|\mathbf{Z}</em>\right|$.
B. If $P\left(V_{k}, \mathbf{Z}}^{(1)<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \quad P\left(V_{l} \mid V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and $P\left(V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \not P\left(V_{k} \mid V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>$;
for $Z \in \mathbf{Z}}^{(2, n)}\right)$, output $V_{k} \rightarrow V_{l<em l="l">{l k}^{(2, n)}$ with $Z-V</em>$;
for $Z \in \mathbf{Z}}$, output $Z \rightarrow V_{l<em k="k">{l k}^{(2, n)}$ with $Z-V</em>$.
C. If $P\left(V_{k}, \mathbf{Z}}$, output $Z \rightarrow V_{k<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \not P\left(V_{l} \mid V_{k}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right)$ and $P\left(V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>}^{(2, n)}\right) \quad P\left(V_{k} \mid V_{l}, \mathbf{Z<em k="k" l="l">{l k}^{(1)}, \mathbf{Z}</em>$;
for $Z \in \mathbf{Z}}^{(2, n)}\right)$, output $V_{l} \rightarrow V_{k<em l="l">{l k}^{(2, n)}$ with $Z-V</em>$;
for $Z \in \mathbf{Z}}$, output $Z \rightarrow V_{l<em k="k">{l k}^{(2, n)}$ with $Z-V</em>$.
D. If one of the conditions in (B) and (C) holds, return to step (i);}$, output $Z \rightarrow V_{k</p>
<p>Until every unoriented pair of adjacent variables $\left(V_{l}, V_{k}\right)$, with $V_{l}, V_{k} \in \mathbf{V}<em _mathcal_G="\mathcal{G">{S}$, has been selected.
$n=n+1$.
3. Output: graph $U</em>$ oriented.}}$, with edges between variables in $\mathbf{V}_{S</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>True graph</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Graph after Algorithms 1 and 2</p>
<p>Independencies \&amp; Dependencies
Resulting graphs
$n=0: \quad P\left(V_{3}\right) \Perp P\left(V_{1} \mid V_{3}\right) \&amp; P\left(V_{1}\right) \Perp P\left(V_{3} \mid V_{1}\right)$.</p>
<p>So output $V_{3} \rightarrow V_{1}$.</p>
<p>$$
P\left(V_{3}\right) \Perp P\left(V_{4} \mid V_{3}\right) \&amp; P\left(V_{4}\right) \Perp P\left(V_{3} \mid V_{1}\right)
$$</p>
<p>So output $V_{3} \rightarrow V_{4}$.</p>
<p>$$
P\left(V_{1}, V_{3}\right) \Perp P\left(V_{2} \mid V_{1}, V_{3}\right) \&amp; P\left(V_{2}, V_{3}\right) \Perp P\left(V_{1} \mid V_{2}, V_{3}\right)
$$</p>
<p>So output $V_{1} \rightarrow V_{2}$.</p>
<p>$$
P\left(V_{4}, V_{3}\right) \Perp P\left(V_{2} \mid V_{4}, V_{3}\right) \&amp; P\left(V_{2}, V_{3}\right) \Perp P\left(V_{4} \mid V_{2}, V_{3}\right)
$$</p>
<p>So output $V_{4} \rightarrow V_{2}$.</p>
<p>Figure 5: An example to illustrate causal direction identification with Algorithm 3.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ol>
<li>More specifically, for data with multiple domains, we require that the confounders can be written as a function of the domain index (i.e., it does not change within a domain); for nonstationary time series, we require that the confounder is a smooth function of the time index. Roughly speaking, the smoothness constraint requires the gradient of the function to not change rapidly. In practice, one may specify the level of smoothness in advance (say, by assuming the function follows a Gaussian process prior and properly setting the kernel width to some range) or learn it from data by maximizing marginal likelihood or cross validation.</li>
</ol>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>