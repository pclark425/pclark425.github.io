<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1462 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1462</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1462</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-30.html">extraction-schema-30</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of curriculum learning approaches for teaching agents commonsense or science procedures in interactive text environments, including details about the curriculum strategy, task composition, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-fc56bbd824b907a7d047f4a37afd61788fa23067</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/fc56bbd824b907a7d047f4a37afd61788fa23067" target="_blank">Modeling Worlds in Text</a></p>
                <p><strong>Paper Venue:</strong> NeurIPS Datasets and Benchmarks</p>
                <p><strong>Paper TL;DR:</strong> A dataset that enables the creation of learning agents that can build knowledge graph-based world models of interactive narratives and baseline models using rules-based, question-answering, and sequence learning approaches are provided in addition to an analysis of the data and corresponding learning tasks.</p>
                <p><strong>Paper Abstract:</strong> We provide a dataset that enables the creation of learning agents that can build knowledge graph-based world models of interactive narratives. Interactive narratives -- or text-adventure games -- are partially observable environments structured as long puzzles or quests in which an agent perceives and interacts with the world purely through textual natural language. Each individual game typically contains hundreds of locations, characters, and objects -- each with their own unique descriptions -- providing an opportunity to study the problem of giving language-based agents the structured memory necessary to operate in such worlds. Our dataset provides 24198 mappings between rich natural language observations and: (1) knowledge graphs that reflect the world state in the form of a map; (2) natural language actions that are guaranteed to cause a change in that particular world state. The training data is collected across 27 games in multiple genres and contains a further 7836 heldout instances over 9 additional games in the test set. We further provide baseline models using rules-based, question-answering, and sequence learning approaches in addition to an analysis of the data and corresponding learning tasks.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1462",
    "paper_id": "paper-fc56bbd824b907a7d047f4a37afd61788fa23067",
    "extraction_schema_id": "extraction-schema-30",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00570025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Modeling Worlds in Text</h1>
<p>Prithviraj Ammanabrolu<br>School of Interactive Computing<br>Georgia Institute of Technology<br>raj.ammanabrolu@gatech.edu</p>
<p>Mark O. Riedl<br>School of Interactive Computing<br>Georgia Institute of Technology<br>riedl@cc.gatech.edu</p>
<h4>Abstract</h4>
<p>We provide a dataset that enables the creation of learning agents that can build knowledge graph-based world models of interactive narratives. ${ }^{1}$ Interactive narratives-or text-adventure games-are partially observable environments structured as long puzzles or quests in which an agent perceives and interacts with the world purely through textual natural language. Each individual game typically contains hundreds of locations, characters, and objects-each with their own unique descriptions-providing an opportunity to study the problem of giving language-based agents the structured memory necessary to operate in such worlds. Our dataset provides 24198 mappings between rich natural language observations and: (1) knowledge graphs that reflect the world state in the form of a map; (2) natural language actions that are guaranteed to cause a change in that particular world state. The training data is collected across 27 games in multiple genres and contains a further 7836 heldout instances over 9 additional games in the test set. We further provide baseline models using rules-based, question-answering, and sequence learning approaches in addition to an analysis of the data and corresponding learning tasks.</p>
<h2>1 Introduction</h2>
<p>We seek to create agents that exhibit human-like capabilities such as commonsense reasoning and natural language understanding in interactive and situated settings. Interactive narrative environments provide a critical stepping stone in this pursuit towards creating learning agents that can produce contextually relevant and goal-driven natural language [Côté et al., 2018, Urbanek et al., 2019, Hausknecht et al., 2020]. They require agents to observe textual descriptions and then act upon the world using natural language with the aim of completing a long term goal or quest as seen in Figures 1, 2. We focus on two of the core challenges faced by learning agents in these environments-as identified in prior work-knowledge representation and a combinatorially sized state-action space.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Excerpt from Zork1.</p>
<p>The knowledge representation challenge rises from the fact that interactive narratives span many distinct locations, each with unique descriptions,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: A map showcasing the size and complexity of the world of Zork by artist ion_bond.
objects, and characters as seen can be seen in Figure 2. Players move by issuing navigational commands, which can convey Euclidean space like go West or non-Euclidean span like step into portal, warping the agent to an entirely new section of the world. To cope with such challenges, humans often create structured memory aids such as hand drawn maps when attempting to play these games. A good knowledge representation can assist with long-term action dependencies that often arise in game quests (as well as real world environments). An example of a long-term dependency is a key being found in one location that opens a lock on a chest in an entirely different section of the map. For an agent to learn this relationship, it must be able to replicate the sequence of picking up the key and unlocking the chest while not being distracted by interstitial actions and states.</p>
<p>Long-term action dependencies are made challenging by two aspects of interactive narrative environments, which are also present in real-world environments. First, these environments are partially observable in the sense that an agent only has local observability. Second, interactive narrative environments have a combinatorially-sized natural language state-action space. For example, in the cannonical game Zork1 an action can consist of up to five-words from a relatively modest vocabulary of 697 words, resulting in $\mathcal{O}\left(697^{5}\right)=1.64 \times 10^{14}$ possible actions at every step-though the number of valid actions that are gramatically coherent and contextually relevant is significantly smaller. This makes exploration sample-inefficient, making it harder to learn the relationship between actions that are temporally distant from each other.</p>
<p>The knowledge representation challenges inherent to interactive narrative games give rise to the Textual-SLAM problem, a textual variant of Simultaneous Localization And Mapping (SLAM) [Thrun et al., 2005] problem of constructing a map by inferring information from one's surroundings while navigating a novel environment. As in humans, the creation of such world models or memory aids in agents-in the form of knowledge graphs-has been shown to be critical in helping automated learning agents operate in these textual worlds [Ammanabrolu and Riedl, 2019, Murugesan et al., 2020, Adhikari et al., 2020, Ammanabrolu and Hausknecht, 2020].</p>
<p>Despite the success of knowledge graphs in addressing these problems, a broad dataset across a diverse set of games mapping text game observations to knowledge graphs does not exist-hindering progress in building of world modeling agents with structured memory. Building off the popular text game simulator Jericho [Hausknecht et al., 2020], we have constructed a dataset dubbed JerichoWorld that maps text game state observations to both the underlying ground truth knowledge graph representations of the game and the set of contextually relevant actions that can be performed in that state. Using this data, we seek to enable development of agents that focus on answering the questions of "What actions make sense for me to perform right now?" and "What have I already done and how will the world change now if I perform a particular action?"-questions relating to the problems natural language understanding, commonsense reasoning, and structured memory. The training set contains 24198 instances across 27 games and the heldout test set contains 7836 instances from 9 games. We further formally define two initial tasks for this dataset focusing on the questions mentioned: (1) Given a textual observation, predict the underlying knowledge graph of the world. (2) Given a textual observation, predict the set of actions that are contextually relevant. Results for</p>
<p>three baselines-using rules-based, question-answering, and sequence-learning approaches-are provided in addition to an analysis of the dataset and results themselves.</p>
<h1>2 Related Work</h1>
<p>We constrain our related work section to three primary areas: current interactive narrative benchmarks, world modeling and model-based reinforcement learning, and the use of knowledge graphs in text games. Currently, three primary open-source platforms and baseline benchmarks have been developed so far to help measure progress in this field: Jericho [Hausknecht et al., 2020] ${ }^{2}$ a learning environment for human-made interactive narrative games; TextWorld [Côté et al., 2018] ${ }^{3}$ a framework for procedural generation in text-games; and LIGHT [Urbanek et al., 2019] ${ }^{4}$ a large-scale crowdsourced multi-user text-game for studying situated dialogue. Further extensions and adaptation to some of these benchmarks have been proposed for use in neighboring domains such as vision-and-language navigation [Shridhar et al., 2021], commonsense reasoning [Murugesan et al., 2021], and procedural text understanding [Tamari et al., 2021]. Our work builds on the Jericho environment.</p>
<p>Work on world models in learning agents have recently been inspired by theories of how humans form mental models of the world [Jancke, 2000, Ha and Schmidhuber, 2018]. When in the form of predictive probabilistic generative models of the world, they can be used in model-based reinforcement learning tasks [Sutton and Barto, 1998, Arulkumaran et al., 2017, Schrittwieser et al., 2019]. In such cases, a learning agent attempts to learn the underlying environment dynamics at the same time as a policy, often using information about one to inform the other. Ha and Schmidhuber [2018] take this one step further by replacing a environment entirely with the agent's own learned world model and training a control policy there. All of these methods have been shown to have the added benefits of significantly improving sample efficiency as the agent is now able to (at least partially) simulate the environment via the world model.</p>
<p>In all of the world modeling cases mentioned, the state representations that the models are conditioned on are drawn directly from the existing base environments, e.g. raw pixel game screens in the case of the Arcade Learning Environment [Bellemare et al., 2013] or other visual games such as Sokoban [Bamford and Lucas, 2020]. In the case of human-made text games, however, knowledge graphs-not directly provided by existing text game learning frameworks-have been shown to be superior state representations when compared to just the textual observations by themselves. They aid in the challenges of partial observability/knowledge representation [Ammanabrolu and Riedl, 2019, Adhikari et al., 2020, Sautier et al., 2020], combinatorial state-action spaces [Ammanabrolu and Hausknecht, 2020, Ammanabrolu et al., 2020b], and commonsense reasoning [Ammanabrolu and Riedl, 2019, Murugesan et al., 2020, 2021, Dambekodi et al., 2020].
Closest in spirit to this work is the Jericho-QA dataset [Ammanabrolu et al., 2020b], a questionanswering dataset tuned to text games that enables agents to identify common objects in the world and their attributes. It does not have information regarding the full underlying knowledge graph state or valid actions, however. As far as we know, ground truth knowledge graph state representation dataset across a diverse set of human-made text games is not currently available in any of the primary text game benchmarks mentioned previously, hindering the ability to create agents with structured memory in the form of graph-based world models.</p>
<h2>3 JerichoWorld</h2>
<p>Côté et al. [2018] and Hausknecht et al. [2020] define text games as Partially-Observable Markov Decision Processes. A game can be represented as a 7-tuple of $\langle S, T, A, \Omega, O, R, \gamma\rangle$ representing the set of environment states, mostly deterministic conditional transition probabilities between states, the vocabulary or words used to compose text commands, observations returned by the game, observation conditional probabilities, reward function, and the discount factor respectively. Drawing from this definition, each instance of our dataset takes the tuples of $\left\langle s_{t}, a_{t}, s_{t+1}, r_{t+1}\right\rangle$ where $s_{t}$ and $s_{t+1}$ are two subsequent states with $a_{t}$ being the action used to transition states and $r_{t+1}$ is the observed reward for some step $t$.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>To collect the $\left\langle s_{t}, a_{t}, s_{t+1}, r_{t+1}\right\rangle$ tuples we implement a basic agent that explores the game along a trajectory corresponding to a game walkthrough. Game walkthroughs are texts describing the solutions to games, generally retrieved from the internet, but already part of the Jericho framework. Walkthroughs, however, only present one possible solution to a game and solve all the core puzzles required to complete a game with the maximum possible score. To achieve greater coverage of the game's state space, our data collection agent stops off to explore by executing random valid actions for $n$ steps before resetting to the walkthrough. One such collected state-a part of the full tuple mentioned-is detailed below.</p>
<p>The textual observations consist of descriptions of the location and inventory as well as the game engine response to the previous action performed. For example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">Game</span><span class="o">:</span><span class="w"> </span><span class="n">ztuu</span>
<span class="n">Location</span><span class="o">:</span><span class="w"> </span><span class="n">Cultural</span><span class="w"> </span><span class="n">Complex</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">imposing</span><span class="w"> </span><span class="n">ante</span><span class="o">-</span><span class="n">room</span><span class="o">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">center</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="n">was</span><span class="w"> </span><span class="n">apparently</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">cultural</span><span class="w"> </span><span class="n">center</span>
<span class="w">    </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">GUE</span><span class="o">,</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">adorned</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ghastly</span><span class="w"> </span><span class="n">style</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">GUE</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="s2">&quot;Grotesque Period.&quot;</span><span class="w"> </span><span class="n">With</span><span class="w"> </span><span class="n">leering</span><span class="w"> </span><span class="n">gargoyles</span><span class="o">,</span>
<span class="w">    </span><span class="n">cartoonish</span><span class="w"> </span><span class="n">friezes</span><span class="w"> </span><span class="n">depicting</span><span class="w"> </span><span class="n">long</span><span class="o">-</span><span class="n">forgotten</span><span class="w"> </span><span class="n">scenes</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">GUE</span><span class="w"> </span><span class="n">history</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">primitive</span><span class="w"> </span><span class="n">statuary</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">pointy</span><span class="o">-</span>
<span class="w">    </span><span class="n">headed</span><span class="w"> </span><span class="n">personages</span><span class="w"> </span><span class="n">unknown</span><span class="w"> </span><span class="o">(</span><span class="n">perhaps</span><span class="w"> </span><span class="n">very</span><span class="o">,</span><span class="w"> </span><span class="n">very</span><span class="w"> </span><span class="n">distant</span><span class="w"> </span><span class="n">progenitors</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Flatheads</span><span class="o">),</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">place</span><span class="w"> </span><span class="n">would</span>
<span class="w">    </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">best</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">undiscovered</span><span class="o">.</span><span class="w"> </span><span class="n">North</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">here</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">hallway</span><span class="w"> </span><span class="n">passes</span><span class="w"> </span><span class="n">under</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">roughly</span><span class="w"> </span><span class="n">hewn</span>
<span class="w">    </span><span class="n">inscription</span><span class="w"> </span><span class="s2">&quot;Convention Center.&quot;</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span><span class="o">,</span><span class="w"> </span><span class="n">under</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">fifty</span><span class="o">-</span><span class="n">story</span><span class="w"> </span><span class="n">triumphal</span><span class="w"> </span><span class="n">arch</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">passageway</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">size</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">city</span><span class="w"> </span><span class="n">boulevard</span><span class="w"> </span><span class="n">opens</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Royal</span><span class="w"> </span><span class="n">Theater</span><span class="o">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">relatively</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">unobtrusive</span><span class="w"> </span><span class="n">sign</span>
<span class="w">    </span><span class="o">(</span><span class="n">perhaps</span><span class="w"> </span><span class="n">ten</span><span class="w"> </span><span class="n">feet</span><span class="w"> </span><span class="n">high</span><span class="o">)</span><span class="w"> </span><span class="n">stands</span><span class="w"> </span><span class="n">nearby</span><span class="o">.</span><span class="w"> </span><span class="n">South</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">smaller</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">dignified</span><span class="w"> </span><span class="o">(</span><span class="n">i</span><span class="o">.</span><span class="na">e</span><span class="o">.</span><span class="w"> </span><span class="n">post</span><span class="o">-</span><span class="n">Dimwit</span><span class="o">)</span><span class="w"> </span><span class="n">path</span>
<span class="w">    </span><span class="n">leads</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">what</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">billed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="s2">&quot;Hall of Science.&quot;</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">pair</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">razor</span><span class="o">-</span><span class="n">like</span><span class="w"> </span><span class="n">gloves</span><span class="w"> </span><span class="n">here</span><span class="o">.</span>
<span class="n">Observation</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">razor</span><span class="o">-</span><span class="n">like</span><span class="w"> </span><span class="n">gloves</span><span class="o">.</span>
<span class="n">Inventory</span><span class="o">:</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">carrying</span><span class="o">:</span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="n">brass</span><span class="w"> </span><span class="n">lantern</span><span class="w"> </span><span class="o">(</span><span class="n">providing</span><span class="w"> </span><span class="n">light</span><span class="o">)</span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="n">pair</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">glasses</span>
<span class="w">        </span><span class="n">four</span><span class="w"> </span><span class="n">candy</span><span class="w"> </span><span class="n">bars</span><span class="o">:</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="n">ZM$100000</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="n">Multi</span><span class="o">-</span><span class="n">Implementeers</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="n">Forever</span><span class="w"> </span><span class="n">Gores</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="n">Baby</span><span class="w"> </span><span class="n">Rune</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="n">cheaply</span><span class="o">-</span><span class="n">made</span><span class="w"> </span><span class="n">sword</span>
<span class="n">Prev</span><span class="w"> </span><span class="n">Act</span><span class="o">:</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">gloves</span>
</code></pre></div>

<p>We further provide the set of objects that are found in both the agent's inventory and surroundings, including textual descriptions for each of the objects. Attributes for each of these objects are also included are acquired by decompiling the games, following [Ammanabrolu et al., 2020b]. For example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">Inventory</span><span class="w"> </span><span class="n">Objects</span><span class="p">:</span>
<span class="w">    </span><span class="n">candy</span><span class="p">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">do</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">ZM</span><span class="o">$</span><span class="mi">100000</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Multi</span><span class="w"> </span><span class="n">Implementeers</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Forever</span><span class="w"> </span><span class="n">Gores</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Baby</span><span class="w"> </span><span class="n">Rune</span><span class="err">?</span>
<span class="w">    </span><span class="n">Implementeers</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">profiles</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wrapper</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">delicacy</span><span class="w"> </span><span class="n">look</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">Moe</span><span class="p">,</span><span class="w"> </span><span class="n">Larry</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">Curly</span><span class="w"> </span><span class="n">than</span>
<span class="w">        </span><span class="n">those</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="n">favorite</span><span class="w"> </span><span class="n">Implementeers</span><span class="w"> </span><span class="p">(</span><span class="n">presumably</span><span class="p">,</span><span class="w"> </span><span class="n">Marc</span><span class="p">,</span><span class="w"> </span><span class="n">Mike</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">David</span><span class="o">.</span><span class="p">)</span>
<span class="w">    </span><span class="n">Forever</span><span class="o">/</span><span class="n">Gores</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">wrapper</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">bar</span><span class="w"> </span><span class="n">pictures</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Milky</span><span class="w"> </span><span class="n">Way</span><span class="p">,</span><span class="w"> </span><span class="n">but</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">stars</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">blood</span><span class="w"> </span><span class="n">red</span><span class="o">.</span><span class="w"> </span><span class="n">Kids</span>
<span class="w">        </span><span class="n">love</span><span class="w"> </span><span class="n">them</span><span class="o">.</span>
<span class="w">    </span><span class="n">sword</span><span class="p">:</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">cheaply</span><span class="w"> </span><span class="n">made</span><span class="w"> </span><span class="n">sword</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">antiquity</span><span class="w"> </span><span class="n">whatsoever</span><span class="o">.</span><span class="w"> </span><span class="n">With</span><span class="w"> </span><span class="n">regard</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">grues</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">other</span>
<span class="w">        </span><span class="n">underworldly</span><span class="w"> </span><span class="n">denizens</span><span class="p">,</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="n">weapon</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">likely</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">engender</span><span class="w"> </span><span class="n">laughter</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">fear</span><span class="o">.</span>
<span class="w">    </span><span class="n">rune</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">covered</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">mystical</span><span class="w"> </span><span class="n">runes</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">meanings</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">elude</span><span class="w"> </span><span class="n">you</span><span class="o">.</span>
<span class="w">    </span><span class="n">glasses</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">owner</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">these</span><span class="w"> </span><span class="n">glasses</span><span class="w"> </span><span class="n">had</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">indeterminate</span><span class="w"> </span><span class="n">vision</span><span class="w"> </span><span class="n">problem</span><span class="p">,</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">lenses</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">both</span>
<span class="w">        </span><span class="n">been</span><span class="w"> </span><span class="n">crushed</span><span class="w"> </span><span class="n">underfoot</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">vision</span><span class="w"> </span><span class="n">problem</span><span class="p">,</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">course</span><span class="p">,</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">solved</span><span class="o">.</span>
<span class="w">    </span><span class="n">lantern</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">lantern</span><span class="p">,</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">cheapest</span><span class="w"> </span><span class="n">construction</span><span class="p">,</span><span class="w"> </span><span class="n">appears</span><span class="w"> </span><span class="n">functional</span><span class="w"> </span><span class="n">enough</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">moment</span><span class="o">.</span>
<span class="w">        </span><span class="n">Your</span><span class="w"> </span><span class="n">best</span><span class="w"> </span><span class="n">hope</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">stays</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">way</span><span class="o">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">looks</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">lamp</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">gone</span><span class="w"> </span><span class="n">through</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">few</span><span class="w"> </span><span class="n">cycles</span><span class="w"> </span><span class="n">of</span>
<span class="w">            </span><span class="n">impact</span><span class="w"> </span><span class="n">revitalization</span><span class="o">.</span>
<span class="n">Inventory</span><span class="w"> </span><span class="n">Attributes</span><span class="p">:</span>
<span class="w">    </span><span class="n">glasses</span><span class="p">:</span><span class="w"> </span><span class="n">clothing</span>
<span class="w">    </span><span class="n">gloves</span><span class="p">:</span><span class="w"> </span><span class="n">clothing</span>
<span class="w">    </span><span class="n">sword</span><span class="p">:</span><span class="w"> </span><span class="n">animate</span><span class="p">,</span><span class="w"> </span><span class="n">equip</span>
<span class="w">    </span><span class="n">lantern</span><span class="p">:</span><span class="w"> </span><span class="n">animate</span><span class="p">,</span><span class="w"> </span><span class="n">equip</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="n">Objects</span><span class="p">:</span>
<span class="w">    </span><span class="n">gargoyles</span><span class="p">:</span><span class="w"> </span><span class="n">Unless</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">inordinately</span><span class="w"> </span><span class="n">masochistic</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">less</span><span class="w"> </span><span class="n">time</span><span class="w"> </span><span class="n">spent</span><span class="w"> </span><span class="n">examining</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">artwork</span><span class="p">,</span><span class="w"> </span><span class="n">the</span>
<span class="w">        </span><span class="n">better</span><span class="o">.</span>
<span class="w">    </span><span class="n">east</span><span class="p">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">nothing</span><span class="w"> </span><span class="n">special</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span><span class="w"> </span><span class="n">wall</span><span class="o">.</span>
<span class="w">    </span><span class="n">tunnel</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">tunnel</span><span class="w"> </span><span class="n">leads</span><span class="w"> </span><span class="n">west</span><span class="o">.</span>
<span class="w">    </span><span class="n">gloves</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">razor</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">gloves</span><span class="w"> </span><span class="n">would</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">very</span><span class="w"> </span><span class="n">attractive</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">axe</span><span class="w"> </span><span class="n">murderer</span><span class="o">.</span><span class="w"> </span><span class="n">And</span><span class="w"> </span><span class="n">they</span><span class="s1">&#39;re just your size.</span>
<span class="w">    </span><span class="n">south</span><span class="p">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">nothing</span><span class="w"> </span><span class="n">special</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">south</span><span class="w"> </span><span class="n">wall</span><span class="o">.</span>
<span class="w">    </span><span class="nb">sign</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="nb">sign</span><span class="w"> </span><span class="n">indicates</span><span class="w"> </span><span class="n">today</span><span class="s1">&#39;s performance, which (in honor of the festivities in the Convention</span>
<span class="w">        </span><span class="n">Center</span><span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="s2">&quot;A Massacre on 34th Street.&quot;</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="n">Attributes</span><span class="p">:</span>
<span class="w">    </span><span class="n">gloves</span><span class="p">:</span><span class="w"> </span><span class="n">clothing</span>
<span class="w">    </span><span class="n">tunnel</span><span class="p">:</span><span class="w"> </span><span class="n">animate</span>
<span class="w">    </span><span class="nb">sign</span><span class="p">:</span><span class="w"> </span><span class="n">animate</span>
</code></pre></div>

<p>We further provide the ground truth knowledge graph representing the world state corresponding to these textual observations. The ground truth knowledge graph is a set of tuples $\langle s, r, o\rangle$ such that $s$ is</p>
<p>a subject, $r$ is a relation, and $o$ is an object. It reflects information on the current state such as objects and attributes and is extracted from the game engine by traversing the engine's internal representation and converting it to human readable form. Relations are defined on the basis of traversal operations in the game engine's internal representation, e.g. "in" and "have" signify parent-child ownership for locations and inventory respectively. For example:</p>
<div class="codehilite"><pre><span></span><code>Graph: [sign, in, Cultural Complex], [you, have, Forever Gores], [you, have, ZM$100000], [you, have, Baby
    Rune], [tunnel, in, Cultural Complex], [you, in, Cultural Complex], [you, have, brass lantern], [you,
    have, glasses], [decoration, in, Cultural Complex], [you, have, cheaply-made sword], [you, have,
    Multi-Implementeers], [you, have, razor-like gloves], [glasses, is, clothing], [gloves, is, clothing],
    [sword, is, animate], [tunnel, is, animate], [sign, is, animate], [lantern, is, animate], [sword, is,
    equip], [lantern, is, equip]
</code></pre></div>

<p>Valid actions are defined by Hausknecht et al. [2020] as the set of actions guaranteed to cause a change in the current world state and are identified by the Jericho framework. For example in one particular state me might have the following valid actions:</p>
<div class="codehilite"><pre><span></span><code>Valid Actions: west, turn lantern off, east, south, put multi down, put forever down, put lantern down,
    put rune down, put glasses down, put sword down, take razor off, put on glasses, examine glasses,
    lower razor, throw multi, throw lantern, put multi in glasses, north
</code></pre></div>

<h1>3.1 Dataset Analysis</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Game</th>
<th style="text-align: center;">No. <br> Samples</th>
<th style="text-align: center;">Input <br> Vocab Size</th>
<th style="text-align: center;">Avg. Obs <br> Token Len.</th>
<th style="text-align: center;">Avg. Graph <br> Triple Len.</th>
<th style="text-align: center;">Avg. No. <br> Valid Actions</th>
<th style="text-align: center;">Avg. Surround. <br> Objects</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Training games</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">wishbringer</td>
<td style="text-align: center;">560</td>
<td style="text-align: center;">1043</td>
<td style="text-align: center;">136.54</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">10.35</td>
<td style="text-align: center;">8.51</td>
</tr>
<tr>
<td style="text-align: center;">snacktime</td>
<td style="text-align: center;">168</td>
<td style="text-align: center;">468</td>
<td style="text-align: center;">190.08</td>
<td style="text-align: center;">2.33</td>
<td style="text-align: center;">4.82</td>
<td style="text-align: center;">5.52</td>
</tr>
<tr>
<td style="text-align: center;">tryx205</td>
<td style="text-align: center;">1052</td>
<td style="text-align: center;">871</td>
<td style="text-align: center;">136.24</td>
<td style="text-align: center;">7.81</td>
<td style="text-align: center;">14.30</td>
<td style="text-align: center;">8.38</td>
</tr>
<tr>
<td style="text-align: center;">enter</td>
<td style="text-align: center;">440</td>
<td style="text-align: center;">470</td>
<td style="text-align: center;">219.06</td>
<td style="text-align: center;">14.79</td>
<td style="text-align: center;">18.04</td>
<td style="text-align: center;">9.23</td>
</tr>
<tr>
<td style="text-align: center;">omniquest</td>
<td style="text-align: center;">784</td>
<td style="text-align: center;">460</td>
<td style="text-align: center;">79.96</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">21.50</td>
<td style="text-align: center;">5.30</td>
</tr>
<tr>
<td style="text-align: center;">zork3</td>
<td style="text-align: center;">1142</td>
<td style="text-align: center;">564</td>
<td style="text-align: center;">137.68</td>
<td style="text-align: center;">6.59</td>
<td style="text-align: center;">12.72</td>
<td style="text-align: center;">5.26</td>
</tr>
<tr>
<td style="text-align: center;">zork2</td>
<td style="text-align: center;">584</td>
<td style="text-align: center;">684</td>
<td style="text-align: center;">154.90</td>
<td style="text-align: center;">7.82</td>
<td style="text-align: center;">29.66</td>
<td style="text-align: center;">5.73</td>
</tr>
<tr>
<td style="text-align: center;">inhumane</td>
<td style="text-align: center;">1004</td>
<td style="text-align: center;">409</td>
<td style="text-align: center;">90.24</td>
<td style="text-align: center;">3.86</td>
<td style="text-align: center;">4.31</td>
<td style="text-align: center;">2.48</td>
</tr>
<tr>
<td style="text-align: center;">905</td>
<td style="text-align: center;">504</td>
<td style="text-align: center;">296</td>
<td style="text-align: center;">100.91</td>
<td style="text-align: center;">11.69</td>
<td style="text-align: center;">13.60</td>
<td style="text-align: center;">12.24</td>
</tr>
<tr>
<td style="text-align: center;">loose</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">1141</td>
<td style="text-align: center;">140.38</td>
<td style="text-align: center;">10.12</td>
<td style="text-align: center;">2.12</td>
<td style="text-align: center;">9.00</td>
</tr>
<tr>
<td style="text-align: center;">murdac</td>
<td style="text-align: center;">1914</td>
<td style="text-align: center;">251</td>
<td style="text-align: center;">80.76</td>
<td style="text-align: center;">4.30</td>
<td style="text-align: center;">8.67</td>
<td style="text-align: center;">1.63</td>
</tr>
<tr>
<td style="text-align: center;">moonlit</td>
<td style="text-align: center;">684</td>
<td style="text-align: center;">669</td>
<td style="text-align: center;">131.62</td>
<td style="text-align: center;">12.10</td>
<td style="text-align: center;">9.20</td>
<td style="text-align: center;">11.61</td>
</tr>
<tr>
<td style="text-align: center;">dragon</td>
<td style="text-align: center;">894</td>
<td style="text-align: center;">1049</td>
<td style="text-align: center;">182.79</td>
<td style="text-align: center;">11.64</td>
<td style="text-align: center;">13.13</td>
<td style="text-align: center;">12.29</td>
</tr>
<tr>
<td style="text-align: center;">jewel</td>
<td style="text-align: center;">1418</td>
<td style="text-align: center;">657</td>
<td style="text-align: center;">119.08</td>
<td style="text-align: center;">7.21</td>
<td style="text-align: center;">13.82</td>
<td style="text-align: center;">5.15</td>
</tr>
<tr>
<td style="text-align: center;">weapon</td>
<td style="text-align: center;">294</td>
<td style="text-align: center;">481</td>
<td style="text-align: center;">230.41</td>
<td style="text-align: center;">29.79</td>
<td style="text-align: center;">9.65</td>
<td style="text-align: center;">35.68</td>
</tr>
<tr>
<td style="text-align: center;">karn</td>
<td style="text-align: center;">2196</td>
<td style="text-align: center;">615</td>
<td style="text-align: center;">138.87</td>
<td style="text-align: center;">13.24</td>
<td style="text-align: center;">26.36</td>
<td style="text-align: center;">8.44</td>
</tr>
<tr>
<td style="text-align: center;">zenon</td>
<td style="text-align: center;">402</td>
<td style="text-align: center;">401</td>
<td style="text-align: center;">101.52</td>
<td style="text-align: center;">5.01</td>
<td style="text-align: center;">5.97</td>
<td style="text-align: center;">3.95</td>
</tr>
<tr>
<td style="text-align: center;">acorncourt</td>
<td style="text-align: center;">474</td>
<td style="text-align: center;">343</td>
<td style="text-align: center;">323.38</td>
<td style="text-align: center;">36.14</td>
<td style="text-align: center;">20.18</td>
<td style="text-align: center;">16.08</td>
</tr>
<tr>
<td style="text-align: center;">baltyhoo</td>
<td style="text-align: center;">2132</td>
<td style="text-align: center;">962</td>
<td style="text-align: center;">127.08</td>
<td style="text-align: center;">7.25</td>
<td style="text-align: center;">15.39</td>
<td style="text-align: center;">7.11</td>
</tr>
<tr>
<td style="text-align: center;">yomomma</td>
<td style="text-align: center;">884</td>
<td style="text-align: center;">619</td>
<td style="text-align: center;">129.06</td>
<td style="text-align: center;">3.00</td>
<td style="text-align: center;">16.11</td>
<td style="text-align: center;">5.52</td>
</tr>
<tr>
<td style="text-align: center;">enchanter</td>
<td style="text-align: center;">1714</td>
<td style="text-align: center;">722</td>
<td style="text-align: center;">133.56</td>
<td style="text-align: center;">14.83</td>
<td style="text-align: center;">45.27</td>
<td style="text-align: center;">7.40</td>
</tr>
<tr>
<td style="text-align: center;">gold</td>
<td style="text-align: center;">2082</td>
<td style="text-align: center;">728</td>
<td style="text-align: center;">166.96</td>
<td style="text-align: center;">15.76</td>
<td style="text-align: center;">25.03</td>
<td style="text-align: center;">12.92</td>
</tr>
<tr>
<td style="text-align: center;">huntdark</td>
<td style="text-align: center;">344</td>
<td style="text-align: center;">539</td>
<td style="text-align: center;">162.33</td>
<td style="text-align: center;">13.01</td>
<td style="text-align: center;">6.33</td>
<td style="text-align: center;">6.90</td>
</tr>
<tr>
<td style="text-align: center;">afflicted</td>
<td style="text-align: center;">574</td>
<td style="text-align: center;">762</td>
<td style="text-align: center;">165.13</td>
<td style="text-align: center;">2.91</td>
<td style="text-align: center;">17.34</td>
<td style="text-align: center;">11.85</td>
</tr>
<tr>
<td style="text-align: center;">adventuscland</td>
<td style="text-align: center;">870</td>
<td style="text-align: center;">398</td>
<td style="text-align: center;">87.41</td>
<td style="text-align: center;">6.99</td>
<td style="text-align: center;">9.02</td>
<td style="text-align: center;">5.17</td>
</tr>
<tr>
<td style="text-align: center;">reverb</td>
<td style="text-align: center;">722</td>
<td style="text-align: center;">526</td>
<td style="text-align: center;">101.92</td>
<td style="text-align: center;">5.23</td>
<td style="text-align: center;">9.04</td>
<td style="text-align: center;">4.78</td>
</tr>
<tr>
<td style="text-align: center;">night</td>
<td style="text-align: center;">346</td>
<td style="text-align: center;">462</td>
<td style="text-align: center;">49.92</td>
<td style="text-align: center;">10.17</td>
<td style="text-align: center;">4.55</td>
<td style="text-align: center;">3.37</td>
</tr>
<tr>
<td style="text-align: center;">overall train</td>
<td style="text-align: center;">24198</td>
<td style="text-align: center;">11056</td>
<td style="text-align: center;">133.30</td>
<td style="text-align: center;">9.74</td>
<td style="text-align: center;">17.41</td>
<td style="text-align: center;">7.70</td>
</tr>
<tr>
<td style="text-align: center;">Testing games</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">deephome</td>
<td style="text-align: center;">630</td>
<td style="text-align: center;">760</td>
<td style="text-align: center;">147.33</td>
<td style="text-align: center;">10.20</td>
<td style="text-align: center;">15.31</td>
<td style="text-align: center;">7.15</td>
</tr>
<tr>
<td style="text-align: center;">balances</td>
<td style="text-align: center;">990</td>
<td style="text-align: center;">452</td>
<td style="text-align: center;">107.15</td>
<td style="text-align: center;">7.61</td>
<td style="text-align: center;">13.04</td>
<td style="text-align: center;">3.85</td>
</tr>
<tr>
<td style="text-align: center;">ludicorp</td>
<td style="text-align: center;">2210</td>
<td style="text-align: center;">503</td>
<td style="text-align: center;">88.32</td>
<td style="text-align: center;">9.47</td>
<td style="text-align: center;">9.27</td>
<td style="text-align: center;">4.60</td>
</tr>
<tr>
<td style="text-align: center;">pentari</td>
<td style="text-align: center;">276</td>
<td style="text-align: center;">472</td>
<td style="text-align: center;">130.34</td>
<td style="text-align: center;">3.46</td>
<td style="text-align: center;">3.72</td>
<td style="text-align: center;">2.84</td>
</tr>
<tr>
<td style="text-align: center;">detective</td>
<td style="text-align: center;">434</td>
<td style="text-align: center;">344</td>
<td style="text-align: center;">105.97</td>
<td style="text-align: center;">2.80</td>
<td style="text-align: center;">5.72</td>
<td style="text-align: center;">2.16</td>
</tr>
<tr>
<td style="text-align: center;">ztuu</td>
<td style="text-align: center;">462</td>
<td style="text-align: center;">607</td>
<td style="text-align: center;">170.89</td>
<td style="text-align: center;">11.97</td>
<td style="text-align: center;">18.39</td>
<td style="text-align: center;">7.94</td>
</tr>
<tr>
<td style="text-align: center;">zork1</td>
<td style="text-align: center;">886</td>
<td style="text-align: center;">697</td>
<td style="text-align: center;">109.70</td>
<td style="text-align: center;">6.46</td>
<td style="text-align: center;">13.02</td>
<td style="text-align: center;">4.54</td>
</tr>
<tr>
<td style="text-align: center;">library</td>
<td style="text-align: center;">654</td>
<td style="text-align: center;">510</td>
<td style="text-align: center;">154.40</td>
<td style="text-align: center;">9.18</td>
<td style="text-align: center;">4.59</td>
<td style="text-align: center;">10.20</td>
</tr>
<tr>
<td style="text-align: center;">temple</td>
<td style="text-align: center;">1294</td>
<td style="text-align: center;">622</td>
<td style="text-align: center;">138.07</td>
<td style="text-align: center;">10.77</td>
<td style="text-align: center;">8.56</td>
<td style="text-align: center;">8.78</td>
</tr>
<tr>
<td style="text-align: center;">overall test</td>
<td style="text-align: center;">7836</td>
<td style="text-align: center;">11056</td>
<td style="text-align: center;">118.92</td>
<td style="text-align: center;">8.71</td>
<td style="text-align: center;">10.30</td>
<td style="text-align: center;">5.86</td>
</tr>
</tbody>
</table>
<p>Table 1: Dataset statistics across the games. All games together have a combined input vocabulary of size 11056 . There are 17 unique graph relations and 6985 unique graph entity names (i.e. locations, characters, and objects) across all the games. Vocabulary files are provided in the dataset.</p>
<p>Table 1 presents statistics for our data in the form of showing vocab sizes, and average lengths of different data fields. The dataset as a whole has an input vocabulary size of 11056 -this is the superset of the vocabulary that can be used to act in any of these games. It is worth noting, that</p>
<p>the output vocabulary size-determined by the observations-is not restricted. As seen later when we introduce models for these tasks, this means that subword based tokenization [Kudo, 2018] for processing inputs is the most effective way of avoiding unknown tokens.
The training and testing games both cover a wide range of genres as noted by Hausknecht et al. [2020], Ammanabrolu et al. [2020b]-e.g. 905 is a everyday slice-of-life simulator in which a character walks around a house preparing for work, afflicted is a monster horror game, ballyhoo, detective are murder mysteries, and karn, zork1 are traditional fantasies. On average, the observation token, graph, and valid action lengths are comparable across both the training and testing games. Outliers in these metrics usually represent game-specific challenges. For example, acorncourt has the highest observation token and graph length counts by far. This is because the game is focused heavily on object collection and so contains more entities on average than others. In a similar vein, enchanter has significantly more valid actions than other games. This is due to the game being focused on constantly discovering valid actions in the form of spells and their effects by casting them-everything from healing yourself to causing an object to give off light. It is worth noting that many of these spells appear and have similar effects in other fantasy text games. These are some examples of challenges that players must overcome to be successful in these worlds.</p>
<h1>4 Benchmarks</h1>
<p>This section introduces the two primary tasks using JerichoWorld required for world modeling in learning agents: knowledge graph prediction and valid action prediction. We then introduce baseline models for each of the tasks, report zero-shot results on the testing games, and analyze performance.</p>
<h3>4.1 Knowledge Graph Prediction</h3>
<p>The first world modeling task involves predicting a knowledge graph from the current set of textual observations. Recall that our dataset takes the form of tuples of $\left\langle s_{t}, a_{t}, s_{t+1}, r_{t+1}\right\rangle$ where $s_{t}$ and $s_{t+1}$ are two subsequent states with $a_{t}$ being the action used to transition states and $r_{t+1}$ is the observed reward. This task is to predict $s_{t+1}^{\text {graph }}$, a set of knowledge graph relations, given the textual observations $s_{t}^{\text {obs }}$, the previous state's graph $s_{t}^{\text {graph }}$, and action $a_{t}$ for all samples in the dataset. We present three baseline models for this task.
Rules. Following Ammanabrolu and Hausknecht [2020], we extract graph information from the observation using information extraction tools such as OpenIE [Angeli et al., 2015] in addition to some hand-authored rules to account for the irregularities of text games.
Question-Answering. This baseline comes from the Q*BERT agent described in Ammanabrolu et al. [2020b]. It is trained on the SQuAD 2.0 [Rajpurkar et al., 2018], the Jericho-QA text game question answering dataset [Ammanabrolu et al., 2020b] on the same set of training games as found in JerichoWorld, and then on JerichoWorld itself by formatting our dataset in the style of questions and answers when possible. It uses the ALBERT [Lan et al., 2020] variant of the BERT [Devlin et al., 2018] natural language transformer to answer questions and populate the knowledge graph via a few hand-authored rules from the answers. Examples of questions asked include: "What is my current location?", "What objects are around me?".
Seq2Seq. We further introduce a encoder-decoder based sequence-to-sequence learning approach [Sutskever et al., 2014] inspired by the transformer model BART [Lewis et al., 2020]. The model architecture is shown in Figure 3 and consists of a bidirectional encoder such as BERT [Devlin et al., 2018] that takes the full set of textual observations-including location and inventory descriptions-as input and an autoregressive decoder such as GPT-2 [Radford et al., 2019] which takes in the current graph and learns to predict the graph sequence shifted by a token. The weights of the encoder are fine-tuned from BERT's original weights on both the graphs, in triple form, and the textual observations taken from the training games using a masked language modeling loss. The decoder is not pre-trained. During test time, only the starting token is given to the decoder and it decodes the graph token by token via bean search until an end-of-sequence token is reached.
Metrics. For this task, we report two types of metrics (Exact Match or EM and F1) operating on two different levels-at a graph tuple level and another at a token level. EM checks for accuracy or direct overlap between the predictions and ground truth, while F1 is a harmonic mean of predicted precision</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: A description of the Seq2Seq architecture for knowledge graph prediction task with a bidirectional encoder and autoregressive decoder. A similar architecture is used for the Seq2Seq model shown in the valid action prediction task.
and recall. The graph level metrics are based on matching the set of $\langle$ subject, relation, object $\rangle$ triples within the graph, all three tokens in a particular triple must match a triple within the ground truth graph to count as a true positive. The token level metrics operate on measuring unigram overlap in the graphs, any relations or entities in the predicted tokens that match the ground truth count towards a true positive.
Analysis. Table 2 presents a breakdown of the results for this task across the testing games on all the baseline models presented. There are a few main trends to note in these results.
The first is that the question-answering (QA) approach significantly outperforms both the Rules and Seq2Seq approaches on average across all the testing games. The QA method used is extractive. This means that the system is trained to pick out answers by highlighting spans in the input context that best answers a question. The Rules approach also functions similarly but is not trained in any way on our data. This is inherently a simpler problem formulation than the Seq2Seq approach-which seeks to generate the graph by decoding token by token-but has its limitations.
These limitations are seen in the relative differences between the magnitudes of the graph and token metrics for these approaches. Both QA and Rules have significantly lower graph metrics than token metrics, a phenomenon not observed in the Seq2Seq model. In other words, the right information is extracted but is potentially not well shaped into knowledge graph form. We hypothesize that this implies two things. (1) That these systems likely over-extract by extracting more information than is strictly necessary. Take for example the sample observation seen in Figure 3: "You are standing in an open field west of a white house, with a boarded front door.". QA when asked the question "What is my location?" answers: "open field west of a white house, with a boarded front door". Seq2Seq, in contrast, is trained to map this sentence more tersely to: $\langle$ you, in, West of House $\rangle$. (2) Both QA and Rules use hand-crafted rules to put the graphs together once information has been extracted either through the core QA model or OpenIE. We see here that while over-extraction can be beneficial for the token metrics-it makes it difficult to create a set of graph construction rules that generalize well across games with different structures, resulting in relatively lower graph metrics.
On the other hand, the main advantage of the Seq2Seq approach is that it is not extractive and trained directly on the graphs found in the dataset. This means that it is potentially able to infer facts that are not directly present in the input context. Recall that text games are partially observable and so the textual observations themselves may potentially be incomplete. An example of such an observation is: "You see a locked chest in front of you in the cellar.". The ground truth graph for this would be: $\langle$ you, in, Cellar $\rangle$, $\langle$ chest, in, cellar $\rangle$, $\langle$ chest, is, lockable $\rangle$, $\langle$ sword, in, chest $\rangle$. The last fact in the graph, the sword being in the chest, is not revealed to you via the observation until you open the chest and thus cannot be predicted by extractive approaches like Rules and QA. This gives models like Seq2Seq-that are trained directly on the graph-the ability to perform commonsense inference by potentially filling in information missing from the partially observable text inputs. It further implies that extractive models, in their current form, will not be able to achieve perfect performance.
The main limitation of the Seq2Seq model, however, is that this non-extractive framing-given that every token is decoded autoregressively, requiring a prediction at every step over the entire combined</p>
<table>
<thead>
<tr>
<th>Expt.</th>
<th></th>
<th>Rules</th>
<th></th>
<th></th>
<th></th>
<th>Question-Answering</th>
<th></th>
<th></th>
<th></th>
<th>Seq2Seq</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Metric</td>
<td></td>
<td>Graph</td>
<td></td>
<td>Token</td>
<td></td>
<td>Graph</td>
<td></td>
<td>Token</td>
<td></td>
<td>Graph</td>
<td></td>
<td>Token</td>
<td></td>
</tr>
<tr>
<td>Game</td>
<td>Size</td>
<td>EM</td>
<td>F1</td>
<td>EM</td>
<td>F1</td>
<td>EM</td>
<td>F1</td>
<td>EM</td>
<td>F1</td>
<td>EM</td>
<td>F1</td>
<td>EM</td>
<td>F1</td>
</tr>
<tr>
<td>zork1</td>
<td>886</td>
<td>3.72</td>
<td>4.46</td>
<td>6.08</td>
<td>8.42</td>
<td>24.56</td>
<td>24.88</td>
<td>43.93</td>
<td>48.31</td>
<td>12.44</td>
<td>12.96</td>
<td>18.01</td>
<td>21.12</td>
</tr>
<tr>
<td>library</td>
<td>654</td>
<td>7.61</td>
<td>12.87</td>
<td>10.33</td>
<td>26.74</td>
<td>29.14</td>
<td>31.46</td>
<td>49.78</td>
<td>52.76</td>
<td>18.42</td>
<td>18.89</td>
<td>20.26</td>
<td>20.84</td>
</tr>
<tr>
<td>detective</td>
<td>434</td>
<td>1.39</td>
<td>4.55</td>
<td>7.51</td>
<td>10.23</td>
<td>34.45</td>
<td>36.23</td>
<td>60.28</td>
<td>63.21</td>
<td>26.86</td>
<td>29.48</td>
<td>35.86</td>
<td>35.86</td>
</tr>
<tr>
<td>balances</td>
<td>990</td>
<td>9.17</td>
<td>11.9</td>
<td>32.53</td>
<td>36.09</td>
<td>41.22</td>
<td>41.85</td>
<td>85.81</td>
<td>86.18</td>
<td>8.19</td>
<td>9.04</td>
<td>17.6</td>
<td>18.86</td>
</tr>
<tr>
<td>pentari</td>
<td>276</td>
<td>6.44</td>
<td>10.22</td>
<td>16.48</td>
<td>23.36</td>
<td>28.96</td>
<td>30.12</td>
<td>65.02</td>
<td>69.54</td>
<td>22.18</td>
<td>23.54</td>
<td>25.48</td>
<td>27.72</td>
</tr>
<tr>
<td>ztuu</td>
<td>462</td>
<td>4.94</td>
<td>10.06</td>
<td>14.4</td>
<td>21.74</td>
<td>22.17</td>
<td>26.26</td>
<td>49.44</td>
<td>49.82</td>
<td>16.89</td>
<td>16.89</td>
<td>17.19</td>
<td>17.87</td>
</tr>
<tr>
<td>ludicorp</td>
<td>2210</td>
<td>5.1</td>
<td>8.37</td>
<td>14.47</td>
<td>18.48</td>
<td>41.44</td>
<td>46.74</td>
<td>57.58</td>
<td>60.95</td>
<td>12.94</td>
<td>14.18</td>
<td>14.8</td>
<td>15.42</td>
</tr>
<tr>
<td>deephome</td>
<td>630</td>
<td>0.49</td>
<td>0.64</td>
<td>3.34</td>
<td>3.86</td>
<td>4.42</td>
<td>4.66</td>
<td>9.31</td>
<td>9.84</td>
<td>8.38</td>
<td>10.47</td>
<td>13.25</td>
<td>13.25</td>
</tr>
<tr>
<td>temple</td>
<td>1294</td>
<td>2.48</td>
<td>3.36</td>
<td>7.42</td>
<td>9.44</td>
<td>36.84</td>
<td>39.86</td>
<td>48.98</td>
<td>49.17</td>
<td>16.48</td>
<td>18.52</td>
<td>22.48</td>
<td>24.34</td>
</tr>
<tr>
<td>overall</td>
<td>7836</td>
<td>4.70</td>
<td>7.25</td>
<td>13.08</td>
<td>17.50</td>
<td>32.78</td>
<td>35.48</td>
<td>53.58</td>
<td>55.74</td>
<td>14.29</td>
<td>15.54</td>
<td>18.80</td>
<td>19.96</td>
</tr>
</tbody>
</table>
<p>Table 2: Results for the Knowledge Graph Prediction task. Overall indicates a size weighted average. All experiments are evaluated over three random seeds with standard deviations not exceeding $\pm 2.8$ in any overall category.
entity and relation vocabulary length of 7002-is a significantly more difficult problem than the other approaches. It is likely that that such non-extractive approaches will have to simplify the problem by adding constraints that account for properties of knowledge graphs (e.g. graph are sets of tuples and the same tuple in a set cannot be decoded twice).</p>
<h1>4.2 Valid Action Prediction</h1>
<p>The second world modeling task involves predicting the set of valid actions from the current set of textual observations. Given the data $\left\langle s_{t-1}, a_{t-1}, s_{t}, r_{t}\right\rangle$ (note the change in indexing), this task is formally defined as: predict the set of valid actions for the subsequent state $s_{t}^{\text {valid }}$ given the current state text observation $s_{t}^{\text {obs }}$, current knowledge graph $s_{t}^{\text {graph }}$, previous valid actions $s_{t-1}^{\text {valid }}$, and action $a_{t-1}$ that caused the state change for all individual samples across the dataset. This task requires linguistic priors in the form of commonsense reasoning and a knowledge of affordances-e.g. open mailbox is a more reasonable action to take in most situations than eat mailbox.
We present a single baseline for this task. We developed a Seq2Seq model that is identical to that presented for the Knowledge Graph Prediction task, except adapted to Valid Action Prediction. That is, it performs sequence learning on the valid actions token by token. Extractive approaches like QA are not possible for valid action prediction given that the verbs in the action-e.g. take, get, put, swing, go-are not often found anywhere within the observation. The Seq2Seq approach thus decodes actions token by token from the entire combined output vocab of 11056 (see Table 1) at every step until a special end-of-sequence tag is reached.
Metrics. For this task, we adapt the graph level Exact Match (EM) and F1 metrics as described in the previous task to actions. In other words, positive EM or F1 happens only when all tokens in a predicted valid action match one in the gold standard set. Given that most valid actions have less than four tokens, we do not use standard Seq2Seq metrics-such as BLEU [Papineni et al., 2002]-intended for measuring $n$-gram overlap in longer sequences. We do not report token unigram overlap, as with the knowledge graph task as here, because predicted actions are required to match gold standard actions exactly in order to be executable in the game.
Analysis. Table 3 shows the results for the valid action prediction task on all the testing games for the Seq2Seq baseline. Recall that an EM of 20 means that if there were 100 gold standard valid actions in an instance, the model predicted 20 of them exactly. Based on this, we further note a trend in Table 3 that negative correlation between the as seen in Table 1. That is, the more the average number of gold standard valid actions per instance in a game, the more predicted actions match. Games like ztuu, deephome, balances have a high number of gold standard average valid actions and lower performance than games like pentari, ludicorp, detective, temple which have a low</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Game</th>
<th style="text-align: center;">Size</th>
<th style="text-align: center;">EM</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">zork1</td>
<td style="text-align: center;">886</td>
<td style="text-align: center;">16.65</td>
<td style="text-align: center;">17.85</td>
</tr>
<tr>
<td style="text-align: center;">library</td>
<td style="text-align: center;">654</td>
<td style="text-align: center;">15.13</td>
<td style="text-align: center;">16.88</td>
</tr>
<tr>
<td style="text-align: center;">detective</td>
<td style="text-align: center;">434</td>
<td style="text-align: center;">18.19</td>
<td style="text-align: center;">21.12</td>
</tr>
<tr>
<td style="text-align: center;">balances</td>
<td style="text-align: center;">990</td>
<td style="text-align: center;">16.19</td>
<td style="text-align: center;">18.23</td>
</tr>
<tr>
<td style="text-align: center;">pentari</td>
<td style="text-align: center;">276</td>
<td style="text-align: center;">23.39</td>
<td style="text-align: center;">25.87</td>
</tr>
<tr>
<td style="text-align: center;">ztuu</td>
<td style="text-align: center;">462</td>
<td style="text-align: center;">14.75</td>
<td style="text-align: center;">15.13</td>
</tr>
<tr>
<td style="text-align: center;">ludicorp</td>
<td style="text-align: center;">2210</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">20.86</td>
</tr>
<tr>
<td style="text-align: center;">deephome</td>
<td style="text-align: center;">630</td>
<td style="text-align: center;">14.71</td>
<td style="text-align: center;">14.86</td>
</tr>
<tr>
<td style="text-align: center;">temple</td>
<td style="text-align: center;">1294</td>
<td style="text-align: center;">20.34</td>
<td style="text-align: center;">22.14</td>
</tr>
<tr>
<td style="text-align: center;">overall</td>
<td style="text-align: center;">7836</td>
<td style="text-align: center;">18.10</td>
<td style="text-align: center;">19.44</td>
</tr>
</tbody>
</table>
<p>Table 3: Results for the Valid Action Prediction task. Overall indicates a size weighted average. All experiments are evaluated over three random seeds with standard deviations not exceeding $\pm 3.7$ in any overall category.</p>
<p>number of average valid actions. This is counter intuitive as the expected result would be that a model is able to learn a smaller sequence more effectively than a larger one-implying that a smaller number of gold standard valid actions per instance would lead to more matches. We hypothesize that this is likely due to the fact that the model best learns common actions found across all games first before learning potentially more fine grained actions-effectively a label imbalance issue across the valid actions in the dataset. E.g. navigation actions like go north are found much more often than actions like hit monster with sword-which are usually found in only a handful of fantasy games. When performing zero-shot prediction on testing games, the model thus predicts these common actions with higher confidence than the more fine grained ones. Testing games with a smaller number of average gold standard valid actions also tend to have a larger proportion of uncommon actions-thus posing more of a challenge for the Seq2Seq model.</p>
<h1>5 Conclusions and Future Work</h1>
<p>This paper presents the JerichoWorld dataset and corresponding benchmarks that seek to drive progress in textual world modeling. This primarily involves two key challenges behind the creation of agents that can understand and generate natural language in a diverse set of interactive and situated settings such as text games. Our dataset provides mappings from textual observations to ground truth knowledge graph states to enable agents to learn to infer the state of the world-alleviating the knowledge representation or Textual-SLAM challenge. A key insight from an comparison of baseline models shows that a promising future direction lies in inferring the knowledge graph world state through commonsense reasoning rather than extracting this information due to the partial observability of text games.
A second world modeling task revolves around tacking the combinatorially-sized action space of text games. The dataset also provides mappings from textual observations to valid actions-i.e. the set of contextually relevant actions guaranteed to change the world in any state. A qualitative analysis of a state-of-the-art Seq2Seq model adapted to the domain and trained for this task suggests that while learning to conditionally generate commonly occurring actions across a large set of games might be relatively easy, learning to generate specific and contextually relevant actions provides a significantly more difficult challenge. Current performance by state-of-the-art models across both these tasks suggests that there is much space for improvement.
There are many more tasks that can be framed for other challenges related to world modeling from this dataset. Some immediate examples: (1) offline reinforcement learning for game agents through imitation learning-predicting the sequence of actions that finish the game based on walkthroughs and reward information; (2) knowledge graph verbalization, a form of the standard data-to-text natural language processing task [Wiseman et al., 2017], in which we learn to generate text that is conditioned on a knowledge graph; and (3) description generation conditioned on the names of various objects, locations, and characters-with applications in long-form text generation domains such as automated storytelling [Martin et al., 2018, Fan et al., 2019] and procedural generation of interactive narratives [Ammanabrolu et al., 2020a, Walton et al., 2020].</p>
<h2>6 Broader Impacts</h2>
<p>Text games are simplified analogues for systems capable of long-term dialogue with humans, such as in assistance with planning complex tasks, and also discrete planning domains such as logistics. Our focus is on helping agents to better model such worlds, enabling greater efficiency for agents training to produce such contextually relevant language.
The data is collected from games containing situations of non-normative language usage-describing situations that fictional characters may engage in that are potentially inappropriate, and on occasion impossible, for the real world such as running a troll through with a sword. Instances of such scenarios are mitigated by careful curation of the games that the data is collected from. The original Jericho framework [Hausknecht et al., 2020]-further verified by us in this work-uses a curated set of games found not to contain extreme examples of non-normative language usage. This is based on manual vetting and (existing) crowd-sourced reviews on the popular interactive narrative forum IFDB. ${ }^{5}$</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>References</h1>
<p>A. Adhikari, X. Yuan, M.-A. Côté, M. Zelinka, M.-A. Rondeau, R. Laroche, P. Poupart, J. Tang, A. Trischler, and W. Hamilton. Learning dynamic belief graphs to generalize on text-based games. Advances in Neural Information Processing Systems, 33, 2020.
P. Ammanabrolu and M. Hausknecht. Graph Constrained Reinforcement Learning for Natural Language Action Spaces. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=B1x6w0EtwH.
P. Ammanabrolu and M. O. Riedl. Playing text-adventure games with graph-based deep reinforcement learning. In Proceedings of 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 2019.
P. Ammanabrolu, W. Cheung, D. Tu, W. Broniec, and M. O. Riedl. Bringing stories alive: Generating interactive fiction worlds. In Proceedings of the Sixteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE-20), 2020a. URL https://www.aaai.org/ojs/index. php/AIIDE/article/view/7400.
P. Ammanabrolu, E. Tien, M. Hausknecht, and M. O. Riedl. How to avoid being eaten by a grue: Structured exploration strategies for textual worlds. arXiv preprint arXiv:2006.07409, 2020b.
G. Angeli, J. Premkumar, M. Jose, and C. D. Manning. Leveraging Linguistic Structure For Open Domain Information Extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2015.
K. Arulkumaran, M. P. Deisenroth, M. Brundage, and A. A. Bharath. Deep reinforcement learning: A brief survey. IEEE Signal Processing Magazine, 34(6):26-38, 2017. doi: 10.1109/MSP.2017. 2743240 .
C. Bamford and S. M. Lucas. Neural game engine: Accurate learning of generalizable forward models from pixels. In 2020 IEEE Conference on Games (CoG), pages 81-88. IEEE, 2020.
M. G. Bellemare, Y. Naddaf, J. Veness, and M. Bowling. The arcade learning environment: An evaluation platform for general agents. Journal of Artificial Intelligence Research, 47:253-279, jun 2013.
M.-A. Côté, A. Kádár, X. Yuan, B. Kybartas, T. Barnes, E. Fine, J. Moore, M. Hausknecht, L. E. Asri, M. Adada, W. Tay, and A. Trischler. Textworld: A learning environment for text-based games. CoRR, abs/1806.11532, 2018.
S. Dambekodi, S. Frazier, P. Ammanabrolu, and M. O. Riedl. Playing text-based games with common sense. arXiv preprint arXiv:2012.02757, 2020.
J. Devlin, M. Chang, K. Lee, and K. Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. CoRR, abs/1810.04805, 2018.
A. Fan, J. Urbanek, P. Ringshia, E. Dinan, E. Qian, S. Karamcheti, S. Prabhumoye, D. Kiela, T. Rocktaschel, A. Szlam, and Others. Generating Interactive Worlds with Text. arXiv preprint arXiv:1911.09194, 2019.
T. Gebru, J. Morgenstern, B. Vecchione, J. W. Vaughan, H. Wallach, H. Daumé III, and K. Crawford. Datasheets for datasets. arXiv preprint arXiv:1803.09010, 2018.
D. Ha and J. Schmidhuber. Recurrent world models facilitate policy evolution. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf.
M. Hausknecht, P. Ammanabrolu, M.-A. Côté, and X. Yuan. Interactive fiction games: A colossal adventure. In Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI), 2020. URL https://arxiv.org/abs/1909.05398.</p>
<p>D. Jancke. Orientation formed by a spot's trajectory: a two-dimensional population approach in primary visual cortex. Journal of Neuroscience, 20(14):RC86-RC86, 2000.
T. Kudo. Subword regularization: Improving neural network translation models with multiple subword candidates. Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2018. doi: 10.18653/v1/p18-1007.
Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. Albert: A lite bert for self-supervised learning of language representations. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=H1eA7AEtvS.
M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871-7880, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https://www.aclweb.org/anthology/2020. acl-main. 703 .
L. Martin, P. Ammanabrolu, X. Wang, W. Hancock, S. Singh, B. Harrison, and M. Riedl. Event representations for automated story generation with deep neural nets. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/ 17046/15769.
K. Murugesan, M. Atzeni, P. Shukla, M. Sachan, P. Kapanipathi, and K. Talamadupula. Enhancing text-based reinforcement learning agents with commonsense knowledge. arXiv preprint arXiv:2005.00811, 2020.
K. Murugesan, M. Atzeni, P. Kapanipathi, P. Shukla, S. Kumaravel, G. Tesauro, K. Talamadupula, M. Sachan, and M. Campbell. Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines. In Thirty Fifth AAAI Conference on Artificial Intelligence, 2021.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311-318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL https://www.aclweb.org/anthology/ P02-1040.
A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language Models are Unsupervised Multitask Learners. 2019.
P. Rajpurkar, R. Jia, and P. Liang. Know what you don't know: Unanswerable questions for SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784-789, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-2124. URL https://www.aclweb.org/anthology/ P18-2124.
C. Sautier, D. J. Agravante, and M. Tatsubori. State Prediction in TextWorld with a Predicate-Logic Pointer Network Architecture. In In Workshop on Knowledge-based Reinforcment Learning at IJCAI-20, 2020. URL https://kbrl.github.io/papers/08-KBRL.pdf.
J. Schrittwieser, I. Antonoglou, T. Hubert, K. Simonyan, L. Sifre, S. Schmitt, A. Guez, E. Lockhart, D. Hassabis, T. Graepel, et al. Mastering atari, go, chess and shogi by planning with a learned model. arXiv preprint arXiv:1911.08265, 2019.
M. Shridhar, X. Yuan, M.-A. Cote, Y. Bisk, A. Trischler, and M. Hausknecht. {ALFW}orld: Aligning text and embodied environments for interactive learning. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=0IOX0YcCdTn.
I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems Volume 2, NIPS'14, page 3104-3112, Cambridge, MA, USA, 2014. MIT Press.</p>
<p>R. S. Sutton and A. G. Barto. Introduction to Reinforcement Learning. MIT Press, Cambridge, MA, USA, 1st edition, 1998. ISBN 0262193981.
R. Tamari, F. Bai, A. Ritter, and G. Stanovsky. Process-level representation of scientific protocols with interactive annotation. arXiv preprint arXiv:2101.10244, 2021.
S. Thrun, W. Burgard, and D. Fox. Probabilistic Robotics (Intelligent Robotics and Autonomous Agents). The MIT Press, 2005. ISBN 0262201623.
J. Urbanek, A. Fan, S. Karamcheti, S. Jain, S. Humeau, E. Dinan, T. Rocktäschel, D. Kiela, A. Szlam, and J. Weston. Learning to speak and act in a fantasy text adventure game. CoRR, abs/1903.03094, 2019.
N. Walton et al. AI Dungeon. https://play.aidungeon.io/, 2020.
S. Wiseman, S. Shieber, and A. Rush. Challenges in data-to-document generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2253-2263, Copenhagen, Denmark, Sept. 2017. Association for Computational Linguistics. doi: 10.18653/v1/ D17-1239. URL https://www.aclweb.org/anthology/D17-1239.
S. Yao, R. Rao, M. Hausknecht, and K. Narasimhan. Keep CALM and explore: Language models for action generation in text-based games. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8736-8754, Online, Nov. 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.704. URL https://www.aclweb.org/anthology/2020.emnlp-main. 704.</p>
<h1>A Appendix</h1>
<p>We would first like to note the presence of a complementary dataset of observation-action pairs created by humans on the ClubFloyd online Interactive Narrative forum. ${ }^{6}$ This dataset appears in both Ammanabrolu and Hausknecht [2020] and Yao et al. [2020] with the latter using it to tune a GPT-2 model for valid action prediction. To prevent data leakage from human transcripts to our test games, we do not use this dataset to pre-train or tune our models.
The rest of this Appendix first provides additional samples for the dataset for qualitative purposes and then provides training details for the baseline models.</p>
<h2>A. 1 Dataset</h2>
<p>The games used in the Jericho suite and here are all open sourced freeware. The walkthroughs required to create the oracle agents for the collection of data for the games were drawn from various sources on the internet and errors were corrected manually. We provide our data at https: //github.com/JerichoWorld/JerichoWorld under an MIT license. We provide 3 samples drawn from different games in the full dataset to help the readers better understand the diversity of text there.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Game</span><span class="o">:</span><span class="w"> </span><span class="mi">905</span>
<span class="n">Location</span><span class="o">:</span>
<span class="w">    </span><span class="n">Bedroom</span><span class="w"> </span><span class="o">(</span><span class="k">in</span><span class="w"> </span><span class="n">bed</span><span class="o">)</span>
<span class="w">    </span><span class="n">This</span><span class="w"> </span><span class="n">bedroom</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">extremely</span><span class="w"> </span><span class="n">spare</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">dirty</span><span class="w"> </span><span class="n">laundry</span><span class="w"> </span><span class="n">scattered</span><span class="w"> </span><span class="n">haphazardly</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">floor</span><span class="o">.</span><span class="w"> </span><span class="n">Cleaner</span>
<span class="w">        </span><span class="n">clothing</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">found</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">dresser</span><span class="o">.</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">bathroom</span><span class="w"> </span><span class="n">lies</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">south</span><span class="o">,</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">door</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span>
<span class="w">        </span><span class="n">leads</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">living</span><span class="w"> </span><span class="n">room</span><span class="o">.</span>
<span class="w">    </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">telephone</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wallet</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">keys</span><span class="o">.</span>
<span class="w">    </span><span class="n">The</span><span class="w"> </span><span class="n">phone</span><span class="w"> </span><span class="n">rings</span><span class="o">.</span>
<span class="n">Observation</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">off</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">gold</span><span class="w"> </span><span class="n">watch</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">phone</span><span class="w"> </span><span class="n">rings</span><span class="o">.</span>
<span class="n">Inventory</span><span class="o">:</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">carrying</span><span class="o">:</span>
<span class="w">        </span><span class="n">some</span><span class="w"> </span><span class="n">soiled</span><span class="w"> </span><span class="n">clothing</span><span class="w"> </span><span class="o">(</span><span class="n">being</span><span class="w"> </span><span class="n">worn</span><span class="o">)</span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="n">gold</span><span class="w"> </span><span class="n">watch</span>
<span class="n">Prev</span><span class="w"> </span><span class="n">Act</span><span class="o">:</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">off</span><span class="w"> </span><span class="n">watch</span>
<span class="n">Inventory</span><span class="w"> </span><span class="n">Objects</span><span class="o">:</span>
<span class="w">    </span><span class="n">gold</span><span class="w"> </span><span class="n">watch</span><span class="o">:</span><span class="w"> </span><span class="n">Apparently</span><span class="w"> </span><span class="n">it</span><span class="s1">&#39;s 9:07. The phone rings.</span>
<span class="s1">    soiled clothing: These clothes are a lost cause, sad to say no amount of laundering is going to get</span>
<span class="s1">        these stains out.</span>
<span class="s1">Inventory Attributes:</span>
<span class="s1">    watch: animate, equip</span>
<span class="s1">    clothing: animate, equip</span>
<span class="s1">Surrounding Objects:</span>
<span class="s1">    phone: An ordinary telephone, notable chiefly for being fifteen or twenty years old.</span>
<span class="s1">    keys: House keys, car keys, they&#39;</span><span class="n">re</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span><span class="w"> </span><span class="n">chain</span><span class="o">.</span>
<span class="w">    </span><span class="n">end</span><span class="w"> </span><span class="n">table</span><span class="o">:</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="n">table</span><span class="o">,</span><span class="w"> </span><span class="n">oak</span><span class="w"> </span><span class="n">veneer</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="n">plywood</span><span class="o">.</span>
<span class="w">    </span><span class="n">living</span><span class="w"> </span><span class="n">room</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">living</span><span class="w"> </span><span class="n">room</span><span class="w"> </span><span class="n">lies</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span><span class="o">.</span>
<span class="w">    </span><span class="n">dirty</span><span class="w"> </span><span class="n">dresser</span><span class="o">:</span><span class="w"> </span><span class="n">Just</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">simple</span><span class="w"> </span><span class="n">dresser</span><span class="o">.</span>
<span class="w">    </span><span class="n">laundry</span><span class="o">:</span><span class="w"> </span><span class="n">Shirts</span><span class="o">,</span><span class="w"> </span><span class="n">pants</span><span class="o">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">usual</span><span class="o">.</span>
<span class="w">    </span><span class="n">floor</span><span class="o">,</span><span class="w"> </span><span class="n">east</span><span class="o">,</span><span class="w"> </span><span class="n">south</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">nothing</span><span class="w"> </span><span class="n">unexpected</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">direction</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">phone</span><span class="w"> </span><span class="n">rings</span><span class="o">.</span>
<span class="w">    </span><span class="n">wallet</span><span class="o">:</span><span class="w"> </span><span class="n">It</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brown</span><span class="w"> </span><span class="n">leather</span><span class="w"> </span><span class="n">wallet</span><span class="o">.</span>
<span class="w">    </span><span class="n">door</span><span class="o">:</span><span class="w"> </span><span class="n">Just</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">regular</span><span class="w"> </span><span class="n">door</span><span class="o">.</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="n">Attributes</span><span class="o">:</span>
<span class="w">    </span><span class="n">keys</span><span class="o">:</span><span class="w"> </span><span class="n">animate</span><span class="o">,</span><span class="w"> </span><span class="n">equip</span>
<span class="w">    </span><span class="n">wallet</span><span class="o">:</span><span class="w"> </span><span class="n">animate</span><span class="o">,</span><span class="w"> </span><span class="n">equip</span>
<span class="n">Graph</span><span class="o">:</span><span class="w"> </span><span class="o">[</span><span class="n">you</span><span class="o">,</span><span class="w"> </span><span class="n">have</span><span class="o">,</span><span class="w"> </span><span class="n">gold</span><span class="w"> </span><span class="n">watch</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">you</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">bed</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">you</span><span class="o">,</span><span class="w"> </span><span class="n">have</span><span class="o">,</span><span class="w"> </span><span class="n">soiled</span><span class="w"> </span><span class="n">clothing</span><span class="o">]</span>
<span class="n">Valid</span><span class="w"> </span><span class="n">Actions</span><span class="o">:</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">phone</span><span class="o">,</span><span class="w"> </span><span class="kd">get</span><span class="w"> </span><span class="n">up</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">off</span><span class="w"> </span><span class="n">clothing</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">off</span><span class="w"> </span><span class="n">watch</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">keys</span><span class="o">,</span><span class="w"> </span><span class="n">close</span><span class="w"> </span><span class="n">door</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">wallet</span><span class="o">,</span>
<span class="w">    </span><span class="n">close</span><span class="w"> </span><span class="n">door</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">clothing</span><span class="w"> </span><span class="n">down</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">watch</span><span class="w"> </span><span class="n">down</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">clothing</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">table</span><span class="o">,</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">wallet</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">watch</span><span class="w"> </span><span class="n">down</span><span class="o">,</span>
<span class="w">    </span><span class="n">put</span><span class="w"> </span><span class="n">clothing</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">phone</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">watch</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">table</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">gold</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">phone</span><span class="o">,</span><span class="w"> </span><span class="n">look</span><span class="w"> </span><span class="n">under</span><span class="w"> </span><span class="n">bed</span>
</code></pre></div>

<p>Game: deephome
Location:
Secret Entrance
This is a rather dark and small room, having only two exits, back north the way you came, from the ancestral homes of Tana, or through the heavily barred wooden door before you that leads southwest and inward to the abandoned Deephome, abode of the Dwarves in Telleen. It has been three hundred years since your people lived here.</p>
<p>The heavy door stands open, admitting you into Deephome.
Observation: As you touch the finely etched symbol, you hear a click and a shir. Then the door swings open before you, opening into the abandoned city of Deephome. Your score has just gone up by five points. Inventory:</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="nl">carrying</span><span class="p">:</span>
<span class="w">        </span><span class="n">King</span><span class="err">&#39;</span><span class="n">s</span><span class="w"> </span><span class="k">Order</span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="n">lantern</span><span class="w"> </span><span class="p">(</span><span class="n">providing</span><span class="w"> </span><span class="n">light</span><span class="p">)</span>
<span class="n">Prev</span><span class="w"> </span><span class="nl">Act</span><span class="p">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">mountain</span>
<span class="n">Inventory</span><span class="w"> </span><span class="nl">Objects</span><span class="p">:</span>
<span class="w">    </span><span class="nl">lantern</span><span class="p">:</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="k">old</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">trusty</span><span class="w"> </span><span class="p">(</span><span class="ow">not</span><span class="w"> </span><span class="n">rusty</span><span class="p">)</span><span class="w"> </span><span class="n">lantern</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">centuries</span><span class="p">.</span><span class="w"> </span><span class="n">It</span>
<span class="w">        </span><span class="n">has</span><span class="w"> </span><span class="n">yet</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">shut</span><span class="w"> </span><span class="k">off</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">inopportune</span><span class="w"> </span><span class="n">moment</span><span class="p">.</span><span class="w"> </span><span class="n">However</span><span class="p">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">saying</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="n">family</span><span class="p">...</span><span class="ss">&quot;That</span>
<span class="ss">        lantern is bound to go off at an inopportune time sometime!&quot;</span>
<span class="k">order</span><span class="err">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="k">reads</span><span class="err">:</span><span class="w"> </span><span class="ss">&quot;Reclaimer: You have the esteemed duty to return to our Mountain Kingdom of</span>
<span class="ss">        Deephome and prepare it for our return. There are several things a Reclaimer must do: 1. Restore</span>
<span class="ss">        Power to the City 2. Restore Water to the city. 3. Visit each location and make sure it is safe,</span>
<span class="ss">        a quick appraisal should be sufficient. 4. Open the City Gates once more. 5. MOST IMPORTANT: Make</span>
<span class="ss">        sure the city is SAFE to return to. May the Peace of Kraxis go with you King Derash of the</span>
<span class="ss">        Mountain Tana, the year 782 SK.&quot;</span>
<span class="n">Inventory</span><span class="w"> </span><span class="nl">Attributes</span><span class="p">:</span>
<span class="w">    </span><span class="nl">lantern</span><span class="p">:</span><span class="w"> </span><span class="n">equip</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="nl">Objects</span><span class="p">:</span>
<span class="w">    </span><span class="nl">southwest</span><span class="p">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">nothing</span><span class="w"> </span><span class="n">special</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">southwest</span><span class="w"> </span><span class="n">wall</span><span class="p">.</span>
<span class="w">    </span><span class="nl">house</span><span class="p">:</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">typical</span><span class="w"> </span><span class="n">human</span><span class="w"> </span><span class="n">house</span><span class="p">,</span><span class="w"> </span><span class="n">maybe</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">stories</span><span class="p">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">etched</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wood</span><span class="p">.</span>
<span class="w">    </span><span class="n">wooden</span><span class="w"> </span><span class="nl">door</span><span class="p">:</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">door</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">made</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">thick</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">sturdy</span><span class="w"> </span><span class="n">wood</span><span class="p">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">three</span><span class="w"> </span><span class="n">symbols</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">it</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tree</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">house</span><span class="p">,</span>
<span class="w">        </span><span class="ow">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">mountain</span><span class="p">.</span>
<span class="w">    </span><span class="nl">symbols</span><span class="p">:</span><span class="w"> </span><span class="k">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">door</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">are</span><span class="w"> </span><span class="n">pictures</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">mountain</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tree</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">house</span><span class="p">.</span>
<span class="w">    </span><span class="nl">tree</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">tree</span><span class="w"> </span><span class="n">symbol</span><span class="w"> </span><span class="n">looks</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">were</span><span class="w"> </span><span class="n">etched</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wood</span><span class="p">.</span>
<span class="w">    </span><span class="nl">mountain</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">mountain</span><span class="w"> </span><span class="n">looks</span><span class="w"> </span><span class="n">mighty</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">high</span><span class="w"> </span><span class="n">peak</span><span class="w"> </span><span class="n">among</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">clouds</span><span class="p">.</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">etched</span><span class="w"> </span><span class="k">into</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">wood</span><span class="p">.</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="nl">Attributes</span><span class="p">:</span>
<span class="w">    </span><span class="nl">door</span><span class="p">:</span><span class="w"> </span><span class="n">unlockable</span>
<span class="w">    </span><span class="nl">symbols</span><span class="p">:</span><span class="w"> </span><span class="n">unlock</span>
<span class="nl">Graph</span><span class="p">:</span><span class="w"> </span><span class="o">[</span><span class="n">symbols, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">wooden door, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">ground, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span>
<span class="w">        </span><span class="o">[</span><span class="n">you, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">house, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">Kraxis, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">you, have,</span>
<span class="n">        lantern</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">mountain, in, Secret Entrance</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">you, have, &quot;Kings Order&quot;</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">tree, in, Secret Entrance</span><span class="o">]</span>
<span class="n">Valid</span><span class="w"> </span><span class="nl">Actions</span><span class="p">:</span><span class="w"> </span><span class="n">say</span><span class="w"> </span><span class="n">manaz</span><span class="p">,</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">mountain</span><span class="p">,</span><span class="w"> </span><span class="k">close</span><span class="w"> </span><span class="n">wooden</span><span class="p">,</span><span class="w"> </span><span class="k">get</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">southwest</span><span class="p">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">light</span><span class="w"> </span><span class="n">down</span><span class="p">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="k">order</span><span class="w"> </span><span class="n">down</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">Game</span><span class="o">:</span><span class="w"> </span><span class="n">reverb</span>
<span class="n">Location</span><span class="o">:</span>
<span class="w">    </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Counter</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="s2">&quot;Mr. Tasty&#39;s Pizza Parlor&quot;</span><span class="o">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">southwest</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rest</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span>
<span class="w">        </span><span class="n">restaurant</span><span class="o">.</span>
<span class="w">    </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="o">(</span><span class="n">which</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">closed</span><span class="o">).</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">here</span><span class="o">.</span>
<span class="n">Observation</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">.</span>
<span class="n">Inventory</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">carrying</span><span class="w"> </span><span class="n">nothing</span><span class="o">.</span>
<span class="n">Prev</span><span class="w"> </span><span class="n">Act</span><span class="o">:</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">counter</span>
<span class="n">Inventory</span><span class="w"> </span><span class="n">Objects</span><span class="o">:</span>
<span class="n">Inventory</span><span class="w"> </span><span class="n">Attributes</span><span class="o">:</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="n">Objects</span><span class="o">:</span>
<span class="w">    </span><span class="n">southwest</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">nothing</span><span class="w"> </span><span class="n">special</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">southwest</span><span class="w"> </span><span class="n">wall</span><span class="o">.</span>
<span class="w">    </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">reads</span><span class="o">:</span><span class="w"> </span><span class="s2">&quot;Stanley, Don&#39;t forget to make your delivery to Mr. Calzone, located</span>
<span class="s2">        at the San Doppleton Courthouse. You&#39;re already on thin ice, kid. One more screwup and you can</span>
<span class="s2">        expect to be looking for a new job.&quot;</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">signed</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">initials</span><span class="w"> </span><span class="s2">&quot;RT&quot;</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">paper</span><span class="w"> </span><span class="k">is</span>
<span class="w">        </span><span class="n">official</span><span class="w"> </span><span class="s2">&quot;Mr. Tasty&#39;s&quot;</span><span class="w"> </span><span class="n">stationery</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="n">Bob</span><span class="w"> </span><span class="s2">&quot;Tasty&quot;</span><span class="w"> </span><span class="n">Tasker</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">lots</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">balloons</span><span class="w"> </span><span class="n">and</span>
<span class="w">        </span><span class="n">smiley</span><span class="w"> </span><span class="n">faces</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">border</span><span class="o">.</span><span class="w"> </span><span class="n">Isn</span><span class="s1">&#39;t that cute?</span>
<span class="s1">    large pizza box: It&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="o">,</span><span class="w"> </span><span class="n">flat</span><span class="o">,</span><span class="w"> </span><span class="n">greasy</span><span class="w"> </span><span class="n">cardboard</span><span class="w"> </span><span class="n">box</span><span class="o">.</span><span class="w"> </span><span class="n">Hastily</span><span class="w"> </span><span class="n">scrawled</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">outside</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">word</span>
<span class="w">        </span><span class="s2">&quot;Calzone&quot;</span><span class="o">.</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">weird</span><span class="o">,</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">it</span><span class="s1">&#39;s clearly a pizza.</span>
<span class="s1">    counter: It&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">majorly</span><span class="w"> </span><span class="n">boring</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">you</span><span class="err">&#39;</span><span class="n">re</span><span class="w"> </span><span class="n">unfortunately</span><span class="w"> </span><span class="n">very</span><span class="w"> </span><span class="n">familiar</span><span class="w"> </span><span class="k">with</span><span class="o">.</span>
<span class="n">Surrounding</span><span class="w"> </span><span class="n">Attributes</span><span class="o">:</span>
<span class="w">    </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span><span class="o">,</span><span class="w"> </span><span class="n">readable</span>
<span class="w">    </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span>
<span class="w">    </span><span class="n">counter</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span>
<span class="n">Graph</span><span class="o">:</span><span class="w"> </span><span class="o">[</span><span class="n">metal</span><span class="w"> </span><span class="n">file</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">you</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Counter</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">Counter</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span><span class="w"> </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Counter</span><span class="o">],</span><span class="w"> </span><span class="o">[</span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="o">,</span><span class="w"> </span><span class="k">in</span><span class="o">,</span>
<span class="w">        </span><span class="n">counter</span><span class="o">]</span>
<span class="n">Valid</span><span class="w"> </span><span class="n">Actions</span><span class="o">:</span><span class="w"> </span><span class="kd">get</span><span class="w"> </span><span class="n">up</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">note</span><span class="o">,</span><span class="w"> </span><span class="n">take</span><span class="w"> </span><span class="n">large</span><span class="o">,</span><span class="w"> </span><span class="n">examine</span><span class="w"> </span><span class="n">note</span><span class="o">,</span><span class="w"> </span><span class="n">undo</span><span class="w"> </span><span class="n">large</span><span class="o">,</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">southwest</span><span class="o">,</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">large</span>
<span class="w">        </span><span class="n">to</span><span class="w"> </span><span class="n">southwest</span><span class="o">,</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">push</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">counter</span>
</code></pre></div>

<h1>A. 2 Baselines</h1>
<p>The baseline models that are adapted from other works, i.e. the Rules and QA systems, are trained using hyperparameters and methodologies described in their respective works.</p>
<h2>A.2.1 Rules</h2>
<p>Following Ammanabrolu and Hausknecht [2020], the exact details regarding knowledge graph updates are found as follows. At every step, given the current state and possible attributes as context. The rest of the triples are extracted using OpenIE [Angeli et al., 2015].</p>
<ul>
<li>Linking the current room type (e.g. "Kitchen", "Cellar") to the items found in the room with the relation "has", e.g. $\langle$ kitchen, has, lamp $\rangle$</li>
<li>All attribute information for each object is linked to the object with the relation "is". e.g. $\langle$ egg, is, treasure $\rangle$</li>
<li>Linking all inventory objects with relation "have" to the "you" node, e.g. $\langle$ you, have, sword $\rangle$</li>
<li>Linking rooms with directions based on the action taken to move between the rooms, e.g. $\langle$ Behind House, east of, Forest $\rangle$ after the action "go east" is taken to go from behind the house to the forest</li>
</ul>
<h1>A.2.2 Question-Answering</h1>
<p>The QA models are trained on the SQuAD 2.0 [Rajpurkar et al., 2018], the Jericho-QA text game question answering dataset on the same set of training games as found in JerichoWorld, and then on JerichoWorld itself by formatting our dataset in the style of questions and answers when possible. Our dataset is formatted in the style of Jericho-QA by templating questions that ask about location, objects (including characters), and attributes. An example of a JerichoWorld dataset example converted to Jericho-QA format is seen below-though we would like to note that this removes much of the information present naturally within our dataset. All other model architecture and hyperparameter details are as seen in Ammanabrolu et al. [2020b].</p>
<div class="codehilite"><pre><span></span><code><span class="n">Game</span><span class="o">:</span><span class="w"> </span><span class="n">reverb</span>
<span class="n">Location</span><span class="o">:</span>
<span class="w">    </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Counter</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="s2">&quot;Mr. Tasty&#39;s Pizza Parlor&quot;</span><span class="o">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">southwest</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rest</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span>
<span class="w">        </span><span class="n">restaurant</span><span class="o">.</span>
<span class="w">    </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="o">(</span><span class="n">which</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">closed</span><span class="o">).</span>
<span class="w">    </span><span class="n">You</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">here</span><span class="o">.</span>
<span class="n">Observation</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">.</span>
<span class="n">Inventory</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">carrying</span><span class="w"> </span><span class="n">nothing</span><span class="o">.</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">Where</span><span class="w"> </span><span class="n">am</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">located</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">Behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Counter</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">What</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">here</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="o">,</span><span class="w"> </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="o">,</span><span class="w"> </span><span class="n">southwest</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">What</span><span class="w"> </span><span class="k">do</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">have</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">nothing</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">What</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">handwritten</span><span class="w"> </span><span class="n">note</span><span class="w"> </span><span class="n">have</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span><span class="o">,</span><span class="w"> </span><span class="n">readable</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">What</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">southwest</span><span class="w"> </span><span class="n">have</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span>
<span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">What</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">pizza</span><span class="w"> </span><span class="n">box</span><span class="w"> </span><span class="n">have</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">indoor</span>
</code></pre></div>

<h2>A.2.3 Seq2Seq</h2>
<p>For both tasks, models were trained until validation accuracy (picked to be a random $10 \%$ subset of the training data) did not improve for 5 epochs or 72 wall clock hours on a machine with 4 Nvidia GeForce RTX 2080 GPUs, three times with three random seeds. All models decode using beam search with a beam width of 15 at test time until the end-of-sequence tag is reached. The size of the decoding vocabulary for the action prediction task is 11056 and for the graph prediction task is 6985 . Hyperparameters were not tuned and were taken from BART [Lewis et al., 2020].</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Hyperparameter type</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Dictionary Tokenizer</td>
<td style="text-align: left;">Byte-pair encoding</td>
</tr>
<tr>
<td style="text-align: left;">Num. Encoder layers</td>
<td style="text-align: left;">6</td>
</tr>
<tr>
<td style="text-align: left;">Num. Decoder layers</td>
<td style="text-align: left;">6</td>
</tr>
<tr>
<td style="text-align: left;">Num. encoder and decoder attention heads</td>
<td style="text-align: left;">8</td>
</tr>
<tr>
<td style="text-align: left;">Feedforward network hidden size</td>
<td style="text-align: left;">4096</td>
</tr>
<tr>
<td style="text-align: left;">Input length</td>
<td style="text-align: left;">1024</td>
</tr>
<tr>
<td style="text-align: left;">Embedding size</td>
<td style="text-align: left;">768</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: left;">16</td>
</tr>
<tr>
<td style="text-align: left;">Dropout ratio</td>
<td style="text-align: left;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">Gradient clip</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">Optimizer</td>
<td style="text-align: left;">Adam</td>
</tr>
<tr>
<td style="text-align: left;">Learning rate</td>
<td style="text-align: left;">$1.0 \times 10^{-3}$</td>
</tr>
</tbody>
</table>
<p>Table 4: Hyperparameters used to train the Seq2Seq model. It has a total of 232 million trainable parameters.</p>
<h1>B Datasheet</h1>
<p>We provide comprehensive documentation of the dataset based on Datasheets for Datasets [Gebru et al., 2018].</p>
<h2>B. 1 Motivation</h2>
<p>For what purpose was the dataset created? Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description. We seek to create agents that exhibit human-like capabilities such as commonsense reasoning and natural language understanding in interactive and situated settings. In pursuit of this goal, we provide a dataset that enables the creation of learning agents that can build knowledge graph-based world models of interactive narratives.
Who created this dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)? It was created by Prithviraj Ammanabrolu and Mark Riedl at the Georgia Institute of Technology.
Who funded the creation of the dataset? If there is an associated grant, please provide the name of the grantor and the grant name and number. It was funded by the US's Defense Advanced Research Projects Agency (DARPA) as part of a fundamental science research grant Science of Artificial Intelligence and Learning for Open-world Novelty (SAIL-ON https://www.darpa. mil/program/science-of-artificial-intelligence-and-learning-for-open-world-novelty).</p>
<h2>B. 2 Composition</h2>
<p>What do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)? Are there multiple types of instances (e.g., movies, users, and ratings; people and interactions between them; nodes and edges)? Please provide a description. Each instance of our dataset takes the tuples of $\left\langle s_{t}, a_{t}, s_{t+1}, r_{t+1}\right\rangle$ where $s_{t}$ and $s_{t+1}$ are two subsequent states of a text game with $a_{t}$ being the action used to transition states and $r_{t+1}$ is the observed reward for some step $t$. Everything is in text. These are all collected from various text games and examples of instances are found in Appendix A.1.</p>
<p>How many instances are there in total (of each type, if appropriate)? The training data has 24198 mappings and is collected across 27 games in multiple genres and contains a further 7836 heldout instances over 9 additional games in the test set.
Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set? If the dataset is a sample, then what is the larger set? Is the sample representative of the larger set (e.g., geographic coverage)? If so, please describe how this representativeness was validated/verified. If it is not representative of the larger set, please describe why not (e.g., to cover a more diverse range of instances, because instances were withheld or unavailable). The dataset is a sample of the larger set of all possible states in each game. The samples are made to be biased towards states near the walkthroughs required to finish a game.
What data does each instance consist of? "Raw" data (e.g., unprocessed text or images)or features? In either case, please provide a description. Data is all in the form of text, either raw or in structured knowledge graph form.
Is there a label or target associated with each instance? If so, please provide a description. The data has multiple fields, depending on the tasks defined any of them can be used as labels. E.g. the knowledge graph prediction task has the graph field as the target.
Is any information missing from individual instances? If so, please provide a description, explaining why this information is missing (e.g., because it was unavailable). This does not include intentionally removed information, but might include, e.g., redacted text Not all games have human readable attributes for objects-when they do not, these are omitted by leaving the attributes fields blank. All other data is present for all instances.
Are relationships between individual instances made explicit (e.g., users' movie ratings, social network links)? If so, please describe how these relationships are made explicit. Instances are grouped together by game through the game field.</p>
<p>Are there recommended data splits (e.g., training, development/validation, testing)? If so, please provide a description of these splits, explaining the rationale behind them. We provide a training split of 27 games, and a testing split of 9 games. These are selected on the basis of existing works and each split contains a diverse set of games in terms of genre.
Are there any errors, sources of noise, or redundancies in the dataset? If so, please provide a description.</p>
<p>Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)? If it links to or relies on external resources, a) are there guarantees that they will exist, and remain constant, over time; b) are there official archival versions of the complete dataset (i.e., including the external resources as they existed at the time the dataset was created); c) are there any restrictions (e.g., licenses, fees) associated with any of the external resources that might apply to a future user? Please provide descriptions of all external resources and any restrictions associated with them, as well as links or other access points, as appropriate. The creation of the dataset depends on the Jericho framework https: //github.com/microsoft/jericho but the archival versions themselves do not have any dependencies.
Does the dataset contain data that might be considered confidentiality, data that includes the content of individuals non-public communications)? If so, please provide a description. No, all data is part of games that are already public.
Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? If so, please describe why. The data is collected from games containing situations of non-normative language usage-describing situations that fictional characters may engage in that are potentially inappropriate, and on occasion impossible, for the real world such as running a troll through with a sword. Instances of such scenarios are mitigated by careful curation of the games that the data is collected from. The original Jericho framework [Hausknecht et al., 2020]-further verified by us in this work-uses a curated set of games found not to contain extreme examples of non-normative language usage. This is based on manual vetting and (existing) crowd-sourced reviews on the popular interactive narrative forum IFDB https://ifdb.org/.</p>
<h1>B. 3 Collection</h1>
<p>How was the data associated with each instance acquired? Was the data directly observable (e.g., raw text, movie ratings), reported by subjects (e.g., survey responses), or indirectly inferred/derived from other data (e.g., part-of-speech tags, model-based guesses for age or language)? If data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified? If so, please describe how We build off the popular text game simulator Jericho [Hausknecht et al., 2020], we have constructed a dataset dubbed JerichoWorld that maps text game state observations to both the underlying ground truth knowledge graph representations of the game and the set of contextually relevant actions that can be performed in that state.
What mechanisms or procedures were used to collect the data (e.g., hardware apparatus or sensor, manual human curation, software program, software API)? How were these mechanisms or procedures validated? To collect the $\left\langle s_{t}, a_{t}, s_{t+1}, r_{t+1}\right\rangle$ tuples we implement a basic agent that explores the game along a trajectory corresponding to a game walkthrough. Game walkthroughs are texts describing the solutions to games, generally retrieved from the internet, but already part of the Jericho framework. Walkthroughs, however, only present one possible solution to a game and solve all the core puzzles required to complete a game with the maximum possible score. To achieve greater coverage of the game's state space, our data collection agent stops off to explore by executing random valid actions for $n$ steps before resetting to the walkthrough.
If the dataset is a sample from a larger set, what was the sampling strategy (e.g., deterministic, probabilistic with specific sampling probabilities)? Randomly sampled actions are based on a random seed in Python's random package https://docs.python.org/3/library/random.html. We provide a seed and the specific package version.
Who was involved in the data collection process (e.g., students, crowdworkers, contractors) and how were they compensated (e.g., how much were crowdworkers paid)? Only the authors were involved, building on the contributions of the Jericho developers.</p>
<p>Over what timeframe was the data collected? Does this timeframe match the creation timeframe of the data associated with the instances (e.g., recent crawl of old news articles)? If not, please describe the timeframe in which the data associated with the instances was created. This dataset was developed over a period of 6 months, though the games used within date back to the 1970s.</p>
<p>Were any ethical review processes conducted (e.g., by an institutional review board)? If so, please provide a description of these review processes, including the outcomes, as well as a link or other access point to any supporting documentation. No human subjects were involved, no IRB process was undertaken.</p>
<h1>B. 4 Preprocessing</h1>
<p>Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)? If so, please provide a description. If not, you may skip the remainder of the questions in this section. Games were decompiled to extract attributes and ground truth knowledge graphs, the creation script is provided in the GitHub repo.
Was the "raw" data saved in addition to the preprocessed/cleaned/labeled data (e.g., to support unanticipated future uses)? If so, please provide a link or other access point to the "raw" data. No, raw binary game states were not saved and were converted to human readable text.
Is the software used to preprocess/clean/label the instances available? If so, please provide a link or other access point. Games were decompiled to extract attributes and ground truth knowledge graphs, the creation script will be provided in the GitHub repository.</p>
<h2>B. 5 Uses</h2>
<p>Has the dataset been used for any tasks already? If so, please provide a description. No.
Is there a repository that links to any or all papers or systems that use the dataset? If so, please provide a link or other access point. No.
What (other) tasks could the dataset be used for? There are many more tasks that can be framed for other challenges related to world modeling from this dataset. Some immediate examples: (1) offline reinforcement learning for game agents through imitation learning-predicting the sequence of actions that finish the game based on walkthroughs and reward information; (2) knowledge graph verbalization, a form of the standard data-to-text natural language processing task [Wiseman et al., 2017], in which we learn to generate text that is conditioned on a knowledge graph; and (3) description generation conditioned on the names of various objects, locations, and characters-with applications in long-form text generation domains such as automated storytelling [Martin et al., 2018, Fan et al., 2019] and procedural generation of interactive narratives [Ammanabrolu et al., 2020a, Walton et al., 2020].
Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? For example, is there anything that a future user might need to know to avoid uses that could result in unfair treatment of individuals or groups (e.g., stereotyping, quality of service issues) or other undesirable harms (e.g., financial harms, legal risks) If so, please provide a description. Is there anything a future user could do to mitigate these undesirable harms? Users should keep in mind that these come from games and can potentially describe non-normative situations.
Are there tasks for which the dataset should not be used? If so, please provide a description This dataset should not be used for tasks that involve direct physical interactions with humans, such as robotics.</p>
<h2>B. 6 Distribution</h2>
<p>Will the dataset be distributed to third parties outside of the entity (e.g., company, institution, organization) on behalf of which the dataset was created? If so, please provide a description. It is open-sourced.</p>
<p>How will the dataset will be distributed (e.g., tarball on website, API, GitHub)? Does the dataset have a digital object identifier (DOI)? The dataset will be open-sourced at https://github. com/JerichoWorld/JerichoWorld.</p>
<p>When will the dataset be distributed? It was first released in May 2021.
Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)? If so, please describe this license and/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms or ToU, as well as any fees associated with these restrictions. The dataset will be under an MIT license, this is indicated on the GitHub repository.
Have any third parties imposed IP-based or other restrictions on the data associated with the instances? If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with these restrictions. No.</p>
<p>Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any supporting documentation. No.</p>
<h1>B. 7 Maintenance</h1>
<p>Who is supporting/hosting/maintaining the dataset? Prithviraj Ammanabrolu will be responsible for maintenance.</p>
<p>How can the owner/curator/manager of the dataset be contacted (e.g., email address)? raj.ammanabrolu@gatech.edu or by filing an issue on the GitHub.
Is there an erratum? If so, please provide a link or other access point No.
Will the dataset be updated (e.g., to correct labeling errors, add new instances, delete instances)? If so, please describe how often, by whom, and how updates will be communicated to users (e.g., mailing list, GitHub)? Yes, more games will be added and corresponding data will be collected. Previous versions will be kept for backwards compatibility.
If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (e.g., were individuals in question told that their data would be retained for a fixed period of time and then deleted)? If so, please describe these limits and explain how they will be enforced. No.</p>
<p>Will older versions of the dataset continue to be supported/hosted/maintained? If so, please describe how. If not, please describe how its obsolescence will be communicated to users. Yes, versions will be archived on the GitHub repository.
If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so? If so, please provide a description. Will these contributions be validated/verified? If so, please describe how. If not, why not? Is there a process for communicating/distributing these contributions to other users? If so, please provide a description They can fork and submit pull requests to the current repository if they wish to extend it-these will be validated in an open-source manner on GitHub via reviews of the extensions.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ http://www.allthingsjacq.com/interactive_fiction.html&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>