<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2524 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2524</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2524</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-227745938</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2012.04225v2.pdf" target="_blank">Active Learning: Problem Settings and Recent Developments</a></p>
                <p><strong>Paper Abstract:</strong> In supervised learning, acquiring labeled training data for a predictive model can be very costly, but acquiring a large amount of unlabeled data is often quite easy. Active learning is a method of obtaining predictive models with high precision at a limited cost through the adaptive selection of samples for labeling. This paper explains the basic problem settings of active learning and recent research trends. In particular, research on learning acquisition functions to select samples from the data for labeling, theoretical work on active learning algorithms, and stopping criteria for sequential data acquisition are highlighted. Application examples for material development and measurement are introduced.</p>
                <p><strong>Cost:</strong> 0.029</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2524.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2524.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BALD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Active Learning by Disagreement</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An acquisition strategy that selects queries maximizing mutual information between predictions and model posterior (i.e., high predictive entropy but low expected entropy under parameter posterior), aiming to reduce posterior uncertainty about model parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bayesian Active Learning for Classification and Preference Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BALD (Bayesian Active Learning by Disagreement)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A Bayesian acquisition function that evaluates candidate inputs by the mutual information between the predicted label and the model parameter posterior: it selects points with high entropy in the predictive distribution but low expected entropy conditioned on parameters. Implementations typically use approximate Bayesian deep models (e.g., dropout as approximate Bayesian NN) and compute per-sample mutual information to rank queries.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General supervised learning; highlighted for deep learning and classification tasks (e.g., image classification).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Rank unlabeled candidates by mutual information (predictive entropy minus expected parameter-conditional entropy) and select top queries; can be extended to batch selection (BatchBALD) that accounts for joint information of a batch.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of forward passes / Monte Carlo samples for approximate posterior (e.g., multiple stochastic passes for Bayesian NN), and number of label queries (label budget).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Mutual information between label and model posterior; predictive entropy minus expected entropy under parameter posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Prefers examples that maximally reduce parameter uncertainty (exploration of uncertain regions) rather than purely exploiting high-performing hypotheses; in batch variants (BatchBALD) it explicitly accounts for joint information across the batch to avoid redundancy.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>BatchBALD extends BALD by selecting jointly informative and thus diverse batches (accounts for joint mutual information), reducing redundancy among selected points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Label budget (fixed number of queries); computational budget via approximate posterior sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Select top-ranked points until budget exhausted; for batch selection account jointly for batch information (BatchBALD) to maximize information per labeling cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported qualitatively as strong performance for deep active learning; in the paper BatchBALD is said to be among best performing methods (no numerical metric given in this survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Uncertainty sampling, entropy sampling, margin sampling, random sampling, other acquisition heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Survey states BALD and BatchBALD are high-performing compared with common heuristics for Bayesian deep learners (no specific numbers in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not numerically specified in survey; conceptual improvement in information per label by selecting high mutual-information samples.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>BALD focuses on information gain (parameter uncertainty reduction) and can avoid selecting redundant points if batch mutual information is considered; computational cost rises with approximate posterior sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Selecting queries by mutual information is effective for reducing posterior uncertainty; batch extensions that consider joint information mitigate redundancy and improve label-efficiency for deep models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2524.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BatchBALD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Batchbald: Efficient and diverse batch acquisition for deep Bayesian active learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch-mode extension of BALD that approximates joint mutual information of a candidate batch to select diverse, jointly informative sets under a labeling budget.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BatchBALD</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An acquisition algorithm that approximates the joint mutual information between a candidate batch of unlabeled inputs and model posterior; it greedily constructs a batch maximizing joint information to select diverse, non-redundant queries for batch labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Deep Bayesian active learning for classification (e.g., image recognition).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy batch construction maximizing estimated joint mutual information subject to a batch size constraint; selects batches rather than single points to match parallel labeling or costly retraining scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost of computing joint mutual information approximations (Monte Carlo sampling over model posterior) and labeling cost per batch; model retraining time per acquisition round.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Estimated joint mutual information of the batch with the model posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via selecting high-joint-information batches (targets areas that reduce posterior uncertainty); implicitly trades off redundant exploitation by penalizing overlap in information across batch items.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: joint mutual information objective discourages redundant samples and thereby induces diversity in selected batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch size constraints and label budget per round.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy selection under fixed batch size budget to approximate the optimal batch-information objective.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey cites BatchBALD as one of the best-performing methods for batch deep Bayesian active learning (no numeric values provided in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single-sample BALD, uncertainty heuristics, random sampling, naive top-k selection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Reported to outperform single-sample heuristics by selecting diverse informative batches; no numeric comparisons in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not quantified here; described as improving label-efficiency and reducing redundant queries in batch settings.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Balances information gain with diversity implicitly via joint mutual information; computational burden high due to joint-information estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Joint-information-aware batch selection yields better label-efficiency than naive repeated single-sample selection when retraining cost or parallel labeling makes batch queries necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2524.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QBC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Query by Committee</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An uncertainty-sampling family where a committee (ensemble) of hypotheses is used and samples are queried when committee members disagree, aiming to most efficiently reduce version space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Query by Committee</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Query by Committee (QBC)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Construct an ensemble or sample hypotheses from the version space and measure disagreement (e.g., vote entropy); query instances where committee members most disagree to maximally reduce the hypothesis version space.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Binary and multiclass classification; theoretical analysis of label complexity and version-space reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select unlabeled points where sampled hypotheses disagree (high committee vote entropy); sampling from version space is used to identify informative queries.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost to sample/maintain multiple hypotheses or committees and to evaluate predictions for candidate points (ensemble forward passes); number of labels requested (label complexity).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Version-space reduction or disagreement measure (vote entropy); expected decrease in generalization error due to shrinking version space.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Targets regions of hypothesis uncertainty (exploration of ambiguous regions) rather than exploiting high-confidence areas; disagreement-driven selection naturally explores hypotheses that are plausible under current data.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Committee disagreement encourages sampling across boundaries of competing hypotheses; not an explicit diversity optimization but tends to sample diverse boundary points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Label budget / number of queries (label complexity).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Query high-disagreement points until budget exhausted; theoretical analyses consider how many queries needed to reduce version space to desired size.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Theoretically, generalization error can decrease exponentially with the number of queries in idealized noise-free settings; empirical improvements over random sampling are reported historically (no numeric values in this survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random sampling, uncertainty heuristics, version-space greedy approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>QBC shown historically to achieve faster version-space reduction than random sampling in idealized settings; survey notes implementation difficulty in sampling realistic version spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Potential exponential decrease in error for noise-free discrimination problems (theoretical limit); practical gains depend on committee construction.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>QBC focuses on hypothesis uncertainty but may be computationally costly to implement; sampling hypotheses from version space is nontrivial and approximations are needed.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Sampling by committee disagreement is effective for version-space reduction; efficient implementations require approximations (e.g., projection to low-dimensions) to be practical.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2524.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Submodular Batch Selection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy batch selection via submodular objectives (entropy, Fisher-information approximations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formulate batch selection as maximizing a monotone submodular set function (e.g., entropy, Fisher-information surrogate) so that greedy selection yields provable 1-1/e approximation guarantees under cardinality constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Batch mode active learning and its application to medical image classification</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Submodular Greedy Batch Active Learning</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Define a monotone submodular value function over subsets of unlabeled points (e.g., entropy of predictions, approximations of Fisher information mismatch Tr[I_q^{-1} I_p]) and apply a greedy selection (iteratively add element with largest marginal gain) to pick a batch of size k with guaranteed approximation to the optimal batch.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Pool-based batch active learning for classification and parametric models (logistic regression) and broader settings via surrogates.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy maximization of a submodular objective until batch size limit met; objective measures information or closeness of selected-batch distribution to pooled data distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of objective evaluations (marginal gains) and cost of computing the surrogate (e.g., Fisher matrix traces); labeling budget as number of queries.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Entropy of predicted labels, Fisher-information-based trace objective Tr[I_q^{-1} I_p], or other submodular surrogates for expected error reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Greedy selection with submodular objective naturally embodies diminishing returns (encourages exploration/diversity early then exploitation); the objective can be chosen to trade off representativeness vs uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Submodularity (diminishing marginal returns) encourages coverage/diversity among selected points; objectives like Fisher information encourage representative coverage of pooled data.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size (k) and label budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy algorithm yields a guaranteed (1 - 1/e) approximation to optimal subset under fixed-cardinality budget; surrogate choices affect practical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Theoretical approximation ratio 1 - 1/e for monotone submodular objectives; empirical gains reported in literature for batch selection (no numeric values in this survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Naive top-k repeated single-sample selection, random sampling, task-specific heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Greedy submodular batch selection provides theoretical guarantees and tends to outperform naive repeated single-sample selection by avoiding redundancy; specific numeric comparisons not provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Provable near-optimality under submodular objective (1 - 1/e) ensures efficient use of a fixed batch budget.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Submodular objectives let practitioners tune representativeness vs informativeness; however, choosing a surrogate with valid submodularity and computational tractability is key.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When a suitable monotone submodular objective exists, greedy batch selection is an efficient, near-optimal policy for allocating labeling budget across a batch.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2524.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adaptive Submodularity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive Submodularity (policy-level generalization of submodularity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generalization of submodularity to adaptive policies where value of future selections depends on observed outcomes; it enables greedy policies with performance guarantees for sequential active learning under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Adaptive submodularity: Theory and applications in active learning and stochastic optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adaptive Submodularity Framework</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extends submodularity to adaptive decision-making: define conditional marginal benefits of actions given observed labels, and show that certain objectives (e.g., version-space reduction) are adaptively submodular so that a greedy adaptive policy attains approximation guarantees to the optimal adaptive policy.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Sequential active learning, generalized binary search, budgeted labeling policies, and other adaptive experiment-design problems with stochastic outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Run an adaptive greedy policy that at each step selects the action with largest expected marginal gain conditioned on observations so far; stop when version space reduced or budget exhausted.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Expected number of labels (label cost), computational overhead to compute conditional expected marginal gains under model/posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected marginal reduction in target objective (e.g., version-space size, entropy); formalized as expected value under current posterior of hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Adaptive greedy policies explicitly trade off exploration and exploitation by using posterior-conditioned expected gains; guarantees hold for adaptively submodular objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Adaptive submodularity leads to selection diversity because marginal gains diminish after similar selections, discouraging redundant queries.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Labeling cost budget; cumulative cost minimization of labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy adaptive policy with approximation guarantees for minimizing cumulative cost (select until budget exhausted or objective met); special algorithms for budgeted stream-based settings.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Provable approximation guarantees for greedy adaptive policies (near-optimality for adaptively submodular objectives) and label-complexity bounds for certain search tasks (e.g., generalized binary search).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Optimal adaptive policy (intractable), naive heuristics, non-adaptive greedy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Adaptive greedy policies achieve provable near-optimal performance relative to optimal adaptive policy when objective is adaptively submodular; empirical improvements in batch/stream settings reported in literature.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Theoretical near-optimality reduces the need for solving intractable stochastic optimizations; practical gains in label-efficiency and reduced redundancy.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Adaptive submodularity formalizes diminishing returns under sequential observations, providing a principled way to trade off immediate vs future information gains under labeling budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>When objectives (e.g., version-space reduction) are adaptively submodular, greedy adaptive selection is an effective, provably near-optimal allocation strategy under label-cost constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2524.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Core-Set Active Learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Core-set approach for batch active learning (Sener & Savarese)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formulates batch selection as a core-set problem: pick a subset of unlabeled points whose induced predictor approximates the predictor trained on full data, leading to representative batch selection for deep networks where single-point heuristics are ineffective.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Active learning for convolutional neural networks: A core-set approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Core-set Batch Selection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Derive an upper bound on the difference between the average loss on a selected subset and the full dataset; select a subset that minimizes this bound (a core-set), implemented via geometry-based selection (e.g., k-center) to choose representative diverse samples for deep models.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Deep learning (CNNs) active learning, large-scale image classification where retraining cost is high.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select a batch of size k that best geometrically covers the unlabeled pool (minimize maximum distance to selected points) to ensure selected subset approximates full-data loss, favoring representativeness and diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Batch selection combinatorial optimization cost, cost to retrain deep model on selected subset; label budget in number of examples.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Upper bound on difference between subset loss and full-data loss (core-set loss bound) used as surrogate for expected predictive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Emphasizes exploration/coverage (representativeness) over uncertainty-driven exploitation; designed because single-sample uncertainty heuristics were empirically ineffective for CNNs.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: geometric core-set selection (e.g., k-center) enforces diversity/coverage of feature space representations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch sizes and limited labeling budget (labels per round).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Solve (approximate) core-set selection under cardinality constraint to choose most representative batch within given budget; avoids many rounds of retraining by selecting meaningful batches.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical results (from referenced work) show that core-set selection outperforms classical single-sample heuristics for CNNs; survey does not list numerical metrics here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Uncertainty heuristics, random sampling, naive top-k selection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Reported empirically to outperform classical active learning heuristics for CNNs in referenced work; no numeric values in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Improves label-efficiency for deep models by selecting representative batches rather than many similar uncertain points; reduces retraining overhead via informative batch design.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Core-set focuses on representativeness to counteract ineffectiveness of uncertainty heuristics in overparameterized deep models; tradeoff: may select less uncertain points but improves downstream training stability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>For large overparameterized models (CNNs), representative core-set batch selection is more effective than standard uncertainty-based acquisition; minimizing core-set loss bound is a practical allocation principle.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2524.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RL-based Acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforcement learning for acquisition function / query policy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formulate active learning sample selection as a sequential decision (policy) learned by reinforcement learning (e.g., DQN, LSTM-based Q-function, matching-network based policies), enabling adaptive allocation under changing environments and budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning algorithms for active learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reinforcement-Learned Acquisition Policies</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Treat stream or pool-based active learning as an MDP where states encode model uncertainty, previous queries, unlabeled candidates, etc.; actions are 'query' or 'predict' (or choose which candidate to label). Learn a policy (e.g., via deep Q-networks, LSTMs, matching networks) that optimizes cumulative reward balancing labeling cost versus prediction accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Stream-based and pool-based active learning across classification tasks; one-shot learning and settings where a learned policy generalizes across tasks/domains.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Policy maps state (unlabeled example, model confidence, past actions) to action whether to request label or not, or which sample to select; learned to maximize reward (accuracy minus labeling cost).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost to train RL policy (compute for simulations), per-decision inference cost (policy forward pass), number of label queries (label budget).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Indirect: reward design may include accuracy improvement or reduction in expected loss; not always explicit mutual-information metric but learned to maximize expected utility of queries.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Intrinsic to RL: policy learns tradeoff between querying (exploration/information gathering) and predicting (exploitation) based on reward shaping; policies can adapt to input distribution shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not intrinsic; diversity can be encouraged via state features or reward terms but not standardized  some works learn filters or policies that implicitly avoid redundant queries.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Label cost per decision or cumulative label budget; can be encoded in reward as negative cost for queries.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Incorporate labeling cost directly into reward (penalize queries) or train policy under fixed budget episodes to learn efficient allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey cites RL methods for learning acquisition policies and reports empirical successes (no specific numeric values in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Hand-designed acquisition heuristics (uncertainty, entropy), rule-based filters, multi-armed bandit selection over strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>RL-based policies can adaptively outperform static heuristics when trained on representative tasks; exact improvements depend on training regime and tasks (no numbers in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Ability to amortize policy learning across tasks and reduce per-instance decision costs; can reduce number of queries by learning when to abstain from querying.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>RL enables explicit encoding of the cost-information tradeoff in the reward; practical success depends on state representation, reward shaping, and training diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Learning a policy that directly optimizes labeling-accuracy tradeoff can yield better allocation than fixed heuristics, especially when environments shift or labeling costs are non-uniform.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2524.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bandit for Acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-armed bandit strategies for selecting acquisition functions or queries</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Model the selection among multiple acquisition strategies (or direct query choices) as a bandit problem to adaptively allocate labeling budget among strategies based on observed rewards (improvement), balancing exploration of strategies vs exploitation of high-performing ones.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Online Choice of Active Learning Algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-armed Bandit Acquisition Meta-Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Treat each acquisition heuristic or policy as an arm; observe reward signals (e.g., accuracy improvement per query) and use bandit algorithms to allocate query selections among strategies or to form weighted combinations, adapting to domain characteristics.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Meta-active-learning across domains; selection among acquisition functions for pool-based active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequentially allocate queries to the acquisition strategy estimated to yield the highest expected reward (accuracy gain per label) while exploring other strategies sufficiently to detect shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of queries allocated to each strategy, overhead of evaluating multiple acquisition functions, and the meta-learning computation for the bandit algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Proxy via observed empirical reward (e.g., accuracy improvement, loss reduction) rather than explicit mutual information.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Standard bandit exploration-exploitation strategies (e.g., UCB, EXP3) to try different acquisition functions and exploit those with higher empirical reward.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not directly about sample diversity; diversity arises indirectly if different arms favor different sample types.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Label budget and need to allocate limited labeling resources across candidate strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Bandit algorithms allocate labeling actions across strategies so as to maximize cumulative reward under budget constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey references works that demonstrate adaptive selection among strategies can improve performance over fixed single-strategy approaches; no specific numeric metrics provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single fixed acquisition heuristic, uniform combination of heuristics, static linear combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Bandit meta-strategies reported to adapt and often outperform fixed heuristics in changing domains (no numeric values in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Improved allocation of query budget across strategies leading to better empirical gains per label in heterogeneous domains.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Bandit framing treats acquisition function choice as a resource allocation problem, directly confronting exploration (trying strategies) vs exploitation (using best-known strategy) but relies on informative reward signals.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Adaptive selection among acquisition strategies via bandits can robustly allocate labeling resources across domains; transferring learned strategy weights between domains has also been explored.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2524.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Golovin et al. near-optimal BAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Near-optimal Bayesian active learning with noisy observations / adaptive submodularity cost minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work that extends adaptive submodularity to noisy observations and proposes algorithms to minimize cumulative labeling cost until a decision objective (e.g., identify true hypothesis) is met, providing approximation guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Near-optimal Bayesian active learning with noisy observations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adaptive Submodular Cost-Minimizing Active Learning (Golovin & Krause et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Formulate the problem of sequential querying to identify a target hypothesis under noisy observations as an adaptive stochastic optimization; show that expected version-space reduction objectives are adaptively submodular and propose greedy-like algorithms with approximation guarantees for minimizing cumulative label cost to reach identification.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General active learning/search in noisy environments, generalized binary search, experimental design where labels have cost and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Adaptive greedy selection according to expected marginal gain per unit cost (e.g., expected version-space reduction normalized by labeling cost), continuing until target confidence/identification criterion met.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cumulative labeling cost (number of queries weighted by per-query cost), computational cost to evaluate expected gains under posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected reduction in posterior mass of incorrect hypotheses (version-space reduction) or other posterior-based utilities.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Greedy selection of queries with largest expected marginal gain per cost naturally mediates exploration of uncertain hypotheses vs exploitation of promising leads; theoretical bounds hold under adaptive submodularity.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via diminishing returns: after querying similar points, marginal benefit drops, encouraging diverse future queries.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative labeling cost budget or objective to minimize cost until identification.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Provide approximation algorithms that minimize cumulative labeling cost with provable guarantees under adaptively submodular objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Provable approximation bounds for expected cost to achieve identification objectives; near-optimality results in theoretical analysis (survey summarizes conceptually).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Optimal adaptive policy (intractable), non-adaptive strategies, naive heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Greedy adaptive algorithms achieve near-optimality under stated conditions compared to optimal adaptive strategies; concrete numerical gains are in cited works rather than this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Provable bounds mean cheaper approximate policies with bounded excess cost versus optimal policy; practical reductions in labeling cost for identification tasks when using greedy adaptive policies.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Framework explicitly quantifies tradeoff of marginal information gain per unit label cost and yields policies that balance cost vs expected information under noise.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Select queries by expected marginal posterior benefit per unit cost with greedy adaptive policies when objectives are adaptively submodular; this yields near-optimal cost-minimization for noisy active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2524.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ishibashi-Hino PAC-Bayes stopping</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Stopping criterion for active learning based on deterministic generalization bounds (PAC-Bayesian stopping)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A PAC-Bayesian approach to stopping active learning that upper-bounds expected generalization error reduction via KL divergence between successive posterior hypothesis distributions, enabling principled stopping decisions under a Bayesian model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Stopping criterion for active learning based on deterministic generalization bounds</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PAC-Bayesian Stopping Criterion (Ishibashi & Hino)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Derive bounds on reduction in expected generalization error R(p(h|S), p(h|S')) in terms of KL divergence between successive posteriors plus constants related to loss range, and use this computable upper bound (or a tighter variant using Lambert W) to decide when additional labeling yields negligible expected improvement, providing a stopping rule for pool-based active learning (illustrated for GP regression with predictive-variance acquisition).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Active learning stopping decisions; illustrated for Gaussian process regression and predictive-variance acquisition in measurement tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Not a selection policy but a stopping strategy: sequentially compute upper bound on expected risk reduction from adding labels and stop when bound falls below threshold relative to labeling cost/budget.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>KL divergence between posteriors (computable for parametric/Bayesian predictors), number of additional labels avoided (label budget savings), and model retraining cost if needed.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Upper-bound on reduction in expected generalization error linked to KL divergence between posteriors; effectively uses posterior change as proxy for information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Provides a principled stopping rule that trades off further information gain (expected risk reduction) against labeling cost; not directly an exploration-exploitation policy but governs when to cease exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Implicit label budget / desire to minimize labels; stopping when further labels yield negligible expected improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Compute an upper bound on expected improvement per additional label via KL divergence; stop when bound is below threshold or no longer justifies label cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey describes that the PAC-Bayes derived upper bounds can be computed (tightness depends on constants); applied in referenced work to GP regression with predictive-variance acquisition (no numeric summary in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Heuristic stopping rules (entropy thresholds, prediction stability), cross-validation/holdout approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PAC-Bayes approach provides a theoretically grounded alternative to heuristics; tightness of bound and practical usefulness depend on model and constant terms.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables principled stopping that can save labeling cost by avoiding futile queries when posterior change (KL) is small.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Exposes a tradeoff between KL-change (information gain) and constant terms in the bound; tight bounds permit earlier stopping while loose bounds may defer stop unnecessarily.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Stopping should be based on measurable posterior-change bounds (e.g., KL between successive posteriors) to balance labeling cost against expected generalization improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2524.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Terayama Phase Diagram AL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Efficient construction method for phase diagrams using uncertainty sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An application of active learning to construct phase diagrams by discretizing parameter space, propagating initial labels to a probability map, and selecting grid points with high uncertainty for measurement, dramatically reducing required experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Efficient construction method for phase diagrams using uncertainty sampling</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Phase-diagram Active Learning via Label Propagation + Uncertainty Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Divide continuous parameter space into a grid; initialize labels at a few measured points; create a probability map via label propagation (diffusion) to estimate class probabilities across grid; select next measurement points where predictive uncertainty (near phase boundaries) is highest using uncertainty-sampling acquisition functions; iterate until diagram resolved.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science: generating phase diagrams (materials state vs thermodynamic/processing parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Choose measurement points with highest predictive uncertainty from the propagated probability map, focusing experimental budget on likely phase boundaries to maximize information per measurement.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of physical measurements (experimental runs), grid resolution (# of candidate points), computational cost of label propagation and uncertainty evaluation (negligible compared to experimental cost).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Predictive uncertainty from label-propagation probability map (entropy/uncertainty near boundaries) used as proxy for expected information from performing the measurement.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explores high-uncertainty regions (phase boundaries) to refine the diagram (exploration of informative regions) while implicitly exploiting known regions by label propagation to infer low-uncertainty areas.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Grid discretization and propagation encourage spatial coverage; acquisition focuses on distinct boundary regions yielding diversity across phase boundaries rather than clustered repeats.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget (number of measurements); high cost per physical measurement.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Sequentially allocate measurements to high-uncertainty grid points until budget; demonstrated to reconstruct phase diagram with ~20% of measurements compared to dense grid scanning.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical: for water and a Si-Al-Mg glass-ceramic glaze, the same phase diagrams obtained with approximately 20% of measurements compared to a conventional dense grid.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Dense grid scanning (uniform sampling), random sampling across grid.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Achieved equivalent phase diagram reconstruction with ~20% of the measurements vs dense scanning (i.e., ~80% reduction in required experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Approximately 80% reduction in number of measurements compared to full dense-grid exploration for the tested phase-diagram tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Demonstrates tradeoff favoring focused boundary exploration (high uncertainty) over uniform coverage; combining diffusion-based representation with uncertainty sampling efficiently allocates experimental resources to informative regions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Prioritize measurements near phase boundaries (high-propagation uncertainty) to maximally improve phase-diagram resolution under tight experimental budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2524.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ueno XMCD GP AL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied active learning for spectral measurement: model spectrum with Gaussian process regression and sequentially select energy points with largest predictive variance to estimate integrated spectral quantity with far fewer measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian Process Predictive-Variance Acquisition for Spectroscopy</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Model one-dimensional spectral curve using Gaussian process regression; use predictive variance at candidate energy points as acquisition function to sequentially select measurement points from a candidate pooled set; integrate the GP-predicted spectrum to obtain physical quantities (e.g., magnetic moment) with fewer measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Experimental measurement optimization in spectroscopy (XMCD) and one-dimensional regression measurement tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select next measurement points where predictive variance (uncertainty) is largest to most reduce uncertainty in integrated spectral quantity per expensive measurement.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of physical measurement points taken (primary experimental cost); GP inference compute for predictive variances (minor relative to experimental cost).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Predictive variance from the Gaussian process as proxy for expected information about the spectrum at unmeasured points and hence about integrated physical quantities.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explores high-uncertainty spectral regions (e.g., near peaks) to improve estimate of integrated value; exploitation is implicit via GP posterior interpolation in low-uncertainty regions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Predictive-variance acquisition tends to sample points across different uncertain spectral regions (diverse energies) rather than clustering, but no explicit diversity regularizer is described.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of experimental measurements (measurement budget).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Sequentially pick high-variance points until measurement budget reached; demonstrated using pooled candidate set of 220 points with small initial sample and 20 sequential acquisitions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical: starting from 30 random points and acquiring 20 further points via GP variance, the integrated value matched the ground-truth spectrum; achieved similar physical-quantity accuracy with ~22% of measurements compared to dense sampling (220 points).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Conventional dense energy sampling (hundreds of measurements) or random sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Obtained equivalent integrated spectral measurement with ~22% of measurements compared to conventional dense scanning, implying ~78% reduction in experimental runs.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Approximately 78% reduction in number of measurements required to obtain equivalent integrated spectral accuracy in the tested XMCD case.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>GP-variance prioritizes uncertain spectral regions and reduces experimental cost substantially; remaining issues include handling measurement noise, prior incorporation, and stopping criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Using GP predictive variance as acquisition function enables major reductions in measurement counts for one-dimensional spectral estimation when measurement cost dominates computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2524.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2524.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VAE+Adv AL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Adversarial Active Learning (VAE + Adversarial discriminator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Learn acquisition functions task-independently by training a VAE to embed data and an adversarial discriminator to distinguish labeled vs unlabeled latent representations; discriminator score is used to prioritize samples for labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Variational adversarial active learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>VAE + Adversarial Acquisition Function</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Train a variational autoencoder to map labeled and unlabeled data into a latent space, then train an adversarial discriminator to predict whether a latent code comes from labeled or unlabeled pool; use discriminator output (degree of 'unfamiliarity' relative to labeled set) as acquisition score to select unlabeled samples independent of task-specific labels.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Pool-based active learning across tasks where task-independent acquisition helps (e.g., image classification), especially with deep representations.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select unlabeled samples that the discriminator deems most unlike current labeled set (high discriminator score), thereby prioritizing samples under-represented in labeled pool to improve representativeness of labeled set.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Compute cost of training VAE and discriminator, cost to embed and score unlabeled pool; number of labels acquired (label budget).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicit: discriminator score as proxy for expected marginal gain from labeling (task-agnostic proxy for novelty/representativeness); no explicit mutual-information metric.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Favors exploration of underrepresented or novel regions in latent space (diversity/coverage); not explicitly balancing exploitation of currently promising hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: discriminator identifies latent codes dissimilar to labeled set, promoting diverse selection and coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Label budget (fixed number of queries per round or total).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Rank unlabeled samples by discriminator score and select top-k under batch budget; training VAE/discriminator is amortized across acquisitions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey reports this approach as a task-independent acquisition learning method; specific empirical numbers are in the referenced work not included in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Task-specific uncertainty heuristics, random sampling, core-set approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Referenced works show improvements in some scenarios, particularly by avoiding query redundancy and improving labeled-set representativeness; no numbers in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Potentially reduces number of labels required to cover data manifold and improves downstream training efficiency; exact gains depend on task.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Task-agnostic discriminator focuses on diversity/novelty which may miss task-specific informative examples; combining with uncertainty can balance this tradeoff.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Learning task-independent acquisition using latent-space adversarial scoring is effective to promote diversity and representativeness when label budgets are limited.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning: Problem Settings and Recent Developments', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Adaptive submodularity: Theory and applications in active learning and stochastic optimization <em>(Rating: 2)</em></li>
                <li>Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning <em>(Rating: 2)</em></li>
                <li>Active learning for convolutional neural networks: A core-set approach <em>(Rating: 2)</em></li>
                <li>Near-optimal Bayesian active learning with noisy observations <em>(Rating: 2)</em></li>
                <li>Budgeted stream-based active learning via adaptive submodular maximization <em>(Rating: 2)</em></li>
                <li>Variational adversarial active learning <em>(Rating: 2)</em></li>
                <li>Learning how to active learn: A deep reinforcement learning approach <em>(Rating: 2)</em></li>
                <li>Efficient construction method for phase diagrams using uncertainty sampling <em>(Rating: 2)</em></li>
                <li>Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling <em>(Rating: 2)</em></li>
                <li>Online Choice of Active Learning Algorithms <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2524",
    "paper_id": "paper-227745938",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "BALD",
            "name_full": "Bayesian Active Learning by Disagreement",
            "brief_description": "An acquisition strategy that selects queries maximizing mutual information between predictions and model posterior (i.e., high predictive entropy but low expected entropy under parameter posterior), aiming to reduce posterior uncertainty about model parameters.",
            "citation_title": "Bayesian Active Learning for Classification and Preference Learning",
            "mention_or_use": "mention",
            "system_name": "BALD (Bayesian Active Learning by Disagreement)",
            "system_description": "A Bayesian acquisition function that evaluates candidate inputs by the mutual information between the predicted label and the model parameter posterior: it selects points with high entropy in the predictive distribution but low expected entropy conditioned on parameters. Implementations typically use approximate Bayesian deep models (e.g., dropout as approximate Bayesian NN) and compute per-sample mutual information to rank queries.",
            "application_domain": "General supervised learning; highlighted for deep learning and classification tasks (e.g., image classification).",
            "resource_allocation_strategy": "Rank unlabeled candidates by mutual information (predictive entropy minus expected parameter-conditional entropy) and select top queries; can be extended to batch selection (BatchBALD) that accounts for joint information of a batch.",
            "computational_cost_metric": "Number of forward passes / Monte Carlo samples for approximate posterior (e.g., multiple stochastic passes for Bayesian NN), and number of label queries (label budget).",
            "information_gain_metric": "Mutual information between label and model posterior; predictive entropy minus expected entropy under parameter posterior.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Prefers examples that maximally reduce parameter uncertainty (exploration of uncertain regions) rather than purely exploiting high-performing hypotheses; in batch variants (BatchBALD) it explicitly accounts for joint information across the batch to avoid redundancy.",
            "diversity_mechanism": "BatchBALD extends BALD by selecting jointly informative and thus diverse batches (accounts for joint mutual information), reducing redundancy among selected points.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Label budget (fixed number of queries); computational budget via approximate posterior sampling.",
            "budget_constraint_handling": "Select top-ranked points until budget exhausted; for batch selection account jointly for batch information (BatchBALD) to maximize information per labeling cost.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Reported qualitatively as strong performance for deep active learning; in the paper BatchBALD is said to be among best performing methods (no numerical metric given in this survey).",
            "comparison_baseline": "Uncertainty sampling, entropy sampling, margin sampling, random sampling, other acquisition heuristics.",
            "performance_vs_baseline": "Survey states BALD and BatchBALD are high-performing compared with common heuristics for Bayesian deep learners (no specific numbers in this paper).",
            "efficiency_gain": "Not numerically specified in survey; conceptual improvement in information per label by selecting high mutual-information samples.",
            "tradeoff_analysis": "BALD focuses on information gain (parameter uncertainty reduction) and can avoid selecting redundant points if batch mutual information is considered; computational cost rises with approximate posterior sampling.",
            "optimal_allocation_findings": "Selecting queries by mutual information is effective for reducing posterior uncertainty; batch extensions that consider joint information mitigate redundancy and improve label-efficiency for deep models.",
            "uuid": "e2524.0",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "BatchBALD",
            "name_full": "Batchbald: Efficient and diverse batch acquisition for deep Bayesian active learning",
            "brief_description": "A batch-mode extension of BALD that approximates joint mutual information of a candidate batch to select diverse, jointly informative sets under a labeling budget.",
            "citation_title": "Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning",
            "mention_or_use": "mention",
            "system_name": "BatchBALD",
            "system_description": "An acquisition algorithm that approximates the joint mutual information between a candidate batch of unlabeled inputs and model posterior; it greedily constructs a batch maximizing joint information to select diverse, non-redundant queries for batch labeling.",
            "application_domain": "Deep Bayesian active learning for classification (e.g., image recognition).",
            "resource_allocation_strategy": "Greedy batch construction maximizing estimated joint mutual information subject to a batch size constraint; selects batches rather than single points to match parallel labeling or costly retraining scenarios.",
            "computational_cost_metric": "Cost of computing joint mutual information approximations (Monte Carlo sampling over model posterior) and labeling cost per batch; model retraining time per acquisition round.",
            "information_gain_metric": "Estimated joint mutual information of the batch with the model posterior.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration via selecting high-joint-information batches (targets areas that reduce posterior uncertainty); implicitly trades off redundant exploitation by penalizing overlap in information across batch items.",
            "diversity_mechanism": "Explicit: joint mutual information objective discourages redundant samples and thereby induces diversity in selected batch.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch size constraints and label budget per round.",
            "budget_constraint_handling": "Greedy selection under fixed batch size budget to approximate the optimal batch-information objective.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Survey cites BatchBALD as one of the best-performing methods for batch deep Bayesian active learning (no numeric values provided in survey).",
            "comparison_baseline": "Single-sample BALD, uncertainty heuristics, random sampling, naive top-k selection.",
            "performance_vs_baseline": "Reported to outperform single-sample heuristics by selecting diverse informative batches; no numeric comparisons in this survey.",
            "efficiency_gain": "Not quantified here; described as improving label-efficiency and reducing redundant queries in batch settings.",
            "tradeoff_analysis": "Balances information gain with diversity implicitly via joint mutual information; computational burden high due to joint-information estimation.",
            "optimal_allocation_findings": "Joint-information-aware batch selection yields better label-efficiency than naive repeated single-sample selection when retraining cost or parallel labeling makes batch queries necessary.",
            "uuid": "e2524.1",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "QBC",
            "name_full": "Query by Committee",
            "brief_description": "An uncertainty-sampling family where a committee (ensemble) of hypotheses is used and samples are queried when committee members disagree, aiming to most efficiently reduce version space.",
            "citation_title": "Query by Committee",
            "mention_or_use": "mention",
            "system_name": "Query by Committee (QBC)",
            "system_description": "Construct an ensemble or sample hypotheses from the version space and measure disagreement (e.g., vote entropy); query instances where committee members most disagree to maximally reduce the hypothesis version space.",
            "application_domain": "Binary and multiclass classification; theoretical analysis of label complexity and version-space reduction.",
            "resource_allocation_strategy": "Select unlabeled points where sampled hypotheses disagree (high committee vote entropy); sampling from version space is used to identify informative queries.",
            "computational_cost_metric": "Cost to sample/maintain multiple hypotheses or committees and to evaluate predictions for candidate points (ensemble forward passes); number of labels requested (label complexity).",
            "information_gain_metric": "Version-space reduction or disagreement measure (vote entropy); expected decrease in generalization error due to shrinking version space.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Targets regions of hypothesis uncertainty (exploration of ambiguous regions) rather than exploiting high-confidence areas; disagreement-driven selection naturally explores hypotheses that are plausible under current data.",
            "diversity_mechanism": "Committee disagreement encourages sampling across boundaries of competing hypotheses; not an explicit diversity optimization but tends to sample diverse boundary points.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Label budget / number of queries (label complexity).",
            "budget_constraint_handling": "Query high-disagreement points until budget exhausted; theoretical analyses consider how many queries needed to reduce version space to desired size.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Theoretically, generalization error can decrease exponentially with the number of queries in idealized noise-free settings; empirical improvements over random sampling are reported historically (no numeric values in this survey).",
            "comparison_baseline": "Random sampling, uncertainty heuristics, version-space greedy approaches.",
            "performance_vs_baseline": "QBC shown historically to achieve faster version-space reduction than random sampling in idealized settings; survey notes implementation difficulty in sampling realistic version spaces.",
            "efficiency_gain": "Potential exponential decrease in error for noise-free discrimination problems (theoretical limit); practical gains depend on committee construction.",
            "tradeoff_analysis": "QBC focuses on hypothesis uncertainty but may be computationally costly to implement; sampling hypotheses from version space is nontrivial and approximations are needed.",
            "optimal_allocation_findings": "Sampling by committee disagreement is effective for version-space reduction; efficient implementations require approximations (e.g., projection to low-dimensions) to be practical.",
            "uuid": "e2524.2",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Submodular Batch Selection",
            "name_full": "Greedy batch selection via submodular objectives (entropy, Fisher-information approximations)",
            "brief_description": "Formulate batch selection as maximizing a monotone submodular set function (e.g., entropy, Fisher-information surrogate) so that greedy selection yields provable 1-1/e approximation guarantees under cardinality constraints.",
            "citation_title": "Batch mode active learning and its application to medical image classification",
            "mention_or_use": "mention",
            "system_name": "Submodular Greedy Batch Active Learning",
            "system_description": "Define a monotone submodular value function over subsets of unlabeled points (e.g., entropy of predictions, approximations of Fisher information mismatch Tr[I_q^{-1} I_p]) and apply a greedy selection (iteratively add element with largest marginal gain) to pick a batch of size k with guaranteed approximation to the optimal batch.",
            "application_domain": "Pool-based batch active learning for classification and parametric models (logistic regression) and broader settings via surrogates.",
            "resource_allocation_strategy": "Greedy maximization of a submodular objective until batch size limit met; objective measures information or closeness of selected-batch distribution to pooled data distribution.",
            "computational_cost_metric": "Number of objective evaluations (marginal gains) and cost of computing the surrogate (e.g., Fisher matrix traces); labeling budget as number of queries.",
            "information_gain_metric": "Entropy of predicted labels, Fisher-information-based trace objective Tr[I_q^{-1} I_p], or other submodular surrogates for expected error reduction.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Greedy selection with submodular objective naturally embodies diminishing returns (encourages exploration/diversity early then exploitation); the objective can be chosen to trade off representativeness vs uncertainty.",
            "diversity_mechanism": "Submodularity (diminishing marginal returns) encourages coverage/diversity among selected points; objectives like Fisher information encourage representative coverage of pooled data.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size (k) and label budget.",
            "budget_constraint_handling": "Greedy algorithm yields a guaranteed (1 - 1/e) approximation to optimal subset under fixed-cardinality budget; surrogate choices affect practical performance.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Theoretical approximation ratio 1 - 1/e for monotone submodular objectives; empirical gains reported in literature for batch selection (no numeric values in this survey).",
            "comparison_baseline": "Naive top-k repeated single-sample selection, random sampling, task-specific heuristics.",
            "performance_vs_baseline": "Greedy submodular batch selection provides theoretical guarantees and tends to outperform naive repeated single-sample selection by avoiding redundancy; specific numeric comparisons not provided in this survey.",
            "efficiency_gain": "Provable near-optimality under submodular objective (1 - 1/e) ensures efficient use of a fixed batch budget.",
            "tradeoff_analysis": "Submodular objectives let practitioners tune representativeness vs informativeness; however, choosing a surrogate with valid submodularity and computational tractability is key.",
            "optimal_allocation_findings": "When a suitable monotone submodular objective exists, greedy batch selection is an efficient, near-optimal policy for allocating labeling budget across a batch.",
            "uuid": "e2524.3",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Adaptive Submodularity",
            "name_full": "Adaptive Submodularity (policy-level generalization of submodularity)",
            "brief_description": "A generalization of submodularity to adaptive policies where value of future selections depends on observed outcomes; it enables greedy policies with performance guarantees for sequential active learning under uncertainty.",
            "citation_title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization",
            "mention_or_use": "mention",
            "system_name": "Adaptive Submodularity Framework",
            "system_description": "Extends submodularity to adaptive decision-making: define conditional marginal benefits of actions given observed labels, and show that certain objectives (e.g., version-space reduction) are adaptively submodular so that a greedy adaptive policy attains approximation guarantees to the optimal adaptive policy.",
            "application_domain": "Sequential active learning, generalized binary search, budgeted labeling policies, and other adaptive experiment-design problems with stochastic outcomes.",
            "resource_allocation_strategy": "Run an adaptive greedy policy that at each step selects the action with largest expected marginal gain conditioned on observations so far; stop when version space reduced or budget exhausted.",
            "computational_cost_metric": "Expected number of labels (label cost), computational overhead to compute conditional expected marginal gains under model/posterior.",
            "information_gain_metric": "Expected marginal reduction in target objective (e.g., version-space size, entropy); formalized as expected value under current posterior of hypotheses.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Adaptive greedy policies explicitly trade off exploration and exploitation by using posterior-conditioned expected gains; guarantees hold for adaptively submodular objectives.",
            "diversity_mechanism": "Adaptive submodularity leads to selection diversity because marginal gains diminish after similar selections, discouraging redundant queries.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Labeling cost budget; cumulative cost minimization of labeling.",
            "budget_constraint_handling": "Greedy adaptive policy with approximation guarantees for minimizing cumulative cost (select until budget exhausted or objective met); special algorithms for budgeted stream-based settings.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Provable approximation guarantees for greedy adaptive policies (near-optimality for adaptively submodular objectives) and label-complexity bounds for certain search tasks (e.g., generalized binary search).",
            "comparison_baseline": "Optimal adaptive policy (intractable), naive heuristics, non-adaptive greedy.",
            "performance_vs_baseline": "Adaptive greedy policies achieve provable near-optimal performance relative to optimal adaptive policy when objective is adaptively submodular; empirical improvements in batch/stream settings reported in literature.",
            "efficiency_gain": "Theoretical near-optimality reduces the need for solving intractable stochastic optimizations; practical gains in label-efficiency and reduced redundancy.",
            "tradeoff_analysis": "Adaptive submodularity formalizes diminishing returns under sequential observations, providing a principled way to trade off immediate vs future information gains under labeling budgets.",
            "optimal_allocation_findings": "When objectives (e.g., version-space reduction) are adaptively submodular, greedy adaptive selection is an effective, provably near-optimal allocation strategy under label-cost constraints.",
            "uuid": "e2524.4",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Core-Set Active Learning",
            "name_full": "Core-set approach for batch active learning (Sener & Savarese)",
            "brief_description": "Formulates batch selection as a core-set problem: pick a subset of unlabeled points whose induced predictor approximates the predictor trained on full data, leading to representative batch selection for deep networks where single-point heuristics are ineffective.",
            "citation_title": "Active learning for convolutional neural networks: A core-set approach",
            "mention_or_use": "mention",
            "system_name": "Core-set Batch Selection",
            "system_description": "Derive an upper bound on the difference between the average loss on a selected subset and the full dataset; select a subset that minimizes this bound (a core-set), implemented via geometry-based selection (e.g., k-center) to choose representative diverse samples for deep models.",
            "application_domain": "Deep learning (CNNs) active learning, large-scale image classification where retraining cost is high.",
            "resource_allocation_strategy": "Select a batch of size k that best geometrically covers the unlabeled pool (minimize maximum distance to selected points) to ensure selected subset approximates full-data loss, favoring representativeness and diversity.",
            "computational_cost_metric": "Batch selection combinatorial optimization cost, cost to retrain deep model on selected subset; label budget in number of examples.",
            "information_gain_metric": "Upper bound on difference between subset loss and full-data loss (core-set loss bound) used as surrogate for expected predictive performance.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Emphasizes exploration/coverage (representativeness) over uncertainty-driven exploitation; designed because single-sample uncertainty heuristics were empirically ineffective for CNNs.",
            "diversity_mechanism": "Explicit: geometric core-set selection (e.g., k-center) enforces diversity/coverage of feature space representations.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch sizes and limited labeling budget (labels per round).",
            "budget_constraint_handling": "Solve (approximate) core-set selection under cardinality constraint to choose most representative batch within given budget; avoids many rounds of retraining by selecting meaningful batches.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Empirical results (from referenced work) show that core-set selection outperforms classical single-sample heuristics for CNNs; survey does not list numerical metrics here.",
            "comparison_baseline": "Uncertainty heuristics, random sampling, naive top-k selection.",
            "performance_vs_baseline": "Reported empirically to outperform classical active learning heuristics for CNNs in referenced work; no numeric values in survey.",
            "efficiency_gain": "Improves label-efficiency for deep models by selecting representative batches rather than many similar uncertain points; reduces retraining overhead via informative batch design.",
            "tradeoff_analysis": "Core-set focuses on representativeness to counteract ineffectiveness of uncertainty heuristics in overparameterized deep models; tradeoff: may select less uncertain points but improves downstream training stability.",
            "optimal_allocation_findings": "For large overparameterized models (CNNs), representative core-set batch selection is more effective than standard uncertainty-based acquisition; minimizing core-set loss bound is a practical allocation principle.",
            "uuid": "e2524.5",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "RL-based Acquisition",
            "name_full": "Reinforcement learning for acquisition function / query policy",
            "brief_description": "Formulate active learning sample selection as a sequential decision (policy) learned by reinforcement learning (e.g., DQN, LSTM-based Q-function, matching-network based policies), enabling adaptive allocation under changing environments and budgets.",
            "citation_title": "Learning algorithms for active learning",
            "mention_or_use": "mention",
            "system_name": "Reinforcement-Learned Acquisition Policies",
            "system_description": "Treat stream or pool-based active learning as an MDP where states encode model uncertainty, previous queries, unlabeled candidates, etc.; actions are 'query' or 'predict' (or choose which candidate to label). Learn a policy (e.g., via deep Q-networks, LSTMs, matching networks) that optimizes cumulative reward balancing labeling cost versus prediction accuracy.",
            "application_domain": "Stream-based and pool-based active learning across classification tasks; one-shot learning and settings where a learned policy generalizes across tasks/domains.",
            "resource_allocation_strategy": "Policy maps state (unlabeled example, model confidence, past actions) to action whether to request label or not, or which sample to select; learned to maximize reward (accuracy minus labeling cost).",
            "computational_cost_metric": "Cost to train RL policy (compute for simulations), per-decision inference cost (policy forward pass), number of label queries (label budget).",
            "information_gain_metric": "Indirect: reward design may include accuracy improvement or reduction in expected loss; not always explicit mutual-information metric but learned to maximize expected utility of queries.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Intrinsic to RL: policy learns tradeoff between querying (exploration/information gathering) and predicting (exploitation) based on reward shaping; policies can adapt to input distribution shifts.",
            "diversity_mechanism": "Not intrinsic; diversity can be encouraged via state features or reward terms but not standardized  some works learn filters or policies that implicitly avoid redundant queries.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Label cost per decision or cumulative label budget; can be encoded in reward as negative cost for queries.",
            "budget_constraint_handling": "Incorporate labeling cost directly into reward (penalize queries) or train policy under fixed budget episodes to learn efficient allocation.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Survey cites RL methods for learning acquisition policies and reports empirical successes (no specific numeric values in survey).",
            "comparison_baseline": "Hand-designed acquisition heuristics (uncertainty, entropy), rule-based filters, multi-armed bandit selection over strategies.",
            "performance_vs_baseline": "RL-based policies can adaptively outperform static heuristics when trained on representative tasks; exact improvements depend on training regime and tasks (no numbers in survey).",
            "efficiency_gain": "Ability to amortize policy learning across tasks and reduce per-instance decision costs; can reduce number of queries by learning when to abstain from querying.",
            "tradeoff_analysis": "RL enables explicit encoding of the cost-information tradeoff in the reward; practical success depends on state representation, reward shaping, and training diversity.",
            "optimal_allocation_findings": "Learning a policy that directly optimizes labeling-accuracy tradeoff can yield better allocation than fixed heuristics, especially when environments shift or labeling costs are non-uniform.",
            "uuid": "e2524.6",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Bandit for Acquisition",
            "name_full": "Multi-armed bandit strategies for selecting acquisition functions or queries",
            "brief_description": "Model the selection among multiple acquisition strategies (or direct query choices) as a bandit problem to adaptively allocate labeling budget among strategies based on observed rewards (improvement), balancing exploration of strategies vs exploitation of high-performing ones.",
            "citation_title": "Online Choice of Active Learning Algorithms",
            "mention_or_use": "mention",
            "system_name": "Multi-armed Bandit Acquisition Meta-Strategy",
            "system_description": "Treat each acquisition heuristic or policy as an arm; observe reward signals (e.g., accuracy improvement per query) and use bandit algorithms to allocate query selections among strategies or to form weighted combinations, adapting to domain characteristics.",
            "application_domain": "Meta-active-learning across domains; selection among acquisition functions for pool-based active learning.",
            "resource_allocation_strategy": "Sequentially allocate queries to the acquisition strategy estimated to yield the highest expected reward (accuracy gain per label) while exploring other strategies sufficiently to detect shifts.",
            "computational_cost_metric": "Number of queries allocated to each strategy, overhead of evaluating multiple acquisition functions, and the meta-learning computation for the bandit algorithm.",
            "information_gain_metric": "Proxy via observed empirical reward (e.g., accuracy improvement, loss reduction) rather than explicit mutual information.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Standard bandit exploration-exploitation strategies (e.g., UCB, EXP3) to try different acquisition functions and exploit those with higher empirical reward.",
            "diversity_mechanism": "Not directly about sample diversity; diversity arises indirectly if different arms favor different sample types.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Label budget and need to allocate limited labeling resources across candidate strategies.",
            "budget_constraint_handling": "Bandit algorithms allocate labeling actions across strategies so as to maximize cumulative reward under budget constraints.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Survey references works that demonstrate adaptive selection among strategies can improve performance over fixed single-strategy approaches; no specific numeric metrics provided here.",
            "comparison_baseline": "Single fixed acquisition heuristic, uniform combination of heuristics, static linear combinations.",
            "performance_vs_baseline": "Bandit meta-strategies reported to adapt and often outperform fixed heuristics in changing domains (no numeric values in survey).",
            "efficiency_gain": "Improved allocation of query budget across strategies leading to better empirical gains per label in heterogeneous domains.",
            "tradeoff_analysis": "Bandit framing treats acquisition function choice as a resource allocation problem, directly confronting exploration (trying strategies) vs exploitation (using best-known strategy) but relies on informative reward signals.",
            "optimal_allocation_findings": "Adaptive selection among acquisition strategies via bandits can robustly allocate labeling resources across domains; transferring learned strategy weights between domains has also been explored.",
            "uuid": "e2524.7",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Golovin et al. near-optimal BAL",
            "name_full": "Near-optimal Bayesian active learning with noisy observations / adaptive submodularity cost minimization",
            "brief_description": "Work that extends adaptive submodularity to noisy observations and proposes algorithms to minimize cumulative labeling cost until a decision objective (e.g., identify true hypothesis) is met, providing approximation guarantees.",
            "citation_title": "Near-optimal Bayesian active learning with noisy observations",
            "mention_or_use": "mention",
            "system_name": "Adaptive Submodular Cost-Minimizing Active Learning (Golovin & Krause et al.)",
            "system_description": "Formulate the problem of sequential querying to identify a target hypothesis under noisy observations as an adaptive stochastic optimization; show that expected version-space reduction objectives are adaptively submodular and propose greedy-like algorithms with approximation guarantees for minimizing cumulative label cost to reach identification.",
            "application_domain": "General active learning/search in noisy environments, generalized binary search, experimental design where labels have cost and noise.",
            "resource_allocation_strategy": "Adaptive greedy selection according to expected marginal gain per unit cost (e.g., expected version-space reduction normalized by labeling cost), continuing until target confidence/identification criterion met.",
            "computational_cost_metric": "Cumulative labeling cost (number of queries weighted by per-query cost), computational cost to evaluate expected gains under posterior.",
            "information_gain_metric": "Expected reduction in posterior mass of incorrect hypotheses (version-space reduction) or other posterior-based utilities.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Greedy selection of queries with largest expected marginal gain per cost naturally mediates exploration of uncertain hypotheses vs exploitation of promising leads; theoretical bounds hold under adaptive submodularity.",
            "diversity_mechanism": "Implicit via diminishing returns: after querying similar points, marginal benefit drops, encouraging diverse future queries.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Cumulative labeling cost budget or objective to minimize cost until identification.",
            "budget_constraint_handling": "Provide approximation algorithms that minimize cumulative labeling cost with provable guarantees under adaptively submodular objectives.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Provable approximation bounds for expected cost to achieve identification objectives; near-optimality results in theoretical analysis (survey summarizes conceptually).",
            "comparison_baseline": "Optimal adaptive policy (intractable), non-adaptive strategies, naive heuristics.",
            "performance_vs_baseline": "Greedy adaptive algorithms achieve near-optimality under stated conditions compared to optimal adaptive strategies; concrete numerical gains are in cited works rather than this survey.",
            "efficiency_gain": "Provable bounds mean cheaper approximate policies with bounded excess cost versus optimal policy; practical reductions in labeling cost for identification tasks when using greedy adaptive policies.",
            "tradeoff_analysis": "Framework explicitly quantifies tradeoff of marginal information gain per unit label cost and yields policies that balance cost vs expected information under noise.",
            "optimal_allocation_findings": "Select queries by expected marginal posterior benefit per unit cost with greedy adaptive policies when objectives are adaptively submodular; this yields near-optimal cost-minimization for noisy active learning.",
            "uuid": "e2524.8",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Ishibashi-Hino PAC-Bayes stopping",
            "name_full": "Stopping criterion for active learning based on deterministic generalization bounds (PAC-Bayesian stopping)",
            "brief_description": "A PAC-Bayesian approach to stopping active learning that upper-bounds expected generalization error reduction via KL divergence between successive posterior hypothesis distributions, enabling principled stopping decisions under a Bayesian model.",
            "citation_title": "Stopping criterion for active learning based on deterministic generalization bounds",
            "mention_or_use": "mention",
            "system_name": "PAC-Bayesian Stopping Criterion (Ishibashi & Hino)",
            "system_description": "Derive bounds on reduction in expected generalization error R(p(h|S), p(h|S')) in terms of KL divergence between successive posteriors plus constants related to loss range, and use this computable upper bound (or a tighter variant using Lambert W) to decide when additional labeling yields negligible expected improvement, providing a stopping rule for pool-based active learning (illustrated for GP regression with predictive-variance acquisition).",
            "application_domain": "Active learning stopping decisions; illustrated for Gaussian process regression and predictive-variance acquisition in measurement tasks.",
            "resource_allocation_strategy": "Not a selection policy but a stopping strategy: sequentially compute upper bound on expected risk reduction from adding labels and stop when bound falls below threshold relative to labeling cost/budget.",
            "computational_cost_metric": "KL divergence between posteriors (computable for parametric/Bayesian predictors), number of additional labels avoided (label budget savings), and model retraining cost if needed.",
            "information_gain_metric": "Upper-bound on reduction in expected generalization error linked to KL divergence between posteriors; effectively uses posterior change as proxy for information gain.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Provides a principled stopping rule that trades off further information gain (expected risk reduction) against labeling cost; not directly an exploration-exploitation policy but governs when to cease exploration.",
            "diversity_mechanism": null,
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Implicit label budget / desire to minimize labels; stopping when further labels yield negligible expected improvement.",
            "budget_constraint_handling": "Compute an upper bound on expected improvement per additional label via KL divergence; stop when bound is below threshold or no longer justifies label cost.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Survey describes that the PAC-Bayes derived upper bounds can be computed (tightness depends on constants); applied in referenced work to GP regression with predictive-variance acquisition (no numeric summary in survey).",
            "comparison_baseline": "Heuristic stopping rules (entropy thresholds, prediction stability), cross-validation/holdout approaches.",
            "performance_vs_baseline": "PAC-Bayes approach provides a theoretically grounded alternative to heuristics; tightness of bound and practical usefulness depend on model and constant terms.",
            "efficiency_gain": "Enables principled stopping that can save labeling cost by avoiding futile queries when posterior change (KL) is small.",
            "tradeoff_analysis": "Exposes a tradeoff between KL-change (information gain) and constant terms in the bound; tight bounds permit earlier stopping while loose bounds may defer stop unnecessarily.",
            "optimal_allocation_findings": "Stopping should be based on measurable posterior-change bounds (e.g., KL between successive posteriors) to balance labeling cost against expected generalization improvement.",
            "uuid": "e2524.9",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Terayama Phase Diagram AL",
            "name_full": "Efficient construction method for phase diagrams using uncertainty sampling",
            "brief_description": "An application of active learning to construct phase diagrams by discretizing parameter space, propagating initial labels to a probability map, and selecting grid points with high uncertainty for measurement, dramatically reducing required experiments.",
            "citation_title": "Efficient construction method for phase diagrams using uncertainty sampling",
            "mention_or_use": "mention",
            "system_name": "Phase-diagram Active Learning via Label Propagation + Uncertainty Sampling",
            "system_description": "Divide continuous parameter space into a grid; initialize labels at a few measured points; create a probability map via label propagation (diffusion) to estimate class probabilities across grid; select next measurement points where predictive uncertainty (near phase boundaries) is highest using uncertainty-sampling acquisition functions; iterate until diagram resolved.",
            "application_domain": "Materials science: generating phase diagrams (materials state vs thermodynamic/processing parameters).",
            "resource_allocation_strategy": "Choose measurement points with highest predictive uncertainty from the propagated probability map, focusing experimental budget on likely phase boundaries to maximize information per measurement.",
            "computational_cost_metric": "Number of physical measurements (experimental runs), grid resolution (# of candidate points), computational cost of label propagation and uncertainty evaluation (negligible compared to experimental cost).",
            "information_gain_metric": "Predictive uncertainty from label-propagation probability map (entropy/uncertainty near boundaries) used as proxy for expected information from performing the measurement.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explores high-uncertainty regions (phase boundaries) to refine the diagram (exploration of informative regions) while implicitly exploiting known regions by label propagation to infer low-uncertainty areas.",
            "diversity_mechanism": "Grid discretization and propagation encourage spatial coverage; acquisition focuses on distinct boundary regions yielding diversity across phase boundaries rather than clustered repeats.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed experimental budget (number of measurements); high cost per physical measurement.",
            "budget_constraint_handling": "Sequentially allocate measurements to high-uncertainty grid points until budget; demonstrated to reconstruct phase diagram with ~20% of measurements compared to dense grid scanning.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Empirical: for water and a Si-Al-Mg glass-ceramic glaze, the same phase diagrams obtained with approximately 20% of measurements compared to a conventional dense grid.",
            "comparison_baseline": "Dense grid scanning (uniform sampling), random sampling across grid.",
            "performance_vs_baseline": "Achieved equivalent phase diagram reconstruction with ~20% of the measurements vs dense scanning (i.e., ~80% reduction in required experiments).",
            "efficiency_gain": "Approximately 80% reduction in number of measurements compared to full dense-grid exploration for the tested phase-diagram tasks.",
            "tradeoff_analysis": "Demonstrates tradeoff favoring focused boundary exploration (high uncertainty) over uniform coverage; combining diffusion-based representation with uncertainty sampling efficiently allocates experimental resources to informative regions.",
            "optimal_allocation_findings": "Prioritize measurements near phase boundaries (high-propagation uncertainty) to maximally improve phase-diagram resolution under tight experimental budgets.",
            "uuid": "e2524.10",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Ueno XMCD GP AL",
            "name_full": "Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling",
            "brief_description": "Applied active learning for spectral measurement: model spectrum with Gaussian process regression and sequentially select energy points with largest predictive variance to estimate integrated spectral quantity with far fewer measurements.",
            "citation_title": "Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling",
            "mention_or_use": "mention",
            "system_name": "Gaussian Process Predictive-Variance Acquisition for Spectroscopy",
            "system_description": "Model one-dimensional spectral curve using Gaussian process regression; use predictive variance at candidate energy points as acquisition function to sequentially select measurement points from a candidate pooled set; integrate the GP-predicted spectrum to obtain physical quantities (e.g., magnetic moment) with fewer measurements.",
            "application_domain": "Experimental measurement optimization in spectroscopy (XMCD) and one-dimensional regression measurement tasks.",
            "resource_allocation_strategy": "Select next measurement points where predictive variance (uncertainty) is largest to most reduce uncertainty in integrated spectral quantity per expensive measurement.",
            "computational_cost_metric": "Number of physical measurement points taken (primary experimental cost); GP inference compute for predictive variances (minor relative to experimental cost).",
            "information_gain_metric": "Predictive variance from the Gaussian process as proxy for expected information about the spectrum at unmeasured points and hence about integrated physical quantities.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explores high-uncertainty spectral regions (e.g., near peaks) to improve estimate of integrated value; exploitation is implicit via GP posterior interpolation in low-uncertainty regions.",
            "diversity_mechanism": "Predictive-variance acquisition tends to sample points across different uncertain spectral regions (diverse energies) rather than clustering, but no explicit diversity regularizer is described.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of experimental measurements (measurement budget).",
            "budget_constraint_handling": "Sequentially pick high-variance points until measurement budget reached; demonstrated using pooled candidate set of 220 points with small initial sample and 20 sequential acquisitions.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Empirical: starting from 30 random points and acquiring 20 further points via GP variance, the integrated value matched the ground-truth spectrum; achieved similar physical-quantity accuracy with ~22% of measurements compared to dense sampling (220 points).",
            "comparison_baseline": "Conventional dense energy sampling (hundreds of measurements) or random sampling.",
            "performance_vs_baseline": "Obtained equivalent integrated spectral measurement with ~22% of measurements compared to conventional dense scanning, implying ~78% reduction in experimental runs.",
            "efficiency_gain": "Approximately 78% reduction in number of measurements required to obtain equivalent integrated spectral accuracy in the tested XMCD case.",
            "tradeoff_analysis": "GP-variance prioritizes uncertain spectral regions and reduces experimental cost substantially; remaining issues include handling measurement noise, prior incorporation, and stopping criteria.",
            "optimal_allocation_findings": "Using GP predictive variance as acquisition function enables major reductions in measurement counts for one-dimensional spectral estimation when measurement cost dominates computational cost.",
            "uuid": "e2524.11",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "VAE+Adv AL",
            "name_full": "Variational Adversarial Active Learning (VAE + Adversarial discriminator)",
            "brief_description": "Learn acquisition functions task-independently by training a VAE to embed data and an adversarial discriminator to distinguish labeled vs unlabeled latent representations; discriminator score is used to prioritize samples for labeling.",
            "citation_title": "Variational adversarial active learning",
            "mention_or_use": "mention",
            "system_name": "VAE + Adversarial Acquisition Function",
            "system_description": "Train a variational autoencoder to map labeled and unlabeled data into a latent space, then train an adversarial discriminator to predict whether a latent code comes from labeled or unlabeled pool; use discriminator output (degree of 'unfamiliarity' relative to labeled set) as acquisition score to select unlabeled samples independent of task-specific labels.",
            "application_domain": "Pool-based active learning across tasks where task-independent acquisition helps (e.g., image classification), especially with deep representations.",
            "resource_allocation_strategy": "Select unlabeled samples that the discriminator deems most unlike current labeled set (high discriminator score), thereby prioritizing samples under-represented in labeled pool to improve representativeness of labeled set.",
            "computational_cost_metric": "Compute cost of training VAE and discriminator, cost to embed and score unlabeled pool; number of labels acquired (label budget).",
            "information_gain_metric": "Implicit: discriminator score as proxy for expected marginal gain from labeling (task-agnostic proxy for novelty/representativeness); no explicit mutual-information metric.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Favors exploration of underrepresented or novel regions in latent space (diversity/coverage); not explicitly balancing exploitation of currently promising hypotheses.",
            "diversity_mechanism": "Explicit: discriminator identifies latent codes dissimilar to labeled set, promoting diverse selection and coverage.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Label budget (fixed number of queries per round or total).",
            "budget_constraint_handling": "Rank unlabeled samples by discriminator score and select top-k under batch budget; training VAE/discriminator is amortized across acquisitions.",
            "breakthrough_discovery_metric": null,
            "performance_metrics": "Survey reports this approach as a task-independent acquisition learning method; specific empirical numbers are in the referenced work not included in this survey.",
            "comparison_baseline": "Task-specific uncertainty heuristics, random sampling, core-set approaches.",
            "performance_vs_baseline": "Referenced works show improvements in some scenarios, particularly by avoiding query redundancy and improving labeled-set representativeness; no numbers in survey.",
            "efficiency_gain": "Potentially reduces number of labels required to cover data manifold and improves downstream training efficiency; exact gains depend on task.",
            "tradeoff_analysis": "Task-agnostic discriminator focuses on diversity/novelty which may miss task-specific informative examples; combining with uncertainty can balance this tradeoff.",
            "optimal_allocation_findings": "Learning task-independent acquisition using latent-space adversarial scoring is effective to promote diversity and representativeness when label budgets are limited.",
            "uuid": "e2524.12",
            "source_info": {
                "paper_title": "Active Learning: Problem Settings and Recent Developments",
                "publication_date_yy_mm": "2020-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization",
            "rating": 2,
            "sanitized_title": "adaptive_submodularity_theory_and_applications_in_active_learning_and_stochastic_optimization"
        },
        {
            "paper_title": "Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning",
            "rating": 2,
            "sanitized_title": "batchbald_efficient_and_diverse_batch_acquisition_for_deep_bayesian_active_learning"
        },
        {
            "paper_title": "Active learning for convolutional neural networks: A core-set approach",
            "rating": 2,
            "sanitized_title": "active_learning_for_convolutional_neural_networks_a_coreset_approach"
        },
        {
            "paper_title": "Near-optimal Bayesian active learning with noisy observations",
            "rating": 2,
            "sanitized_title": "nearoptimal_bayesian_active_learning_with_noisy_observations"
        },
        {
            "paper_title": "Budgeted stream-based active learning via adaptive submodular maximization",
            "rating": 2,
            "sanitized_title": "budgeted_streambased_active_learning_via_adaptive_submodular_maximization"
        },
        {
            "paper_title": "Variational adversarial active learning",
            "rating": 2,
            "sanitized_title": "variational_adversarial_active_learning"
        },
        {
            "paper_title": "Learning how to active learn: A deep reinforcement learning approach",
            "rating": 2,
            "sanitized_title": "learning_how_to_active_learn_a_deep_reinforcement_learning_approach"
        },
        {
            "paper_title": "Efficient construction method for phase diagrams using uncertainty sampling",
            "rating": 2,
            "sanitized_title": "efficient_construction_method_for_phase_diagrams_using_uncertainty_sampling"
        },
        {
            "paper_title": "Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling",
            "rating": 2,
            "sanitized_title": "adaptive_design_of_an_xray_magnetic_circular_dichroism_spectroscopy_experiment_with_gaussian_process_modeling"
        },
        {
            "paper_title": "Online Choice of Active Learning Algorithms",
            "rating": 1,
            "sanitized_title": "online_choice_of_active_learning_algorithms"
        }
    ],
    "cost": 0.028854,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Active Learning: Problem Settings and Recent Developments
16 Dec 2020</p>
<p>Hideitsu Hino hino@ism.ac.jp 
The Institute of Statistical Mathematics
10-3 Midori-cho190-8562Tachikawa, TokyoJapan</p>
<p>Active Learning: Problem Settings and Recent Developments
16 Dec 20203BBA4516096625344EB29A5DA5F8EA63arXiv:2012.04225v2[cs.LG]
In supervised learning, acquiring labeled training data for a predictive model can be very costly, but acquiring a large amount of unlabeled data is often quite easy.Active learning is a method of obtaining predictive models with high precision at a limited cost through the adaptive selection of samples for labeling.This paper explains the basic problem settings of active learning and recent research trends.In particular, research on learning acquisition functions to select samples from the data for labeling, theoretical work on active learning algorithms, and stopping criteria for sequential data acquisition are highlighted.Application examples for material development and measurement are introduced.</p>
<p>Introduction</p>
<p>Supervised learning is a typical problem setting for machine learning that approximates the relationship between the input and output based on a given sets of input and output data.The accuracy of the approximation can be increased using more input and output data to build the model; however, obtaining the appropriate output for the input can be costly.A classic example is the crossbreeding of plants.The environmental conditions (e.g., average monthly temperature, type and amount of fertilizer used, watering conditions, weather) are the input, and the specific properties of the crops are the output.In this case, the controllable variables are related to the fertilizer and watering conditions, but it would take several months to years to perform experiments under various conditions and determine the optimal fertilizer composition and watering conditions.Methodologies to determine experimental protocols have been developed for obtaining the necessary information at a minimum cost, such as the experimental  *
x x x 0 1 0 1 x 0 0 x x 1  x (1)
x (2)  x (3) x (4)   Figure 1: Example of binary search for a split threshold of x  [0, 1] that is completely separable.A two-class classifier y = h  (x) = (x  ) is efficiently learned.</p>
<p>design method (Fisher, 1935;Hotelling, 1944;Lindley, 1956) and the sequential experimental design method (Ford and Silvey, 1980;Johnson, 1961).In the context of supervised machine learning, sequential experimental design is generally called active learning.Various methodologies have been proposed for the problem of sequentially selecting samples to improve the predictive performance based on a small amount of learning data available.In contrast to active learning, passive learning refers to when all data are given at once.</p>
<p>For active learning, proper selection of samples for training the predictor can reduce the probability of mistakenly predicting the response variable for an unknown explanatory variable (i.e., generalization error).Intuitively, the usefulness of active learning can be demonstrated by the following simple situation (Cohn et al., 1994).If the variable x is distributed in the interval [0, 1], it is completely separable when y = h  * (x) = (x   * ) with a certain threshold  *  (0, 1).According to standard Vapnik-Chervonenkis (VC) theory, a sample of m = O(1/) needs to be obtained from Pr(x, y) to yield a discriminator with an error of  or less.In active learning, the predictor is trained with increasing the number of number of samples by sequentially selecting x  [0, 1] and querying y  {0, 1} for it; then, a hypothesis with a prediction error of  or less can be efficiently obtained through a binary search.As shown in Figure 1, y is queried to obtain label y = 0 for the midpoint x (1) (i.e., half the interval [0, 1]).Then, label y = 0 is obtained for the midpoint x (2) between x (1) and 1.Subsequently, label y = 1 is obtained for the midpoint x (3) between x (2) and 1.Finally, label y = 1 is obtained for the midpoint x (4) between x (2) and x (3) .The interval of x (2) and x (4) is  or less.Thus, by making the midpoint the estimated value of  * , the threshold  *   can be searched.This binary search has a complexity of O(log(1/)) and is an example where active learning can be realized with exponentially fewer samples than passive learning but with the same accuracy 1 .This is a very simple one-dimensional two-class classification problem and is an</p>
<p>1 Generalized binary search (Nowak, 2008(Nowak, , 2009)), which considers a situation with no observation noise (i.e., no uncertainty in the predicted label), uses the concept of adaptive submodularity, which has been shown to be nearly optimal (Golovin and Krause, 2011).</p>
<p>Figure 2: Example of using active learning to predict MNIST data with random forest as the predictor.The horizontal axis represents the number of samples added to the initial 500 samples, and the vertical axis represents the prediction accuracy.The accuracy is observed to be improved with active learning compared with the accuracy of random sampling.</p>
<p>ideal situation without noise.Although exponential acceleration is not possible in all cases, theoretical and experimental demonstrations have shown that active learning can achieve a high prediction accuracy with few samples.Figure 2 compares some active learning methods with random sampling for the prediction of MNIST data (Lecun et al., 1998) with random forest (Breiman, 2001).Specifically, the problem was to predict a 28  28 pixel handwritten number from 0  9.The prediction model was trained with 500 sets of labeled data in advance.Fifty points of data were sequentially selected from the pooled data of 60, 000500 = 59, 500 points and added to the training data for the prediction model to learn, and the prediction accuracy was evaluated with a test dataset consisting of 10,000 points.Uncertainty (Lewis and Catlett, 1994), entropy, and margin (Settles, 2010) represent the acquisition functions that were used to determine which sample was labeled next for active learning.Each learning curve shows the average results when the training dataset used for the initial prediction model was randomly changed 100 times.The graph shows that active learning improved the accuracy while using a smaller amount of data than random sampling.This paper introduces the basic problem setting and concept of active learning, including recent research trends and application examples.Section 2 introduces terms and notations and explains the basic problem setting.Section 3 introduces typical criteria for selecting data that require labeling.Although various algorithms and acquisition functions have been proposed, it is not evident for which situations active learning is better than passive learning.In addition, some methods require solving an optimization problem that is difficult to execute in practice, even if the learning is efficient in principle.In such a case, an approximation method and guaranteeing the accuracy of the approximation are important.Accordingly, section 4 introduces results for theoretical guarantees of active learning.Section 5 presents research on the stopping criteria for active learning.Section 6 provides an example of applying active learning to measurement and material development.Finally, section 7 concludes the paper with future tasks and prospects.</p>
<p>We note that Settles (2010) presented a well-known survey of active learning.Hanneke ( 2014) presented a survey focusing on the theoretical aspects when no assumption is made on the noise distribution, which is called agnostic active learning.Ramirez-Loaiza et al. (2017) presented an experimental comparison of various methods, and Lowell et al. ( 2019) summarized the problems with practical application of active learning to natural language processing.</p>
<p>Active learning may be used in a broad sense to include Bayesian optimization.In this study, Bayesian optimization is considered as the search for optimal experimental settings (parameters or variables) from a small number of trials, while active learning is distinguished as improving the predictive model using a small amount of learning data.</p>
<p>Problem Setting</p>
<p>Let X  X be an explanatory variable and Y  Y be a response variable.Y is a subset of R for regression problems and is {+1, 1} for discrimination problems.The realizations of the random variables X, Y are denoted as x and y, respectively.The function h : X  Y, which predicts the response variable from the explanatory variable, is called a hypothesis or predictor.The set of hypothesis spaces is represented by H.The mechanism for generating data, i.e., the true function y = f (x), is called realizable when it is included in the assumed hypothesis space and non-realizable when it is not.Consider the random variables (X, Y ) with the joint distribution D XY , and let the marginal distribution for X of D XY be D X .The data used for learning the hypothesis are S n = {(x 1 , y 1 ), (x 2 , y 2 ), ..., (x n , y n )}  (X  Y) n .The loss function for evaluating the prediction error based on the hypothesis is represented by  : H  X  Y  R + .In the case of a regression problem, the squared loss (h, x, y) = (y  h(x)) 2 is often used.In the case of a discrimination problem, the discriminant error or 0  1 loss (h, x, y) = (h(x) = y) is often used.For active learning, discrepancies in discriminant results are easier to evaluate compared to discrepancies in regression results.In addition, theoretical analysis is easier with a version space that is described later, but the version space for regression problems does not have a clear definition.Thus, most studies on active learning have focused on discrimination problems.However, several active learning methods have been proposed for regression problems (Burbidge et al., 2007;Castro et al., 2005;Cohn et al., 1996;Hall and Molchanov, 2003;Krogh and Vedelsby, 1995;Sung et al., 1994).In this paper, whether a situation is a discrimination or regression problem depends on the context and explicitly stated when necessary.</p>
<p>For active learning, it is convenient to assume a subject (i.e., learner) who performs the learning for the predictor.The learner selects a sample x for which the value of the corresponding explanatory variable y is unknown by some criteria, thereby obtaining the value of y.The value of the explanatory variable is called a label for both discriminant and regression problems.The function that returns the value of the explanatory variable for x is often called the oracle, but this implies that the label is always correct.In this paper, the term observation is used rather than oracle because, in practice, occasionally, only values that include labeling errors are obtained.</p>
<p>For distribution D XY on X  Y, the generalization error and empirical error are defined as
L D XY (h) = E D XY [(h, X, Y )], L Sn (h) = 1 n n i=1 (h, x i , y i ).
Certain active learning methods for discrimination problems use the concept of version space:
V(S n ) = {h  H|h(x) = y, (x, y)  S n },(1)
which is a subset of the hypothesis set that is consistent with the training data obtained until that point.</p>
<p>In general, the prior distribution p(h) is set for each hypothesis h  H, and the hypothesis is stochastically selected.In Bayesian active learning, the posterior probability p(h|S n ) of the hypothesis is learned with data S n to consider the inference given by the hypothesis sampled according to the posterior probability or the expected value given by the posterior probability of the predicted value (Mackay, 1992).A setting with the distribution included with respect to h  H is advantageous because the volume of the version space can be measured naturally.</p>
<p>The number of samples required for learning a hypothesis to obtain the desired prediction accuracy is called sample complexity in standard statistical learning theory.In the context of active learning, however, the required number of labels is the main concern and is sometimes called label complexity.In addition, there is some debate on how much unlabeled data is sufficient.In probably approximately correct (PAC) learning, terms such as log d, log(1/), log log(1/) often appear in relation to parameters such as the VC dimension d, prediction error , and confidence .However, in this paper, such terms are omitted in favor of order notation, such as O(n) and O(log n).In statistics, most sequential designs assume a setting where observation points can be freely selected according to some standard; this is called membership query synthesis in the context of active learning (Angluin, 1988).This is acceptable when the corresponding explanatory variable value can be reliably obtained.However, for example, this is difficult to apply to problems involving optical character recognition (e.g., appropriate labeling of characters freely composed by the learner)2 .Thus, two types of active learning are usually considered for machine learning, as detailed in the subsequent subsections.</p>
<p>Stream-based active learning</p>
<p>In stream-based active learning, data are sequentially presented from the data generating distribution D X to the learner, who decides whether to request label y for the presented data x based on some criterion.If a label is not requested, then the data are discarded.Labeled data are used to train the predictor.There may be an option where the labeled data are not used to train the predictor.Atlas et al. (1990) presented a typical discussion of stream-based active learning in the field of machine learning.For a discrimination problem, if there is a region in the version space where the predicted label differs from the presented sample, it is possible to query samples that are difficult to predict with the current hypothesis by labeling the sample with a high degree of uncertainty.An exact calculation of the version space and its sub-regions is difficult, hence approximation methods have been proposed.For example, Atlas et al. (1990) proposed a method of constructing a filter that uses a neural network to extract samples that do not match the predictions included in the version space.</p>
<p>Pool-based active learning</p>
<p>In pool-based active learning, a small number of pre-labeled datasets and rich unlabeled datasets (i.e., pooled data) are provided, and a predictor trained with a small dataset is used to select samples from the pooled data for labeling.The data selected for labeling are added to the pre-labeled data available, and the predictor is trained again.This setting represents a typical problem where data collection is easy but the annotation cost is high.Although numerous active learning methods assume that only one query is issued at a time, retraining the model every time a sample is added is inefficient.The time required for one learning session may not be neglected, or the addition of a single sample may not make a meaningful change in the model, especially for deep learning models.Cohn et al. (1994) suggested batch active learning because of the high complexity of version space management.In situations where multiple experiments are parallelly conducted, batch active learning is effective because multiple samples from the pooled data can be selected and labeled simultaneously.If a batch of size k can be labeled at once, a simple strategy may be to select the top k samples by repeatedly selecting a single sample k times; however, a concern is that only k similar samples may be selected.For batch active learning, it is crucial for the selection criteria to consider sample diversity as well as the amount of information that each sample contains with respect to the model.Various methods have been proposed, such as a method based on the notion of submodularity (Hoi et al., 2006) as described below, and formulating the batch selection problem as a non-convex integer program for empirical risk minimization (Wang and Ye, 2015).Problem settings can be conveniently classified as stream-based, pool-based, or arbitrary design; often, a method that assumes a certain setting can still be applied to another setting with slight modifications.</p>
<p>Acquisition Function</p>
<p>Perhaps the most important component of active learning is the acquisition function, which determines whether a sample requires labeling.Several acquisition functions aim to quantify the difficulty of label prediction in some way and actively incorporate difficult-to-predict samples into learning.Numerous early studies on active learning designed the acquisition function through heuristics and presented theoretical analyses.In addition, several methods have recently proposed using reinforcement learning or transfer learning to obtain acquisition functions according to the environment and data.</p>
<p>Design of acquisition function</p>
<p>Most active learning algorithms use an acquisition function that selects a more informative sample or representative sample.The most intuitive approach is to choose the most uncertain data for the current hypothesis.This is called uncertainty sampling and is based on the expectation that if the current prediction model labels the most uncertain data, then the model uncertainty will be reduced the most (Lewis and Gale, 1994;Yang et al., 2015).Various measures of uncertainty are available depending on the problem and model.For logistic regression and multinomial logistic regression models, where the probability value naturally accompanies the prediction, all data that are query candidates are predicted, and the sample with the prediction probability closest to 0.5 (for two-class classification) or with high entropy in the predicted distribution (entropy sampling) can be selected.Alternatively, a sample can be selected that maximizes the difference in probabilities of the labels with the highest and second-highest probabilities (margin sampling).Another approach is to choose the sample with the smallest maximum prediction probability (i.e., least confident sampling).Probabilistic models are a standard means of measuring the prediction uncertainty.Nevertheless, there are also methods that use the reciprocal of the support vector machine (SVM) margin (Tong and Koller, 2002), where the hypothesis can be efficiently narrowed down by dividing the version space into two parts with approximately equal volumes for each query.To evaluate uncertainty, a standard approach is to learn a hypothesis that provides a probabilistic output or to use an ensemble of several hypotheses.However, such prediction models are not always suitable for learning.Lewis and Catlett (1994) achieved a low error rate with significantly fewer samples than random sampling by performing active learning using a different model from the one used for prediction.Houlsby et al. (2011) proposed a method of issuing queries under a Bayesian setting where the entropy of the predicted values is high and the expected entropy of predicted values for the parameter posterior distribution of the prediction model is low (i.e., low uncertainty of predicted values with individual parameter settings).They called their method Bayesian active learning by disagreement (BALD).This method was extended by Kirsch et al. (2019) for batch active deep learning, (BatchBALD), and it is currently considered one of the best-performing methods available.</p>
<p>Given the premise of ensemble learning, the uncertainty of a prediction can be defined as the sample with the most split votes.Seung et al. (1992) studied the most basic form of query by committee (QBC), where an even number of hypotheses is learned, and samples are queried such that the prediction results of two-class labels fall in two halves.They proposed a method of sampling a hypothesis from the version space for unlabeled samples and issuing a query when the prediction results do not match.Intuitively, a sample is difficult to predict when multiple elements of the version space corresponding to the hypothesis are extracted and do not match the prediction results.Moreover, the learning efficiency can be improved if the corresponding label is obtained.Seung et al. (1992) used a method of statistical physics to show that the generalization error decreases exponentially with the number of queries in the limit of an infinite number of hypotheses that are learned simultaneously.Freund et al. (1992) extended the analytical approach of Seung et al. (1992) to a broader class of discrimination problems.They showed that, under certain conditions, the generalization error decreases exponentially with the increase of labeling.Because QBC involves sampling hypotheses from the version space, rigorous implementation is difficult.Gilad-Bachrach et al. (2005) proposed a method for efficiently sampling hypotheses by projecting a version space onto a low-dimensional space.Various acquisition functions are available (Settles, 2010), such as selecting the query that changes the model majorly (Cai et al., 2013) or minimizes the approximation of the expected error (Guo and Greiner, 2007).</p>
<p>The acquisition functions introduced so far have focused on selecting samples with a large amount of information with regard to model uncertainty and change.Because this approach does not consider the distribution of unlabeled data, there is a risk of issuing queries that are considerably affected by the discriminant surface obtained from the current hypothesis.It is pointed out by Eisenberg and Rivest (1990) that it is only a limited situation that active learning improves sample complexity in terms of PAC learning theory.One explanation for this is that random sampling contains information on hypotheses (i.e., correct mapping of explanatory variables to response variables) and on the distribution of explanatory variables, which is lost with active learning (Freund et al., 1992).It is reasonable to require active learning strategy to reflect the distribution of explanatory variables (e.g., actively sampling points with high density as representative), and methods have been proposed that are based on the idea of annotating representative samples.Nguyen and Smeulders ( 2004) selected representative samples by clustering pooled data in advance, and Settles and Craven (2008) implemented the same by weighting data according to the k-neighbor distance.However, selecting a representative sample requires a large number of queries compared to an approach that focuses on the amount of information, such as uncertainty.Some studies have considered combining the two approaches to construct efficient and effective acquisition functions (Donmez et al., 2007;Huang et al., 2014;Xu et al., 2003)).For example, Huang et al. ( 2014) considered a sample with a small margin for a two-class discrimination problem to have high uncertainty; they selected a representative and informative query by solving the minimax optimization problem of minimizing the risk for all possible labels of pooled data, while maximizing the risk of labeling candidate samples.</p>
<p>Learning the acquisition function</p>
<p>The success or failure of active learning with the acquisition functions introduced in the previous subsection depends on the prediction model, data distribution, and compatibility of the acquisition function to them.In addition to the selection of the prediction model, another problem is the general difficulty of selecting an appropriate acquisition function.Accordingly, an approach called meta-active learning has recently been proposed, where an acquisition function is learned from data (Konyushkova et al., 2017).A promising approach is to formulate active learning in the framework of reinforcement learning and express the acquisition function as a policy to be learned by reinforcement learning (Ebert et al., 2012).</p>
<p>For the reinforcement learning of a typical acquisition function, some methods approximate the Q-function with a deep Q-network (DQN) (Mnih et al., 2015).Fang et al. (2017) regarded stream-based active learning as a Markov decision process and proposed learning the optimal policy by setting the parameter  of the prediction model and represented state as the unlabeled sample x and action as whether or not labeling is required.Woodward and Finn (2017) used one-shot learning with neural Turing machines to design states, behaviors, strategies, and rewards; in addition, they used reinforcement learning to design a function that determines if a label needs to be requested for the presented sample for stream-based active learning.By using deep reinforcement learning with long short-term memory (LSTM) as the Q-function to determine the value of an action in a certain state, it is possible to judge whether a sample is unknown and whether a label should be requested.Specifically, the state (or observation) is a pair of labels for the input and the previous observation.It is used to determine whether to request a label for the currently given input, depending on the confidence level of the prediction for the input and if a label was requested for the previous input.The action is to request a label for the presented sample or predict the label itself.If the prediction of the learner of the label is correct, the reward is zero; if it is incorrect, the reward is negative.If the learner requests a label, a slightly negative reward is obtained.This allows a policy to be learned so that a label is not required if there is confidence in the prediction.Furthermore, Bachman et al. (2017) applied this method to reinforcement learning of the acquisition function based on matching networks for pool-based active learning.</p>
<p>The problem of learning a policy for selecting the optimal query in an ever-changing environment is closely related to the bandit problem.Baram et al. (2004); Hsu and Lin (2015) considered the design problem of the acquisition function for active learning as a multi-armed bandit problem.They proposed a method to select the optimal strategy as multiple acquisition functions or a linear combination of such functions.Chu and Lin (2017) further proposed a method of using a strategy learned as a multi-armed bandit problem in one domain for active learning in a different domain.Wassermann et al. (2019) proposed reinforcement learning of a filter for stream-based active learning based on reinforcement learning.Deep reinforcement learning has also been used to change the acquisition function dynamically to follow changes in the input distribution.Haumann et al. ( 2019) used a Bayesian deep learner as a model for evaluating uncertainty and defined states with its predicted distribution.In addition, they proposed a method where another Bayesian deep learning model is learned separately from the output prediction, and the current predictor state and the acquisition function appropriate for the data are used as feature quantities together with the predicted output distribution and data.</p>
<p>Large-scale models for active learning are not expected to change significantly if only a single data point is added to the training data (Sener and Savarese, 2018).In addition, because of the high learning cost of the model, batch active learning is considered as a suitable approach.Ravi and Larochelle (2018) used meta-learning for batch active learning of acquisition functions.(Sener and Savarese, 2018) empirically showed that the classical active learning of acquisition functions based on heuristics is ineffective for a convolutional neural network (CNN).They formulated batch selection as a core-set selection problem, which is defined as selecting a group of data points for learning such that the predictor trained using the selected subset is not significantly different from the case where all data points are used for learning.To solve the core-set selection problem with no label information, they derived an upper bound for the difference between the average loss for a subset and the average loss for all data.Subsequently, they developed an active learning algorithm that minimizes the upper bound.Attempts to apply active learning to large-scale models such as deep learning have been actively studied in recent years.Sinha et al. (2019) designs an acquisition function using a variational autoencoder (VAE) (Kingma and Welling, 2014) and an adversarial network (Goodfellow et al., 2014).Specifically, the VAE is trained to match the distribution of labeled and unlabeled data, and adversarial networks are labeled against the latent space of the VAE.It is learned to determine whether or not it corresponds to the data already given.By using the discrimination network of the adversarial network as the acquisition function, the learning of the acquisition function that performs query selection independent of the task is realized.</p>
<p>Theoretical Guarantee</p>
<p>Active learning is a type of feedback system.Because samples are added through the acquisition function, training samples cannot be expected to follow a independent and identical distribution, which is the assumption of standard learning theory and statistical analysis.The generalization error can be reduced exponentially by reducing the version space, as in QBC for a noise-free discrimination problem (Freund et al., 1997).The generalization error for practical algorithms is still being actively researched.In several cases, the acquisition function is defined so that some criterion is maximized or minimized.However, this optimization is often an NP-hard problem that is difficult to solve.This section introduces an approach that uses submodularity to provide a theoretical guarantee when an optimization problem associated with the evaluation of an acquisition function is approximated by a greedy algorithm.Also, researches on evaluation of label complexity are briefly summarized.</p>
<p>Utilization of submodularity</p>
<p>The concept of submodularity with respect to a set function (Fujishige, 1991) is useful for characterizing the effect of gradually adding training data, such as in active learning.Suppose there is a support set V and power set function 2 V , and a set function f : 2 V  R. Here, the set function f is considered as an index that expresses the value when certain elements are selected from V .Although there are some equivalent expressions, we adopt the definition of submodularity which is suitable for the purpose of this paper.For any S  V, v  V , f (v|S) = f ({v}  S)  f (S) is called the increase by v relative to a set S. For an arbitrary A  B  V and v  V \B, when f (A  {v})  f (A)  f (B  {v})  f (B) or equivalently f (v|A)  f (v|B) holds true, the set function f is called submodular.Intuitively, the value of the newly added element v decreases as the existing element set increases in size.When the function f further satisfies f (v|A)  0, f is called monotonous.Consider the problem of maximizing f (A k ) by sequentially extracting k elements from V to construct a subset A k .For a monotonic submodular function with f () = 0, the simple policy A i+1 = A i {argmax eV \A i f (A i  {e})}, where a greedy element is added solely based on the value of f , guarantees an approximation ratio of 1  1/e (Nemhauser et al., 1978).In other words, f (A k )  (1  1/e) max |A|k f (A).Because the value obtained by acquiring new labels gradually decreases in pool-based active learning, an algorithm using submodularity is suitable for batch active learning.If the batch size k is fixed, the problem of selecting k samples to maximize the entropy of the predicted distribution p(y|x) is guaranteed to have an approximation rate of 1  1/e through selection by the greedy algorithm based on the submodularity of entropy.Hoi et al. ( 2006) considered a two-class discrimination problem using a model with the parameter w as a hypothesis, and quantified the effect of batch data on the model by using a Fisher information matrix
I p (w) = E p y=1 p(y|x)  2 w 2 log p(y|x)dx(2)
for the distribution p(x) of the sample x.Specifically, they aimed to select a batch that was as close as possible to the information that all samples had, by minimizing Tr[I q (w) 1 I p (w)], where p(x) and q(x) represent the pooled data distribution and selected batch distribution, respectively.This criterion is equivalent to asymptotically minimizing the expected squared error and has long been used as an acquisition function for active learning (Cohn et al., 1996;Fukumizu, 1996;Fukumizu and Watanabe, 1994).Hoi et al. (2006) showed that an approximation of Tr[I q (w) 1 I p (w)] for a logistic regression model is a monotonic submodular function and that the selection of batch data by the greedy algorithm is a suitable approximation of the optimal batch.Thus, by designing an acquisition function with submodularity for batch active learning, batch data can be efficiently acquired in each round by the greedy algorithm at a guaranteed approximation rate.However, the concept of submodularity is insufficient for describing the selection of the optimal sample according to data acquired so far and the hypothesis.Some research has characterized the sample acquisition policy by generalizing the notion of submodularity, which is called adaptive submodularity.Golovin and Krause (2010) showed that reducing the version space can be regarded as a covering problem for a set of unsuitable hypotheses, which has adaptive submodularity.</p>
<p>They utilized this fact to analyze the label complexity of a generalized binary search algorithm when there is no noise in the observation.When there is noise, Golovin et al. (2010) considered the problem of seeking a query strategy that minimizes the cumulative cost of labeling.By selecting samples in a finite hypothesis space until the size of the version space becomes unity, a unique hypothesis can be identified.They proposed an efficient approximation algorithm based on adaptive submodularity.Similarly, the adaptive submodularity of version space reduction has been used to derive approximation rates for batch active learning with a greedy algorithm and pool-based active learning using several criteria, such as entropy maximization (Chen and Krause, 2013;Nguyen et al., 2013).The concept of adaptive submodularity is originally for poolbased active learning, but Fujii and Kashima (2016) extended it as a policy adaptive submodularity, and derived a mini-batch active learning algorithm and a stream-based active learning algorithm with guarantees of the approximation rate.</p>
<p>Learning theory of active learning</p>
<p>Determining when active learning reduces the generalization error at a faster rate than passive learning is an important question and has been the subject of various studies.</p>
<p>Although active learning can be applied to the binary search introduced in section 1, it does not work well if there is even a small amount of observation noise.Eisenberg and Rivest (1990) stated that queries often have little effect on label complexity in the framework of PAC learning.Nevertheless, active learning has been clearly demonstrated to improve label complexity in noisy observation cases.Regarding problems where active learning is no better than passive learning, (Balcan et al., 2008) indicated that the sample complexity required to train a predictor with a generalization error of  or less differs from the sample complexity required to guarantee that the resulting predictor has a generalization error of  or less.Subsequently, they analyzed situations where active learning can effectively reduce label complexity.</p>
<p>Representative studies on the label complexity of active learning algorithms are found in (Dasgupta, 2005a,b).Dasgupta (2005a) presented a simple example: for a realizable and one-dimensional case, learning by O(log(1/)) through a binary search is possible; for a case with two dimensions or more, O(1/) is unavoidable in the worst case (i.e., the correct solution is an unbalanced hypothesis).The study shows that O(d log(1/)) is possible as an average for an appropriate distribution in the hypothesis space, where d is the VC dimension of the hypothesis space.For the problem of two-class discrimination without noise, Dasgupta (2005b)) introduced the following three quantities: desired accuracy , the degree to which the size of the version space is reduced by a single query , and the quantity  to characterize the amount of unlabeled data (i.e., pooled data).Then, defining the notion of (, ,  ) separability of the hypothesis space H, active learning algorithm was characterized.By using , Dasgupta (2005b) introduced an example that the sample complexity of active learning is between O(1/) and O(log(1/)), and for the realizable hypothesis space, O(log(1/)) can be achieved depending on the size of the data distribution and pooled data.</p>
<p>In online active learning, when the problem is linearly separable and the data is in the d dimensional unit sphere, Freund et al. (1997) showed that lable complexity for solving a realizable problem if of order O(d log(1/)), and the number of discarded samples without labeling is of order O((d/) log(1/)).In QBC, it is generally difficult to sample hypotheses from the version space.Cesa-Bianchi et al. (2003); Dasgupta et al. (2009) showed that O(d log(1/)) is realizable with a simpler algorithm than QBC for data distributed on a unit sphere.</p>
<p>Much of the discussion about sample complexity in active learning has been on reducing version space, and the hypothesis space has been assumed to contain a true hypothesis (otherwise the version space can be an empty set).Kriinen (2010) discussed the label complexity of active learning in unrealizable situations and showed that this typically did not lead to exponential improvement compared to passive learning.In ordinary statistical learning theory, faster convergence can be obtained by impos-ing conditions on the observation noise rather than using active learning.Even with active learning, imposing restrictions on conditional distributions, such as the margin conditions, may result in exponentially faster convergence than with passive learning.On the other hand, agnostic active learning can be used to deal with situations where observation noise is not assumed (Balcan et al., 2009;Dasgupta et al., 2008;Hanneke, 2007).Balcan et al. (2009) proposed an A 2 algorithm that operates under arbitrary noise conditions and achieved a sample complexity of O( 2 / 2 ), where  is the generalization error due to the optimal hypothesis in the assumed hypothesis space.The learner must approach the optimal hypothesis in the hypothesis space as close as .Hanneke (2007) introduced the discrepancy coefficient , which is determined by the hypothesis space and data distribution and showed that the sample complexity of the A 2 algorithm by (Balcan et al., 2009) is of order O( 2  2 / 2 ).This was further improved to O( 2 / 2 ) by Dasgupta et al. (2008).Notably, noise is not the only reason for a case to be non-realizable.Research on sample complexity has also considered noise models, such as the margin condition (Castro and Nowak, 2008).</p>
<p>Not many studies on label complexity have focused on computational efficiency.Awasthi et al. (2017) discussed a methodology that guarantees the acquisition of the error  in polynomial time with bounded noise and agnostic settings.The theoretical analysis of active learning is detailed in a tutorial by Hanneke and Nowak3 .</p>
<p>Stopping problem</p>
<p>For sequential algorithms, the timing to stop learning is generally an important issue.For active learning, the optimal stopping criterion depends on the tradeoff between the labeling cost and the gain of improving the prediction accuracy.If the limit of the measurement technology (noise level) is known or the theoretically achievable error can be estimated, learning may be stopped when the prediction accuracy comes close to that level.However, even if the labeling cost is not clearly determined or the target accuracy is not clearly defined, there may be situations where active learning is desirable to reduce learning costs.In the case of a fixed budget for labeling (i.e., fixed number of times), requesting the full budget of labels may seem the best approach.However, if sufficient learning data have already been obtained within the budget, a smaller budget may be sufficient for similar situations in the future.In addition, determining the room for improvement of the prediction accuracy when the budget is exhausted is important.A simple approach to determine whether the maximum generalization error has reached its peak is to evaluate the prediction performance with cross-validation or holdout data.However, active learning is generally assumed to be for situations with high labeling costs, and obtaining holdout and validation data separately cannot be expected.In other words, determining when to stop active learning requires self-contained statistics.The optimal stopping problem has been considered in the field of OR (Ciss et al., 2012;Gilbert and Mosteller, 1966).In addition, early stopping (Prechelt, 2012) is widely used with regularization methods, especially for the learning of complex models, such as deep learning.For kernel ridge regression, early stopping has an implicit regularization effect (Rosasco and Villa, 2015;Yao et al., 2007), and its theoretical properties have been considered for nonparametric regression (Raskutti et al., 2014).Some heuristics have been proposed in the context of Bayesian optimization (Desautels et al., 2014;Lorenz et al., 2015), but few have a solid theoretical background (Dai et al., 2019).Particularly for active learning, the less is more phenomenon (Schohn and Cohn, 2000) has shown that a model trained with a small amount of data outperforms a model trained with all the data.This is the motivation for active learning and shows the significance of determining the optimal time to stop learning.Methods for determining the stopping criterion for active learning include using the entropy of the prediction result for the pooled data, changes in the prediction result, and certainty of the prediction (Zhu et al., 2008); or considering the stability of prediction results by multiple predictors (Altschuler and Bloodgood, 2019;Bloodgood and Grothendieck, 2013).Other methods include stopping when the sample inside the SVM margin disappears from the pooled data (Schohn and Cohn, 2000;Vlachos, 2008) and checking the convergence of a similar quantities (Krause and Guestrin, 2007;Laws and Schtze, 2008), but their theoretical bases have not been fully verified.Krause and Guestrin (2007) focused on batch-mode Bayesian active learning with Gaussian process regression; they used submodularity to derive a relation among mutual information for the predicted distributions when samples are actively selected or randomly selected.Although their method has been suggested as a stopping criterion for active learning, it significantly relies on the prediction model being a Gaussian process regression, and it also requires appropriate discretization of the domain of an explanatory variable.The A 2 algorithm of Balcan et al. (2009) is formulated as the following procedure according to Hanneke (2014).For the t-th iteration of the algorithm, 2t unlabeled samples are selected and set as S. A query is issued, and a label is provided to the intersection Q = DIS(H)  S of the disagreement subspace
DIS(H) = {x  X |h, h   H, h(x) = h  (x)}
for the hypothesis space and S. By using the labeled dataset Q, the empirical loss L Q (h) is minimized to select the hypothesis h  H. Namely,  = argmin hH L Q (h).Finally, a hypothesis h is removed from the hypothesis space if it satisfies
L Q (h)  L Q ( ) &gt; PQ (h = ) d |Q| .
Here, PQ (h = ) is the estimated probability using Q that h is not equal to the hypothesis , and d is the VC dimension of the hypothesis space.By repeating this process and reducing the hypothesis space, a highly accurate hypothesis remains.Using this algorithm, it is natural to stop learning if max hH PQ (h = ) d |Q| &lt;  with an appropriate threshold  &gt; 0.</p>
<p>In a more general approach, Ishibashi and Hino (2020) tackled the problem of stopping active learning from the perspective of PAC Bayesian learning (McAllester, 1999) when the posterior distribution is obtained.The range of the loss function  is assumed to be [a, b],  &lt; a &lt; b &lt; .In the PAC Bayesian learning framework, hypothesis h also follows the distribution of function values, and a prior distribution p(h) is introduced.Let p(h|S n ) be the posterior distribution of h  H.If the negative log-likelihood  is the loss function, then (h, x, y) =  log p(y|h, x) and p(y|h, x) = e  (h,x,y) .The posterior distribution of h obtained using the training data S n is
p(h|S n ) = p(y n |h)p(h) p(y n ) = e nL Sn (h) p(h) p(y n )
where the values of the response variable included in S n are arranged as the vector y n .The predictive distribution for y * corresponding to the new input point x * can be represented as
p(y * |S n , x * ) = p(y * |h, x * )p(h|S n )dh.
The posterior distributions of the hypotheses obtained by learning with S n and S n+1 = S n  {(x n+1 , y n+1 )} are p(h|S n ) and p(h|S n+1 ), respectively.The difference with the expected values for the posterior distribution of the expected risk is defined as
R(p(h|S n ), p(h|S n+1 )) = E p(h|Sn) [L D (h)]  E p(h|S n+1 ) [L D (h)],(3)
where R represents the amount of reduction in the expected generalization error.When p(h|S 0 ) = p(h), then
R(p(h)|p(h|S n )) = n i=1 R(p(h|S i1 ), p(h|S i )) =E p(h) [L D (h)]  E p(h|Sn) [L D (h)] = const.  E p(h|Sn) [L D (h)]
and the convergence of R and E p(h|Sn) [L D (h)] is equivalent.If p(h|S n ) and p(h|S n+1 ) are the posterior distributions of h  H given S n and S n+1 , then the following holds true:
R(p(h|S n ), p(h|S n+1 ))  D KL [p(h|S n )||p(h|S n+1 )] + C.(4)
Here, D KL is the Kullback-Leibler (KL) divergence, and C is a quantity that depends on the range [a, b] that h  H can take.The KL divergence on the right hand side is a quantity that can be calculated for a concrete predictor (e.g., Gaussian process) under certain conditions.Ishibashi and Hino (2020) proposed a method to determine the optimal time to stop active learning by sequentially calculating the upper bound of R and combining convergence tests for pool-based active learning when Gaussian process regression is the predictor and the acquisition function is the predictive variance.Note that the upper bound of Eq. ( 4) does not become less than the constant term because KL divergence is nonnegative.Therefore, when the constant term becomes large, the upper bound does not become tight.Another upper bound can be derived that is tight even if the constant term is large as long as the KL divergence is sufficiently small.Let p(h|S) and p(h|S  ) be posterior distributions for the hypothesis h  H given S and S  .At this time, the following inequality holds for any  &gt; 0 and any measurable function
L D (f ) and v  E[L 2 D (f )]: R(p(h|S), p(h|S  ))  v b  a (e W (u)+1  1).(5)
Here, W () is the Lambert W function, and u
= (ba) 2 D KL [p(h|S)||p(h|S  )]v ve .
For the bound of Eq. ( 5), W (1/e) = 1 when the KL divergence is zero.This guarantees that the upper bound also approaches zero as the KL divergence approaches zero, making it a tight bound.</p>
<p>Application to measurement and material development</p>
<p>Since the establishment of the US Materials Genome Initiative, research has been actively done to improve the efficiency, acceleration, and sophistication of materials and measurements through machine learning.Prototyping high-performance materials and measurements in synchrotron radiation facilities is often time-consuming and costly.Therefore, active learning is expected to substantially improve efficiency (del Rosario et al., 2020;Lookman et al., 2019;Tian et al., 2020).This section introduces two example applications of active learning to material searching and measurement.</p>
<p>Efficient phase diagram creation</p>
<p>A phase diagram or state diagram represents the relationship between the state of a material or system and thermodynamic parameters.For example, H 2 O takes one of three states depending on the temperature and pressure: solid, gas, and liquid.For metallic materials, the microstructure can be austenite, ferrite, or pearlite depending on the mixture ratio of raw materials, processing temperature, and annealing pattern.Understanding the relationship between these different states and the thermodynamic parameters is necessary to understand the material properties and develop materials with desirable properties.An important first step for material development is running trials and measuring materials while varying different parameters to create phase diagrams.Comprehensive prototyping and the measurement of multiple parameters are often bottlenecks for the development process.Terayama et al. (2019) proposed using active learning to create phase diagrams efficiently.In their method, the range of the target parameter is divided into an appropriate grid resolution, and the state is measured at a few points on the grid.In terms of the notation of active learning, the grid is X , and the parameter configuration represented by each point corresponds to x  X .The state at each point x corresponds to y.A probability map is created for the grid using a label propagation algorithm based on the diffusion process and starting from a point that corresponds to these few (x, y).Uncertainty is expected to increase near the phase boundary.Based on the probability values obtained at each point, a phase diagram can be created by sequentially selecting measurement points with three types of acquisition functions based on uncertainty sampling.Terayama et al. (2019) conducted an evaluation experiment where they created a three-phase diagrams of water and of Si-Al-Mg glass-ceramic glaze.They showed that the same phase diagram could be obtained with approximately 20% of the measurements compared to using a conventional dense grid.</p>
<p>Improving the efficiency of X-ray magnetic circular dichroism spectroscopy</p>
<p>As an example of the improvement in measurement efficiency achieved by active learning, its application to X-ray magnetic circular dichroism (XMCD) spectroscopy by Ueno et al. (2018) is briefly introduced here.For XMCD spectroscopy, because the integrated intensity of the spectrum directly corresponds to the magnetic moment according to the magneto-optical sum rule, this can be used to analyze the magnetic properties of a material quantitatively.A precise spectrum can be obtained by fine grid of the energy measurement point, and high-precision quantitative analysis is possible by integrating the spectrum.In the past, the energy was measured at several hundred points based on the intuition and experience of the experimenter.The spectrum measurement can be formulated as a problem of estimating a function or curve f (x) under the assumption that the spectral curves with the X-ray energy on the x-axis and absorption on the y-axis are connected by the function y = f (x) + , where  is the measurement noise.Thus, approximating the function f (x) from a small number of measured points is simply a one-dimensional regression problem with active learning.Ueno et al. (2018) approximated the relationship between the X-ray energy (x) and absorption amount (y) through Gaussian process regression, and they used the predictive variance at an unobserved point of the Gaussian process regression as the acquisition function.The spectral data corresponding to 220 points measured previously were regarded as ground truth.The initial data were set to 30 randomly measured points, and a Gaussian process model was applied.Points with a large predictive variance were sequentially measured from the 220 candidate points (corresponding to pooled data) excluding the measured points.The integrated value of the Gaussian process regression curve according to the 20 new points added to the initial 30 points was confirmed to be approximately the same as the integrated value of the ground truth spectrum.In other words, the physical quantity could be measured with approximately 22% of the number of measurements for the conventional method, which demonstrates the usefulness of active learning for material measurement.However, several issues remain to be addressed, such as the introduction of prior knowledge, dealing with measurement noise (e.g., whether or not short-term measurements should be performed multiple times), and stopping criteria.</p>
<p>Future works and prospects</p>
<p>Active learning has long history, originated in sequential experimental design, but it is still being actively researched because of its usefulness and necessity.Depending on the samples used to train the predictor, some samples may not help improve the prediction performance or even degrade it, such as in the case of incorrect labels or outliers.</p>
<p>Although not stated in this paper, active learning has been applied to screening such samples (Abe et al., 2006).In addition, methods such as curriculum learning (Bengio et al., 2009) and self-paced learning (Kumar et al., 2010), where samples are selected in an appropriate order for sequential and iterative learning, can be considered as an extension of pool-based active learning.</p>
<p>For active learning, a small number of pre-collected samples are assumed to be available at hand.However, if the pre-collected samples are chosen according to a certain collection policy such as treatment of a particular patient, then the initial learning uses data that differ from the population distribution of the pooled data.Thus, the variance of the estimated loss function will be excessively large if the initial collected data are not handled properly.Active learning using initial data collected according to such a policy (Yan et al., 2018(Yan et al., , 2019) ) or using a decision-making model (Sundin et al., 2019) has attracted attention in recent years.Numerous studies have used active learning to select the optimal intervention for identification in causal reasoning (Hauser and Bhlmann, 2014;He and Geng, 2008;Masegosa and Moral, 2013;Tong and Koller, 2001) and analyze the number of interventions (i.e., label complexity) required to identify causal relationships (Greenewald et al., 2019;Shanmugam et al., 2015).</p>
<p>In deep learning, over-parameterization refers to the learning error tending to zero while the test error tends to decrease continuously.In this situation, bounds using learning errors are meaningless.The application of non-parametric methods (e.g., the kernel method or deep learning) may be a promising approach for reducing the problem of model bias inherent in active learning, which assumes a conventional simple hypotheses class.However, few studies have considered this approach, except for heuristic ones.For example, Karzand and Nowak (2020) focused on the smoothness of the function characterized by the RKHS norm of the function h  H to be approximated, and they proposed the acquisition function x * = argmax xX min{ h x  , h x + }, where h x  is the RKHS norm of the hypothesis h  H that is updated when the label y of the point x is +1 or 1.They showed a case in which a label complexity of O(log n) can be achieved with this acquisition function, albeit for a special function class.As described above, several active learning methods assume that some labeled data are available in advance, but there has been not enough discussion about the quality of the initially obtained data.Identifying a sample set for labeling from unlabeled pooled data is important for the initialization of active learning and has been discussed by Murata and Suzuki (2020).</p>
<p>In character recognition research, the approach of synthesizing and learning character images on a computer is widely taken, and in this case, the label of the synthesized image is known. On the other hand, in active learning, an unlabeled synthetic image that is judged to belong to the boundary region of the character type, which is difficult to label, is generated, and labeling is required for that image.
https://nowak.ece.wisc.edu/ActiveML.html
AcknowledgementThe author is supported by JST JPMJCR1761 and JPMJMI19G1.The author thank Dr. Hideaki Ishibashi, Tetsuro Ueno, Kanta Ono and Mr. Masanari Kimura for their valuable comments on the draft of this paper.
Outlier detection by active learning. Naoki Abe, Bianca Zadrozny, John Langford, 10.1145/1150402.1150459Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining200620061595933395</p>
<p>Stopping Active Learning Based on Predicted Change of F Measure for Text Classification. Michael Altschuler, Michael Bloodgood, 10.1109/ICOSC.2019.8665646IEEE International Conference on Semantic Computing, ICSC 2019. 2019ISBN 9781538667835</p>
<p>Queries and Concept Learning. Dana Angluin, 10.1023/A:1022821128753Machine Learning. 19882</p>
<p>Training connectionist networks with queries and selective sampling. Les E Atlas, David Cohn, Richard Ladner, Advances in Neural Information Processing Systems, NIPS 1989. 1990ISBN 9781558601000</p>
<p>The power of localization for efficiently learning linear separators with noise. Pranjal Awasthi, Maria Florina Balcan, Philip M Long, 10.1145/3006384J. ACM. 0004-5411636January 2017</p>
<p>Learning algorithms for active learning. Philip Bachman, Alessandro Sordoni, Adam Trischler, International Conference on Machine Learning, ICML 2017. 2017</p>
<p>The true sample complexity of active learning. Maria Florina Balcan, Steve Hanneke, Jennifer Wortman, Conference on Learning Theory, COLT 2008. 2008</p>
<p>Agnostic active learning. Maria-Florina Balcan, Alina Beygelzimer, John Langford, org/10.1016/j.jcss.2008.07.003Journal of Computer and System Sciences. 0022-00007512009. 2006</p>
<p>Online Choice of Active Learning Algorithms. Yoram Baram, Ran El-Yaniv, Kobi Luz, Journal of Machine Learning Research. 52004</p>
<p>Curriculum learning. Yoshua Bengio, Jrme Louradour, Ronan Collobert, Jason Weston, International Conference On Machine Learning. 2009. 2009ISBN 9781605585161</p>
<p>Analysis of Stopping Active Learning based on Stabilizing Predictions. Michael Bloodgood, John Grothendieck, Conference on Computational Natural Language Learning, Proceedings, CoNLL 2013. 2013ISBN 9781937284701</p>
<p>Random forests. Leo Breiman, 10.1023/A:1010933404324Machine Learning. 200145</p>
<p>Active learning for regression based on query by committee. Robert Burbidge, Jem J Rowland, Ross D King, Intelligent Data Engineering and Automated Learning, IDEAL 2007. Hujun Yin, Peter Tino, Emilio Corchado, Will Byrne, Xin Yao, Berlin, Heidelberg; Berlin HeidelbergSpringer2007</p>
<p>Maximizing expected model change for active learning in regression. Wenbin Cai, Ya Zhang, Jun Zhou, 10.1109/ICDM.2013.104IEEE International Conference on Data Mining, ICDM 2013. 2013</p>
<p>Faster rates in regression via active learning. Rui Castro, Rebecca Willett, Robert Nowak, Advances in Neural Information Processing Systems, NIPS 2005. 2005ISBN 9780262232531</p>
<p>Minimax bounds for active learning. M Rui, Robert D Castro, Nowak, 10.1109/TIT.2008.920189IEEE Transactions on Information Theory. 5452008</p>
<p>Learning probabilistic linear-threshold classifiers via selective sampling. Nicol Cesa-Bianchi, Alex Conconi, Claudio Gentile, 10.1007/978-3-540-45167-928Annual Conference on Learning Theory, COLT 2003. 20032777</p>
<p>Near-optimal batch mode active learning and adaptive submodular optimization. Yuxin Chen, Andreas Krause, International Conference on Machine Learning, ICML 2013. 2013</p>
<p>Can active learning experience be transferred. Min Hong, Hsuan Chu, Lin Tien, 10.1109/ICDM.2016.135IEEE International Conference on Data Mining, ICDM 2017. 2017</p>
<p>Optimal stopping problems for some markov processes. Mamadou Ciss, Pierre Patie, Etienne Tanr, 10.1214/11-AAP795Annals of Applied Probability. 2232012</p>
<p>Improving Generalization with Active Learning. David Cohn, Les Atlas, Richard Ladner, 10.1023/A:1022673506211Machine Learning. 199415</p>
<p>Active learning with statistical models. David A Cohn, Zoubin Ghahramani, Michael I Jordan, 10.1613/jair.295Journal of Artificial Intelligence Research. 41996</p>
<p>Bayesian optimization meets Bayesian optimal stopping. Zhongxiang Dai, Haibin Yu, Bryan Kian Hsiang Low, Patrick Jaillet, International Conference on Machine Learning, ICML 2019. 2019ISBN 9781510886988</p>
<p>Analysis of a greedy active learning strategy. Sanjoy Dasgupta, Advances in Neural Information Processing Systems. 2005a</p>
<p>Coarse sample complexity bounds for active learning. Sanjoy Dasgupta, Advances in Neural Information Processing Systems, NIPS 2005. 2005bISBN 9780262232531</p>
<p>A general agnostic active learning algorithm. Sanjoy Dasgupta, Daniel Hsu, Claire Monteleoni, 10th International Symposium on Artificial Intelligence and Mathematics, ISAIM 2008. 2008</p>
<p>Analysis of perceptronbased active learning. Sanjoy Dasgupta, Adam Tauman Kalai, Claire Monteleoni, Journal of Machine Learning Research. 15324435102009</p>
<p>Assessing the frontier: Active learning, model accuracy, and multi-objective candidate discovery and optimization. Zachary Del Rosario, Matthias Rupp, Yoolhee Kim, Erin Antono, Julia Ling, 10.1063/5.0006124The Journal of Chemical Physics. 0021-960615322020</p>
<p>Parallelizing explorationexploitation tradeoffs with Gaussian process bandit optimization. Thomas Desautels, Andreas Krause, Joel Burdick, Journal of Machine Learning Research. 1533-7928152014</p>
<p>Dual strategy active learning. Pinar Donmez, Jaime G Carbonell, Paul N Bennett, 10.1007/978-3-540-74958-514European Conference on Machine Learning and Principles and Practiceof Knowledge Discovery in Database. 2007ISBN 9783540749578</p>
<p>RALF: A reinforced active learning formulation for object class recognition. Sandra Ebert, Mario Fritz, Bernt Schiele, 10.1109/CVPR.2012.6248108Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. the IEEE Computer Society Conference on Computer Vision and Pattern Recognition2012ISBN 9781467312264</p>
<p>On the sample complexity of pac-learning using random and chosen examples. Bonnie Eisenberg, Ronald L Rivest, Conference on Learning Theory, COLT 1990. 1990</p>
<p>Learning how to active learn: A deep reinforcement learning approach. Meng Fang, Yuan Li, Trevor Cohn, 10.18653/v1/d17-1063Conference on Empirical Methods in Natural Language Processing. 2017. 2017ISBN 9781945626838</p>
<p>A Sequentially Constructed Design for Estimating a Nonlinear Parametric Function. R A Fisher, ; I Ford, S Silvey, Biometrika. 6721935. 1980Oliver and BoydThe design of experiments</p>
<p>Information, prediction, and query by committee. Yoav Freund, Sebastian Seung, Eli Shamir, Naftali Tishby, Advances in Neural Information Processing Systems, NIPS 1992. 1992</p>
<p>Selective Sampling Using the Query by Committee Algorithm. Yoav Freund, Sebastian Seung, Eli Shamir, Naftali Tishby, 10.1023/A:1007330508534Machine Learning. 199728</p>
<p>Budgeted stream-based active learning via adaptive submodular maximization. Kaito Fujii, Hisashi Kashima, Advances in Neural Information Processing Systems, NIPS 2016. 2016</p>
<p>Submodular Functions and Optimization. S Fujishige, 1991Elsevier ScienceISBN 9780080867878</p>
<p>Active learning in multilayer perceptrons. Kenji Fukumizu, Advances in Neural Information Processing Systems, NIPS 1996. 19968</p>
<p>Error estimation and learning data arrangement for neural networks. Kenji Fukumizu, Sumio Watanabe, IEEE International Conference on Neural Networks, ICNN 1994. 19942</p>
<p>Query by Committee made real. Ran Gilad-Bachrach, Amir Navot, Naftali Tishby, Advances in Neural Information Processing Systems, NIPS 2005. 2005</p>
<p>Recognizing the Maximum of a Sequence. P John, Frederick Gilbert, Mosteller, 10.1080/01621459.1966.10502008Journal of the American Statistical Association. 613131966</p>
<p>Adaptive submodularity: A new approach to active learning and stochastic optimization. Daniel Golovin, Andreas Krause, Conference on Learning Theory, COLT 2010. Omnipress2010</p>
<p>Adaptive submodularity: Theory and applications in active learning and stochastic optimization. Daniel Golovin, Andreas Krause, 10.1613/jair.3278Journal of Artificial Intelligence Research. 422011</p>
<p>Near-optimal Bayesian active learning with noisy observations. Andreas Daniel Golovin, Debajyoti Krause, Ray, Advances in Neural Information Processing Systems, NIPS 2010. 2010ISBN 9781617823800</p>
<p>Generative adversarial nets. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Advances in Neural Information Processing Systems, NIPS 2014. Curran Associates, Inc201427</p>
<p>Sample Efficient Active Learning of Causal Trees. Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric Boix-Adser, Guy Bresler, Advances in Neural Information Processing Systems. NeurIPS2019. 2019</p>
<p>Optimistic active learning using mutual information. Yuhong Guo, Russ Greiner, International Joint Conference on Artificial Intelligence, IJCAI 2007. 2007</p>
<p>Sequential methods for design-adaptive estimation of discontinuities in regression curves and surfaces. Peter Hall, Ilya Molchanov, 10.1214/aos/1056562467Annals of Statistics. 3132003</p>
<p>A bound on the label complexity of agnostic active learning. Steve Hanneke, 10.1145/1273496.1273541International Conference on Machine Learning. 2007227</p>
<p>Theory of disagreement-based active learning. Steve Hanneke, 10.1561/2200000037Foundations and Trends in Machine Learning. 20147</p>
<p>Two optimal strategies for active learning of causal models from interventional data. Alain Hauser, Peter Bhlmann, 10.1016/j.ijar.2013.11.007International Journal of Approximate Reasoning. 5542014</p>
<p>Deep active learning with adaptive acquisition. Manuel Haumann, Fred Hamprecht, Melih Kandemir, 10.24963/ijcai.2019/343International Joint Conference on Artificial Intelligence, IJCAI 2019. 2019ISBN 9780999241141</p>
<p>Active learning of causal networks with intervention experiments and optimal designs. Yang , Bo He, Zhi Geng, Journal of Machine Learning Research. 1532443592008</p>
<p>Batch mode active learning and its application to medical image classification. C H Steven, Rong Hoi, Jianke Jin, Zhu, Michael R Lyu, 10.1145/1143844.1143897Proceedings of the International Conference on Machine Learning. the International Conference on Machine Learning2006148</p>
<p>Some Improvements in Weighing and Other Experimental Techniques. Harold Hotelling, Annals of Mathematical Statistics. 0091-17981531944</p>
<p>Bayesian Active Learning for Classification and Preference Learning. Neil Houlsby, Ferenc Huszr, Zoubin Ghahramani, Mt Lengyel, 2011</p>
<p>Active learning by learning. Wei Ning, Hsu , Hsuan Tien, Lin , AAAI Conference on Artificial Intelligence, AAAI 2015. 20154</p>
<p>Active Learning by Querying Informative and Representative Examples. Jun Sheng, Rong Huang, Zhi Hua Jin, Zhou, 10.1109/TPAMI.2014.2307881IEEE Transactions on Pattern Analysis and Machine Intelligence. 36102014</p>
<p>Stopping criterion for active learning based on deterministic generalization bounds. Hideaki Ishibashi, Hideitsu Hino, International Conference on Artificial Intelligence and Statistics. 20202020</p>
<p>Sequential Analysis: A Survey. N L Johnson, 10.2307/2343243Journal of the Royal Statistical Society. Series A (General). 12433721961</p>
<p>Active Learning in the Non-realizable Case. Matti Kriinen, International Conference on Algorithmic Learning Theory, ALT 2010. 2010</p>
<p>MaxiMin Active Learning in Overparameterized Model Classes. Mina Karzand, Robert D Nowak, 10.1109/jsait.2020.2991518IEEE Journal on Selected Areas in Information Theory. 112020</p>
<p>Auto-Encoding Variational Bayes. P Diederik, Max Kingma, Welling, ICLR 2014International Conference on Learning Representations. 2014</p>
<p>Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning. Andreas Kirsch, Joost Van Amersfoort, Yarin Gal, Advances in Neural Information Processing Systems. NeurIPS2019. 2019</p>
<p>Learning active learning from data. -Lear Ksenia Konyushkova, Sznitman Raphael, Pascal Fua, Advances in Neural Information Processing Systems. Decem2017. 20172017batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active</p>
<p>Nonmyopic active learning of Gaussian processes: An exploration-exploitation approach. Andreas Krause, Carlos Guestrin, 10.1145/1273496.1273553International Conference on Machine Learning. 2007227</p>
<p>Neural Network Ensembles, Cross Validation, and Active Learning. Anders Krogh, Jesper Vedelsby, doi: 10.1.1.37.8876Advances in Neural Information Processing Systems, NIPS 1995. 1995</p>
<p>Self-paced learning for latent variable models. Benjamin M Pawan Kumar, Daphne Packer, Koller, Advances in Neural Information Processing Systems, NIPS 2010. 2010ISBN 9781617823800</p>
<p>Stopping criteria for active learning of named entity recognition. Florian Laws, Hinrich Schtze, 10.3115/1599081.1599140International Conference on Computational Linguistics. Manchester2008. 20081ISBN 9781905593446</p>
<p>Gradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 86111998</p>
<p>Heterogeneous Uncertainty Sampling for Supervised Learning. David D Lewis, Jason Catlett, 10.1016/b978-1-55860-335-6.50026-xInternational Conference on Machine Learning, ICML 1994. 1994</p>
<p>A sequential algorithm for training text classifiers. D David, William A Lewis, Gale, 10.1145/219587.219592International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 1994. Springer-Verlag1994ISBN 038719889X</p>
<p>On a Measure of the Information Provided by an Experiment. Dennis Lindley, Annals of Mathematical Statistics. 2741956</p>
<p>Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design. Turab Lookman, Dezhen Prasanna V Balachandran, Ruihao Xue, Yuan, 10.1038/s41524-019-0153-8npj Computational Materials. 512019</p>
<p>Stopping criteria for boosting automatic experimental design using real-time fMRI with Bayesian optimization. Romy Lorenz, Ricardo P Monti, Ines R Violante, Aldo A Faisal, Christoforos Anagnostopoulos, Robert Leech, Giovanni Montana, 5th NIPS Workshop on Machine Learning and Interpretation in Neuroimaging: Beyond the Scanner. 2015</p>
<p>Practical Obstacles to Deploying Active Learning. David Lowell, Zachary C Lipton, Byron C Wallace, 10.18653/v1/d19-1003Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing, EMNLP/IJCNLP 2019. 2019</p>
<p>Bayesian Methods for Adaptive Models. David John, Cameron Mackay, PhD thesis, USA, 1992. UMI Order No. GAX92-32200</p>
<p>An interactive approach for Bayesian network learning using domain/expert knowledge. R Andrs, Serafn Masegosa, Moral, 10.1016/j.ijar.2013.03.009International Journal of Approximate Reasoning. 5482013</p>
<p>Some pac-bayesian theorems. David A Mcallester, 10.1023/A:1007618624809Machine Learnerning. 3731999</p>
<p>Human-level control through deep reinforcement learning. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, Demis Hassabis, 10.1038/nature14236Nature. 51875402015</p>
<p>Gradient Descent in RKHS with Importance Labeling. Tomoya Murata, Taiji Suzuki, 2020Technical report</p>
<p>An analysis of approximations for maximizing submodular set functions-I. Mathematical Programming. George L Nemhauser, Laurence A Wolsey, Marshall L Fisher, 197814</p>
<p>Active learning using pre-clustering. T Hieu, Arnold Nguyen, Smeulders, 10.1145/1015330.1015349International Conference on Machine Learning, ICML 2004. 2004</p>
<p>Active learning for probabilistic hypotheses using the maximum Gibbs error criterion. Cuong Viet, Wee Nguyen, Nan Sun Lee, Ye, Ming A Kian, Hai Leong Chai, Chieu, Advances in Neural Information Processing Systems, NIPS 2013. 2013</p>
<p>Generalized binary search. Robert Nowak, 10.1109/ALLERTON.2008.479760946th Annual Allerton Conference on Communication, Control, and Computing. 2008ISBN 9781424429264</p>
<p>Noisy generalized binary search. Robert Nowak, Advances in Neural Information Processing Systems, NIPS 2009. 2009ISBN 9781615679119</p>
<p>Early Stopping -But When?. Lutz Prechelt, 10.1007/978-3-642-35289-82012SpringerBerlin Heidelberg; Berlin, Heidelberg</p>
<p>. URL10.1007/978-3-642-35289-8_5</p>
<p>Active learning: an empirical study of common baselines. Maria E Ramirez-Loaiza, Manali Sharma, Geet Kumar, Mustafa Bilgic, 10.1007/s10618-016-0469-7Data Mining and Knowledge Discovery. 3122017</p>
<p>Early Stopping and Nonparametric Regression: An Optimal Data-dependent Stopping Rule. Garvesh Raskutti, Martin J Wainwright, Bin Yu, 2014Technical report</p>
<p>Meta-learning for batch mode active learning. Sachin Ravi, Hugo Larochelle, International Conference on Learning Representations. 2018. 2018</p>
<p>Learning with incremental iterative regularization. Lorenzo Rosasco, Silvia Villa, Advances in Neural Information Processing Systems, NIPS 2015. 2015</p>
<p>Less is More: Active Learning with Support Vector Machines. Greg Schohn, David Cohn, International Conference on Machine Learning, ICML2000. 2000</p>
<p>Active learning for convolutional neural networks: A core-set approach. Ozan Sener, Silvio Savarese, International Conference on Learning Representations. 2018. 2018</p>
<p>Active Learning Literature Survey. Burr Settles, Machine Learning. 201015</p>
<p>An analysis of active learning strategies for sequence labeling tasks. Burr Settles, Mark Craven, 10.3115/1613715.1613855Conference on Empirical Methods in Natural Language Processing. 2008. 2008</p>
<p>Query by committee. M H S Seung, Opper, Sompolinsky, 10.1145/130385.130417Annual ACM Workshop on Computational Learning Theory, COLT 1992. 1992ISBN 089791497X</p>
<p>Learning causal graphs with small interventions. Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, Sriram Vishwanath, Advances in Neural Information Processing Systems, NIPS 2015. 2015</p>
<p>Variational adversarial active learning. Samrath Sinha, Sayna Ebrahimi, Trevor Darrell, 10.1109/ICCV.2019.00607IEEE International Conference on Computer Vision, ICCV 2019. 2019ISBN 9781728148038</p>
<p>Active learning for decision-making from imbalanced observational data. Iiris Sundin, Peter Schulam, Eero Siivola, Aki Vehtari, Suchi Saria, Samuel Kaski, International Conference on Machine Learning, ICML 2019. 2019ISBN 9781510886988</p>
<p>Active Learning for Function Approximation. Kay Sung, , , Partha Niyogi, Advances in Neural Information Processing Systems, NIPS 1994. 19947</p>
<p>Efficient construction method for phase diagrams using uncertainty sampling. Kei Terayama, Ryo Tamura, Yoshitaro Nose, Hidenori Hiramatsu, Hideo Hosono, Yasushi Okuno, Koji Tsuda, 10.1103/PhysRevMaterials.3.033802Physical Review Materials. 33338022019</p>
<p>Role of uncertainty estimation in accelerating materials development via active learning. Ruihao Yuan Tian, Dezhen Yuan, Yumei Xue, Xiangdong Zhou, Jun Ding, Turab Sun, Lookman, 10.1063/5.0012405Journal of Applied Physics. 0021- 89791281141032020</p>
<p>Support vector machine active learning with applications to text classification. Support vector machine active learning with applications to text classification. Simon Tong, Daphne Koller, Simon Tong, Daphne Koller, 10.1162/153244302760185243International Joint Conference on Artificial Intelligence, IJCAI. 2001. 2001. 20022Active learning for structure in Bayesian networks</p>
<p>Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modeling. npj Computational Materials, 4(1). Tetsuro Ueno, Hideitsu Hino, Ai Hashimoto, Yasuo Takeichi, Yasuhiro Sawada, Kanta Ono, 10.1038/s41524-017-0057-42018</p>
<p>A stopping criterion for active learning. Andreas Vlachos, 10.1016/j.csl.2007.12.001Computer Speech and Language. 2232008</p>
<p>Querying discriminative and representative samples for batch mode active learning. Zheng Wang, Jieping Ye, 10.1145/2700408ACM Transactions on Knowledge Discovery from Data. 93172015</p>
<p>RAL -Improving streambased active learning by reinforcement learning. Sarah Wassermann, Thibaut Cuvelier, Pedro Casas, European Conference on Machine Learning and Principles and Practiceof Knowledge Discovery in Database, Workshop on Iterative Adaptive Learning. 20192444</p>
<p>Active One-shot Learning. Mark Woodward, Chelsea Finn, 2017Technical report</p>
<p>Representative sampling for text classification using support vector machines. Zhao Xu, Kai Yu, Xiaowei Volker Tresp, Jizhi Xu, Wang, 10.1007/3-540-36618-028European Conference on Information Retrieval Research. 26332003</p>
<p>Active Learning with Logged Data. Songbai Yan, Kamalika Chaudhuri, Tara Javidi, 2018Technical report</p>
<p>The Label Complexity of Active Learning from Observational Data. Songbai Yan, Kamalika Chaudhuri, Tara Javidi, Advances in Neural Information Processing Systems. NeurIPS2019. 2019</p>
<p>Multi-Class Active Learning by Uncertainty Sampling with Diversity Maximization. Yi Yang, Zhigang Ma, Feiping Nie, Xiaojun Chang, Alexander G Hauptmann, 10.1007/s11263-014-0781-xInternational Journal of Computer Vision. 11322015</p>
<p>On early stopping in gradient descent learning. Yuan Yao, Lorenzo Rosasco, Andrea Caponnetto, 10.1007/s00365-006-0663-2Constructive Approximation. 2622007</p>
<p>Multi-criteria-based strategy to stop active learning for data annotation. Jingbo Zhu, Huizhen Wang, Eduard Hovy, 10.3115/1599081.1599223International Conference on Computational Linguistics. 2008. 20081ISBN 9781905593446</p>            </div>
        </div>

    </div>
</body>
</html>