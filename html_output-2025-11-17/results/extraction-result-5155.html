<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5155 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5155</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5155</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-258866103</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.14356v1.pdf" target="_blank">Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</a></p>
                <p><strong>Paper Abstract:</strong> There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5155.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5155.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented by a central prototype (an idealized set of characteristic features); categorization and inference depend on similarity to that prototype rather than stored discrete instances.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional-level account in which each concept is represented by a prototypical combination of characteristic features or dimensions; members of a category vary in degree of match to that prototype and conceptual behavior arises from similarity-based operations on feature vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>feature-based / prototype (central tendency) representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>central tendency representation; graded membership; similarity-based classification; compact summary of category features; supports abstraction and induction from prototype features.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Literature review (Murphy 2016) reports phenomena better explained by prototype accounts such as hierarchical conceptual structure, knowledge effects on categorization, and induction; behavioral findings often show typicality gradients consistent with prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Prototype models sometimes fail to account for exemplar effects in categorization and specific-instance influences; Murphy notes exemplar explanations are strong for some tasks and that prototype models are not universally sufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>categorization, concept learning, induction, semantic memory and prototype-based reasoning tasks discussed in the reviewed literature.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted explicitly with exemplar models in Murphy (2016): prototype models explain hierarchical and knowledge-driven effects better, while exemplar models better explain some instance-driven categorization phenomena; the paper argues prototype accounts align with Hofstadter-style feature-manipulation metaphors.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Concept formation via extraction or storage of characteristic features into a prototypical vector; retrieval and classification by computing similarity between a stimulus and the prototype; concept variation achieved by adjusting feature values ('control knobs').</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Does not fully account for all exemplar-driven behaviors; how prototypes are learned, updated, and contextually modulated remains underspecified; links to underlying neural mechanisms are indirect in the reviewed work.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5155.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as memory of individual encountered instances (exemplars), and categorization proceeds by comparing stimuli to stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional account where conceptual knowledge consists of stored exemplars (individual instances); new items are classified by similarity-weighted retrieval of these exemplars rather than by comparison to a summary prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>instance-based / exemplar (memory trace collection)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>memory of multiple instances; similarity-weighted retrieval; explains effects of specific remembered examples; flexible to capture variability in categories.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Strong empirical support in categorization and category-learning tasks where salient exemplars influence decisions; behavioral findings show exemplar effects in some learning paradigms.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Murphy (2016) argues exemplar models lack evidence for explaining concepts broadly (beyond category learning), failing to account for hierarchical structure, knowledge effects, and induction that prototype/theory-based accounts explain.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>category learning and categorization tasks, memory-influenced classification phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Positioned against prototype theory: strengths in modeling instance-driven categorization but weaker in explaining abstract conceptual reasoning and structure; paper concludes exemplar models may not constitute a general theory of concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Retrieval of stored exemplars via similarity measures; aggregation of exemplar matches to make classification or inference decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Scaling to rich conceptual reasoning and abstract knowledge is unclear; how exemplar storage and selection operate in rich, knowledge-laden conceptual tasks remains an open question.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5155.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mental models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mental models (Vosniadou)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>People form internally manipulable models of phenomena that are used for reasoning; these models are revised and tweaked with new information and imagination to produce novel explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mental Models in Conceptual Development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Mental models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional account that conceptual knowledge is organized as coherent, structured mental simulations or models that can be manipulated in imagination to answer counterfactual/generative questions and integrate explicit knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>structured model-based (simulation-like internal models)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>compositional, manipulable, supports simulation and counterfactual reasoning, integrates explicit knowledge, context-sensitive and revisable over time.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Developmental and interview studies (Vosniadou, 2002) with children and adults using drawings and generative questioning show people constructing, manipulating and revising internal models (e.g., models of the Earth) to solve problems and explain phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Findings also show that revisions can lead to persistent misconceptions; mental models are inferred indirectly from behavior and verbal reports, leaving internal format underdetermined.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>conceptual development, scientific reasoning, education, explanation generation, counterfactual reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Differs from pure feature/prototype or exemplar views by positing richer, structured, simulation-capable representations; compatible with prototype-like feature structure in some respects but emphasizes dynamics and manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Construction of an internal model from experience and explicit knowledge; manipulation of that model under imagined scenarios to derive predictions and explanations; revision when faced with inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Internal representational format and neural substrate are indirect; how mental models compose, how they map to simpler feature representations, and individual differences in model complexity remain open.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5155.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Implicospheres</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Implicospheres (Hofstadter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Philosophical/metaphorical proposal that concepts are vague 'clouds' of possible variations with many context-dependent 'control knobs', and creative ideas arise from intersections (slipping/blending) of these clouds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>METAMAGICAL THEMAS.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Implicosphere / concept-cloud model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>A functional metaphor positing that concepts are fuzzy, high-dimensional possibility spaces (clouds) of variants parameterized by many latent 'knobs'; context alters which parameters are salient, and intersecting clouds produce novel blended concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>continuous, high-dimensional, context-sensitive cloud/possibility-space representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>vagueness, high-dimensionality, context-dependent parameter salience (control knobs), compositional intersection (blending), supports large space of variations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Philosophical argumentation and thought experiments (Hofstadter, 1982) motivate the model; later work (de Mello & de Carvalho) and computational co-creative systems borrow the metaphor to design manipulable concept spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Hofstadter's original proposal lacked direct empirical tests; the implicosphere is largely metaphorical and underspecified for experimental validation without formalization.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>inspirational basis for formal models of creative exploration, computational co-creativity interfaces, and mathematical projections of concept spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More continuous and high-dimensional than prototype/exemplar models; emphasizes dynamic context-dependent parameterization unlike static prototype summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Concept variation through adjusting latent parameters ('knobs'); creativity via intersection/blending of multiple implicosphere clouds producing new points in possibility space.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Vague/metaphorical without precise operationalization; requires formal mapping to measurable representations to be testable and to link to neural data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5155.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge Geometry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Geometry (de Mello & de Carvalho)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formal, spatial knowledge representation that projects Hofstadter-style implicospheres onto three planes (real, conceptual, symbolic) with a cultural filter to model person-dependent conceptual variations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge Geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Knowledge Geometry (three-plane implicosphere projection)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Mathematical formalization mapping concepts into spatial planes—real (observables), conceptual (feature/meaning space), and symbolic (language/symbols)—with a cultural/person-dependent filter mediating transfers, enabling geometric operations to model reification, interpretation and deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>spatial / geometric multi-plane representation with context (filter)-dependent mappings</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>explicit geometry, multi-plane mapping (real/conceptual/symbolic), person-dependent cultural filter, supports reification and operations like projection and intersection.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>De Mello & de Carvalho (2015) demonstrate how the framework can model cognitive phenomena such as intuition, formalization, and interpretation; aligns conceptually with prototype/mental-model findings described in reviewed literature.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Primarily a formal/modeling contribution; empirical validation in behavioral or neural data is limited in the reviewed paper.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>knowledge representation, cognitive modeling of concept reification, computational systems needing mappings between observables, conceptual spaces, and symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides a formal geometric bridge between Hofstadter's implicospheres and prototype/feature accounts, offering explicit mappings absent in metaphorical accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Conceptual transformations via geometric projections between planes and contextual filtering; concept combination via geometric intersection or transformation operations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Needs empirical tests relating geometric constructs to behavioral or neural measures; how to instantiate filters and dimensional axes for real cognitive domains remains open.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5155.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Emergent binding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Emergent binding in neural networks (Thagard & Stewart)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational model using distributed vector representations of neural activity and convolution-based binding to combine concept representations, producing emergent activity patterns associated with creative insight.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The AHA! Experience: Creativity through Emergent Binding in Neural Networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Emergent binding (distributed vector convolution) model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional model in which concepts are encoded as high-dimensional neural-activity vectors; combining concepts corresponds to convolution or binding operations on these vectors, producing novel emergent patterns that can correspond to new ideas and the emotional 'aha' signal.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed population-code / high-dimensional vector representations (neural activity patterns)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>distributed encoding across many units, compositional binding via convolution, stochasticity handled by dimensional expansion, emergence of novel patterns and associated affective signals.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Simulations (Thagard & Stewart, 2010) show that convolving simulated neural activity patterns can produce novel patterns that authors interpret as corresponding to creative discoveries and associated emotional responses; demonstrates plausibility of concept intersection producing 'aha' experiences.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Evidence is based on simulation rather than direct neural recording linking such convolution operations to actual brain activity during creativity; not every simulated combination is judged creative, and mapping to subjective criteria is indirect.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>modeling insight/creativity, explanation of affective 'aha' moments, computational cognitive modeling of concept combination.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Differs from symbolic/prototype/exemplar accounts by positing distributed population codes with explicit binding operations; offers a mechanistic account of how combination and emergence might occur at a functional population-code level.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Represent each concept as a multi-dimensional activity vector; combine concepts by convolution/multiplicative binding across vectors to create new activity patterns; emergent patterns that align with stored evaluative/affective circuits trigger insight feelings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Simulation-based support needs empirical neural validation; precise binding operations in biological networks and how they relate to psychological criteria of creativity are open questions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5155.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MI-CC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixed-initiative co-creativity (MI-CC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A paradigm where human and computer agents jointly and proactively collaborate in creative tasks, effectively extending the human's concept space via external representations and suggestions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mixed-initiative co- creativity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Mixed-initiative co-creativity</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Not a cognitive representational theory per se but a functional paradigm showing that external AI-held concept spaces and suggestion mechanisms can interact with human internal representations to explore concept variation spaces more effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>external extended concept spaces / interactive suggestion-based representations (engineered)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>externalization of concept spaces, interactive suggestions, affordance of control knobs and contextual reframing, promotes exploration of possibility spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Human-subject studies with tools like Sentient Sketchbook (Yannakakis et al., 2014) show MI-CC guides user creative paths and leads to greater exploration; engineered studies (Lin & Riedl, 2021; Lin et al., 2022) demonstrate user preference and increased creative exploration using controllable interfaces.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>These are engineered/observational demonstrations of utility rather than direct evidence about internal brain-format representations; success does not prove the brain uses the same representational format.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>interactive level design, story generation, creative augmentation tools, human-AI co-creative systems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Supports the functional plausibility of concept-space and control-knob metaphors (Hofstadter) by showing external analogues that facilitate creativity; does not compete directly with internal representational theories.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Augmentation of human cognition via external representations and AI suggestions; iterative suggestion-revision loop that expands exploration of conceptual possibility spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Doesn't directly reveal internal representational formats; degree to which external control-knob metaphors map onto internal cognitive representations remains to be shown.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5155.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5155.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Control-knob controllable generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Plug-and-blend controllable story generation (Lin & Riedl)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An engineered control-knob system that lets humans steer a language model's generation by providing sketches/sketch-like constraints, enabling blending and gradual variation of concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Control-knob (parametric steering) model for concept variation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional engineering approach that operationalizes Hofstadter's control-knob metaphor: concepts are manipulable by explicit parameters (sketches) that guide a generative model to blend topics and produce controlled creative outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>parametric / controllable feature-space steering of generative models (engineered)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>explicit control parameters, blendability of topics, iterative/stepwise steering of generation, measurable control fidelity and blending fluency.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Computational analysis and human-subject studies (Lin & Riedl, 2021) show preferred outputs and effective guidance when users provide sketches; demonstrates practicable control knobs for creative generation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>This is an engineered demonstration for artificial systems; it shows feasibility of control-knob metaphors but not that human brains instantiate identical parametric interfaces.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>controllable story generation, co-creative writing tools, interactive creative AI systems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides an operational analog to Hofstadter's metaphor and to prototype-style parametric variation; unlike psychological theories, it's an implemented system with measurable outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Human-provided sketches set parametric constraints which the generative model uses to bias sampling and guide blending between conceptual topics; iterative human-in-the-loop adjustments refine outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Mapping from engineered control knobs to human internal parameters is speculative; how these control parameters correspond to cognitive dimensions is unresolved.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>METAMAGICAL THEMAS. <em>(Rating: 2)</em></li>
                <li>Mental Models in Conceptual Development <em>(Rating: 2)</em></li>
                <li>Is There an Exemplar Theory of Concepts? <em>(Rating: 2)</em></li>
                <li>Knowledge Geometry. <em>(Rating: 2)</em></li>
                <li>The AHA! Experience: Creativity through Emergent Binding in Neural Networks. <em>(Rating: 2)</em></li>
                <li>Mixed-initiative co- creativity <em>(Rating: 2)</em></li>
                <li>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5155",
    "paper_id": "paper-258866103",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory of concepts",
            "brief_description": "Concepts are represented by a central prototype (an idealized set of characteristic features); categorization and inference depend on similarity to that prototype rather than stored discrete instances.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Functional-level account in which each concept is represented by a prototypical combination of characteristic features or dimensions; members of a category vary in degree of match to that prototype and conceptual behavior arises from similarity-based operations on feature vectors.",
            "representation_format_type": "feature-based / prototype (central tendency) representation",
            "key_properties": "central tendency representation; graded membership; similarity-based classification; compact summary of category features; supports abstraction and induction from prototype features.",
            "empirical_support": "Literature review (Murphy 2016) reports phenomena better explained by prototype accounts such as hierarchical conceptual structure, knowledge effects on categorization, and induction; behavioral findings often show typicality gradients consistent with prototypes.",
            "empirical_challenges": "Prototype models sometimes fail to account for exemplar effects in categorization and specific-instance influences; Murphy notes exemplar explanations are strong for some tasks and that prototype models are not universally sufficient.",
            "applied_domains_or_tasks": "categorization, concept learning, induction, semantic memory and prototype-based reasoning tasks discussed in the reviewed literature.",
            "comparison_to_other_models": "Contrasted explicitly with exemplar models in Murphy (2016): prototype models explain hierarchical and knowledge-driven effects better, while exemplar models better explain some instance-driven categorization phenomena; the paper argues prototype accounts align with Hofstadter-style feature-manipulation metaphors.",
            "functional_mechanisms": "Concept formation via extraction or storage of characteristic features into a prototypical vector; retrieval and classification by computing similarity between a stimulus and the prototype; concept variation achieved by adjusting feature values ('control knobs').",
            "limitations_or_open_questions": "Does not fully account for all exemplar-driven behaviors; how prototypes are learned, updated, and contextually modulated remains underspecified; links to underlying neural mechanisms are indirect in the reviewed work.",
            "uuid": "e5155.0"
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory of concepts",
            "brief_description": "Concepts are represented as memory of individual encountered instances (exemplars), and categorization proceeds by comparing stimuli to stored exemplars.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar theory",
            "theory_or_model_description": "Functional account where conceptual knowledge consists of stored exemplars (individual instances); new items are classified by similarity-weighted retrieval of these exemplars rather than by comparison to a summary prototype.",
            "representation_format_type": "instance-based / exemplar (memory trace collection)",
            "key_properties": "memory of multiple instances; similarity-weighted retrieval; explains effects of specific remembered examples; flexible to capture variability in categories.",
            "empirical_support": "Strong empirical support in categorization and category-learning tasks where salient exemplars influence decisions; behavioral findings show exemplar effects in some learning paradigms.",
            "empirical_challenges": "Murphy (2016) argues exemplar models lack evidence for explaining concepts broadly (beyond category learning), failing to account for hierarchical structure, knowledge effects, and induction that prototype/theory-based accounts explain.",
            "applied_domains_or_tasks": "category learning and categorization tasks, memory-influenced classification phenomena.",
            "comparison_to_other_models": "Positioned against prototype theory: strengths in modeling instance-driven categorization but weaker in explaining abstract conceptual reasoning and structure; paper concludes exemplar models may not constitute a general theory of concepts.",
            "functional_mechanisms": "Retrieval of stored exemplars via similarity measures; aggregation of exemplar matches to make classification or inference decisions.",
            "limitations_or_open_questions": "Scaling to rich conceptual reasoning and abstract knowledge is unclear; how exemplar storage and selection operate in rich, knowledge-laden conceptual tasks remains an open question.",
            "uuid": "e5155.1"
        },
        {
            "name_short": "Mental models",
            "name_full": "Mental models (Vosniadou)",
            "brief_description": "People form internally manipulable models of phenomena that are used for reasoning; these models are revised and tweaked with new information and imagination to produce novel explanations.",
            "citation_title": "Mental Models in Conceptual Development",
            "mention_or_use": "mention",
            "theory_or_model_name": "Mental models",
            "theory_or_model_description": "Functional account that conceptual knowledge is organized as coherent, structured mental simulations or models that can be manipulated in imagination to answer counterfactual/generative questions and integrate explicit knowledge.",
            "representation_format_type": "structured model-based (simulation-like internal models)",
            "key_properties": "compositional, manipulable, supports simulation and counterfactual reasoning, integrates explicit knowledge, context-sensitive and revisable over time.",
            "empirical_support": "Developmental and interview studies (Vosniadou, 2002) with children and adults using drawings and generative questioning show people constructing, manipulating and revising internal models (e.g., models of the Earth) to solve problems and explain phenomena.",
            "empirical_challenges": "Findings also show that revisions can lead to persistent misconceptions; mental models are inferred indirectly from behavior and verbal reports, leaving internal format underdetermined.",
            "applied_domains_or_tasks": "conceptual development, scientific reasoning, education, explanation generation, counterfactual reasoning.",
            "comparison_to_other_models": "Differs from pure feature/prototype or exemplar views by positing richer, structured, simulation-capable representations; compatible with prototype-like feature structure in some respects but emphasizes dynamics and manipulation.",
            "functional_mechanisms": "Construction of an internal model from experience and explicit knowledge; manipulation of that model under imagined scenarios to derive predictions and explanations; revision when faced with inconsistencies.",
            "limitations_or_open_questions": "Internal representational format and neural substrate are indirect; how mental models compose, how they map to simpler feature representations, and individual differences in model complexity remain open.",
            "uuid": "e5155.2"
        },
        {
            "name_short": "Implicospheres",
            "name_full": "Implicospheres (Hofstadter)",
            "brief_description": "Philosophical/metaphorical proposal that concepts are vague 'clouds' of possible variations with many context-dependent 'control knobs', and creative ideas arise from intersections (slipping/blending) of these clouds.",
            "citation_title": "METAMAGICAL THEMAS.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Implicosphere / concept-cloud model",
            "theory_or_model_description": "A functional metaphor positing that concepts are fuzzy, high-dimensional possibility spaces (clouds) of variants parameterized by many latent 'knobs'; context alters which parameters are salient, and intersecting clouds produce novel blended concepts.",
            "representation_format_type": "continuous, high-dimensional, context-sensitive cloud/possibility-space representation",
            "key_properties": "vagueness, high-dimensionality, context-dependent parameter salience (control knobs), compositional intersection (blending), supports large space of variations.",
            "empirical_support": "Philosophical argumentation and thought experiments (Hofstadter, 1982) motivate the model; later work (de Mello & de Carvalho) and computational co-creative systems borrow the metaphor to design manipulable concept spaces.",
            "empirical_challenges": "Hofstadter's original proposal lacked direct empirical tests; the implicosphere is largely metaphorical and underspecified for experimental validation without formalization.",
            "applied_domains_or_tasks": "inspirational basis for formal models of creative exploration, computational co-creativity interfaces, and mathematical projections of concept spaces.",
            "comparison_to_other_models": "More continuous and high-dimensional than prototype/exemplar models; emphasizes dynamic context-dependent parameterization unlike static prototype summaries.",
            "functional_mechanisms": "Concept variation through adjusting latent parameters ('knobs'); creativity via intersection/blending of multiple implicosphere clouds producing new points in possibility space.",
            "limitations_or_open_questions": "Vague/metaphorical without precise operationalization; requires formal mapping to measurable representations to be testable and to link to neural data.",
            "uuid": "e5155.3"
        },
        {
            "name_short": "Knowledge Geometry",
            "name_full": "Knowledge Geometry (de Mello & de Carvalho)",
            "brief_description": "A formal, spatial knowledge representation that projects Hofstadter-style implicospheres onto three planes (real, conceptual, symbolic) with a cultural filter to model person-dependent conceptual variations.",
            "citation_title": "Knowledge Geometry.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Knowledge Geometry (three-plane implicosphere projection)",
            "theory_or_model_description": "Mathematical formalization mapping concepts into spatial planes—real (observables), conceptual (feature/meaning space), and symbolic (language/symbols)—with a cultural/person-dependent filter mediating transfers, enabling geometric operations to model reification, interpretation and deduction.",
            "representation_format_type": "spatial / geometric multi-plane representation with context (filter)-dependent mappings",
            "key_properties": "explicit geometry, multi-plane mapping (real/conceptual/symbolic), person-dependent cultural filter, supports reification and operations like projection and intersection.",
            "empirical_support": "De Mello & de Carvalho (2015) demonstrate how the framework can model cognitive phenomena such as intuition, formalization, and interpretation; aligns conceptually with prototype/mental-model findings described in reviewed literature.",
            "empirical_challenges": "Primarily a formal/modeling contribution; empirical validation in behavioral or neural data is limited in the reviewed paper.",
            "applied_domains_or_tasks": "knowledge representation, cognitive modeling of concept reification, computational systems needing mappings between observables, conceptual spaces, and symbols.",
            "comparison_to_other_models": "Provides a formal geometric bridge between Hofstadter's implicospheres and prototype/feature accounts, offering explicit mappings absent in metaphorical accounts.",
            "functional_mechanisms": "Conceptual transformations via geometric projections between planes and contextual filtering; concept combination via geometric intersection or transformation operations.",
            "limitations_or_open_questions": "Needs empirical tests relating geometric constructs to behavioral or neural measures; how to instantiate filters and dimensional axes for real cognitive domains remains open.",
            "uuid": "e5155.4"
        },
        {
            "name_short": "Emergent binding",
            "name_full": "Emergent binding in neural networks (Thagard & Stewart)",
            "brief_description": "A computational model using distributed vector representations of neural activity and convolution-based binding to combine concept representations, producing emergent activity patterns associated with creative insight.",
            "citation_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Emergent binding (distributed vector convolution) model",
            "theory_or_model_description": "Functional model in which concepts are encoded as high-dimensional neural-activity vectors; combining concepts corresponds to convolution or binding operations on these vectors, producing novel emergent patterns that can correspond to new ideas and the emotional 'aha' signal.",
            "representation_format_type": "distributed population-code / high-dimensional vector representations (neural activity patterns)",
            "key_properties": "distributed encoding across many units, compositional binding via convolution, stochasticity handled by dimensional expansion, emergence of novel patterns and associated affective signals.",
            "empirical_support": "Simulations (Thagard & Stewart, 2010) show that convolving simulated neural activity patterns can produce novel patterns that authors interpret as corresponding to creative discoveries and associated emotional responses; demonstrates plausibility of concept intersection producing 'aha' experiences.",
            "empirical_challenges": "Evidence is based on simulation rather than direct neural recording linking such convolution operations to actual brain activity during creativity; not every simulated combination is judged creative, and mapping to subjective criteria is indirect.",
            "applied_domains_or_tasks": "modeling insight/creativity, explanation of affective 'aha' moments, computational cognitive modeling of concept combination.",
            "comparison_to_other_models": "Differs from symbolic/prototype/exemplar accounts by positing distributed population codes with explicit binding operations; offers a mechanistic account of how combination and emergence might occur at a functional population-code level.",
            "functional_mechanisms": "Represent each concept as a multi-dimensional activity vector; combine concepts by convolution/multiplicative binding across vectors to create new activity patterns; emergent patterns that align with stored evaluative/affective circuits trigger insight feelings.",
            "limitations_or_open_questions": "Simulation-based support needs empirical neural validation; precise binding operations in biological networks and how they relate to psychological criteria of creativity are open questions.",
            "uuid": "e5155.5"
        },
        {
            "name_short": "MI-CC",
            "name_full": "Mixed-initiative co-creativity (MI-CC)",
            "brief_description": "A paradigm where human and computer agents jointly and proactively collaborate in creative tasks, effectively extending the human's concept space via external representations and suggestions.",
            "citation_title": "Mixed-initiative co- creativity",
            "mention_or_use": "mention",
            "theory_or_model_name": "Mixed-initiative co-creativity",
            "theory_or_model_description": "Not a cognitive representational theory per se but a functional paradigm showing that external AI-held concept spaces and suggestion mechanisms can interact with human internal representations to explore concept variation spaces more effectively.",
            "representation_format_type": "external extended concept spaces / interactive suggestion-based representations (engineered)",
            "key_properties": "externalization of concept spaces, interactive suggestions, affordance of control knobs and contextual reframing, promotes exploration of possibility spaces.",
            "empirical_support": "Human-subject studies with tools like Sentient Sketchbook (Yannakakis et al., 2014) show MI-CC guides user creative paths and leads to greater exploration; engineered studies (Lin & Riedl, 2021; Lin et al., 2022) demonstrate user preference and increased creative exploration using controllable interfaces.",
            "empirical_challenges": "These are engineered/observational demonstrations of utility rather than direct evidence about internal brain-format representations; success does not prove the brain uses the same representational format.",
            "applied_domains_or_tasks": "interactive level design, story generation, creative augmentation tools, human-AI co-creative systems.",
            "comparison_to_other_models": "Supports the functional plausibility of concept-space and control-knob metaphors (Hofstadter) by showing external analogues that facilitate creativity; does not compete directly with internal representational theories.",
            "functional_mechanisms": "Augmentation of human cognition via external representations and AI suggestions; iterative suggestion-revision loop that expands exploration of conceptual possibility spaces.",
            "limitations_or_open_questions": "Doesn't directly reveal internal representational formats; degree to which external control-knob metaphors map onto internal cognitive representations remains to be shown.",
            "uuid": "e5155.6"
        },
        {
            "name_short": "Control-knob controllable generation",
            "name_full": "Plug-and-blend controllable story generation (Lin & Riedl)",
            "brief_description": "An engineered control-knob system that lets humans steer a language model's generation by providing sketches/sketch-like constraints, enabling blending and gradual variation of concepts.",
            "citation_title": "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Control-knob (parametric steering) model for concept variation",
            "theory_or_model_description": "Functional engineering approach that operationalizes Hofstadter's control-knob metaphor: concepts are manipulable by explicit parameters (sketches) that guide a generative model to blend topics and produce controlled creative outputs.",
            "representation_format_type": "parametric / controllable feature-space steering of generative models (engineered)",
            "key_properties": "explicit control parameters, blendability of topics, iterative/stepwise steering of generation, measurable control fidelity and blending fluency.",
            "empirical_support": "Computational analysis and human-subject studies (Lin & Riedl, 2021) show preferred outputs and effective guidance when users provide sketches; demonstrates practicable control knobs for creative generation.",
            "empirical_challenges": "This is an engineered demonstration for artificial systems; it shows feasibility of control-knob metaphors but not that human brains instantiate identical parametric interfaces.",
            "applied_domains_or_tasks": "controllable story generation, co-creative writing tools, interactive creative AI systems.",
            "comparison_to_other_models": "Provides an operational analog to Hofstadter's metaphor and to prototype-style parametric variation; unlike psychological theories, it's an implemented system with measurable outputs.",
            "functional_mechanisms": "Human-provided sketches set parametric constraints which the generative model uses to bias sampling and guide blending between conceptual topics; iterative human-in-the-loop adjustments refine outputs.",
            "limitations_or_open_questions": "Mapping from engineered control knobs to human internal parameters is speculative; how these control parameters correspond to cognitive dimensions is unresolved.",
            "uuid": "e5155.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "METAMAGICAL THEMAS.",
            "rating": 2,
            "sanitized_title": "metamagical_themas"
        },
        {
            "paper_title": "Mental Models in Conceptual Development",
            "rating": 2,
            "sanitized_title": "mental_models_in_conceptual_development"
        },
        {
            "paper_title": "Is There an Exemplar Theory of Concepts?",
            "rating": 2,
            "sanitized_title": "is_there_an_exemplar_theory_of_concepts"
        },
        {
            "paper_title": "Knowledge Geometry.",
            "rating": 2,
            "sanitized_title": "knowledge_geometry"
        },
        {
            "paper_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks.",
            "rating": 2,
            "sanitized_title": "the_aha_experience_creativity_through_emergent_binding_in_neural_networks"
        },
        {
            "paper_title": "Mixed-initiative co- creativity",
            "rating": 2,
            "sanitized_title": "mixedinitiative_co_creativity"
        },
        {
            "paper_title": "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.",
            "rating": 2,
            "sanitized_title": "plugandblend_a_framework_for_plugandplay_controllable_story_generation_with_sketches"
        }
    ],
    "cost": 0.011858,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>Rohan Agarwal roaga@gatech.edu 
Georgia Institute of Technology</p>
<p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
<p>Introduction</p>
<p>Creativity is often said to be one of the hallmarks that make us human, and it is a trait that serves us every day, from art and music to innovative technology and problem-solving. However, it is not well understood how it works; how does the human brain be creative so effectively?</p>
<p>There are many philosophical ideas on how creativity should be modeled cognitively, but this paper examines the popular proposal that creativity results from variations on a theme. Rather than effortful creation, this model imagines existing concepts subconsciously colliding and overlapping into new, creative ones that give us the creativity we see. There is plenty of anecdotal and philosophical reasoning that supports this idea, as Hofstadter (1982) originally presented. It also serves as a valuable and unique way to think about creativity, originality, and innovation.</p>
<p>However, more formalization and empirical evidence are needed to accept it as a model of creative cognition. To do so, this paper first examines the components of this model and how it imagines mental concepts being represented and how they interact. Then, empirical studies, from both computational and psychological approaches, that examine this form of mental concept representation are reviewed. While these studies formalize concept representation, insight into concept collision is still needed. A study using simulated neural network activity is reviewed to provide evidence for this idea. The field of human-AI co-creativity is also explored as an example and potentially useful application of concept collision, and more generally, this model of creativity. It is crucial to understand how this philosophical perspective on creativity can function and benefit us in a more concrete way. Engineered co-creative applications shed light on the empirical effectiveness of this model and its translation to real-world creativity, not just its correctness with respect to human cognition. Hofstadter (1982) set out to answer the fundamental question of how humans can imagine ideas that do not already exist (i.e., to be creative and original), which are notably often sensible and valuable (like an invention, scientific theory, or a piece of a music). He claimed that creativity stems from variations on existing themes and concepts in the creator's mind. He then justified his claim through a series of thought experiments and anecdotes, which while convincing, underscore the need for scientific evidence to support this model of creativity. First, acknowledging that he lacked a scientific model for what a concept is, he imagined a concept as a box with control knobs used to vary different attributes of the concept. By imagining the consequences of that metaphor for musical compositions and n-dimensional Rubik's Cubes, he concluded that a concept has an infinite number of knobs which reveal themselves depending on the concepts in the mind of the person. He noted how one person can vary a theme to create an idea, but others can still take that idea and vary it infinitely further (Hofstadter, 1982).</p>
<p>Review</p>
<p>Philosophical Proposal</p>
<p>Hofstadter then proposed subconscious slipping and blending between concepts as the source of these variations, changing the mental context and revealing different sets of knobs to the mind. He modeled concepts as vague clouds representing the possible set of variations and slipping as the intersection of multiple clouds. It is also notable that he advocated for using computers to help humans explore these possibility spaces, which he termed "implicospheres" (Hofstadter, 1982). In summary, the model of creativity proposed here is that of subconscious possibility spaces around concepts, built through manipulatable, context-dependent parameters, that intersect to yield new variations and concepts. Hofstadter, however, provides no scientific basis for this representation of concepts or their blending, so formal studies are now presented. Vosniadou (2002) investigated mental models in concept development and reasoning in children, arguing they are a core part of human cognition. She first analyzed their construction by having children draw and answer generative questions about their model of the Earth. Through further generative questioning (e.g., where would you end up if you walked forever?), the children were manipulating their models with imaginary scenarios to answer the questions. It was found that explicit knowledge can integrate with the conceptual model to create novel explanations and further conceptual knowledge. In fact, this is done over time as new information creates new theories in the mind and lets mental models be tweaked and revised.</p>
<p>Scientific Basis for Variations on a Theme as Creativity</p>
<p>Vosniadou also presented other interviews with adults that highlight how when faced with inconsistencies in their mental model, people creatively revise their model to solve the problem (often leading to misconceptions). The existing mental model in mind determines how new information is interpreted and conceptualized (Vosniadou, 2002). These findings support the idea of iteratively tweaking and growing concepts, and the power of concepts in generating novel creative ideas, especially when trying to integrate new information.</p>
<p>However, this does not answer how mental models are represented in the brain. Two main theories of concepts are the prototype theory, where categories are defined based on sets of characteristic features, and the exemplar theory, where categories are defined by encountered instances of the category (Murphy, 2016). Murphy (2016) conducted a literature review on both theories and psychological findings surrounding concepts. While there is strong evidence for salient exemplars influencing categorization, he found lackluster evidence on recalling specific exemplars to decide categorization. Murphy (2016) highlights several phenomena that have prototype explanations but no exemplar explanation, such as hierarchical structure of concepts, knowledge effects, and induction. In fact, since exemplar models in the literature seemed to only apply to category learning, and not concepts (i.e., mental models that can be used for learning, communication, and reasoning, as Vosniadou (2002) demonstrated), he argued that there is no exemplar theory of concepts at all (Murphy, 2016). If the prototype theory, or representing concepts through their features, is more accurate to human cognition, then that aligns well with the proposal of variations on a theme. It implies that concepts really are built around a central set of attributes that, if adjusted, can yield new variations of a concept and even new concepts entirely.</p>
<p>Such a model can also be mathematically formalized. Based on the idea of the implicosphere (Hofstadter, 1982), researchers designed a spatial knowledge representation based on projecting the implicosphere onto three planes: the real, the conceptual, and the symbolic (de Mello and de Carvalho, 2015). A cultural filter, or person-dependent context as Hofstadter (1982) described it, was used to transfer real-world phenomena to the conceptual plane, creating different variations of concepts for different people. The authors also demonstrated how this three-plane model can be used to explain reification (imagining new ideas from abstracted concepts), intuition, formalization, interpretation, and deduction of concepts (de Mello and de Carvalho, 2015). This work formalizes the idea of variations on a theme and demonstrates its usefulness for modeling many creative and cognitive tasks, which include key abilities found to apply to mental models (Vosniadou, 2002) and the prototype theory of concepts (Murphy, 2016).</p>
<p>This formalization shows that this model of creativity can align effectively with empirical findings on the subject.</p>
<p>More than just concept representation, though, how concepts collide to cause creative output is important to this theory of creativity. While concept combination has been successfully shown with symbolic representations in the past, Thagard and Stewart (2010) demonstrated its more generalizable potential with neural activity-in particular, by using convolution to combine vectors represented neural activity patterns. Their neural representations, more than symbolic/verbal ones, facilitated the fluid creative thinking Hofstadter described (Thagard and Stewart, 2010). The authors first devised a multi-dimensional vector representation of neural activity by multiplying the number of neurons to handle their stochasticity. Then they successfully convolved multiple representations of simulated neural activity into new ones, including patterns that correspond to the heightened emotions upon a creative discovery (e.g., an "aha!" or "eureka!" moment). These simulations provided evidence for the intersection of multimodal concepts in the brain leading to original ideas and a sense of creative discovery. The authors also stated that not every combination will be considered "creative," as Hofstadter (1982) also pointed out for the collision of implicospheres. However, the ones accompanied by the emotional experience of discovery likely are what we consider creative (Thagard and Stewart, 2010). This study directly supports the proposal that the collision of concepts in the brain is the source of creativity, not only in the outputted ideas, but also in the sense in which humans emotionally experience it.</p>
<p>Co-Creativity as a Lens</p>
<p>While all these studies provide great insight into the plausibility of this model of creativity, it is also valuable to consider concrete examples of how it enables creativity. Yannakakis et. al. (2014) introduced the paradigm of mixed-initiative co-creativity (MI-CC):</p>
<p>when a human and a computer both proactively collaborate on a creative work, like a story or a video game level. Reframing parts of the possibility space and introducing random stimulus are found to foster the creative process and creative output. The user of a co-creative system often has a diagram or user interface that serves as an extension of their mind, and facilitates creative, lateral thinking (Yannakakis, 2014). Effectively, the AI agent's concept space and the user's concept space collide and interact on this diagram; later works even outline multiple dimensions for such interactions, as if in 3D space, and modularize the different parts of this extended mind (Lin et. al, 2022). Yannakakis et. al. (2014) argued that this interaction (usually suggestions and iterative co-creation) facilitates greater exploration of the possibility space, leading to more novel and valuable creative output. Using a human subject study with a co-creative level design tool called Sentient Sketchbook, analysis of usage of the tool led to the conclusion that MI-CC is useful to human users and strongly guides the creative paths they take (Yannakakis, 2014). While this study is not about creative within the human mind, it demonstrates that when the human mind is effectively extended onto an external diagram, introducing new context, suggesting new ideas and concepts, and exploring the possibility space or variations around a concept lead to superior creative process and output. It is an engineered example that shows that the variations on a theme model is in fact an effective and valuable source of creativity.</p>
<p>In addition, MI-CC takes great advantage of "control knobs" similar to Hofstadter's (1982) metaphor for varying the features on a concept. For example, Lin and Riedl (2021) introduced a control knob system for guiding the story generation of a large language model. By providing a "sketch," a human user can guide the topics of a generated story, sentence by sentence. Not only does this framework allow for control knobs, but also blending of topics and concepts in the generation. Blending fluency and control fidelity were found to be effective through computational analysis, and a human subject study confirmed preference for the generations from this system. The authors envisioned their system being used for co-creative applications, as it was in Lin et. al. (2022). The system is remarkably similar to Hofstadter's (1982) metaphor of control knobs on a black box and blending of concepts to generate creative output. The study proves the possibility and effectiveness of a system based on these proposals.</p>
<p>Discussion</p>
<p>Summary</p>
<p>Variations on a theme as the source of creativity is a common model of how human creativity works, but without empirical evidence, it remained an anecdotal and philosophical one.</p>
<p>This paper presented studies that do provide substantial support for this theory, as originally proposed by Hofstadter (1982). Research into how we form and use mental models (Vosniadou, 2002) showed how they can grow, be manipulated, and used to produce novel, creative ideas in response to new context. Further literature review lent support to the prototype theory of concepts (Murphy, 2016), meaning we form concepts around characteristic features which can vary, similar to Hofstadter's idea of implicospheres (Hofstadter, 1982). While Hofstadter's (1982) theory may seem vague and unscientific, implicospheres and changing context can be used as a basis for geometric knowledge representations that explain core creative processes (de Mello and de Carvalho, 2015).</p>
<p>With evidence for variable features forming concepts and leading to creativity, there is also evidence for the intersection of concepts and its benefits for creativity. Thagard and Stewart (2010) demonstrated that multiple neural activity patterns, representing concepts, can be fluidly interweaved into novel activity and lead to the emotional "aha!" moment we often get upon a creative discovery. The field of mixed-initiative co-creativity also lends great support to the creative usefulness of this idea. Yannakakis et. al. (2014) demonstrated that when humans and AI proactively collaborate on creative tasks, effectively extending the mind of the human and introducing new context, the possible variations are better explored, and creativity is fostered.</p>
<p>This paradigm also makes extensive use of control knobs and blending concepts like what Hofstadter (1982) proposed, as shown by Lin and Riedl's (2021) controllable story generation model. Overall, there is evidence in diverse areas of scientific literature for variations on a theme being the source of human creativity, and an effective method for achieving creativity in engineered applications, including creative AI.</p>
<p>Limitations and Future Research</p>
<p>While there is substantial support, the question of the nature of human creativity is not settled. All the literature reviewed has only been able to answer that question through indirect observation, because it is near impossible to parse the inner workings of the brain otherwise.</p>
<p>There is still no clear-cut answer to how creativity works, and other theories could also be supported with the same studies. Additionally, all the studies that involve creative output-whether learning how the Earth works, new (but illegible) neural patterns, or video game levels-are very small examples of creativity compared to the most grand and valuable examples of scientific discovery, artistry, or innovation. In case creative cognition changes depending on the quality or scale of creative output, future work should aim to produce more valuable creative works or capture insights from those who do (perhaps through a longitudinal study). Some people are also more creative personality-wise, more successfully creative, or have different creative processes and styles. Further investigation is also needed in identifying how cognition varies between people-can one theory apply to everyone and everything we consider creative?</p>
<p>Knowledge Geometry. Flávio De Mello, Roberto Lins De Luis, Carvalho, 10.1142/s0219649215500288Journal of Information &amp; Knowledge Management. 14041550028de Mello, Flávio Luis, and Roberto Lins de Carvalho. "Knowledge Geometry." Journal of Information &amp; Knowledge Management 14, no. 04 (2015): 1550028. https://doi.org/10.1142/s0219649215500288.</p>
<p>. Douglas R &quot; Hofstadter, Metamagical Themas, Scientific American. 2474Hofstadter, Douglas R. "METAMAGICAL THEMAS." Scientific American 247, no. 4 (1982): 20-31. http://www.jstor.org/stable/24966697.</p>
<p>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches. Zhiyu Lin, Mark O Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment17Lin, Zhiyu, and Mark O. Riedl. "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 17, no. 1, pp. 58-65. 2021.</p>
<p>Creative Wand: A System to Study Effects of Communications in Co-creative Settings. Zhiyu Lin, Rohan Agarwal, Mark Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment18Lin, Zhiyu, Rohan Agarwal, and Mark Riedl. "Creative Wand: A System to Study Effects of Communications in Co-creative Settings." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 18, no. 1, pp. 45-52. 2022.</p>
<p>Is There an Exemplar Theory of Concepts?. Gregory L Murphy, 10.3758/s13423-015-0834-3Psychonomic Bulletin &amp; Review. 234Murphy, Gregory L. "Is There an Exemplar Theory of Concepts?" Psychonomic Bulletin &amp; Review 23, no. 4 (2016): 1035-42. https://doi.org/10.3758/s13423-015-0834-3.</p>
<p>The AHA! Experience: Creativity through Emergent Binding in Neural Networks. Paul Thagard, Terrence C Stewart, 10.1111/j.1551-6709.2010.01142.xCognitive Science. 351Thagard, Paul, and Terrence C. Stewart. "The AHA! Experience: Creativity through Emergent Binding in Neural Networks." Cognitive Science 35, no. 1 (2010): 1-33. https://doi.org/10.1111/j.1551-6709.2010.01142.x.</p>
<p>Mental Models in Conceptual Development. Stella Vosniadou, 10.1007/978-1-4615-0605-8_20Model-Based ReasoningVosniadou, Stella. "Mental Models in Conceptual Development." Model-Based Reasoning, 2002, 353-68. https://doi.org/10.1007/978-1-4615-0605-8_20.</p>
<p>Mixed-initiative cocreativity. Georgios N Yannakakis, Antonios Liapis, Constantine Alexopoulos, Yannakakis, Georgios N., Antonios Liapis, and Constantine Alexopoulos. "Mixed-initiative co- creativity." (2014).</p>            </div>
        </div>

    </div>
</body>
</html>