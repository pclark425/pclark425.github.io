<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5160 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5160</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5160</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-18949530</p>
                <p><strong>Paper Title:</strong> Compositional Reasoning in Early Childhood</p>
                <p><strong>Paper Abstract:</strong> Compositional “language of thought” models have recently been proposed to account for a wide range of children’s conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5–4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5160.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5160.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented by prototypical central tendency exemplars or averaged feature vectors; membership is graded by similarity to the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as prototypical summaries (central tendencies) of category instances; category membership and inferential judgments are produced by measuring similarity between items and these prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype / feature-based (symbolic-less, summary vectors)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>graded membership, similarity-based judgments, compact summary of category structure, non-compositional by default (requires extra machinery for composition).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited classical empirical work showing family resemblance and graded category structure (Rosch et al.); used to explain many categorization phenomena where central members are preferred.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper notes prototype theories struggle to handle compositionality (combining concepts into structured complex concepts) without added mechanisms; references critiques (e.g. Fodor & Lepore) arguing prototypes can't straightforwardly yield productive, systematic composition.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, graded membership tasks, typicality effects, some concept combination studies.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with LOT/symbolic compositional approaches which naturally support compositionality and systematicity; prototypes are simpler but need ad-hoc extensions to capture rule-like combinatorial structure.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity computation between item features and stored prototypical feature vectors to produce graded category membership; no inherent operation for composing prototypes into structured complex expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to derive compositional complex concepts from prototype summaries; whether prototype representations can be augmented to support productively recombining concepts without symbolic machinery.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5160.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory / exemplar models of categorization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are functionally represented as sets of stored individual exemplars; categorization is performed by comparing novel items to stored exemplars and aggregating similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual representation consists of memory traces of individual exemplars; decisions result from similarity-weighted retrieval and aggregation over those exemplars rather than abstraction to a prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar-based / episodic-like (collection of instances)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>instance-rich representation, context-sensitive, accounts for variability and exceptions, but not inherently compositional.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as an influential approach to categorization (Medin & Schaffer; Smith & Medin); good fit to many categorization data where exemplar effects (specific memories) matter.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Like prototypes, exemplar models do not by themselves explain systematic compositional combination of conceptual operations; the paper contrasts exemplar and LOT approaches on compositionality grounds.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, similarity-based induction, memory-influenced classification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Compared to prototype and symbolic LOT models: exemplar models handle variability and exceptions but lack natural compositional combinators; LOT predicts systematic recombination from primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity retrieval to stored exemplars, similarity-weighted voting/aggregation to form category judgments; no explicit function-composition operator.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether exemplar stores can be organized or indexed to support productive composition without introducing symbolic/computational primitives.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5160.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LOT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language of Thought (LOT) / symbolic compositional model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where concepts are symbolic expressions built from primitive functions and composition rules, allowing systematic and productive combination of concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Language of Thought (LOT) / symbolic compositionality</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At the functional level, concepts are structured symbolic expressions (functions, predicates, logical forms) composed from a small set of primitives; complex thoughts arise by composing simpler functional operators (e.g., f2(f1(x)) or f2 ∘ f1).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / compositional / function-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>systematicity, productivity, compositionality, explicit manipulation of functions/operators, supports chunking of composed operations, amenable to rule-like inference.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Motivates the experiment: authors show 3.5–4.5 year-olds can represent individual functions (iconic screens) and predictively compose them on two-screen trials above chance, supporting LOT's basic assumption that learners can represent and compose functions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper reports limits inconsistent with a naïve, unconstrained LOT: children fail when both composed operations act on the same feature dimension (CH-Color then CH-Color), suggesting additional processing or memory constraints not captured by a bare LOT account; also does not settle whether children form explicit symbolic names for compositions or merely sequentially apply functions.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Concept learning, language semantics, logical reasoning, structured concept induction, the present non-linguistic composition task.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Explicitly compared to prototype, exemplar, and connectionist accounts; argued to naturally explain compositionality that other models struggle with, but challenged by empirical limits (same-dimension failures) and by the question whether connectionist systems can emulate compositionality without assuming it.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Representation of primitive functions that map inputs to outputs; rule-based composition operations (function application and composition) create complex concepts; chunking/compression may allow creating new composed functions (h = f2 ∘ f1) to be re-used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether children explicitly represent composed functions as single symbols (chunking) or merely apply operations sequentially; how memory/production constraints interact with symbolic composition; how LOT mechanisms map to learning algorithms/hypothesis selection (link to Bayesian/Learner models).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5160.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian LOT learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rational/Bayesian models within LOT frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models that formalize induction over symbolic compositional hypothesis spaces using probabilistic (Bayesian/rational) inference to select among composed programs or logical forms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Bayesian / rational LOT learning models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>These posit that learners have a prior over symbolic/programmatic hypothesis spaces (built from primitives) and use Bayesian inference to evaluate which compositions best explain observed data, trading off complexity and fit.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / probabilistic over programs</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>compositional hypothesis space, rational inductive inference, complexity-sensitive priors, ability to learn structured operators from sparse data.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as explanatory framework for prior modeling work (Goodman et al., Piantadosi et al.) that can account for a wide range of concept learning phenomena and predicts compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>The paper's experiment does not directly test Bayesian inference mechanisms; observed limitations (same-dimension failure) indicate additional cognitive constraints (memory, processing time) beyond ideal Bayesian learners.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Concept learning, grammar induction, causal and theory learning, semantic learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Straddles symbolic LOT and statistical learning: combines symbolic representational primitives with probabilistic inference, contrasted with pure connectionist accounts which lack explicit symbolic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Probabilistic search/selection over composed symbolic hypotheses (programs), with priors favoring simpler/shorter compositions and likelihoods determined by data fit.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to account for resource/bottleneck effects (e.g., same-dimension interference) within idealized Bayesian frameworks; how learners acquire the primitive functions themselves.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5160.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Connectionism/PDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / Parallel Distributed Processing (PDP) models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representations are distributed activation patterns across networks; learning occurs by adjusting connection weights so that patterns map to outputs, often lacking explicit symbol-like compositional operators.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Connectionist / parallel distributed processing models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is encoded as patterns of activation across distributed units; combination arises via learned mappings and interactions rather than explicit function composition; compositionality must be emergent from learned representations or network architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed / connectionist</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>graded representations, robustness to noise, learning via weight adaptation, emergent structure, potential difficulty in capturing explicit compositional systematicity without engineered mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as an alternative framework; historically successful in many cognitive tasks (e.g., pattern recognition, generalization) though canonical PDP lacks built-in symbolic composition.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Authors raise the question whether a connectionist system can learn separate functions that can flexibly compose without explicit training on compositions — suggesting this is nontrivial and perhaps requires presupposing compositional primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perception, pattern learning, certain language phenomena, associative tasks; debates remain about structured symbolic cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with LOT: connectionism emphasizes distributed representations and learned mappings, while LOT posits explicit symbolic primitives and composition rules; hybrid proposals exist but are not the focus here.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Distributed activation, learned transformations via weight adjustments, feedforward/ recurrent dynamics produce mappings from inputs to outputs; composition requires network architectures or training regimes that support combinatorial generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether connectionist architectures can naturally yield the kind of rapid, zero-shot composition seen in the experiment without built-in symbolic primitives; how to prevent implicit presupposition of compositionality when designing networks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5160.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constraint-combination alternative</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constraint-combination (non-compositional constraint) account</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An alternative functional account where each operation provides constraints on possible outcomes and learners combine constraints to infer results, without representing operations as composable functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Constraint-combination (non-compositional) model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Learners encode each screen/operation as a constraint on the set of possible object states; when two constraints are present they intersect or otherwise combine constraint sets to infer the outcome, rather than computing a composed function mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>constraint-based / set-of-possible-states representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>combination via constraint intersection or elimination, does not require representing functions as first-class entities, potentially less structured than symbolic composition.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper posits this as a plausible non-compositional account that might explain success by combining constraints rather than composing functions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Authors argue constraint-combination would struggle to naturally explain specific empirical patterns (e.g., below-chance performance in within-dimension CH/CH trials) and might still be interpretable as function composition in many cases; more detailed predictions would be needed to distinguish it empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Inference under partial observability, reasoning with constraints, some non-linguistic predictive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Presented as an alternative to LOT-style composition; less committed to symbol-like functions but must account for same empirical signatures that compositional models predict.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Represent possible output states compatible with each observed transformation; combine constraints (set intersection, elimination) to narrow outcomes; selection among outcomes based on additional heuristics or priors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to formalize constraint combination so it cannot be reinterpreted as composition; whether it can account for fine-grained error patterns (recency bias, same-dimension failures) observed in data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5160.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lambda / combinatory logic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lambda calculus and combinatory logic (formal function-composition systems)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal minimal computational systems built from function application and composition that can express arbitrary computation; used as theoretical motivation for function-based representational formats.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Lambda calculus / combinatory logic</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Formal systems in which functions are first-class objects and arbitrary computations are built by repeated function application and composition; function abstraction and composition are the core representational/computational primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>formal symbolic / function-based (programs)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>minimal primitives (function application/composition), supports Turing-complete computation, emphasizes functions-as-objects and higher-order composition.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Used in discussion to illustrate how minimal compositional primitives can yield arbitrary computation; not directly tested empirically in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Practical cognitive constraints (memory, processing speed) may limit direct mapping of these ideal systems to human cognition; empirical data (same-dimension failures) indicate resource limitations not captured by pure formal models.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Theoretical foundations for symbolic program induction, LOT-style models, formal semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides formal underpinning for LOT-style function-based representations; contrasts with distributed/connectionist representations that do not treat functions as primitive tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Function abstraction and composition, variable binding, higher-order functions; constructs programs that map inputs to outputs via nested applications.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to implement these formal mechanisms within human cognitive constraints and learning processes; whether children ever represent functions in full higher-order formalism or only approximate variants.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5160.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Empirical finding: child function composition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Preschoolers' ability to represent and compose functions (this study)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical result showing 3.5–4.5 year-old children can represent novel functions (visual transformations) and predictively compose two such functions above chance without explicit training on composition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Empirical finding: children represent functions and compose them (behavioral evidence)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At a functional level, children represent mapping operations (screens that transform object features) as functions that can be applied to object representations and can successively apply (compose) two such transformations to infer the unseen outcome of sequential operations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>function-based / compositional (behavioral evidence for symbolic-like function manipulation)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>ability to represent operations as mappings, sequential application (f2(f1(x))), above-chance zero-feedback composition, recency bias in errors, dimension-specific interference for rapid sequential updates.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Experiment: N=21 children (mean age ~50.9 months). Training on single-screen mappings, then test with two-screen trials without feedback. Overall two-screen accuracy >25% chance (intercept logit significantly above chance); specific two-change across-dimension conditions: CH-Color→CH-Pattern accuracy 50% (p=0.003), CH-Pattern→CH-Color 55% (p=0.002). Mixed-effects regression: SameDimension predictor strongly negative (β = −0.50, z = −4.23, p < 0.001). Error analysis: incorrect responses more likely to have second-screen transformation applied (β = 1.15, z = 4.946, p < 0.001).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Children performed at chance on trials where both operations changed the same feature dimension (CH-Color then CH-Color), and their overall accuracy was near 50%, showing limits: failures when rapid sequential updates act on same variable and sub-50% performance suggests possible destructive interference beyond simple forgetting.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Non-linguistic conceptual composition tasks, causal/transformational prediction tasks, early concept learning, studies of compositional reasoning in development.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Findings support LOT-like assumptions that functions can be represented and composed, while posing challenges to models that cannot produce zero-shot composition (pure exemplar/prototype) or that cannot account for dimension-specific interference; authors also note constraint-based and connectionist alternatives need to specify how composition emerges without direct training on compositions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Behaviorally, children appear to (a) encode each screen as an operation mapping input features to outputs, (b) apply the second operation and often the first in sequence to predict final state (f2(f1(x))), and (c) show recency/overwrite effects suggesting limited maintenance of earlier transformation or interference when both operations target same feature.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether children form explicit chunked symbols for composed functions (h = f2 ∘ f1) versus only sequentially updating representations; the origin of same-dimension failure (memory overwrite, race conditions, attentional constraints); generality to more complex feature sets, older/younger ages, and whether connectionist models can reproduce these results without presupposing compositional primitives.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5160.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5160.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boolean / Feldman</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Boolean/compositional models and minimization of Boolean complexity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Accounts that conceptual representations are Boolean combinations of primitives and that humans favor simpler (lower Boolean complexity) conceptual formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Boolean / compositional minimization models (Feldman)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented as Boolean formulas composed from primitives (and/or/not); learning and representation favor minimal Boolean expressions that explain data.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / Boolean compositional</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>compositional logical structure, complexity-sensitive preference (simpler Boolean formulas preferred), explains patterns in concept learning.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited empirical modeling work (Feldman) showing human concept learning aligns with minimization of Boolean complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper does not directly test Boolean minimization; some developmental limits observed (same-dimension interference) point to process constraints orthogonal to representational complexity preferences.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Boolean concept learning, rule-based categorization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Similar to LOT in compositional symbolic structure but emphasizes complexity minimization; differs from prototype/exemplar accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Construct Boolean expressions from primitives and apply simplicity prior when inferring concepts from data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How process constraints (memory, time) interact with preference for simpler symbolic formulas in developmental populations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The language of thought <em>(Rating: 2)</em></li>
                <li>Minimization of Boolean complexity in human concept learning <em>(Rating: 2)</em></li>
                <li>A Rational Analysis of Rule-Based Concept Learning <em>(Rating: 2)</em></li>
                <li>Bootstrapping in a language of thought: a formal model of numerical concept learning <em>(Rating: 2)</em></li>
                <li>Parallel distributed processing <em>(Rating: 2)</em></li>
                <li>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings <em>(Rating: 1)</em></li>
                <li>To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5160",
    "paper_id": "paper-18949530",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory of concepts",
            "brief_description": "Concepts are represented by prototypical central tendency exemplars or averaged feature vectors; membership is graded by similarity to the prototype.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Conceptual knowledge is functionally represented as prototypical summaries (central tendencies) of category instances; category membership and inferential judgments are produced by measuring similarity between items and these prototypes.",
            "representation_format_type": "prototype / feature-based (symbolic-less, summary vectors)",
            "key_properties": "graded membership, similarity-based judgments, compact summary of category structure, non-compositional by default (requires extra machinery for composition).",
            "empirical_support": "Cited classical empirical work showing family resemblance and graded category structure (Rosch et al.); used to explain many categorization phenomena where central members are preferred.",
            "empirical_challenges": "Paper notes prototype theories struggle to handle compositionality (combining concepts into structured complex concepts) without added mechanisms; references critiques (e.g. Fodor & Lepore) arguing prototypes can't straightforwardly yield productive, systematic composition.",
            "applied_domains_or_tasks": "Categorization, graded membership tasks, typicality effects, some concept combination studies.",
            "comparison_to_other_models": "Contrasted with LOT/symbolic compositional approaches which naturally support compositionality and systematicity; prototypes are simpler but need ad-hoc extensions to capture rule-like combinatorial structure.",
            "functional_mechanisms": "Similarity computation between item features and stored prototypical feature vectors to produce graded category membership; no inherent operation for composing prototypes into structured complex expressions.",
            "limitations_or_open_questions": "How to derive compositional complex concepts from prototype summaries; whether prototype representations can be augmented to support productively recombining concepts without symbolic machinery.",
            "uuid": "e5160.0"
        },
        {
            "name_short": "Exemplar model",
            "name_full": "Exemplar theory / exemplar models of categorization",
            "brief_description": "Concepts are functionally represented as sets of stored individual exemplars; categorization is performed by comparing novel items to stored exemplars and aggregating similarity.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar theory",
            "theory_or_model_description": "Conceptual representation consists of memory traces of individual exemplars; decisions result from similarity-weighted retrieval and aggregation over those exemplars rather than abstraction to a prototype.",
            "representation_format_type": "exemplar-based / episodic-like (collection of instances)",
            "key_properties": "instance-rich representation, context-sensitive, accounts for variability and exceptions, but not inherently compositional.",
            "empirical_support": "Cited as an influential approach to categorization (Medin & Schaffer; Smith & Medin); good fit to many categorization data where exemplar effects (specific memories) matter.",
            "empirical_challenges": "Like prototypes, exemplar models do not by themselves explain systematic compositional combination of conceptual operations; the paper contrasts exemplar and LOT approaches on compositionality grounds.",
            "applied_domains_or_tasks": "Categorization, similarity-based induction, memory-influenced classification.",
            "comparison_to_other_models": "Compared to prototype and symbolic LOT models: exemplar models handle variability and exceptions but lack natural compositional combinators; LOT predicts systematic recombination from primitives.",
            "functional_mechanisms": "Similarity retrieval to stored exemplars, similarity-weighted voting/aggregation to form category judgments; no explicit function-composition operator.",
            "limitations_or_open_questions": "Whether exemplar stores can be organized or indexed to support productive composition without introducing symbolic/computational primitives.",
            "uuid": "e5160.1"
        },
        {
            "name_short": "LOT",
            "name_full": "Language of Thought (LOT) / symbolic compositional model",
            "brief_description": "A representational format where concepts are symbolic expressions built from primitive functions and composition rules, allowing systematic and productive combination of concepts.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_or_model_name": "Language of Thought (LOT) / symbolic compositionality",
            "theory_or_model_description": "At the functional level, concepts are structured symbolic expressions (functions, predicates, logical forms) composed from a small set of primitives; complex thoughts arise by composing simpler functional operators (e.g., f2(f1(x)) or f2 ∘ f1).",
            "representation_format_type": "symbolic / compositional / function-based",
            "key_properties": "systematicity, productivity, compositionality, explicit manipulation of functions/operators, supports chunking of composed operations, amenable to rule-like inference.",
            "empirical_support": "Motivates the experiment: authors show 3.5–4.5 year-olds can represent individual functions (iconic screens) and predictively compose them on two-screen trials above chance, supporting LOT's basic assumption that learners can represent and compose functions.",
            "empirical_challenges": "Paper reports limits inconsistent with a naïve, unconstrained LOT: children fail when both composed operations act on the same feature dimension (CH-Color then CH-Color), suggesting additional processing or memory constraints not captured by a bare LOT account; also does not settle whether children form explicit symbolic names for compositions or merely sequentially apply functions.",
            "applied_domains_or_tasks": "Concept learning, language semantics, logical reasoning, structured concept induction, the present non-linguistic composition task.",
            "comparison_to_other_models": "Explicitly compared to prototype, exemplar, and connectionist accounts; argued to naturally explain compositionality that other models struggle with, but challenged by empirical limits (same-dimension failures) and by the question whether connectionist systems can emulate compositionality without assuming it.",
            "functional_mechanisms": "Representation of primitive functions that map inputs to outputs; rule-based composition operations (function application and composition) create complex concepts; chunking/compression may allow creating new composed functions (h = f2 ∘ f1) to be re-used.",
            "limitations_or_open_questions": "Whether children explicitly represent composed functions as single symbols (chunking) or merely apply operations sequentially; how memory/production constraints interact with symbolic composition; how LOT mechanisms map to learning algorithms/hypothesis selection (link to Bayesian/Learner models).",
            "uuid": "e5160.2"
        },
        {
            "name_short": "Bayesian LOT learning",
            "name_full": "Rational/Bayesian models within LOT frameworks",
            "brief_description": "Models that formalize induction over symbolic compositional hypothesis spaces using probabilistic (Bayesian/rational) inference to select among composed programs or logical forms.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Bayesian / rational LOT learning models",
            "theory_or_model_description": "These posit that learners have a prior over symbolic/programmatic hypothesis spaces (built from primitives) and use Bayesian inference to evaluate which compositions best explain observed data, trading off complexity and fit.",
            "representation_format_type": "symbolic / probabilistic over programs",
            "key_properties": "compositional hypothesis space, rational inductive inference, complexity-sensitive priors, ability to learn structured operators from sparse data.",
            "empirical_support": "Cited as explanatory framework for prior modeling work (Goodman et al., Piantadosi et al.) that can account for a wide range of concept learning phenomena and predicts compositional generalization.",
            "empirical_challenges": "The paper's experiment does not directly test Bayesian inference mechanisms; observed limitations (same-dimension failure) indicate additional cognitive constraints (memory, processing time) beyond ideal Bayesian learners.",
            "applied_domains_or_tasks": "Concept learning, grammar induction, causal and theory learning, semantic learning.",
            "comparison_to_other_models": "Straddles symbolic LOT and statistical learning: combines symbolic representational primitives with probabilistic inference, contrasted with pure connectionist accounts which lack explicit symbolic structures.",
            "functional_mechanisms": "Probabilistic search/selection over composed symbolic hypotheses (programs), with priors favoring simpler/shorter compositions and likelihoods determined by data fit.",
            "limitations_or_open_questions": "How to account for resource/bottleneck effects (e.g., same-dimension interference) within idealized Bayesian frameworks; how learners acquire the primitive functions themselves.",
            "uuid": "e5160.3"
        },
        {
            "name_short": "Connectionism/PDP",
            "name_full": "Connectionist / Parallel Distributed Processing (PDP) models",
            "brief_description": "Representations are distributed activation patterns across networks; learning occurs by adjusting connection weights so that patterns map to outputs, often lacking explicit symbol-like compositional operators.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Connectionist / parallel distributed processing models",
            "theory_or_model_description": "Conceptual knowledge is encoded as patterns of activation across distributed units; combination arises via learned mappings and interactions rather than explicit function composition; compositionality must be emergent from learned representations or network architecture.",
            "representation_format_type": "distributed / connectionist",
            "key_properties": "graded representations, robustness to noise, learning via weight adaptation, emergent structure, potential difficulty in capturing explicit compositional systematicity without engineered mechanisms.",
            "empirical_support": "Cited as an alternative framework; historically successful in many cognitive tasks (e.g., pattern recognition, generalization) though canonical PDP lacks built-in symbolic composition.",
            "empirical_challenges": "Authors raise the question whether a connectionist system can learn separate functions that can flexibly compose without explicit training on compositions — suggesting this is nontrivial and perhaps requires presupposing compositional primitives.",
            "applied_domains_or_tasks": "Perception, pattern learning, certain language phenomena, associative tasks; debates remain about structured symbolic cognition.",
            "comparison_to_other_models": "Contrasted with LOT: connectionism emphasizes distributed representations and learned mappings, while LOT posits explicit symbolic primitives and composition rules; hybrid proposals exist but are not the focus here.",
            "functional_mechanisms": "Distributed activation, learned transformations via weight adjustments, feedforward/ recurrent dynamics produce mappings from inputs to outputs; composition requires network architectures or training regimes that support combinatorial generalization.",
            "limitations_or_open_questions": "Whether connectionist architectures can naturally yield the kind of rapid, zero-shot composition seen in the experiment without built-in symbolic primitives; how to prevent implicit presupposition of compositionality when designing networks.",
            "uuid": "e5160.4"
        },
        {
            "name_short": "Constraint-combination alternative",
            "name_full": "Constraint-combination (non-compositional constraint) account",
            "brief_description": "An alternative functional account where each operation provides constraints on possible outcomes and learners combine constraints to infer results, without representing operations as composable functions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Constraint-combination (non-compositional) model",
            "theory_or_model_description": "Learners encode each screen/operation as a constraint on the set of possible object states; when two constraints are present they intersect or otherwise combine constraint sets to infer the outcome, rather than computing a composed function mapping.",
            "representation_format_type": "constraint-based / set-of-possible-states representation",
            "key_properties": "combination via constraint intersection or elimination, does not require representing functions as first-class entities, potentially less structured than symbolic composition.",
            "empirical_support": "Paper posits this as a plausible non-compositional account that might explain success by combining constraints rather than composing functions.",
            "empirical_challenges": "Authors argue constraint-combination would struggle to naturally explain specific empirical patterns (e.g., below-chance performance in within-dimension CH/CH trials) and might still be interpretable as function composition in many cases; more detailed predictions would be needed to distinguish it empirically.",
            "applied_domains_or_tasks": "Inference under partial observability, reasoning with constraints, some non-linguistic predictive tasks.",
            "comparison_to_other_models": "Presented as an alternative to LOT-style composition; less committed to symbol-like functions but must account for same empirical signatures that compositional models predict.",
            "functional_mechanisms": "Represent possible output states compatible with each observed transformation; combine constraints (set intersection, elimination) to narrow outcomes; selection among outcomes based on additional heuristics or priors.",
            "limitations_or_open_questions": "How to formalize constraint combination so it cannot be reinterpreted as composition; whether it can account for fine-grained error patterns (recency bias, same-dimension failures) observed in data.",
            "uuid": "e5160.5"
        },
        {
            "name_short": "Lambda / combinatory logic",
            "name_full": "Lambda calculus and combinatory logic (formal function-composition systems)",
            "brief_description": "Formal minimal computational systems built from function application and composition that can express arbitrary computation; used as theoretical motivation for function-based representational formats.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Lambda calculus / combinatory logic",
            "theory_or_model_description": "Formal systems in which functions are first-class objects and arbitrary computations are built by repeated function application and composition; function abstraction and composition are the core representational/computational primitives.",
            "representation_format_type": "formal symbolic / function-based (programs)",
            "key_properties": "minimal primitives (function application/composition), supports Turing-complete computation, emphasizes functions-as-objects and higher-order composition.",
            "empirical_support": "Used in discussion to illustrate how minimal compositional primitives can yield arbitrary computation; not directly tested empirically in this paper.",
            "empirical_challenges": "Practical cognitive constraints (memory, processing speed) may limit direct mapping of these ideal systems to human cognition; empirical data (same-dimension failures) indicate resource limitations not captured by pure formal models.",
            "applied_domains_or_tasks": "Theoretical foundations for symbolic program induction, LOT-style models, formal semantics.",
            "comparison_to_other_models": "Provides formal underpinning for LOT-style function-based representations; contrasts with distributed/connectionist representations that do not treat functions as primitive tokens.",
            "functional_mechanisms": "Function abstraction and composition, variable binding, higher-order functions; constructs programs that map inputs to outputs via nested applications.",
            "limitations_or_open_questions": "How to implement these formal mechanisms within human cognitive constraints and learning processes; whether children ever represent functions in full higher-order formalism or only approximate variants.",
            "uuid": "e5160.6"
        },
        {
            "name_short": "Empirical finding: child function composition",
            "name_full": "Preschoolers' ability to represent and compose functions (this study)",
            "brief_description": "Empirical result showing 3.5–4.5 year-old children can represent novel functions (visual transformations) and predictively compose two such functions above chance without explicit training on composition.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Empirical finding: children represent functions and compose them (behavioral evidence)",
            "theory_or_model_description": "At a functional level, children represent mapping operations (screens that transform object features) as functions that can be applied to object representations and can successively apply (compose) two such transformations to infer the unseen outcome of sequential operations.",
            "representation_format_type": "function-based / compositional (behavioral evidence for symbolic-like function manipulation)",
            "key_properties": "ability to represent operations as mappings, sequential application (f2(f1(x))), above-chance zero-feedback composition, recency bias in errors, dimension-specific interference for rapid sequential updates.",
            "empirical_support": "Experiment: N=21 children (mean age ~50.9 months). Training on single-screen mappings, then test with two-screen trials without feedback. Overall two-screen accuracy &gt;25% chance (intercept logit significantly above chance); specific two-change across-dimension conditions: CH-Color→CH-Pattern accuracy 50% (p=0.003), CH-Pattern→CH-Color 55% (p=0.002). Mixed-effects regression: SameDimension predictor strongly negative (β = −0.50, z = −4.23, p &lt; 0.001). Error analysis: incorrect responses more likely to have second-screen transformation applied (β = 1.15, z = 4.946, p &lt; 0.001).",
            "empirical_challenges": "Children performed at chance on trials where both operations changed the same feature dimension (CH-Color then CH-Color), and their overall accuracy was near 50%, showing limits: failures when rapid sequential updates act on same variable and sub-50% performance suggests possible destructive interference beyond simple forgetting.",
            "applied_domains_or_tasks": "Non-linguistic conceptual composition tasks, causal/transformational prediction tasks, early concept learning, studies of compositional reasoning in development.",
            "comparison_to_other_models": "Findings support LOT-like assumptions that functions can be represented and composed, while posing challenges to models that cannot produce zero-shot composition (pure exemplar/prototype) or that cannot account for dimension-specific interference; authors also note constraint-based and connectionist alternatives need to specify how composition emerges without direct training on compositions.",
            "functional_mechanisms": "Behaviorally, children appear to (a) encode each screen as an operation mapping input features to outputs, (b) apply the second operation and often the first in sequence to predict final state (f2(f1(x))), and (c) show recency/overwrite effects suggesting limited maintenance of earlier transformation or interference when both operations target same feature.",
            "limitations_or_open_questions": "Whether children form explicit chunked symbols for composed functions (h = f2 ∘ f1) versus only sequentially updating representations; the origin of same-dimension failure (memory overwrite, race conditions, attentional constraints); generality to more complex feature sets, older/younger ages, and whether connectionist models can reproduce these results without presupposing compositional primitives.",
            "uuid": "e5160.7"
        },
        {
            "name_short": "Boolean / Feldman",
            "name_full": "Boolean/compositional models and minimization of Boolean complexity",
            "brief_description": "Accounts that conceptual representations are Boolean combinations of primitives and that humans favor simpler (lower Boolean complexity) conceptual formulas.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Boolean / compositional minimization models (Feldman)",
            "theory_or_model_description": "Concepts are represented as Boolean formulas composed from primitives (and/or/not); learning and representation favor minimal Boolean expressions that explain data.",
            "representation_format_type": "symbolic / Boolean compositional",
            "key_properties": "compositional logical structure, complexity-sensitive preference (simpler Boolean formulas preferred), explains patterns in concept learning.",
            "empirical_support": "Cited empirical modeling work (Feldman) showing human concept learning aligns with minimization of Boolean complexity.",
            "empirical_challenges": "Paper does not directly test Boolean minimization; some developmental limits observed (same-dimension interference) point to process constraints orthogonal to representational complexity preferences.",
            "applied_domains_or_tasks": "Boolean concept learning, rule-based categorization tasks.",
            "comparison_to_other_models": "Similar to LOT in compositional symbolic structure but emphasizes complexity minimization; differs from prototype/exemplar accounts.",
            "functional_mechanisms": "Construct Boolean expressions from primitives and apply simplicity prior when inferring concepts from data.",
            "limitations_or_open_questions": "How process constraints (memory, time) interact with preference for simpler symbolic formulas in developmental populations.",
            "uuid": "e5160.8"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The language of thought",
            "rating": 2,
            "sanitized_title": "the_language_of_thought"
        },
        {
            "paper_title": "Minimization of Boolean complexity in human concept learning",
            "rating": 2,
            "sanitized_title": "minimization_of_boolean_complexity_in_human_concept_learning"
        },
        {
            "paper_title": "A Rational Analysis of Rule-Based Concept Learning",
            "rating": 2,
            "sanitized_title": "a_rational_analysis_of_rulebased_concept_learning"
        },
        {
            "paper_title": "Bootstrapping in a language of thought: a formal model of numerical concept learning",
            "rating": 2,
            "sanitized_title": "bootstrapping_in_a_language_of_thought_a_formal_model_of_numerical_concept_learning"
        },
        {
            "paper_title": "Parallel distributed processing",
            "rating": 2,
            "sanitized_title": "parallel_distributed_processing"
        },
        {
            "paper_title": "A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings",
            "rating": 1,
            "sanitized_title": "a_computational_study_of_crosssituational_techniques_for_learning_wordtomeaning_mappings"
        },
        {
            "paper_title": "To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic",
            "rating": 1,
            "sanitized_title": "to_mock_a_mockingbird_and_other_logic_puzzles_including_an_amazing_adventure_in_combinatory_logic"
        }
    ],
    "cost": 0.014407999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Compositional Reasoning in Early Childhood</p>
<p>Steven Piantadosi *spiantado@gmail.com 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Richard Aslin 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Compositional Reasoning in Early Childhood
RESEARCH ARTICLE
Compositional "language of thought" models have recently been proposed to account for a wide range of children's conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5-4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
<p>Introduction</p>
<p>One of the basic goals of cognitive science is to understand the nature of conceptual representations. Proposals for the format and structure of concepts range through theories based on prototypes [1], exemplars [2,3], language-like representations [4], and others [5]. A central issue for all approaches is that of compositionality-how to handle the combination of individual concepts into more complex representations (e.g. "beautiful" composed with "accordions" yields a composite concept, "beautiful accordions") [6][7][8][9]. This ability may be built "on top" of a representational format like prototypes [10] or it may be intrinsically a part of the core conceptual representation itself, as is hypothesized in language of thought (LOT) theories. According to LOT theories, the formation of a complex thought like "all sailboats are heavy" occurs when thinkers construct the corresponding compositional structure built out of simpler operations. For instance, such a conceptual format may be similar to standard logic: 8x.sailboat(x)! heavy(x). Here, 8, sailboat and heavy are functions that are composed in one particular way to express the composite idea "all sailboats are heavy." These functions may themselves be built out of simpler operations, but in LOT theories eventually this process grounds out in primitive functions from which all other thoughts and representations are derived.</p>
<p>LOT theories are motivated in part by the rich structure human concepts appear to easily represent, as well as by factors like the systematicity, productivity, and compositionality of cognition [11]. Indeed, the LOT has a rich history in cognitive science, dating back at least to Boole [12] and later Frege [13]. Boole sought to characterize the "laws of thought" and did so by postulating the formal logical system of Boolean logic, which builds logical representations (formulas) out of the logical primitives and, or, and not. More recent incarnations of LOT theories have argued specifically for compositional, symbolic representations as fuller cognitive theories encompassing a wider range of semantic and logical operations [4]. A structured LOT has also been argued to explain developmental change in concept and language learning [14][15][16][17][18][19][20][21], providing a convenient formalism to express both what learners bring to learning tasks (primitive functions), and what exactly they acquire (compositions of those functions to explain observed data). For instance, Piantadosi et al. [21] suggest that children may know about simple functions on sets (e.g. union, intersection, etc.) and build more complex representations of cardinality and counting by appropriately composing these operations. This type of general approach builds on work of Feldman [22] who used a compositional system to explain patterns in Boolean concept learning, and Siskind [14] who first developed a compositional account of learning semantics. Following Goodman et al. [16], many recent theories posit rational (Bayesian) statistical models as the core inductive mechanism that decides between possible combinations of primitives in the face of data. In all cases-dating back to Boole-the core claim is that composition of simple primitive functions is what allows for the creation of complex cognitive representations.</p>
<p>While learning studies and modeling work have established LOT-based models as plausible in principle, no experimental work has examined LOT models' most basic assumptions: learners should be able to represent functions and combine them through composition. This ability should be present without any explicit instruction on either the fact that functions can be composed, or what happens when they are composed. This ability is not trivial. Functions may perform many kinds of operations and in principle function combination can be used to express arbitrary computation [23][24][25].</p>
<p>To be clear, we focus here on conceptual compositionality (combinations of concepts), not linguistic compositionality (combinations of words in sentences), which has been studied previously [26][27][28][29]. The reason for this is that acquisition models have so far focused on learning either individual word meanings by composing simpler conceptual elements [14] or using compositional LOT systems to learn non-linguistic systems of concepts like magnetism [19]. In these cases, the learning models therefore make the strong prediction that children should be able to compose operations outside of the domain of language. Note that an ability to compose linguistic expressions does not establish that children will be able to compose conceptual operations; the compositionality of linguistics may or may not be encapsulated within language processing. The present work takes a first step towards investigating non-linguistic conceptual combination in children.</p>
<p>Of course, it is important to note that many tasks can be interpreted as compositional, depending on how they are formalized. Even, for instance, Sally-Ann [30] or simple numerical tasks with infants [31] require multiple updates to a representation, and therefore can be phrased as compositions of functions. Here, however, we approach compositionality from a more directed stance, constructing an experiment that is difficult to interpret in any way but compositional. The general logic of our experiment is to teach children that certain "screens" (occluders) cause specific feature changes (color or pattern) to an occluded object. The critical test conditions occur when two such screens are adjacent and children observe an object go behind both screens but they do not observe it between screens. Prediction of the correct outcome in this case requires them to apply both object transformations. Children receive no feedback on their responses to the compositional (two-screen) trials, meaning that success is indicative of automatic compositional reasoning without instruction or encouragement.</p>
<p>This experiment tests whether children can compute a composition of functions like f 2 (f 1 (x)), where f 2 is the second screen and f 1 is the first. However, there is a stronger sense in which learners might "know" compositionality: they might be able to form an explicit symbol h = f 2 (f 1 (x)) for the composition itself. Creating such a symbol is not a necessary ability for success on our task. In a linguistic analogy, the strong form of compositionality is tantamount to knowing that the term (symbol) "pit stop" refers to "refueling" and "changing tires." The weaker form corresponds to being able to refuel and then change tires, without knowing that there is a term or symbol that refers to the combination of both operations. Because we are just beginning to explore the type of compositional reasoning in a non-linguistic task, we start by investigating the developmental origins of the weaker sense: can preschoolers predictively compose novel operations? Or, do they show catastrophic failures when attempting to combine multiple functions, perhaps reminiscent of younger children's limitations with multiple updates to representations of objects or numerosity [32][33][34]?</p>
<p>Methods</p>
<p>In the experiment, preschoolers were shown displays on a touchscreen monitor in which a car with a colored pattern appeared. Cars had one of two patterns (dots/stars) occurring in one of two colors (red/blue). A car with one choice of these features drove on-screen and children were required to select which pattern it matched from a menu with all four possible options (Fig 1a). This ensured that they attended to the features of the cars and knew them at the start of each trial. For this response, children were required to respond until they answered correctly, with incorrect responses penalized by a buzzing noise and correct responses rewarded by a trumpet sound. The car then drove behind a single screen, making its pattern (but not wheels) occluded (Fig 1b). It jiggled behind the screen to indicate that a transformation was taking place. Children then responded with what they expected the car to look like when the screen lifted.</p>
<p>The experiment began with 6 explicit training trials in which children were provided with verbal feedback and instruction on the operation provided by each of the screens. Participants then entered an second training phase in which they received no verbal feedback from the experimenter, but were required to answer single-screen trials until correct, at which time the screen lifted to reveal the correct outcome (Fig 1c). Presentation of operations in this phase was in blocks of 6 single operations (red, blue, dots, stars, and two with no changes, in random order).</p>
<p>Children stayed in the training phase until they answered 5 out of 6 correct in a block. After meeting this criterion, the experiment progressed to a test phase. Here, children were shown blocks containing 2 single screen displays with feedback, and 4 two-screen displays without feedback (Fig 1d). In these critical trials, children observed the car pass behind one screen, then the next, without seeing it in between. As in training, they were required to answer correctly to the first question on the car's initial pattern, but crucially received no feedback on their selected outcome after the car had passed behind both screens. The screens never lifted to reveal the car after selection and the experiment simply progressed to the next trial.</p>
<p>Screens were chosen to be iconic of the color and pattern transformations because we are primarily interested in how children combine these operations when they know them, not how hard it is for children to learn each individual function. However, sometimes the screen would not cause a change-for instance, if a car with blue dots drove behind a blue screen. These trials were included in order to ensure that children really paid attention to the pattern on the screens and did not just "flip" the relevant dimension. We refer to transformations in which a feature changed (e.g. red car behind blue screen) as change (CH) screens, and transformations which did not change a feature (e.g. blue car behind blue screen) as identity (ID) screens.</p>
<p>Children were run in the experiment for a maximum of approximately 30 minutes, and were shown a short "reward" animation every three responses in order to keep the experiment interesting. Stimuli were presented using Kelpy, the Kid Experimental Library in Python, which is available under the GNU Public License from the first author [35]. This study was approved by the University of Rochester Research Subjects Review Board. Written informed consent was gathered from parents/guardians of the children involved.</p>
<p>Participants</p>
<p>Twenty-one children (10 females and 11 males) aged approximately 3.5-4.5 years (mean: 50.9 months; range: 42.9 to 53.9 months) were recruited to the Rochester Baby Lab. In order to assess overall levels of performance, all subjects were included in the following analysis, although two did not progress out of training.  subject intercepts and slopes by function type [36]. This type of analysis is well-suited to unbalanced designs where children have been run for varying amounts of test and training items. The red line corresponds to a chance rate of 25%, for guessing at random from the four possible choices. This figure shows that in each condition children are substantially above chance on single screen displays. They thus learned the operations performed by each iconic screen. However, children are not very good at this task-their overall accuracy is near 50%. This likely results from the fact that the task is somewhat complex, requiring tracking of multiple values of multiple dimensions.</p>
<p>Results</p>
<p>Critical two-screen test trials are shown in Fig 3. Again, error bars were computed via a mixed effect logistic regression with subject intercepts by function type (a model with random slopes did not converge). First, this figure shows that the overall mean response (teal bar) is substantially higher than the chance rate of 25%. The overall accuracy is also only slightly worse than the overall accuracy on single screen displays, meaning that knowledge of compositions is available to learners after training on single screens despite the fact that feedback was never provided on these two-screen trials. The other bars in this plot show performance broken down by the type of function performed by each of the two screens. Despite above chance performance overall, children are at chance in conditions involving feature changes within the same dimension (e.g. CH-Color/ CH-Color). In such a condition, a red circle car would go behind a blue screen (changing its color) and then behind a red screen (changing its color again). This requires keeping track of several different values within the same dimension, and-because the features are binary-realizing that a feature changes and then reverts back to its original value. Note that children are not just having difficulty in this condition in tracking the order in which the functions applied: that would predict 50% performance in these conditions (since children would have the other dimension right). Instead, it appears that children's performance breaks down completely in this case, not unlike total breakdowns seen in object tracking [32][33][34].</p>
<p>These detailed patterns of responses also rule out several other hypotheses about children's performance. First, it is clear that children are not above chance by merely applying one of the two screens. Such a tactic would predict 0% accuracy on conditions with two changes (e.g. CH-Color-CH-Pattern and CH-Pattern-CH-Shape) since application of only one screen would always give the wrong answer. Instead, children performed particularly well in these two conditions, with a mean accuracy of nearly 50%, trending above even the overall experiment mean. Responses in these conditions are each individually significantly above the 25% chance level (CH-Color-CH-Pattern accuracy is 50%, p = 0.003 when compared to chance; CH-Pattern-  CH-Color is 55%, p = 0.002 when compared to chance). Children's success in these conditions provides strong evidence that they do not simply choose one box to apply.</p>
<p>Moreover, children's performance surpasses their expected performance based on their ability to apply single screens. The blue dots in Fig 3 show the performance that would be expected if children's accuracy was determined by independent application of each function, with individual function accuracies determined by the performance on single boxes. Thus, the blue dot for CH-Color/CH-Pattern corresponds to the probability of success on a CH-Color operation followed by the probability of success on a CH-Pattern operation, according to Fig 2. Because the accuracies in Fig 2 are near 50% for each function type, application of two of these correctly is near 25%(= 0.5 Á 0.5). Across nearly all function types other than changes within the same dimension, children are substantially above this performance level. This suggests that their failures are not due to independent failures on each screen. This pattern could occur if, for instance, children's low accuracy in Fig 2 was driven by not paying attention on all trials, rather than not knowing the right answer.</p>
<p>Responses were also analyzed using a mixed-effect logistic regression [36] with intercepts by subject (a model with random slopes did not converge). This analysis lets us simultaneously evaluate the influence of multiple factors of children's response accuracies, and determine their mean accuracy while controlling these factors. Fig 4 shows estimated coefficients and standard errors. The coefficients here correspond to whether the first function is an identity function (Identity F1), the second is an identity (Identity F2; this is computed as whether the second function is an identity function on the output of the first function), the first change is a color dimension (IsColor F1), the second is the same feature dimension as the first (SameDimension), children's age, whether the child is male, the child's training accuracy, the number of items it took the child to progress on to testing, and the number of test items seen so far. The binary predictors here (Identity F1, Identity F2, IsColor F1, SameDimension, IsMale) are all negative sum coded and the continuous predictors are all standardized, meaning that the intercept can be interpreted as the mean response accuracy across all predictors. In this figure, coefficients far from the zero line indicate significant influences on response accuracy. This shows that there are three significant predictors: children are substantially worse when both boxes operate on the same dimension (SameDimension) (β = −0.50,z = −4.23,p &lt; 0.001). This means that when the first box changes a color, children are worse when the second box also changes a color, and analogously when both boxes change pattern. Children are worse when they take longer to reach testing (β = −0.25, z = 2.14, p = 0.03). Children with better training accuracy also perform better on testing (β = 0.54, z = 4.40, p &lt; 0.001). Importantly, the intercept here represents the mean accuracy controlling for all other effects. This shows that the intercept (β = −0.19) is significantly higher than the chance rate logit(0.25) shown by the red dot in the graph (p &lt; 0.001), indicating that children are substantially above the chance guessing rate. They are not, however, significantly different from 50% accuracy (p = 0.15). These results revealed no significant effect of age, indicating that we have no evidence older children are better at this task. This might suggest that such compositional reasoning is attained earlier than about 3.5 years of age so that children in the range 3.5 * 4.5 are not differentially capable of dealing with composition.</p>
<p>We additionally analyzed the pattern of errors children made in their responses. To do this, we looked only at incorrect responses and tried to predict which components of an incorrect response children were likely to get correct. In a mixed effect regression, we found that these responses were substantially more likely to provide a response with the second screen correctly applied rather than the first (β = 1.15, z = 4.946, p &lt; 0.001). This effect was independent of whether the first and second screens were colors or not (|β|&lt;0.1, z &lt; 0.5, p &gt; 0.65). This suggests that children's difficulty with composition may be in tracking or encoding the features of the car and the first screen while focusing on the second, temporally more recent, screen.</p>
<p>Discussion</p>
<p>These results provide evidence that preschoolers spontaneously infer the outcome of combinations of function applications after receiving training on only the individual pieces. Their performance on two screen displays-though not perfect-is comparable to their performance on single screen displays. These results suggest that knowledge of composition does not require training for preschoolers beyond learning the individual pieces: children at this age have already learned how to predictively combine operations. This does not mean that children have never required instruction (or data) for learning about composition, but it does mean that whatever they have learned before the experiment began is abstract enough to apply to novel functions.</p>
<p>It is worth noting that while our experiments were motivated by compositionality, there are likely non-compositional models that could capture these results. For instance, children may learn that each screen constrains the possible outcomes, and combine constraints in order to predict the outcome. The challenge for these theories would be to state combination in a way that cannot be viewed (or perhaps cannot be viewed naturally) as function composition. There are also challenging data points for such theories even in this simple experiment: for instance, they would have a difficult time explaining why children are below 50% on within-dimension CH/CH trials, a fact that almost certainly depends on the details of how constraints may be combined. Stronger results could likely be provided by displays with more features and operations in order to fully probe the extent of children's ability and distinguish alternative models. We therefore take our results as a first step that provides suggestive-not definitive-evidence for compositionality.</p>
<p>Our analysis revealed some subtle facts about which compositions are easy and difficult for young learners. Changes within the same feature dimension are difficult, but two changes across dimensions are as easy as one. The limitation within dimensions presents a challenge to the purest form of compositional theories: what type of mechanism could correctly compose, but only when the composed functions operate on separate feature dimensions? One theory is that setting a feature value in memory is slow. Thus, when the value of two features change rapidly, children may get confused about what the resulting value is. On the other hand, if one feature changes and then a different feature changes, both "write" processes can occur in parallel and not interfere with each other. Difficulties dealing with rapidly sequential updates to a variable are common in parallel programming in computer science, (resulting in a so-called race condition). This view is consistent with the pattern of children's errors, where it appears that the transformation of the first screen is most likely to get overwritten or lost.</p>
<p>Interestingly, however, children's performance is also below 50%, indicating that their failure is perhaps more than a problem with remembering both screens. It is more likely to be a complete breakdown, because forgetting a single screen would still give 50% performance in the two-screen trials (since half the time, one will be an identity screen). This may indicate that memory mechanisms are fundamentally incapable of tracking multiple updates to the same feature dimension, perhaps because two rapid updates interfere in a particularly destructive way.</p>
<p>In the introduction, we discussed two forms of compositionality corresponding to whether learners explicitly represent a combination of functions f 2 ⚬ f 1 or whether they merely have the capacity to successively apply them to a representation f 2 (f 1 (x)). The present experiment does not strongly distinguish between these possibilities; it is possible that children only track the object moving behind the screens, successively updating its visual features (corresponding to f 2 (f 1 (x))). It is also possible that children could explicitly know that two screens together can be chunked into a single unit, the function f 2 ⚬ f 1 . These possibilities might be disentangled by future work where children's ability to treat compositional functions as single units (e.g. in other compositions) could be evaluated.</p>
<p>In addition to demonstrating compositional ability, these results also suggest that children aged 3.5 * 4.5 are able to represent functions, not itself a trivial capacity. In particular, to perform above chance children must be able to represent the fact that each of four screens performs a particular change to an object's features, and that that change occurs even if the outcome is not directly observed. Such an ability to represent functions themselves might be viewed as an even more basic ability than compositionality. However, fluency with functions can only yield more complex computations if those functions can be combined to form novel combinations-which our results indicate preschoolers are likely able to do.</p>
<p>We consider this capacity for representing functions themselves as potentially a basic fact about the organization of cognitive computation. In modern computer systems, encapsulated functions play a critical role by allowing complex computations to efficiently and easily be built from simpler components. For instance, programs are constructed only out of simpler elementary operations (e.g. +, −, Á, /, for, if, etc.) which are eventually directly interpretable by the computer's hardware. Using only these kinds of primitive functions, one can create a structure implementing a more complex computation, like f(x) = x Á x Á x+x − (x+1)/x. The capacity to combine such elementary operations in arbitrary ways is extremely powerful, and an ability to manipulate functions themselves potentially allows a huge range of computations to be executed using very little "built in" knowledge (ie. few primitives). Indeed, the simplest computational systems like lambda calculus [23,25] and combinatory logic [24,37] "build in" almost nothing, essentially only the rules of function composition. A striking result in formal logic holds that arbitrary (ie. Turing-complete) computational processes can then be built out of nothing more than this capacity for composition [23]. This means that the ability of children to represent, manipulate, and compose functions may point to how they are able to acquire operations of substantial computational complexity, while requiring only very simple cognitive machinery. In this sense, compositionality may be the key component of LOT theories that allows arbitrarily complex computations to be represented by learners.</p>
<p>Our study was in large part motivated by LOT learning models, but it is also interesting to consider how to interpret these results in the context of larger theoretical divides in cognitive science. It may be productive, for example, to determine how such learning might be captured in connectionist or parallel distribution processing [38] approaches: how might one capture learning of separate functions which can be composed, without requiring any additional training on composition? Is it possible to set up such a system in a way that cannot be interpreted as presupposing compositionality itself? Or, it may be that compositionality is basic enough that, as in LOT theories, it should be assumed as a core computational primitive.</p>
<p>Conclusion</p>
<p>These results are an early step in linking contemporary structured learning models with infant and early childhood experimental studies. An ability to combine novel functions appears to be robustly present by three or four years of age, with children requiring no explicit training on combination once they have learned individual functions. This suggests that learning theories based around assuming compositionality are behaviorally plausible and that a capacity for combining mental operations may be one of the mechanisms that supports children's creation of rich conceptual systems.</p>
<p>Fig 2
2shows mean first response accuracies to single screen trials, broken down by each type of function: change (CH) color, change pattern, identity (ID) color, identity pattern. Means and standard errors were computed using a mixed effect logistic regression, taking into account</p>
<p>Fig 1 .
1The four phases of the experiment. First, a truck is observed (a) and children are required to touch which pattern of the four possible patterns in the box matches the car. The response of the first pattern on the car stays on the screen (right box in (b)) and the car moves behind a screen with an iconic representation of its operation. Children are then asked to predict the outcome with a new set of four choices on the left (b). In training trials (b), children answer until they are correct and then see the screen lift to reveal the car with the new pattern (c). The critical response in test trials is shown in (d), with the car occluded after passing behind two screens. No feedback is provided on these trials. doi:10.1371/journal.pone.0147734.g001</p>
<p>Fig 2 .
2Mean response accuracies to single screens which performed change (CH) or identity (ID) operations. A chance rate of 25% is shown by the dotted red line. doi:10.1371/journal.pone.0147734.g002</p>
<p>Fig 3 .
3Mean response accuracies to double screens, each of which performed change (CH) or identity (ID) operations. Error bars show confidence intervals. A chance rate of 25% is shown by the dotted red line. The blue dots correspond to the accuracy predicted under independent application of the single function accuracies in Fig 2.</p>
<p>doi:10.1371/journal.pone.0147734.g003</p>
<p>Fig 4 .
4Coefficients in a mixed-effect logistic regression predicting accuracy on test (two-screen) trials from a number of predictors. There intercept here, representing the mean accuracy, should be compared to the chance rate of 1/4 (red dot, at logit(0.25) on this scale), the overall chance guessing rate for 4 options. All other coefficients should be compared to the x = 0 line, showing whether they had a statistically significant influence on response accuracy. Effects significant at p &lt; 0.05) are shown with gray bars. doi:10.1371/journal.pone.0147734.g004
PLOS ONE | DOI:10.1371/journal.pone.0147734 September 2, 2016
AcknowledgmentsThis work benefited greatly from discussions with Roman Feiman, Celeste Kidd, Noah Goodman, and members of AKlab. Children were run with the help of Holly Palmeri and the Rochester Babylab RAs. Research reported in this publication was supported by the Eunice Kennedy Shriver National Institute Of Child Health &amp; Human Development of the National Institutes of Health under Award Number F32HD070544 and an NIH research grant to R. Aslin and E. Newport (HD-037082). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.
Family resemblances: Studies in the internal structure of categories. E Rosch, C B Mervis, 10.1016/0010-0285(75)90024-9Cognitive psychology. 74Rosch E, Mervis CB. Family resemblances: Studies in the internal structure of categories. Cognitive psychology. 1975; 7(4):573-605. doi: 10.1016/0010-0285(75)90024-9</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, 10.1037/0033-295X.85.3.207Psychological review. 853Medin DL, Schaffer MM. Context theory of classification learning. Psychological review. 1978; 85 (3):207-238. doi: 10.1037/0033-295X.85.3.207</p>
<p>The exemplar view. Foundations of cognitive psychology: Core readings. E E Smith, D L Medin, Smith EE, Medin DL. The exemplar view. Foundations of cognitive psychology: Core readings. 2002; p. 277-292.</p>
<p>The language of thought. J A Fodor, Harvard University PressCambridge, MAFodor JA. The language of thought. Cambridge, MA: Harvard University Press; 1975.</p>
<p>Concepts: Core Readings. E Margolis, S Laurence, The MIT PressCambridge, MAMargolis E., Laurence S. Concepts: Core Readings. Cambridge, MA: The MIT Press; 1999.</p>
<p>On the adequacy of prototype theory as a theory of concepts. D N Osherson, E E Smith, 10.1016/0010-0277(81)90013-5Cognition. 91Osherson DN, Smith EE. On the adequacy of prototype theory as a theory of concepts. Cognition. 1981; 9(1):35-58. doi: 10.1016/0010-0277(81)90013-5 PMID: 7196818</p>
<p>Conceptual combination with prototype concepts. E E Smith, D N Osherson, 10.1207/s15516709cog0804_2Cognitive Science. 84Smith EE, Osherson DN. Conceptual combination with prototype concepts. Cognitive Science. 1984; 8 (4):337-361. doi: 10.1207/s15516709cog0804_2</p>
<p>Prototype theory and compositionality. H Kamp, B Partee, 10.1016/0010-0277(94)00659-98556840Cognition. 572Kamp H, Partee B. Prototype theory and compositionality. Cognition. 1995; 57(2):129-191. doi: 10. 1016/0010-0277(94)00659-9 PMID: 8556840</p>
<p>The red herring and the pet fish: Why concepts still can't be prototypes. J Fodor, E Lepore, 10.1016/0010-0277(95)00694-XCognition. 582Fodor J, Lepore E. The red herring and the pet fish: Why concepts still can't be prototypes. Cognition. 1996; 58(2):253-270. doi: 10.1016/0010-0277(95)00694-X PMID: 8820389</p>
<p>Combining prototypes: A selective modification model. Cognitive Science. E E Smith, D N Osherson, L Rips, M Keane, 10.1207/s15516709cog1204_112Smith EE, Osherson DN, Rips L, Keane M. Combining prototypes: A selective modification model. Cog- nitive Science. 1988; 12(4):485-527. doi: 10.1207/s15516709cog1204_1</p>
<p>Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue. J Fodor, Z W Pylyshyn, Pinker S and Mehler JFodor J, Pylyshyn ZW. Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue, Pinker S and Mehler J (eds). 1988; p. 3-71.</p>
<p>An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. G Boole, Walton and MaberlyLondon, UKBoole G. An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. London, UK: Walton and Maberly; 1854.</p>
<p>Über sinn und bedeutung. G Frege, Wittgenstein Studien. 18921Frege G. Über sinn und bedeutung. Wittgenstein Studien. 1892; 1(1).</p>
<p>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. J M Siskind, 10.1016/S0010-0277(96)00728-7Cognition. 61Siskind JM. A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. Cognition. 1996; 61:31-91. doi: 10.1016/S0010-0277(96)00728-7</p>
<p>Modeling semantic cognition as logical dimensionality reduction. Y Katz, N D Goodman, K Kersting, C Kemp, J B Tenenbaum, Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society. Thirtieth Annual Meeting of the Cognitive Science SocietyKatz Y, Goodman ND, Kersting K, Kemp C, Tenenbaum JB. Modeling semantic cognition as logical dimensionality reduction. In: Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society; 2008.</p>
<p>A Rational Analysis of Rule-Based Concept Learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, 10.1080/0364021070180207121635333Cognitive Science. 321Goodman ND, Tenenbaum JB, Feldman J, Griffiths TL. A Rational Analysis of Rule-Based Concept Learning. Cognitive Science. 2008; 32(1):108-154. doi: 10.1080/03640210701802071 PMID: 21635333</p>
<p>Advances in neural information processing systems. C Kemp, N D Goodman, J B Tenenbaum, 20Learning and using relational theoriesKemp C, Goodman ND, Tenenbaum JB. Learning and using relational theories. Advances in neural information processing systems. 2008; 20:753-760.</p>
<p>Learning a theory of causality. N D Goodman, T D Ullman, J B Tenenbaum, Proceedings of the 31st annual conference of the cognitive science society. the 31st annual conference of the cognitive science societyGoodman ND, Ullman TD, Tenenbaum JB. Learning a theory of causality. In: Proceedings of the 31st annual conference of the cognitive science society; 2009. p. 2188-2193.</p>
<p>Theory Acquisition as Stochastic Search. T D Ullman, N D Goodman, J B Tenenbaum, Proceedings of thirty second annual meeting of the cognitive science society. thirty second annual meeting of the cognitive science societyUllman TD, Goodman ND, Tenenbaum JB. Theory Acquisition as Stochastic Search. In: Proceedings of thirty second annual meeting of the cognitive science society; 2010.</p>
<p>Learning and the language of thought. MIT. S T Piantadosi, Piantadosi ST. Learning and the language of thought. MIT; 2011. Available from: http://colala.bcs. rochester.edu/papers/piantadosi_thesis.pdf.</p>
<p>Bootstrapping in a language of thought: a formal model of numerical concept learning. S T Piantadosi, J B Tenenbaum, N D Goodman, 10.1016/j.cognition.2011.11.00522284806Cognition. 123Piantadosi ST, Tenenbaum JB, Goodman ND. Bootstrapping in a language of thought: a formal model of numerical concept learning. Cognition. 2012; 123:199-217. doi: 10.1016/j.cognition.2011.11.005 PMID: 22284806</p>
<p>Minimization of Boolean complexity in human concept learning. J Feldman, 10.1038/3503658611034211Nature. 4076804Feldman J. Minimization of Boolean complexity in human concept learning. Nature. 2000; 407 (6804):630-633. doi: 10.1038/35036586 PMID: 11034211</p>
<p>An unsolvable problem of elementary number theory. A Church, 10.2307/2371045American journal of mathematics. 582Church A. An unsolvable problem of elementary number theory. American journal of mathematics. 1936; 58(2):345-363. doi: 10.2307/2371045</p>
<p>On the building blocks of mathematical logic. From Frege to Gödel. M Schönfinkel, Schönfinkel M. On the building blocks of mathematical logic. From Frege to Gödel. 1967; p. 355-366.</p>
<p>Introduction to Combinators and λ-calculus. J R Hindley, J P Seldin, Cambridge, UKPress Syndicate of the University of CambridgeHindley JR, Seldin JP. Introduction to Combinators and λ-calculus. Cambridge, UK: Press Syndicate of the University of Cambridge; 1986.</p>
<p>The acquisition of prenominal modifier sequences. E H Matthei, 10.1016/0010-0277(82)90018-XCognition. 113Matthei EH. The acquisition of prenominal modifier sequences. Cognition. 1982; 11(3):301-332. doi: 10.1016/0010-0277(82)90018-X PMID: 7199414</p>
<p>Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. D Barner, J Snedeker, 10.1111/j.1467-8624.2008.01145.x1848941579Barner D, Snedeker J. Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. 2008; 79 (3):594-608. doi: 10.1111/j.1467-8624.2008.01145.x PMID: 18489415</p>
<p>Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. A Fernald, K Thorpe, V A Marchman, 10.1016/j.cogpsych.2009.12.00220189552Cognitive psychology. 603Fernald A, Thorpe K, Marchman VA. Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. Cognitive psychology. 2010; 60(3):190-217. doi: 10.1016/j.cogpsych.2009. 12.002 PMID: 20189552</p>
<p>30-month-olds use the distribution and meaning of adverbs to interpret novel adjectives. K Syrett, J Lidz, 10.1080/15475440903507905Language Learning and Development. 64Syrett K, Lidz J. 30-month-olds use the distribution and meaning of adverbs to interpret novel adjec- tives. Language Learning and Development. 2010; 6(4):258-282. doi: 10.1080/15475440903507905</p>
<p>Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. H Wimmer, J Perner, 10.1016/0010-0277(83)90004-56681741Cognition. 131Wimmer H, Perner J. Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. Cognition. 1983; 13(1):103-128. doi: 10.1016/0010-0277 (83)90004-5 PMID: 6681741</p>
<p>Addition and subtraction by human infants. K Wynn, 10.1038/358749a01508269Nature. 3586389Wynn K. Addition and subtraction by human infants. Nature. 1992; 358(6389):749-750. doi: 10.1038/ 358749a0 PMID: 1508269</p>
<p>Ten-month-old infants' intuitions about addition. Unpublished manuscript. R Baillargeon, K Miller, J Constantino, Urbana, Champaign, IL.University of Illinois atBaillargeon R, Miller K, Constantino J. Ten-month-old infants' intuitions about addition. Unpublished manuscript, University of Illinois at Urbana, Champaign, IL. 1994;.</p>
<p>On the limits of infants' quantification of small object arrays. L Feigenson, S Carey, 10.1016/j.cognition.2004.09.01016260263Cognition. 973Feigenson L, Carey S. On the limits of infants' quantification of small object arrays. Cognition. 2005; 97 (3):295-313. doi: 10.1016/j.cognition.2004.09.010 PMID: 16260263</p>
<p>Seven-month old infants chunk items in working memory. M Moher, A S Tuerk, L Feigenson, 10.1016/j.jecp.2012.03.00722575845Journal of Experimental Child Psychology. 112Moher M, Tuerk AS, Feigenson L. Seven-month old infants chunk items in working memory. Journal of Experimental Child Psychology. 2012; 112:361-377. doi: 10.1016/j.jecp.2012.03.007 PMID: 22575845</p>
<p>Kelpy: a free library for child experimentation in python. S T Piantadosi, Piantadosi ST. Kelpy: a free library for child experimentation in python; 2012. available from https:// github.com/piantado/kelpy/.</p>
<p>Data Analysis Using Regression and Multilevel/Hierarchical Models. A Gelman, J Hill, Cambridge University PressCambridge, UKGelman A, Hill J. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge, UK: Cambridge University Press; 2007.</p>
<p>To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic. R M Smullyan, Oxford University PressSmullyan RM. To Mock a Mockingbird: and other logic puzzles including an amazing adventure in com- binatory logic. Oxford University Press; 1985.</p>
<p>Parallel distributed processing. D E Rumelhart, J L Mcclelland, MIT PressCambridge, MARumelhart DE, McClelland JL. Parallel distributed processing. Cambridge, MA: MIT Press; 1986.</p>            </div>
        </div>

    </div>
</body>
</html>