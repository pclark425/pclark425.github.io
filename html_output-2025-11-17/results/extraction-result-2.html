<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-1.html">extraction-schema-1</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games or interactive fiction, focusing on how they use memory to improve task performance, including types of memory used, memory representations, and performance comparisons with and without memory.</div>
                <p><strong>Paper ID:</strong> paper-ab75caec496c00664bafdb1633540ee07626ba75</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games or interactive fiction, focusing on how they use memory to improve task performance, including types of memory used, memory representations, and performance comparisons with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based Cognitive Architecture</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model-based Cognitive Architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive architecture that integrates a large language model (LLM) as the core thinking component, alongside modules for perception, memory, role-playing, action, and learning, to enhance the capabilities of game agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Interactive Artificial Society Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A set of 25 distinct LLM-based game agents with varying personalities and professions, designed to interact in a virtual 2D village environment.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>Interactive Artificial Society</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Text-based memory stream</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Each agent maintains a text-based memory stream that includes perceptions, action plans, and reflections. The LLM interacts with this memory to generate new reflections and adapt action plans.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Demonstrated complex social behaviors, including natural dialogues and coordinated actions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits_summary</strong></td>
                            <td>The use of memory allows agents to lead natural dialogues, coordinate actions, and dynamically update social relationships, enhancing realism and immersion.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_training_method</strong></td>
                            <td>Reinforcement learning and supervised fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_training_method</strong></td>
                            <td>Memory is continuously updated through interactions and reflections generated by the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_description</strong></td>
                            <td>The task involves managing social interactions and behaviors in a dynamic environment, requiring agents to remember past interactions and adapt their strategies accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>A survey on large language model-based game agents <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2",
    "paper_id": "paper-ab75caec496c00664bafdb1633540ee07626ba75",
    "extraction_schema_id": "extraction-schema-1",
    "extracted_data": [
        {
            "name_short": "LLM-based Cognitive Architecture",
            "name_full": "Large Language Model-based Cognitive Architecture",
            "brief_description": "A cognitive architecture that integrates a large language model (LLM) as the core thinking component, alongside modules for perception, memory, role-playing, action, and learning, to enhance the capabilities of game agents.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Interactive Artificial Society Agents",
            "agent_description": "A set of 25 distinct LLM-based game agents with varying personalities and professions, designed to interact in a virtual 2D village environment.",
            "text_game_name": "Interactive Artificial Society",
            "memory_used": true,
            "memory_type": "Text-based memory stream",
            "memory_mechanism_description": "Each agent maintains a text-based memory stream that includes perceptions, action plans, and reflections. The LLM interacts with this memory to generate new reflections and adapt action plans.",
            "performance_with_memory": "Demonstrated complex social behaviors, including natural dialogues and coordinated actions.",
            "performance_without_memory": null,
            "performance_comparison_reported": false,
            "memory_benefits_summary": "The use of memory allows agents to lead natural dialogues, coordinate actions, and dynamically update social relationships, enhancing realism and immersion.",
            "memory_limitations_or_challenges": null,
            "agent_training_method": "Reinforcement learning and supervised fine-tuning.",
            "memory_training_method": "Memory is continuously updated through interactions and reflections generated by the LLM.",
            "task_complexity_description": "The task involves managing social interactions and behaviors in a dynamic environment, requiring agents to remember past interactions and adapt their strategies accordingly.",
            "uuid": "e2.0",
            "source_info": {
                "paper_title": "Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "A survey on large language model-based game agents",
            "rating": 1
        }
    ],
    "cost": 0.00301815,
    "model_str": null
}</code></pre>
        </div>

    </div>
</body>
</html>