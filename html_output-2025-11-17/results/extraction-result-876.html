<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-876 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-876</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-876</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-21.html">extraction-schema-21</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <p><strong>Paper ID:</strong> paper-d1500f1dbd62e26ef0753f31e845078f58479968</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d1500f1dbd62e26ef0753f31e845078f58479968" target="_blank">Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners</a></p>
                <p><strong>Paper Venue:</strong> Conference on Robot Learning</p>
                <p><strong>Paper TL;DR:</strong> This work presents KnowNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) exhibit a wide range of promising capabilities -- from step-by-step planning to commonsense reasoning -- that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KnowNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KnowNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KnowNo performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. KnowNo can be used with LLMs out of the box without model-finetuning, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models. Website: https://robot-help.github.io</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e876.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e876.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KNOWNO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNOWNo: Know When You Don't Know (LLM planner + Conformal Prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that pairs an LLM-based stepwise planner with conformal prediction (CP) to produce calibrated set-valued next-step predictions; triggers human help when the CP prediction set is non-singleton and converts chosen plans to low-level actions via controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KNOWNO</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM-centered planning agent that: (1) obtains environment observations via perception modules (object detectors / segmentation) and encodes them as text context, (2) prompts an LLM (PaLM-2L by default) to generate a small set of semantically distinct candidate next steps (MCQA generation), (3) queries the LLM for next-token probabilities over MCQA labels to obtain uncalibrated confidences, (4) applies conformal prediction (CP) on a held-out calibration dataset to construct prediction sets with a user-specified coverage 1-ε, (5) if the prediction set is a singleton executes the corresponding plan via a low-level controller (RT-1 policy, scripted policies, or trajectory optimizer like SQP), otherwise (6) asks a human supervisor to pick among items in the prediction set. For multi-step problems, KNOWNO performs sequence-level calibration (nonconformity score = min over timestep confidences) and uses causal reconstruction so per-timestep prediction sets can be built online.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Language-instructed robotics tasks (simulated tabletop rearrangement; hardware tabletop rearrangement with UR5; bimanual Kuka setup; mobile manipulator in office kitchen)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially observable embodied environments formalized as POMDPs: at each timestep the agent only sees observations (object detections, images) summarized into textual context; tasks include ambiguous natural-language instructions (spatial, numeric, attribute, Winograd-style ambiguities), manipulation and some mobile-manipulation tasks near counters/bins. Challenges: natural-language ambiguity, perceptual uncertainty, multi-step dependencies where actions influence future observations.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>Vision detectors (MDETR, Owl-ViT), Segment Anything (segmentation masks), polylabel (compute suction/center point), LLMs for planning (PaLM-2L, PaLM-2L-IF, GPT-3.5 experiments), low-level control modules: RT-1 end-to-end policy for mobile manipulation, scripted controllers for some behaviors, SQP trajectory optimizer for bimanual reachability.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Perception outputs: object class labels, bounding boxes, segmentation masks, object locations/coordinates; polylabel: pole-of-inaccessibility point (suction point); LLM outputs: candidate plan text, next-token probabilities (confidence scores), human-readable questions for clarification; low-level tools: action trajectories, motor commands.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Textual augmented context per timestep: the belief about the environment and instruction is represented implicitly as the concatenated textual context x^t containing (1) latest robot observations (detected object labels + spatial hints or coordinates), (2) user instruction, (3) few-shot examples and generated candidate plans. For multi-step planning, sequence-level calibration uses the minimum confidence across timesteps as a sequence nonconformity score; there is no explicit structured probabilistic belief distribution beyond LLM confidences and conformal prediction sets.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>At each timestep, perception tool outputs (object detections, segmentation-derived points) are converted to text and appended to the context; the LLM is re-prompted with this augmented context to generate candidate options. For multi-step tasks, the agent collects the sequence of augmented contexts (assuming correct earlier actions) and uses the minimum per-step confidence as the sequence-level score during calibration; causally, per-step prediction sets are reconstructed using the same quantile threshold, i.e., C^t(x^t) = {y | f(x^t)_y >= 1 - q_hat}. Human choices (when invoked) resolve ambiguity and then the low-level controller executes a chosen action, which then changes future observations (and thus future contexts).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>LLM-generated multiple-choice next-step planning (MCQA) with conformal prediction for calibrated set-valued outputs; human-in-the-loop disambiguation when CP set size > 1; low-level execution via learned policies (RT-1) or optimization (SQP) / scripted controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td>In reported hardware multi-step tabletop experiments (UR5), KNOWNo (with PaLM-2L and perception + controllers) achieved plan success 0.76 and trial task success 0.74 with average prediction set size 1.72, step-wise help rate 0.58 and trial-wise help 0.92 (table shown in paper). In simulated and hardware tasks KNOWNo achieved user-specified coverage 1-ε robustly (e.g., target 0.85 in simulation) and reduced human help by ~10-24% versus baseline uncertified methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td>No Help baseline (i.e., execute highest-scoring option without CP/human-in-loop) reported plan success 0.41 and task success 0.38 in the hardware multi-step table experiment (same table), and generally shows much lower reliability and no calibrated guarantee.</td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Appending perception outputs as textual context enables an LLM planner to operate in partially observable embodied settings; framing next-step choices as MCQA and using per-label next-token probabilities lets conformal prediction produce calibrated prediction sets with statistical coverage guarantees (1-ε) even when LLM confidences are miscalibrated; sequence-level CP (min-over-steps nonconformity score + causal reconstruction) extends guarantees to multi-step problems; this approach reduces human help compared to baseline thresholding/ensemble/prompt-based methods while ensuring target task success rates; system depends on accurate grounding of objects into text and faithful human help when invoked.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e876.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e876.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of agents that use external tools for planning in partially observable text environments, including how they maintain belief states, incorporate tool outputs, and perform navigation or path-finding tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM (PaLM-2L)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM-2L (large language model used as planner)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pre-trained instruction-capable LLM used to (a) generate semantically distinct candidate next steps given textual context including perception outputs, and (b) provide next-token probabilities over MCQA label tokens to derive confidences used by conformal prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PaLM-2L (as LLM planner)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Used as a black-box language model for two subroutines: (1) few-shot prompted generation of a small set (four) of semantically distinct candidate plans plus an 'option not listed' choice; (2) zero-shot next-token probability evaluation for MCQA labels A/B/C/D/E to obtain normalized confidences f(x)_y which feed into conformal prediction. Also evaluated variants (PaLM-2L-IF instruction-finetuned; GPT-3.5 was tested and found to have MCQA bias). No model fine-tuning required.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same language-instructed robotics tasks as KNOWNo (simulation and hardware setups used in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Partially observable robotic scenarios where perception outputs are textually described and appended to prompt; LLM operates over this augmented textual context to propose and score candidate actions.</td>
                        </tr>
                        <tr>
                            <td><strong>is_partially_observable</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tools_used</strong></td>
                            <td>Receives outputs from external perception tools (MDETR, Owl-ViT, Segment Anything) and uses those textualized observations as part of prompts; interacts with conformal prediction calibration module and human supervisor as part of KNOWNO pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>tool_output_types</strong></td>
                            <td>Textual candidate plans, per-label next-token log-probabilities/normalized next-token probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>belief_state_mechanism</strong></td>
                            <td>Implicit belief represented via the current textual prompt (observation descriptions + instruction + few-shot exemplars); LLM internal activations are not treated as explicit belief; confidence (next-token probability) is used as a heuristic for nonconformity scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>incorporates_tool_outputs_in_belief</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>belief_update_description</strong></td>
                            <td>Per-step, perception outputs are converted to text and concatenated to the prompt; the LLM re-generates candidate plans and rescoring occurs, producing updated confidences that are used by CP to form per-step prediction sets.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_approach</strong></td>
                            <td>MCQA-style next-step selection (few-shot generation + next-token scoring) combined with external CP calibration; not performing explicit search or graph-based planning internally.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_shortest_path_planning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>navigation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_tool_ablation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PaLM-2L can be used out-of-the-box for planning when its outputs are cast into MCQA and combined with CP: the CP guarantee is agnostic to LLM calibration so even miscalibrated LLM confidences can be managed by triggering human help; different LLM variants changed prediction-set sizes and biases (PaLM-2L-IF produced smaller sets; GPT-3.5 exhibited MCQA label bias).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Do as I can, not as I say: Grounding language in robotic affordances <em>(Rating: 2)</em></li>
                <li>Inner monologue: Embodied reasoning through planning with language models <em>(Rating: 2)</em></li>
                <li>Code as policies: Language model programs for embodied control <em>(Rating: 2)</em></li>
                <li>Socratic models: Composing zero-shot multimodal reasoning with language <em>(Rating: 1)</em></li>
                <li>Vision-and-dialog navigation <em>(Rating: 1)</em></li>
                <li>DialFRED: Dialogue-enabled agents for embodied instruction following <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-876",
    "paper_id": "paper-d1500f1dbd62e26ef0753f31e845078f58479968",
    "extraction_schema_id": "extraction-schema-21",
    "extracted_data": [
        {
            "name_short": "KNOWNO",
            "name_full": "KNOWNo: Know When You Don't Know (LLM planner + Conformal Prediction)",
            "brief_description": "A framework that pairs an LLM-based stepwise planner with conformal prediction (CP) to produce calibrated set-valued next-step predictions; triggers human help when the CP prediction set is non-singleton and converts chosen plans to low-level actions via controllers.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "KNOWNO",
            "agent_description": "An LLM-centered planning agent that: (1) obtains environment observations via perception modules (object detectors / segmentation) and encodes them as text context, (2) prompts an LLM (PaLM-2L by default) to generate a small set of semantically distinct candidate next steps (MCQA generation), (3) queries the LLM for next-token probabilities over MCQA labels to obtain uncalibrated confidences, (4) applies conformal prediction (CP) on a held-out calibration dataset to construct prediction sets with a user-specified coverage 1-ε, (5) if the prediction set is a singleton executes the corresponding plan via a low-level controller (RT-1 policy, scripted policies, or trajectory optimizer like SQP), otherwise (6) asks a human supervisor to pick among items in the prediction set. For multi-step problems, KNOWNO performs sequence-level calibration (nonconformity score = min over timestep confidences) and uses causal reconstruction so per-timestep prediction sets can be built online.",
            "environment_name": "Language-instructed robotics tasks (simulated tabletop rearrangement; hardware tabletop rearrangement with UR5; bimanual Kuka setup; mobile manipulator in office kitchen)",
            "environment_description": "Partially observable embodied environments formalized as POMDPs: at each timestep the agent only sees observations (object detections, images) summarized into textual context; tasks include ambiguous natural-language instructions (spatial, numeric, attribute, Winograd-style ambiguities), manipulation and some mobile-manipulation tasks near counters/bins. Challenges: natural-language ambiguity, perceptual uncertainty, multi-step dependencies where actions influence future observations.",
            "is_partially_observable": true,
            "external_tools_used": "Vision detectors (MDETR, Owl-ViT), Segment Anything (segmentation masks), polylabel (compute suction/center point), LLMs for planning (PaLM-2L, PaLM-2L-IF, GPT-3.5 experiments), low-level control modules: RT-1 end-to-end policy for mobile manipulation, scripted controllers for some behaviors, SQP trajectory optimizer for bimanual reachability.",
            "tool_output_types": "Perception outputs: object class labels, bounding boxes, segmentation masks, object locations/coordinates; polylabel: pole-of-inaccessibility point (suction point); LLM outputs: candidate plan text, next-token probabilities (confidence scores), human-readable questions for clarification; low-level tools: action trajectories, motor commands.",
            "belief_state_mechanism": "Textual augmented context per timestep: the belief about the environment and instruction is represented implicitly as the concatenated textual context x^t containing (1) latest robot observations (detected object labels + spatial hints or coordinates), (2) user instruction, (3) few-shot examples and generated candidate plans. For multi-step planning, sequence-level calibration uses the minimum confidence across timesteps as a sequence nonconformity score; there is no explicit structured probabilistic belief distribution beyond LLM confidences and conformal prediction sets.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "At each timestep, perception tool outputs (object detections, segmentation-derived points) are converted to text and appended to the context; the LLM is re-prompted with this augmented context to generate candidate options. For multi-step tasks, the agent collects the sequence of augmented contexts (assuming correct earlier actions) and uses the minimum per-step confidence as the sequence-level score during calibration; causally, per-step prediction sets are reconstructed using the same quantile threshold, i.e., C^t(x^t) = {y | f(x^t)_y &gt;= 1 - q_hat}. Human choices (when invoked) resolve ambiguity and then the low-level controller executes a chosen action, which then changes future observations (and thus future contexts).",
            "planning_approach": "LLM-generated multiple-choice next-step planning (MCQA) with conformal prediction for calibrated set-valued outputs; human-in-the-loop disambiguation when CP set size &gt; 1; low-level execution via learned policies (RT-1) or optimization (SQP) / scripted controllers.",
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": "In reported hardware multi-step tabletop experiments (UR5), KNOWNo (with PaLM-2L and perception + controllers) achieved plan success 0.76 and trial task success 0.74 with average prediction set size 1.72, step-wise help rate 0.58 and trial-wise help 0.92 (table shown in paper). In simulated and hardware tasks KNOWNo achieved user-specified coverage 1-ε robustly (e.g., target 0.85 in simulation) and reduced human help by ~10-24% versus baseline uncertified methods.",
            "performance_without_tools": "No Help baseline (i.e., execute highest-scoring option without CP/human-in-loop) reported plan success 0.41 and task success 0.38 in the hardware multi-step table experiment (same table), and generally shows much lower reliability and no calibrated guarantee.",
            "has_tool_ablation": true,
            "key_findings": "Appending perception outputs as textual context enables an LLM planner to operate in partially observable embodied settings; framing next-step choices as MCQA and using per-label next-token probabilities lets conformal prediction produce calibrated prediction sets with statistical coverage guarantees (1-ε) even when LLM confidences are miscalibrated; sequence-level CP (min-over-steps nonconformity score + causal reconstruction) extends guarantees to multi-step problems; this approach reduces human help compared to baseline thresholding/ensemble/prompt-based methods while ensuring target task success rates; system depends on accurate grounding of objects into text and faithful human help when invoked.",
            "uuid": "e876.0",
            "source_info": {
                "paper_title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "LLM (PaLM-2L)",
            "name_full": "PaLM-2L (large language model used as planner)",
            "brief_description": "A pre-trained instruction-capable LLM used to (a) generate semantically distinct candidate next steps given textual context including perception outputs, and (b) provide next-token probabilities over MCQA label tokens to derive confidences used by conformal prediction.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "PaLM-2L (as LLM planner)",
            "agent_description": "Used as a black-box language model for two subroutines: (1) few-shot prompted generation of a small set (four) of semantically distinct candidate plans plus an 'option not listed' choice; (2) zero-shot next-token probability evaluation for MCQA labels A/B/C/D/E to obtain normalized confidences f(x)_y which feed into conformal prediction. Also evaluated variants (PaLM-2L-IF instruction-finetuned; GPT-3.5 was tested and found to have MCQA bias). No model fine-tuning required.",
            "environment_name": "Same language-instructed robotics tasks as KNOWNo (simulation and hardware setups used in paper).",
            "environment_description": "Partially observable robotic scenarios where perception outputs are textually described and appended to prompt; LLM operates over this augmented textual context to propose and score candidate actions.",
            "is_partially_observable": true,
            "external_tools_used": "Receives outputs from external perception tools (MDETR, Owl-ViT, Segment Anything) and uses those textualized observations as part of prompts; interacts with conformal prediction calibration module and human supervisor as part of KNOWNO pipeline.",
            "tool_output_types": "Textual candidate plans, per-label next-token log-probabilities/normalized next-token probabilities.",
            "belief_state_mechanism": "Implicit belief represented via the current textual prompt (observation descriptions + instruction + few-shot exemplars); LLM internal activations are not treated as explicit belief; confidence (next-token probability) is used as a heuristic for nonconformity scoring.",
            "incorporates_tool_outputs_in_belief": true,
            "belief_update_description": "Per-step, perception outputs are converted to text and concatenated to the prompt; the LLM re-generates candidate plans and rescoring occurs, producing updated confidences that are used by CP to form per-step prediction sets.",
            "planning_approach": "MCQA-style next-step selection (few-shot generation + next-token scoring) combined with external CP calibration; not performing explicit search or graph-based planning internally.",
            "uses_shortest_path_planning": null,
            "navigation_method": null,
            "performance_with_tools": null,
            "performance_without_tools": null,
            "has_tool_ablation": true,
            "key_findings": "PaLM-2L can be used out-of-the-box for planning when its outputs are cast into MCQA and combined with CP: the CP guarantee is agnostic to LLM calibration so even miscalibrated LLM confidences can be managed by triggering human help; different LLM variants changed prediction-set sizes and biases (PaLM-2L-IF produced smaller sets; GPT-3.5 exhibited MCQA label bias).",
            "uuid": "e876.1",
            "source_info": {
                "paper_title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Do as I can, not as I say: Grounding language in robotic affordances",
            "rating": 2
        },
        {
            "paper_title": "Inner monologue: Embodied reasoning through planning with language models",
            "rating": 2
        },
        {
            "paper_title": "Code as policies: Language model programs for embodied control",
            "rating": 2
        },
        {
            "paper_title": "Socratic models: Composing zero-shot multimodal reasoning with language",
            "rating": 1
        },
        {
            "paper_title": "Vision-and-dialog navigation",
            "rating": 1
        },
        {
            "paper_title": "DialFRED: Dialogue-enabled agents for embodied instruction following",
            "rating": 1
        }
    ],
    "cost": 0.014492999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners</h1>
<p>Allen Z. Ren ${ }^{1,2}$, Anushri Dixit ${ }^{1}$, Alexandra Bodrova ${ }^{1}$, Sumeet Singh ${ }^{2}$, Stephen Tu ${ }^{2}$, Noah Brown ${ }^{2}$, Peng Xu ${ }^{2}$, Leila Takayama ${ }^{2}$, Fei Xia ${ }^{2}$, Jake Varley ${ }^{2}$, Zhenjia Xu ${ }^{2}$, Dorsa Sadigh ${ }^{2}$, Andy Zeng ${ }^{2}$, Anirudha Majumdar ${ }^{1,2}$<br>${ }^{1}$ Princeton University, ${ }^{2}$ Google DeepMind</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) exhibit a wide range of promising capabilities - from step-by-step planning to commonsense reasoning - that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KNOWNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KNOWNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KNOWNo performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. KNOWNo can be used with LLMs out of the box without modelfinetuning, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models. ${ }^{1}$</p>
<p>Keywords: Language-based planning, uncertainty estimation, conformal prediction</p>
<h2>1 Introduction</h2>
<p>How can we endow our robots with the ability to know when they don't know? Accurately modeling and accounting for uncertainty is a longstanding challenge towards robots that operate reliably in unstructured and novel environments. In this work, we study this challenge in the context of language-instructed robots. Language provides a natural and flexible interface for humans to specify tasks, contextual information, and intentions, while also allowing us to provide help and clarification to robots when they are uncertain.
Recently, approaches that leverage large language models (LLMs) for planning [1, 2] have demonstrated the ability to respond to natural and unstructured language instructions to generate temporally extended plans. These approaches enable leveraging the vast amount of prior knowledge and rich context embedded in pretrained LLMs, and lead to substantial abstract reasoning capabilities. However, one of the major challenges with current LLMs is their tendency to hallucinate, i.e., to confidently generate outputs that are plausible but incorrect and untethered from reality. Such false confidence in incorrect outputs poses a significant challenge to LLM-based planning in robotics. Moreover, natural language instructions in realworld environments often contain a high degree of ambiguity inherently or unintentionally from humans, and confidently following an incorrectly constructed plan could lead to undesirable or even unsafe actions.
As an example (Fig. 1), a robot tasked with heating food may be asked to "place the bowl in the microwave"; if there are multiple bowls on the counter, the instruction is ambiguous. Moreover, the metal bowl may not be safe for the microwave. Rather than acting in this ambiguous setting and damaging the microwave or even causing a fire, the robot should know when it doesn't know and ask for clarification instead (e.g., ask which bowl should be placed in the microwave). Prior work in language-based planning either does not seek such clarifications [1] or does so via extensive prompting [2], which requires careful prompt engineering to prevent the robot from excessively relying on seeking assistance. Moreover, prior</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: KNOWNO uses Conformal Prediction (CP) to align the uncertainty of LLM planners. Given a language instruction, an LLM generates possible next steps and its confidences (scores) in these options. CP then provides a prediction set that includes the options with scores above a certain quantile. If there is more than one option in the set, the robot asks for help. Experiments across multiple embodiments and a variety of ambiguous situations show that KNOWNO significantly improves efficiency and autonomy compared to baselines.
approaches do not provide a way to ensure that asking for help results in a desired level of task success. We formalize these challenges via two desiderata: (i) calibrated confidence: the robot should seek sufficient help to ensure a statistically guaranteed level of task success specified by the user, and (ii) minimal help: the robot should minimize the overall amount of help it seeks by narrowing down possible ambiguities in a task. We collectively refer to these sufficiency and minimality conditions as uncertainty alignment.
Statement of contributions. We propose KNOWNO— Know When You Don't Know — a framework for aligning the uncertainty of LLM-based planners utilizing the theory of conformal prediction (CP) [3, 4]. We make the following contributions: (1) Given a language instruction, we utilize a pre-trained LLM with uncalibrated confidence to generate a set of possible actions for the robot to execute next. We demonstrate how to use CP to select a subset of these options, which allows the robot to decide an action to execute (if the subset is a singleton) or to ask for help otherwise. (2) We prove theoretical guarantees on calibrated confidence in both single-step and multi-step planning problems: with a user-specified level $1-\epsilon$, the robot performs the tasks correctly in $1-\epsilon \%$ of scenarios by asking for help when it deems it necessary. CP also minimizes the average size of prediction sets, thus addressing the goal of minimal help. (3) We evaluate KNOWNO in both simulation and hardware with a suite of language-instructed manipulation tasks with various types of potential ambiguities (e.g., based on spatial locations, numerical values, attributes of objects, and Winograd schemas). Experiments across multiple settings and embodiments validate the ability of KNOWNO to provide statistically guaranteed levels of task success while reducing the amount of help required by $10-24 \%$ as compared to baseline approaches.</p>
<h1>2 Overview: Robots that Ask for Help</h1>
<p>Language-based planners. Language model planners can generate step-by-step robot plans, where each step $y$ is composed of variable-length sequences of symbols $\left(\sigma_{1}, \sigma_{2}, \ldots, \sigma_{k}\right)$, e.g., text tokens as input to a language-conditioned policy [1] (see Fig. 1), or robot code executed by an interpreter [5]. Pretrained autoregressive LLMs predict each step $y$, whose joint probability over tokens can be factorized as the product of conditional probabilities of next token prediction $p(y)=\prod_{i=1}^{k} p\left(\sigma_{i} \mid \sigma_{1}, \ldots, \sigma_{i-1}\right)$. Here, we are interested in characterizing the uncertainty of next step prediction $p(y)$. The distribution of $p$ remains highly sensitive to variable-length $k$; hence $p(y)$ on its own serves as a rather poor scoring function [6] particularly when steps in a plan are expressed in natural language (our experiments in Section A9 also show that using $p(y)$ directly for calibration leads to poor performance).</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: KNOWNO formulates LLM planning as MCQA by first prompting an LLM to generate plausible options, and then asking it to predict the correct one. Based on the next-token likelihoods from a calibration dataset, CP finds the quantile value $\hat{q}$ such that all options with a score $\geq 1-\hat{q}$ are included in the prediction set in a test scenario. The resulting sets are guaranteed to cover the true option with the user-specified probability.</p>
<p>Planning as multiple-choice Q\&amp;A. We can address this length bias with a simple trick. First, with a few-shot prompt that includes possible next steps in a few scenarios (Fig. A1), the LLM generates a set $\left{y^{i}\right}$ of candidate next steps (e.g., "Put plastic bowl in microwave", "Put metal bowl in microwave", etc., in Fig. 1) that are semantically different. Then the task of choosing among them is formatted as multiple-choice Q\&amp;A (MCQA). This eliminates plans that the LLM considers unlikely and reduces the problem of next-step prediction down to a single next-token prediction - aligning with LLM log-likelihood loss functions and LLM training data (e.g., MCQA datasets [7, 8]). These probabilities can serve as normalized scores that can be used by various uncertainty quantification methods such as thresholding and ensemble methods. In this work, we use these normalized scores within a conformal prediction (CP) framework. Specifically, CP uses a held-out calibration set of example plans in different scenarios to generate a reduced prediction set of plans among $\left{y^{i}\right}$ (Fig. 2). The LLM is certain if this prediction set is a singleton, and triggers help from a human otherwise. Section A1 details additional rationale of applying MCQA to evaluate the semantic uncertainty of the LLM.</p>
<p>Robots that ask for help. In this work, we show that LLM planning - combined with CP for uncertainty estimation - can effectively enable robots to interact with an environment, and ask for help when needed. The environment $e$ can be formulated as a partially observable Markov decision process (POMDP): at any given state $s^{t}$ at time $t$, given a user instruction $\ell$, the robot executes an action $a^{t}$ according to a policy $\pi$, then transitions to a new state $s^{t+1}$. Our policy $\pi$ is composed of four parts (Fig. 1):</p>
<ol>
<li>Multiple-choice generation: An LLM generates a diverse set of candidate plans labeled with ' $A$ ', ' $B$ ', ' $C$ ', ' $D$ ' , and an additional possible plan, ' $E$ ) an option not listed here', which is appended post-hoc. We denote the set of labels by $\mathcal{Y}:=\left{{ }^{\prime} A^{\prime},{ }^{\prime} B^{\prime},{ }^{\prime} C^{\prime},{ }^{\prime} D^{\prime},{ }^{\prime} E^{\prime}\right}$. These plans are generated by prompting the LLM with context $x^{t}$, which is text that includes (1) the robot observation at each time step (e.g., using a vision-based object detector or an oracle; see Fig. 1), (2) the user instruction, and (3) few-shot examples of possible plans in other scenarios. An augmented context $\tilde{x}^{t}$ is obtained by appending the LLM-generated plans to the context $x^{t}$.</li>
<li>Prediction set generation: We use CP to choose a subset $C\left(\tilde{x}^{t}\right) \subseteq \mathcal{Y}$ of candidate plans using the LLM's (uncalibrated) confidence $f\left(\tilde{x}^{t}\right)_{y}$ in each prediction $y \in \mathcal{Y}$ given the context $\tilde{x}^{t}$.</li>
<li>Human help: If the prediction set is a non-singleton, the robot leverages help from a human (or any other supervisor agent, denoted as a function $f_{\mathcal{H}}$ ) to arrive at an unambiguous next step $y_{\mathcal{H}} \in C\left(\tilde{x}^{t}\right)$.</li>
<li>Low-level control: A low-level module $\varphi$ converts the plan in $y_{\mathcal{H}}$ to an action $a^{t}=\varphi\left(y_{\mathcal{H}}\right)$.</li>
</ol>
<p>Goal: uncertainty alignment. Often in real-world settings, language instructions $\ell$ can be ambiguous, e.g., "place the bowl in the microwave" does not specify that the human means the plastic bowl (Fig. 1). Our goal in this work is to address uncertainty alignment: achieve a desired level of task success while minimizing human help. We formalize this by considering a joint distribution $\mathcal{D}$ over scenarios $\xi:=(e, \ell, g)$, where $e$ is an environment (POMDP), $\ell$ is a (potentially ambiguous) language instruction, and $g$ is a goal (e.g., formulated as a subset of acceptable states in the POMDP and partially observable through $l$ ). Importantly, we do not assume knowledge of $\mathcal{D}$, except that we can sample a finite-size dataset of i.i.d. scenarios from it. We formalize uncertainty alignment in our setting as (i) calibrated confidence: the robot's policy (with human help as described above) succeeds with a user-specified probability $1-\epsilon$ over</p>
<p>new scenarios $\xi \sim \mathcal{D}$, and (ii) minimal help: the policy minimizes the number $|C(\cdot)|$ of options presented to the human on average across scenarios $\xi \sim \mathcal{D}$.</p>
<h1>3 Calibrating LLM Confidence with Conformal Prediction</h1>
<p>The MCQA setup above allows us to apply CP to obtain calibrated confidence guarantees while (approximately) minimizing help. We introduce CP below, and then present the different practical settings we consider (possibly involving multiple planning steps and/or multiple correct plans per step).</p>
<h3>3.1 Background: Conformal Prediction</h3>
<p>For now, we drop the timestep superscript and consider a generic MCQA setup with pairs $(\tilde{x}, y)$ consisting of input $\tilde{x}$ and true label $y$. Suppose there is a calibration set $Z=\left{z_{i}=\left(\tilde{x}<em i="i">{i}, y</em>\right)\right}<em _test="{test" _text="\text">{i=1}^{N}$ of such pairs drawn i.i.d. from an unknown distribution $\mathcal{D}$ over $\mathcal{Z}:=\mathcal{X} \times \mathcal{Y}$. Now, given a new i.i.d. sample $z</em>}}=\left(\tilde{x<em _test="{test" _text="\text">{\text {test }}, y</em>}}\right)$ with unknown true label $y_{\text {test }}, \mathrm{CP}$ generates a prediction set $C\left(\tilde{x<em _test="{test" _text="\text">{\text {test }}\right) \subseteq \mathcal{Y}$ that contains $y</em>$ with high probability [3]:}</p>
<p>$$
\mathbb{P}\left(y_{\text {test }} \in C\left(\tilde{x}_{\text {test }}\right)\right) \geq 1-\epsilon
$$</p>
<p>where $1-\epsilon$ is a user-specified value (desired task success level in our setting) that affects the size of $C(\cdot)$.
To generate $C\left(\tilde{x}<em i="i">{\text {test }}\right), \mathrm{CP}$ first uses the LLM's confidence $\hat{f}$ (cf. Section 2) to evaluate the set of nonconformity scores $\left{\kappa</em>}=1-\hat{f}\left(\tilde{x<em y__i="y_{i">{i}\right)</em>\right}}<em 1="1">{i=1}^{N}$ over the calibration set - the higher the score is, the less each data in the calibration set conforms to the data used for training $\hat{f}$. Then CP performs calibration by defining $\hat{q}$ to be the $\frac{\left\lfloor(N+1)(1-\epsilon)\right\rfloor}{N}$ empirical quantile of $\kappa</em>}, \ldots, \kappa_{N}$. Lastly, CP generates $C\left(\tilde{x<em _test="{test" _text="\text">{\text {test }}\right)=\left{y \in \mathcal{Y} \mid \hat{f}\left(\tilde{x}</em>\right)}<em _test="{test" _text="\text">{y} \geq 1-\hat{q}\right)}$, i.e., the prediction set that includes all labels that the predictor is at least $1-\hat{q}$ confident in. The generated prediction set ensures that the coverage guarantee in Eq. (1) holds.
Dataset-conditional guarantee. The probability in Eq. (1) is over both the sampling of the calibration set $Z$ and $z</em>$, one needs a fresh calibration set. Instead, we apply the following dataset-conditional guarantee [9] which is conditioned on a particular calibration dataset being sampled, and thus can be applied to new test data without re-calibration:}}$ (i.e., a marginal guarantee). Thus, to ensure the desired probability of coverage for each new $z_{\text {test }</p>
<p>$$
\mathbb{P}\left(y_{\text {test }} \in C\left(\tilde{x}<em 1="1">{\text {test }}\right) \mid\left{z</em>\rfloor
$$}, \ldots, z_{N}\right}\right) \geq \operatorname{Beta}_{N+1-v, v}^{-1}(\delta), \quad v:=\lfloor(N+1) \hat{\epsilon</p>
<p>where $\operatorname{Beta}<em y="y">{N+1-v, v}^{-1}(\delta)$ denotes the inverse CDF (quantile) level of $\delta$ in a Beta distribution with parameters $N+1-v$ and $v$, and $\hat{\epsilon}$ is the threshold used for calibration. In practice, we use a modest-sized calibration dataset $(N=400)$ and $\delta=0.01$, and adjust $\hat{\epsilon}$ to achieve the desired $1-\epsilon$ coverage (with probability $1-\delta=0.99$ over the sampling of the calibration set).
Minimal prediction set size. From [10, Thm. 1], $C(\cdot)$ achieves the smallest average set size among possible prediction schemes $\mathcal{C}$ that achieve the coverage guarantee, if $\hat{f}(\tilde{x})</em>$ models true conditional probabilities:</p>
<p>$$
\min _{C \in \mathcal{C}} \underset{(\tilde{x}, \cdot) \sim \mathcal{D}}{\mathbb{E}}[|C(\tilde{x})|], \text { subject to }(1)
$$</p>
<p>The assumption that $\hat{f}$ models true conditional probabilities may be a good approximation for LLMs trained on large-scale data with a proper scoring rule [11]; one can also obtain bounds on near-optimal average set size for CP using $\hat{f}$ that approximately models conditional probabilities [12, 10], but we omit these results for brevity. We emphasize that the CP coverage guarantees hold regardless of the accuracy of $\hat{f}$. Overall, CP is a powerful and easy-to-use statistical tool to produce (1) tight coverage guarantees-addressing the goal of calibrated confidence, and (2) small prediction sets for unseen data given a blackbox predictor like an LLM and an unknown data distribution-addressing our second goal of minimal help.</p>
<h3>3.2 Single-Step Uncertainty Alignment</h3>
<p>We now demonstrate how to use CP to achieve uncertainty alignment for LLM-based planning with a user-specified task completion rate $1-\epsilon$. We first consider a single-step setting, where the LLM plans only once given a context. For simplicity, we again drop the timestep superscript $t$ in this section.</p>
<p>Data collection. We collect $N$ i.i.d. scenarios from the distribution $\mathcal{D}$, and the corresponding contexts summarizing the robot observation and instruction (Section 2). We use the MCQA approach from Section 2 to generate candidate plans and then label each augmented context $\tilde{x}$ (i.e., context combined with plans)</p>
<p>with the correct label (here and in Section 3.3, we assume that there is a unique correct candidate plan; we provide an extension to multiple acceptable options in Section A3). We thus obtain a calibration set $Z=\left{z_{i}=\left(\hat{x}<em i="i">{i}, y</em>$ with pairs of augmented contexts and correct labels.}\right)\right}_{i=1}^{N</p>
<p>Calibration. Next we follow Section 3.1 to perform calibration: first adjust $\hat{\epsilon}$ to achieve the $1-\epsilon$ coverage based on Eq. (2) and then find the quantile $\hat{q}$. Given a new context $\hat{x}<em _test="{test" _text="\text">{\text {test }}$ (after MCQA in a new scenario) at test time, we can construct the calibration set $C\left(\hat{x}</em>$ with $1-\epsilon$ probability.}}\right)$ that contains $y_{\text {test }</p>
<p>Triggering help. If $C\left(\hat{x}<em _test="{test" _text="\text">{\text {test }}\right)$ is a singleton, the robot executes the corresponding plan. Otherwise, we deem the LLM uncertain over possible actions and trigger human help. The robot presents the human with $C\left(\hat{x}</em>$, or halts the operation otherwise. This setup turns the coverage guarantee from CP to the task completion guarantee:}}\right)$ (including the corresponding plans in text) and asks the human to choose one ${ }^{2}$. The human chooses $y_{\text {test }}$ if $y_{\text {test }} \in C\left(\hat{x}_{\text {test }}\right)^{2</p>
<p>Proposition 1 (Single-step uncertainty alignment) Consider a single-step setting where we use CP with coverage level $1-\epsilon$ to generate prediction sets and seek help whenever the set is not a singleton. With probability $1-\delta$ over the sampling of the calibration set, the task completion rate over new test scenarios drawn from $\mathcal{D}$ is at least $1-\epsilon$. If $\hat{f}$ models true conditional probabilities, the average prediction set size is minimized among possible prediction schemes that achieve $1-\epsilon$ completion rate.</p>
<p>The proof immediately follows from the fact that under the assumption of accurate human help, the robot fails only when the prediction set does not contain the true label; the prediction set minimality follows from Eq. (3). Thus, our approach addresses the goals of calibrated confidence and minimal help from Section 2.</p>
<h1>3.3 Multi-Step Uncertainty Alignment</h1>
<p>Now we extend the CP-based uncertainty alignment approach to settings where the LLM plans in multiple timesteps. This setting can be helpful when the LLM receives feedback from the environment or human between steps. However, the original CP formulation cannot be applied here since the context $x^{t}$ between steps are dependent; moreover, the robot's actions at step $t$ influence the distribution over contexts that the robot observes at future steps. Thus, the i.i.d. assumption for the coverage guarantee is no longer valid. Here, we present a novel extension of CP to multi-step settings that tackles this challenge.</p>
<p>Sequence-level calibration. The key ideas are to (i) lift the data to sequences, and (ii) perform calibration at the sequence level using a carefully designed nonconformity score function that allows for causal reconstruction of the prediction set at test time. Suppose that each data point consists of a sequence of augmented context $\bar{x}=\left(\bar{x}^{0}, \bar{x}^{1}, \ldots, \bar{x}^{T-1}\right)$ and true labels $\bar{y}=\left(y^{0}, y^{1}, \ldots, y^{T-1}\right)$, where $T$ is the time horizon and $\bar{x}^{t}$ arises from having performed the correct actions in previous steps. The distribution $\mathcal{D}$ over scenarios induces a distribution over data sequences. We can again collect a calibration set $\overline{\bar{Z}}=\left{\bar{z}<em i="i">{i}=\left(\bar{x}</em>}, \bar{y<em i="1">{i}\right)\right}</em>$ :}^{N}$. Next we use the lowest score over the timesteps as the score for the sequence ${ }^{4</p>
<p>$$
\hat{f}(\bar{x})<em _in_T_="\in[T]" t="t">{\bar{y}}:=\min </em>
$$} \hat{f}\left(x^{t}\right)_{y^{t}</p>
<p>With the standard calibration procedure in Section 3.1, we construct a sequence-level prediction set $\overline{C}\left(\bar{x}<em _test="{test" _text="\text">{\text {test }}\right):=\left{\bar{y} \in \mathcal{Y}^{T} \mid \hat{f}\left(\bar{x}</em>\right)}<em _test="{test" _text="\text">{\bar{y}} \geq 1-\hat{q}\right}$ for a new context sequence $\bar{x}</em>$.}}$ with the quantile $\hat{q</p>
<p>Causal reconstruction of $C(\bar{x})$ at test time. Note that $\overline{C}\left(\bar{x}<em _test="{test" _text="\text">{\text {test }}\right)$ is constructed with the full sequence $\bar{x}</em>}}$ at once. However, at test time, we do not see the entire sequence of contexts all at once but rather $x_{\text {test }}^{t}$ one at a time. We thus need to reconstruct $\overline{C}\left(\bar{x<em _test="{test" _text="\text">{\text {test }}\right)$ in a causal manner (i.e., always relying only on current and past information). Consider the causally constructed prediction set $C^{t}\left(x</em>\right)}}^{t}\right):=\left{y^{t} \mid \hat{f}\left(x_{\text {test }}^{t<em _test="{test" _text="\text">{y^{t}} \geq 1-\hat{q}\right}$ at time $t$ using the same quantile level $\hat{q}$ from the non-causal calibration above, and define $C\left(\bar{x}</em>}}\right):=C^{0}\left(x_{\text {test }}^{0}\right) \times C^{1}\left(x_{\text {test }}^{1}\right) \times \cdots \times C^{T-1}\left(x_{\text {test }}^{T-1}\right)$. We would like to obtain a lower bound on the sequence-level coverage: $\mathbb{P}\left(\bar{y<em _test="{test" _text="\text">{\text {test }} \in C\left(\bar{x}</em>\right)\right) \geq 1-\epsilon$.}</p>
<p>Claim 1 For any $\bar{y} \in \mathcal{Y}^{T}, \bar{y} \in \overline{C}\left(\bar{x}<em _test="{test" _text="\text">{\text {test }}\right) \Longleftrightarrow \bar{y} \in C\left(\bar{x}</em>\right)$.}</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Proposition 2 (Multi-step uncertainty alignment) Consider a multi-step setting where we use CP with coverage level $1-\epsilon$ to causally construct the prediction set and seek help whenever the set is not a singleton at each timestep. With probability $1-\delta$ over the sampling of the calibration set, the task completion rate over new test scenarios drawn from $\mathcal{D}$ is at least $1-\epsilon$. If $\hat{f}$ models true conditional probabilities, the average prediction set size is minimized among possible prediction schemes that achieve $1-\epsilon$ completion rate.</p>
<p>The proofs are deferred to Section A2. Claim 1 allows us to construct causal prediction sets from non-causal calibration. We then show that the sequence-level task completion rate guarantee still holds.</p>
<p>Multiple acceptable options. Often, there can be multiple acceptable options at the same timestep, e.g., the task is to bring the human a soda, and either the Coke or Sprite on the table is acceptable. In such settings, we would like the prediction set to contain at least one acceptable option. We extend our method and confidence guarantees to this setting for both single- and multi-step problems in Section A3 and Section A4.</p>
<h1>4 Experiments</h1>
<p>We evaluate our framework in a diverse set of language-instructed tasks and environments below, and demonstrate its effectiveness in achieving a user-specified task completion rate while minimizing user help. We use PaLM-2L [13] as the LLM in all examples unless otherwise noted.</p>
<p>Scenario Distribution and Calibration Dataset. KNOWNo can be applied to unknown scenario distribution if one can collect i.i.d. samples from it for calibration. In future deployment, we envision that a robot can interact with an end-user (e.g., in a home) to collect a dataset through interactions with the human; the human can provide their true intentions during this data collection phase. For experiments here, we assume that the human faithfully provides help. We parameterize the scenario distribution for each experiment with details shown in Section A7. Each calibration dataset is then generated by random sampling from the corresponding distribution. Labeling the calibration data takes about 4 hours (for 400 examples) in the multi-step setting and 1.5 hours in single-step settings.</p>
<p>Baselines. A straightforward way to construct prediction sets given a desired $1-\epsilon$ coverage is to rank options according to confidence and construct a set such that the cumulative confidence exceeds $1-\epsilon$; we consider two baselines that are based on such cumulative thresholding but use different kinds of scores: Simple Set uses the same $\hat{f}$ as KNOWNo; Ensemble Set [14] instead uses the frequencies of the LLM outputting $y \in \mathcal{Y}$ (out of 20 trials total) with randomized sampling of few-shot examples in the prompt. However, the resulting prediction sets are not guaranteed to achieve $1-\epsilon$ coverage as the probabilities can be miscalibrated [15], and often include additional unnecessary options [16]. Instead of using cumulative thresholding, KNOWNo constructs prediction sets by including options with scores higher than a threshold computed using CP, which results in statistical guarantees. We also introduce two prompt-based baselines: Prompt Set prompts the LLM to directly output the prediction set (e.g., "Prediction set: [A, C]"); Binary prompts the LLM to directly output a binary indicator for uncertainty (e.g., "Certain/Uncertain: Certain"), which is used in other LLM-based planning work [2] for triggering human intervention. Note that the $\epsilon$ level is not used in Prompt Set or Binary, and so the user cannot explicitly control the task success rate. Lastly, we consider No Help where the option with the highest score is always executed without any human intervention.</p>
<h3>4.1 Simulation: Tabletop Rearrangement</h3>
<p>A robot arm is asked to rearrange objects on a table in the PyBullet simulator [17] (Fig. 1 right top). Each scenario is initialized with three bowls and blocks of green, yellow, and blue colors. The task is to move a certain number of blocks or bowls towards a different object or at a specific location around it. We introduce three settings based on different types of ambiguities in the user instruction: (1) Attribute (e.g., referring to the bowl with the word "receptacle"), (2) Numeric (e.g., under-specifying the number of blocks to be moved by saying "a few blocks"), and (3) Spatial (e.g., "put the yellow block next to the green bowl", but the human has a preference over placing it at the front/back/left/right). For each setting,
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Deviation from specified task success level $1-\epsilon=0.85$ to the empirical success rate for the three settings in Simulation. 200 trials are run for each method/setting.</p>
<p>we construct a distribution over scenarios (detailed in Section A7) and perform experiments separately. This is a single-step setting with single acceptable option per step.</p>
<p>KNOwNO achieves target task success rate consistently. First, we investigate whether KnowNo and the baselines achieve a given target task success rate consistently in the three settings - we set the failure level $\epsilon=0.15$. In Fig. 3 we show the difference between achieved and target rates for all methods. Results show that KnowNo achieve the least deviations overall, due to the coverage guarantee from CP. Simple Set and Ensemble Set cannot achieve coverage consistently. Prompt Set, Binary, and No Help have larger deviations from the target since the user has no control over the error rate. Also, as the scenarios get increasingly ambiguous (least in Attribute and most in Spatial), the baselines show larger deviations.</p>
<p>KnowNo achieves high task success rate with lower human help as $\epsilon$ varies. In Fig. 4 we vary the target error rate $\epsilon$ and show the curves of task success rate vs. prediction set size and human help rate averaged over the three settings. For KnowNo, Simple Set, and Ensemble Set, specifying a lower $\epsilon$ improves the empirical task success rate while also requiring more human help. The most natural comparison is between KnowNo and Simple Set, as both use next-token probabilities from the LLM as the confidence score. KnowNo achieves higher success-to-help ratios across $\epsilon$ levels, thanks to calibrated confidence from CP. Meanwhile, Prompt Set and Binary do not allow controlling success rates. Prompt Set performs the worst, indicating the challenge of prompting-based methods for calibrated prediction sets. Binary works favorably at some success levels, but lacks flexibility and doesn't provide prediction sets for human feedback. In addition, Fig. A10 shows the results for individual ambiguity settings. As the scenarios become more ambiguous, KnowNo shows a greater reduction of human help compared to Simple Set as much as $24 \%$ at certain success levels.</p>
<p>Ensemble Set can perform well but is computationally expensive. Fig. 4 also shows that Ensemble Set provides high task success rate with small amount of human help at higher $\epsilon$ levels. However, there are two main drawbacks. First, we find in some scenarios that even with 20 randomized prompts, the LLM can fail to choose the correct option and thus assigns zero probability to it. As shown in Fig. 4, this means that Ensemble Set can fail to improve once it reaches some level of human help. Second, it requires $20 \times$ inference time compared to other methods. Investigating how to lower the computational burden and combining ensemble-based probabilities with CP can be a fruitful future direction.</p>
<h1>4.2 Hardware: Multi-Step Tabletop Rearrangement</h1>
<p>In this example, a UR5 robot arm is asked to sort a variety of toy food items on a table (Fig. 5 left). In each scenario, three items are placed on the table initially, and the task is to sort them based on human preferences; we simulate a human with strong preferences for healthy food like eggs and fruits, and dislike for less healthy food like donuts and Skittles candies. To introduce ambiguities, the context for the LLM reveals only a subset of the preferences. Here we consider a multi-step setting with possibly multiple acceptable options per step - the LLM plans the new step conditioned on the previous action taken.</p>
<p>KnowNo reduces step-wise and trial-wise intervention rates in multi-step setting. Since Section 4.1 has shown that Ensemble Set can be expensive (even more so in the multi-step setting) and Prompt Set and Binary can fail to achieve the user-specified success level, we focus on comparing KnowNo with Simple Set for the remainder of the evaluation. Here we set the desired error level $\epsilon=0.25$. Since Simple Set does not provide calibrated coverage, we first find $\epsilon=0.42$ for Simple Set to achieve the same planning error rate as KnowNo in simulation. Then we run 50 trials for both methods in hardware. Table 1 shows</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: (Left) Multi-step CP is applied in Hardware Tabletop Rearrangement. (Right) CP models ambiguity in possible human locations and triggers clarification from the human in Bimanual.
that KNOWNO reduces the human help rate by $14 \%$ step-wise and $8 \%$ trial-wise, while also reducing the average prediction set size. Compared to Simple Set which uses a much higher $\epsilon$, KNOWNO achieves the specified trial-level task success rate precisely by leveraging the Multi-Step Uncertainty Alignment from Sec. 3.3. We also find that if we set $\epsilon=0.25$ for Simple Set, the planner is grossly over-conservative and requires a step-wise help rate of $87 \%$.</p>
<p>Bimanual manipulation. We additionally present results for a bimanual object rearrangement setup where ambiguities arise from the choice of the arm due to the limited reachability of each arm (Fig. 5 right); results are deferred to Section A5.</p>
<h3>4.3 Hardware: Mobile Manipulator in a Kitchen</h3>
<p>In this example, each scenario involves a mobile manipulator in front of a countertop and next to a set of recycling/compost/landfill bins in an office kitchen (Fig. 1). The tasks include picking up some object from the counter, and possibly putting it in the drawer, or disposing of it in one of the bins. For the distribution of possible scenarios, we introduce new types of ambiguities based on Winograd Schemas [18] (e.g., "There is an apple and bottled water on the counter...it is rotten. Can you dispose of it?"), and ones that potentially involve unsafe actions (e.g., "place the bowl in the microwave."; there is a plastic bowl and a metal bowl, but only the plastic one is safe for the microwave). This is a single-step setting with multiple acceptable options. In Table 2, we compare KNOWNO to Simple Set again by first setting $\epsilon=0.15$ and also finding $\epsilon=0.24$ for Simple Set that achieves the same plan success rate in simulation. The hardware experiment results again show that KNOWNO reduces the human help rate by $14 \%$ and also reduces the average prediction set size.</p>
<p>Target success guarantee from KnowNo is robust to varying LLM choice. We also run KnowNo with two other LLMs (without hardware evaluation). First, we use an instruction-finetuned version of PaLM-2L (PaLM-2L-IF); there is no significant performance difference from PaLM-2L; however, it generates smaller prediction sets in general by reducing the number of larger prediction sets (size 3 and 4) significantly. Second, we run GPT-3.5 (text-davinci-003) from OpenAI. However, we find that it exhibits significant MCQA bias towards options D and E and against A and B, affecting the overall performance. Nonetheless, KnowNo still achieves $1-\epsilon$ target success rate, as the coverage guarantee from CP makes no assumption about the LLM confidences (e.g., calibrated or accurate) — KnowNo flexibly compensates for the degraded LLM performance by triggering more human intervention.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">1- $\epsilon$</th>
<th style="text-align: center;">Plan Succ</th>
<th style="text-align: center;">Task Succ</th>
<th style="text-align: center;">Set Size</th>
<th style="text-align: center;">Help-Step Help-Trial</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">KnowNo</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">1.72</td>
<td style="text-align: center;">0.58</td>
</tr>
<tr>
<td style="text-align: center;">Simple Set</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">2.04</td>
<td style="text-align: center;">0.72</td>
</tr>
<tr>
<td style="text-align: center;">No Help</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>Table 1: Results for Hardware Multi-Step Tabletop
Rearrangement. Plan success rate is fixed between KNOWNO and Simple Set for comparing the other metrics.</p>
<p>Table 2: Results for Hardware Mobile Manipulation. Plan success rate is fixed between KNOWNO and Simple Set to compare the other metrics.</p>
<h1>5 Related Work</h1>
<p>LLMs for robot planning and interaction. Large language models have shown a wide range of capabilities: reasoning [19, 20], logic [21, 22], math [23], physics [24, 25], high-level planning [1, 26, 27, 28, 29, 30] with language feedback [31, 2], and writing robot code [5, 32, 33]. The generated outputs can be guided to a certain extent with sufficient prompting, but LLMs are still prone to confidently hallucinating outputs (e.g., referring to objects not observed in the scene [31], or calling motion primitive APIs that may not exist [5]). We hypothesize that these challenges can be alleviated while obtaining statistical guarantees by modeling the uncertainty of LLMs [34] and generating prediction sets via CP.
Uncertainty quantification for LLMs. Motivated by LLMs' overconfidence and hallucinations, there has been a growing body of work in quantifying and better calibrating uncertainty [35, 36, 37, 38, 39, 40, 41]. In contrast to typical calibration methods that associate uncertainty with point-valued outputs, CP-based methods for language modeling provide coverage guarantees for set-valued predictors [42, 43, 44, 45]. However, there have been few applications of CP in quantifying uncertainty of LLMs with free-form outputs [46]: Kumar et al. [47] apply CP to next-token prediction in MCQA tasks exclusively, while KnOwNO builds on MCQA but is applicable to general natural language generation tasks.</p>
<p>Conformal prediction in robotics. To the best of our knowledge, this work is the first to employ CP for language-based planning. Prior work has utilized CP for fault detection, trajectory prediction, and planning in dynamic environments [48, 49, 50, 51]. At each point in the planning horizon, the probabilistic safety guarantee either holds on average [51, 48], or is too conservative due to union bounding [49], or requires additional calibration data to reduce conservatism [50]. In contrast, we provide a novel multi-step extension to CP to guarantee correctness for the entire planning horizon by performing sequence-level calibration in settings where the robot's actions influence the distribution of future inputs.</p>
<p>Human-robot dialogue and interaction. KNOWNO builds off previous work in robotics that addresses effective human-robot interaction through dialogue in both simulation and on hardware [52, 53, 54, 55]. KNOWNO uses a relatively simple setup between robot and human such that the human specifies potentially ambiguous instruction and clarifies it when the robot deems necessary; such setup does not consider human providing information related to robot observation or possible human error.</p>
<h2>6 Discussion</h2>
<p>Summary: We propose KNOWNO, a framework that applies conformal prediction (CP) to address the problem of uncertainty alignment for language-instructed robots, which we formalize as providing statistical guarantees of task completion while minimizing human help. Experiments across a variety of simulated and hardware setups demonstrate that KNOWNO achieves user-specified task completion levels consistently while reducing human help by $10-24 \%$ compared to baseline approaches that lack formal assurances.</p>
<p>Limitations and future work: The primary limitation of our work is that the task completion guarantee assumes environments (objects) are fully grounded in the text input to the LLM, and the actions proposed by the LLM planner can be executed successfully. In the future, we are looking to incorporate uncertainty of the perception module (e.g., vision-language model) and the low-level action policy (e.g., languageconditioned affordance prediction) into the CP calibration. Another limitation is that, for the task guarantee to hold, the human needs to faithfully provide help when the robot needs it. Future work could also incorporate human modeling/error in the conformal prediction framework. Another exciting direction is to combine our methods with active preference learning [56, 57, 58, 59] to generate open-ended queries that maximally reduce uncertainty about human preferences. On the theoretical front, modifying CP to optimize different metrics for human help (e.g., minimizing human intervention rate by maximizing number of singleton sets) would be of practical interest. Overall, we hope that the work presented here spurs further efforts towards uncertainty alignment for safe and reliable language-instructed robots.</p>
<h2>Acknowledgments</h2>
<p>This work was partially supported by the NSF CAREER Award [#2044149] and the Office of Naval Research [N00014-23-1-2148]. We thank Chad Boodoo for helping set up the UR5 hardware experiments, and Jensen Gao, Nathaniel Simon, and David Snyder for their helpful feedback on the paper.</p>
<h1>References</h1>
<p>[1] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al. Do as I can, not as I say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691, 2022.
[2] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, P. Sermanet, T. Jackson, N. Brown, L. Luu, S. Levine, K. Hausman, and B. Ichter. Inner monologue: Embodied reasoning through planning with language models. In 6th Annual Conference on Robot Learning, 2022. URL https://openreview.net/forum?id=3R3Pz5i0tye.
[3] V. Vovk, A. Gammerman, and G. Shafer. Algorithmic Learning in a Random World, volume 29. Springer, 2005.
[4] A. N. Angelopoulos, S. Bates, et al. Conformal prediction: A gentle introduction. Foundations and Trends® in Machine Learning, 16(4):494-591, 2023.
[5] J. Liang, W. Huang, F. Xia, P. Xu, K. Hausman, B. Ichter, P. Florence, and A. Zeng. Code as policies: Language model programs for embodied control. arXiv preprint arXiv:2209.07753, 2022.
[6] K. Murray and D. Chiang. Correcting length bias in neural machine translation. arXiv preprint arXiv:1808.10006, 2018.
[7] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.
[8] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.
[9] V. Vovk. Conditional validity of inductive conformal predictors. In Asian Conference on Machine Learning, pages 475-490. PMLR, 2012.
[10] M. Sadinle, J. Lei, and L. Wasserman. Least ambiguous set-valued classifiers with bounded error levels. Journal of the American Statistical Association, 114(525):223-234, 2019.
[11] Z. Jiang, J. Araki, H. Ding, and G. Neubig. How can we know when language models know? on the calibration of language models for question answering. Transactions of the Association for Computational Linguistics, 9: $962-977,2021$.
[12] Y. Bai, S. Mei, H. Wang, Y. Zhou, and C. Xiong. Efficient and differentiable conformal prediction with general function classes. arXiv preprint arXiv:2202.11091, 2022.
[13] Google. PaLM 2 technical report, 2023.
[14] Y. Lu, M. Bartolo, A. Moore, S. Riedel, and P. Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786, 2021.
[15] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, pages 1321-1330. PMLR, 2017.
[16] A. Angelopoulos, S. Bates, J. Malik, and M. I. Jordan. Uncertainty sets for image classifiers using conformal prediction. arXiv preprint arXiv:2009.14193, 2020.
[17] E. Coumans and Y. Bai. Pybullet, a python module for physics simulation for games, robotics and machine learning. http://pybullet.org, 2016-2022.
[18] H. Levesque, E. Davis, and L. Morgenstern. The winograd schema challenge. In Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning, 2012.
[19] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. Chi, Q. Le, and D. Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.
[20] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.
[21] M. Suzgun, N. Scales, N. Schärli, S. Gehrmann, Y. Tay, H. W. Chung, A. Chowdhery, Q. V. Le, E. H. Chi, D. Zhou, et al. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022.</p>
<p>[22] A. Creswell, M. Shanahan, and I. Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning. In The Eleventh International Conference on Learning Representations, 2023. URL https: //openreview.net/forum?id=3Pf3Wg6o-A4.
[23] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, et al. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858, 2022.
[24] R. Liu, J. Wei, S. S. Gu, T.-Y. Wu, S. Vosoughi, C. Cui, D. Zhou, and A. M. Dai. Mind's eye: Grounded language model reasoning through simulation. arXiv preprint arXiv:2210.05359, 2022.
[25] A. Z. Ren, B. Govil, T.-Y. Yang, K. R. Narasimhan, and A. Majumdar. Leveraging language for accelerated learning of tool manipulation. In Conference on Robot Learning, 2023.
[26] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International Conference on Machine Learning, pages 9118-9147. PMLR, 2022.
[27] Y. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh. Translating natural language to planning goals with large-language models. arXiv preprint arXiv:2302.05128, 2023.
[28] Y. Ding, X. Zhang, C. Paxton, and S. Zhang. Task and motion planning with large language models for object rearrangement. arXiv preprint arXiv:2303.06247, 2023.
[29] B. Liu, Y. Jiang, X. Zhang, Q. Liu, S. Zhang, J. Biswas, and P. Stone. LLM+P: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477, 2023.
[30] J. Wu, R. Antonova, A. Kan, M. Lepert, A. Zeng, S. Song, J. Bohg, S. Rusinkiewicz, and T. Funkhouser. Tidybot: Personalized robot assistance with large language models. arXiv preprint arXiv:2305.05658, 2023.
[31] A. Zeng, M. Attarian, B. Ichter, K. Choromanski, A. Wong, S. Welker, F. Tombari, A. Purohit, M. Ryoo, V. Sindhwani, J. Lee, V. Vanhoucke, and P. Florence. Socratic models: Composing zero-shot multimodal reasoning with language. arXiv preprint arXiv:2204.00598, 2022.
[32] I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay, D. Fox, J. Thomason, and A. Garg. Progprompt: Generating situated robot task plans using large language models. arXiv preprint arXiv:2209.11302, 2022.
[33] E. Zelikman, Q. Huang, G. Poesia, N. D. Goodman, and N. Haber. Parsel: A (de-) compositional framework for algorithmic reasoning with language models. arXiv preprint arXiv:2212.10561, 2023.
[34] J. Park, S. Lim, J. Lee, S. Park, Y. Yu, and S. Choi. Clara: Classifying and disambiguating user commands for reliable interactive robotic agents. arXiv preprint arXiv:2306.10376, 2023.
[35] K. Zhou, D. Jurafsky, and T. Hashimoto. Navigating the grey area: Expressions of overconfidence and uncertainty in language models. arXiv preprint arXiv:2302.13439, 2023.
[36] Y. Xiao and W. Y. Wang. Quantifying uncertainties in natural language processing tasks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 7322-7329, 2019.
[37] Y. Xiao, P. P. Liang, U. Bhatt, W. Neiswanger, R. Salakhutdinov, and L.-P. Morency. Uncertainty quantification with pre-trained language models: A large-scale empirical analysis. arXiv preprint arXiv:2210.04714, 2022.
[38] L. Kuhn, Y. Gal, and S. Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. arXiv preprint arXiv:2302.09664, 2023.
[39] S. Kadavath, T. Conerly, A. Askell, T. Henighan, D. Drain, E. Perez, N. Schiefer, Z. Hatfield-Dodds, N. DasSarma, E. Tran-Johnson, S. Johnston, S. El-Showk, A. Jones, N. Elhage, T. Hume, A. Chen, Y. Bai, S. Bowman, S. Fort, D. Ganguli, D. Hernandez, J. Jacobson, J. Kernion, S. Kravec, L. Lovitt, K. Ndousse, C. Olsson, S. Ringer, D. Amodei, T. Brown, J. Clark, N. Joseph, B. Mann, S. McCandlish, C. Olah, and J. Kaplan. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022.
[40] S. Lin, J. Hilton, and O. Evans. Teaching models to express their uncertainty in words. arXiv preprint arXiv:2205.14334, 2022.
[41] S. J. Mielke, A. Szlam, E. Dinan, and Y.-L. Boureau. Reducing conversational agents' overconfidence through linguistic calibration. Transactions of the Association for Computational Linguistics, 10:857-872, 2022.
[42] T. Schuster, A. Fisch, T. Jaakkola, and R. Barzilay. Consistent accelerated inference via confident adaptive transformers. arXiv preprint arXiv:2104.08803, 2021.</p>
<p>[43] T. Schuster, A. Fisch, J. Gupta, M. Dehghani, D. Bahri, V. Tran, Y. Tay, and D. Metzler. Confident adaptive language modeling. Advances in Neural Information Processing Systems, 35:17456-17472, 2022.
[44] N. Dey, J. Ding, J. Ferrell, C. Kapper, M. Lovig, E. Planchon, and J. P. Williams. Conformal prediction for text infilling and part-of-speech prediction. The New England Journal of Statistics in Data Science, 1(1):69-83, 2022. ISSN 2693-7166. doi:10.51387/22-NEJSDS8.
[45] P. Giovannotti and A. Gammerman. Transformer-based conformal predictors for paraphrase detection. In Conformal and Probabilistic Prediction and Applications, pages 243-265. PMLR, 2021.
[46] V. Quach, A. Fisch, T. Schuster, A. Yala, J. H. Sohn, T. S. Jaakkola, and R. Barzilay. Conformal language modeling. arXiv preprint arXiv:2306.10193, 2023.
[47] B. Kumar, C. Lu, G. Gupta, A. Palepu, D. Bellamy, R. Raskar, and A. Beam. Conformal prediction with large language models for multi-choice question answering. arXiv preprint arXiv:2305.18404, 2023.
[48] R. Luo, S. Zhao, J. Kuck, B. Ivanovic, S. Savarese, E. Schmerling, and M. Pavone. Sample-efficient safety assurances using conformal prediction. In Algorithmic Foundations of Robotics XV, pages 149-169, Cham, 2023. Springer International Publishing. ISBN 978-3-031-21090-7.
[49] L. Lindemann, M. Cleaveland, G. Shim, and G. J. Pappas. Safe planning in dynamic environments using conformal prediction. arXiv preprint arXiv:2210.10254, 2022.
[50] L. Lindemann, X. Qin, J. V. Deshmukh, and G. J. Pappas. Conformal prediction for STL runtime verification. In Proceedings of the ACM/IEEE 14th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2023), pages 142-153, 2023.
[51] A. Dixit, L. Lindemann, S. Wei, M. Cleaveland, G. J. Pappas, and J. W. Burdick. Adaptive conformal prediction for motion planning among dynamic agents. arXiv preprint arXiv:2212.00278, 2022.
[52] J. Thomason, M. Murray, M. Cakmak, and L. Zettlemoyer. Vision-and-dialog navigation. In Conference on Robot Learning, pages 394-406. PMLR, 2020.
[53] A. Padmakumar, J. Thomason, A. Shrivastava, P. Lange, A. Narayan-Chen, S. Gella, R. Piramuthu, G. Tur, and D. Hakkani-Tur. Teach: Task-driven embodied agents that chat. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 2017-2025, 2022.
[54] X. Gao, Q. Gao, R. Gong, K. Lin, G. Thattai, and G. S. Sukhatme. Dialfred: Dialogue-enabled agents for embodied instruction following. IEEE Robotics and Automation Letters, 7(4):10049-10056, 2022.
[55] S. Banerjee, J. Thomason, and J. Corso. The robotslang benchmark: Dialog-guided robot localization and navigation. In Conference on Robot Learning, pages 1384-1393. PMLR, 2021.
[56] D. Sadigh, A. D. Dragan, S. S. Sastry, and S. A. Seshia. Active preference-based learning of reward functions. In Proceedings of Robotics: Science and Systems (RSS), July 2017. doi:10.15607/RSS.2017.XIII. 053.
[57] E. Biyik. Learning Preferences For Interactive Autonomy. PhD thesis, EE Department, Stanford University, 2022.
[58] D. S. Brown, W. Goo, and S. Niekum. Better-than-demonstrator imitation learning via automatically-ranked demonstrations. In Conference on Robot Learning, pages 330-359. PMLR, 2020.
[59] V. Myers, E. Biyik, and D. Sadigh. Active reward learning from online preferences. In International Conference on Robotics and Automation (ICRA), 2023.
[60] A. Kamath, M. Singh, Y. LeCun, G. Synnaeve, I. Misra, and N. Carion. MDETR-modulated detection for end-to-end multi-modal understanding. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1780-1790, 2021.
[61] M. Minderer, A. Gritsenko, A. Stone, M. Neumann, D. Weissenborn, A. Dosovitskiy, A. Mahendran, A. Arnab, M. Dehghani, Z. Shen, et al. Simple open-vocabulary object detection with vision transformers. arXiv preprint arXiv:2205.06230, 2022.
[62] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo, P. Dollár, and R. Girshick. Segment anything. arXiv:2304.02643, 2023.
[63] V. Agafonkin. Polylabel: a fast algorithm for finding the pole of inaccessibility of a polygon, July 2016. URL https://github.com/mapbox/polylabel.</p>
<p>[64] S. Singh, J.-J. Slotine, and V. Sindhwani. Optimizing trajectories with closed-loop dynamic SQP. In 2022 International Conference on Robotics and Automation (ICRA), pages 5249-5254. IEEE, 2022.
[65] A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, J. Dabis, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, J. Hsu, et al. RT-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:2212.06817, 2022.</p>
<h1>A1 Evaluating Semantic Uncertainty of the LLM with MCQA</h1>
<p>Here we provide additional rationale of using the MCQA setup for evaluating LLM uncertainty. The uncertainty of the language model can be thought of as the predictive entropy of the output distribution. Consider the input tokens $x=\left(\sigma_{i}, \ldots \sigma_{k}\right)$ and the output distribution $Y$ where $y=\left(\sigma_{i}, \ldots \sigma_{k}\right) \in Y$ :</p>
<p>$$
U(x):=H(Y \mid x)=-\int p(y \mid x) \ln p(y \mid x) d y
$$</p>
<p>Evaluating this is very challenging for LLMs: the output distribution over $Y$ lies on the space of dimension $\mathcal{O}\left(|\mathcal{T}|^{k-i+1}\right)$ where $\mathcal{T}$ is the set of possible tokens, and it has to be evaluated with a large number of samples and Monte-Carlo integration. Among the samples, there is also the bias against longer sequences [6].
We are partially inspired by Kuhn et al. [38] that instead consider the semantic uncertainty of the model: among samples in $Y$, there are groups of samples that have the same semantic meanings, such as "put the sponge in the top drawer by first opening it" and "open the top drawer and put the sponge in it". They may differ in $p(y \mid x)$ but we are not concerned with such uncertainty since it does not reflect the uncertainty of the LLM about the scenario. Kuhn et al. [38] addresses this by first sampling a large number of samples from $Y$, and then grouping them based on some semantics classifier before evaluating the semantic uncertainty, which is the predictive entropy over the groups instead of over $Y$.
Could we improve the efficiency of finding semantically distinct groups in $Y$ ? The MCQA setup that we propose addresses this by prompting the LLM to generate likely, and also semantically different, options given the task using few-shot exemplars. We can think of this as splitting the output space $Y$ into multiple spaces representing semantically different outputs. MCQA first samples the representative outputs from the spaces with higher weights in $Y$ (top four), and then includes the additional option "an option not listed here" to cover rest of the spaces. Unlike Kuhn et al. [38] who calculate the entropy among the groups to decide whether to trust the answer to a question, KNOWNO instead combines the normalized probabilities with conformal prediction to provide set-based predictions with coverage guarantees.</p>
<h2>A2 Proofs for CP in Multi-Step Setting</h2>
<div class="codehilite"><pre><span></span><code>Algorithm 1 Multi-step LLM planning with human help.
    for time \(t \leftarrow 0\) to \(T-1\) do
        Observe input \(x_{\text {test }}^{t}\) and predict the set \(C\left(x_{\text {test }}^{t}\right)\)
        if \(C\left(x_{\text {test }}^{t}\right)\) is a singleton then
            Execute the action in \(C\left(x_{\text {test }}^{t}\right)\)
        else
            Ask for human help
        end if
    end for
</code></pre></div>

<p>Proof of Claim 1: Suppose $\bar{y} \in \overline{C}\left(\bar{x}_{\text {test }}\right)$. We have,</p>
<p>$$
\begin{aligned}
\bar{y} \in \overline{C}\left(\bar{x}<em t="t">{\text {test }}\right) &amp; \Longleftrightarrow \min </em>\right)} \hat{f}\left(x_{\text {test }}^{t<em _test="{test" _text="\text">{y^{t}} \geq 1-\hat{q} \
&amp; \Longleftrightarrow \hat{f}\left(x</em>\right)}}^{t<em _test="{test" _text="\text">{y^{t}} \geq 1-\hat{q}, \quad \forall t \in[T] \
&amp; \Longleftrightarrow y^{t} \in C^{t}\left(x</em>\right), \quad \forall t \in[T] \
&amp; \Longleftrightarrow \bar{y} \in C\left(\bar{x}_{\text {test }}\right) .
\end{aligned}
$$}}^{t</p>
<p>Proof of Proposition 2: Since we can bound the probability that $\bar{y}<em _test="{test" _text="\text">{\text {test }} \notin \overline{C}\left(\bar{x}</em>}}\right)$, we can also bound the probability that $\bar{y<em _test="{test" _text="\text">{\text {test }} \notin C\left(\bar{x}</em>$, we have}}\right)$. From the conformalization procedure, we have the following datasetconditional guarantee: with probability $1-\delta$ over the sampling of the calibration set $\bar{Z</p>
<p>$$
\begin{aligned}
\mathbb{P}\left(\bar{y}<em _test="{test" _text="\text">{\text {test }} \in \overline{C}\left(\bar{x}</em>}}\right) \mid \bar{Z}\right) &amp; \geq \operatorname{Beta<em _test="{test" _text="\text">{\mathcal{N}+1-v, v}^{-1}(\delta), \quad v=\lfloor(N+1) \bar{\epsilon}\rfloor \
\stackrel{\text { Claim 1 }}{ } \mathbb{P}\left(\bar{y}</em>}} \in C\left(\bar{x<em _mathcal_N="\mathcal{N">{\text {test }}\right) \mid \bar{Z}\right) &amp; \geq \operatorname{Beta}</em>(\delta),
\end{aligned}
$$}+1-v, v}^{-1</p>
<p>where $\hat{\epsilon}$ is chosen such that $\epsilon=1-\operatorname{Beta}_{N+1-v, v}^{-1}(\delta)$. Hence, the following marginal guarantee also holds:</p>
<p>$$
\begin{aligned}
\mathbb{P}\left(\bar{y}<em _test="{test" _text="\text">{\text {test }} \in \bar{C}\left(\bar{x}</em> \
\stackrel{\text { Claim 1 }}{=} \mathbb{P}\left(\bar{y}}}\right)\right) &amp; \geq 1-\hat{\epsilon<em _test="{test" _text="\text">{\text {test }} \in C\left(\bar{x}</em>
\end{aligned}
$$}}\right)\right) &amp; \geq 1-\hat{\epsilon</p>
<p>This result provides a bound on the task completion rate if $\bar{x}_{\text {test }}$ is drawn using the distribution $\mathcal{D}$. However, recall that the sequence $\bar{x}$ of augmented contexts as defined in Section 3.3 arises from having performed the correct actions in previous steps; incorrect actions may result in a distribution shift. In order to obtain a bound on the task completion rate, we consider three cases at any given timestep: (1) the prediction set is a singleton and contains the correct label, (2) the prediction set is not a singleton but does contain the correct label, and (3) the prediction set does not contain the true label. The robot performs the correct action in the first two cases (without help in (1) and with help in (2)), while CP bounds the probability of case (3). Thus, the CP bound translates to a bound on the task success rate.
As seen in Eq. (3), we have from [10, Thm. 1], that we achieve the smallest average set size among all possible sequence-level prediction schemes, $\overline{\mathcal{C}}$, if $\hat{f}$ models the prediction uncertainty accurately,</p>
<p>$$
\min _{\bar{C} \in \overline{\mathcal{C}}} \underset{\left(\bar{x}, \cdot\right) \sim \mathcal{D}}{\mathbb{E}}\left[|\bar{C}(\bar{x})|\right], \text { subject to } \mathbb{P}(\bar{y} \in \bar{C}(\bar{x})) \geq 1-\hat{\epsilon}
$$</p>
<h1>A3 CP in Settings with Multiple Acceptable Options Per Step</h1>
<p>Proposition 3 (Multi-label uncertainty alignment) Consider a setting where we use CP with coverage level $1-\epsilon$ to construct the prediction set when there are multiple true labels and seek help whenever the set is not a singleton at each timestep. With probability $1-\delta$ over the sampling of the calibration set, the task completion rate over new test scenarios drawn from $\mathcal{D}$ is at least $1-\epsilon$.</p>
<p>Proof: We have a dataset of $Z=\left{\left(\hat{x}<em i="i">{i}, Y</em>\right), \ldots\right}<em i="i">{i=1}^{N}$ sampled i.i.d. from a data distribution $\mathcal{D}$ for calibration (we use the same notation $\mathcal{D}$ as in the single-label setting here), where $Y</em>\right}}:=\left{y_{i, j<em i="i">{j=1}^{J</em> \in[0,1]$.
We define an operator $\beta: \mathcal{X} \times \mathcal{Y}^{J} \rightarrow \mathcal{Y}$ where $\mathcal{X}$ is the space of contexts and $\mathcal{Y}$ is the space of labels:}}$ is the set of true labels for a single trial. For each label, we use the same heuristic notion of confidence, $\hat{f}(x)_{y</p>
<p>$$
\beta(x, Y):=\underset{y \in Y}{\operatorname{argmax}} \hat{f}(x)_{y}
$$</p>
<p>which takes the true label with the highest confidence value from the true label set.
If we consider applying $\beta$ to every point in the support of $\mathcal{D}$, a new distribution $\mathcal{D}^{\prime}$ is induced. We also consider the induced dataset of samples $S^{\prime}=\left{\left(x_{i}, y_{i}^{\max }\right)\right}<em i="i">{i=1}^{N}$, where $y</em>\right)$. Then we can perform the usual conformalization and obtain the guarantee that with}^{\max }:=\beta\left(x_{i}, Y_{i</p>
<p>$$
C\left(x_{\text {test }}\right):=\left{y \mid \hat{f}\left(x_{\text {test }}\right)_{y} \geq 1-\hat{q}\right}
$$</p>
<p>the following marginal guarantee holds,</p>
<p>$$
\begin{gathered}
\mathbb{P}\left(y_{\text {test }}^{\max } \notin C\left(x_{\text {test }}\right)\right) \leq \hat{\epsilon} \
\Rightarrow \mathbb{P}\left(\underset{y \in Y_{\text {test }}}{\operatorname{argmax}} \hat{f}\left(x_{\text {test }}\right)<em _test="{test" _text="\text">{y} \notin C\left(x</em> \
\Rightarrow \mathbb{P}\left(\beta\left(x_{\text {test }}, Y_{\text {test }}\right) \notin C\left(x_{\text {test }}\right)\right) \leq \hat{\epsilon}
\end{gathered}
$$}}\right)\right) \leq \hat{\epsilon</p>
<p>and the following dataset-conditional guarantee holds when we choose $\hat{\epsilon}$ such that $\epsilon=1-\operatorname{Beta}_{N+1-v, v}^{-1}(\delta)$ where $v=\lfloor(N+1) \hat{\epsilon}\rfloor$,</p>
<p>$$
\mathbb{P}\left(\beta\left(x_{\text {test }}, Y_{\text {test }}\right) \in C\left(x_{\text {test }}\right) \mid Z\right) \geq 1-\epsilon
$$</p>
<p>Hence, $C\left(x_{\text {test }}\right)$ contains the true label with the highest confidence with probability at least $1-\epsilon$.
At test time, we sample $\left(x_{\text {test }}, Y_{\text {test }}\right)$ from $\mathcal{D}$ that is i.i.d. with samples in $S$ - for the guarantee to hold for $\beta\left(x_{\text {test }}, Y_{\text {test }}\right)$, we need to show $\beta\left(x_{\text {test }}, Y_{\text {test }}\right)$ is a sample from $\mathcal{D}^{\prime}$ that is i.i.d. with samples in $S^{\prime}$. This is true since functions of independent random variables are independent, and functions of identically distributed random variables are identically distributed if the functions are measurable.</p>
<h1>A4 CP in Multi-Step Setting with Multiple Acceptable Options Per Step</h1>
<p>Proposition 4 (Multi-step, multi-label uncertainty alignment) Consider a multi-step setting where we use CP with coverage level $1-\epsilon$ to causally construct the prediction set when there may be multiple true labels at any step and seek help whenever the set is not a singleton at each timestep. With probability $1-\delta$ over the sampling of the calibration set, the task completion rate over new test scenarios drawn from $\mathcal{D}$ is at least $1-\epsilon$.</p>
<p>Proof: For the multi-step setting, each trial now involves a sequence of contexts $\bar{x}$ and a set of sequences of true labels:</p>
<p>$$
\bar{Y}=\left{\bar{y}<em 2="2">{1}, \bar{y}</em>\right}
$$}, \ldots, \bar{y}_{M</p>
<p>where $\bar{y}<em m="m">{m}:=\left(y</em>}^{0}, y_{m}^{2}, \ldots, y_{m}^{T-1}\right)$. For example, $\bar{Y}$ can contain the sequence of "blue block, yellow block, green block", "green block, blue block, yellow block", ..., for the task of picking up three blocks. We collect a dataset of $\bar{Z}=\left{\left(\bar{x<em i="i">{i}, \bar{Y}</em>$.
Unlike the single-step setting, here we cannot apply $\beta$ to the set of true labels in each step since we are reasoning over a set of sequences, and not a sequence of sets of true labels. Notably, the true label set at time step $t$ depends upon the sequence of previously chosen true labels.
Let $Y^{t}\left[x^{0}, \bar{y}^{t-1}\right]$ denote the set of true labels at timestep $t$, conditioned upon the initial context $x^{0}$ and a partial sequence of past true labels $\bar{y}^{t-1}:=\left(y^{0}, \ldots, y^{t-1}\right)$ extracted from $\bar{Y}$. We then autoregressively define the following sequence:}\right)\right}$ of i.i.d. samples from the data distribution $\overline{\mathcal{D}</p>
<p>$$
\begin{aligned}
&amp; \bar{\beta}<em y="y">{0}(\bar{x}, \bar{Y}):=\underset{y \in Y^{0}}{\operatorname{argmax}} \hat{f}\left(x^{0}\right)</em>\right} \
&amp; \bar{\beta}}, \quad Y^{0}:=\left{y_{1}^{0}, \ldots, y_{M}^{0<em t-1="t-1">{t}(\bar{x}, \bar{Y}):=\bar{\beta}</em>}(\bar{x}, \bar{Y}) \bigcup_{y \in Y^{t}\left[x^{0}, \bar{\beta<em y="y">{t-1}(\bar{x}, \bar{Y})\right]} \hat{f}\left(x^{t}\right)</em>, \quad t=1, \ldots, T-1
\end{aligned}
$$</p>
<p>For convenience, we denote $\bar{\beta}<em t="t">{t}(\bar{x}, \bar{Y})[\tau]$ the $\tau$ element in $\bar{\beta}</em>}(\bar{x}, \bar{Y}), \tau \leq t$. An intuitive interpretation is that, we can consider $\bar{Y}$ forming a tree of valid executions (all possible actions that can be taken by choosing each of true labels). Hence, at each time step $t, \bar{\beta<em T-1="T-1">{t}(\bar{x}, \bar{Y})$ prunes the tree to a single branch by taking the true label with the highest heuristic value $\hat{f}\left(x^{t}\right)$. This reduces the tree of all possible sequences of true labels to a single branch of true labels with highest confidence. Given this single branch of true labels, we can now perform CP as shown in the multi-step setting in Section A2.
We apply $\bar{\beta}</em>}$ to every point in the support of $\overline{\mathcal{D}}$, and a new distribution $\overline{\mathcal{D}}^{\prime}$ is induced. We consider $\bar{S}^{\prime}=\left{\left(\bar{x<em i="i">{i}, \bar{y}</em>}^{\max }\right)\right}$, where $\bar{y<em T-1="T-1">{i}^{\max }:=\bar{\beta}</em>}\left(\bar{x<em i="i">{i}, \bar{Y}</em>}\right)$. Let $\bar{Y<em _test="{test" _text="\text">{\text {test }}$ be the set of sequences of true labels for $\bar{x}</em>$ as the labels:}}$. Suppose we get the marginal bound with $\bar{\beta}_{T-1</p>
<p>$$
\mathbb{P}\left(\bar{\beta}<em _test="{test" _text="\text">{T-1}\left(\bar{x}</em>}}, \bar{Y<em _test="{test" _text="\text">{\text {test }}\right) \notin C\left(\bar{x}</em>
$$}}\right)\right) \leq \hat{\epsilon</p>
<p>and dataset-conditional bound when we choose $\hat{\epsilon}$ such that $\epsilon=1-\operatorname{Beta}_{\bar{x}+1-v, v}^{-1}(\delta)$ where $v=\lfloor(N+1) \hat{\epsilon}\rfloor$,</p>
<p>$$
\mathbb{P}\left(\bar{\beta}<em _test="{test" _text="\text">{T-1}\left(\bar{x}</em>}}, \bar{Y<em _test="{test" _text="\text">{\text {test }}\right) \notin C\left(\bar{x}</em>\right) \leq \epsilon
$$}}\right) \mid \bar{Z</p>
<p>which states that at test time, given a context sequence $\bar{x}<em _test="{test" _text="\text">{\text {test }}$, we produce a prediction set of sequences; if we consider a sequence consisting of the true label with the highest score at each step, the probability of this sequence covered by $C\left(\bar{x}</em>$ at each step at test time. Conside the three cases:}}\right)$ is lower bounded by $1-\epsilon$. However, we need to be careful of following $\bar{\beta}_{t</p>
<ul>
<li>(1) At a given time-step, the prediction set $C^{t}\left(x_{\text {test }}^{t}\right)$ does not contain the true label, $\bar{\beta}_{t}(\bar{x}, \bar{Y})[t]$.</li>
<li>(2a) The prediction set is a singleton and does contain the true label.</li>
<li>(2b) The prediction set is not a singleton (but does contain the correct label).</li>
</ul>
<p>We already bound the probability of (1) happening with the CP bound; (2a) is fine since the LLM will take the correct action; (2b) is more challenging - in this case the robot asks the human for help, and we need to make sure the human "follows" the true label, by choosing the true label in the prediction set with the highest confidence by $\hat{f}$. In practice, we present the labels ranked by $\hat{f}$ and ask the human to choose the true label with the highest rank.</p>
<p>Now let's derive the bound in Eq. (A18) and Eq. (A19). Again we need to consider the causal construction issue. As seen in Section 3.3, we construct the prediction set $\bar{C}\left(\bar{x}<em i="i">{\text {test }}\right)$ non-causally using the score function $s</em>}=1-\bar{f}\left(\bar{x<em _bar_y="\bar{y">{i}\right)</em><em _test="{test" _text="\text">{\text {test }}^{\max }}$ (taking minimum over steps). For a test sequence $\bar{x}</em>}}$, we apply $\bar{\beta<em _test="{test" _text="\text">{T-1}$ to the true label set of sequences $\bar{Y}</em>}}$ to get $\bar{y<em T-1="T-1">{\text {test }}^{\max }=\bar{\beta}</em>}\left(\bar{x<em _test="{test" _text="\text">{\text {test }}, \bar{Y}</em>}}\right)$. Now suppose $\bar{y<em _test="{test" _text="\text">{\text {test }}^{\max } \in \bar{C}\left(\bar{x}</em>}}\right)$, then we can show $\bar{y<em _test="{test" _text="\text">{\text {test }}^{\max } \in C\left(\bar{x}</em>\right)$ with the same proof as the single-label setting, which gives us the bound.
Lastly we need to show the sampled test sequence from $\bar{D}$ leads to a sample from $\bar{D}^{\prime}$ i.i.d. with $\bar{S}^{\prime}$. This is true with the same argument that functions of independent random variables are independent.}</p>
<h1>A5 Additional Experiment Setting: Hardware Bimanual Setup</h1>
<p>In this example, a bimanual setup with two Kuka IIWA 7 arms move objects on the table, with one bin at each side (Fig. 5 right). The reachable workspace of each arm is limited so that one arm cannot reach the other end of the table or the other bin. Thus, there can be ambiguities in the choice of the arm depending on the task; e.g., Fig. 5 shows the human asking the robot to pass over the mango, but not specifying which side the human is standing at. KNOWNO is able to capture such ambiguities and triggers clarification. We design a scenario distribution (single-step with single acceptable options) with all instructions being ambiguous (thus requiring high human intervention rate): with $\epsilon=0.15$, the robot achieves $84 \%$ plan success with $92 \%$ help. With 10 trials, the robot succeeds 9 times while triggering help for 9 times. Details of the scenario distribution are shown in Section A7.</p>
<h2>A6 LLM Prompt Setup</h2>
<p>Next we detail the LLM prompt setup for MCQA applied in KnowNo. We will use Mobile Manipulation from Section 4.3 as the example.</p>
<p>Multiple choice generation. Given a scenario, we first prompt the LLM to generate four semantically different options for possible next step. We apply few-shot prompting as shown in Fig. A1 below. In this scenario, there is a Coke, a bottled tea, and a Pepsi on the counter, and the task is to put the Coke in the top drawer but the choice of drawer is under-specified ("Put the Coke in the drawer please.").</p>
<div class="codehilite"><pre><span></span><code><span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">robot</span><span class="w"> </span><span class="n">operating</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">office</span><span class="w"> </span><span class="n">kitchen</span><span class="o">.</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">front</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">closed</span><span class="w"> </span><span class="n">drawers</span><span class="o">,</span>
<span class="n">a</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">middle</span><span class="w"> </span><span class="n">one</span><span class="o">.</span><span class="w"> </span><span class="n">There</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">landfill</span><span class="w"> </span><span class="n">bin</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">recycling</span><span class="w"> </span><span class="n">bin</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">compost</span><span class="w"> </span><span class="n">bin</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">soda</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Pepsi</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">apple</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">drink</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">drawer</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">soda</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">it</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">middle</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Pepsi</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">it</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">middle</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">orange</span><span class="w"> </span><span class="n">soda</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">it</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Pepsi</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">it</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">energy</span><span class="w"> </span><span class="n">bar</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">banana</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">microwave</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">snack</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">microwave</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">energy</span><span class="w"> </span><span class="n">bar</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">microwave</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">banana</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">energy</span><span class="w"> </span><span class="n">bar</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">banana</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">microwave</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">energy</span><span class="w"> </span><span class="n">bar</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">next</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">banana</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Coke</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Sprite</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">sponge</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Can</span><span class="w"> </span><span class="n">you</span><span class="w"> </span><span class="n">dispose</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">can</span><span class="o">?</span><span class="w"> </span><span class="n">It</span><span class="w"> </span><span class="n">should</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">expired</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sponge</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">landfill</span><span class="w"> </span><span class="n">bin</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Coke</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">recycling</span><span class="w"> </span><span class="n">bin</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Sprite</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">recycling</span><span class="w"> </span><span class="n">bin</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Coke</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">landfill</span><span class="w"> </span><span class="n">bin</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bottled</span><span class="w"> </span><span class="n">water</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bag</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">jalapeno</span><span class="w"> </span><span class="n">chips</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bag</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">rice</span><span class="w"> </span><span class="n">chips</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">would</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bag</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">chips</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bottled</span><span class="w"> </span><span class="n">water</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">jalapeno</span><span class="w"> </span><span class="n">chips</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">kettle</span><span class="w"> </span><span class="n">chips</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rice</span><span class="w"> </span><span class="n">chips</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Coke</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bottled</span><span class="w"> </span><span class="n">unsweetened</span><span class="w"> </span><span class="n">tea</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Pepsi</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Coke</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">please</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
</code></pre></div>

<p>Figure A1: Prompt used for multiple choice generation in Mobile Manipulation. With few-shot prompting show examples of possible next steps in different scenarios, the LLM can generate semantically different plans that are more likely than others (see prompting result in Fig. A2).</p>
<p>After the LLM generates four options, we append an additional option 'an option not listed here' to the four generated ones and then randomize the order to further prevent bias. We then use a zero-shot prompt in Fig. A2 for querying next-token probabilities ('A', 'B', 'C', D', 'E').</p>
<div class="codehilite"><pre><span></span><code><span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">robot</span><span class="w"> </span><span class="n">operating</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">office</span><span class="w"> </span><span class="n">kitchen</span><span class="o">.</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">front</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">counter</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">two</span><span class="w"> </span><span class="n">closed</span><span class="w"> </span><span class="n">drawers</span><span class="o">,</span>
<span class="n">a</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">middle</span><span class="w"> </span><span class="n">one</span><span class="o">.</span><span class="w"> </span><span class="n">There</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">also</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">landfill</span><span class="w"> </span><span class="n">bin</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">recycling</span><span class="w"> </span><span class="n">bin</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">compost</span><span class="w"> </span><span class="n">bin</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">counter</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Coke</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">bottled</span><span class="w"> </span><span class="n">unsweetened</span><span class="w"> </span><span class="n">tea</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Pepsi</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Coke</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">drawer</span><span class="w"> </span><span class="n">please</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">coke</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">coke</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">top</span><span class="w"> </span><span class="n">drawer</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">coke</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">bottom</span><span class="w"> </span><span class="n">drawer</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">listed</span><span class="w"> </span><span class="n">here</span>
<span class="n">E</span><span class="o">)</span><span class="w"> </span><span class="n">pick</span><span class="w"> </span><span class="n">up</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">pepsi</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">correct</span><span class="o">?</span><span class="w"> </span><span class="n">Answer</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="n">letter</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span>
</code></pre></div>

<p>Figure A2: Prompt used for next-token prediction with generated multiple choices in Mobile Manipulation.</p>
<h1>A7 Additional Experiment Details</h1>
<p>Environments. In addition to Fig. 1 and Fig. 5, here Fig. A3 shows the office kitchen environment with the set of drawers and bins used in Mobile Manipulation (left), and the bimanual setup with the set of objects used on the mat used in Bimanual (right). There is another set of drawers used in the mobile manipulation experiments underneath a much bigger countertop not shown here.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure A3: (Left) Office kitchen environment with drawers and bins for Mobile Manipulation. (Right) Bimanual setup with the set of objects used in the experiments.</p>
<p>Scenario Distribution and Calibration Dataset Next, we provide more details on the parameterization of the scenario distribution in each experiment setting, in particular, the possible ambiguities with the instruction and goal. With the distributions set up, the calibration dataset are then generated by randomly sampling 400 i.i.d. scenarios from them:</p>
<ul>
<li>Simulated setting:</li>
<li>Environment: there are always three blocks and bowls of color red, yellow, and green with random locations on the table.</li>
<li>Goal: we use the following template: {put, place, move} {a, one, a single of, two, a pair of, three, all, red, yellow, green $}{$ block(s), bowl(s) $}$ {on, to the left of, to the right of, to the front of, at the back of $}$ the ${$ red, green, yellow $}{$ block(s), bowl(s) $}$. The scenario distribution is uniform over these possibilities.</li>
<li>Instruction: for the language instructions, we modify the goal (from the template) according to the ambiguity type. The scenario distribution is uniform over the listed ambiguous cases in each ambiguity type.</li>
<li>Attribute ambiguities: refer to the block as one of "cube", "cuboid", "box", "square object", to the bowl as one of "container", "round object", "receptacle", or to either block or bowl as one of "object", "item", "thing" ("move the blue object in yellow bowl"); refer to "blue" as one of "cyan", "navy", to "green" as one of "greenish", "grass-colored", and to "yellow" as "orange" or "gold". This setting is the least ambiguous one among the three ambiguity types.</li>
<li>Numeric ambiguities: refer to either two or three numerically with one of "a few", "a couple of", "some", "a handful of" ("put some blocks in the green bowl").</li>
<li>Spatial ambiguities: refer to any of the four possible directions with "near", "close to", "beside", "next to", refer to either left to right with "lateral to", and refer to either front or behind with</li>
</ul>
<p>"along the line of sight". This setting is the most ambiguous one among the three ambiguity types.</p>
<ul>
<li>Hardware Tabletop Rearrangement setting:</li>
<li>Environment: there are three items to be sorted placed randomly on the table, and there is a blue plate and a green plate. 28 toy items are split (Fig. A7) into two categories of human liking them or disliking them: the things the human likes include corn, avocado, celery, carrot, tomato, lettuce, apple, orange, pear, lemon, peanut butter, sunny-side-up egg, egg, and pea; the human dislikes pretzel, cracker, waffle, mustard, ketchup, pizza, meat patty, cheese, chicken drumstick, peach, mango M\&amp;M, Skittles, and donut. The three items on the table are uniformly sampled ones from the two categories ( 1 from likes and 2 from dislikes, or 2 from likes and 1 from dislikes).</li>
<li>Goal: place the items that human likes in the blue plate, and ones that human dislikes in the green plate.</li>
<li>Instruction: to make the goal ambiguous, only a subset of human preferences are revealed in the prompt:"I like: corn, celery, pear, peanut butter, sunny-side-up egg. I don't like: pretzel, cracker, mustard, peach, M\&amp;M". And then the instruction includes "Can you sort things I like and dislike in blue and green plates?"</li>
<li>Hardware Mobile Manipulator setting:</li>
<li>Environment: the full list of possible objects include: bottled water, bottled tea, orange soda, RedBull, Coke, Pepsi, Sprite, rice chips, jalapeno chips, kettle chips, multigrain chips, apple, orange, energy bar, clean sponge, dirty sponge, metal bowl, plastic bowl. Depending on the ambiguity listed below, there is three objects placed on the top of the counter (including randomly sampled distractors from the list). There is also a set of landfill, compost, and recycling bins, a microwave, and a portable stove.</li>
<li>Instruction: for convenience, we introduce the possible instructions first in different ambiguous scenarios; they each correspond to possible goals. Please refer to https://robot-help. github.io/prompts/mobile_tasks.txt for the full list. The possible instructions are a uniform distribution over different types: (1) single-label, e.g., 'Bring me a Coke' (unambiguous); (2) creative-single-label, e.g., 'I want a healthy fruit to munch on.' which means the apple (unambiguous); (3) multi-label, e.g., 'Bring me a cola.' and either Coke or Pepsi is acceptable; (4) creative-multi-label, e.g., 'Bring me something with a kick.' and either RedBull or jalapeno chips are acceptable; (5) spatially-ambiguous, e.g., 'Put the Coke in the drawer' or 'Put the Coke near the fruit' which under-specifies the drawer or fruit; (6) unsafe, e.g., 'Can you dispose of the bottle drink? It should have expired.' or 'Place the bowl on the stove, please.'; (7) Winograd, e.g., 'There is a sponge and a bag of rice chips...I don't want to use it for cleaning any more. Can you please dispose of it?" We use the GPT-4 model for generating the creative tasks.</li>
<li>Goal: the corresponding goal for the ambiguous instructions above. For example, the instruction is "Put the Coke in the drawer", and the goal is uniform over the two possibilities: put the Coke in the top drawer, and put the Coke in the bottom drawer.</li>
<li>Bimanual setting:</li>
<li>Environment: the full list of possible objects include: Coke can, Sprite can, green apple, banana, mango, red block, green block, yellow block, pink plushie, yellow plushie, purple plushie. Depending on the ambiguity listed below, there is three objects placed on the table (including randomly sampled distractors from the list). There is possibly a human standing at the left or right side of the table.</li>
<li>Instruction: Please refer to https://robot-help.github.io/prompts/bimanual_tasks. txt for the full list of scenarios sampled from the distribution. The possible instructions are a uniform distribution over different types: (1) 'Pick up the {object} and pass it to me. I am next to the bin.' (2) 'Pick up the {object} with the left arm.' (3) 'Put the {object} in the bin closer to it.' (4) 'Pick up the {object} with the arm closer to it.' (5) 'Pick up the {object}.' (6) 'Pick up the {object} at the handle.' (7) 'Move the {object} to the front of the table.' (8) 'Move the {object} on the sticky rubber mat to the front of the table.'</li>
<li>Goal: the corresponding goal for the ambiguous instructions above. For example, the instruction is "Pick up the Coke can and pass it to me. I am next to the bin.", and the goal is pick up the Coke can with the left arm and pass it to human, if human is at the left side, and with the right arm if human is at the right side.</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="err">#</span><span class="w"> </span><span class="n">Define</span><span class="w"> </span><span class="n">possible</span><span class="w"> </span><span class="n">environment</span><span class="p">,</span><span class="w"> </span><span class="n">goal</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">instruction</span>
<span class="n">possible_envs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">&#39;three blocks and three bowls&#39;</span><span class="o">]</span>
<span class="n">possible_goals_with_instructions</span><span class="w"> </span><span class="o">=</span>
<span class="err">{</span><span class="s1">&#39;put three blocks in the green bowl&#39;</span><span class="err">:</span><span class="w"> </span><span class="o">[</span><span class="n">&#39;put three blocks in the green bowl&#39;, &#39;put all blocks in the green</span>
<span class="n">bowl&#39;, &#39;put three cubes in the green bowl&#39;, ...},</span>
<span class="n">    &#39;put two blocks in the blue bowl&#39;: [&#39;put two blocks in the blue bowl&#39;, &#39;put a pair of blocks in the blue</span>
<span class="n">bowl&#39;, ...},</span>
<span class="n">..} # key: goal; value: list of possible instructions</span>
<span class="n"># Sample scenarios by uniformly sampling from possible environments, goals, and instructions</span>
<span class="n">num_calibration_data = 100</span>
<span class="n">calibration_dataset = [</span><span class="o">]</span>
<span class="k">for</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="n">num_calibration_data</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="n">env</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">possible_envs</span><span class="p">)</span>
<span class="w">    </span><span class="n">goal</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">list</span><span class="p">(</span><span class="n">possible_goals_with_instructions</span><span class="p">.</span><span class="n">keys</span><span class="p">()))</span>
<span class="w">    </span><span class="n">instruction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="n">possible_goals_with_instructions</span><span class="o">[</span><span class="n">goal</span><span class="o">]</span><span class="p">)</span>
<span class="w">    </span><span class="n">calibration_dataset</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">env</span><span class="p">,</span><span class="w"> </span><span class="n">goal</span><span class="p">,</span><span class="w"> </span><span class="n">instruction</span><span class="p">))</span>
</code></pre></div>

<p>Figure A4: Sample algorithm for defining the scenario distribution and generating the calibration dataset in the Simulation setting.</p>
<p>Next we provide more details on the baselines that require additional prompting strategies.
Baselines - Ensemble Set. Our ensemble-based method is a weaker method than the traditional modelbased ensemble where multiple copies of neural network are trained and inferred with; however, this is infeasible with the LLM we use. In our work, we randomize over the few-shot examples in the prompt as the ensemble. We select a pool of 20 possible MCQA examples (see examples in Fig. A1), and then randomly sample a certain amount from it for each inference. Note that in this case, Ensemble Set actually has advantage over KNOWNo and Simple Set that, for the same data, it has seen many more examples than the fixed ones in the prompt used in KNOWNo and Simple Set. We only apply ensemble for next-token prediction; the same set of multiple choices generated is used.
Baselines - Prompt Set. First, multiple choices are generated in the same way as KnowNo. Then LLM is prompted to generate the prediction set, with few-shot examples in the prompt showing the possible labels (Fig. A5). For example, "We: Which options are possibly correct? You: A, C, D.".
Baselines - Binary. Instead of generating multiple choices, the LLM is first prompted to give the most likely action (e.g., "We: Put the Coke can in the drawer. You: I will" shown in Fig. A8). Then we attach the generated response to the same prompt, and ask LLM to label "Certain/Uncertain:" given few-shot examples (Fig. A6).</p>
<div class="codehilite"><pre><span></span><code><span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">these</span><span class="w"> </span><span class="n">objects</span><span class="o">:</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span>
<span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Now</span><span class="o">,</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">object</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">right</span><span class="w"> </span><span class="n">side</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">grass</span><span class="o">-</span><span class="n">colored</span><span class="w"> </span><span class="n">square</span><span class="w"> </span><span class="n">object</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span><span class="w"> </span><span class="n">These</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">options</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">listed</span><span class="w"> </span><span class="n">here</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">right</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">right</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span>
<span class="n">E</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">options</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">possibly</span><span class="w"> </span><span class="n">correct</span><span class="o">?</span>
<span class="n">You</span><span class="o">:</span><span class="w"> </span><span class="n">B</span><span class="o">,</span><span class="w"> </span><span class="n">D</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">these</span><span class="w"> </span><span class="n">objects</span><span class="o">:</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Now</span><span class="o">,</span><span class="w"> </span><span class="n">Put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">round</span><span class="w"> </span><span class="n">object</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">side</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">greenish</span><span class="w"> </span><span class="n">block</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span><span class="w"> </span><span class="n">These</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">options</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">listed</span><span class="w"> </span><span class="n">here</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span>
<span class="n">E</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">left</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">options</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">possibly</span><span class="w"> </span><span class="n">correct</span><span class="o">?</span>
<span class="n">You</span><span class="o">:</span><span class="w"> </span><span class="n">C</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">On</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">table</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">these</span><span class="w"> </span><span class="n">objects</span><span class="o">:</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span><span class="o">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span><span class="o">,</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span>
<span class="n">green</span><span class="w"> </span><span class="n">bowl</span><span class="o">.</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Now</span><span class="o">,</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">cyan</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">gold</span><span class="w"> </span><span class="n">object</span><span class="o">.</span>
<span class="n">You</span><span class="o">:</span><span class="w"> </span><span class="n">These</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">options</span><span class="o">:</span>
<span class="n">A</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">block</span>
<span class="n">B</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">green</span><span class="w"> </span><span class="n">block</span>
<span class="n">C</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">yellow</span><span class="w"> </span><span class="n">bowl</span>
<span class="n">D</span><span class="o">)</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">option</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">listed</span><span class="w"> </span><span class="n">here</span>
<span class="n">E</span><span class="o">)</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">bowl</span><span class="w"> </span><span class="n">behind</span><span class="w"> </span><span class="n">blue</span><span class="w"> </span><span class="n">block</span>
<span class="n">We</span><span class="o">:</span><span class="w"> </span><span class="n">Which</span><span class="w"> </span><span class="n">options</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">possibly</span><span class="w"> </span><span class="n">correct</span><span class="o">?</span>
<span class="n">You</span><span class="o">:</span>
</code></pre></div>

<p>Figure A5: Prompt with few-shot examples (two shown) for LLM generating the prediction set in Prompt Set baseline.</p>
<div class="codehilite"><pre><span></span><code>...
We: On the table there are these objects: blue bowl, green block, yellow bowl, yellow block, blue block,
green bowl.
We: Now, Put the green round object at the left side of the greenish block.
You: I will put green bowl to the left of yellow block.
Certain/Uncertain: Uncertain
We: On the table there are these objects: blue block, yellow bowl, green block, green bowl, blue bowl,
yellow block.
We: Now, Put the yellow box in front of the cyan receptacle.
You: I will put yellow block at the front of blue block
Certain/Uncertain: Certain
We: On the table there are these objects: blue bowl, blue block, green bowl, yellow bowl, green block,
yellow block.
We: Put the yellow box at the right side of the navy receptacle.
You: I will put yellow block to the right of blue block.
Certain/Uncertain:
</code></pre></div>

<p>Figure A6: Prompt with few-shot examples (two shown) for LLM expressing binary uncertainty in Binary baseline.</p>
<h1>A8 Additional Implementation Details</h1>
<p>While the focus of KNOWNO is mainly on providing uncertainty alignment for the LLM-based planner, below we provide details of the perception and action modules applied in all examples.</p>
<p>Perception. For all examples except for the Mobile Manipulation, we use either MDETR [60] (Hardware Tabletop Rearrangement) or Owl-ViT [61] (Simulation and Bimanual) open-vocabulary object detector for recognizing the objects in the environment and obtaining the object locations for low-level action. In Simulation and Bimanual, the variations of the object types are limited, and with general prompting, the objects are detected without issue. In Hardware Tabletop Rearrangement, since we are use a wide variety of toy items (Fig. A7 right), the detector has issues often differentiating objects like peanut butter and meat patty that are both darker colors. We modify the scenario distributions to avoid using such items together in one scenario. In addition, we apply the Segment Anything model [62] to extract the object segmentation masks (shown overlaid in Fig. A7 left), and then use the polylabel algorithm [63] to find the most distant internal point of the mask as the suction point (shown as red dots).
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure A7: (Left) MDTER [60] object detection with Segment Anything [62] and most distant internal point (red dots) for Hardware Tabletop Rearrangement. (Right) The total 28 toy items used for the experiments.</p>
<p>Low-level action. In Simulation and Hardware Tabletop Rearrangement, simple pick-and-place actions are executed based on object locations and solving the inverse kinematics. In Bimanual, the reachability of the Kuka arm is limited, and the pick-and-place action trajectories are solved using Sequential Quadtratic Programming (SQP) instead [64]. In Mobile Manipulation, for most of the tasks that involve simple pick-and-place and opening the drawers, the action is from an end-to-end policy from the RT-1 policy (please refer to [65] for details), which takes in the raw observation. For some of the hard tasks such as putting the plastic bowl in the microwave and putting the metal bowl on the bowl, object locations are assumed known and we use scripted action policies.</p>
<p>Human feedback. In KNOWNO, once human help is triggered, human is presented with the prediction set to choose the correct action from (if there is one). For example, the prediction set could include 'A) put peanut butter in blue plate' and 'C) put peanut butter in green plate' in Hardware Tabletop Rearrangement. In practice, we can convert the prediction set to a question in more natural language, e.g., "Do you like peanut butter or not?" using simple heuristics. In Mobile Manipulation and Bimanual, we prompt the LLM to generate the question based on the prediction set.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ In practice we convert the prediction set to a question in natural language (Section A8).
${ }^{3}$ If the correct option in $C\left(\hat{x}_{\text {test }}\right)$ is 'E', the human provides the correct action that was not listed by the robot.
${ }^{4}$ We overload notation here and use $\hat{f}$ to also assign confidence scores to sequences.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>