<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2564 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2564</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2564</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-4747e72c5bc706c50e76953188f0144df18992d0</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/4747e72c5bc706c50e76953188f0144df18992d0" target="_blank">Communicative Agents for Software Development</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2564.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2564.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDev: Communicative Agents for Software Development</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A chat-powered multi-agent software-development framework that composes specialized LLM-driven agents into a chain-structured workflow (design → coding → testing), using dual-agent subtasks, inception prompting, short- and long-term memory, and a communicative dehallucination pattern to reduce coding hallucinations and iteratively refine solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ChatDev</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ChatDev orchestrates multiple LLM-powered 'software agents' (with social roles like CEO/CTO/programmer/reviewer/tester/requirements analyst) in a sequential, chain-structured workflow that breaks the software lifecycle into phases (design, coding, testing) and further into subtasks. Each subtask is executed by a dual-agent pair (instructor I and assistant A) engaging in multi-turn natural-language and programming-language dialogue guided by system prompts (P_I and P_A). The system uses 'inception prompting' to instantiate role-specific system messages, maintains short-term (per-phase) and long-term (cross-phase solutions-only) memories, and applies a 'communicative dehallucination' pattern where assistants request specific clarifications before producing final code. Subtask termination is based on stability (two unchanged code modifications) or an upper round limit (10).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (dual-agent per subtask; experimental runs used a set of ~5 specialized roles: CEO, CTO, programmer, reviewer, tester)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Roles described and used: requirements analyst / CEO (define high-level goals and constraints), CTO (technical architecture decisions), programmer (write and complete code; sometimes biased to GUI or CLI depending on role), reviewer (static code review, finds issues like missing imports, infinite loops, placeholder methods), tester (dynamic/system testing, runs compilation and reports runtime errors via Python-3.11.4 integration), plus other coordinating roles (e.g., product-level role to guide feature additions). Some reviewers are specialized (e.g., 'careful reviewer for bug detection' or 'reviewer skilled at identifying endless loops'), programmers may be specialized (e.g., 'GUI-focused programmer').</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Design (natural-language requirement analysis and system design), Implementation/Coding (code writing and completion), Evaluation/Testing (static code review and dynamic system testing).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Sequential chain-structured pipeline (chat chain) organizing phases and subtasks; each subtask executed by a dual-agent instructor→assistant pair communicating until consensus. Coordination is centralized in the sense of a predefined sequence of phases and subtask instantiations (P_I/P_A) with role-specific system prompts; solutions from previous subtasks are passed forward as long-term memories (solutions-only), creating a sequential pipeline across phases.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Primarily natural-language messages augmented with programming-language snippets; system- and role-prompts (P_I, P_A) initialize agents; messages are free-form language but follow structured patterns: instructor -> assistant instructions, assistant responses often start with '<SOLUTION>' on consensus, and assistant may request clarifications (role-reversal) during communicative dehallucination. Communication includes exchanged short-term dialogue tuples tracked as (I_t^i, A_t^i). Agents also integrate tool feedback (compiler/runtime output) passed back as textual messages.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative multi-turn refinement loops: reviewers and testers provide textual critique and concrete error messages (e.g., 'ModuleNotFound', 'NameError') which feed back to programmer agents; communicative dehallucination enforces assistant-initiated clarifying questions before committing changes; termination uses either two unchanged code modifications or 10 communication rounds. There is integrated automated execution feedback via Python-3.11.4 used by tester agents for dynamic testing.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand but structured: agents communicate continuously in multi-turn loops within each subtask until consensus or termination conditions are met (up to 10 rounds), and only solutions (not full dialogue history) are propagated between phases at phase start.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development (creating prototype applications across categories such as Education, Work, Life, Game, Creation); generalizable to other multi-step, language-and-code integrated tasks but evaluated on software generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics (averaged over 1,200 SRDD tasks): Completeness = 0.5600, Executability = 0.8800, Consistency = 0.8021; Quality (product of the three) = 0.3953. Pairwise preference evaluations: vs GPT-Engineer by GPT-4: ChatDev wins 77.08%, baseline 22.50% (draw 0.42%); vs GPT-Engineer by human: ChatDev 90.16% / baseline 9.18% (draw 0.66%); vs MetaGPT by GPT-4: ChatDev 57.08% / MetaGPT 37.50% (draw 5.42%); vs MetaGPT by human: ChatDev 88.00% / MetaGPT 7.92% (draw 4.08%).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to GPT-Engineer (single-agent) and MetaGPT (multi-agent baseline). ChatDev outperforms both across completeness/executability/consistency/quality; e.g., Quality: ChatDev 0.3953 vs MetaGPT 0.1523. ChatDev also achieved higher pairwise win rates in both GPT-4 and human evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Quantified improvements in software quality metrics (higher completeness, executability, consistency, and overall Quality). Multi-agent dialog leads to autonomous functional enhancements (more files and larger codebase) and better alignment to requirements. Communicative dehallucination reduces coding hallucinations and increases compilation success in testing loops. Example quantitative benefit: Quality increased from 0.1523 (MetaGPT) to 0.3953 (ChatDev).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Longer wall-clock time and higher token consumption compared to single-agent approaches; increased computational cost and environmental impact. Challenges from limited LLM context lengths requiring segmented memory; agents can produce low information-density or simple/placeholder logic when requirements are vague; risk of role flipping, instruction repetition, and fake replies mitigated by inception prompting; coding hallucinations persist without communicative dehallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Ablations reported (Table 4): Halting chat chain earlier decreased metrics: halting after Coding: Completeness 0.4100 / Executability 0.7700 / Consistency 0.7958 / Quality 0.2512; halting after Complete: Completeness 0.6250 / Executability 0.7400 / Consistency 0.7978 / Quality 0.3690; halting after Review: Completeness 0.5750 / Executability 0.8100 / Consistency 0.7980 / Quality 0.3717. Removing communicative dehallucination (\CDH): Completeness 0.4700 / Executability 0.8400 / Consistency 0.7983 / Quality 0.3094. Removing role specifications (\Roles): Completeness 0.5400 / Executability 0.5800 / Consistency 0.7385 / Quality 0.2212. These ablations show communicative dehallucination and explicit role prompts materially improve performance, and that later phases (testing) are critical for executability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper suggests full chain (design → coding → review → testing) with explicit role system prompts (inception prompting) and communicative dehallucination enabled is empirically best. Typical experimental configuration used ~5 specialized roles and dual-agent instructor/assistant per subtask, short-term per-phase memory plus long-term solutions-only memory, and termination conditions of two unchanged code edits or 10 rounds.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2564.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent framework that assigns explicit roles to LLM-driven agents and follows standardized operating procedures so agents generate solutions by adhering to static, human-defined instructions; used here as a multi-agent baseline for software development.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MetaGPT is a role-assigned multi-agent framework in which different LLM agents have specific human-defined roles and standardized operating procedures; agents produce solutions by following static, predefined instructions and coordination rules rather than dynamic chat chains.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>multi-agent (variable; multiple role-assigned agents)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Role-assigned agents (e.g., product manager, architect, developer, tester) with static SOPs; exact specializations vary per deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Software development phases (design, coding, review/test) per its use as a baseline for software tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Role-assignment with static operating procedures; agents follow human-predefined instructions and a shared SOP rather than a dynamic chain-of-chat refinement model.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Textual/natural-language messages among agents following static instructions (not the chain-inception pattern used by ChatDev).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agents follow SOP-driven handoffs and human-predefined checks; not described as using communicative dehallucination or iterative role-reversal clarification by default.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Stepwise according to SOP; agents produce outputs per-step rather than prolonged multi-turn dialogue loops.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development (multi-agent programming tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported baseline metrics (Table 1): Completeness = 0.4834, Executability = 0.4145, Consistency = 0.7601, Quality = 0.1523.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared directly to ChatDev and GPT-Engineer in experiments; ChatDev outperforms MetaGPT across all reported metrics and in pairwise preference evaluations (ChatDev preferred by GPT-4 and humans).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>MetaGPT demonstrates that role assignment helps multi-agent systems outperform single-agent approaches (GPT-Engineer) on some metrics, but ChatDev's dynamic cooperative communication achieves larger gains.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Relies on static, human-defined instructions and SOPs which limit autonomous iterative refinement and adaptability compared to ChatDev's dialogue-driven refinements.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Not specified in this paper beyond its use as a baseline; ChatDev results imply dynamic multi-turn communication and dehallucination may outperform static SOP-based coordination.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2564.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A single-agent LLM-based software engineering approach that attempts end-to-end repository-level generation in a primarily one-step reasoning manner; used as a baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-Engineer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A single-agent system that interprets software requirements and generates software repositories using one-step or limited multi-step reasoning without an explicit multi-agent communication/coordination framework.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (single-agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Generalist single agent performing requirement parsing, coding, and (limited) testing tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Design, coding, and possibly some testing within a single agent pipeline but without explicit multi-agent roles.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>No multi-agent coordination; centralized single-agent processing.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not applicable (single agent). Internally uses LLM prompts to generate code and text.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Limited self-contained generation; may include internal checks but no peer-agent review loops.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>N/A (single-step or limited iteration within the single agent's reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Software development (software repository generation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics (Table 1): Completeness = 0.3583, Executability = 0.7887, Consistency = 0.1419; Quality not clearly reported in Table 1 for this baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Serves as a single-agent baseline; ChatDev and MetaGPT outperform GPT-Engineer, showing benefits of decomposition and multi-agent cooperation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Not applicable to GPT-Engineer itself, but comparisons show multi-agent coordination improves completeness and consistency over single-agent generation.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Single-agent approach struggles with complex multi-step tasks requiring decomposition and specialized checks, resulting in lower completeness and consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>N/A in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2564.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A platform/framework exploring multi-agent collaboration and emergent behaviours among LLM-based agents; mentioned in related work as an example of multi-agent systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A general framework/platform for building and studying collaborations among multiple LLM-driven agents and emergent behaviors; cited as related work illustrating multi-agent coordination research.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>multi-agent (variable)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Varies per AgentVerse deployment; typically role-assigned agents for tasks (not detailed in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General multi-agent tasks (research/platform for studying interactions), not specifically software development in this citation context.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Platform-level orchestration for agent interactions (details in original AgentVerse paper; this paper only cites it).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Likely natural-language message passing among agents (cited only; details not included here).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-agent collaboration research.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Mentioned as an example of multi-agent exploration; no empirical comparisons here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2564.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CAMEL: Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent communicative framework that studies agent societies and dialog-driven problem solving; referenced in the paper as related work on communicative agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CAMEL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A communicative multi-agent system designed to explore agent societies and the emergent behaviors of LLM agents communicating to solve tasks; cited for inspiration around multi-agent communication patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>multi-agent (variable)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Depends on specific CAMEL experiments; generally multiple role-playing agents.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General problem-solving and agent society experiments (not specific to software development here).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Communicative multi-agent interactions; details not specified in ChatDev paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language dialogues among agents.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agent-to-agent communicative feedback; not concretely detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Multi-agent communication research and problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Cited as demonstrating value of agent-to-agent communication for complex tasks; not quantified here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2564.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source autonomous agent framework that chains LLM calls with tool use and memory to accomplish multi-step goals; mentioned in related work as an example of autonomous agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An autonomous-agent approach that uses chained LLM reasoning, memory and tool access to pursue goals with limited human supervision; referenced as part of the broader landscape of autonomous LLM agents.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>typically single autonomous agent (though can spawn sub-processes); mentioned as autonomous agent work</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>General autonomous agent (planner/actor/tool-user) rather than role-specialized multi-agent teams.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>General task planning and execution across multiple steps; not specific to software research in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Internal planning and tool-invocation loops rather than explicit multi-agent coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Internal LLM prompt/tool calls and memory; not agent-to-agent chat in the same sense as ChatDev.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Planner-execute-observe loops; not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>N/A (single autonomous agent cycles).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>AutoGPT exemplifies autonomous, iterative problem solving; cited for context.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2564.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaAgents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system for simulating human-like agent interactions to coordinate task-oriented behaviors; referenced as related work on multi-agent coordination and role-play.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaAgents</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A framework that simulates human behavior via LLM agents to coordinate task-oriented activities; included as related research on LLM agent collaboration mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>multi-agent (variable)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Role-simulating agents (human-behavior like roles) depending on task configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Task-oriented coordination and simulation; not specific to software research in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Simulated human-interaction based coordination among agents; details are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language dialogues simulating human interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agent-to-agent conversational feedback, not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Simulation of human-like task coordination and multi-agent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrates LLMs' capacity to simulate human interactions for coordination; cited for context.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2564.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2564.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GameGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GameGPT: Multi-agent Collaborative Framework for Game Development</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent collaborative framework targeted at game development tasks where LLM agents take on different roles to design and build games; cited as related work on multi-agent application-specific frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GameGPT: Multi-agent Collaborative Framework for Game Development</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GameGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A specialized multi-agent framework for collaborative game development by multiple role-assigned LLM agents; cited to illustrate domain-specific multi-agent collaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>multi-agent (variable)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Role-assigned agents (e.g., game designer, developer, tester) tailored for game development tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Design, implementation, testing phases specific to game development.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Role-based multi-agent collaboration with communications among agents; specific coordination details are in the referenced GameGPT paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language dialogues transmitting design and code artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Iterative dialogue and role-specific critique; not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Game development (software domain).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrates multi-agent frameworks applied to domain-specific creative software tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework <em>(Rating: 2)</em></li>
                <li>AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents <em>(Rating: 2)</em></li>
                <li>CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society <em>(Rating: 2)</em></li>
                <li>AutoGPT <em>(Rating: 2)</em></li>
                <li>GameGPT: Multi-agent Collaborative Framework for Game Development <em>(Rating: 2)</em></li>
                <li>MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2564",
    "paper_id": "paper-4747e72c5bc706c50e76953188f0144df18992d0",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "ChatDev",
            "name_full": "ChatDev: Communicative Agents for Software Development",
            "brief_description": "A chat-powered multi-agent software-development framework that composes specialized LLM-driven agents into a chain-structured workflow (design → coding → testing), using dual-agent subtasks, inception prompting, short- and long-term memory, and a communicative dehallucination pattern to reduce coding hallucinations and iteratively refine solutions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ChatDev",
            "system_description": "ChatDev orchestrates multiple LLM-powered 'software agents' (with social roles like CEO/CTO/programmer/reviewer/tester/requirements analyst) in a sequential, chain-structured workflow that breaks the software lifecycle into phases (design, coding, testing) and further into subtasks. Each subtask is executed by a dual-agent pair (instructor I and assistant A) engaging in multi-turn natural-language and programming-language dialogue guided by system prompts (P_I and P_A). The system uses 'inception prompting' to instantiate role-specific system messages, maintains short-term (per-phase) and long-term (cross-phase solutions-only) memories, and applies a 'communicative dehallucination' pattern where assistants request specific clarifications before producing final code. Subtask termination is based on stability (two unchanged code modifications) or an upper round limit (10).",
            "number_of_agents": "variable (dual-agent per subtask; experimental runs used a set of ~5 specialized roles: CEO, CTO, programmer, reviewer, tester)",
            "agent_specializations": "Roles described and used: requirements analyst / CEO (define high-level goals and constraints), CTO (technical architecture decisions), programmer (write and complete code; sometimes biased to GUI or CLI depending on role), reviewer (static code review, finds issues like missing imports, infinite loops, placeholder methods), tester (dynamic/system testing, runs compilation and reports runtime errors via Python-3.11.4 integration), plus other coordinating roles (e.g., product-level role to guide feature additions). Some reviewers are specialized (e.g., 'careful reviewer for bug detection' or 'reviewer skilled at identifying endless loops'), programmers may be specialized (e.g., 'GUI-focused programmer').",
            "research_phases_covered": "Design (natural-language requirement analysis and system design), Implementation/Coding (code writing and completion), Evaluation/Testing (static code review and dynamic system testing).",
            "coordination_mechanism": "Sequential chain-structured pipeline (chat chain) organizing phases and subtasks; each subtask executed by a dual-agent instructor→assistant pair communicating until consensus. Coordination is centralized in the sense of a predefined sequence of phases and subtask instantiations (P_I/P_A) with role-specific system prompts; solutions from previous subtasks are passed forward as long-term memories (solutions-only), creating a sequential pipeline across phases.",
            "communication_protocol": "Primarily natural-language messages augmented with programming-language snippets; system- and role-prompts (P_I, P_A) initialize agents; messages are free-form language but follow structured patterns: instructor -&gt; assistant instructions, assistant responses often start with '&lt;SOLUTION&gt;' on consensus, and assistant may request clarifications (role-reversal) during communicative dehallucination. Communication includes exchanged short-term dialogue tuples tracked as (I_t^i, A_t^i). Agents also integrate tool feedback (compiler/runtime output) passed back as textual messages.",
            "feedback_mechanism": "Iterative multi-turn refinement loops: reviewers and testers provide textual critique and concrete error messages (e.g., 'ModuleNotFound', 'NameError') which feed back to programmer agents; communicative dehallucination enforces assistant-initiated clarifying questions before committing changes; termination uses either two unchanged code modifications or 10 communication rounds. There is integrated automated execution feedback via Python-3.11.4 used by tester agents for dynamic testing.",
            "communication_frequency": "On-demand but structured: agents communicate continuously in multi-turn loops within each subtask until consensus or termination conditions are met (up to 10 rounds), and only solutions (not full dialogue history) are propagated between phases at phase start.",
            "task_domain": "Software development (creating prototype applications across categories such as Education, Work, Life, Game, Creation); generalizable to other multi-step, language-and-code integrated tasks but evaluated on software generation tasks.",
            "performance_metrics": "Reported metrics (averaged over 1,200 SRDD tasks): Completeness = 0.5600, Executability = 0.8800, Consistency = 0.8021; Quality (product of the three) = 0.3953. Pairwise preference evaluations: vs GPT-Engineer by GPT-4: ChatDev wins 77.08%, baseline 22.50% (draw 0.42%); vs GPT-Engineer by human: ChatDev 90.16% / baseline 9.18% (draw 0.66%); vs MetaGPT by GPT-4: ChatDev 57.08% / MetaGPT 37.50% (draw 5.42%); vs MetaGPT by human: ChatDev 88.00% / MetaGPT 7.92% (draw 4.08%).",
            "baseline_comparison": "Compared to GPT-Engineer (single-agent) and MetaGPT (multi-agent baseline). ChatDev outperforms both across completeness/executability/consistency/quality; e.g., Quality: ChatDev 0.3953 vs MetaGPT 0.1523. ChatDev also achieved higher pairwise win rates in both GPT-4 and human evaluations.",
            "coordination_benefits": "Quantified improvements in software quality metrics (higher completeness, executability, consistency, and overall Quality). Multi-agent dialog leads to autonomous functional enhancements (more files and larger codebase) and better alignment to requirements. Communicative dehallucination reduces coding hallucinations and increases compilation success in testing loops. Example quantitative benefit: Quality increased from 0.1523 (MetaGPT) to 0.3953 (ChatDev).",
            "coordination_challenges": "Longer wall-clock time and higher token consumption compared to single-agent approaches; increased computational cost and environmental impact. Challenges from limited LLM context lengths requiring segmented memory; agents can produce low information-density or simple/placeholder logic when requirements are vague; risk of role flipping, instruction repetition, and fake replies mitigated by inception prompting; coding hallucinations persist without communicative dehallucination.",
            "ablation_studies": "Ablations reported (Table 4): Halting chat chain earlier decreased metrics: halting after Coding: Completeness 0.4100 / Executability 0.7700 / Consistency 0.7958 / Quality 0.2512; halting after Complete: Completeness 0.6250 / Executability 0.7400 / Consistency 0.7978 / Quality 0.3690; halting after Review: Completeness 0.5750 / Executability 0.8100 / Consistency 0.7980 / Quality 0.3717. Removing communicative dehallucination (\\CDH): Completeness 0.4700 / Executability 0.8400 / Consistency 0.7983 / Quality 0.3094. Removing role specifications (\\Roles): Completeness 0.5400 / Executability 0.5800 / Consistency 0.7385 / Quality 0.2212. These ablations show communicative dehallucination and explicit role prompts materially improve performance, and that later phases (testing) are critical for executability.",
            "optimal_configurations": "Paper suggests full chain (design → coding → review → testing) with explicit role system prompts (inception prompting) and communicative dehallucination enabled is empirically best. Typical experimental configuration used ~5 specialized roles and dual-agent instructor/assistant per subtask, short-term per-phase memory plus long-term solutions-only memory, and termination conditions of two unchanged code edits or 10 rounds.",
            "uuid": "e2564.0"
        },
        {
            "name_short": "MetaGPT",
            "name_full": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework",
            "brief_description": "A multi-agent framework that assigns explicit roles to LLM-driven agents and follows standardized operating procedures so agents generate solutions by adhering to static, human-defined instructions; used here as a multi-agent baseline for software development.",
            "citation_title": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework",
            "mention_or_use": "use",
            "system_name": "MetaGPT",
            "system_description": "MetaGPT is a role-assigned multi-agent framework in which different LLM agents have specific human-defined roles and standardized operating procedures; agents produce solutions by following static, predefined instructions and coordination rules rather than dynamic chat chains.",
            "number_of_agents": "multi-agent (variable; multiple role-assigned agents)",
            "agent_specializations": "Role-assigned agents (e.g., product manager, architect, developer, tester) with static SOPs; exact specializations vary per deployment.",
            "research_phases_covered": "Software development phases (design, coding, review/test) per its use as a baseline for software tasks.",
            "coordination_mechanism": "Role-assignment with static operating procedures; agents follow human-predefined instructions and a shared SOP rather than a dynamic chain-of-chat refinement model.",
            "communication_protocol": "Textual/natural-language messages among agents following static instructions (not the chain-inception pattern used by ChatDev).",
            "feedback_mechanism": "Agents follow SOP-driven handoffs and human-predefined checks; not described as using communicative dehallucination or iterative role-reversal clarification by default.",
            "communication_frequency": "Stepwise according to SOP; agents produce outputs per-step rather than prolonged multi-turn dialogue loops.",
            "task_domain": "Software development (multi-agent programming tasks).",
            "performance_metrics": "Reported baseline metrics (Table 1): Completeness = 0.4834, Executability = 0.4145, Consistency = 0.7601, Quality = 0.1523.",
            "baseline_comparison": "Compared directly to ChatDev and GPT-Engineer in experiments; ChatDev outperforms MetaGPT across all reported metrics and in pairwise preference evaluations (ChatDev preferred by GPT-4 and humans).",
            "coordination_benefits": "MetaGPT demonstrates that role assignment helps multi-agent systems outperform single-agent approaches (GPT-Engineer) on some metrics, but ChatDev's dynamic cooperative communication achieves larger gains.",
            "coordination_challenges": "Relies on static, human-defined instructions and SOPs which limit autonomous iterative refinement and adaptability compared to ChatDev's dialogue-driven refinements.",
            "ablation_studies": null,
            "optimal_configurations": "Not specified in this paper beyond its use as a baseline; ChatDev results imply dynamic multi-turn communication and dehallucination may outperform static SOP-based coordination.",
            "uuid": "e2564.1"
        },
        {
            "name_short": "GPT-Engineer",
            "name_full": "GPT-Engineer",
            "brief_description": "A single-agent LLM-based software engineering approach that attempts end-to-end repository-level generation in a primarily one-step reasoning manner; used as a baseline in this paper.",
            "citation_title": "GPT-Engineer",
            "mention_or_use": "use",
            "system_name": "GPT-Engineer",
            "system_description": "A single-agent system that interprets software requirements and generates software repositories using one-step or limited multi-step reasoning without an explicit multi-agent communication/coordination framework.",
            "number_of_agents": "1 (single-agent)",
            "agent_specializations": "Generalist single agent performing requirement parsing, coding, and (limited) testing tasks.",
            "research_phases_covered": "Design, coding, and possibly some testing within a single agent pipeline but without explicit multi-agent roles.",
            "coordination_mechanism": "No multi-agent coordination; centralized single-agent processing.",
            "communication_protocol": "Not applicable (single agent). Internally uses LLM prompts to generate code and text.",
            "feedback_mechanism": "Limited self-contained generation; may include internal checks but no peer-agent review loops.",
            "communication_frequency": "N/A (single-step or limited iteration within the single agent's reasoning).",
            "task_domain": "Software development (software repository generation).",
            "performance_metrics": "Reported metrics (Table 1): Completeness = 0.3583, Executability = 0.7887, Consistency = 0.1419; Quality not clearly reported in Table 1 for this baseline.",
            "baseline_comparison": "Serves as a single-agent baseline; ChatDev and MetaGPT outperform GPT-Engineer, showing benefits of decomposition and multi-agent cooperation.",
            "coordination_benefits": "Not applicable to GPT-Engineer itself, but comparisons show multi-agent coordination improves completeness and consistency over single-agent generation.",
            "coordination_challenges": "Single-agent approach struggles with complex multi-step tasks requiring decomposition and specialized checks, resulting in lower completeness and consistency.",
            "ablation_studies": null,
            "optimal_configurations": "N/A in this paper.",
            "uuid": "e2564.2"
        },
        {
            "name_short": "AgentVerse",
            "name_full": "AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents",
            "brief_description": "A platform/framework exploring multi-agent collaboration and emergent behaviours among LLM-based agents; mentioned in related work as an example of multi-agent systems.",
            "citation_title": "AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents",
            "mention_or_use": "mention",
            "system_name": "AgentVerse",
            "system_description": "A general framework/platform for building and studying collaborations among multiple LLM-driven agents and emergent behaviors; cited as related work illustrating multi-agent coordination research.",
            "number_of_agents": "multi-agent (variable)",
            "agent_specializations": "Varies per AgentVerse deployment; typically role-assigned agents for tasks (not detailed in this paper).",
            "research_phases_covered": "General multi-agent tasks (research/platform for studying interactions), not specifically software development in this citation context.",
            "coordination_mechanism": "Platform-level orchestration for agent interactions (details in original AgentVerse paper; this paper only cites it).",
            "communication_protocol": "Likely natural-language message passing among agents (cited only; details not included here).",
            "feedback_mechanism": "Not detailed in this paper.",
            "communication_frequency": "Not detailed in this paper.",
            "task_domain": "General multi-agent collaboration research.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Mentioned as an example of multi-agent exploration; no empirical comparisons here.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2564.3"
        },
        {
            "name_short": "CAMEL",
            "name_full": "CAMEL: Communicative Agents for 'Mind' Exploration of Large Scale Language Model Society",
            "brief_description": "A multi-agent communicative framework that studies agent societies and dialog-driven problem solving; referenced in the paper as related work on communicative agents.",
            "citation_title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society",
            "mention_or_use": "mention",
            "system_name": "CAMEL",
            "system_description": "A communicative multi-agent system designed to explore agent societies and the emergent behaviors of LLM agents communicating to solve tasks; cited for inspiration around multi-agent communication patterns.",
            "number_of_agents": "multi-agent (variable)",
            "agent_specializations": "Depends on specific CAMEL experiments; generally multiple role-playing agents.",
            "research_phases_covered": "General problem-solving and agent society experiments (not specific to software development here).",
            "coordination_mechanism": "Communicative multi-agent interactions; details not specified in ChatDev paper.",
            "communication_protocol": "Natural-language dialogues among agents.",
            "feedback_mechanism": "Agent-to-agent communicative feedback; not concretely detailed in this paper.",
            "communication_frequency": "Not specified in this paper.",
            "task_domain": "Multi-agent communication research and problem solving.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Cited as demonstrating value of agent-to-agent communication for complex tasks; not quantified here.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2564.4"
        },
        {
            "name_short": "AutoGPT",
            "name_full": "AutoGPT",
            "brief_description": "An open-source autonomous agent framework that chains LLM calls with tool use and memory to accomplish multi-step goals; mentioned in related work as an example of autonomous agents.",
            "citation_title": "AutoGPT",
            "mention_or_use": "mention",
            "system_name": "AutoGPT",
            "system_description": "An autonomous-agent approach that uses chained LLM reasoning, memory and tool access to pursue goals with limited human supervision; referenced as part of the broader landscape of autonomous LLM agents.",
            "number_of_agents": "typically single autonomous agent (though can spawn sub-processes); mentioned as autonomous agent work",
            "agent_specializations": "General autonomous agent (planner/actor/tool-user) rather than role-specialized multi-agent teams.",
            "research_phases_covered": "General task planning and execution across multiple steps; not specific to software research in this paper.",
            "coordination_mechanism": "Internal planning and tool-invocation loops rather than explicit multi-agent coordination.",
            "communication_protocol": "Internal LLM prompt/tool calls and memory; not agent-to-agent chat in the same sense as ChatDev.",
            "feedback_mechanism": "Planner-execute-observe loops; not detailed in this paper.",
            "communication_frequency": "N/A (single autonomous agent cycles).",
            "task_domain": "General autonomous tasks.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "AutoGPT exemplifies autonomous, iterative problem solving; cited for context.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2564.5"
        },
        {
            "name_short": "MetaAgents",
            "name_full": "MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents",
            "brief_description": "A system for simulating human-like agent interactions to coordinate task-oriented behaviors; referenced as related work on multi-agent coordination and role-play.",
            "citation_title": "MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents",
            "mention_or_use": "mention",
            "system_name": "MetaAgents",
            "system_description": "A framework that simulates human behavior via LLM agents to coordinate task-oriented activities; included as related research on LLM agent collaboration mechanisms.",
            "number_of_agents": "multi-agent (variable)",
            "agent_specializations": "Role-simulating agents (human-behavior like roles) depending on task configuration.",
            "research_phases_covered": "Task-oriented coordination and simulation; not specific to software research in this paper.",
            "coordination_mechanism": "Simulated human-interaction based coordination among agents; details are in the cited work.",
            "communication_protocol": "Natural-language dialogues simulating human interactions.",
            "feedback_mechanism": "Agent-to-agent conversational feedback, not specified in this paper.",
            "communication_frequency": "Not specified here.",
            "task_domain": "Simulation of human-like task coordination and multi-agent interactions.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Demonstrates LLMs' capacity to simulate human interactions for coordination; cited for context.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2564.6"
        },
        {
            "name_short": "GameGPT",
            "name_full": "GameGPT: Multi-agent Collaborative Framework for Game Development",
            "brief_description": "A multi-agent collaborative framework targeted at game development tasks where LLM agents take on different roles to design and build games; cited as related work on multi-agent application-specific frameworks.",
            "citation_title": "GameGPT: Multi-agent Collaborative Framework for Game Development",
            "mention_or_use": "mention",
            "system_name": "GameGPT",
            "system_description": "A specialized multi-agent framework for collaborative game development by multiple role-assigned LLM agents; cited to illustrate domain-specific multi-agent collaboration.",
            "number_of_agents": "multi-agent (variable)",
            "agent_specializations": "Role-assigned agents (e.g., game designer, developer, tester) tailored for game development tasks.",
            "research_phases_covered": "Design, implementation, testing phases specific to game development.",
            "coordination_mechanism": "Role-based multi-agent collaboration with communications among agents; specific coordination details are in the referenced GameGPT paper.",
            "communication_protocol": "Natural-language dialogues transmitting design and code artifacts.",
            "feedback_mechanism": "Iterative dialogue and role-specific critique; not specified in this paper.",
            "communication_frequency": "Not specified here.",
            "task_domain": "Game development (software domain).",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Demonstrates multi-agent frameworks applied to domain-specific creative software tasks.",
            "coordination_challenges": "Not discussed in this paper.",
            "ablation_studies": null,
            "optimal_configurations": null,
            "uuid": "e2564.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework",
            "rating": 2
        },
        {
            "paper_title": "AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents",
            "rating": 2
        },
        {
            "paper_title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society",
            "rating": 2
        },
        {
            "paper_title": "AutoGPT",
            "rating": 2
        },
        {
            "paper_title": "GameGPT: Multi-agent Collaborative Framework for Game Development",
            "rating": 2
        },
        {
            "paper_title": "MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents",
            "rating": 2
        }
    ],
    "cost": 0.017218499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ChatDev: Communicative Agents for Software Development</h1>
<p>Chen Qian<em> Wei Liu</em> Hongzhang Liu<em> Nuo Chen</em> Yufan Dang<em><br>Jiahao Li</em> Cheng Yang<em> Weize Chen</em> Yusheng Su<em> Xin Cong</em><br>Juyuan Xu<em> Dahai Li</em> Zhiyuan Liu<em> ${ }^{\text {m }}$ Maosong Sun</em> ${ }^{\text {m }}$<br>*Tsinghua University $\star$ The University of Sydney $\star$ BUPT $\star$ Modelbest Inc.<br>qianc62@gmail.com liuzy@tsinghua.edu.cn sms@tsinghua.edu.cn</p>
<h4>Abstract</h4>
<p>Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique designs, leading to technical inconsistencies across various phases, which results in a fragmented and ineffective development process. In this paper, we introduce ChatDev, a chat-powered software development framework in which specialized agents driven by large language models (LLMs) are guided in what to communicate (via chat chain) and how to communicate (via communicative dehallucination). These agents actively contribute to the design, coding, and testing phases through unified language-based communication, with solutions derived from their multi-turn dialogues. We found their utilization of natural language is advantageous for system design, and communicating in programming language proves helpful in debugging. This paradigm demonstrates how linguistic communication facilitates multi-agent collaboration, establishing language as a unifying bridge for autonomous task-solving among LLM agents. The code and data are available at https://github.com/OpenBMB/ChatDev.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) have led to substantial transformations due to their ability to effortlessly integrate extensive knowledge expressed in language (Brown et al., 2020; Bubeck et al., 2023), combined with their strong capacity for roleplaying within designated roles (Park et al., 2023; Hua et al., 2023; Chen et al., 2023b). This advancement eliminates the need for model-specific designs and delivers impressive performance in</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: ChatDev, a chat-powered software development framework, integrates LLM agents with various social roles, working autonomously to develop comprehensive solutions via multi-agent collaboration.
diverse downstream applications. Furthermore, autonomous agents (Richards, 2023; Zhou et al., 2023a) have gained attention for enhancing the capabilities of LLMs with advanced features such as context-aware memory (Sumers et al., 2023), multistep planning (Liu et al., 2023), and strategic tool using (Schick et al., 2023).</p>
<p>Software development is a complex task that necessitates cooperation among multiple members with diverse skills (e.g., architects, programmers, and testers) (Basili, 1989; Sawyer and Guinan, 1998). This entails extensive communication among different roles to understand and analyze requirements through natural language, while also encompassing development and debugging using programming languages (Ernst, 2017; Banker et al., 1998). Numerous studies use deep learning to improve specific phases of the waterfall model in software development, such as design, coding, and testing (Pudlitz et al., 2019; Martín and Abran, 2015;</p>
<p>Gao et al., 2019; Wang et al., 2016). Due to these technical inconsistencies, methods employed in different phases remain isolated until now. Every phase, from data collection and labeling to model training and inference, requires its unique designs, leading to a fragmented and less efficient development process in the field (Freeman et al., 2001; Ernst, 2017; Winkler et al., 2020).</p>
<p>Motivated by the expert-like potential of autonomous agents, we aim to establish language as a unifying bridge-utilizing multiple LLM-powered agents with specialized roles for cooperative software development through language-based communication across different phases; solutions in different phases are derived from their multi-turn dialogues, whether dealing with text or code. Nevertheless, due to the tendency of LLM hallucinations (Dhuliawala et al., 2023; Zhang et al., 2023b), the strategy of generating software through communicative agents could lead to the non-trivial challenge of coding hallucinations, which involves the generation of source code that is incomplete, unexecutable, or inaccurate, ultimately failing to fulfill the intended requirements (Agnihotri and Chug, 2020). The frequent occurrence of coding hallucination in turn reflects the constrained autonomy of agents in task completion, inevitably demanding additional manual intervention and thereby hindering the immediate usability and reliability of the generated software (Ji et al., 2023).</p>
<p>In this paper, we propose ChatDev (see Figure 1), a chat-powered software-development framework integrating multiple "software agents" for active involvement in three core phases of the software lifecycle: design, coding, and testing. Technically, ChatDev uses a chat chain to divide each phase into smaller subtasks further, enabling agents’ multi-turn communications to cooperatively propose and develop solutions (e.g., creative ideas or source code). The chain-structured workflow guides agents on what to communicate, fostering cooperation and smoothly linking natural- and programming-language subtasks to propel problemsolving. Additionally, to minimize coding hallucinations, ChatDev includes an communicative dehallucination mechanism, enabling agents to actively request more specific details before giving direct responses. The communication pattern instructs agents on how to communicate, enabling precise information exchange for effective solution optimization while reducing coding hallucinations. We built a comprehensive dataset containing
software requirement descriptions and conducted comprehensive analyses. The results indicate that ChatDev notably improves the quality of software, leading to improved completeness, executability, and better consistency with requirements. Further investigations reveal that natural-language communications contribute to comprehensive system design, while programming-language communications drive software optimization. In summary, the proposed paradigm demonstrates how linguistic communication facilitates multi-agent collaboration, establishing language as a unifying bridge for autonomous task-solving among LLM agents.</p>
<h2>2 Related Work</h2>
<p>Trained on vast datasets to comprehend and manipulate billions of parameters, LLMs have become pivotal in natural language processing due to their seamless integration of extensive knowledge (Brown et al., 2020; Bubeck et al., 2023; Vaswani et al., 2017; Radford et al.; Touvron et al., 2023; Wei et al., 2022a; Shanahan et al., 2023; Chen et al., 2021; Brants et al., 2007; Chen et al., 2021; Ouyang et al., 2022; Yang et al., 2023a; Qin et al., 2023b; Kaplan et al., 2020). Furthermore, LLMs have demonstrated strong role-playing abilities (Li et al., 2023a; Park et al., 2023; Hua et al., 2023; Chan et al., 2023; Zhou et al., 2023b; Chen et al., 2023b,a; Cohen et al., 2023; Li et al., 2023b). Recent progress, particularly in the field of autonomous agents (Zhou et al., 2023a; Wang et al., 2023a; Park et al., 2023; Wang et al., 2023e; Richards, 2023; Osika, 2023; Wang et al., 2023d), is largely attributed to the foundational advances in LLMs. These agents utilize the robust capabilities of LLMs, displaying remarkable skills in memory (Park et al., 2023; Sumers et al., 2023), planning (Chen et al., 2023b; Liu et al., 2023) and tool use (Schick et al., 2023; Cai et al., 2023; Qin et al., 2023a; Ruan et al., 2023; Yang et al., 2023b), enabling them to reason in complex scenarios (Wei et al., 2022b; Zhao et al., 2023; Zhou et al., 2023a; Ma et al., 2023; Zhang et al., 2023a; Wang et al., 2023b; Ding et al., 2023; Weng, 2023).</p>
<p>Software development is a multifaceted and intricate process that requires the cooperation of multiple experts from various fields (Yilmaz et al., 2012; Acuna et al., 2006; Basili, 1989; Sawyer and Guinan, 1998; Banker et al., 1998; France and Rumpe, 2007), encompassing the requirement analysis and system design in natural lan-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Upon receiving a preliminary task requirement (<em>e.g.,</em> "<em>develop a Gomoku game</em>"), these software agents engage in multi-turn communication and perform instruction-following along a chain-structured workflow, collaborating to execute a series of subtasks autonomously to craft a comprehensive solution.</p>
<p>guages (Pudlitz et al., 2019; Martín and Abran, 2015; Nahar et al., 2022), along with system development and debugging in programming languages (Gao et al., 2019; Wang et al., 2016; Wan et al., 2022). Numerous studies employ the waterfall model, a particular software development life cycle, to segment the process into discrete phases (<em>e.g.,</em> design, coding, testing) and apply deep learning to improve the effectiveness of certain phases (Winkler et al., 2020; Ezzini et al., 2022; Thaller et al., 2019; Zhao et al., 2021; Nijkamp et al., 2023; Wan et al., 2018; Wang et al., 2021).</p>
<h2>3 ChatDev</h2>
<p>We introduce ChatDev, a chat-powered software-development framework that integrates multiple "software agents" with various social roles (<em>e.g.,</em> requirements analysts, professional programmers and test engineers) collaborating in the core phases of the software life cycle, see Figure 1. Technically, to facilitate cooperative communication, ChatDev introduces <em>chat chain</em> to further break down each phase into smaller and manageable subtasks, which guides multi-turn communications between different roles to propose and validate solutions for each subtask. In addition, to alleviate unexpected hallucinations, a communicative pattern named <em>communicative dehallucination</em> is devised, wherein agents request more detailed information before responding directly and then continue the next round of communication based on these details.</p>
<h3>3.1 Chat Chain</h3>
<p>Although LLMs show a good understanding of natural and programming languages, efficiently transforming textual requirements into functional software in a single step remains a significant challenge. ChatDev thus adopts the core principles of the waterfall model, using a chat chain (C) with sequential phases (P), each comprising sequential subtasks (T). Specifically, ChatDev segments the software development process into three sequential phases: design, coding, and testing. The coding phase is further subdivided into subtasks of code writing and completion, and the testing phase is segmented into code review (static testing) and system testing (dynamic testing), as illustrated in Figure 2. In every subtask, two agents, each with their own specialized roles (<em>e.g.,</em> a reviewer skilled at identifying endless loops and a programmer adept in GUI design), perform the functions of an instructor (I) and an assistant (A). The instructor agent initiates instructions, instructing (→) the discourse toward the completion of the subtask, while the assistant agent adheres to these instructions and responds with (↔︎) appropriate solutions. They engage in a multi-turn dialogue (C), working cooperatively until they achieve consensus, extracting (↑) solutions that can range from the text (<em>e.g.,</em> defining a software function point) to code (<em>e.g.,</em> creating the initial version of source code), ultimately leading to the completion of the subtask. The entire task-solving process along the agentic workflow can be formulated as:</p>
<p>$$
\begin{aligned}
\mathcal{C} &amp;= \langle \mathcal{P}^{1}, \mathcal{P}^{2}, \dots, \mathcal{P}^{|\mathcal{C}|} \rangle \
\mathcal{P}^{i} &amp;= \langle \mathcal{T}^{1}, \mathcal{T}^{2}, \dots, \mathcal{T}^{|\mathcal{P}^{i}|} \rangle \
\mathcal{T}^{j} &amp;= \tau (\mathbf{C}(\mathcal{I}, \mathcal{A})) \
\mathbf{C}(\mathcal{I}, \mathcal{A}) &amp;= \langle \mathcal{I} \to \mathcal{A}, \mathcal{A} \sim \mathcal{I} \rangle_{\circlearrowleft}
\end{aligned}
\tag{1}
$$</p>
<p>The dual-agent communication design simplifies communications by avoiding complex multi-agent topologies, effectively streamlining the consensusreaching process <em>Yin et al. (2023); Chen et al. (2023b)</em>. Subsequently, the solutions from previous tasks serve as bridges to the next phase, allowing a smooth transition between subtasks. This approach continues until all subtasks are completed. It’s worth noting that the conceptually simple but empirically powerful chain-style structure guides agents on what to communicate, fostering cooperation and smoothly linking natural- and programming-language subtasks. It also offers a transparent view of the entire software development process, allowing for the examination of intermediate solutions and assisting in identifying possible problems.</p>
<p>Agentization To enhance the quality and reduce human intervention, ChatDev implements prompt engineering that only takes place at the start of each subtask round. As soon as the communication phase begins, the instructor and the assistant will communicate with each other in an automated loop, continuing this exchange until the task concludes. However, simply exchanging responses cannot achieve effective multi-round task-oriented communication, since it inevitably faces significant challenges including role flipping, instruction repeating, and fake replies. As a result, there is a failure to advance the progression of productive communications and hinders the achievement of meaningful solutions. ChatDev thus employs inception prompting mechanism <em>Li et al. (2023a)</em> for initiating, sustaining, and concluding agents’ communication to guarantee a robust and efficient workflow. This mechanism is composed of the instructor system prompt $\mathrm{P}<em A="A">{I}$ and the assistant system prompt $\mathrm{P}</em>}$. The system prompts for both roles are mostly symmetrical, covering the overview and objectives of the current subtask, specialized roles, accessible external tools, communication protocols, termination conditions, and constraints or requirements to avoid undesirable behaviors. Then, an instructor $\mathcal{I}$ and an assistant $\mathcal{A}$ are instantiated by hypnotizing LLMs via $\mathrm{P<em A="A">{I}$ and $\mathrm{P}</em>$:</p>
<p>$\mathcal{I}=\rho\left(L L M, \mathrm{P}<em A="A">{I}\right), \quad \mathcal{A}=\rho\left(L L M, \mathrm{P}</em>\right)$ (2)</p>
<p>where $\rho$ is the role customization operation, implemented via system message assignment.</p>
<p>Memory Note that the limited context length of common LLMs typically restricts the ability to maintain a complete communication history among all agents and phases. To tackle this issue, based on the nature of the chat chain, we accordingly segment the agents’ context memories based on their sequential phases, resulting in two functionally distinct types of memory: short-term memory and long-term memory. Short-term memory is utilized to sustain the continuity of the dialogue within a single phase, while long-term memory is leveraged to preserve contextual awareness across different phases.</p>
<p>Formally, short-term memory records an agent’s current phase utterances, aiding context-aware decision-making. At the time $t$ during phase $\mathcal{P}^{i}$, we use $\mathcal{I}<em t="t">{t}^{i}$ to represent the instructor’s instruction and $\mathcal{A}</em>$ collects utterances up to time $t$ as:}^{i}$ for the assistant’s response. The short-term memory $\mathcal{M</p>
<p>$\mathcal{M}<em 1="1">{t}^{i}=\left\langle\left(\mathcal{I}</em>}^{i}, \mathcal{A<em 2="2">{1}^{i}\right),\left(\mathcal{I}</em>}^{i}, \mathcal{A<em t="t">{2}^{i}\right), \ldots,\left(\mathcal{I}</em>\right)\right\rangle$ (3)}^{i}, \mathcal{A}_{t}^{i</p>
<p>In the next time step $t+1$, the instructor utilizes the current memory to generate a new instruction $\mathcal{I}<em t_1="t+1">{t+1}^{i}$, which is then conveyed to the assistant to produce a new response $\mathcal{A}</em>\right|$ :}^{i}$. The short-term memory iteratively updates until the number of communications reaches the upper limit $\left|\mathcal{M}^{i</p>
<p>$$
\begin{gathered}
\mathcal{I}<em t="t">{t+1}^{i}=\mathcal{I}\left(\mathcal{M}</em>}^{i}\right), \quad \mathcal{A<em t="t">{t+1}^{i}=\mathcal{A}\left(\mathcal{M}</em>}^{i}, \mathcal{I<em t_1="t+1">{t+1}^{i}\right) \
\mathcal{M}</em>}^{i}=\mathcal{M<em t_1="t+1">{t}^{i} \cup\left(\mathcal{I}</em>\right)
\end{gathered}
$$}^{i}, \mathcal{A}_{t+1}^{i</p>
<p>To perceive dialogues through previous phases, the chat chain only transmits the solutions from previous phases as long-term memories $\overline{\mathcal{M}}$, integrating them at the start of the next phase and enabling the cross-phase transmission of long dialogues:</p>
<p>$$
\mathcal{I}<em _mathcal_I="\mathcal{I">{1}^{i+1}=\overline{\mathcal{M}}^{i} \cup \mathrm{P}</em>\right)
$$}}^{i+1}, \quad \overline{\mathcal{M}}^{i}=\bigcup_{j=1}^{i} \tau\left(\mathcal{M}_{\left|\mathcal{M}^{j}\right|}^{j</p>
<p>where P symbolizes a predetermined prompt that appears exclusively at the start of each phase.</p>
<p>By sharing only the solutions of each subtask rather than the entire communication history, ChatDev minimizes the risk of being overwhelmed by too much information, enhancing concentration on each task and encouraging more targeted cooperation, while simultaneously facilitating cross-phase context continuity.</p>
<h3>3.2 Communicative Dehallucination</h3>
<p>LLM hallucinations manifest when models generate outputs that are nonsensical, factually incorrect, or inaccurate *Dhuliawala et al. (2023); Zhang</p>
<p>et al., 2023b). This issue is particularly concerning in software development, where programming languages demand precise syntax-the absence of even a single line can lead to system failure. We have observed that LLMs often produce coding hallucinations, which encompass potential issues like incomplete implementations, unexecutable code, and inconsistencies that don't meet requirements. Coding hallucinations frequently appear when the assistant struggles to precisely follow instructions, often due to the vagueness and generality of certain instructions that require multiple adjustments, making it challenging for agents to achieve full compliance. Inspired by this, we introduce communicative dehallucination, which encourages the assistant to actively seek more detailed suggestions from the instructor before delivering a formal response.</p>
<p>Specifically, a vanilla communication pattern between the assistant and the instructor follows a straightforward instruction-response format:</p>
<p>$$
\langle\mathcal{I} \rightarrow \mathcal{A}, \mathcal{A} \leadsto \mathcal{I}\rangle_{\odot}
$$</p>
<p>In contrast, our communicative dehallucination mechanism features a deliberate "role reversal", where the assistant takes on an instructor-like role, proactively seeking more specific information (e.g., the precise name of an external dependency and its related class) before delivering a conclusive response. After the instructor provides a specific modification suggestion, the assistant proceeds to perform precise optimization:</p>
<p>$$
\langle\mathcal{I} \rightarrow \mathcal{A},\langle\mathcal{A} \rightarrow \mathcal{I}, \mathcal{I} \sim \mathcal{A}\rangle_{\odot}, \mathcal{A} \sim \mathcal{I}\rangle_{\odot}
$$</p>
<p>Since this mechanism tackles one concrete issue at a time, it requires multiple rounds of communication to optimize various potential problems. The communication pattern instructs agents on how to communicate, enabling finer-grained information exchange for effective solution optimization, which practically aids in reducing coding hallucinations.</p>
<h2>4 Evaluation</h2>
<p>Baselines We chose some representative LLMbased software development methods as our baselines. GPT-Engineer (Osika, 2023) is a fundamental single-agent approach in LLM-driven software agents with a precise understanding of task requirements and the application of one-step reasoning, which highlights its efficiency in generating detailed software solutions at the repository level.</p>
<p>MetaGPT (Hong et al., 2023) is an advanced framework that allocates specific roles to various LLMdriven software agents and incorporates standardized operating procedures to enable multi-agent participation. In each step agents with specific roles generate solutions by adhering to static instructions predefined by human experts.</p>
<p>Datasets Note that, as of now, there isn't a publicly accessible dataset containing textual descriptions of software requirements in the context of agent-driven software development. To this end, we are actively working towards developing a comprehensive dataset for software requirement descriptions, which we refer to as SRDD (Software Requirement Description Dataset). Drawing on previous work (Li et al., 2023a), we utilize existing software descriptions as initial examples, which are then further developed through a process that combines LLM-based automatic generation with post-processing refinement guided by humans. As a result, this dataset includes important software categories from popular platforms such as Ubuntu, Google Play, Microsoft Store, and Apple Store. It comprises 1,200 software task prompts that have been carefully categorized into 5 main areas: Education, Work, Life, Game, and Creation. All these areas are further divided into 40 subcategories, and each subcategory contains 30 unique task prompts.</p>
<p>Metrics Evaluating software is also a challenging task, especially when trying to assess it on a holistic level. Under the current limitation of scarce benchmark resources, traditional function-oriented code generation metrics (e.g., pass@k), cannot seamlessly transfer to a comprehensive evaluation of entire software systems. The main reason for this is that it is often impractical to develop manual or automated test cases for various types of software, especially those involving complex interfaces, frequent user interactions, or non-deterministic feedback. As an initial strategy, we apply three fundamental and objective dimensions that reflect different aspects of coding hallucinations to evaluate the agent-generated software, and then integrate them to facilitate a more holistic evaluation:</p>
<ul>
<li>Completeness measures the software's ability to fulfill code completion in software development, quantified as the percentage of software without any "placeholder" code snippets. A higher score indicates a higher probability of automated completion.</li>
</ul>
<table>
<thead>
<tr>
<th>Method</th>
<th>Paradigm</th>
<th>Completeness</th>
<th>Executability</th>
<th>Consistency</th>
<th>Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-Engineer</td>
<td>95022^{†}</td>
<td>0.3583^{†}</td>
<td>0.7887^{†}</td>
<td>0.1419^{†}</td>
<td></td>
</tr>
<tr>
<td>MetaGPT</td>
<td>95022^{†}</td>
<td>0.4834^{†}</td>
<td>0.4145^{†}</td>
<td>0.7601^{†}</td>
<td>0.1523^{†}</td>
</tr>
<tr>
<td>ChatDev</td>
<td>95022^{†}</td>
<td>0.5600</td>
<td>0.8800</td>
<td>0.8021</td>
<td>0.3953</td>
</tr>
</tbody>
</table>
<p>Table 1: Overall performance of the LLM-powered software development methods, encompassing both single-agent (95) and multi-agent (95) paradigms. Performance metrics are averaged for all tasks. The top scores are in bold, with second-highest underlined. $\dagger$ indicates significant statistical differences (p$\leq$0.05) between a baseline and ours.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Evaluator</th>
<th>Baseline Wins</th>
<th>ChatDev Wins</th>
<th>Draw</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-Engineer</td>
<td>GPT-4</td>
<td>22.50%</td>
<td>77.08%</td>
<td>00.42%</td>
</tr>
<tr>
<td></td>
<td>Human</td>
<td>09.18%</td>
<td>90.16%</td>
<td>00.66%</td>
</tr>
<tr>
<td>MetaGPT</td>
<td>GPT-4</td>
<td>37.50%</td>
<td>57.08%</td>
<td>05.42%</td>
</tr>
<tr>
<td></td>
<td>Human</td>
<td>07.92%</td>
<td>88.00%</td>
<td>04.08%</td>
</tr>
</tbody>
</table>
<p>Table 2: Pairwise evaluation results.</p>
<ul>
<li>Executability assesses the software’s ability to run correctly within a compilation environment, quantified as the percentage of software that compiles successfully and can run directly. A higher score indicates a higher probability of successful execution.</li>
<li>Consistency measures how closely the generated software code aligns with the original requirement description, quantified as the cosine distance between the semantic embeddings of the textual requirements and the generated software code. A higher score indicates a greater degree of consistency with the requirements.</li>
<li>Quality is a comprehensive metric that integrates various factors to assess the overall quality of software, quantified by multiplying2 completeness, executability, and consistency. A higher quality score suggests a higher overall satisfaction with the software generated, implying a lower need for further manual intervention.</li>
</ul>
<p>Implementation Details We divided software development into 5 subtasks within 3 phases, assigning specific roles like CEO, CTO, programmer, reviewer, and tester. A subtask would terminate and get a conclusion either after two unchanged code modifications or after 10 rounds of communication. During the code completion, review, and testing, a communicative dehallucination is activated. For ease of identifying solutions, the assistant begins responses with "<SOLUTION>" when</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 3: Software statistics include Duration (time consumed), #Tokens (number of tokens used), #Files (number of code files generated), and #Lines (total lines of code across all files) in the software generation process.
a consensus is reached. We used ChatGPT-3.5 with a temperature of 0.2 and integrated Python-3.11.4 for feedback. All baselines in the evaluation share the same hyperparameters and settings for fairness.</p>
<h3>4.1 Overall Performance</h3>
<p>As illustrated in Table 1, ChatDev outperforms all baseline methods across all metrics, showing a considerable margin of improvement. Firstly, the improvement of ChatDev and MetaGPT over GPT-Engineer demonstrates that complex tasks are difficult to solve in a single-step solution. Therefore, explicitly decomposing the difficult problem into several smaller, more manageable subtasks enhances the effectiveness of task completion. Additionally, in comparison to MetaGPT, ChatDev significantly raises the Quality from 0.1523 to 0.3953. This advancement is largely attributed to the agents employing a cooperative communication method, which involves autonomously proposing and continuously refining source code through a blend of natural and programming languages, as opposed to merely delivering responses based on humanpredefined instructions. The communicative agents guide each subtask towards integrated and automated solutions, efficiently overcoming the restrictions typically linked to manually established optimization rules, and offering a more versatile and adaptable framework for problem-solving.</p>
<p>To further understand user preferences in practical settings, we use the setting adopted by Li et al. (2023a), where agent-generated solutions are com-</p>
<table>
<thead>
<tr>
<th>Variant</th>
<th>Completeness</th>
<th>Executability</th>
<th>Consistency</th>
<th>Quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>ChatDev</td>
<td>0.5600</td>
<td>0.8800</td>
<td>0.8021</td>
<td>0.3953</td>
</tr>
<tr>
<td>$\leq$ Coding</td>
<td>0.4100</td>
<td>0.7700</td>
<td>0.7958</td>
<td>0.2512</td>
</tr>
<tr>
<td>$\leq$ Complete</td>
<td>0.6250</td>
<td>0.7400</td>
<td>0.7978</td>
<td>0.3690</td>
</tr>
<tr>
<td>$\leq$ Review</td>
<td>0.5750</td>
<td>0.8100</td>
<td>0.7980</td>
<td>0.3717</td>
</tr>
<tr>
<td>$\leq$ Testing</td>
<td>0.5600</td>
<td>0.8800</td>
<td>0.8021</td>
<td>0.3953</td>
</tr>
<tr>
<td>$\backslash$ CDH</td>
<td>0.4700</td>
<td>0.8400</td>
<td>0.7983</td>
<td>0.3094</td>
</tr>
<tr>
<td>$\backslash$ Roles</td>
<td>0.5400</td>
<td>0.5800</td>
<td>0.7385</td>
<td>0.2212</td>
</tr>
</tbody>
</table>
<p>Table 4: Ablation study on main components or mechanisms. $\leq x$ denotes halting the chat chain after the completion of the $x$ phrase, and $\backslash$, denotes the removing operation. CDH denotes the communicative dehallucination mechanism.
pared in pairs by both human participants and the prevalent GPT-4 model to identify the preferred one. ${ }^{3}$ Table 2 shows ChatDev consistently outperforming other baselines, with higher average win rates in both GPT-4 and human evaluations.</p>
<p>Furthermore, the software statistics presented in Table 3 indicates that the multi-agent paradigm, despite being slower and consuming more tokens than the single-agent method, yields a greater number of code files and a larger codebase, which may enhance the software's functionality and integrity. Analyzing the dialogues of agents suggests that the multi-agent communication method often leads agents to autonomously offer functional enhancements (e.g., GUI creation or increasing game difficulty), thereby potentially resulting in the incorporation of beneficial features that were not explicitly specified in requirements. Taking all these factors together, we posit that the fundamental characteristics of multi-agent software development take on greater significance, surpassing short-term concerns like time and economic costs in the current landscape.</p>
<h3>4.2 Ablation Study</h3>
<p>This section examines key components or mechanisms within our multi-agent cooperation framework by removing particular phases in the chat chain, communicative dehallucination, or the roles assigned to all agents in their system prompts. Figure 4 shows that the code complete phase enhances Completeness, with testing critical for Executability. Quality steadily rises with each step, suggesting that software development optimization is progressively attained through multi-phase communica-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The utterance distribution of agent communications throughout the entire development process.
tions among intelligent agents. Meanwhile, eliminating communicative dehallucination results in a decrease across all metrics, indicating its effectiveness in addressing coding hallucinations. Most interestingly, the most substantial impact on performance occurs when the roles of all agents are removed from their system prompts. Detailed dialogue analysis shows that assigning a "prefer GUI design" role to a programmer results in generated source code with relevant GUI implementations; in the absence of such role indications, it defaults to implement unfriend command-line-only programs only. Likewise, assigning roles such as a "careful reviewer for bug detection" enhances the chances of discovering code vulnerabilities; without such roles, feedback tends to be high-level, leading to limited adjustments by the programmer. This finding underscores the importance of assigning roles in eliciting responses from LLMs, underscoring the significant influence of multi-agent cooperation on software quality.</p>
<h3>4.3 Communication Analysis</h3>
<p>Our agent-driven software development paradigm promotes cooperative agents through effective communication for automated solution optimization. Phases in the chat chain have varying levels of engagement in natural and programming languages.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The chart demonstrates the distribution of suggestions made by a reviewer agent during a multi-round reviewing process, where each sector in the chart represents a different category of suggestion.</p>
<p>We now analyze the content of their communications to understand linguistic effects.</p>
<p>Figure 3 depicts a communication breakdown, with natural language at 57.20%. In the natural-language phase (<em>i.e.,</em> design), natural language communication plays a crucial role in the thorough design of the system, with agents autonomously discussing and designing aspects like target user, data management, and user interface. Post-design phases show a balanced mix of coding, code completion, and testing activities, with most communication occurring during code reviews. This trend is due to agents' self-reviews and code fixes consistently propelling software development; otherwise, progress halts when successive updates don't show significant changes, leading to a natural decrease in code review communications.</p>
<p>We explore the properties of static debugging dynamics in code reviews resulting from communication between reviewers and programmers, as depicted in Figure 4. The data uncovers that during the review phase, reviewers may spot different issues through language interactions. The programmer's intervention can transform certain issues into different ones or a state where no further suggestions are needed; the increasing proportion of the latter indicates successful software optimization. Particularly, the "Method Not Implemented" issue is most common in communication between reviewers and programmers during code reviews, accounting for 34.85% of discussions. This problem usually arises from unclear text requirements and the use of "placeholder" tags in Python code, necessitating additional manual adjustments. Furthermore, the "Module Not Imported" issue often arises due to code generation omitting crucial details. Apart from common problems, reviewers often focus on enhancing code robustness by identifying rare exceptions, unused classes, or potential infinite loops.</p>
<p>Likewise, we analyze the tester-programmer communication during the testing phase, illustrating the dynamic debugging dynamics in their multi-turn interactions with compiler feedback, as depicted in Figure 5. The likelihood of successful compilation at each step is generally higher than encountering errors, with most errors persisting and a lower probability of transforming into different errors. The most frequent error is "ModuleNotFound" (45.76%), followed by "NameError" and "ImportError" (each at 15.25%). The observation highlights the model's tendency to overlook basic elements like an "import" statement, underscoring its difficulty in managing intricate details during code generation. Besides, the tester also detects rarer errors like improperly initialized GUIs, incorrect method calls, missing file dependencies, and unused modules. The communicative dehallucination mechanism effectively resolves certain errors, frequently resulting in "compilation success" after code changes. There's a significantly low chance of returning to an error state from a successful compilation. Over time, the multi-turn communication process statisti-</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" />Figure 5: The diagram illustrates the progression of iterations in a multi-round testing process, where each colored column represents a dialogue round, showcasing the evolution of the solution through successive stages of testing.
cally shows a consistent decrease in errors, steadily moving towards successful software execution.</p>
<h2>5 Conclusion</h2>
<p>We have introduced ChatDev, an innovative multiagent collaboration framework for software development that utilizes multiple LLM-powered agents to integrate fragmented phases of the waterfall model into a cohesive communication system. It features chat chain organizing communication targets and dehallucination for resolving coding hallucinations. The results demonstrate its superiority and highlight the benefits of multi-turn communications in software optimization. We aim for the insights to advance LLM agents towards increased autonomy and illuminate the profound effects of "language" and its empowering role across an even broader spectrum of applications.</p>
<h2>6 Limitations</h2>
<p>Our study explores the potential of cooperative autonomous agents in software development, but certain limitations and risks must be considered by researchers and practitioners. Firstly, the capabilities of autonomous agents in software production might be overestimated. While they enhance development quality, agents often implement simple logic, resulting in low information density. Without clear, detailed requirements, agents struggle to grasp task ideas. For instance, vague guidelines in developing a Snake game lead to basic representa-
tions; in information management systems, agents might retrieve static key-value placeholders instead of external databases. Therefore, it is crucial to clearly define detailed software requirements. Currently, these technologies are more suitable for prototype systems rather than complex real-world applications. Secondly, unlike traditional functionlevel code generation, automating the evaluation of general-purpose software is highly complex. While some efforts have focused on Human Revision Cost (Hong et al., 2023), manual verification for large datasets is impractical. Our paper emphasizes completeness, executability, consistency, and overall quality, but future research should consider additional factors such as functionalities, robustness, safety, and user-friendliness. Thirdly, compared to single-agent approaches, multiple agents require more tokens and time, increasing computational demands and environmental impact. Future research should aim to enhance agent capabilities with fewer interactions. Despite these limitations, we believe that engaging a broader, technically proficient audience can unlock additional potential directions in LLM-powered multi-agent collaboration.</p>
<h2>Acknowledgments</h2>
<p>The work was supported by the National Key R\&amp;D Program of China (No.2022ZD0116312), the Postdoctoral Fellowship Program of CPSF under Grant Number GZB20230348, and Tencent Rhino-Bird Focused Research Program.</p>
<h2>References</h2>
<p>Silvia T Acuna, Natalia Juristo, and Ana M Moreno. 2006. Emphasizing Human Capabilities in Software Development. In IEEE Software, volume 23, pages $94-101$.</p>
<p>Mansi Agnihotri and Anuradha Chug. 2020. A Systematic Literature Survey of Software Metrics, Code Smells and Refactoring Techniques. In booktitle of Information Processing Systems, volume 16, pages 915-934.</p>
<p>Rajiv D Banker, Gordon B Davis, and Sandra A Slaughter. 1998. Software Development Practices, Software Complexity, and Software Maintenance Performance: A Field Study. In Management science, volume 44, pages 433-450.</p>
<p>Victor R Basili. 1989. Software Development: A Paradigm for The Future. In Proceedings of the Annual International Computer Software and Applications Conference, pages 471-485. IEEE.</p>
<p>Thorsten Brants, Ashok C Popat, Peng Xu, Franz J Och, and Jeffrey Dean. 2007. Large Language Models in Machine Translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 858867.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems (NeurIPS), volume 33, pages 1877-1901.</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. In arXiv preprint arXiv:2303.12712.</p>
<p>Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. 2023. Large Language Models as Tool Makers. In arXiv preprint arXiv:2305.17126.</p>
<p>Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate. In arXiv preprint arXiv:2308.07201.</p>
<p>Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, and Haoyang Zhang. 2023a. GameGPT: Multi-agent</p>
<p>Collaborative Framework for Game Development. In arXiv preprint arXiv:2310.08067.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating Large Language Models Trained on Code. In arXiv preprint arXiv:2107.03374.</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023b. AgentVerse: Facilitating Multi-agent Collaboration and Exploring Emergent Behaviors in Agents. In International Conference on Learning Representations (ICLR).</p>
<p>Roi Cohen, May Hamri, Mor Geva, and Amir Globerson. 2023. LM vs LM: Detecting Factual Errors via Cross Examination. In ArXiv, volume abs/2305.13281.</p>
<p>Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023. Chain-of-Verification Reduces Hallucination in Large Language Models. In arXiv preprint arXiv:2309.11495.</p>
<p>Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, and Chunlei Chai. 2023. DesignGPT: MultiAgent Collaboration in Design. In arXiv preprint arXiv:2311.11591.</p>
<p>Michael D. Ernst. 2017. Natural Language is a Programming Language: Applying Natural Language Processing to Software Development. In Advances in Programming Languages (SNAPL), volume 71, pages 4:1-4:14.</p>
<p>Saad Ezzini, Sallam Abualhaija, Chetan Arora, and Mehrdad Sabetzadeh. 2022. Automated Handling of Anaphoric Ambiguity in Requirements: A Multisolution Study. In International Conference on Software Engineering (ICSE), pages 187-199.</p>
<p>Robert France and Bernhard Rumpe. 2007. Modeldriven Development of Complex Software: A Research Roadmap. In Future of Software Engineering (FOSE), pages 37-54.</p>
<p>Peter Freeman, Donald J. Bagert, Hossein Saiedian, Mary Shaw, Robert Dupuis, and J. Barrie Thompson. 2001. Software Engineering Body of Knowledge (SWEBOK). In Proceedings of the International Conference on Software Engineering (ICSE), pages 693-696.</p>
<p>Sa Gao, Chunyang Chen, Zhenchang Xing, Yukun Ma, Wen Song, and Shang-Wei Lin. 2019. A Neural Model for Method Name Generation from Functional Description. In 26th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pages 411-421.</p>
<p>Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, and Jürgen Schmidhuber. 2023. MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. In International Conference on Learning Representations (ICLR).</p>
<p>Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. 2023. War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars. In arXiv preprint arXiv:2311.17227.</p>
<p>Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of Hallucination in Natural Language Generation. In ACM Computing Surveys, volume 55, pages 1-38.</p>
<p>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling Laws for Neural Language Models. In arXiv preprint arXiv:2001.08361.</p>
<p>Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023a. CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. In Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS).</p>
<p>Yuan Li, Yixuan Zhang, and Lichao Sun. 2023b. MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents. In arXiv preprint arXiv:2310.06500.</p>
<p>Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, and Silvio Savarese. 2023. BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents. In arXiv preprint arXiv:2308.05960.</p>
<p>Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiaoman Pan, and Dong Yu. 2023. LASER: LLM Agent with State-Space Exploration for Web Navigation. In arXiv preprint arXiv:2309.08172.</p>
<p>Cuauhtémoc López Martín and Alain Abran. 2015. Neural networks for predicting the duration of new software projects. In J. Syst. Softw., volume 101, pages $127-135$.</p>
<p>Nadia Nahar, Shurui Zhou, Grace A. Lewis, and Christian Kästner. 2022. Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process. In IEEE/ACM International Conference on Software Engineering (ICSE), pages 413-425.</p>
<p>Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2023. CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis. In The International Conference on Learning Representations (ICLR).</p>
<p>Anton Osika. 2023. GPT-Engineer. In https://github.com/AntonOsika/gpt-engineer.</p>
<p>Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training Language Models to Follow Instructions with Human Feedback. In arXiv preprint arXiv:2203.02155.</p>
<p>Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2023. Generative Agents: Interactive Simulacra of Human Behavior. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology (UIST).</p>
<p>Florian Pudlitz, Florian Brokhausen, and Andreas Vogelsang. 2019. Extraction of System States from Natural Language Requirements. In IEEE International Requirements Engineering Conference (RE), pages 211-222.</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. 2023a. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-World APIs. In arXiv preprint arXiv:2307.16789.</p>
<p>Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, and Michael Bendersky. 2023b. Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting. In arXiv preprint arXiv:2306.17563.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language Models are Unsupervised Multitask Learners. In OpenAI Blog, volume 1, page 9.</p>
<p>Toran Bruce Richards. 2023. AutoGPT. In https://github.com/Significant-Gravitas/AutoGPT.</p>
<p>Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng, and Rui Zhao. 2023. TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage. In arXiv preprint arXiv:2308.03427.</p>
<p>Steve Sawyer and Patricia J. Guinan. 1998. Software development: Processes and Performance. In IBM Systems Journal, volume 37, pages 552-569.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. ToolFormer: Language Models Can Teach Themselves to Use Tools. In arXiv preprint arXiv:2302.04761.</p>
<p>Murray Shanahan, Kyle McDonell, and Laria Reynolds. 2023. Role Play with Large Language Models. In Nature, volume 623, pages 493-498.</p>
<p>Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths. 2023. Cognitive Architectures for Language Agents. In arXiv preprint arXiv:2309.02427.</p>
<p>Hannes Thaller, Lukas Linsbauer, and Alexander Egyed. 2019. Feature Maps: A Comprehensible Software Representation for Design Pattern Detection. In IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pages 207-217.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. LLaMA: Open and Efficient Foundation Language Models. In arXiv preprint arXiv:2302.13971.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is All You Need. In Advances in Neural Information Processing Systems (NeurIPS), volume 30.</p>
<p>Chengcheng Wan, Shicheng Liu, Sophie Xie, Yifan Liu, Henry Hoffmann, Michael Maire, and Shan Lu. 2022. Automated Testing of Software that Uses Machine Learning APIs. In IEEE/ACM International Conference on Software Engineering (ICSE), pages 212-224.</p>
<p>Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S. Yu. 2018. Improving Automatic Source Code Summarization via Deep Reinforcement Learning. In Proceedings of the ACM/IEEE International Conference on Automated Software Engineering (ASE), pages 397-407.</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023a. Voyager: An Open-ended Embodied Agent with Large Language Models. In arXiv preprint arXiv:2305.16291.</p>
<p>Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou, Jun Wang, and Ji-Rong Wen. 2023b. When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm. In arXiv preprint arXiv:2306.02552.</p>
<p>Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui. 2023c. Large Language Models are not Fair Evaluators. In arXiv preprint arXiv:2305.17926.</p>
<p>Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically Learning Semantic Features for Defect Prediction. In Proceedings of the International Conference on Software Engineering (ICSE), pages 297-308.</p>
<p>Song Wang, Nishtha Shrestha, Abarna Kucheri Subburaman, Junjie Wang, Moshi Wei, and Nachiappan Nagappan. 2021. Automatic Unit Test Generation for Machine Learning Libraries: How Far Are We? In IEEE/ACM International Conference on Software Engineering (ICSE), pages 1548-1560.</p>
<p>Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Haotian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing, and Zhiting Hu. 2023d. PromptAgent: Strategic Planning with Language Models Enables Expertlevel Prompt Optimization. In arXiv preprint arXiv:2310.16427.</p>
<p>Zhilin Wang, Yu Ying Chiu, and Yu Cheung Chiu. 2023e. Humanoid Agents: Platform for Simulating Human-like Generative Agents. In arXiv preprint arXiv:2310.05418.</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Emergent Abilities of Large Language Models. In arXiv preprint arXiv:2206.07682.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In Advances in Neural Information Processing Systems (NeurIPS), volume 35, pages 24824-24837.</p>
<p>Lilian Weng. 2023. LLM-powered Autonomous Agents. In lilianweng.github.io.</p>
<p>Jonas Winkler, Jannis Grönberg, and Andreas Vogelsang. 2020. Predicting How to Test Requirements: An Automated Approach. In Software Engineering, volume P-300 of $L N I$, pages 141-142.</p>
<p>Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023a. Large Language Models as Optimizers. In arXiv preprint arXiv:2309.03409.</p>
<p>Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, and Ying Shan. 2023b. GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction. In Advances in Neural Information Processing Systems (NeurIPS).</p>
<p>Murat Yilmaz, Rory V O'Connor, and Paul Clarke. 2012. A Systematic Approach to the Comparison of Roles in the Software Development Processes. In International Conference on Software Process Improvement and Capability Determination, pages 198-209. Springer.</p>
<p>Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, Xuanjing Huang, and Xipeng Qiu. 2023. Exchange-of-Thought: Enhancing Large Language</p>
<p>Model Capabilities through Cross-Model Communication. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 15135-15153.</p>
<p>An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang Deng, Xiang Wang, and Tat-Seng Chua. 2023a. On Generative Agents in Recommendation. In arXiv preprint arXiv:2310.10108.</p>
<p>Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. 2023b. Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. In arXiv preprint arXiv:2309.01219.</p>
<p>Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. 2023. ExpeL: LLM Agents Are Experiential Learners. In AAAI Conference on Artificial Intelligence (AAAI).</p>
<p>Tianming Zhao, Chunyang Chen, Yuanning Liu, and Xiaodong Zhu. 2021. GUIGAN: Learning to Generate GUI Designs Using Generative Adversarial Networks. In IEEE/ACM International Conference on Software Engineering (ICSE), pages 748-760.</p>
<p>Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. 2023a. WebArena: A Realistic Web Environment for Building Autonomous Agents. In arXiv preprint arXiv:2307.13854.</p>
<p>Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, and Mrinmaya Sachan. 2023b. Agents: An Open-source Framework for Autonomous Language Agents. In arXiv preprint arXiv:2309.07870.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ For fairness, GPT-4's evaluation mitigated possible positional bias (Wang et al., 2023c), and human experts independently assessed the task solutions, randomized to prevent order bias.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>