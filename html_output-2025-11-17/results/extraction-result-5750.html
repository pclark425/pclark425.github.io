<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5750 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5750</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5750</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-118.html">extraction-schema-118</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill qualitative laws, principles, or generalizable rules from large numbers of scholarly or scientific papers, including methods, results, limitations, and examples.</div>
                <p><strong>Paper ID:</strong> paper-268723544</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2403.18173v1.pdf" target="_blank">LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices</a></p>
                <p><strong>Paper Abstract:</strong> Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process. Our paper introduces and analyses a new information retrieval system using state-of-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements. Then We analyze the challenges and risks of using LLMs in the world of research. We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques. The GPT-3.5 model gains an accuracy of 58\% and a mean absolute error of 7.00. In contrast, the Llama2 model indicates an accuracy of 56\% with a mean absolute error of 7.63. The ability to answer questions was also included in the system in order to work with streamlined data. By evaluating the risks and opportunities presented by LLMs, our work contributes to the ongoing dialogue on establishing methodological validity and ethical guidelines for LLM use in HCI data work.</p>
                <p><strong>Cost:</strong> 0.007</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5750.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5750.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill qualitative laws, principles, or generalizable rules from large numbers of scholarly or scientific papers, including methods, results, limitations, and examples.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial Large Language Model used in this study via API to extract structured experimental parameters from HCI papers; paired with preprocessing (NER, keyword extraction) and human verification to produce vectors of paper features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-3.5 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Described in the paper as a state-of-the-art GPT-3.5 family model accessed through OpenAI API (paper reports large pretraining scale; used as an API service with a 4096 token limit).</td>
                        </tr>
                        <tr>
                            <td><strong>task_goal</strong></td>
                            <td>Automatic extraction of experimental parameters (e.g., number of participants, recruitment method, number of tasks, type of experiment, experimental variables, number of trials) from HCI research papers to produce structured vectors representing each paper.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Human-Computer Interaction (HCI) research papers (CHI 2020-2022 subset).</td>
                        </tr>
                        <tr>
                            <td><strong>methodology</strong></td>
                            <td>Preprocessing (remove headers/references, NER, keyword extraction) + prompt-based API calls sending paper text to GPT-3.5 with task-specific prompts to produce structured parameter outputs; outputs compared to manually annotated vectors. System includes error handling, API-key rotation, latency/memory measurement, and human verification.</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_qualitative_law</strong></td>
                            <td>Not applicable — the model was used for structured information extraction of experimental parameters rather than to distill explicit qualitative laws or general principles. The extracted structured dataset could serve as input for future rule/law synthesis but no laws were distilled in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Mean Absolute Error (MAE) between model-predicted vectors and human-annotated vectors, accuracy of extracted labels (with a tolerance of ±1 for numerical features), baseline comparison against random samples from a fitted normal distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT-3.5 outperformed Llama-2 on the extraction task in this study: reported accuracy ~58% overall (62% on numerical features with ±1 tolerance) and MAE = 7; faster processing speed and lower latency (~4.52 s per paper) and higher memory consumption (~166.42 MB) compared to Llama-2. Both models substantially outperformed a random baseline (~13% accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>human_involvement</strong></td>
                            <td>Human-in-the-loop: manual annotation of a 300-paper subset (from 2148 collected CHI papers) used as ground truth; manual checks and corrections performed, particularly for ambiguous or multi-stage experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_corpus</strong></td>
                            <td>Collected 2148 CHI articles (2020–2022); random subset of 300 articles (100 per year) used for detailed annotation and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Dependence on input file formats (PDF/HTML/etc.); token limit constraints (4096 tokens) when sending long texts via API; reliance on online API access (no offline use); errors in handling multi-stage experiments (models sometimes report only first-stage participants), task-counting ambiguities, and human annotation is time-consuming and not error-free; domain/timeframe limited to CHI 2020–2022.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>No distilled qualitative laws reported; concrete extraction targets reported were: Number of Participants, Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables (independent levels and controls), and Number of Trials.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5750.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5750.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill qualitative laws, principles, or generalizable rules from large numbers of scholarly or scientific papers, including methods, results, limitations, and examples.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2 (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2 (70 billion parameter variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source LLM (Llama-2 family) used in this study via API to extract the same structured experimental parameters from HCI papers; evaluated alongside GPT-3.5 for accuracy, latency, memory, and processing speed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Llama-2 (70B)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Described in the paper as Meta's Llama-2 family (available in sizes 7B, 13B, 70B); used via API with a 4096 token limit; open-source model with community-driven improvements (paper reports training on large token counts).</td>
                        </tr>
                        <tr>
                            <td><strong>task_goal</strong></td>
                            <td>Same as GPT-3.5: extract experimental/design parameters from HCI papers to produce structured vectors for each paper, enabling large-scale analysis of experimental practices.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Human-Computer Interaction (HCI) research papers (CHI 2020-2022 subset).</td>
                        </tr>
                        <tr>
                            <td><strong>methodology</strong></td>
                            <td>Same pipeline as GPT-3.5: document preprocessing (NER, keyword extraction, header/reference removal) then prompt-based extraction using Llama-2 API, with outputs compared to manual annotations using MAE and accuracy measures; system logs latency and memory consumption.</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_qualitative_law</strong></td>
                            <td>Not applicable — Llama-2 was applied to structured information extraction, not to synthesize or distill qualitative laws or general principles within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Mean Absolute Error (MAE) and accuracy of extracted labels (numerical tolerance ±1 for minor discrepancies); baseline random-sampling comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Llama-2 performed slightly worse than GPT-3.5 on extraction accuracy: reported accuracy ~56% (59% on numerical features with ±1 tolerance) and MAE = 7.63; much higher latency (~31.22 s per paper) but lower memory consumption (~91.70 MB); processing speed notably lower than GPT-3.5 in this implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_involvement</strong></td>
                            <td>Human-in-the-loop: same manual annotation and verification process for the 300-paper subset; manual review used to compute evaluation metrics and correct ambiguous extractions.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_or_corpus</strong></td>
                            <td>Same corpus: 2148 CHI articles collected (2020–2022) with a manually-annotated subset of 300 used for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Same as GPT-3.5: format dependence, token limits, reliance on online API, difficulties with multi-stage experiments and task counting; additionally, in this implementation Llama-2 exhibited higher latency and slower processing throughput which affected scalability in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>No examples of distilled qualitative laws; reported extracted items include Number of Participants, Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables, and Number of Trials.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Inpars-v2: large language models as efficient dataset generators for information retrieval <em>(Rating: 2)</em></li>
                <li>Hagrid: a human-llm collaborative dataset for generative information-seeking with attribution <em>(Rating: 2)</em></li>
                <li>Retrieval augmented generation and representative vector summarization for large unstructured textual data in medical education <em>(Rating: 1)</em></li>
                <li>In-context retrieval-augmented language models <em>(Rating: 1)</em></li>
                <li>Reimagining retrieval augmented language models for answering queries <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5750",
    "paper_id": "paper-268723544",
    "extraction_schema_id": "extraction-schema-118",
    "extracted_data": [
        {
            "name_short": "GPT-3.5 (text-davinci-003)",
            "name_full": "GPT-3.5 (text-davinci-003)",
            "brief_description": "A commercial Large Language Model used in this study via API to extract structured experimental parameters from HCI papers; paired with preprocessing (NER, keyword extraction) and human verification to produce vectors of paper features.",
            "citation_title": "LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices",
            "mention_or_use": "use",
            "llm_model_name": "GPT-3.5 (text-davinci-003)",
            "llm_model_description": "Described in the paper as a state-of-the-art GPT-3.5 family model accessed through OpenAI API (paper reports large pretraining scale; used as an API service with a 4096 token limit).",
            "task_goal": "Automatic extraction of experimental parameters (e.g., number of participants, recruitment method, number of tasks, type of experiment, experimental variables, number of trials) from HCI research papers to produce structured vectors representing each paper.",
            "domain": "Human-Computer Interaction (HCI) research papers (CHI 2020-2022 subset).",
            "methodology": "Preprocessing (remove headers/references, NER, keyword extraction) + prompt-based API calls sending paper text to GPT-3.5 with task-specific prompts to produce structured parameter outputs; outputs compared to manually annotated vectors. System includes error handling, API-key rotation, latency/memory measurement, and human verification.",
            "type_of_qualitative_law": "Not applicable — the model was used for structured information extraction of experimental parameters rather than to distill explicit qualitative laws or general principles. The extracted structured dataset could serve as input for future rule/law synthesis but no laws were distilled in this paper.",
            "evaluation_metrics": "Mean Absolute Error (MAE) between model-predicted vectors and human-annotated vectors, accuracy of extracted labels (with a tolerance of ±1 for numerical features), baseline comparison against random samples from a fitted normal distribution.",
            "results_summary": "GPT-3.5 outperformed Llama-2 on the extraction task in this study: reported accuracy ~58% overall (62% on numerical features with ±1 tolerance) and MAE = 7; faster processing speed and lower latency (~4.52 s per paper) and higher memory consumption (~166.42 MB) compared to Llama-2. Both models substantially outperformed a random baseline (~13% accuracy).",
            "human_involvement": "Human-in-the-loop: manual annotation of a 300-paper subset (from 2148 collected CHI papers) used as ground truth; manual checks and corrections performed, particularly for ambiguous or multi-stage experiments.",
            "dataset_or_corpus": "Collected 2148 CHI articles (2020–2022); random subset of 300 articles (100 per year) used for detailed annotation and evaluation.",
            "limitations_or_challenges": "Dependence on input file formats (PDF/HTML/etc.); token limit constraints (4096 tokens) when sending long texts via API; reliance on online API access (no offline use); errors in handling multi-stage experiments (models sometimes report only first-stage participants), task-counting ambiguities, and human annotation is time-consuming and not error-free; domain/timeframe limited to CHI 2020–2022.",
            "notable_examples": "No distilled qualitative laws reported; concrete extraction targets reported were: Number of Participants, Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables (independent levels and controls), and Number of Trials.",
            "uuid": "e5750.0",
            "source_info": {
                "paper_title": "LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Llama-2 (70B)",
            "name_full": "Llama-2 (70 billion parameter variant)",
            "brief_description": "An open-source LLM (Llama-2 family) used in this study via API to extract the same structured experimental parameters from HCI papers; evaluated alongside GPT-3.5 for accuracy, latency, memory, and processing speed.",
            "citation_title": "LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices",
            "mention_or_use": "use",
            "llm_model_name": "Llama-2 (70B)",
            "llm_model_description": "Described in the paper as Meta's Llama-2 family (available in sizes 7B, 13B, 70B); used via API with a 4096 token limit; open-source model with community-driven improvements (paper reports training on large token counts).",
            "task_goal": "Same as GPT-3.5: extract experimental/design parameters from HCI papers to produce structured vectors for each paper, enabling large-scale analysis of experimental practices.",
            "domain": "Human-Computer Interaction (HCI) research papers (CHI 2020-2022 subset).",
            "methodology": "Same pipeline as GPT-3.5: document preprocessing (NER, keyword extraction, header/reference removal) then prompt-based extraction using Llama-2 API, with outputs compared to manual annotations using MAE and accuracy measures; system logs latency and memory consumption.",
            "type_of_qualitative_law": "Not applicable — Llama-2 was applied to structured information extraction, not to synthesize or distill qualitative laws or general principles within this paper.",
            "evaluation_metrics": "Mean Absolute Error (MAE) and accuracy of extracted labels (numerical tolerance ±1 for minor discrepancies); baseline random-sampling comparison.",
            "results_summary": "Llama-2 performed slightly worse than GPT-3.5 on extraction accuracy: reported accuracy ~56% (59% on numerical features with ±1 tolerance) and MAE = 7.63; much higher latency (~31.22 s per paper) but lower memory consumption (~91.70 MB); processing speed notably lower than GPT-3.5 in this implementation.",
            "human_involvement": "Human-in-the-loop: same manual annotation and verification process for the 300-paper subset; manual review used to compute evaluation metrics and correct ambiguous extractions.",
            "dataset_or_corpus": "Same corpus: 2148 CHI articles collected (2020–2022) with a manually-annotated subset of 300 used for evaluation.",
            "limitations_or_challenges": "Same as GPT-3.5: format dependence, token limits, reliance on online API, difficulties with multi-stage experiments and task counting; additionally, in this implementation Llama-2 exhibited higher latency and slower processing throughput which affected scalability in practice.",
            "notable_examples": "No examples of distilled qualitative laws; reported extracted items include Number of Participants, Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables, and Number of Trials.",
            "uuid": "e5750.1",
            "source_info": {
                "paper_title": "LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Inpars-v2: large language models as efficient dataset generators for information retrieval",
            "rating": 2,
            "sanitized_title": "inparsv2_large_language_models_as_efficient_dataset_generators_for_information_retrieval"
        },
        {
            "paper_title": "Hagrid: a human-llm collaborative dataset for generative information-seeking with attribution",
            "rating": 2,
            "sanitized_title": "hagrid_a_humanllm_collaborative_dataset_for_generative_informationseeking_with_attribution"
        },
        {
            "paper_title": "Retrieval augmented generation and representative vector summarization for large unstructured textual data in medical education",
            "rating": 1,
            "sanitized_title": "retrieval_augmented_generation_and_representative_vector_summarization_for_large_unstructured_textual_data_in_medical_education"
        },
        {
            "paper_title": "In-context retrieval-augmented language models",
            "rating": 1,
            "sanitized_title": "incontext_retrievalaugmented_language_models"
        },
        {
            "paper_title": "Reimagining retrieval augmented language models for answering queries",
            "rating": 1,
            "sanitized_title": "reimagining_retrieval_augmented_language_models_for_answering_queries"
        }
    ],
    "cost": 0.00718375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices
27 Mar 2024</p>
<p>Neda Taghizadeh 
Sharif University of Technology Tehran
TehranIran Iman Mohammadi</p>
<p>Sharif University of Technology Tehran
TehranIran Vittorio Fuccella</p>
<p>University of Salerno Fisciano (SA)
Italy</p>
<p>Mattia De Rosa</p>
<p>University of Salerno Fisciano (SA)
Italy</p>
<p>LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices
27 Mar 2024A9720B5D0A26918AA2A8407739838D73arXiv:2403.18173v1[cs.HC]Large Language Models' Information RetrievalStructured Text AnalysisHuman-Computer Interaction LiteratureScientific Papers' Experiment ParametersData Retrieval Accuracy
Efficient and accurate information extraction from scientific papers is significant in the rapidly developing human-computer interaction research in the literature review process.Our paper introduces and analyses a new information retrieval system using stateof-the-art Large Language Models (LLMs) in combination with structured text analysis techniques to extract experimental data from HCI literature, emphasizing key elements.Then We analyse the challenges and risks of using LLMs in the world of research.We performed a comprehensive analysis on our conducted dataset, which contained the specified information of 300 CHI 2020-2022 papers, to evaluate the performance of the two large language models, GPT-3.5 (text-davinci-003) and Llama-2-70b, paired with structured text analysis techniques.The GPT-3.5 model gains an accuracy of 58% and a mean absolute error of 7.00.In contrast, the Llama2 model indicates an accuracy of 56% with a mean absolute error of 7.63.The ability to answer questions was also included in the system in order to work with streamlined data.By evaluating the risks and opportunities presented by LLMs, our work contributes to the ongoing dialogue on establishing methodological validity and ethical guidelines for LLM use in HCI data work.CCS CONCEPTS• Information Retrieval → Interactive systems and tools.</p>
<p>INTRODUCTION</p>
<p>The field of human-computer interaction (HCI) has been developing rapidly these years, and the wide range of information and its scientific contributions indicate proof of that statement.As the HCI knowledge extends exponentially, the need to collect efficient and accurate information for the literature review part of research becomes critical [12].In response to this data-rich era, our research tries to introduce a novel approach for HCI researchers to extract and interpret information from scientific documents.Our study is a new method of information retrieval by using advanced techniques and Large Language Models (LLM) combined [15].By experimenting with the capabilities of prominent LLMs such as GPT-3.5 [1] and Llama2 [5], we can reach our goal, which is to improve HCI research by extracting accurate and deep understanding of experimental data and answering user questions from the scientific papers [4].The reason we chose these experimental data as the recording parameters of each paper is that the complexity of extracting this type of data indicated high [12], and it comes from different understandings researchers may have from them.However, because of this type of complexity, we aim to extract this valuable information with high accuracy from each paper [12].Moreover, some of the parameters extracted by the models were very different from the obtained human parameters, which we investigated.We also review a comprehensive analysis performed on a smaller selected dataset, randomly, consisting of 300 papers from CHI conferences between 2020 and 2022.Our methodology not only has good accuracy in data mining but also addresses the complexities of user studies, interviews, and controlled experiments.Also, due to our manual checks, we recorded the values of each required parameter specifically.Eventually we were able to report the accuracy of our work, and we reached a favorable result [3].Another feature of our approach is the ability to process a wide range of file formats.This adaptability makes our method flexible, allowing it to keep up with the changing world of digital publishing.Furthermore, users can seamlessly engage with our developed userfriendly interface, finding answers to their questions on the input documents.</p>
<p>RELATED WORKS</p>
<p>The field of Human-Computer Interaction (HCI) and scientific literature information extraction has seen the appearance of numerous innovative tools designed for specific purposes.Before discussing other similar tools in this domain, it is crucial to mention our system.Our system is meticulously designed to combine the capabilities of Large Language Models with structured text analysis.By doing so, we're not just merely extracting data but interpreting, categorizing, and presenting the specified information in a coherent and user-friendly format.Our approach involves conducting a literature review focused on the experimental sections of HCI papers.This section will provide a comprehensive overview of several notable tools, explaining their functionalities and contextualizing them within HCI and information extraction.Throughout the exploration of each tool, we will highlight their advantages and compare them to our system.</p>
<p>Existing Tools</p>
<p>This section explores different information extraction tools, focusing on their features and functionalities.Also, in Table 1, we provide a brief view of these tools and our work.</p>
<p>2.1.1Grobid.Grobid [6] is a machine-learning library that extracts structured metadata from academic documents [7], focusing on PDF extraction.It excels in bibliographic database applications, but our tool offers a more general approach, despite longer processing times using LLMs.</p>
<p>2.1.2CoreNLP.Stanford CoreNLP, developed by the Stanford NLP Group[9], offers a variety of linguistic tools for tasks like tokenization and parsing across multiple languages.Our system combines preprocessing and direct data extraction, providing users with the flexibility to choose between streamlined but slower information extraction or faster offline preprocessing based on their needs.</p>
<p>Elastic Search.</p>
<p>Elasticsearch is a powerful search engine that analyzes big data in real-time [2].It uses flexible JSON documents and a compatible Web API.The system discussed improves search by extracting and interpreting data from scientific literature, especially in HCI.This integrated approach offers users structured information, giving the tool a unique edge in data processing.</p>
<p>LLMs</p>
<p>As the digital age progresses, Large Language Models (LLMs) have come to the forefront of information retrieval[16], representing a paradigm shift in how data is parsed, understood, and presented [11].Rooted in deep learning, LLMs like GPT-2 [10,1] have the capacity to comprehend vast swaths of text [13], extracting not just explicit facts but also nuanced insights [3].They are also adaptive [8], learning from new data and user interactions, making them adept at handling the dynamism of modern digital content [14].Moreover, with their capability to work across languages and domains, they transcend geographical and disciplinary boundaries [12].</p>
<p>METHOD</p>
<p>Our project aims to develop a tool that automates the extraction of information from empirical papers in the field of Human-Computer Interaction, following the APA Style guidelines.</p>
<p>The experiment aims to gather important information for HCI research papers, including details like the number of participants, recruitment methods, tasks, type of experiment, and specifics about experimental variables and trials.This data is valuable for literature reviews in the field.</p>
<p>In order to improve text processing for model analysis, we used techniques like Named Entity Recognition (NER) to identify important entities and Keyword Extraction to prioritize key phrases.We also removed unnecessary elements like references and headers to minimize program overhead and focus on relevant content.Our system supports HTML and PDF formats commonly used in academic publishing.HTML is great for online reading, while PDFs are convenient for offline access.We also handle compressed files like zip, rar, and 7z, making it easier to work with academic documents.The document processing uses a Python framework with BeautifulSoup for HTML, PyPDF2 for PDF, and LLMs for OpenAI and Llama2 API integration to automatically extract important experimental data from scientific papers, making data handling faster and more accurate.The implementation of our information extraction system faced challenges with HTML and PDF formats.HTML changes in tags, classes, and styles required adapting the parser to each file's unique structure.PDFs, with binary formats and embedded elements, posed obstacles in data extraction.Addressing these complexities was crucial for ensuring the reliability of our system.</p>
<p>The main focus of this implementation is the interaction with Llama2 [5] and GPT3.5 [1] APIs, where the text of each article is processed based on a defined prompt.Implemented a method that acts as a bridge, sending paper content to an API and retrieving targeted details.The code includes features to handle errors, switch between API keys, and measure performance metrics like latency and memory consumption for extraction efficiency insights.</p>
<p>The prompt discussed the need to include specific output values related to a parameter model, such as Number of Participants, Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables, and Number of Trials.It also highlighted the importance of avoiding redundant or irrelevant explanations in the command.Emphasis was placed on key items to improve understanding.The suggestion was made to focus on writing a parameter model with a comprehensive explanation, summary, and emphasis on crucial parts, particularly for long short-term memory (LSTM) models.</p>
<p>We assessed the system's performance using measures like latency, processing speed, and memory consumption, summarized in Table 2. Latency, the time to process a document, is crucial for responsiveness.Lower latency enables handling large datasets quickly.Processing speed, measured as papers processed per unit time, gauges system consistency across diverse datasets.Memory consumption indicates resource utilization, ensuring scalability for larger inputs without slowdowns or crashes.</p>
<p>Dataset Construction</p>
<p>We collected 2148 articles from 2020 to 2022 CHI conferences to study HCI research trends.We randomly picked 300 articles (100 per year) and reviewed them with our system.Each article was carefully annotated based on specific criteria.</p>
<p>Number of participants and recruitment method.</p>
<p>The dataset shows how participants were chosen for each study, considering factors like age, gender, and relevant skills.</p>
<p>3.1.2Number of tasks.We noted how many tasks participants had in each study, giving us insights into workload and testing complexity.</p>
<p>Type of Experiment.</p>
<p>We sorted studies by their experimental design, covering methods like user studies, interviews, lab experiments, and online surveys.Brief explanations were given for the chosen experimental approaches.</p>
<p>3.1.4Experimental variables.Detailed annotations were made to identify and specify the experimental variables used in each study.This comprehensive documentation includes the independent variables, their associated levels, and any control variables that are integrated to reduce potential confounding effects.</p>
<p>Number of trials.</p>
<p>For experiments involving repeated or repetitive tasks, we detailed the total number of trials performed by participants for each specific task.These data shed light on the participation and repetition of participants in the experiments.Considering these criteria, our dataset not only provides a snapshot of recent HCI research methods but also serves as a good resource for understanding and comparing the complexities of experimental design across many studies.This dataset serves as a valuable asset for researchers seeking to explore the landscape of HCI research methods and trends.</p>
<p>EVALUATION</p>
<p>Two evaluation methods, mean absolute error (MAE) and accuracy, are used for evaluating the system's performance by comparing the accuracy and similarity of information extracted by the system to manually selected vectors for each paper.</p>
<p>MAE</p>
<p>Our approach involves representing each article as a vector containing extracted features.Each vector serves as a representation of the corresponding paper.The evaluation process is focused on evaluating the alignment of the output vectors of the models with the manually generated vectors for each article.Specifically, we use the MAE method and treat the problem as a regression task.The goal is for the models to accurately reconstruct the vector of each article.MAE represents the regression error, which indicates the closeness of the reconstructed vectors by the model to the original vectors.For the GPT-3.5 model [1], LOSS MAE was equal to 7, which indicates a relatively strong performance in reconstructing paper vectors.In comparison, the Llama model [5] achieved a LOSS MAE of 7.63, indicating a slightly lower accuracy.Therefore, the GPT-3.5 model [1] performed better than Llama [5] in this evaluation method.
MAE = 1 =1 | − ˆ | ≤approximation level MAE represents the Mean Absolute Error.
is the total number of data points (articles) represents the actual value (manually obtained vector for each article)</p>
<p>ˆ represents the predicted value (vector generated by the model) "Approximation Level" is the threshold for the absolute difference that determines whether the indicator function equals 1 or 0 | − ˆ | ≤ approximation level is the indicator function that checks whether the absolute difference between and ˆ is less than or equal to the specified approximation level.</p>
<p>Accuracy</p>
<p>In this evaluation method, we look at the features extracted from articles as labels.We compare the labels generated by the system with manually collected ones to measure accuracy.Higher accuracy means more precise feature extraction.Overall, GPT-3.5 [1] performed slightly better in predicting features compared to manual evaluation.</p>
<p>Approximation of one.</p>
<p>For minor numerical discrepancies, a tolerance of one is allowed, enhancing accuracy calculations.Under this criterion, GPT-3.5'saccuracy for numerical features is 62%, surpassing Llama's 59%.This emphasizes the data retrieval system's efficiency.</p>
<p>Baseline approach.</p>
<p>A baseline comparison using randomly generated samples from a fitted normal distribution against the actual data reveals a mere 13% accuracy.This underscores the substantial advancement of our models over random approximation, with GPT-3.5 and Llama outperforming the baseline by 45% and 43%, respectively.</p>
<p>RESULT</p>
<p>In the early stages of this project, our goal was to implement an efficient system for information retrieval from scientific articles, coupled with an interface that users found effortless to use.Then implementing LLM information retrieval as the main method was a strategic decision driven by its proven effectiveness in handling large volumes of academic data and its adaptability to diverse research contexts.Bearing these ideas, a comprehensive analysis was made from the two models, GPT [1] and Llama [5].GPT [1] consistently outperformed Llama [5] across various accuracy metrics.While both models had high capabilities, GPT's [1] baseline accuracy (58%) marginally surpassed Llama's (56%) [5].This difference was further accentuated when assessing the Mean Absolute Error (MAE), where GPT's [1]predictions showed a lower deviation from actual values with an MAE of 7, compared to Llama's 7.63 [5].To specifically determine the GPT [1] and Llama models' [5] efficacy, we evaluated some more performance metrics in specific tasks.Table 1 shows that when it comes to processing speed, GPT [1] is about 7 times higher than Llama [5].The max token limit was another limitation that we had to face in the system's implementation.Both of the models had the same amount of tokens limit while using their APIs.In terms of latency, GPT 3.5 [1] exhibited a significantly faster response time of approximately 4.52 seconds per paper, while Llama [5] took notably longer with an average latency of 31.22 seconds per paper.When evaluating memory consumption, GPT 3.5 [1] utilized around 166.42 MB of memory, in contrast to the more efficient Llama [5], which consumed just about 91.70 MB.</p>
<p>DISCUSSION</p>
<p>The paper highlights the advantages of using LLMs in a data recovery tool.These models improve accuracy, efficiency, and user understanding of the recovered information.The tool can handle various file formats, including PDF, HTML, 7z, zip, and rar.Another advantage of our study is the collection and use of a comprehensive dataset of 2148 CHI articles related to human-computer interaction (HCI).We selected a subset of 300 articles underwent a rigorous human review process, which allowed us to measure the accuracy of our methodology using the exact recall method.Careful examination of this subset ensures that it has the necessary diversity and specificity, making it particularly valuable for quality assessment.Therefore, given the scope and limitations of our study, focusing on a smaller yet representative sample was a more manageable and efficient approach.This strategy not only ensured accuracy but also reduced surveillance risk.In doing so, we maintained the integrity of our research while increasing efficiency, given the study's specific goals and limitations.Almost all the models that are prepared and taught today can meet the needs of users with accuracy and information, but the important thing is to choose them according to your needs.We used 2 models, GPT-3.5 [1] and Lama2, for this system.The GPT-3.5 [1] model has unparalleled accuracy because it has been trained on about 45 terabytes of data and 175 bytes of trained parameters.Llama Model 2 [5] is open source and promotes continuous improvement from the global developer community.Meta trained and published Llama-2 [5] in three model sizes: 7, 13, and 70 billion parameters, and they are trained on 2 trillion tokens.</p>
<p>Reasons of Accuracy Decrease</p>
<p>In the process of manual verification and comparison of our system's outputs with the original data from the articles, several noteworthy observations came to our mind.These insights provide valuable context for interpreting the performance of the models.</p>
<p>Handling of Multi-Stage Experiments: In multi-stage experiments, a common issue is that models often only report the number of participants in the initial phase, ignoring those in later stages.This can be problematic when participant counts vary across stages.Despite this limitation, manual checks were conducted to address the issue.</p>
<p>Task Counting Accuracy: Another noteworthy observation concerns the extraction of task counts.When articles state, for example, "We administered tests to participants across n tests, including m phases, " the models often extract the value n, whereas our desired output was × .This highlights the need for refining the models' ability to capture the intricacies of task counting within sentences.</p>
<p>These observations shed light on specific challenges and nuances encountered during the evaluation process.</p>
<p>Limitation</p>
<p>While our study provides a significant contribution to information mining in human-computer interaction (HCI) research, it is important to acknowledge its inherent limitations, which include: Dependency format.The effectiveness of our system depends on the compatibility of the input data with the specified file formats (e.g.text, pdf, HTML, zip, rar, 7z).</p>
<p>Limited data set selection.Although we selected a representative subset of articles for analysis, our dataset includes a specific time frame (CHI articles from 2020 to 2022).Also, finding the required information and checking it manually is very time-consuming and difficult, and because some of the data collected to calculate the accuracy of the system is collected by humans, it is definitely not 100% error-free.</p>
<p>Dependence on online access.Our data retrieval tool relies on online access to large language models (LLM) through APIs.As a result, it cannot be used offline.</p>
<p>Experimenting based on complex parameters.In the experiment part, we assessed our system's proficiency in extracting specific values from documents by finding the values of the Number of Participants and Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables, and Number of Trials of 300 papers in our dataset.These parameters are notably ambiguous and challenging to pinpoint in scientific papers which contain experimental data.This complexity comes from the fact that each can have different definitions depending on the research domain.</p>
<p>While these limitations are inherent to our current implementation, they also present opportunities for future research and tool modification to address these challenges and expand the usability and utility of the tool.</p>
<p>Table 1 :
1
Comparison of Various Systems.
NameMain PurposeProgramming LanguageOpen SourceLicenseSpeedScalabilityGrobidPDF extractionJavaYesApache 2.0Over 36 PDFs per secondModerateCoreNLPNLP ToolkitJavaYesGPLOver 1000 words per secondHighElasticsearchSearch and Analytics EngineJavaYesApache 2.0Over 1000 documents per secondHighOur SystemInformation ExtractionPythonYesMITIt depends on the API model usedHigh</p>
<p>Table 2 :
2
Comparative Performance Metrics of LLMs.
Parameter/ModelGPT 3.5Llama2Accuracy5856mean absolute error77.63Processing Speed (papers/sec) 0.22105924780.03103395873Max Token Limit4,096 tokens4096 tokensLatency (s)4.5236741273 seconds 31.2227663099Memory Consumption (MB)166.416445312591.702734375</p>
<p>. Chatgpt, Chatgpt. chat.openai.com. </p>
<p>Elasticsearch: Distributed search &amp; analytics engine 2023. Sw] Elasticsearch, Contributors, </p>
<p>Inpars-v2: large language models as efficient dataset generators for information retrieval. Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, Rodrigo Nogueira, arXiv:2301.01820[cs.IR]2023. 2023</p>
<p>Hagrid: a human-llm collaborative dataset for generative informationseeking with attribution. Ehsan Kamalloo, Aref Jafari, Xinyu Zhang, Nandan Thakur, Jimmy Lin, arXiv:2307.16883[cs.CL]2023. 2023</p>
<p>. Llama. meta.com. </p>
<p>Grobid: combining automatic bibliographic data recognition and term extraction for scholarship publications. Patrice Lopez, 978-3-642-04346-8Research and Advanced Technology for Digital Libraries. Maristella Agosti, José Borbinha, Sarantos Kapidakis, Christos Papatheodorou, and Giannis Tsakonas. Berlin Heidelberg, Berlin, HeidelbergSpringer2009</p>
<p>GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications. Patrice Sw, Lopez, 2009</p>
<p>Retrieval augmented generation and representative vector summarization for large unstructured textual data in medical education. S S Manathunga, Y A Illangasekara, arXiv:2308.00479[cs.CL]2023. 2023</p>
<p>D Christopher, Mihai Manning, John Surdeanu, Jenny Bauer, Steven Finkel, David Bethard, Mcclosky, The Stanford CoreNLP Natural Language Processing Toolkit. 2014</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, 2019</p>
<p>In-context retrieval-augmented language models. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham, arXiv:2302.00083[cs.CL]2023. 2023</p>
<p>Modern information retrieval: a brief overview. Amit Singhal, I Google, IEEE Data Engineering Bulletin. 242001. Jan. 2001</p>
<p>Lxmert: learning cross-modality encoder representations from transformers. Hao Tan, Mohit Bansal, arXiv:1908.07490[cs.CL]2019. 2019</p>
<p>Reimagining retrieval augmented language models for answering queries. Wang-Chiew Tan, Yuliang Li, Pedro Rodriguez, Richard James, Xi Victoria Lin, Alon Halevy, Scott Yih, arXiv:2306.01061[cs.CL]2023. 2023</p>
<p>A proximity language model for information retrieval. Jinglei Zhao, Yeogirl Yun, Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '09). the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '09)Boston, MA, USAAssociation for Computing Machinery20099781605584836</p>            </div>
        </div>

    </div>
</body>
</html>