<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3539 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3539</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3539</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-78.html">extraction-schema-78</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-54b2ea740b51d9a1b329c136dd9094190a6ee37f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/54b2ea740b51d9a1b329c136dd9094190a6ee37f" target="_blank">Interpretable Proof Generation via Iterative Backward Reasoning</a></p>
                <p><strong>Paper Venue:</strong> North American Chapter of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> IBR, an Iterative Backward Reasoning model to solve the proof generation tasks on rule-based Question Answering (QA), where models are required to reason over a series of textual rules and facts to find out the related proof path and derive the final answer.</p>
                <p><strong>Paper Abstract:</strong> We present IBR, an Iterative Backward Reasoning model to solve the proof generation tasks on rule-based Question Answering (QA), where models are required to reason over a series of textual rules and facts to find out the related proof path and derive the final answer. We handle the limitations of existed works in two folds: 1) enhance the interpretability of reasoning procedures with detailed tracking, by predicting nodes and edges in the proof path iteratively backward from the question; 2) promote the efficiency and accuracy via reasoning on the elaborate representations of nodes and history paths, without any intermediate texts that may introduce external noise during proof generation. There are three main modules in IBR, QA and proof strategy prediction to obtain the answer and offer guidance for the following procedure; parent node prediction to determine a node in the existing proof that a new child node will link to; child node prediction to find out which new node will be added to the proof. Experiments on both synthetic and paraphrased datasets demonstrate that IBR has better in-domain performance as well as cross-domain transferability than several strong baselines. Our code and models are available at https://github. com/find-knowledge/IBR.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3539.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3539.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IBR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative Backward Reasoning (IBR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative proof-generation model that constructs proof paths backward from the question by predicting parent and child nodes using RoBERTa-based token embeddings, LSTMs and lightweight Transformer modules; avoids generating intermediate natural-language texts to reduce noise and latency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>IBR (Iterative Backward Reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Iterative neural model for rule-based QA and proof generation. Uses RoBERTa_large as encoder for token embeddings, LSTM encoders for node/path representations, a 2-layer Transformer for path-focus selection, prediction heads for QA and proof-strategy, and iterative parent/child node attention to grow a proof graph backward from the question; uses beam search for paths.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based QA proof generation (DU0-DU5 / RuleTaker-style datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Given natural-language rules and facts plus a question, produce a binary answer (True/False) and an interpretable proof path (a directed acyclic graph of facts/rules/NAF nodes) that derives the answer; tasks require multi-step logical deduction over textual implications and facts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Iterative backward construction of the proof graph from the question: predict a proof strategy (Proof vs Fail-proof), then iteratively predict a parent node (from the current partial proof) and a child node (from all candidate facts/rules/NAF/END) using path- and node-aware representations rather than generating intermediate textual conclusions; uses LSTMs and a small Transformer for path-focused attention and beam search.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On DU5 (fully-supervised): QA accuracy 99.4%, Proof Accuracy (PA) 93.5%, Full Accuracy (FA) 93.5% (Table 1, aggregated across depths). Depth-specific PA: D0 99.5%, D1 95.6%, D2 93.0%, D3 90.7%, D4 86.5%, D5 81.7%. On a partial DU5 split (excluding Fail-proof samples) vs EVR: QA 99.5%, PA 92.4%, FA 92.3% (Table 2). Out-of-domain Birds-Electricity (selected splits) PA values reported (e.g., aggregated PA ~83.2 on that OOD evaluation in Table 5). IBR also achieves PA 95.0% on Fail-proof-only samples (Table 13).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Compared to baselines on DU5 (Table 1): PROVER (PV) QA 99.3%, PA 87.1%, FA 87.1%; PROBR (PB) QA 99.9%, PA 88.8%, FA 88.8%. Compared to EVR on the partial DU5 split (Table 2): EVR QA 94.4%, PA 83.6%, FA 83.6%. On Fail-proof samples EVR PA = 0.0% while IBR PA = 95.0% (Table 13).</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>IBR improves proof generation substantially vs at-once baselines: aggregated PA +4.7 percentage points over PROBR (93.5% vs 88.8%) and +6.4 over PROVER (93.5% vs 87.1%) on DU5; vs iterative EVR on comparable split: +8.8 pp PA (92.4% vs 83.6%). On Fail-proof samples IBR succeeds (PA 95.0%) while EVR fails (PA 0.0%). Improvements are larger at higher proof depths (relative gains increase for deeper proofs).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Performance degrades with increasing proof depth (PA falls to 81.7% at depth 5). The authors note the strategy-specific operations were tuned for existing dataset proof types and may require redesign for novel proof strategies; IBR is less interpretable than methods that emit human-readable intermediate texts (e.g., EVR/ProofWriter) because it reasons on learned node/path representations rather than explicit textual steps. Some drop in generalization on certain OOD subsets compared to best QA models (e.g., PROBR has higher QA on some OOD subsets).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Ablations (Table 9): providing gold child nodes yields PA 99.6% (indicating child selection is a primary remaining error source); providing gold parent yields PA 95.6%; removing node-LSTM (use mean pooling) drops PA slightly to 93.2%; removing the supplementary focus LSTM drops PA to 92.6%; removing QA supervision still yields comparable PA (93.7%), indicating proof generation can be learned without QA loss. Latency analysis: IBR is much faster than EVR (up to ~119.5x speedup) and faster than PROVER in some settings due to avoiding intermediate-text generation and heavy post-processing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3539.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROVER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PRover: Proof generation for interpretable reasoning over rules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An at-once transformer-based proof generation model that enumerates candidate nodes and edges and classifies which are in the proof using RoBERTa encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PRover: Proof generation for interpretable reasoning over rules</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PROVER (PRover)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>At-once graph-based model for proof generation that encodes question+context with RoBERTa and predicts existence of each node and each edge in the proof graph simultaneously.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based QA proof generation (DU datasets / RuleTaker-style)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Predict binary answer and the full proof graph (nodes and edges) that entail or contradict the question using transformer-encoded representations of textual rules and facts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Enumerate all possible nodes and edges, use transformer encodings (RoBERTa) and classifiers to predict node/edge existence jointly; post-processing enforces connectivity constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On DU5 (Table 1): QA 99.3%, Proof Accuracy (PA) 87.1%, Full Accuracy (FA) 87.1% (aggregated). Depth-specific PA drops notably with depth (e.g., D5 PA 65.1%). On Birds-Electricity OOD aggregate PA ~80.7 (Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Compared to IBR in this paper, PROVER is outperformed on PA and FA (IBR PA 93.5% vs PROVER 87.1% on DU5), showing IBR's iterative node/path modeling yields better proof generation accuracy, especially at larger depths.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>PROVER lacks interpretability of step-by-step reasoning (selects nodes/edges at once without tracking the rationale for each step) and can be slower due to post-processing constraints to ensure proof connectivity; its PA degrades substantially with depth.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>This paper reports PROVER's numbers as a baseline but does not reproduce PROVER ablations; the authors attribute some PROVER runtime overhead to post-processing constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3539.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROBR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic graph reasoning for natural proof generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of PROVER that models the proof graph probabilistically, jointly considering answer, nodes and edges for proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Probabilistic graph reasoning for natural proof generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PROBR</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Improves the at-once graph classification approach by introducing probabilistic graph modeling to better capture dependencies among answer, nodes and edges; uses transformer encodings (RoBERTa backbone).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based QA proof generation (RuleTaker/DU datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Generate binary answers and full proof graphs from textual rules and facts; requires multi-step deductive reasoning over natural-language implications.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Probabilistic graph modeling over node/edge variables, joint inference over answer, nodes and edges to produce consistent proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On DU5 (Table 1): QA 99.9%, PA 88.8%, FA 88.8% (aggregated). Depth-specific PA: e.g., D5 PA 72.2%. On some OOD Bird/Electricity subsets PROBR achieves highest QA in Table 5 (e.g., aggregated QA 96.3) but is still beaten by IBR on PA/FA in aggregate.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>PROBR improves modestly over PROVER (e.g., DU5 PA 88.8% vs PROVER 87.1%), but IBR still outperforms PROBR on proof accuracy and full accuracy in these experiments (IBR PA 93.5% vs PROBR 88.8%).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Despite strong QA, PROBR's proof generation accuracy lags behind IBR on DU5 and OOD robustness in PA/FA; probabilistic joint modeling did not fully close the gap for complex/deeper proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>No additional ablation results reported for PROBR within this paper; PROBR's improvements are presented as baseline numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3539.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EVR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Explainable Verbal Reasoner (EVR) / Explainable multi-hop verbal reasoning through internal monologue</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative model that decomposes complex reasoning into sequential intermediate textual steps (internal monologue / sub-questions) and generates those intermediate texts to guide proof construction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Explainable multi-hop verbal reasoning through internal monologue</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>EVR</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Iterative model that generates intermediate textual sub-questions or internal monologue statements at each reasoning step and uses them to guide subsequent inference; operates over the full inferable text space.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based QA proof generation and multi-step reasoning (RuleTaker-style datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Break down a complex proof task into a sequence of simpler textual sub-questions / conclusions and iteratively produce intermediate texts to support proof generation; requires multi-step logical deduction expressed in language.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Generate intermediate textual sub-questions/conclusions (internal monologue) at each iteration to decompose the reasoning process; use generated texts to select next proof items.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On a partial DU5 test split (excluding Fail-proof samples) EVR reported QA 94.4%, PA 83.6%, FA 83.6% (Table 2). On full DU5 including Fail-proof samples EVR fails on Fail-proof proofs (PA 0.0% on those samples, Table 13). Out-of-domain Birds-Electricity EVR aggregated PA reported as 63.1% (Table 6) indicating large OOD drop.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>IBR substantially outperforms EVR on proof accuracy and robustness, e.g., IBR PA 92.4% vs EVR 83.6% on the comparable DU5 partial split; on Fail-proof samples EVR cannot generate proofs (PA 0) while IBR achieves PA 95.0%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>EVR relies on generating intermediate textual steps which can introduce noise and errors; it cannot handle 'Fail-proof' samples where appropriate intermediate questions are unavailable, resulting in PA=0% on those samples; has higher latency and poor cross-domain generalization (strong drop in PA on Birds/Electricity).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>The paper cites EVR's failure modes (inability to handle Fail-proof strategy, high latency due to generating on full context at every step, OOD brittleness) as motivation for IBR; EVR's intermediate-text generation is identified as a major source of noise and inefficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3539.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ProofWriter</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ProofWriter: Generating implications, proofs, and abductive statements over natural language</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system that uses large text-to-text models (notably T5-11B) to generate intermediate textual conclusions and explicit proofs over natural-language rules and facts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ProofWriter: Generating implications, proofs, and abductive statements over natural language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ProofWriter (Tafjord et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Approach using large sequence-to-sequence models (e.g., T5-11B) to produce implication generation and proofs as sequences of intermediate textual conclusions; relies on large-capacity text-generation to produce explicit, human-readable proof steps.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>T5-11B (11B parameters) as used in the referenced work</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based implication/proof generation (natural-language rules/facts)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Generate explicit textual implications and full proofs from a set of natural-language rules and facts; focuses on human-readable reasoning chains.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Generate intermediate textual conclusions stepwise (textual decomposition) using a large T5 model (T5-11B) to produce proofs and implications.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>This paper does not reproduce ProofWriter experiments; it notes that ProofWriter uses T5-11B and is effective at iterative textual proof generation but is computationally costly and hard to reproduce. Quantitative comparisons are not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Mentioned as an iterative, text-generative approach; authors argue IBR avoids the noise and inefficiency inherent in intermediate-text-based methods like ProofWriter, improving latency and proof accuracy in their comparisons (though direct numeric comparisons are not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>ProofWriter's use of large text generation (T5-11B) makes reproduction difficult and incurs high computational cost; generation of intermediate text can introduce noise and propagate errors across steps (cited as motivation for non-textual intermediate representations).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>No ablation in this paper; the authors compare conceptually and note trade-offs (interpretability via textual steps vs noise/latency).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3539.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RuleTaker</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformers as soft reasoners over language (RuleTaker dataset / baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The RuleTaker setup and datasets demonstrate that pretrained Transformers (RoBERTa-based) can answer rule-based True/False questions over synthetic natural-language rules; provides the DU0-DU5 datasets used for proof tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformers as soft reasoners over language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RuleTaker (RoBERTa-based baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Baseline that uses RoBERTa encodings to predict binary answers (True/False) for rule-based QA tasks; the RuleTaker work also provides the DU0-DU5 synthetic datasets used for proof generation research.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Rule-based QA answer prediction (RuleTaker / DU datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Predict True/False answers to questions given natural-language rules/facts; focuses primarily on answer accuracy rather than producing explicit proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Fine-tune a RoBERTa encoder on synthetic rule-based QA (RuleTaker datasets) to map question+context to a binary answer.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>In this paper's DU5 experiments RuleTaker QA accuracy across depths is high (e.g., aggregated QA 99.2% in Table 1) but RuleTaker does not produce proofs (no PA/FA reported beyond QA).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>IBR matches or slightly exceeds RuleTaker on answer accuracy while also producing high-quality proofs (which RuleTaker does not attempt).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not produce interpretable proof paths; focuses only on answer prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3539.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3539.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa-large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa: A robustly optimized BERT pretraining approach (large)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used pretrained transformer encoder (RoBERTa-large) used as the backbone encoder in IBR and several baselines for token- and sequence-level representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RoBERTa: A robustly optimized bert pretraining approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa-large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained transformer encoder (improved BERT pretraining recipe), used here to produce token-level embeddings for question+context; in experiments authors use the RoBERTa_large checkpoint as backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>RoBERTa-large (~355M parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Backbone encoder for rule-based QA and proof generation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Provides contextualized token embeddings for downstream modules that perform QA classification and iterative proof construction over textual rules and facts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Fine-tuned as the encoder for downstream QA/strategy/parent/child prediction heads; token-level outputs are further processed by LSTMs and small Transformer modules for node/path representation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>As the encoder component, RoBERTa-large enables high QA accuracies across models (e.g., many models using it achieve QA >99% on DU5); exact isolated contribution not separately quantified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Not applicable as RoBERTa is a shared backbone; authors attribute strong strategy-prediction accuracy and QA performance partly to RoBERTa's representational power.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No specific failure modes of RoBERTa are discussed beyond general limitations of supervised fine-tuning and the need for downstream architectural choices (e.g., iterative vs at-once) to obtain interpretable proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>The paper does not ablate RoBERTa choice; implementation notes specify RoBERTa_large was used for all experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Interpretable Proof Generation via Iterative Backward Reasoning', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transformers as soft reasoners over language <em>(Rating: 2)</em></li>
                <li>PRover: Proof generation for interpretable reasoning over rules <em>(Rating: 2)</em></li>
                <li>Probabilistic graph reasoning for natural proof generation <em>(Rating: 2)</em></li>
                <li>ProofWriter: Generating implications, proofs, and abductive statements over natural language <em>(Rating: 2)</em></li>
                <li>Explainable multi-hop verbal reasoning through internal monologue <em>(Rating: 2)</em></li>
                <li>RoBERTa: A robustly optimized bert pretraining approach <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3539",
    "paper_id": "paper-54b2ea740b51d9a1b329c136dd9094190a6ee37f",
    "extraction_schema_id": "extraction-schema-78",
    "extracted_data": [
        {
            "name_short": "IBR",
            "name_full": "Iterative Backward Reasoning (IBR)",
            "brief_description": "An iterative proof-generation model that constructs proof paths backward from the question by predicting parent and child nodes using RoBERTa-based token embeddings, LSTMs and lightweight Transformer modules; avoids generating intermediate natural-language texts to reduce noise and latency.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "IBR (Iterative Backward Reasoning)",
            "model_description": "Iterative neural model for rule-based QA and proof generation. Uses RoBERTa_large as encoder for token embeddings, LSTM encoders for node/path representations, a 2-layer Transformer for path-focus selection, prediction heads for QA and proof-strategy, and iterative parent/child node attention to grow a proof graph backward from the question; uses beam search for paths.",
            "model_size": null,
            "reasoning_task_name": "Rule-based QA proof generation (DU0-DU5 / RuleTaker-style datasets)",
            "reasoning_task_description": "Given natural-language rules and facts plus a question, produce a binary answer (True/False) and an interpretable proof path (a directed acyclic graph of facts/rules/NAF nodes) that derives the answer; tasks require multi-step logical deduction over textual implications and facts.",
            "method_or_intervention": "Iterative backward construction of the proof graph from the question: predict a proof strategy (Proof vs Fail-proof), then iteratively predict a parent node (from the current partial proof) and a child node (from all candidate facts/rules/NAF/END) using path- and node-aware representations rather than generating intermediate textual conclusions; uses LSTMs and a small Transformer for path-focused attention and beam search.",
            "performance": "On DU5 (fully-supervised): QA accuracy 99.4%, Proof Accuracy (PA) 93.5%, Full Accuracy (FA) 93.5% (Table 1, aggregated across depths). Depth-specific PA: D0 99.5%, D1 95.6%, D2 93.0%, D3 90.7%, D4 86.5%, D5 81.7%. On a partial DU5 split (excluding Fail-proof samples) vs EVR: QA 99.5%, PA 92.4%, FA 92.3% (Table 2). Out-of-domain Birds-Electricity (selected splits) PA values reported (e.g., aggregated PA ~83.2 on that OOD evaluation in Table 5). IBR also achieves PA 95.0% on Fail-proof-only samples (Table 13).",
            "baseline_performance": "Compared to baselines on DU5 (Table 1): PROVER (PV) QA 99.3%, PA 87.1%, FA 87.1%; PROBR (PB) QA 99.9%, PA 88.8%, FA 88.8%. Compared to EVR on the partial DU5 split (Table 2): EVR QA 94.4%, PA 83.6%, FA 83.6%. On Fail-proof samples EVR PA = 0.0% while IBR PA = 95.0% (Table 13).",
            "improvement_over_baseline": "IBR improves proof generation substantially vs at-once baselines: aggregated PA +4.7 percentage points over PROBR (93.5% vs 88.8%) and +6.4 over PROVER (93.5% vs 87.1%) on DU5; vs iterative EVR on comparable split: +8.8 pp PA (92.4% vs 83.6%). On Fail-proof samples IBR succeeds (PA 95.0%) while EVR fails (PA 0.0%). Improvements are larger at higher proof depths (relative gains increase for deeper proofs).",
            "limitations_or_failures": "Performance degrades with increasing proof depth (PA falls to 81.7% at depth 5). The authors note the strategy-specific operations were tuned for existing dataset proof types and may require redesign for novel proof strategies; IBR is less interpretable than methods that emit human-readable intermediate texts (e.g., EVR/ProofWriter) because it reasons on learned node/path representations rather than explicit textual steps. Some drop in generalization on certain OOD subsets compared to best QA models (e.g., PROBR has higher QA on some OOD subsets).",
            "ablation_or_analysis": "Ablations (Table 9): providing gold child nodes yields PA 99.6% (indicating child selection is a primary remaining error source); providing gold parent yields PA 95.6%; removing node-LSTM (use mean pooling) drops PA slightly to 93.2%; removing the supplementary focus LSTM drops PA to 92.6%; removing QA supervision still yields comparable PA (93.7%), indicating proof generation can be learned without QA loss. Latency analysis: IBR is much faster than EVR (up to ~119.5x speedup) and faster than PROVER in some settings due to avoiding intermediate-text generation and heavy post-processing.",
            "uuid": "e3539.0",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "PROVER",
            "name_full": "PRover: Proof generation for interpretable reasoning over rules",
            "brief_description": "An at-once transformer-based proof generation model that enumerates candidate nodes and edges and classifies which are in the proof using RoBERTa encodings.",
            "citation_title": "PRover: Proof generation for interpretable reasoning over rules",
            "mention_or_use": "use",
            "model_name": "PROVER (PRover)",
            "model_description": "At-once graph-based model for proof generation that encodes question+context with RoBERTa and predicts existence of each node and each edge in the proof graph simultaneously.",
            "model_size": null,
            "reasoning_task_name": "Rule-based QA proof generation (DU datasets / RuleTaker-style)",
            "reasoning_task_description": "Predict binary answer and the full proof graph (nodes and edges) that entail or contradict the question using transformer-encoded representations of textual rules and facts.",
            "method_or_intervention": "Enumerate all possible nodes and edges, use transformer encodings (RoBERTa) and classifiers to predict node/edge existence jointly; post-processing enforces connectivity constraints.",
            "performance": "On DU5 (Table 1): QA 99.3%, Proof Accuracy (PA) 87.1%, Full Accuracy (FA) 87.1% (aggregated). Depth-specific PA drops notably with depth (e.g., D5 PA 65.1%). On Birds-Electricity OOD aggregate PA ~80.7 (Table 5).",
            "baseline_performance": null,
            "improvement_over_baseline": "Compared to IBR in this paper, PROVER is outperformed on PA and FA (IBR PA 93.5% vs PROVER 87.1% on DU5), showing IBR's iterative node/path modeling yields better proof generation accuracy, especially at larger depths.",
            "limitations_or_failures": "PROVER lacks interpretability of step-by-step reasoning (selects nodes/edges at once without tracking the rationale for each step) and can be slower due to post-processing constraints to ensure proof connectivity; its PA degrades substantially with depth.",
            "ablation_or_analysis": "This paper reports PROVER's numbers as a baseline but does not reproduce PROVER ablations; the authors attribute some PROVER runtime overhead to post-processing constraints.",
            "uuid": "e3539.1",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "PROBR",
            "name_full": "Probabilistic graph reasoning for natural proof generation",
            "brief_description": "An extension of PROVER that models the proof graph probabilistically, jointly considering answer, nodes and edges for proof generation.",
            "citation_title": "Probabilistic graph reasoning for natural proof generation",
            "mention_or_use": "use",
            "model_name": "PROBR",
            "model_description": "Improves the at-once graph classification approach by introducing probabilistic graph modeling to better capture dependencies among answer, nodes and edges; uses transformer encodings (RoBERTa backbone).",
            "model_size": null,
            "reasoning_task_name": "Rule-based QA proof generation (RuleTaker/DU datasets)",
            "reasoning_task_description": "Generate binary answers and full proof graphs from textual rules and facts; requires multi-step deductive reasoning over natural-language implications.",
            "method_or_intervention": "Probabilistic graph modeling over node/edge variables, joint inference over answer, nodes and edges to produce consistent proofs.",
            "performance": "On DU5 (Table 1): QA 99.9%, PA 88.8%, FA 88.8% (aggregated). Depth-specific PA: e.g., D5 PA 72.2%. On some OOD Bird/Electricity subsets PROBR achieves highest QA in Table 5 (e.g., aggregated QA 96.3) but is still beaten by IBR on PA/FA in aggregate.",
            "baseline_performance": null,
            "improvement_over_baseline": "PROBR improves modestly over PROVER (e.g., DU5 PA 88.8% vs PROVER 87.1%), but IBR still outperforms PROBR on proof accuracy and full accuracy in these experiments (IBR PA 93.5% vs PROBR 88.8%).",
            "limitations_or_failures": "Despite strong QA, PROBR's proof generation accuracy lags behind IBR on DU5 and OOD robustness in PA/FA; probabilistic joint modeling did not fully close the gap for complex/deeper proofs.",
            "ablation_or_analysis": "No additional ablation results reported for PROBR within this paper; PROBR's improvements are presented as baseline numbers.",
            "uuid": "e3539.2",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "EVR",
            "name_full": "Explainable Verbal Reasoner (EVR) / Explainable multi-hop verbal reasoning through internal monologue",
            "brief_description": "An iterative model that decomposes complex reasoning into sequential intermediate textual steps (internal monologue / sub-questions) and generates those intermediate texts to guide proof construction.",
            "citation_title": "Explainable multi-hop verbal reasoning through internal monologue",
            "mention_or_use": "use",
            "model_name": "EVR",
            "model_description": "Iterative model that generates intermediate textual sub-questions or internal monologue statements at each reasoning step and uses them to guide subsequent inference; operates over the full inferable text space.",
            "model_size": null,
            "reasoning_task_name": "Rule-based QA proof generation and multi-step reasoning (RuleTaker-style datasets)",
            "reasoning_task_description": "Break down a complex proof task into a sequence of simpler textual sub-questions / conclusions and iteratively produce intermediate texts to support proof generation; requires multi-step logical deduction expressed in language.",
            "method_or_intervention": "Generate intermediate textual sub-questions/conclusions (internal monologue) at each iteration to decompose the reasoning process; use generated texts to select next proof items.",
            "performance": "On a partial DU5 test split (excluding Fail-proof samples) EVR reported QA 94.4%, PA 83.6%, FA 83.6% (Table 2). On full DU5 including Fail-proof samples EVR fails on Fail-proof proofs (PA 0.0% on those samples, Table 13). Out-of-domain Birds-Electricity EVR aggregated PA reported as 63.1% (Table 6) indicating large OOD drop.",
            "baseline_performance": null,
            "improvement_over_baseline": "IBR substantially outperforms EVR on proof accuracy and robustness, e.g., IBR PA 92.4% vs EVR 83.6% on the comparable DU5 partial split; on Fail-proof samples EVR cannot generate proofs (PA 0) while IBR achieves PA 95.0%.",
            "limitations_or_failures": "EVR relies on generating intermediate textual steps which can introduce noise and errors; it cannot handle 'Fail-proof' samples where appropriate intermediate questions are unavailable, resulting in PA=0% on those samples; has higher latency and poor cross-domain generalization (strong drop in PA on Birds/Electricity).",
            "ablation_or_analysis": "The paper cites EVR's failure modes (inability to handle Fail-proof strategy, high latency due to generating on full context at every step, OOD brittleness) as motivation for IBR; EVR's intermediate-text generation is identified as a major source of noise and inefficiency.",
            "uuid": "e3539.3",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "ProofWriter",
            "name_full": "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
            "brief_description": "A system that uses large text-to-text models (notably T5-11B) to generate intermediate textual conclusions and explicit proofs over natural-language rules and facts.",
            "citation_title": "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
            "mention_or_use": "mention",
            "model_name": "ProofWriter (Tafjord et al.)",
            "model_description": "Approach using large sequence-to-sequence models (e.g., T5-11B) to produce implication generation and proofs as sequences of intermediate textual conclusions; relies on large-capacity text-generation to produce explicit, human-readable proof steps.",
            "model_size": "T5-11B (11B parameters) as used in the referenced work",
            "reasoning_task_name": "Rule-based implication/proof generation (natural-language rules/facts)",
            "reasoning_task_description": "Generate explicit textual implications and full proofs from a set of natural-language rules and facts; focuses on human-readable reasoning chains.",
            "method_or_intervention": "Generate intermediate textual conclusions stepwise (textual decomposition) using a large T5 model (T5-11B) to produce proofs and implications.",
            "performance": "This paper does not reproduce ProofWriter experiments; it notes that ProofWriter uses T5-11B and is effective at iterative textual proof generation but is computationally costly and hard to reproduce. Quantitative comparisons are not reported in this paper.",
            "baseline_performance": null,
            "improvement_over_baseline": "Mentioned as an iterative, text-generative approach; authors argue IBR avoids the noise and inefficiency inherent in intermediate-text-based methods like ProofWriter, improving latency and proof accuracy in their comparisons (though direct numeric comparisons are not provided in this paper).",
            "limitations_or_failures": "ProofWriter's use of large text generation (T5-11B) makes reproduction difficult and incurs high computational cost; generation of intermediate text can introduce noise and propagate errors across steps (cited as motivation for non-textual intermediate representations).",
            "ablation_or_analysis": "No ablation in this paper; the authors compare conceptually and note trade-offs (interpretability via textual steps vs noise/latency).",
            "uuid": "e3539.4",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "RuleTaker",
            "name_full": "Transformers as soft reasoners over language (RuleTaker dataset / baseline)",
            "brief_description": "The RuleTaker setup and datasets demonstrate that pretrained Transformers (RoBERTa-based) can answer rule-based True/False questions over synthetic natural-language rules; provides the DU0-DU5 datasets used for proof tasks.",
            "citation_title": "Transformers as soft reasoners over language",
            "mention_or_use": "use",
            "model_name": "RuleTaker (RoBERTa-based baseline)",
            "model_description": "Baseline that uses RoBERTa encodings to predict binary answers (True/False) for rule-based QA tasks; the RuleTaker work also provides the DU0-DU5 synthetic datasets used for proof generation research.",
            "model_size": null,
            "reasoning_task_name": "Rule-based QA answer prediction (RuleTaker / DU datasets)",
            "reasoning_task_description": "Predict True/False answers to questions given natural-language rules/facts; focuses primarily on answer accuracy rather than producing explicit proofs.",
            "method_or_intervention": "Fine-tune a RoBERTa encoder on synthetic rule-based QA (RuleTaker datasets) to map question+context to a binary answer.",
            "performance": "In this paper's DU5 experiments RuleTaker QA accuracy across depths is high (e.g., aggregated QA 99.2% in Table 1) but RuleTaker does not produce proofs (no PA/FA reported beyond QA).",
            "baseline_performance": null,
            "improvement_over_baseline": "IBR matches or slightly exceeds RuleTaker on answer accuracy while also producing high-quality proofs (which RuleTaker does not attempt).",
            "limitations_or_failures": "Does not produce interpretable proof paths; focuses only on answer prediction.",
            "uuid": "e3539.5",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "RoBERTa-large",
            "name_full": "RoBERTa: A robustly optimized BERT pretraining approach (large)",
            "brief_description": "A widely used pretrained transformer encoder (RoBERTa-large) used as the backbone encoder in IBR and several baselines for token- and sequence-level representations.",
            "citation_title": "RoBERTa: A robustly optimized bert pretraining approach",
            "mention_or_use": "use",
            "model_name": "RoBERTa-large",
            "model_description": "Pretrained transformer encoder (improved BERT pretraining recipe), used here to produce token-level embeddings for question+context; in experiments authors use the RoBERTa_large checkpoint as backbone.",
            "model_size": "RoBERTa-large (~355M parameters)",
            "reasoning_task_name": "Backbone encoder for rule-based QA and proof generation tasks",
            "reasoning_task_description": "Provides contextualized token embeddings for downstream modules that perform QA classification and iterative proof construction over textual rules and facts.",
            "method_or_intervention": "Fine-tuned as the encoder for downstream QA/strategy/parent/child prediction heads; token-level outputs are further processed by LSTMs and small Transformer modules for node/path representation.",
            "performance": "As the encoder component, RoBERTa-large enables high QA accuracies across models (e.g., many models using it achieve QA &gt;99% on DU5); exact isolated contribution not separately quantified in this paper.",
            "baseline_performance": null,
            "improvement_over_baseline": "Not applicable as RoBERTa is a shared backbone; authors attribute strong strategy-prediction accuracy and QA performance partly to RoBERTa's representational power.",
            "limitations_or_failures": "No specific failure modes of RoBERTa are discussed beyond general limitations of supervised fine-tuning and the need for downstream architectural choices (e.g., iterative vs at-once) to obtain interpretable proofs.",
            "ablation_or_analysis": "The paper does not ablate RoBERTa choice; implementation notes specify RoBERTa_large was used for all experiments.",
            "uuid": "e3539.6",
            "source_info": {
                "paper_title": "Interpretable Proof Generation via Iterative Backward Reasoning",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 2
        },
        {
            "paper_title": "PRover: Proof generation for interpretable reasoning over rules",
            "rating": 2
        },
        {
            "paper_title": "Probabilistic graph reasoning for natural proof generation",
            "rating": 2
        },
        {
            "paper_title": "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
            "rating": 2
        },
        {
            "paper_title": "Explainable multi-hop verbal reasoning through internal monologue",
            "rating": 2
        },
        {
            "paper_title": "RoBERTa: A robustly optimized bert pretraining approach",
            "rating": 1
        }
    ],
    "cost": 0.01757775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Interpretable Proof Generation via Iterative Backward Reasoning</h1>
<p>Hanhao $\mathbf{Q u}^{1} \quad$ Yu Cao $^{3} \quad$ Jun Gao $^{1} \quad$ Liang Ding ${ }^{3,4} \quad$ Ruifeng Xu ${ }^{1,2 *}$<br>${ }^{1}$ Harbin Institute of Technology, Shenzhen ${ }^{2}$ Peng Cheng Laboratory<br>{hhqu0917,jgao95}@stu.hit.edu.cn xuruifeng@hit.edu.cn<br>${ }^{3}$ The University of Sydney, Australia ${ }^{4}$ JD Explore Academy<br>{ycao8647,ldin3097}@uni.sydney.edu.au</p>
<h4>Abstract</h4>
<p>We present IBR, an Iterative Backward Reasoning model to solve the proof generation tasks on rule-based Question Answering (QA), where models are required to reason over a series of textual rules and facts to find out the related proof path and derive the final answer. We handle the limitations of existed works in two folds: 1) enhance the interpretability of reasoning procedures with detailed tracking, by predicting nodes and edges in the proof path iteratively backward from the question; 2) promote the efficiency and accuracy via reasoning on the elaborate representations of nodes and history paths, without any intermediate texts that may introduce external noise during proof generation. There are three main modules in IBR, QA and proof strategy prediction to obtain the answer and offer guidance for the following procedure; parent node prediction to determine a node in the existing proof that a new child node will link to; child node prediction to find out which new node will be added to the proof. Experiments on both synthetic and paraphrased datasets demonstrate that IBR has better in-domain performance as well as cross-domain transferability than several strong baselines. Our code and models are available at https://github. com/find-knowledge/IBR.</p>
<h2>1 Introduction</h2>
<p>Endowing machines with reasoning capabilities is a longstanding problem (Newell and Simon, 1956) in the field of AI. Though existing tasks such as multi-hop QA (Yang et al., 2018; Welbl et al., 2018) or logical-reasoning QA (Yu et al., 2020; Dua et al., 2019) impose a higher requirement on the reasoning capabilities, they usually just request for an answer without the reasoning procedure that would make it interpretable. Recently, Clark et al. (2020) proposed new datasets and tasks for interpretable</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Illustration of generating proof iteratively. Regarding the proof path as a graph, and using the question as the initial node, other nodes and edges will be added step by step. (The gold proof is the obtained path in a reverse order exclude the question). The main challenges are wrong (cannot derive the answer) or redundant (can derive the answer, but the path is longer than the optimal one) branches may be involved.
reasoning. Given a question, coupling with a set of facts (plain statements) and rules (implication relationships) that are expressed in natural language, there are two tasks: 1) predicting the binary answer; 2) generating the proof path behind this answer. Large-scale pretrained models have shown strong performance on the first subtask in the early work (Liu et al., 2019), but there still remain challenges for the second one. These proof paths are usually more complicated than those involved in multi-hop QA tasks, as there are more nodes and branches rather than a single-directed chain.</p>
<p>Several approaches have been proposed to simultaneously address the two subtasks. PROVER (Saha et al., 2020) and PROBR (Sun et al., 2021) try to construct the reasoning path at once, where two classifiers are used to determine whether each node or edge is involved in the proof path respectively based on corresponding encoded</p>
<p>representations. But they lack interpretability on tracking the detailed reason for selecting each step. To make proof generation more interpretable, Proofwriter (Tafjord et al., 2021) and EVR (Liang et al., 2021) decompose complex reasoning over the question into multiple simple procedures, resulting in iterative and interpretable processes with the help of intermediate texts. Nevertheless, both of them suffer from efficiency and external errors issues. The reason is that they both require a large searching space, as they perform on the whole inferable texts and ignore the structure information from the history path that has been obtained. Moreover, the generation of intermediate text is costly and may introduce extra noise propagation.</p>
<p>Inspired by the top-down AMR parsing (Cai and Lam, 2019), where a sentence is divided into sub-meanings iteratively, we present Iterative Backward Reasoning (IBR) for better proof generation. It generates a proof path iteratively starting from the core component for QA, i.e. the question, making the process interpretable with trackable intermediate states. Regarding a higher efficiency and accuracy, and two challenges mentioned in Figure 1, the proof generation module of IBR simplifies the intermediate process of reasoning as well as avoids the unnecessary search for a possible unsuitable branch. To add a new node and edge to the path, there are two steps in IBR for each iteration: 1) finding out the next parent node, i.e. one existing rule or fact in the parsed history path that a new node will become its child; 2) determine which rule or fact that will be the new child node and added to the path. Equipped with question-aware representations from a pre-trained encoder, along with structure-aware node and path features, our model can choose the optimal endpoint. It accomplishes reasoning with the highest possibility to obtain a correct subsequent proof path based on relevant features, getting rid of intermediate texts while avoiding redundancy on all possible texts than previous iterative works.</p>
<p>In addition, to make IBR applicable for samples with incomplete proof paths, which are abandoned in the former backward iterative model EVR (Liang et al., 2021), we employ a proof strategy predictor to output a proof type. This prediction is then integrated into the later proof generation actions, making the process more controllable under different conditions.</p>
<p>We validate our approach on several datasets that are widely used in previous studies (i.e. DU0DU5, Birds-Electricity, and ParaRules) spanning different settings (i.e. fully-supervised, fewer training data, and out-of-domain). Experimental results show that, compared to existing strong baselines including both non-iterative and iterative ones, IBR can achieve the best overall performance of proof generation and comparable answer prediction accuracy, along with noticeable generalization capability. Extensive analyses show that 1) the improvements come from our elaborately designed iterative and simplified proof generation modules, and 2) both the reasoning ability and latency could be significantly improved compared to former iterative models, making a better trade-off considering its reasonable interpretability.</p>
<h2>2 Related Work</h2>
<p>Question answering and reasoning. Endowing machines to do reasoning over explicit knowledge is a primitive task (Newell and Simon, 1956). Early works tried to solve it by converting texts into logic forms (Newell and Simon, 1956; Musen and Lei, 1988). But such kinds of approaches can be affected by the error propagation caused by semantic parsing (Zettlemoyer and Collins, 2012; Berant et al., 2013; Berant and Liang, 2014).</p>
<p>Lately, question answering (QA) is employed as an important task for machine reasoning. Numerous datasets were proposed, including synthesized data (Weston et al., 2016), comprehension on natural texts (Rajpurkar et al., 2016; Joshi et al., 2017; Fisch et al., 2019) or more complex relationship reasoning (Tafjord et al., 2019; Lin et al., 2019). There are also multi-hop QA tasks like HotpotQA (Yang et al., 2018) or QAngaroo (Welbl et al., 2018), and logical QA datasets such as ReClor (Yu et al., 2020) and LogiQA (Liu et al., 2020), in which textual rules need to be inferred implicitly from a long supporting context. Plenty of studies try to solve these problems via neural networks and achieve remarkable performance (Joshi et al., 2020; Yu et al., 2018; Shao et al., 2020). Nevertheless, nearly all of them only focus on the prediction of final answers and neglect the acquisition of interpretable proofs. Although some datasets provide proof paths for better interpretability, these paths are only short chains with very few entities and cannot teach models to generate complex proofs.</p>
<p>Proof generation. NLProlog (Weber et al., 2019) first employs logic programming to search for a proof and then predicts the answer in multi-hop QA. Recently, Clark et al. (2020) propose new rulebased QA datasets for this line of research that include more complex proof paths, and present RuleTaker to answer questions. Saha et al. (2020) argue that producing answer proofs makes models more reliable and propose PROVER, a transformer-based model that enumerates all possible nodes and edges of a proof path and predicts whether each one exists at once based on their embeddings. PROBR (Sun et al., 2021) further improves this framework using the probabilistic graph to model more variables. There has been also an increasing interest in solving proof generation iteratively. EVR (Liang et al., 2021) splits the question into sub-questions, using generated intermediate texts to guide proof generation step by step. ProofWriter (Tafjord et al., 2021) shares a similar idea but uses intermediate textual conclusions instead and a more powerful T5-11B model (Raffel et al., 2020) for generation, which makes it hard to reproduce. IBR is also an iterative model, being more interpretable than at-once models. Despite getting rid of intermediate texts and directly using various representations to finish each step, it improves efficiency and effectiveness.</p>
<h2>3 Methodology</h2>
<h3>3.1 Task Definition</h3>
<p>We first formulate the proof generation task as follows. Given a tuple $(C, Q, A, P)$, where $C=$ $\left{R F_{i}\right}$ is the contexts containing several textual rules and facts $R F, Q$ is the question, $A \in{$ True, False $}$ is the answer, and $P$ indicates the proof path for the detailed reasoning procedure to derive $A$, our goal is twofold: 1) predicting the answer $A$, and 2) generating the proof path $P$. Taking DU0DU5 (Clark et al., 2020) dataset as example, $P$ is a single-directed acyclic graph having the shortest path to derive $A . P$ can start from one or multiple nodes but must end in one node that directly entails or contradicts $Q$. A node in $P$ can be a fact, a rule, or a special NAF (Negation As Failure) node ${ }^{1}$. Edges between nodes indicate that the start nodes can be used to prove the end nodes during reasoning. Proofs in the dataset can be roughly classified</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Examples of Proof and Fail-proof strategies.
into two types according to their strategies $S$ to prove the question: (1)Proof: the question can be directly proven to be True or False using the given $C$ and NAF; (2) Fail-Proof: the question cannot be explicitly deduced barely using $C$ and NAF as some key information is missed, hence a positive statement is judged as False while a negative statement as True in such cases (Figure 2).</p>
<h3>3.2 Overview</h3>
<p>The proposed Iterative Backward Reasoning (IBR) model takes $Q$ as the initial node and produce a proof path $P$ backward, from the end node to the start node. Two actions are included at each iteration: (1) Predicting the new parent node, i.e. a node in the derived proof path where a child node will be added (except the first step that only $Q$ exists); (2) Predicting the child node, i.e. the fact or rule in $C$ that will be the child for the selected parent node. After each iteration, a new node and an associated edge are added. After obtaining the whole reasoning path, we remove $Q$ and reverse all edges to get the final proof $P$.</p>
<p>The Figure 3 illustrates our IBR model, which can be divided into three modules, (1) QA and Strategy Prediction, (2) Parent Node Prediction, and (3) Child Node Prediction. In order to make the question $Q$ can fully interact with context $C$ (facts and rules) and obtain better representations, IBR uses pretrained RoBERTa (Liu et al., 2019) as the backbone network. The input of RoBERTa is the concatenation of the question $Q$ and the context $C=\left{R F_{i}\right}$, separated by special $[S E P]$ token, denoted as $[C L S] Q[S E P][S E P] C[S E P]$.</p>
<p>IBR only uses the QA prediction and strategy prediction modules once at first to predict the answer $A$ and the strategy of the proof (refer to $\S 3.1$, where the latter one will result in different proof</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The model architecture of IBR. 1) is only used once at the start, then 2) and 3) are applied iteratively to generate the whole proof. It also illustrates the detailed state when adding $\mathrm{F}<em Q="Q">{10}$ into the proof ( F : facts, R : rules).
generation procedures. In order to improve the reasoning efficiency as well as accuracy, instead of using generated intermediate texts (Liang et al., 2021; Tafjord et al., 2021), all possible nodes (rules and facts) are represented by node embeddings in IBR. The initial state of the proof is only the representation of the question $h</em>$, then the rest of the reasoning path will be constructed based on it.</p>
<p>Samples with Fail-Proof strategy differs from ones with Proof, because their proofs are usually short without sub-branches, and only consist of rules due to lacking essential supporting facts. To take the advantage of such a property distinction and extend the applicability compared to former models (Liang et al., 2021) that cannot generate proofs for Fail-Proof samples, we apply different actions in modules (2) and (3) depending on the output from strategy prediction.</p>
<h3>3.3 QA and Strategy Prediction Module</h3>
<p>This module aims to predict the answer $A$ of the question $Q$ and the corresponding strategy $S$ of proof $P$. Since the representation of $[C L S]$ token from pretrained models is proven to have the capability of modeling the whole input, we use it as the input feature for both predictions as they condition the global information. The encoded $[C L S]$ by RoBERTa, $h_{[C L S]}$ is passed to a linear layer and the softmax function $\sigma$ for answer and strategy classification respectively,</p>
<p>$$
\begin{aligned}
P_{Q A} &amp; =\sigma\left(f_{Q A}\left(h_{[C L S]}\right)\right) \
P_{\text {Strategy }} &amp; =\sigma\left(f_{\text {Strategy }}\left(h_{[C L S]}\right)\right)
\end{aligned}
$$</p>
<p>Here, $f_{Q A}$ and $f_{\text {Strategy }}$ indicate the linear layer for QA classification and strategy classification, respectively. $P_{Q A}$ and $P_{\text {Strategy }}$ are binary-class probability values, the former one is for values of $A \in{$ True, False $}$ while the later one is for values of $S \in{$ Proof, Fail-proof $}$.</p>
<h3>3.4 Parent Node Prediction Module</h3>
<p>This module determines which node in the current reasoning path is going to be the next parent node that a new child node will link to. To better represent the sequential information of each possible node (fact or rule), an LSTM (Hochreiter and Schmidhuber, 1997) is used to further encode the token-level embedding from RoBERTa. The hidden state in the last step is used as the textual representation $h_{g i}$ of a possible parent node $R F_{i}$.</p>
<p>In addition, selecting a node from the existing proof path also needs global and structural modeling on the history path. To make this procedure a more convenient representation that involves the order of reasoning, the path is regarded as a tree structure and nodes are reordered by level traversal from top to down. Since $Q$ is always the root node of the tree, e.g., if $Q$ have two children $R F_{1}$ and $R F_{3}$, and $R F_{1}$ has a child $R F_{2}$, the reordered representation sequence is $\left[h_{Q}, h_{g 1}, h_{g 3}, h_{g 2}\right]$. We then utilize another LSTM model to encode the</p>
<p>reordered representation sequence of the current reasoning path obtained before, extracting the overall state of the path, which is the hidden state $h_{g}$ at the last time step in this LSTM.</p>
<p>A parent node attention based on the Transformer attention (Vaswani et al., 2017) is used to obtain the weights of all possible parents nodes. It takes $h_{g}$ and the representation sequence of the current path $\mathbf{H}<em Q="Q">{p}=\left[h</em>\right]$ as input, i.e.}, h_{g 1} \ldots h_{g t</p>
<p>$$
\operatorname{Att}\left(h_{g}, \mathbf{H}<em Q="Q">{p}\right)=\sigma\left(f</em>\right)
$$}\left(h_{g}\right)\left(f_{K}\left(\mathbf{H}_{p}\right)\right)^{T} / \sqrt{d</p>
<p>where $f_{Q}$ and $f_{K}$ indicate linear layers, $\sigma$ is a softmax function, and $d$ is the dimension of $h_{g}$. As we discussed in $\S 3.2$, different operations are employed for corresponding strategy types of proofs. 1) If the predicted proof strategy is Proof, we select the node with the highest weight as the parent node $R F_{p}$. 2) If the predicted proof strategy is Fail-proof, we use the last node in the current path, i.e. $h_{g t}$ in $\mathbf{H}<em p="p">{P}$, as the parent node $R F</em>$, because no sub-branch is included in such proof paths.</p>
<h3>3.5 Child Node Prediction Module</h3>
<p>This module decides which node will be added to the proof path and linked to the parent node $R F_{p}$ we have obtained before. To derive the representations of candidate child nodes, similar to $\S 3.4$, we apply another LSTM model to the encoded RoBERTa embeddings and get $h_{n_{i}}$ for $R F_{i}$. Since we discussed a special NAF node in $\S 3.1$ which may contain information from the whole context, we utilize a linear layer $f_{N A F}$ to transform the $[C L S]$ token embedding $h_{[C L S]}$ into its representation $h_{N A F}$. Moreover, we initialize a representation $h_{E N D}$ for the special END node, indicating that the proof generation process will finish here.</p>
<p>During selecting the new child node, we need to consider not only the knowledge of the history path, but also the state of the parent node. To better model such relationships, we propose a Path Focus Selection module to generate relevant features before predicting the child node. A 2-layer Transformer model along with a LSTM model is introduced. It first encodes the representations of node sequence $\mathbf{H}<em U="U">{p}$ from Parent Node Prediction respectively, then fuses their hidden state via a linear layer $f</em>$,</p>
<p>$$
h_{F}=f_{U}\left(\left[\operatorname{Trans}\left(h_{g p}, \mathbf{H}<em p="p">{p}, \mathbf{H}</em>\right)\right]\right)
$$}\right) ; \operatorname{LSTM}\left(\mathbf{H}_{p</p>
<p>Here, $h_{g p}$ is the representation of the selected parent node in $\S 3.4, f_{U}$ is the linear layer for feature fusing, while $[\cdot ; \cdot]$ stands for concatenation. $q, k, v$ in $\operatorname{Trans}(q, k, v)$ indicate the inputs corresponding to Query, Key, and Value in a transformer model, and only the hidden state in the last time step is remained in both Trans and LSTM. It is worth noting that the LSTM used here is a supplementary knowledge source for a better representation according to our empirical study. Such an operation results in a feature $h_{F}$ that is aware of both the history proof path and the parent node that a child will link to.</p>
<p>This feature $h_{F}$ will then be used in the Child Node Attention to calculate the attention weights on all possible child nodes. Particularly, an attention model same as Eq. 1 is applied on $h_{F}$ and a series of child node representations obtained before $\mathbf{H}<em 1="1" n="n">{c}=\left[h</em>\right)$. It contains all facts and rules in the context, and the special NAF node as well as END node.} \ldots h_{n k}, h_{N A F}, h_{E N D}\right]$, and the attention weights are defined as $\operatorname{Att}\left(h_{F}, \mathbf{H}_{c</p>
<p>Similar to $\S 3.4$, we also apply different actions according to our predicted proof strategies before. (1) If the strategy is Proof, we select the child node with the highest attention weight from all candidates as the new node in the proof path.
(2) If the strategy is Fail-proof, since $R F_{p}$ is the last node during reasoning and this procedure is a first-order logical under such a situation, there is no need to make complex modeling on the derived path. Therefore, we directly use its parent node representation $h_{g p}$ rather than encoded state from Transformer in Eq. 2 to get $h_{F}$. But LSTM is remained to maintain some basic modeling capability on the path. In child node attention, we mask all fact nodes and select the one with the highest weight among the remaining nodes, because this kind of proof usually only contains rules and such masking can avoid extra errors.</p>
<h3>3.6 Training and Inference</h3>
<p>The whole model is trained via binary crossentropy losses from all three above modules jointly,</p>
<p>$$
L=L_{Q A}+L_{\text {Parent }}+L_{\text {Child }}+\alpha * L_{\text {Strategy }}
$$</p>
<p>$L_{Q A}$ and $L_{\text {Strategy }}$ correspond to the loss of QA prediction and strategy prediction, respectively. $\alpha$ is a hyperparameter to reweigh the influence of [CLS] token. $L_{\text {Parent }}$ is the loss for parent node prediction, where the cross-entropy is calculated between the attention weight vector and a one-hot</p>
<p>vector indicating the gold parent node. $L_{\text {Child }}$ is in a similar way on child node prediction. Note that samples labeled as Fail-proof strategy are not involved in the training of parent node prediction. As all their proof paths are chains and the new parent node is always the last node added to the path, so learning about these data may introduce model bias. To determine the gold reasoning order used as the target for training, we set a higher priority of fact nodes than rule nodes, as the clearer subject information is involved in facts. E.g., for a parent node with multiple children, the gold reasoning order of child node prediction is NAF nodes first, then fact nodes, and finally rule nodes. If there are more than one fact or rule nodes, IBR randomly swaps their order within each type at different training epochs.</p>
<p>During inference, IBR first makes predictions on the answer $A$ and strategy $S$, then generate the parent node and child node iteratively, until the special END node is predicted as the new child node. IBR uses beam search to keep the top-K best proof paths at each proof generation step and select the best one as the final prediction, where the beam size is set as 8 .</p>
<h2>4 Experiments</h2>
<p>Following former studies (Saha et al., 2020; Sun et al., 2021), we evaluate our $\mathrm{IBR}^{2}$ on three datasets and four settings including fully-supervised training, training using fewer samples, testing on out-ofdomain samples, and generalization to more complex proofs or language.</p>
<h3>4.1 Setup</h3>
<p>Datasets. Experiments are conducted on three datasets raised by Clark et al. (2020) ${ }^{3}$, where we use the same test split as previous works for fair comparison:</p>
<ul>
<li>DU0-DU5: Five synthesized datasets created by translating hand-crafted rules and formal language to natural language. It is divided by the highest depth of proof, where DU stands for "Depth Upto" (DU=0,1,2,3,5). Data in higher DU values also contain samples with lower depth. Note that proofs in DU0 only have one supporting or opposing fact. All related results are reported on DU5 test split.</li>
<li>Bird-Electricity: It is a test-only dataset that contains samples about birds and electric circuits.</li>
</ul>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>It is generated in the same way as DU0-DU5, but is in different domains from DU0-DU5.</p>
<ul>
<li>ParaRules: This dataset consists of 40k questions expressed in paraphrased natural language based on synthetic data, which is created by crowdsourcing. Multiple facts get together in one statement here rather than separated in DU0-DU5.</li>
</ul>
<p>Baselines. We consider the following baselines ${ }^{4}$.</p>
<ul>
<li>RuleTaker (RT) (Clark et al., 2020): a RoBERTa based model that only predicts answers.</li>
<li>PROVER (PV) (Saha et al., 2020): a method that treats the proof as a graph and predicts all its nodes and edges at once, also using RoBERTa model as the backbone, same as IBR.</li>
<li>PROBR (PB) (Sun et al., 2021): it improves PROVER by introducing the probabilistic graph that jointly considers the answer, nodes and edges.</li>
<li>EVR (Liang et al., 2021): an iterative model that predicts the next proof item by generating textual sub-questions based on logical operator. Note that this model is not applicable for samples whose proof strategy is Fail-proof discussed in $\S 3.1$, so we make comparison with it separately.</li>
</ul>
<p>Metrics. We closely follow previous works to evaluate the performance of models via answer prediction (QA) accuracy and proof generation (PA) accuracy. Since some samples may have multiple gold proofs, a generated proof will be considered correct, as long as its nodes and edges match with the nodes and the edges in any of the gold proofs. Full Accuracy (FA) is also included, where a sample is regarded as correct only both the predicted answer and proof are correct.</p>
<h3>4.2 Results under Fully-Supervised Training</h3>
<p>We train IBR on the training split of the DU5 dataset and evaluate on the test split of DU5. We compare the performance of IBR with baselines except for EVR in Table 1, while with EVR in Table 2 where only partial test split is included, excluding samples whose proof strategy is Fail-proof. Because EVR always fails on these samples (EVR on these excluded samples is given in Appendix A.5).</p>
<p>Obviously, IBR achieves the best proof generation accuracy (PA) as well as full accuracy (FA) among all baseline models, on samples with every depth. Our model also shows a greater advantage on samples with deeper proof path, e.g., 81.7 vs.</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">$\mathbf{0}$</th>
<th style="text-align: center;">$\mathbf{1}$</th>
<th style="text-align: center;">$\mathbf{2}$</th>
<th style="text-align: center;">$\mathbf{3}$</th>
<th style="text-align: center;">$\mathbf{4}$</th>
<th style="text-align: center;">$\mathbf{5}$</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">6299</td>
<td style="text-align: center;">4434</td>
<td style="text-align: center;">2915</td>
<td style="text-align: center;">2396</td>
<td style="text-align: center;">2134</td>
<td style="text-align: center;">2003</td>
<td style="text-align: center;">20192</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">RT</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.2</td>
</tr>
<tr>
<td style="text-align: left;">QA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.3</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.4</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">87.1</td>
</tr>
<tr>
<td style="text-align: left;">PA</td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">88.8</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 0 . 7}$</td>
<td style="text-align: center;">$\mathbf{8 6 . 5}$</td>
<td style="text-align: center;">$\mathbf{8 1 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">87.1</td>
</tr>
<tr>
<td style="text-align: left;">FA</td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">88.8</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 0 . 7}$</td>
<td style="text-align: center;">$\mathbf{8 6 . 5}$</td>
<td style="text-align: center;">$\mathbf{8 1 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 5}$</td>
</tr>
</tbody>
</table>
<p>Table 1: Results of different models on varying proof depth (D) under the fully-supervised setting. Cnt: sample count, RT: RuleTaker, PV: PROVER, PB: PROBR.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">$\mathbf{0}$</th>
<th style="text-align: center;">$\mathbf{1}$</th>
<th style="text-align: center;">$\mathbf{2}$</th>
<th style="text-align: center;">$\mathbf{3}$</th>
<th style="text-align: center;">$\mathbf{4}$</th>
<th style="text-align: center;">$\mathbf{5}$</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">1934</td>
<td style="text-align: center;">11604</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">88.3</td>
<td style="text-align: center;">94.4</td>
</tr>
<tr>
<td style="text-align: left;">QA</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 3}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 3}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">87.7</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">77.3</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">83.6</td>
</tr>
<tr>
<td style="text-align: left;">PA</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 8 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 4}$</td>
<td style="text-align: center;">$\mathbf{9 4 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 2}$</td>
<td style="text-align: center;">$\mathbf{8 8 . 7}$</td>
<td style="text-align: center;">$\mathbf{8 3 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 4}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">87.7</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">77.3</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">83.6</td>
</tr>
<tr>
<td style="text-align: left;">FA</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 8 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 3}$</td>
<td style="text-align: center;">$\mathbf{9 4 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 2}$</td>
<td style="text-align: center;">$\mathbf{8 8 . 7}$</td>
<td style="text-align: center;">$\mathbf{8 3 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
</tr>
</tbody>
</table>
<p>Table 2: Results of IBR and EVR on a partial test split of DU5 (exclude Fail-proof samples). The models are trained on the train split of DU5.
72.2 on PA when depth is 5 , illustrating the superiority of iterative models on complex proof paths. Besides, despite not being the best in answer accuracy (QA), there is a very narrow gap between our model and the best one, which proves that IBR is still a comprehensive model covering both subtasks. When compared to EVR, also an iterative model, IBR shows significantly stronger performance on all metrics, benefiting from our elaborate two-fold reasoning process at each step.</p>
<h3>4.3 Using Fewer Training Samples</h3>
<p>We also explore the performance of IBR when training using fewer data, ranging from 10 k to 30 k to all the examples ( 70 k ) in DU5. The comparison between our model, PROVER (PV), and PROBR $(\mathrm{PB})$ is shown in Table 3, in all three metrics. Our model significantly has the best proof generation performance than the other two baselines in all cases, due to the iterative architecture requiring less global modeling capability and thus fewer training samples. Although PB shows a promising answer prediction accuracy under fewer-data settings, the performance of IBR is close to it while better than</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Data</th>
<th style="text-align: center;">QA</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">PA</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">FA</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">PB IBR</td>
</tr>
<tr>
<td style="text-align: left;">70k</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">88.8</td>
<td style="text-align: center;">$\mathbf{9 3 . 5}$</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">88.893 .5</td>
</tr>
<tr>
<td style="text-align: left;">30k</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">$\mathbf{8 9 . 8}$</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">86.889 .7</td>
</tr>
<tr>
<td style="text-align: left;">10k</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">44.0</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">$\mathbf{7 5 . 7}$</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">72.375 .4</td>
</tr>
</tbody>
</table>
<p>Table 3: Performance comparison using fewer training samples among IBR, PROVER (PV), and PROBR (PB) on the full test split of DU5 after trained on partial DU5 samples.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Data</th>
<th style="text-align: center;">QA</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">PA</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">FA</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">IBR</td>
</tr>
<tr>
<td style="text-align: left;">70k</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">$\mathbf{9 2 . 4}$</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
</tr>
<tr>
<td style="text-align: left;">30k</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">$\mathbf{9 9 . 4}$</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">$\mathbf{8 8 . 2}$</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">$\mathbf{8 8 . 1}$</td>
</tr>
<tr>
<td style="text-align: left;">10k</td>
<td style="text-align: center;">96.2</td>
<td style="text-align: center;">$\mathbf{9 7 . 9}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 8}$</td>
<td style="text-align: center;">71.2</td>
<td style="text-align: center;">$\mathbf{8 2 . 8}$</td>
<td style="text-align: center;">70.8</td>
</tr>
</tbody>
</table>
<p>Table 4: Performance comparison using fewer training samples among EVR and IBR on partial test split of DU5 (without Fail-proof samples) after trained on partial DU5 samples.</p>
<p>PV, e.g., 94.3 vs. 87.1 under 10k. In addition, in Table 4, we also compare with EVR under the same settings but using a different test set that excludes Fail-proof samples. EVR outperforms IBR under the 10 k setting for proof generation, but IBR is stronger if more training samples are available.</p>
<h3>4.4 Evaluation of Out-of-Domain Data</h3>
<p>We further test the out-of-domain performance of IBR against baselines on Birds-Electricity dataset to evaluate their robustness, where B1 and B2 are two sets from the birds domain, and E1-E4 are four sets from the electricity domain. Results are shown in Table 5 and Table 6. Note that Fail-proof samples are still not involved in the comparison for EVR. Overall, our IBR achieves $2.5 \%$ promotion in PA while an equivalent result on QA, compared to PROVER. Despite being the best one on QA, PROBR is also defeated by IBR on both PA and FA. In addition, our model shows more improvement on the hardest E3 and E4 subsets, which further verifies its robustness. When it comes to EVR, we can find its cross-domain capability is relatively weak as it sees a significant drop in PA, and IBR is superior to it without any doubt. Because the cross-domain generation for intermediate texts is much harder, our usage of high-level node features to finished reasoning can alleviate this challenge.</p>
<h3>4.5 Generalization Ability</h3>
<p>Generalize to higher depths. Following the previous work (Sun et al., 2021), we test the general-</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Test</th>
<th style="text-align: center;">B1</th>
<th style="text-align: center;">B2</th>
<th style="text-align: center;">E1</th>
<th style="text-align: center;">E2</th>
<th style="text-align: center;">E3</th>
<th style="text-align: center;">E4</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">162</td>
<td style="text-align: center;">180</td>
<td style="text-align: center;">624</td>
<td style="text-align: center;">4224</td>
<td style="text-align: center;">5270</td>
</tr>
<tr>
<td style="text-align: center;">QA</td>
<td style="text-align: center;">RT</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">91.8</td>
<td style="text-align: center;">76.7</td>
<td style="text-align: center;">80.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">86.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">$\mathbf{9 8 . 2}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 3}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">89.2</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">86.0</td>
</tr>
<tr>
<td style="text-align: center;">PA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">80.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">$\mathbf{9 7 . 5}$</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">79.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">$\mathbf{9 4 . 4}$</td>
<td style="text-align: center;">$\mathbf{8 0 . 2}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 4}$</td>
<td style="text-align: center;">$\mathbf{8 3 . 2}$</td>
</tr>
<tr>
<td style="text-align: center;">FA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">71.8</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">80.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 7 . 5}$</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">$\mathbf{7 9 . 3}$</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">79.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">$\mathbf{9 4 . 4}$</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">$\mathbf{8 2 . 4}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 9}$</td>
</tr>
</tbody>
</table>
<p>Table 5: Out-of-domain performance comparison among RuleTakers (RT), PROVER (PV), and PROBR (PB) on Birds-Electricity dataset after training on DU5.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Test</th>
<th style="text-align: center;">B1</th>
<th style="text-align: center;">B2</th>
<th style="text-align: center;">E1</th>
<th style="text-align: center;">E2</th>
<th style="text-align: center;">E3</th>
<th style="text-align: center;">E4</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">72</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">312</td>
<td style="text-align: center;">1206</td>
<td style="text-align: center;">1736</td>
</tr>
<tr>
<td style="text-align: center;">QA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">83.3</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">83.8</td>
<td style="text-align: center;">81.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 4}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 9}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 6}$</td>
</tr>
<tr>
<td style="text-align: center;">PA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">35.7</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">45.5</td>
<td style="text-align: center;">70.3</td>
<td style="text-align: center;">63.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 1}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 3}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 2}$</td>
<td style="text-align: center;">$\mathbf{9 4 . 3}$</td>
</tr>
<tr>
<td style="text-align: center;">FA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">50.0</td>
<td style="text-align: center;">45.5</td>
<td style="text-align: center;">70.3</td>
<td style="text-align: center;">63.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 4}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 6}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 1}$</td>
<td style="text-align: center;">$\mathbf{8 7 . 1}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 2}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 5}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Out-of-domain performance comparison among EVR and IBR on partial Birds-Electricity dataset (exclude Fail-proof samples) after training on DU5.
ization ability of IBR by first training the model on the training splits of DU0, DU1, DU2, and DU3, then test them on the test split of DU5 with deeper proof paths respectively ${ }^{5}$. Results are shown in Table 7. We notice that all models suffer performance degeneration especially when the proof depth of the training set is lower, because it is hard for the model to learn complex reasoning based on simple proof paths. However, IBR still realizes the best performance in terms of PA and FA, especially on DU3, where it gets $4.2 \%$ PA/FA promotion to PROBR and even outperforms PROVER trained on the whole DU5 data. These observations again prove that iterative approaches can better learn the detailed reasoning step by step, obtaining a better generalization capability than at-once models.</p>
<p>Generalize to complex language. We also evaluate whether IBR can be applied to samples where questions and statements are expressed in more human-like natural language. Following Clark et al. (2020), we train models on the combined training</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 7: Performance of generalization ability between PROVER (PV), PROBR (PB), and IBR when testing on the test split of DU5, after trained on DU0, DU1, DU2, DU3, and DU5, respectively.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">$\mathbf{0}$</th>
<th style="text-align: center;">$\mathbf{1}$</th>
<th style="text-align: center;">$\mathbf{2}$</th>
<th style="text-align: center;">$\mathbf{3}$</th>
<th style="text-align: center;">$\mathbf{4}$</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">2968</td>
<td style="text-align: center;">2406</td>
<td style="text-align: center;">1443</td>
<td style="text-align: center;">1036</td>
<td style="text-align: center;">142</td>
<td style="text-align: center;">8008</td>
</tr>
<tr>
<td style="text-align: center;">QA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">98.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">$\mathbf{9 9 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">98.4</td>
</tr>
<tr>
<td style="text-align: center;">PA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">95.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">$\mathbf{9 0 . 1}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 4}$</td>
<td style="text-align: center;">95.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 1 . 1}$</td>
<td style="text-align: center;">89.0</td>
<td style="text-align: center;">75.3</td>
<td style="text-align: center;">$\mathbf{9 5 . 9}$</td>
</tr>
<tr>
<td style="text-align: center;">FA</td>
<td style="text-align: center;">PV</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">95.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">PB</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">$\mathbf{9 0 . 1}$</td>
<td style="text-align: center;">$\mathbf{8 2 . 4}$</td>
<td style="text-align: center;">95.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 1}$</td>
<td style="text-align: center;">$\mathbf{9 0 . 9}$</td>
<td style="text-align: center;">89.0</td>
<td style="text-align: center;">75.3</td>
<td style="text-align: center;">$\mathbf{9 5 . 7}$</td>
</tr>
</tbody>
</table>
<p>Table 8: Performance on ParaRules test set, after trained on combined D3+ParaRules training partitions, including PROVER (PV), PROBR (PB), and IBR.
partitions of DU3 and ParaRules then test them on the ParaRules test set. To our best knowledge, it is the dataset that is closest to real-world applications. Table 8 demonstrates that our model sees a slight promotion in PA/FA while a similar accuracy as PROVER in QA, indicating that IBR still has good applicability when doing reasoning on more complicated and natural texts.</p>
<h2>5 Analysis</h2>
<h3>5.1 Ablation Study</h3>
<p>To explore the effects between different components in our model, we consider the following ablations: 1) IBR +Gold-Parent: given the gold parent nodes during inference to explore the accuracy of child node prediction; 2) IBR +Gold-Child: given the gold child nodes to verify the accuracy of parent node prediction; 3) w/o QA: removing QA task in loss to check its impact on proof generation; 4) $w / o$ node LSTM: using mean pooling rather than LSTM encoding to get the representations of nodes; 5) $w / o$ focus LSTM: Removing the supplementary LSTM in path focus selection.</p>
<p>Results on the whole DU5 test split are given in Table 9. As the numeric performance shows,</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Models</th>
<th style="text-align: center;">QA</th>
<th style="text-align: center;">PA</th>
<th style="text-align: center;">FA</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">IBR</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">93.5</td>
</tr>
<tr>
<td style="text-align: left;">IBR +Gold-Parent</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">95.3</td>
</tr>
<tr>
<td style="text-align: left;">IBR +Gold-Child</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.3</td>
</tr>
<tr>
<td style="text-align: left;">w/o QA</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">93.7</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">w/o node LSTM</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">93.2</td>
</tr>
<tr>
<td style="text-align: left;">w/o focus LSTM</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">92.6</td>
<td style="text-align: center;">92.4</td>
</tr>
</tbody>
</table>
<p>Table 9: Results of ablation studies on DU5 dataset. We use IBR as the backbone.
giving either gold parent nodes or gold child nodes can benefit the performance especially the later one. This signifies that our parent node prediction achieves promising accuracy while the prediction of child nodes can be further improved. Moreover, IBR can still learn to generate proofs without supervision from answers. And LSTM encoders attribute to a better representation of both the nodes and the path that has been derived.</p>
<h3>5.2 Latency Analysis</h3>
<p>To demonstrate the computational efficiency of IBR, we compare the per sample inference time of IBR with EVR, also an iterative proof generation model, on the test split of DU5. Additionally, we also compare the per sample inference time of IBR with PROVER and PROBR, both at-once models. All models are tested on one NVIDIA Tesla-V100 GPU with the same batch size and the beam size of IBR sets to 1 for a fair comparison. As shown in Figure 4, our IBR could achieve up to $\times 119.5$ speedup compared with EVR, benefiting from our reasoning based on node and path features rather than intermediate texts. It is also noticeable that the runtime of EVR grows linearly with depth, while such an effect is slight on our model. Because EVR needs to infer on all contexts at every step, but IBR uses a simplified parent node prediction based on the derived path. Figure 5 illustrates that IBR is also faster than PROVER because PROVER has some constraints during post-processing in inference, like ensuring proof connectivity, which takes extra time.</p>
<h2>6 Conclusion</h2>
<p>This paper presents IBR, a proof generation model via iterative backward reasoning for rule-based QA tasks. We equip the reasoning procedure with detailed hidden state tracking by predicting nodes and edges in the proof path iteratively backward from the question, and allow the model to reason on the elaborate representations of nodes and his-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Per-sample inference runtime (in second) of EVR and IBR on DU5 dataset with varying depths.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Per-sample inference runtime (in second) of PROVER (PV), IBR, and PROBR (PB) on DU5 dataset with varying depths.
tory paths. Our model is more interpretable than previous at-once models, and is also more effective and efficient than former iterative models. Experiments also demonstrate the superiority of IBR to various baselines on proof generation under various settings.</p>
<h2>Acknowledgements</h2>
<p>This work was partially supported by the National Natural Science Foundation of China (61876053, 62006062, 62176076), the Shenzhen Foundational Research Funding JCYJ20210324115614039, Shenzhen Science and Technology Program JSGG20210802154400001, and the Joint Lab of HITSZ and China Merchants Securities.</p>
<h2>References</h2>
<p>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533-1544, Seattle, Washington, USA. Association for Computational Linguistics.</p>
<p>Jonathan Berant and Percy Liang. 2014. Semantic parsing via paraphrasing. In Proceedings of the 52nd Annual Meeting of the Association for Computational</p>
<p>Linguistics (Volume 1: Long Papers), pages 14151425, Baltimore, Maryland. Association for Computational Linguistics.</p>
<p>Deng Cai and Wai Lam. 2019. Core semantic first: A top-down approach for AMR parsing. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3799-3809, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over language. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3882-3890. ijcai.org.</p>
<p>Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2368-2378, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, and Danqi Chen. 2019. MRQA 2019 shared task: Evaluating generalization in reading comprehension. In Proceedings of the 2nd Workshop on Machine Reading for Question Answering, pages 1-13, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):17351780 .</p>
<p>Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. 2020. SpanBERT: Improving pre-training by representing and predicting spans. Transactions of the Association for Computational Linguistics, 8:64-77.</p>
<p>Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601-1611, Vancouver, Canada. Association for Computational Linguistics.</p>
<p>Zhengzhong Liang, Steven Bethard, and Mihai Surdeanu. 2021. Explainable multi-hop verbal reasoning through internal monologue. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1225-1250, Online. Association for Computational Linguistics.</p>
<p>Kevin Lin, Oyvind Tafjord, Peter Clark, and Matt Gardner. 2019. Reasoning over paragraph effects in situations. In Proceedings of the 2nd Workshop on Machine Reading for Question Answering, pages 58-62, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In Proceedings of the TwentyNinth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3622-3628. ijcai.org.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv preprint, abs/1907.11692.</p>
<p>Mark A Musen and Johan Van Der Lei. 1988. Of brittleness and bottlenecks: Challenges in the creation of pattern-recognition and expert-system models. In Machine Intelligence and Pattern Recognition, 7:335352.</p>
<p>Allen Newell and Herbert Simon. 1956. The logic theory machine-a complex information processing system. IRE Transactions on information theory, 2(3):61-79.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.</p>
<p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383-2392, Austin, Texas. Association for Computational Linguistics.</p>
<p>Swarnadeep Saha, Sayan Ghosh, Shashank Srivastava, and Mohit Bansal. 2020. PRover: Proof generation for interpretable reasoning over rules. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 122-136, Online. Association for Computational Linguistics.</p>
<p>Nan Shao, Yiming Cui, Ting Liu, Shijin Wang, and Guoping Hu. 2020. Is Graph Structure Necessary for Multi-hop Question Answering? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7187-7192, Online. Association for Computational Linguistics.</p>
<p>Changzhi Sun, Xinbo Zhang, Jiangjie Chen, Chun Gan, Yuanbin Wu, Jiaze Chen, Hao Zhou, and Lei Li. 2021. Probabilistic graph reasoning for natural proof generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages</p>
<p>3140-3151, Online. Association for Computational Linguistics.</p>
<p>Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. 2021. ProofWriter: Generating implications, proofs, and abductive statements over natural language. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3621-3634, Online. Association for Computational Linguistics.</p>
<p>Oyvind Tafjord, Matt Gardner, Kevin Lin, and Peter Clark. 2019. QuaRTz: An open-domain dataset of qualitative relationship questions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5941-5946, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, pages 5998-6008.</p>
<p>Leon Weber, Pasquale Minervini, Jannes Mnchmeyer, Ulf Leser, and Tim Rocktschel. 2019. NLProlog: Reasoning with weak unification for question answering in natural language. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6151-6161, Florence, Italy. Association for Computational Linguistics.</p>
<p>Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association for Computational Linguistics, 6:287302 .</p>
<p>Jason Weston, Antoine Bordes, Sumit Chopra, and Toms Mikolov. 2016. Towards ai-complete question answering: A set of prerequisite toy tasks. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2369-2380, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V. Le. 2018. Qanet: Combining local convolution with global self-attention for reading comprehension. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net.</p>
<p>Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: A reading comprehension dataset requiring logical reasoning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Luke S. Zettlemoyer and Michael Collins. 2012. Learning to map sentences to logical form: structured classification with probabilistic categorial grammars. ArXiv preprint, abs/1207.1420.</p>
<h2>A Appendix</h2>
<h2>A. 1 Implementation Details</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Parameter</th>
<th style="text-align: center;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Training Epochs</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: left;">Optimizer</td>
<td style="text-align: center;">AdamW</td>
</tr>
<tr>
<td style="text-align: left;">Batch Size</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: left;">RoBERTa Learning rate</td>
<td style="text-align: center;">$1 \mathrm{e}-5$</td>
</tr>
<tr>
<td style="text-align: left;">QA and Strategy Pre Learning rate</td>
<td style="text-align: center;">$1 \mathrm{e}-5$</td>
</tr>
<tr>
<td style="text-align: left;">Parent Node Pre Learning rate</td>
<td style="text-align: center;">$2 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">Child Node Pre Learning rate</td>
<td style="text-align: center;">$5 \mathrm{e}-4$</td>
</tr>
<tr>
<td style="text-align: left;">All LSTM Learning rate</td>
<td style="text-align: center;">$1 \mathrm{e}-3$</td>
</tr>
<tr>
<td style="text-align: left;">Dropout Rate</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">LSTM hidden state for parent node</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">and child node encoding</td>
<td style="text-align: center;">1024</td>
</tr>
<tr>
<td style="text-align: left;">LSTM hidden state for path encoding</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">in parent node prediction</td>
<td style="text-align: center;">1024</td>
</tr>
<tr>
<td style="text-align: left;">Transformer hidden state in path</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">focus selection</td>
<td style="text-align: center;">1024</td>
</tr>
<tr>
<td style="text-align: left;">LSTM hidden state in path focus</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">selection</td>
<td style="text-align: center;">256</td>
</tr>
<tr>
<td style="text-align: left;">Seed</td>
<td style="text-align: center;">42</td>
</tr>
</tbody>
</table>
<p>Table 10: Implementation details of IBR.</p>
<p>We implement our model based on PyTorch along with Huggingface-Transformers toolkit ${ }^{6}$. We use RoBERTa $_{\text {Large }}$ model $^{7}$ as our backbone encoder to generate token-level representations. Table 10 shows the implementation details of IBR, including learning rates for different modules. All linear layers used in our model have one layer. The model trained after 8 epochs will be used in the evaluation. We remove functional words without lexical meaning like "a" and "the" from facts, rules, and questions to shorten the input length, so each training epoch takes about 2 hours. We select these hyper-parameters according to tuning them empirically based on the performance. All experiments are run on NVIDIA Tesla-V100 GPUs. The main experiment performance of IBR fluctuates by one point.</p>
<h2>A. 2 Dataset Details</h2>
<p>We next introduce the details of the three datasets used in our experiment. All of them are firstly applied in rule-based QA and proof generation tasks in Clark et al., 2020.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 11: The statistics of train and test split in DU5 dataset. Fail-proof and Proof indicate different proof strategies we discussed in 3.1. Avg. Node indicates the average node number in a proof path.</p>
<p>DU0-DU5: A series of synthesized datasets where rules and facts are all generated via manually designed logical programming, while questions are generated by combining random logical operations among them. Data are divided into 5 subsets according to their maximum reasoning depth (D) in the proof path, $\mathrm{D}=0,1,2,3,5$. There are 100 k questions in each subset, where $70 \mathrm{k} / 10 \mathrm{k} / 20 \mathrm{k}$ samples in the train / validation / test partition respectively. $\mathrm{D}=0$ means that the question can be proven directly using a fact in contexts. In our experiment in $\S 4$, we only use the data from DU5 for testing because it covers all possible depths, while the train set is the train split in DU5 except $\S 4.5$, where we use train split from DU0, DU1, DU2 and DU3 for training. We provide some statistics of DU5 in Table 11.</p>
<p>Birds-Electricity: It is a set of data that only contains 5 k test samples for the evaluation of robustness and out-of-domain performance of models. The Birds data only require reasoning up to depth 1 and 2 (B1 and B2), while Electricity data have reasoning depths ranging from 1 to 4 . Both of them include new vocabulary that is not included in DU0-DU5.</p>
<p>ParaRules: A more challenging dataset contains paraphrased samples on the synthesized ones via crowdsourcing. It has 40k questions against about 2 k theories. The statements are expressed in a more natural way, posing a discrepancy between DU0-DU5. It has $28 \mathrm{k} / 4 \mathrm{k} / 8 \mathrm{k}$ samples in the train / validation / test split respectively. In $\S 4.5$, we combine it with the extensive DU3 for training,</p>
<p>resulting in a train set containing 119 k samples.</p>
<h2>A. 3 Possible Limitations of Our Model</h2>
<p>Since our strategy prediction module and operations corresponding to different strategies in node prediction modules are specially designed for the current datasets, we may need to redesign some specific operations to reach the best performance, if some novel proof types are included in new datasets. But we believe our architecture will still take effect without modification. Besides, the interpretability of IBR is not so strong as former works like EVR that make use of intermediate texts.</p>
<h2>A. 4 Strategy Accuracy of IBR</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">$\mathbf{D}$</th>
<th style="text-align: center;">Cnt</th>
<th style="text-align: center;">Strategy Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">0</td>
<td style="text-align: center;">6299</td>
<td style="text-align: center;">99.9</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4434</td>
<td style="text-align: center;">99.1</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2915</td>
<td style="text-align: center;">99.3</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2396</td>
<td style="text-align: center;">99.0</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">2134</td>
<td style="text-align: center;">99.2</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2003</td>
<td style="text-align: center;">99.7</td>
</tr>
<tr>
<td style="text-align: center;">All</td>
<td style="text-align: center;">20192</td>
<td style="text-align: center;">99.4</td>
</tr>
</tbody>
</table>
<p>Table 12: Strategy accuracy of IBR on test split of DU5 after training on training split of DU5.</p>
<p>We provide the strategy prediction accuracy on DU5 in Table 12. It proves that IBR is also well able to make predictions on the proof strategies. This is partly due to RoBERTa's powerful representation capability. On the other hand, there is a certain connection between the answer to the question and the strategy, and there are some common elements at the semantic representation level that can be learned together.</p>
<h2>A. 5 Performance of EVR and IBR on Fail-proof Samples</h2>
<p>As we have discussed in 4.2, EVR (Liang et al., 2021) is not applicable for samples containing Failproof proofs, because it cannot obtain proper intermediate questions to proceed correct following reasoning. Here, we compare our model with EVR on these samples in DU0-DU5, as illustrated in Table 13. Although EVR can achieve promising performance on answer prediction (QA) for these samples, it cannot generate any correct proof path in such cases, which have already been discussed in its original paper.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">$\mathbf{0}$</th>
<th style="text-align: center;">$\mathbf{1}$</th>
<th style="text-align: center;">$\mathbf{2}$</th>
<th style="text-align: center;">$\mathbf{3}$</th>
<th style="text-align: center;">$\mathbf{4}$</th>
<th style="text-align: center;">$\mathbf{5}$</th>
<th style="text-align: center;">all</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cnt</td>
<td style="text-align: center;">4365</td>
<td style="text-align: center;">2500</td>
<td style="text-align: center;">981</td>
<td style="text-align: center;">462</td>
<td style="text-align: center;">200</td>
<td style="text-align: center;">69</td>
<td style="text-align: center;">8577</td>
</tr>
<tr>
<td style="text-align: center;">QA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">$\mathbf{9 8 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 1}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 5}$</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">$\mathbf{9 9 . 4}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 1}$</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">$\mathbf{1 0 0}$</td>
<td style="text-align: center;">99.3</td>
</tr>
<tr>
<td style="text-align: center;">PA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 0}$</td>
<td style="text-align: center;">$\mathbf{8 9 . 5}$</td>
<td style="text-align: center;">$\mathbf{8 4 . 4}$</td>
<td style="text-align: center;">$\mathbf{6 5 . 5}$</td>
<td style="text-align: center;">$\mathbf{2 8 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 0}$</td>
</tr>
<tr>
<td style="text-align: center;">FA</td>
<td style="text-align: center;">EVR</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IBR</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 0}$</td>
<td style="text-align: center;">$\mathbf{8 9 . 5}$</td>
<td style="text-align: center;">$\mathbf{8 4 . 4}$</td>
<td style="text-align: center;">$\mathbf{6 5 . 5}$</td>
<td style="text-align: center;">$\mathbf{2 8 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 0}$</td>
</tr>
</tbody>
</table>
<p>Table 13: The performance of EVR and IBR on the partial test split of DU5 that only contains samples whose proofs strategies are Fail-proof.</p>
<h2>A. 6 Proof Generation samples</h2>
<p>We provide some proof generation samples in Figure 6 for a better understanding of this task, where questions, all contexts, and the proof path generated by our IBR are given (all consistent with the given labels).</p>
<h2>Rules:</h2>
<p>$\mathrm{R}<em 2="2">{1}$ : If someone is nice and kind then they like the bear.
$\mathrm{R}</em>$ : If someone sees the dog and they eat the bear then the bear is cold.
$\mathrm{R}<em 4="4">{3}$ : If someone is big then they eat the cat.
$\mathrm{R}</em>$ : If someone is big then they do not see the rabbit.
$\mathrm{R}<em 6="6">{5}$ : If someone is not big and they do not eat the dog then the dog is cold.
$\mathrm{R}</em>$ : If someone is cold then they like the rabbit.
$\mathrm{R}<em 8="8">{7}$ : If someone likes the rabbit then they see the dog.
$\mathrm{R}</em>$ : If the dog eats the cat then the dog is kind.
$\mathrm{R}_{9}$ : If someone likes the dog and they do not eat the cat then the dog eats the bear.</p>
<h2>Facts:</h2>
<p>$\mathrm{F}<em 2="2">{1}$ : The bear eats the cat.
$\mathrm{F}</em>$ : The bear eats the rabbit.
$\mathrm{F}<em 4="4">{3}$ : The cat eats the dog.
$\mathrm{F}</em>$ : The cat eats the rabbit.
$\mathrm{F}<em 6="6">{5}$ : The cat likes the bear.
$\mathrm{F}</em>$ : The cat sees the rabbit.
$\mathrm{F}<em 8="8">{7}$ : The dog is round.
$\mathrm{F}</em>$ : The dog likes the bear.
$\mathrm{F}_{9}$ : The dog likes the cat.</p>
<h2>$\mathbf{Q}_{1}$ : The bear is cold.</h2>
<p>$\mathbf{A}<em 2="2">{1}$ : True
Proof generated by IBR:
Proof Depth $=3$, Strategy: Proof
$\mathbf{Q}</em>$ : The dog does not see the dog.
$\mathbf{A}<em 3="3">{2}$ : False
Proof generated by IBR:
Proof Depth $=3$, Strategy: Proof
$\mathbf{Q}</em>$ : The dog eats the bear.
$\mathbf{A}<em 1="1">{3}$ : False
Proof generated by IBR:
Proof Depth $=1$, Strategy: Fail-proof
<img alt="img-5.jpeg" src="img-5.jpeg" />
$\mathrm{R}</em>} \longrightarrow \mathrm{R<em 3="3">{2} \longrightarrow \mathrm{R}</em>$
<img alt="img-6.jpeg" src="img-6.jpeg" />
$\mathbf{Q}<em 4="4">{4}$ : The dog eats the bear.
$\mathbf{A}</em>$ : False
Proof generated by IBR:
Proof Depth $=1$, Strategy: Fail-proof
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 6: Some proof cases generated by IBR, along with all contexts and questions, including two proof strategies, Proof and Fail-proof.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://github.com/huggingface/ transformers
${ }^{7}$ https://huggingface.co/roberta-large&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ Results of baselines are obtained from the original papers or by running the released code.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>