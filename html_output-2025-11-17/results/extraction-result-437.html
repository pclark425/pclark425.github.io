<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-437 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-437</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-437</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-274306413</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2411.18564v2.pdf" target="_blank">Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they often struggle with spatial reasoning. This paper presents a novel neural-symbolic framework that enhances LLMs' spatial reasoning abilities through iterative feedback between LLMs and Answer Set Programming (ASP). We evaluate our approach on two benchmark datasets: StepGame and SparQA, implementing three distinct strategies: (1) direct prompting baseline, (2) Facts+Rules prompting, and (3) DSPy-based LLM+ASP pipeline with iterative refinement. Our experimental results demonstrate that the LLM+ASP pipeline significantly outperforms baseline methods, achieving an average 82% accuracy on StepGame and 69% on SparQA, marking improvements of 40-50% and 8-15% respectively over direct prompting. The success stems from three key innovations: (1) effective separation of semantic parsing and logical reasoning through a modular pipeline, (2) iterative feedback mechanism between LLMs and ASP solvers that improves program rate, and (3) robust error handling that addresses parsing, grounding, and solving failures. Additionally, we propose Facts+Rules as a lightweight alternative that achieves comparable performance on complex SparQA dataset, while reducing computational overhead.Our analysis across different LLM architectures (Deepseek, Llama3-70B, GPT-4.0 mini) demonstrates the framework's generalizability and provides insights into the trade-offs between implementation complexity and reasoning capability, contributing to the development of more interpretable and reliable AI systems.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e437.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e437.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DSPy LLM+ASP Pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DSPy-based LLM + Answer Set Programming Iterative Pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular neural-symbolic pipeline that uses LLMs to generate and iteratively refine ASP programs (facts and rules) under DSPy orchestration, with an external ASP solver (Clingo) performing declarative inference and a feedback loop from solver errors to the LLM for program correction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DSPy LLM+ASP Pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A four-stage hybrid system: (a) Facts Generation — LLM converts natural-language contexts/questions into ASP facts and queries; (b) ASP Refining — the LLM iteratively refines ASP code for up to three iterations using solver error messages; (c) Symbolic Reasoning — the Clingo solver performs ASP grounding and solving to produce answer sets; (d) Result Interpretation — map solver outputs to final answers with synonym normalization and post-processing. DSPy provides modular orchestration, prompt/weight optimization, logging, state/memory between modules, and an optimization compiler to refine prompts across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Answer Set Programming (ASP) represented as ASP facts, rules, constraints and queries (predicates such as block/1, object/5, is/3, query/1) executed by the Clingo solver (stable-model semantics).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Large Language Models used as neural semantic parsers and program generators (DeepSeek, Llama3-70B, GPT-4.0 mini); DSPy orchestration code (Python) that implements iterative control flow, prompt optimization and logging (procedural orchestration).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular sequential+iterative integration: LLMs produce declarative ASP text which is executed by an external ASP solver; solver error messages and execution outputs are fed back into the LLM for iterative refinement (closed feedback loop). Orchestration and prompt/weight optimization performed by DSPy; no end-to-end gradient coupling — system is modular and black-box (API calls to LLMs and Clingo).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Marked improvement in multi-hop spatial reasoning accuracy and program executability that neither component achieves alone: (1) high-quality symbolic proofs and explainable answer-sets from ASP combined with LLM flexibility for robust semantic parsing; (2) ability to detect dataset label inconsistencies via symbolic verification; (3) improved executable program generation rates via iterative solver-feedback correcting syntactic and grounding errors; (4) compositional multi-hop reasoning scaling beyond direct LLM output.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Textual spatial reasoning on StepGame (grid-based multi-hop spatial relations) and SparQA (complex natural-language spatial questions including quantifiers, 3D and topological relations).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>StepGame overall accuracies (DSPy pipeline): Deepseek 87.7% overall (per-hop up to 93.7% at k=1, 79.8% at k=10), Llama3 75.6% overall, GPT-4.0 mini 80.8% overall; Reported averages in paper: ~82% on StepGame and ~69% on SparQA. SparQA overall accuracies (DSPy pipeline): Deepseek 67.2%, Llama3 69.4%, GPT-4.0 mini 70.3%.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Direct prompting baselines: StepGame overall — Deepseek 31.3%, Llama3 29.3%, GPT-4.0 mini 29.9%; SparQA overall — Deepseek 59.8%, Llama3 55.2%, GPT-4.0 mini 55.5%.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Shows robust gains across multiple LLM architectures (Deepseek, Llama3, GPT-4.0 mini) and across reasoning depths in StepGame (larger relative gains at deeper hops). Generalizes less perfectly to SparQA: performance improvements are present but smaller and failure modes concentrate on complex natural-language phenomena (quantifiers, implicit relations, coreference), indicating domain sensitivity and limitations for out-of-distribution linguistic complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability from declarative side: ASP answer-sets and explicit rules enable inspectable logical proofs and error messages for debugging; the system logs each module's outputs. The pipeline yields explainable intermediate artifacts (facts, rules, answer-sets) that can be inspected to justify final answers and to locate parsing/grounding errors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Main failure modes: parsing/syntax errors in generated ASP (31% of errors), grounding errors (23%), satisfiable but no-result cases (28%), and wrong answers (18%). High computational overhead due to multiple LLM calls per program (iterative refinement). Sensitivity to prompt design and to complex linguistic constructs (quantifiers, implicit relations). Execution rates varied across models (e.g., pre-feedback execution rates as low as ~34% for some model/dataset combinations).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Principle of division of labor and modular complementary strengths: LLMs as flexible semantic parsers and program generators, ASP as precise declarative reasoner; iterative feedback loop theory — solver-derived error signals guide LLM refinement; DSPy formalizes pipeline modularity and prompt/weight optimization as an empirical framework rather than an end-to-end differentiable theory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e437.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e437.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Facts+Rules Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Facts + Rules Natural-Language Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A lightweight neural-symbolic hybrid that instructs LLMs to generate structured facts (predicates) and then apply explicit logical rules given in natural language (invertible, transitive, symmetric, offset rules) instead of producing executable ASP code or calling an external symbolic solver.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Facts+Rules Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Two-stage approach: (1) LLM converts input to structured predicate-like facts (retaining consistent argument order and naming); (2) LLM is prompted (in natural language) to apply a fixed set of logical rules (encoded in the prompt) to derive answers (e.g., apply inverse/transpose/transitive relations or offset-based chaining). No external solver is invoked; reasoning is performed by the LLM under constrained, rule-guided prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Structured symbolic facts represented as predicate-like strings (e.g., is/3, object/5) and human-specified logical rules encoded in the prompt (inverse, symmetric, transitive, offset-based chain rules). These are not compiled into formal ASP but act as declarative constraints encoded in natural language.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Large Language Models (same family as other methods) operating in a constrained reasoning mode to apply rules over the generated facts; no external procedural solver, but the LLM's procedural token-generation process implements rule application.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybridization by embedding symbolic rule-sets into the LLM prompt (rule-driven chain-of-thought). This is a single-module neural-only execution that uses symbolic structure (facts+rules) as constraints/priors inside the prompt rather than producing formal code executed by a symbolic engine.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Lower computational overhead with comparable performance to full LLM+ASP on some complex datasets (particularly on SparQA in this paper), improved stability from explicit rules and consistent entity naming, and reduction of executable-program generation failures because no formal grounding/solving step is required. However, lacks formal guarantees and explicit explainable solver outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Evaluated on StepGame (multi-hop grid-based spatial reasoning) and SparQA (complex natural-language spatial QA including quantifiers).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td>StepGame overall: Facts+Rules improved over direct prompting — Deepseek 44.9%, Llama3 47.0%, GPT-4.0 mini 47.6% (vs. direct ~29–31%). SparQA overall: Deepseek 66.4%, Llama3 63.9%, GPT-4.0 mini 58.6% (comparable to or slightly below DSPy pipeline in many cases).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td>Direct prompting baselines: StepGame ~29–31% overall; SparQA ~55–60% overall (see paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Shows more reliable behavior than direct prompting on complex NL datasets by enforcing naming and rule-following conventions, and sometimes approaches LLM+ASP on SparQA. However, because reasoning is performed inside the LLM, it remains sensitive to linguistic variation and may not generalize as cleanly as a formal solver when rules require exact logical encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Provides partial interpretability by producing explicit intermediate facts and by making rule application explicit in the chain-of-thought, but lacks the formal, inspectable answer-sets a real solver produces; explanations are LLM-generated and not formally verified.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Less formal correctness guarantees; susceptible to LLM hallucination when applying rules; still vulnerable to parsing and naming inconsistency errors. Generally lower performance than full LLM+ASP on structured StepGame tasks and lacks solver-level error messages for systematic debugging.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Pragmatic trade-off principle: embedding symbolic constraints into prompts to guide neural reasoning reduces implementation and computational overhead while retaining many benefits of symbolic structure; viewed as lighter-weight neural-symbolic integration emphasizing constrained LLM reasoning rather than explicit declarative execution.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e437.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e437.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DSPy Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Python orchestration and optimization framework that compiles declarative task specifications into multi-module LLM workflows, optimizes prompts/weights, retains module-level memory, and supports iterative self-improvement through logged feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dspy: Compiling declarative language model calls into selfimproving pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DSPy (orchestration & optimizer)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DSPy defines modular tasks and metrics rather than manual prompt engineering; it compiles declarative task descriptions into orchestrated LLM pipelines, supports iterative refinement of prompts and model weights via an optimization compiler, retains inter-module state, logs outputs and errors for debugging, and coordinates interactions between LLM modules and external tools (e.g., ASP solvers).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Declarative pipeline specifications (task definitions and desired metrics), and the symbolic specification of input/output signatures for modules to ensure consistent structured data exchange.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Procedural orchestration in Python, optimization compiler that adjusts prompts/weights iteratively, and calls to neural LLM APIs (procedural control flow implementing feedback loops).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Meta-orchestration: DSPy sits above the neural and symbolic components, providing modular interfaces, iterative optimization of prompts/weights, and logging for feedback-driven refinement; it does not make the logic differentiable but manages iterative black-box interactions (LLM <-> solver).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Improved program executability and end-to-end task performance via automated prompt/weight optimization and structured module interfaces; enables iterative solver-feedback to be operationalized at scale and simplifies debugging and reproducibility through comprehensive logging.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Used to implement and evaluate the LLM+ASP pipeline and Facts+Rules methods on StepGame and SparQA (spatial reasoning benchmarks).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Facilitates generalization across different LLM backends by providing standardized module interfaces and prompt-optimization, demonstrated by reuse across DeepSeek, Llama3 and GPT-4.0 mini in the experiments; the framework itself does not guarantee semantic generalization but improves operational portability and repeatability.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Improves observability and interpretability of hybrid systems by logging intermediate outputs, error traces, and versioned prompts; makes it easier to inspect which module produced specific artifacts (facts, ASP code, solver outputs).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Adds orchestration complexity and overhead; optimization compiler relies on measured metrics and can add compute cost; does not eliminate core LLM-to-logic translation errors but helps to mitigate them via iterative prompt improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Engineering framework rather than a formal theory: DSPy operationalizes modularity, iterative refinement, and prompt/weight optimization as practical levers to improve neural-symbolic pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e437.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e437.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Integration Pattern Taxonomy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-Symbolic Integration Patterns (Symbolic[Neural], Neural|Symbolic, Neural:Symbolic → Neural, Neural ⊗ Symbolic, Neural[Symbolic])</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A taxonomy of ways neural and symbolic components may be combined, enumerating patterns such as augmenting symbolic systems with neural modules, composing neural learning with symbolic inference, compiling symbolic rules into neural structures, embedding logic via embeddings, and augmenting neural systems with symbolic tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural-Symbolic Integration Patterns</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A conceptual taxonomy describing high-level integration architectures: Symbolic[Neural] (symbolic systems enhanced by neural modules), Neural|Symbolic (neural learning with symbolic inference), Neural:Symbolic → Neural (compiling symbolic rules into neural representations), Neural ⊗ Symbolic (logic integrated via embeddings), and Neural[Symbolic] (neural systems augmented by symbolic reasoning). Practical instantiations include sequential (translate-then-solve), iterative (looped feedback), embedded (differentiable logic), and tool-augmented LLM approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Various representations depending on pattern — explicit logic programs/rules (ASP/Prolog), symbolic constraints, knowledge graphs, or rule sets.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks/LLMs, learned embeddings, or compiled neural architectures representing symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Enumerates methods: sequential two-step translation (LLM -> symbolic solver), iterative solver-feedback loops, embedded differentiable logic modules, compilations of symbolic knowledge into neural weights, and augmentation of LLMs with external symbolic tools via API/tool calls.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Pattern-dependent: e.g., sequential/iterative yields better executability and precise logical inference; embedded/differentiable methods enable end-to-end learning and smooth gradients but risk loss of exact logical semantics; compilation-based methods can produce fast inference with reduced symbolic overhead but may lose explicit interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Mentioned generically for logical reasoning and spatial/visual QA tasks; no single benchmark — taxonomy used to contextualize approaches including those evaluated in this paper (StepGame, SparQA).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Taxonomy observation: iterative and sequential patterns often improve compositional and multi-hop generalization by preserving symbolic exactness; embedded/differentiable approaches can generalize via learned representations but may fail on strict logical constraints. The paper cites these general tendencies but does not provide a formal empirical breakdown by pattern beyond the implemented pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Taxonomy notes that explicit symbolic modules (sequential/iterative) retain interpretability (inspectable rules/answer-sets), while compiled/embedded approaches trade interpretability for efficiency/learning capacity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Each pattern has trade-offs: sequential/iterative suffers from parser-to-solver mismatch and requires error handling; embedded/differentiable approaches may lose exact semantics; compilation methods can be brittle when rules change. The paper highlights parser error rates and grounding/execution failures as practical limitations for sequential/iterative setups.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>A descriptive framework categorizing integration by interaction style and locus of symbolic/neural functionality; underlying principle is complementarity of neural pattern-recognition and symbolic exact inference, with architectural choices determining trade-offs between interpretability, scalability, and learning capability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dspy: Compiling declarative language model calls into selfimproving pipelines. <em>(Rating: 2)</em></li>
                <li>A neuro-symbolic ASP pipeline for visual question answering. <em>(Rating: 2)</em></li>
                <li>Leveraging large language models to generate answer set programs. <em>(Rating: 2)</em></li>
                <li>Coupling large language models with logic programming for robust and general reasoning from text. <em>(Rating: 2)</em></li>
                <li>Neural-symbolic learning and reasoning: A survey and interpretation <em>(Rating: 2)</em></li>
                <li>Answer set programming at a glance. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-437",
    "paper_id": "paper-274306413",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "DSPy LLM+ASP Pipeline",
            "name_full": "DSPy-based LLM + Answer Set Programming Iterative Pipeline",
            "brief_description": "A modular neural-symbolic pipeline that uses LLMs to generate and iteratively refine ASP programs (facts and rules) under DSPy orchestration, with an external ASP solver (Clingo) performing declarative inference and a feedback loop from solver errors to the LLM for program correction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "DSPy LLM+ASP Pipeline",
            "system_description": "A four-stage hybrid system: (a) Facts Generation — LLM converts natural-language contexts/questions into ASP facts and queries; (b) ASP Refining — the LLM iteratively refines ASP code for up to three iterations using solver error messages; (c) Symbolic Reasoning — the Clingo solver performs ASP grounding and solving to produce answer sets; (d) Result Interpretation — map solver outputs to final answers with synonym normalization and post-processing. DSPy provides modular orchestration, prompt/weight optimization, logging, state/memory between modules, and an optimization compiler to refine prompts across iterations.",
            "declarative_component": "Answer Set Programming (ASP) represented as ASP facts, rules, constraints and queries (predicates such as block/1, object/5, is/3, query/1) executed by the Clingo solver (stable-model semantics).",
            "imperative_component": "Large Language Models used as neural semantic parsers and program generators (DeepSeek, Llama3-70B, GPT-4.0 mini); DSPy orchestration code (Python) that implements iterative control flow, prompt optimization and logging (procedural orchestration).",
            "integration_method": "Modular sequential+iterative integration: LLMs produce declarative ASP text which is executed by an external ASP solver; solver error messages and execution outputs are fed back into the LLM for iterative refinement (closed feedback loop). Orchestration and prompt/weight optimization performed by DSPy; no end-to-end gradient coupling — system is modular and black-box (API calls to LLMs and Clingo).",
            "emergent_properties": "Marked improvement in multi-hop spatial reasoning accuracy and program executability that neither component achieves alone: (1) high-quality symbolic proofs and explainable answer-sets from ASP combined with LLM flexibility for robust semantic parsing; (2) ability to detect dataset label inconsistencies via symbolic verification; (3) improved executable program generation rates via iterative solver-feedback correcting syntactic and grounding errors; (4) compositional multi-hop reasoning scaling beyond direct LLM output.",
            "task_or_benchmark": "Textual spatial reasoning on StepGame (grid-based multi-hop spatial relations) and SparQA (complex natural-language spatial questions including quantifiers, 3D and topological relations).",
            "hybrid_performance": "StepGame overall accuracies (DSPy pipeline): Deepseek 87.7% overall (per-hop up to 93.7% at k=1, 79.8% at k=10), Llama3 75.6% overall, GPT-4.0 mini 80.8% overall; Reported averages in paper: ~82% on StepGame and ~69% on SparQA. SparQA overall accuracies (DSPy pipeline): Deepseek 67.2%, Llama3 69.4%, GPT-4.0 mini 70.3%.",
            "declarative_only_performance": null,
            "imperative_only_performance": "Direct prompting baselines: StepGame overall — Deepseek 31.3%, Llama3 29.3%, GPT-4.0 mini 29.9%; SparQA overall — Deepseek 59.8%, Llama3 55.2%, GPT-4.0 mini 55.5%.",
            "has_comparative_results": true,
            "generalization_properties": "Shows robust gains across multiple LLM architectures (Deepseek, Llama3, GPT-4.0 mini) and across reasoning depths in StepGame (larger relative gains at deeper hops). Generalizes less perfectly to SparQA: performance improvements are present but smaller and failure modes concentrate on complex natural-language phenomena (quantifiers, implicit relations, coreference), indicating domain sensitivity and limitations for out-of-distribution linguistic complexity.",
            "interpretability_properties": "High interpretability from declarative side: ASP answer-sets and explicit rules enable inspectable logical proofs and error messages for debugging; the system logs each module's outputs. The pipeline yields explainable intermediate artifacts (facts, rules, answer-sets) that can be inspected to justify final answers and to locate parsing/grounding errors.",
            "limitations_or_failures": "Main failure modes: parsing/syntax errors in generated ASP (31% of errors), grounding errors (23%), satisfiable but no-result cases (28%), and wrong answers (18%). High computational overhead due to multiple LLM calls per program (iterative refinement). Sensitivity to prompt design and to complex linguistic constructs (quantifiers, implicit relations). Execution rates varied across models (e.g., pre-feedback execution rates as low as ~34% for some model/dataset combinations).",
            "theoretical_framework": "Principle of division of labor and modular complementary strengths: LLMs as flexible semantic parsers and program generators, ASP as precise declarative reasoner; iterative feedback loop theory — solver-derived error signals guide LLM refinement; DSPy formalizes pipeline modularity and prompt/weight optimization as an empirical framework rather than an end-to-end differentiable theory.",
            "uuid": "e437.0",
            "source_info": {
                "paper_title": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Facts+Rules Prompting",
            "name_full": "Facts + Rules Natural-Language Prompting",
            "brief_description": "A lightweight neural-symbolic hybrid that instructs LLMs to generate structured facts (predicates) and then apply explicit logical rules given in natural language (invertible, transitive, symmetric, offset rules) instead of producing executable ASP code or calling an external symbolic solver.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Facts+Rules Prompting",
            "system_description": "Two-stage approach: (1) LLM converts input to structured predicate-like facts (retaining consistent argument order and naming); (2) LLM is prompted (in natural language) to apply a fixed set of logical rules (encoded in the prompt) to derive answers (e.g., apply inverse/transpose/transitive relations or offset-based chaining). No external solver is invoked; reasoning is performed by the LLM under constrained, rule-guided prompting.",
            "declarative_component": "Structured symbolic facts represented as predicate-like strings (e.g., is/3, object/5) and human-specified logical rules encoded in the prompt (inverse, symmetric, transitive, offset-based chain rules). These are not compiled into formal ASP but act as declarative constraints encoded in natural language.",
            "imperative_component": "Large Language Models (same family as other methods) operating in a constrained reasoning mode to apply rules over the generated facts; no external procedural solver, but the LLM's procedural token-generation process implements rule application.",
            "integration_method": "Hybridization by embedding symbolic rule-sets into the LLM prompt (rule-driven chain-of-thought). This is a single-module neural-only execution that uses symbolic structure (facts+rules) as constraints/priors inside the prompt rather than producing formal code executed by a symbolic engine.",
            "emergent_properties": "Lower computational overhead with comparable performance to full LLM+ASP on some complex datasets (particularly on SparQA in this paper), improved stability from explicit rules and consistent entity naming, and reduction of executable-program generation failures because no formal grounding/solving step is required. However, lacks formal guarantees and explicit explainable solver outputs.",
            "task_or_benchmark": "Evaluated on StepGame (multi-hop grid-based spatial reasoning) and SparQA (complex natural-language spatial QA including quantifiers).",
            "hybrid_performance": "StepGame overall: Facts+Rules improved over direct prompting — Deepseek 44.9%, Llama3 47.0%, GPT-4.0 mini 47.6% (vs. direct ~29–31%). SparQA overall: Deepseek 66.4%, Llama3 63.9%, GPT-4.0 mini 58.6% (comparable to or slightly below DSPy pipeline in many cases).",
            "declarative_only_performance": null,
            "imperative_only_performance": "Direct prompting baselines: StepGame ~29–31% overall; SparQA ~55–60% overall (see paper tables).",
            "has_comparative_results": true,
            "generalization_properties": "Shows more reliable behavior than direct prompting on complex NL datasets by enforcing naming and rule-following conventions, and sometimes approaches LLM+ASP on SparQA. However, because reasoning is performed inside the LLM, it remains sensitive to linguistic variation and may not generalize as cleanly as a formal solver when rules require exact logical encoding.",
            "interpretability_properties": "Provides partial interpretability by producing explicit intermediate facts and by making rule application explicit in the chain-of-thought, but lacks the formal, inspectable answer-sets a real solver produces; explanations are LLM-generated and not formally verified.",
            "limitations_or_failures": "Less formal correctness guarantees; susceptible to LLM hallucination when applying rules; still vulnerable to parsing and naming inconsistency errors. Generally lower performance than full LLM+ASP on structured StepGame tasks and lacks solver-level error messages for systematic debugging.",
            "theoretical_framework": "Pragmatic trade-off principle: embedding symbolic constraints into prompts to guide neural reasoning reduces implementation and computational overhead while retaining many benefits of symbolic structure; viewed as lighter-weight neural-symbolic integration emphasizing constrained LLM reasoning rather than explicit declarative execution.",
            "uuid": "e437.1",
            "source_info": {
                "paper_title": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "DSPy Framework",
            "name_full": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines",
            "brief_description": "A Python orchestration and optimization framework that compiles declarative task specifications into multi-module LLM workflows, optimizes prompts/weights, retains module-level memory, and supports iterative self-improvement through logged feedback.",
            "citation_title": "Dspy: Compiling declarative language model calls into selfimproving pipelines.",
            "mention_or_use": "use",
            "system_name": "DSPy (orchestration & optimizer)",
            "system_description": "DSPy defines modular tasks and metrics rather than manual prompt engineering; it compiles declarative task descriptions into orchestrated LLM pipelines, supports iterative refinement of prompts and model weights via an optimization compiler, retains inter-module state, logs outputs and errors for debugging, and coordinates interactions between LLM modules and external tools (e.g., ASP solvers).",
            "declarative_component": "Declarative pipeline specifications (task definitions and desired metrics), and the symbolic specification of input/output signatures for modules to ensure consistent structured data exchange.",
            "imperative_component": "Procedural orchestration in Python, optimization compiler that adjusts prompts/weights iteratively, and calls to neural LLM APIs (procedural control flow implementing feedback loops).",
            "integration_method": "Meta-orchestration: DSPy sits above the neural and symbolic components, providing modular interfaces, iterative optimization of prompts/weights, and logging for feedback-driven refinement; it does not make the logic differentiable but manages iterative black-box interactions (LLM &lt;-&gt; solver).",
            "emergent_properties": "Improved program executability and end-to-end task performance via automated prompt/weight optimization and structured module interfaces; enables iterative solver-feedback to be operationalized at scale and simplifies debugging and reproducibility through comprehensive logging.",
            "task_or_benchmark": "Used to implement and evaluate the LLM+ASP pipeline and Facts+Rules methods on StepGame and SparQA (spatial reasoning benchmarks).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Facilitates generalization across different LLM backends by providing standardized module interfaces and prompt-optimization, demonstrated by reuse across DeepSeek, Llama3 and GPT-4.0 mini in the experiments; the framework itself does not guarantee semantic generalization but improves operational portability and repeatability.",
            "interpretability_properties": "Improves observability and interpretability of hybrid systems by logging intermediate outputs, error traces, and versioned prompts; makes it easier to inspect which module produced specific artifacts (facts, ASP code, solver outputs).",
            "limitations_or_failures": "Adds orchestration complexity and overhead; optimization compiler relies on measured metrics and can add compute cost; does not eliminate core LLM-to-logic translation errors but helps to mitigate them via iterative prompt improvement.",
            "theoretical_framework": "Engineering framework rather than a formal theory: DSPy operationalizes modularity, iterative refinement, and prompt/weight optimization as practical levers to improve neural-symbolic pipelines.",
            "uuid": "e437.2",
            "source_info": {
                "paper_title": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Integration Pattern Taxonomy",
            "name_full": "Neural-Symbolic Integration Patterns (Symbolic[Neural], Neural|Symbolic, Neural:Symbolic → Neural, Neural ⊗ Symbolic, Neural[Symbolic])",
            "brief_description": "A taxonomy of ways neural and symbolic components may be combined, enumerating patterns such as augmenting symbolic systems with neural modules, composing neural learning with symbolic inference, compiling symbolic rules into neural structures, embedding logic via embeddings, and augmenting neural systems with symbolic tools.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Neural-Symbolic Integration Patterns",
            "system_description": "A conceptual taxonomy describing high-level integration architectures: Symbolic[Neural] (symbolic systems enhanced by neural modules), Neural|Symbolic (neural learning with symbolic inference), Neural:Symbolic → Neural (compiling symbolic rules into neural representations), Neural ⊗ Symbolic (logic integrated via embeddings), and Neural[Symbolic] (neural systems augmented by symbolic reasoning). Practical instantiations include sequential (translate-then-solve), iterative (looped feedback), embedded (differentiable logic), and tool-augmented LLM approaches.",
            "declarative_component": "Various representations depending on pattern — explicit logic programs/rules (ASP/Prolog), symbolic constraints, knowledge graphs, or rule sets.",
            "imperative_component": "Neural networks/LLMs, learned embeddings, or compiled neural architectures representing symbolic rules.",
            "integration_method": "Enumerates methods: sequential two-step translation (LLM -&gt; symbolic solver), iterative solver-feedback loops, embedded differentiable logic modules, compilations of symbolic knowledge into neural weights, and augmentation of LLMs with external symbolic tools via API/tool calls.",
            "emergent_properties": "Pattern-dependent: e.g., sequential/iterative yields better executability and precise logical inference; embedded/differentiable methods enable end-to-end learning and smooth gradients but risk loss of exact logical semantics; compilation-based methods can produce fast inference with reduced symbolic overhead but may lose explicit interpretability.",
            "task_or_benchmark": "Mentioned generically for logical reasoning and spatial/visual QA tasks; no single benchmark — taxonomy used to contextualize approaches including those evaluated in this paper (StepGame, SparQA).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Taxonomy observation: iterative and sequential patterns often improve compositional and multi-hop generalization by preserving symbolic exactness; embedded/differentiable approaches can generalize via learned representations but may fail on strict logical constraints. The paper cites these general tendencies but does not provide a formal empirical breakdown by pattern beyond the implemented pipeline.",
            "interpretability_properties": "Taxonomy notes that explicit symbolic modules (sequential/iterative) retain interpretability (inspectable rules/answer-sets), while compiled/embedded approaches trade interpretability for efficiency/learning capacity.",
            "limitations_or_failures": "Each pattern has trade-offs: sequential/iterative suffers from parser-to-solver mismatch and requires error handling; embedded/differentiable approaches may lose exact semantics; compilation methods can be brittle when rules change. The paper highlights parser error rates and grounding/execution failures as practical limitations for sequential/iterative setups.",
            "theoretical_framework": "A descriptive framework categorizing integration by interaction style and locus of symbolic/neural functionality; underlying principle is complementarity of neural pattern-recognition and symbolic exact inference, with architectural choices determining trade-offs between interpretability, scalability, and learning capability.",
            "uuid": "e437.3",
            "source_info": {
                "paper_title": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dspy: Compiling declarative language model calls into selfimproving pipelines.",
            "rating": 2,
            "sanitized_title": "dspy_compiling_declarative_language_model_calls_into_selfimproving_pipelines"
        },
        {
            "paper_title": "A neuro-symbolic ASP pipeline for visual question answering.",
            "rating": 2,
            "sanitized_title": "a_neurosymbolic_asp_pipeline_for_visual_question_answering"
        },
        {
            "paper_title": "Leveraging large language models to generate answer set programs.",
            "rating": 2,
            "sanitized_title": "leveraging_large_language_models_to_generate_answer_set_programs"
        },
        {
            "paper_title": "Coupling large language models with logic programming for robust and general reasoning from text.",
            "rating": 2,
            "sanitized_title": "coupling_large_language_models_with_logic_programming_for_robust_and_general_reasoning_from_text"
        },
        {
            "paper_title": "Neural-symbolic learning and reasoning: A survey and interpretation",
            "rating": 2,
            "sanitized_title": "neuralsymbolic_learning_and_reasoning_a_survey_and_interpretation"
        },
        {
            "paper_title": "Answer set programming at a glance.",
            "rating": 1,
            "sanitized_title": "answer_set_programming_at_a_glance"
        }
    ],
    "cost": 0.01364175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs
12 Dec 2024</p>
<p>Rong Wang 
Kun Sun 
TübingenGermany</p>
<p>Jonas Kuhn 
The Institute of Natural Language Processing
Stuttgart University
StuttgartGermany</p>
<p>Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs
12 Dec 202479780BC935B8FF38FD83CBFB71135F92arXiv:2411.18564v2[cs.AI]
Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they often struggle with spatial reasoning.This paper presents a novel neural-symbolic framework that enhances LLMs' spatial reasoning abilities through iterative feedback between LLMs and Answer Set Programming (ASP).We evaluate our approach on two benchmark datasets: StepGame and SparQA, implementing three distinct strategies: (1) direct prompting baseline, (2) Facts+Rules prompting, and (3) DSPy-based LLM+ASP pipeline with iterative refinement.Our experimental results demonstrate that the LLM+ASP pipeline significantly outperforms baseline methods, achieving an average 82% accuracy on StepGame and 69% on SparQA, marking improvements of 40-50% and 8-15% respectively over direct prompting.The success stems from three key innovations: (1) effective separation of semantic parsing and logical reasoning through a modular pipeline, (2) iterative feedback mechanism between LLMs and ASP solvers that improves program executability rate, and (3) robust error handling that addresses parsing, grounding, and solving failures.Additionally, we propose Facts+Rules as a lightweight alternative that achieves comparable performance on complex SparQA dataset, while reducing computational overhead.Our analysis across different LLM architectures (Deepseek, Llama3-70B, GPT-4.0 mini) demonstrates the framework's generalizability and provides insights into the trade-offs between implementation complexity and reasoning capability, contributing to the development of more interpretable and reliable AI systems.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) are known for their impressive performance across a range of tasks, demonstrating certain commonsense reasoning abilities.However, since LLMs are trained to predict subsequent words in a sequence, they seem to lack sufficient grounding to excel at tasks requiring spatial, physical, and embodied reasoning.Spatial reasoning, the ability to understand and manipulate relationships between objects in two-and threedimensional spaces, represents a crucial component of artificial intelligence systems, enabling practical applications in robotics, navigation, and physical task planning.Recent studies (Bang et al., 2023;Cohn, 2023) highlighted the limitations of models like ChatGPT in deductive logical reasoning, spatial reasoning, and non-textual semantic reasoning, underlining the need for further improvements in spatial reasoning.</p>
<p>Efforts to improve logical reasoning capability have focused on advanced prompting techniques.However, these methods have demonstrated notable limitations, particularly on challenging datasets like StepGame (Shi et al., 2022) and SparQA (Mirzaee and Kordjamshidi, 2022), which often require multi-step planning and complex natural language understanding.In these scenarios, LLMs often struggle with maintaining coherence, frequently hallucinating or losing sight of the original objectives, resulting in inaccurate and unreliable outputs.More recent work demonstrates that augmenting large language models (LLMs) with external tools for arithmetic, navigation, and knowledge lookups improves performance (Fang et al., 2024).Notably, neural-symbolic approaches, where LLMs extract facts while external symbolic solvers handle reasoning, show significant promise in enhancing logical inferenceg) (Yang et al., 2023a).Nevertheless, existing neural-symbolic methods face limitations in generalization, scalability, and comprehensive evaluation.(Yu et al, 2021) Neural-symbolic systems have been applied successfully in visual question answering and robotics (Yang et al., 2023a).These approaches often fail to fully harness LLMs' potential, particularly by omitting feedback loops between multiple LLMs and symbolic modules, limiting performance gains.</p>
<p>To overcome these challenges, this paper proposes a novel neural-symbolic framework that systematically integrates symbolic reasoning components with LLMs.Our approach leverages strategic prompting, feedback loops, and Answer Set Programming (ASP)-based verification, creating a robust pipeline that improves spatial reasoning across different LLM architectures.We evaluate this framework on two benchmark datasets, By integrating feedback loops and verification module, our methodology demonstrates strong generalizability when tackling complex spatial reasoning tasks, showing sig-nificant performance gains, with average accuracy improvements of 40% on StepGame and 20% on SparQA.These outcomes underscore the effectiveness of neural-symbolic integration in enhancing spatial reasoning and emphasize the importance of task-specific implementation strategies.</p>
<p>To address these limitations, we propose a pipeline that effectively enhances LLMs' spatial reasoning capabilities.Our approach combines strategic prompting with symbolic reasoning to create a robust framework that significantly improves performance of spatial reasoning across different LLM architectures.Specifically, building on these insights, we propose a novel neural-symbolic pipeline that integrates LLMs with ASP, aimed at enhancing the LLMs' capabilities of spatial reasoning in SparQA and StepGame datasets.We investigate the potential benefits of integrating symbolic reasoning components into LLMs to further boost their spatial reasoning capabilities.Within the broader field of neural-symbolic AI, the combination of LLMs as parsers with ASP solvers has emerged as a particularly effective approach for complex reasoning tasks.Additionally, the present study is one of the pioneering projects which uses DSPy (Khattab et al., 2023) to pipeline and program LLM.</p>
<p>In the broader field of neural-symbolic AI, combining large language models (LLMs) with symbolic reasoning systems like Prolog has proven successful for tackling complex reasoning tasks (Hamilton et al., 2022;Besold et al., 2021).Our study advances this field by demonstrating how incorporating symbolic reasoning modules can enhance LLMs' spatial reasoning capabilities.Specifically, we introduce a modular pipeline using DSPy, enabling seamless interaction between LLMs and symbolic system solvers.Our pipeline not only improves spatial reasoning but also shows promise in broader domains requiring structured logic, thereby contributing to both the theoretical foundations and practical applications of neural-symbolic integration.</p>
<p>Preliminaries</p>
<p>Prompting LLMs for spatial reasoning</p>
<p>Research on spatial reasoning spans both visual and textual domains, each with its own challenges.In Visual Spatial Reasoning (VSR), even advanced models like CLIP (Radford et al., 2021) face limitations in comprehending complex spatial relationships.In the textual domain, spatial reasoning is further complicated by linguistic ambiguity.</p>
<p>Prompting strategies have played a pivotal role in improving LLMs' reasoning capabilities.Approaches such as chain of thought (CoT) (Wei et al., 2022;Chu et al., 2023), few-shot prompting (Schick and Schütze, 2021), and least-to-most prompting (Zhou et al., 2022) enable LLMs to tackle complex problems by breaking them down into logical steps.Self-consistency methods (Wang et al., 2022), further refine reasoning by aggregating multiple solutions to improve accuracy.Recent techniques like like tree of thoughts, visualization of thought (Wang et al., 2023), and program-aided language models (Gao et al., 2022) provide structured, interpretable reasoning pathways.</p>
<p>These prompting strategies demonstrate the potential for LLMs to handle spatial reasoning, but they also highlight the need for more robust methods to address limitations in multi-hop inference and natural language ambiguity.Our approach integrates prompting strategies with symbolic reasoning to enhance LLMs' spatial reasoning capabilities more comprehensively.</p>
<p>Effective Neural-Symbolic Integration</p>
<p>Despite the success of deep learning, its limitations in reasoning, generalization and interpretability have spurred interest in hybrid approaches (Garcez and Lamb, 2023;Hamilton et al., 2022).Neural-symbolic integration aims to combine the strengths of neural networks (pattern recognition and uncertainty handling) with symbolic systems (logical reasoning and knowledge representation).Based on how neural and symbolic components interact and complement each other, research (Wan et al., 2024) has identified key integration patterns: enhancing symbolic systems with neural capabilities (Symbolic[Neural]), combining neural learning with symbolic inference (Neural|Symbolic), compiling symbolic rules into neural structures (Neural:Symbolic → Neural), integrating logic rules through embeddings (Neural ⊗ Symbolic), and augmenting neural systems with symbolic reasoning (Neural[Symbolic]).These patterns can be grouped into practical architectures, including sequential, iterative, and embedded approaches, as well as LLM-based tool integration (Weber et al., 2019;Riegel et al., 2020;Parisi et al., 2022).</p>
<p>The emergence of LLMs has introduced new possibilities for neural-symbolic integration.Modern approaches leverage LLMs as powerful semantic parsers and natural language interfaces, while delegating the reasoning task to external off-the-shelf symbolic reasoners or solvers.The integration typically follows a two-step process: first, the LLM translates natural language queries into formal logical representations (e.g., Prolog predicates or ASP rules), then the logical solver performs structured reasoning to derive answers.However, this approach faces significant challenges in ensuring accurate and consistent mapping between natural language and logical forms.LLMs are not trained on logical programming language and they tend to generate logically inconsistent or syntactically incorrect programs, and the in-executable logical program will lead to the collpase of the whole neural symbolic system.For some complex and realistic dataset, the parsing succesful rate can be as low as 17% (Feng et al., 2024).To addrress this, researchers (Pan et al., 2023) have proposed self-refinement modules to refine the parsing results based on the solver's erroneous messageses; however, the improvement of accuracy is not obvious with only 5% after 3 iterations, highlighting the need for a more efficient architecture to enable sophisticated and robust feedback loop between LLMs and symbolic solvers.</p>
<p>This study leverages Dspy framework to construct a novel neural-symbolic pipeline that integrates LLMs with Answer Set Programming (ASP) in an iterative manner.Through its modular architecture and systematic optimization approach, DSPy can address many of the limitations faced by previous neural-symbolic integration attempts.By defining clear input-output signatures for each module in the pipeline, the framework ensures that the generated ASP code maintains consistent structure and enable the error feedback verification modules working in concert.Dspy's optimization compiler iteratively refines both the prompting strategies and weights used in each stage, ensuring consistent performance improvement, enabling more robust and adaptable neural-symbolic systems.</p>
<p>Answer Set Programming</p>
<p>Answer Set Programming (ASP) is a declarative programming paradigm that leverages predicate logic and stable model semantics to address complex combinational search tasks.Unlike procedural programming, which specifies step-by-step computations, ASP allows users to define solutions through logical relationships, enabling the solver to autonomously determine how to satisfy these conditions (Brewka et al., 2011).ASP is case-sensitive, utilizing uppercase letters for variables and lowercase letters for constants, including atoms and predicates.The underscore character "_" serves as a "don't care" variable that can be instantiated by any value.However, using placeholders in rule heads without corresponding definitions can lead to unsafe variable errors due to ambiguity during grounding.</p>
<p>ASP is closely related to Prolog, having evolved from it and sharing foundational concepts.Both languages utilize logical rules and facts for knowledge representation.However, while Prolog emphasizes procedural query evaluation, ASP focuses on generating answer sets -collections of ground atoms that satisfy the program's rules.This distinction allows ASP to handle nonmonotonic reasoning more effectively, accommodating multiple stable models for a single program, which is less common in Prolog.The paradigm's expressive power derives from four fundamental components, each serving distinct roles in knowledge representation and reasoning:</p>
<p>Facts: Basic units of knowledge represented as unconditional logical atoms p(t1, ..., tn), where p is a predicate symbol and t1, ..., tn are terms.In spatial reasoning, facts typically represent object properties, locations, and basic spatial relationships.</p>
<p>Rules: Logical implications of the form "Head :-Body", where the Head is an atom and the Body consists of literals.Rules enable inference, allowing new knowledge to be derived from existing facts.</p>
<p>Constraints: Special rules expressed as ":-Body" that eliminate answer sets violating specific conditions, thus serving as integrity checks within the knowledge base.</p>
<p>Queries: Goal-directed statements that extract information from the knowledge base, implemented as special predicates whose extensions yield the requested data.</p>
<p>In spatial reasoning contexts, ASP provides a robust framework for representing both static and dynamic spatial relationships through foundational predicates such as block/1 for defining spatial regions, object/5 for specifying object properties (identifier, size, color, shape, location), is/3 for expressing spatial relationships, and location/3 for precise coordinate definitions.This combination of predicates with ASP's logical foundations enables sophisticated reasoning about spatial configurations and relationships.</p>
<p>Methods</p>
<p>Datasets</p>
<p>StepGame (Shi et al., 2022) StepGame is a dataset designed for robust multi-hop spatial reasoning using a grid-based system, featuring eight directional spatial relations: top (north), down (south), left (west), right (east), top-left (north-west), topright (north-east), down-left (south-west), and down-right (south-east).Each relation is defined by specific angles and distances for detailed visual representation, and it includes an "overlap" relation for scenarios where objects share the same location.The dataset supports reasoning hops from 1 to 10 across 10 subsets, each containing 10,000 samples corresponding to a single reasoning hop.However, the single Finding Relation question type may not fully capture the complexities of real-world spatial reasoning, as research indicates that large language models (LLMs) often struggle more with constructing object-linking chains from shuffled relations than with the spatial reasoning tasks themselves.Additionally, prior studies have identified template errors within StepGame that may skew model performance evaluations due to inadequate quality control during crowdsourcing, leading to inaccuracies in relationship mappings that can misrepresent an LLM's spatial reasoning abilities.</p>
<p>SpartQA/SparTUN(Mirzaee and Kordjamshidi, 2022) SpartQA is built upon the NLVR (Natural Language for Visual Reasoning) images, featuring synthetically generated scenes depicting various spatial arrangements.Typically, each scenario consists of three blocks arranged either vertically or horizontally, with each block containing around four objects characterized by attributes like size, color, and shape.Besides, the dataset incorporates a wider range of spatial relationships, including 3D spatial reasoning, topological relations and distance relations.For FR questions, the candidate choices include ['left', 'right', 'above', 'below', 'near to', 'far from', 'touching', 'DK'], but there are more synonym relation names involved in the context and question.</p>
<p>SparQA differs significantly from StepGame in its complexity and scope.Its language structure is 2.5 times longer, featuring three blocks with approximately four objects each.The dataset handles multiple question types including Yes/No, FR, CO, and FB, with questions often involving complex relationships between multiple objects.For example, "What is the relation between the blue circle touching the top edge of block B and the small square?"Except Yes/No questions, FR, CO and FB questions often have more than one answer.SparQA incorporates 3D spatial reasoning, topological relations, and distance relations, with options like left, above, and near to.</p>
<p>A distinctive feature of SparQA is its focus on quantifier-based reasoning, with questions that test higher-level logic through universal ("all") and exclusive ("only") statements.For example, one third questions process queries like "Are all of the squares in B?" and "Which block has only small black things inside?"These questions require comprehensive evaluation of object sets and their properties rather than simple relational comparisons.</p>
<p>By utilizing these diverse datasets and question types, we aim to assess the spatial reasoning capabilities of LLMs across various complexity levels and spatial relation types.</p>
<p>LLM + ASP pipeline with DSPy</p>
<p>Recent studies have demonstrated LLMs' effectiveness as semantic parsers, often surpassing traditional parsing tools.While Geibinger (2023) and Eiter et al. (2022) showed promising results integrating LLMs with ASP, challenges remain.Ishay et al. (2023) found LLMs could generate complex ASP programs but often with errors, while Yang et al. (2023a) achieved 90% accuracy on StepGame using GPT-3 and ASP, their method's scalability remains uncertain.2023)'s LOGIC-LM framework and integration neural-symbolic strategies, we propose a novel neural-symbolic pipeline employing ASP using DSPy that treats the LLM as an agent capable of feedback and iteration.DSPy is a Python framework that uses a declarative and selfimproving approach to simplify working with LLMs (Khattab et al., 2023).It automates the optimization of prompts and model tuning, enhancing reliability and scalability in AI applications.By defining tasks and metrics rather than manual prompts, DSPy streamlines the development of various NLP tasks and complex AI systems.The framework of this pipeline is shown in Fig. 2.</p>
<p>The pipeline consists of four main stages: a) Facts Generation Stage: LLM converts natural language descriptions into symbolic formulations and formal queries.b) ASP Refining Stage: LLM iteratively refines the ASP representation over three iterations, adding rules, checking consistency, and incorporating feedback from error messages.c) Symbolic Reasoning Stage: The refined ASP undergoes inference using the Clingo solver, ensuring accurate and explainable reasoning by combining LLM capabilities with logical inference.d) Result Interpretation and Evaluation: This stage involves mapping the Clingo solver's outputs to candidate answers.For cer-tain question types, like Yes/No and Finding-Block questions, the solver's output can directly serve as the correct answer.However, for Finding Relations and Choose Object questions, additional processing is necessary to filter relevant solutions.Outputs from the ASP solver are evaluated against a synonym dictionary to determine the accuracy.</p>
<p>Overall, this pipeline requires multiple interactions with LLMs during ASP generation and refinement.We employ the DSPy framework to manage these complex workflows (e.g., interfacing with Llama3 60B DeepSeek and GPT 4.0 mini models via their APIs).DSPy's modular features enhance memory retention between modules, enabling adjustments and optimizations while maintaining workflow integrity.</p>
<p>Additionally, DSPy optimizes LLM prompts and weights, reducing the need for manual prompt engineering and ensuring consistent performance across datasets.Its optimization compiler iteratively generates and refines prompts, enhancing task performance.To support transparency and debugging, outputs from all modules are logged, capturing errors and providing insights for prompt engineering and system optimization, facilitating continuous improvement of the system and enhancing the integration of neural and symbolic components.In this way, this integrated neural-symbolic pipeline could greatly facilitate spatial reasoning in LLMs.</p>
<p>To evaluate the effectiveness of our approaches in spatial reasoning comprehensively, we selected three representative LLMs with diverse architectures and capabilities: DeepSeek, Llama3, and GPT4.0 Mini.These LLMs were chosen to ensure a comprehensive assessment across different types of language representations, ranging from lightweight and specialized models like DeepSeek to more advanced general-purpose systems like GPT4.0 Mini.Llama3, known for its balance between performance and computational efficiency, provides an intermediate perspective.By testing our methods on these distinct models, we want to demonstrate the adaptability and robustness of our approach across a variety of LLM architectures and reasoning capacities.</p>
<p>Given the task nature of multiple choices, we primarily employed exact match metrics for single-choice questions and partial match metrics for multiple-choice questions, aligning with the specific requirements of spatial reasoning tasks.To ensure accurate evaluation, we implemented custom post-processing to normalize responses and developed specialized metrics to handle both exact and partial matches between model outputs and ground truth.</p>
<p>Baselines</p>
<p>Direct prompting</p>
<p>As the most straightforward approach, it involves presenting the task to the LLM without additional guidance.The typical form is " Given the question, please answer: While simple, this method is believed not to elicit the model's full potential, particularly in complex reasoning tasks".This straightforward approach involves presenting the task to the LLM without additional guidance.The basic structure consists of a simple template: "Given the context and question, please answer the question by choosing from the choices".While minimal, this method serves as a crucial baseline for model evaluation as it reflects the model's fundamental ability to handle spatial tasks without any reasoning scaffolds.Despite its simplicity, this approach can achieve competitive results, particularly with well-trained models that have developed robust internal reasoning mechanisms.</p>
<p>Facts + Rule prompting</p>
<p>We explore an alternative approach that retains the benefits of structured knowledge representation while minimizing the complexity of formal logical programming.This method embeds logical rules directly into natural language prompts, testing LLMs' ability to reason within structured frameworks.Using the DSPy framework, this approach functions as a rule-based chain-of-thought (CoT) prompting strategy executed in two stages.</p>
<p>This approach aligns with the core principle of neural-symbolic AI: converting raw data into structured, symbolic representations for reasoning.By using predicates with precise argument structures, LLMs create consistent intermediate knowledge representations that facilitate question answering.This streamlined process maintains the advantages of formal reasoning while reducing computational complexity and implementation overhead.</p>
<p>In the LLM+ASP pipeline, generating a single ASP program requires multiple LLM calls due to the iterative refinement process, creating substantial computational overhead even with a modest three-iteration limit.To mitigate this, our alternative approach replaces formal ASP code generation with direct application of logical rules within natural language.The process begins by instructing LLMs to convert natural language inputs into structured facts using predefined predicates, a step retained from the LLM+ASP pipeline.Instead of formal logic programs, LLMs then apply relevant logical rules-such as inverse, symmetric, and transitive relations for the SparQA dataset, or offset-based chain-linking rules for StepGame-to derive answers through natural language reasoning.</p>
<p>By prompting LLMs to explicitly apply specific rules for different scenarios, this approach avoids dependence on external solvers.Consequently, it is termed "Facts+Rules."This method offers a more straightforward and reliable path to spatial reasoning compared to generating and executing formal logic programs.</p>
<p>Experiment Results and Discussion</p>
<p>In this section, we present the results of three methods: Direct Prompting Baseline, Facts + Rules Prompting, and Iterative LLM+ASP, on two benchmark datasets: StepGame and SparQA.We analyze their performance, computational complexity, and suitability for different types of spatial reasoning tasks.Additionally, we conduct an ablation study to assess the impact of iterative feedback loops in the LLM+ASP approach.</p>
<p>StepGame</p>
<p>Implementation</p>
<p>Another important aspect of the StepGame dataset is its reasoning hops range from 1 to 10 hops, distributed across 10 subsets.Specifically, each subset consists of 10,000 samples, each corresponding to a single reasoning hop.We sampled 300 instances for each reasoning hop 1 to 10, k ∈ {1, . . ., 10} , ensuring comprehensive evaluation across complexity levels.To standardize the task, we prompt LLMs to convert language descriptions into is3 and query2 facts using nine predefined spatial relations (e.g., left, right, top-right).Additional guidelines ensure accurate relation mapping, distinguishing between clockwise directions and cardinal references.This systematic approach maintains consistency and aids the models in handling spatial reasoning effectively.</p>
<p>Our pipeline integrates a customized knowledge module adapted from Yang et al. (2023b).This module employs coordinate-based reasoning rules, treating the second queried object as the reference point (0,0).By applying cardinal offsets, the module calculates the relative positions of connected objects, determining their spatial relationships iteratively.This method refines the models' intermediate inferences, enhancing accuracy in multi-hop tasks.</p>
<p>Results</p>
<p>As shown in Table 1, the DSPy pipeline consistently outperforms baseline methods (Direct prompting and Facts+Rules) across all reasoning depths for Deepseek, Llama3, and GPT-4.0 mini models.This demonstrates the effectiveness of integrating linguistic processing with logical reasoning.For examples, at reasoning hop k=5, Deepseek's accuracy jumps from 33.3% (Direct) to 88.5% (+55.2%) using DSPy.Llama3 improves from 28.2% to 77.9% (+49.7%), and GPT-4.0 mini increases from 29.9% to 87.1% (+57.2%).These gains highlight the power of neural-symbolic feedback.Accuracy declines as reasoning depth increases, reflecting task complexity.For example, at k=10, Direct prompting achieves only 16.8% (Deepseek), 14.2% (Llama3), and 13.5% (GPT-4.0mini), while DSPy maintains significantly higher performance: 79.8%, 65.7%, and 68.9%, respectively.</p>
<p>Adding Facts+Rules boosts the overall accuracy to 44.9%, 47.0%, and 47.6%, though it remains limited by sequential dependencies.In contrast, DSPy achieves the highest overall accuracy: 87.7% (Deepseek), 75.6% (Llama3), and 80.8% (GPT-4.0mini).It is obvious that the DSPy pipeline's iterative approach consistently enhances accuracy, particularly for deeper reasoning tasks, validating the benefits of combining symbolic reasoning with neural methods.</p>
<p>Analysis</p>
<p>Due to the controlled complexity and simple language structure, StepGame provides an ideal testbed for evaluating neural-symbolic integration for reasoning, allowing us to isolate the effects of multi-hop reasoning depth from linguistic complexity.There are no co-reference or named entity recognition issues since each agent is clearly defined (eg., "A", "B", "C", "D"), and there is only one question type, querying the relation between two agents.</p>
<p>The success of LLM + ASP can be attributed to several key factors.The simplified predicate structure, utilizing only is/3 and query/2 predicates, provides a clear bridge between natural language and logical forms.This simplification, com-bined with our well-designed knowledge module, enables efficient handling of spatial relationships while maintaining robust error detection capabilities.</p>
<p>Interestingly, the LLM+ASP method functions as a dataset quality checker.Aligning with Yang et al. (2023b), we identify labeling errors in 10% of the instances.Ambiguities in crowdsourced data accumulate with reasoning depth, revealing issues when models output multiple answers.This highlights the potential of neural-symbolic approaches not only for reasoning but also for improving dataset integrity.</p>
<p>SparQA</p>
<p>In order to evaluate the generalizability of our LLM+ASP approach against the more challenging benchmark SparQA, which focuses on complex natural language queries involving spatial relationships and requires precise fact extraction and reasoning over intricate descriptions.We aims to understand both the capabilities and limitations of neural-symbolic integration when confronted with realistic spatial reasoning tasks that more closely approximate real-world complexity.</p>
<p>Implementation</p>
<p>A representative test set of 220 examples, with 55 samples from each question type, was constructed to balance computational constraints and ensure comprehensive coverage.We also deliberately include challenging quantifier questions to assess the system's capabilities.</p>
<p>We adopted the same pipeline as StepGame to SparQA: (1) Converting Natural Language Context and Question to ASP Facts; (2) Adding Rules and Refining ASP Program; (3) Symbolic Reasoning; (4) Result Mapping and Evaluation.The first module prompted LLMs to identify blocks, objects, and relation facts using three predicates: block/1, object/5, and is/3, constraining the specific relation sets to minimize grounding errors.Rule refinement incorporates predefined inverse, transitive, and symmetric rules for spatial relations, enabling reasoning across multi-block environments.These rules were manually designed and updated, enhancing the system's capability to handle complex spatial queries that go beyond simple 2D reasoning tasks.The specific code and samples are seen in Appendix.</p>
<p>Key challenges in the implementation include parsing context-level descriptions for coreference resolution, representing implicit spatial relationships to avoid grounding errors, and managing object references with varying complexity (object/5).Additionally, query generation is difficult due to diverse question structures and complex quantification requirements.Despite careful prompt engineering, LLMs still struggle with generating queries that are different from the provided examples in the prompts.To overcome the challenge, we try to provide question type-wise query examples, quantification encoding query exampels to guide LLMs to write error free query.As shown in Table 2, the neural-symbolic LLM+ASP pipeline showed mixed results across different models and question types.Finding Relation (FR) questions demonstrated significant improvement with accuracy increasing by approximately 20% across all models (from 26.9% to 53.1% on Llama3, 38.2% to 58.9% on Deepseek, and 45.4% to 65.3% on GPT 4.0).Finding Block (FB) questions benefited from structured block/5 predicate representation, showing substantial gains particularly in GPT 4.0 (from 60.9% to 80.5%).Choose Object (CO) questions showed varied results, with GPT-4.0 achieving a notable 15% improvement while other models showed minimal changes.Interestingly, Yes/No (YN) questions does not benefit too much from complexity of neural-symbolic methods, only showing a slight improvement overr with direct prompting across all models.</p>
<p>Results</p>
<p>SparQA include a lot quantifier reasoning question, almost one third questions include "all, only, any".For examples,"Which block has only squares inside?"."What block has all of the black objects inside of it?","Are all of the triangles to the left of the black circle?",Besides that, it also envolves a set, namely, using one attribute to represent the whole set of objects.Thanks to the object/5 atoms, we use use object(<em>,</em>,black,<em>,</em>) in the query to match all the objects with all the black objects.Quantification typically challenges the pure neural approach.I If an LLM were to rely solely on natural language inference, it would need to exhaustively examine all objects with the black color.In contrast, converting the questions into logical expressions using the universal conditional (:) is relatively straightforward.As long as the logical expression is correctly encoded, the reasoning process becomes swift and accurate.</p>
<p>For example, "What block has all the black objects inside of it?"will be represented as: query(Block):block(Block), not object(<em>, </em>, black, _, OtherBlock): block(OtherBlock), OtherBlock != Block.</p>
<p>As shown in the table, the Facts+Rules method achieves competitive and similar performance with the LLM+ASP approach while significantly outperforming direct prompting (more than 5% improvement).While LLM+ASP achieves marginally higher accuracy in some cases, Facts+Rules offers advantages in implementation simplicity and reduced computational overhead.The improvement over baseline might be attributed to two factors: more consistent entity naming conventions in natural language prompts, and explicit instructions to follow the spatial logical rules.</p>
<p>Analysis</p>
<p>The error analysis revealed four primary categories of issues in the neuralsymbolic system: parsing errors (31%), grounding errors (23%), satisfiable but no result issues (28%), and wrong answers (18%).Parsing errors, the most frequent issue, stemmed from syntax-related problems in ASP code generation, including unqualified relation specifications and improper predicate formatting.Grounding errors emerged from inconsistencies between variable naming and knowledge base content, while satisfiability issues arose when the provided facts and rules were insufficient for query resolution, particularly in cases involving implicit spatial relationships that the system failed to capture explicitly in the ASP code.</p>
<p>Each model exhibited distinct error patterns that impacted their performance differently.Deepseek demonstrated strength in handling complex spatial relationships but frequently generated syntax errors (42% of its errors) and struggled with consistent comment handling in ASP code.GPT-4.0 mini showed promising initial code generation capabilities but consistently encountered issues with argument ordering in block/5 predicates, leading to fact-query inconsistencies.Meanwhile, Llama3 maintained consistent cate formatting but showed higher rates of "satifiable but no result" failures, particularly in cases involving complex spatial relationship chains and nested relationships.To address these challenges, the system would benefit from model-specific optimization strategies with tailored prompting approaches and custom validation rules, alongside an enhanced knowledge representation system capable of better handling implicit relationships and ambiguous spatial descriptions.</p>
<p>Impact of Feedback Loop in the DSPy-based Pipeline</p>
<p>While language models demonstrate remarkable capabilities in semantic parsing task, their ability to generate executable logical programs remains challenging.Previous research points out that the direct translation from natural language to logical rules often results in low success rates, even below random baseline performance.(Feng et al., 2024) This observation reinforces the importance of neural-symbolic integration especially the feedback loop between the two components, so that LLMs can benefit from symbolic solvers output, as shown in (Yang et al., 2023b).</p>
<p>To systematically analyze the effectiveness of our iterative feedback mechanism, we examine three primary error types in ASP solver execution: parsing errors (syntax errors, undefined predicates), grounding failures (infinite grounding scenarios, memory constraints), and solving stage failures (overconstrained conditions, inconsistent rules).Additionally, even successfully executed programs might produce solutions that don't align with ground truth labels due to semantic gaps between natural language specifications and logical encodings.Our feedback mechanism addresses these challenges through carefully designed prompts that instruct LLMs on error patterns and their respective fixes.It is hypothesized that the iterative feedback loop would reduce parsing errors and grounding failures.</p>
<p>In the SparQA dataset, which features complex spatial reasoning tasks, our iterative feedback loop demonstrated substantial improvements across all models.As shown in Figure 2, the mechanism shows substantial improvements across all models: Deepseek's execution rate increased from 45.8% to 76.8%, Llama3 from 34.2% to 80.2%, and GPT4mini from 44.8% to 73.2%These results demonstrate that the feedback loop between LLMs and solvers effectively addresses the inherent challenges in natural language to logic translation.The most substantial improvements occur in the first feedback round, with continued but diminishing gains in the second round.While additional feedback rounds might yield further improvements, we limited our experiment to three rounds due to computational costs.These findings demonstrate that the feedback loop significantly enhances both program executability and solution accuracy, establishing the effectiveness of our neural-symbolic integration approach.</p>
<p>Conclusion</p>
<p>This paper presents a neural-symbolic integration approach that significantly enhances LLMs' spatial reasoning capabilities.Our experimental results demonstrate that iterative feedback between LLMs and ASP solvers effectively improves both program executability and accuracy.The pipeline achieves an average 82% accuracy on StepGame and 69% on SparQA, marking substantial improvements over traditional approaches.For instance, our experiments demonstrate significant improvements over the baseline prompt-ing methods, with accuracy increases of 40-50% on StepGame dataset and 8-15% on the more complex SparQA dataset.</p>
<p>The success of neural symbolic integration stems from three key factors: (1) the effective separation of semantic parsing and logical reasoning, enabling precise control over each component; (2) the well-defined spatial relationships in a 2D environment, allowing for unambiguous predicate representation; and (3) the efficient handling of multi-hop reasoning chains through explicit logical rules.</p>
<p>We explored a simplified neural-symbolic approach, Facts+Rules, as an alternative to complex logical programming.This method showed modest improvements of 15-30% over baseline prompting on both datasets and even a comparable perforamce as LLM+ASP pipleine on SparQA.This performance comparison reveals an important trade-off in neural-symbolic integration: LLM+ASP offers superior accuracy at the cost of implementation complexity and computational overhead, while Facts+Rules provides a more lightweight solution with reduced performance on structured tasks.These findings suggest that effective neural-symbolic integration can be achieved through different approaches, each offering distinct advantages in the balance between computational efficiency and reasoning capability.</p>
<p>The key contributions of our work include: (1) a systematic approach to boost spatial reasoning through neural-symbolic integration, (2) a cohesive pipeline that combines the strengths of LLMs and symbolic reasoning, and (3) robust knowledge representation techniques that generalize across different spatial reasoning tasks.Our iterative feedback mechanism particularly demonstrates the value of combining LLMs' natural language understanding with ASP's precise logical inference capabilities.</p>
<p>However, several limitations remain.The performance gap and the variable implementation complexity between StepGame (92%) and SparQA (65%) highlights the challenge of domain sensitivity in neural-symbolic systems.The pipeline struggles particularly with complex queries involving quantifiers and implicit spatial relationships.This study tackles the challenge by careful prompt engineering and providing more examples.Additionally, the conversion from natural language to logical programs remains error-prone, with execution rates varying significantly across different question types.Future work could finetune LLM on specialized logical program dataset and design more sophisticated feedback mechanisms and improved integration between neural and symbolic components.</p>
<p>This work establishes a foundation for enhancing LLMs' reasoning capabilities through neural-symbolic integration, driving forward the quest for more intelligent, interpretable, and efficient systems.In essence, the neuralsymbolic approach treats LLMs as agents within a carefully orchestrated system.This perspective shifts the focus from improving individual LLM performance to optimizing the interplay between different components of the system.Future work should explore optimizing interactions between multiple models and reasoning components, involving more sophisticated orchestration techniques, improved integration of probabilistic reasoning with symbolic solvers, and employing the strengths of different LLMs at various stages of neural-symbolic systems.</p>
<p>Figure 1 :
1
Figure 1: LLM +ASP Pipeline</p>
<p>Figure 2 :
2
Figure 2: Effects of Feedback Loop between LLM and ASP on the SparQA Dataset</p>
<p>Table 1 :
1
Three Methods on StepGame (Accuracy %)
Model &amp; Methodk=1k=2k=3k=4k=5k=6k=7k=8k=9k=10OverallDeepseekDirect53.7 47.4 44.3 34.6 33.3 24.2 22.3 19.5 17.3 16.831.3Facts+Rules61.7 58.2 55.5 48.3 46.2 42.7 38.6 35.2 32.5 30.844.9DSPy Pipeline93.7 89.2 92.5 89.3 88.5 87.7 86.3 85.2 84.5 79.887.7Llama3Direct48.2 49.4 42.5 32.4 28.2 26.3 18.1 17.6 15.8 14.229.3Facts+Rules58.2 56.4 54.5 50.2 48.9 45.4 42.8 40.1 38.3 35.747.0DSPy Pipeline82.2 76.4 79.5 81.2 77.9 80.4 72.8 70.1 69.3 65.775.6GPT-4.0 miniDirect54.6 48.4 47.3 33.2 29.9 27.2 16.3 14.8 13.9 13.529.9Facts+Rules62.8 60.4 58.3 52.3 48.6 45.5 42.2 38.3 35.5 32.947.6DSPy Pipeline85.8 82.4 85.5 85.3 87.1 85.5 79.2 75.3 72.5 68.980.8</p>
<p>Table 2 :
2
Performance Comparison Across Methods on SparQA (Accuracy %)
Model &amp; Method FR FB YN CO OverallDeepseekDirect (Baseline)38.2 74.5 78.2 48.259.8Facts+Rules47.3 80.6 80.9 56.666.4DSPy Pipeline58.9 85.4 81.8 42.867.2Llama3Direct (Baseline)26.9 65.7 72.5 55.855.2Facts+Rules46.8 70.2 81.4 57.163.9DSPy Pipeline53.1 83.3 80.5 60.869.4GPT4.0 miniDirect (Baseline)45.4 60.9 58.2 57.655.5Facts+Rules54.3 68.2 50.4 61.558.6DSPy Pipeline65.3 80.5 64.8 72.770.3</p>
<p>A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. Y Bang, S Cahyawijaya, N Lee, W Dai, D Su, B Wilie, H Lovenia, Z Ji, T Yu, W Chung, Proceedings of the 13th international joint conference on natural language processing and the 3rd conference of the asia-pacific chapter. the 13th international joint conference on natural language processing and the 3rd conference of the asia-pacific chapterthe association for computational linguistics20231Long papers</p>
<p>Neural-symbolic learning and reasoning: A survey and interpretation 1. T R Besold, A Garcez, S Bader, H Bowman, P Domingos, P Hitzler, K.-U Kühnberger, L C Lamb, P M V Lima, L De Penning, Neuro-symbolic artificial intelligence: The state of the art. IOS press2021</p>
<p>Answer set programming at a glance. G Brewka, T Eiter, M Truszczyński, Communications of the ACM. 54122011</p>
<p>A survey of chain of thought reasoning: Advances, frontiers and future. Z Chu, J Chen, Q Chen, W Yu, T He, H Wang, W Peng, M Liu, B Qin, T Liu, ArXiv, abs/2309.154022023</p>
<p>An evaluation of ChatGPT-4's qualitative spatial reasoning capabilities in RCC-8. A G Cohn, arXiv:2309.155772023arXiv preprint</p>
<p>A neuro-symbolic ASP pipeline for visual question answering. T Eiter, N Higuera, J Oetsch, M Pritz, Theory and Practice of Logic Programming. 2252022Cambridge University Press</p>
<p>Large language models are neurosymbolic reasoners. M Fang, S Deng, Y Zhang, Z Shi, L Chen, M Pechenizkiy, J Wang, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence20243816</p>
<p>Language models can be deductive solvers. J Feng, R Xu, J Hao, H Sharma, Y Shen, D Zhao, W Chen, Findings of the Association for Computational Linguistics: NAACL 2024. 2024</p>
<p>PAL: Program-aided language models. L Gao, A Madaan, S Zhou, U Alon, P Liu, Y Yang, J Callan, G Neubig, ArXiv, abs/2211.104352022</p>
<p>Neurosymbolic AI: The 3 rd wave. A D Garcez, L C Lamb, Artificial Intelligence Review. 56112023Springer</p>
<p>Explainable answer-set programming. T Geibinger, arXiv:2308.159012023arXiv preprint</p>
<p>Is neuro-symbolic ai meeting its promises in natural language processing? a structured review. Semantic Web. K Hamilton, A Nayak, B Božić, L Longo, 2022Publisher: IOS PressPreprint</p>
<p>Leveraging large language models to generate answer set programs. A Ishay, Z Yang, J Lee, arXiv:2307.076992023arXiv preprint</p>
<p>Dspy: Compiling declarative language model calls into selfimproving pipelines. O Khattab, A Singhvi, P Maheshwari, Z Zhang, K Santhanam, S Vardhamanan, S Haq, A Sharma, T T Joshi, H Moazam, Others, arXiv:2310.037142023arXiv preprint</p>
<p>Transfer learning with synthetic corpora for spatial role labeling and reasoning. R Mirzaee, P Kordjamshidi, arXiv:2210.169522022arXiv preprint</p>
<p>Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning. L Pan, A Albalak, X Wang, W Y Wang, arXiv:2305.122952023arXiv preprint</p>
<p>A Parisi, Y Zhao, N Fiedel, arXiv:2205.12255Talm: Tool augmented language models. 2022arXiv preprint</p>
<p>R Riegel, A Gray, F Luus, N Khan, N Makondo, I Y Akhalwaya, H Qian, R Fagin, F Barahona, U Sharma, arXiv:2006.13155Logical neural networks. 2020arXiv preprint</p>
<p>True few-shot learning with prompts-a real-world perspective. T Schick, H Schütze, Transactions of the Association for Computational Linguistics. 102021</p>
<p>Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts. Z Shi, Q Zhang, A Lipani, ber: 10Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202236</p>
<p>Z Wan, C.-K Liu, H Yang, C Li, H You, Y Fu, C Wan, T Krishna, Y Lin, A Raychowdhury, arXiv:2401.01040Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI. 2024</p>
<p>Review of large vision models and visual prompt engineering. J Wang, Z Liu, L Zhao, Z Wu, C Ma, S Yu, H Dai, Q Yang, Y.-H Liu, S Zhang, E Shi, Y Pan, T Zhang, D Zhu, X Li, X Jiang, B Ge, Y Yuan, D Shen, T Liu, S Zhang, ArXiv, abs/2307.008552023</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, D Zhou, ArXiv, abs/2203.111712022</p>
<p>Nlprolog: Reasoning with weak unification for question answering in natural language. L Weber, P Minervini, J Münchmeyer, U Leser, T Rocktäschel, arXiv:1906.061872019arXiv preprint</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, F Xia, Q Le, D Zhou, ArXiv, abs/2201.119032022</p>
<p>Coupling large language models with logic programming for robust and general reasoning from text. Z Yang, A Ishay, J Lee, arXiv:2307.076962023aarXiv preprint</p>
<p>Z Yang, A Ishay, J Lee, arXiv:2307.07700Neurasp: Embracing neural networks into answer set programming. 2023barXiv preprint</p>
<p>Least-to-most prompting enables complex reasoning in large language models. D Zhou, N Scharli, L Hou, J Wei, N Scales, X Wang, D Schuurmans, O Bousquet, Q Le, Chi , E , ArXiv, abs/2205.106252022</p>            </div>
        </div>

    </div>
</body>
</html>