<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5106 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5106</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5106</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-107.html">extraction-schema-107</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886" target="_blank">Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> A diagnostic method for first-order logic (FOL) reasoning with a new proposed benchmark, LogicNLI, which effectively disentangles the target FOL reasoning from commonsense inference and can be used to diagnose LMs from four perspectives: accuracy, robustness, generalization, and interpretability.</p>
                <p><strong>Paper Abstract:</strong> Recently, language models (LMs) have achieved significant performance on many NLU tasks, which has spurred widespread interest for their possible applications in the scientific and social area. However, LMs have faced much criticism of whether they are truly capable of reasoning in NLU. In this work, we propose a diagnostic method for first-order logic (FOL) reasoning with a new proposed benchmark, LogicNLI. LogicNLI is an NLI-style dataset that effectively disentangles the target FOL reasoning from commonsense inference and can be used to diagnose LMs from four perspectives: accuracy, robustness, generalization, and interpretability. Experiments on BERT, RoBERTa, and XLNet, have uncovered the weaknesses of these LMs on FOL reasoning, which motivates future exploration to enhance the reasoning ability.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5106.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5106.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT (Bidirectional Encoder Representations from Transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer-based bidirectional pre-trained language model; in this paper the large variant (hidden size 1024) is fine-tuned on the LogicNLI benchmark with a two-layer perceptron classification head to evaluate first-order logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (large, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer encoder (bidirectional) pretrained (Devlin et al. style); in experiments the large variant with hidden size 1024 is fine-tuned on LogicNLI using ADAMW, a two-layer MLP classifier, input formatted as "[CLS] facts rules [SEP] statement [SEP]".</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LogicNLI (Logical Natural Language Inference) and d-LogicNLI (degraded variant)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>An NLI-style benchmark constructed to diagnose first-order logic (FOL) reasoning; covers seven FOL operators (conjunction, disjunction, negation, implication, equivalence, universal and existential quantifiers), includes labels Entailment/Contradiction/Neutral/Paradox, provides proofs and multi-hop reasoning instances, and contains specialized test splits for accuracy (Test-A), robustness to irrelevant info (Test-R), more-hop generalization (Test-G), and proof-based traceability (Test-T).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning the pretrained BERT large model on LogicNLI datasets (no architectural changes), using a two-layer perceptron classifier on top of the pooled representation; evaluation across in-domain and out-of-domain (more hops) splits and traceability by comparing predicted proofs to ground-truth proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On LogicNLI: Dev accuracy 57.0%, Test-A 55.9%; Robustness Dev-R 68.0%, Test-R 66.0%; More-hop generalization (Test-G avg) 31.6%; Traceability Test-T: P-EM (exact match of full proofs) 9.3%, P-Acc (proof-level accuracy) 61.1%. Per-FOL performance (LogicNLI single-FOL sets): conjunction 58.9%, disjunction 65.8%, negation 62.8%, implication 68.2%, equivalence 64.9%, universal 66.8%, existential 76.9%. On d-LogicNLI (no Paradox): higher P-Acc 73.1%, lower P-EM 1.1%; robustness degradation rate delta_R ≈ 24.6%, generalization degradation delta_{A->G} ≈ 43.5%. Human baseline on LogicNLI Test-A ≈ 77.5%, random 25.0%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fails to generalize to out-of-domain more-hop (>5) reasoning (large drop to ~31.6%); low proof-traceability (very small P-EM ~9.3%) meaning many correct predictions are not supported by correct proof chains; sensitive to irrelevant/noisy facts (robustness degradation ~24.6% between 10 and 24 sentences); specific weakness on negation and universal quantifier reasoning and when multiple FOLs are coupled.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Per paper comparisons place BERT as the weakest of the three evaluated LMs (BERT vs RoBERTa vs XLNet): RoBERTa > XLNet > BERT on most LogicNLI metrics; BERT performs substantially below human performance (~20 points lower on Test-A). On d-LogicNLI BERT's in-domain P-Acc improves but traceability remains poor (P-EM low).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Paper reports analyses rather than classical ablations: comparison between LogicNLI and d-LogicNLI shows models trained on the full LogicNLI (with Paradox) obtain better traceability and better generalization than on d-LogicNLI; per-FOL evaluations indicate BERT has relatively higher performance on existential queries and lower on negation and universal quantifiers; robustness curves with increasing numbers of irrelevant sentences show steady performance drop (fitting used to compute degradation rate).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5106.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5106.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa (Robustly Optimized BERT Pretraining Approach)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer-based pretrained LM that improves on BERT via robust pretraining (larger corpus/training); in this paper the large variant (hidden size 1024) is fine-tuned and shows the strongest first-order logical reasoning performance among tested LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (large, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer encoder pretrained with RoBERTa recipe (larger corpora / training improvements); large variant with hidden size 1024 fine-tuned on LogicNLI using ADAMW and a two-layer MLP classifier; input formatted "[CLS] facts rules [SEP] statement [SEP]".</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LogicNLI (Logical Natural Language Inference) and comparisons with d-LogicNLI</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same as above: NLI-style diagnostic benchmark for first-order logic reasoning covering seven FOLs, specialized splits for accuracy, robustness, generalization, and traceability; includes proofs and a Paradox label to force multi-path reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning RoBERTa large on LogicNLI with a two-layer MLP classification head; evaluation includes verification of predicted proof chains (proof-based traceability). No architectural modifications or external symbolic components were used in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On LogicNLI: Dev accuracy 65.0%, Test-A 68.3%; Robustness Dev-R 80.9%, Test-R 80.4%; More-hop generalization (Test-G avg) 49.9%; Traceability Test-T: P-EM 53.1% (instances with fully correct proof chains), P-Acc 87.6% (proof-level accuracy). Per-FOL single-set performance: conjunction 82.1%, disjunction 94.7%, negation 68.5%, implication 87.1%, equivalence 84.4%, universal 80.5%, existential 99.3%. Robustness degradation delta_R ≈ 25.2% (10→24 sentences); generalization degradation delta_{A->G} ≈ 26.9%. Human baseline on Test-A ≈ 77.5%.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Although best among tested LMs, RoBERTa still fails to fully match human reasoning: Test-A gap to humans (~9 percentage points); P-EM ~53.1% meaning nearly half of predictions lack complete human-style proof chains; susceptible to irrelevant information (robustness degradation similar to BERT) and still shows drop when transferring from in-domain to out-of-domain albeit smaller than other models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>RoBERTa outperforms XLNet and BERT on most LogicNLI metrics (accuracy, generalization and traceability); RoBERTa shows the smallest generalization degradation when moving to more-hop instances. On d-LogicNLI (no Paradox), RoBERTa achieves higher in-domain numbers (P-Acc 80.7%) but lower traceability P-EM (~0.9%) than when trained on full LogicNLI, demonstrating that including Paradox examples improves the model's ability to learn traceable reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Analyses include per-FOL breakdowns showing strong performance on existential and disjunctional cases and relative weakness on negation and universal quantification; comparison between d-LogicNLI and LogicNLI highlights that training with Paradox yields better traceability and generalization; robustness curves and computed degradation rates (delta_R) quantify sensitivity to irrelevant facts; traceability metrics (P-EM and P-Acc) introduced to evaluate proof-level explanations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5106.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5106.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>XLNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>XLNet (Generalized Autoregressive Pretraining for Language Understanding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer-based autoregressive pretraining model (XLNet) evaluated in its large variant (hidden size 1024) fine-tuned on LogicNLI to test FOL reasoning; shows intermediate performance between RoBERTa and BERT on many metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>XLNet (large, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generalized autoregressive Transformer pretrained with permutation language modeling (XLNet); large variant (hidden size 1024) fine-tuned on LogicNLI with a two-layer MLP classifier; input formatted "facts rules [SEP] statement [SEP] [CLS]" per XLNet convention.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>LogicNLI (Logical Natural Language Inference) and d-LogicNLI</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>NLI-style benchmark for diagnosing first-order logic reasoning with seven FOLs, multi-hop proofs, Paradox label, and test splits for accuracy, robustness, generalization and traceability.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning XLNet large on LogicNLI using ADAMW and two-layer classifier; no other algorithmic or architectural modifications applied in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On LogicNLI: Dev accuracy 64.0%, Test-A 65.4%; Robustness Dev-R 77.0%, Test-R 78.9%; More-hop generalization (Test-G avg) 43.0%; Traceability Test-T: P-EM 28.6%, P-Acc 77.0%. Per-FOL performance: conjunction 78.0%, disjunction 90.6%, negation 66.2%, implication 81.2%, equivalence 80.1%, universal 75.0%, existential 98.3%. Robustness degradation delta_R ≈ 21.5%; generalization degradation delta_{A->G} ≈ 34.3%. On d-LogicNLI P-Acc higher (85.7%) but P-EM lower (4.1%).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance drops substantially when transferring to more-hop out-of-domain instances; proof-traceability (P-EM 28.6%) is better than BERT but worse than RoBERTa; sensitive to increasing irrelevant facts (robustness degradation ~21.5%), with relatively rapid drop after a noise threshold; same systematic weaknesses on negation and universal quantifiers as other LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>XLNet generally outperforms BERT but is outperformed by RoBERTa on overall accuracy, generalization, and traceability in LogicNLI; on d-LogicNLI XLNet attains the highest in-domain P-Acc (85.7%) among the three, suggesting differences in pretraining/architecture affect behavior depending on dataset complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Paper-level analyses: comparison of results on LogicNLI vs d-LogicNLI demonstrates that excluding Paradox reduces traceability and harms generalization; per-FOL breakdowns show XLNet performs strongly on existential and disjunctional cases but worse on negation/universal; robustness curves show non-linear degradation with increasing irrelevant sentences and delta_R computed by fitting.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5106.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5106.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated or improved for strict logical reasoning, including details of the models, logical reasoning tasks or benchmarks, methods or approaches used, performance results, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogicNLI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logical Natural Language Inference (LogicNLI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark dataset introduced in this paper to diagnose first-order logical (FOL) reasoning of language models; semi-automatically generated NLI-style instances that disentangle logical reasoning from commonsense and include multi-hop proofs and a Paradox label.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dataset constructed via automated logic-expression generation (templates over subjects and predicates) + rule-based natural language realization with manual revision; provides facts, rules, statements, human-constructed proofs, and labels (Entailment/Contradiction/Neutral/Paradox); contains ~16K training, 2K dev, 2K in-domain Test-A plus large robustness (Test-R), generalization (Test-G) and traceability (Test-T) splits.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>logical_reasoning_task</strong></td>
                            <td>First-order logical reasoning diagnosis (NLI-style) covering seven fundamental FOL operators and their combinations</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>LogicNLI requires models to determine the logical relation between a premise (facts and rules) and a statement under open world assumption; designed tests assess accuracy, robustness to irrelevant information, generalization to more-hop reasoning, and proof-based traceability; includes Paradox label for instances where both s and ¬s are entailed along different paths.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Semi-automatic generation pipeline: (1) logic generation from templates with controlled FOL combinations and subjects/predicates, ensuring validity of FOL expressions; (2) natural language generation via rule-based rendering plus manual correction for fluency/diversity; dataset splits created to probe robustness (varying number of irrelevant sentences), generalization (k-hop training / >k-hop testing), and traceability (Test-T contains 6-hop instances with proofs).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Baseline model performances reported: RoBERTa best (Dev 65.0%, Test-A 68.3%), XLNet middle (Dev 64.0%, Test-A 65.4%), BERT weakest (Dev 57.0%, Test-A 55.9%); humans on a sampled set ≈ 77.5%; per-FOL single-set results show strong model performance on existential/disjunction but weaker on negation/universal; proof-traceability P-EM reveals only RoBERTa can fully validate ~53.1% of predicted instances' proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Dataset intentionally simplifies some aspects (only cause→effect reasoning; neglects predicate real-world meaning) so it does not capture all aspects of real-world reasoning; Paradox label is uncommon in natural text (artificial), though included to reduce spurious correlations; open-world assumption and removal of domain predicates reduce realism; dataset may not evaluate predicate semantics or deep commonsense reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison</strong></td>
                            <td>Table compares LogicNLI to related FOL datasets: LogicNLI covers 7 FOLs and provides proofs and natural language, unlike some prior datasets (LogiQA, ReClor include domain knowledge; CLUTRR focuses on predicate relations; LTL is propositional and not natural language; SoftReasoner covers fewer FOL combinations). The paper shows that models trained on LogicNLI generalize better and achieve higher traceability than when trained on d-LogicNLI (degraded variant without Paradox).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis_results</strong></td>
                            <td>Key analyses include: (1) per-FOL performance breakdown showing systematic weaknesses (negation, universal); (2) robustness curves and computed degradation rates delta_R across models; (3) generalization degradation delta_{A->G} when moving from ≤5-hop training to 6–10 hop testing; (4) comparison between LogicNLI and d-LogicNLI demonstrating the positive role of Paradox examples in improving traceability and generalization; (5) proof-based metrics introduced (P-Acc and P-EM) to quantify traceability.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transformers as soft reasoners over language <em>(Rating: 2)</em></li>
                <li>CLUTRR: A diagnostic benchmark for inductive reasoning from text <em>(Rating: 2)</em></li>
                <li>Teaching temporal logics to neural networks <em>(Rating: 2)</em></li>
                <li>Measuring systematic generalization in neural proof generation with transformers <em>(Rating: 2)</em></li>
                <li>Logiqa: A challenge dataset for machine reading comprehension with logical reasoning <em>(Rating: 2)</em></li>
                <li>Reclor: A reading comprehension dataset requiring logical reasoning <em>(Rating: 2)</em></li>
                <li>SoftReasoner (Transformers as soft reasoners over language) -- Clark et al. series <em>(Rating: 1)</em></li>
                <li>Hy-nli: a hybrid system for natural language inference <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5106",
    "paper_id": "paper-61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886",
    "extraction_schema_id": "extraction-schema-107",
    "extracted_data": [
        {
            "name_short": "BERT",
            "name_full": "BERT (Bidirectional Encoder Representations from Transformers)",
            "brief_description": "A Transformer-based bidirectional pre-trained language model; in this paper the large variant (hidden size 1024) is fine-tuned on the LogicNLI benchmark with a two-layer perceptron classification head to evaluate first-order logical reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (large, fine-tuned)",
            "model_description": "Transformer encoder (bidirectional) pretrained (Devlin et al. style); in experiments the large variant with hidden size 1024 is fine-tuned on LogicNLI using ADAMW, a two-layer MLP classifier, input formatted as \"[CLS] facts rules [SEP] statement [SEP]\".",
            "model_size": null,
            "logical_reasoning_task": "LogicNLI (Logical Natural Language Inference) and d-LogicNLI (degraded variant)",
            "task_description": "An NLI-style benchmark constructed to diagnose first-order logic (FOL) reasoning; covers seven FOL operators (conjunction, disjunction, negation, implication, equivalence, universal and existential quantifiers), includes labels Entailment/Contradiction/Neutral/Paradox, provides proofs and multi-hop reasoning instances, and contains specialized test splits for accuracy (Test-A), robustness to irrelevant info (Test-R), more-hop generalization (Test-G), and proof-based traceability (Test-T).",
            "method_or_approach": "Fine-tuning the pretrained BERT large model on LogicNLI datasets (no architectural changes), using a two-layer perceptron classifier on top of the pooled representation; evaluation across in-domain and out-of-domain (more hops) splits and traceability by comparing predicted proofs to ground-truth proofs.",
            "performance": "On LogicNLI: Dev accuracy 57.0%, Test-A 55.9%; Robustness Dev-R 68.0%, Test-R 66.0%; More-hop generalization (Test-G avg) 31.6%; Traceability Test-T: P-EM (exact match of full proofs) 9.3%, P-Acc (proof-level accuracy) 61.1%. Per-FOL performance (LogicNLI single-FOL sets): conjunction 58.9%, disjunction 65.8%, negation 62.8%, implication 68.2%, equivalence 64.9%, universal 66.8%, existential 76.9%. On d-LogicNLI (no Paradox): higher P-Acc 73.1%, lower P-EM 1.1%; robustness degradation rate delta_R ≈ 24.6%, generalization degradation delta_{A-&gt;G} ≈ 43.5%. Human baseline on LogicNLI Test-A ≈ 77.5%, random 25.0%.",
            "limitations_or_failure_cases": "Fails to generalize to out-of-domain more-hop (&gt;5) reasoning (large drop to ~31.6%); low proof-traceability (very small P-EM ~9.3%) meaning many correct predictions are not supported by correct proof chains; sensitive to irrelevant/noisy facts (robustness degradation ~24.6% between 10 and 24 sentences); specific weakness on negation and universal quantifier reasoning and when multiple FOLs are coupled.",
            "comparison": "Per paper comparisons place BERT as the weakest of the three evaluated LMs (BERT vs RoBERTa vs XLNet): RoBERTa &gt; XLNet &gt; BERT on most LogicNLI metrics; BERT performs substantially below human performance (~20 points lower on Test-A). On d-LogicNLI BERT's in-domain P-Acc improves but traceability remains poor (P-EM low).",
            "ablation_or_analysis_results": "Paper reports analyses rather than classical ablations: comparison between LogicNLI and d-LogicNLI shows models trained on the full LogicNLI (with Paradox) obtain better traceability and better generalization than on d-LogicNLI; per-FOL evaluations indicate BERT has relatively higher performance on existential queries and lower on negation and universal quantifiers; robustness curves with increasing numbers of irrelevant sentences show steady performance drop (fitting used to compute degradation rate).",
            "uuid": "e5106.0"
        },
        {
            "name_short": "RoBERTa",
            "name_full": "RoBERTa (Robustly Optimized BERT Pretraining Approach)",
            "brief_description": "A Transformer-based pretrained LM that improves on BERT via robust pretraining (larger corpus/training); in this paper the large variant (hidden size 1024) is fine-tuned and shows the strongest first-order logical reasoning performance among tested LMs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RoBERTa (large, fine-tuned)",
            "model_description": "Transformer encoder pretrained with RoBERTa recipe (larger corpora / training improvements); large variant with hidden size 1024 fine-tuned on LogicNLI using ADAMW and a two-layer MLP classifier; input formatted \"[CLS] facts rules [SEP] statement [SEP]\".",
            "model_size": null,
            "logical_reasoning_task": "LogicNLI (Logical Natural Language Inference) and comparisons with d-LogicNLI",
            "task_description": "Same as above: NLI-style diagnostic benchmark for first-order logic reasoning covering seven FOLs, specialized splits for accuracy, robustness, generalization, and traceability; includes proofs and a Paradox label to force multi-path reasoning.",
            "method_or_approach": "Fine-tuning RoBERTa large on LogicNLI with a two-layer MLP classification head; evaluation includes verification of predicted proof chains (proof-based traceability). No architectural modifications or external symbolic components were used in this paper.",
            "performance": "On LogicNLI: Dev accuracy 65.0%, Test-A 68.3%; Robustness Dev-R 80.9%, Test-R 80.4%; More-hop generalization (Test-G avg) 49.9%; Traceability Test-T: P-EM 53.1% (instances with fully correct proof chains), P-Acc 87.6% (proof-level accuracy). Per-FOL single-set performance: conjunction 82.1%, disjunction 94.7%, negation 68.5%, implication 87.1%, equivalence 84.4%, universal 80.5%, existential 99.3%. Robustness degradation delta_R ≈ 25.2% (10→24 sentences); generalization degradation delta_{A-&gt;G} ≈ 26.9%. Human baseline on Test-A ≈ 77.5%.",
            "limitations_or_failure_cases": "Although best among tested LMs, RoBERTa still fails to fully match human reasoning: Test-A gap to humans (~9 percentage points); P-EM ~53.1% meaning nearly half of predictions lack complete human-style proof chains; susceptible to irrelevant information (robustness degradation similar to BERT) and still shows drop when transferring from in-domain to out-of-domain albeit smaller than other models.",
            "comparison": "RoBERTa outperforms XLNet and BERT on most LogicNLI metrics (accuracy, generalization and traceability); RoBERTa shows the smallest generalization degradation when moving to more-hop instances. On d-LogicNLI (no Paradox), RoBERTa achieves higher in-domain numbers (P-Acc 80.7%) but lower traceability P-EM (~0.9%) than when trained on full LogicNLI, demonstrating that including Paradox examples improves the model's ability to learn traceable reasoning.",
            "ablation_or_analysis_results": "Analyses include per-FOL breakdowns showing strong performance on existential and disjunctional cases and relative weakness on negation and universal quantification; comparison between d-LogicNLI and LogicNLI highlights that training with Paradox yields better traceability and generalization; robustness curves and computed degradation rates (delta_R) quantify sensitivity to irrelevant facts; traceability metrics (P-EM and P-Acc) introduced to evaluate proof-level explanations.",
            "uuid": "e5106.1"
        },
        {
            "name_short": "XLNet",
            "name_full": "XLNet (Generalized Autoregressive Pretraining for Language Understanding)",
            "brief_description": "A Transformer-based autoregressive pretraining model (XLNet) evaluated in its large variant (hidden size 1024) fine-tuned on LogicNLI to test FOL reasoning; shows intermediate performance between RoBERTa and BERT on many metrics.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "XLNet (large, fine-tuned)",
            "model_description": "Generalized autoregressive Transformer pretrained with permutation language modeling (XLNet); large variant (hidden size 1024) fine-tuned on LogicNLI with a two-layer MLP classifier; input formatted \"facts rules [SEP] statement [SEP] [CLS]\" per XLNet convention.",
            "model_size": null,
            "logical_reasoning_task": "LogicNLI (Logical Natural Language Inference) and d-LogicNLI",
            "task_description": "NLI-style benchmark for diagnosing first-order logic reasoning with seven FOLs, multi-hop proofs, Paradox label, and test splits for accuracy, robustness, generalization and traceability.",
            "method_or_approach": "Fine-tuning XLNet large on LogicNLI using ADAMW and two-layer classifier; no other algorithmic or architectural modifications applied in this study.",
            "performance": "On LogicNLI: Dev accuracy 64.0%, Test-A 65.4%; Robustness Dev-R 77.0%, Test-R 78.9%; More-hop generalization (Test-G avg) 43.0%; Traceability Test-T: P-EM 28.6%, P-Acc 77.0%. Per-FOL performance: conjunction 78.0%, disjunction 90.6%, negation 66.2%, implication 81.2%, equivalence 80.1%, universal 75.0%, existential 98.3%. Robustness degradation delta_R ≈ 21.5%; generalization degradation delta_{A-&gt;G} ≈ 34.3%. On d-LogicNLI P-Acc higher (85.7%) but P-EM lower (4.1%).",
            "limitations_or_failure_cases": "Performance drops substantially when transferring to more-hop out-of-domain instances; proof-traceability (P-EM 28.6%) is better than BERT but worse than RoBERTa; sensitive to increasing irrelevant facts (robustness degradation ~21.5%), with relatively rapid drop after a noise threshold; same systematic weaknesses on negation and universal quantifiers as other LMs.",
            "comparison": "XLNet generally outperforms BERT but is outperformed by RoBERTa on overall accuracy, generalization, and traceability in LogicNLI; on d-LogicNLI XLNet attains the highest in-domain P-Acc (85.7%) among the three, suggesting differences in pretraining/architecture affect behavior depending on dataset complexity.",
            "ablation_or_analysis_results": "Paper-level analyses: comparison of results on LogicNLI vs d-LogicNLI demonstrates that excluding Paradox reduces traceability and harms generalization; per-FOL breakdowns show XLNet performs strongly on existential and disjunctional cases but worse on negation/universal; robustness curves show non-linear degradation with increasing irrelevant sentences and delta_R computed by fitting.",
            "uuid": "e5106.2"
        },
        {
            "name_short": "LogicNLI",
            "name_full": "Logical Natural Language Inference (LogicNLI)",
            "brief_description": "A benchmark dataset introduced in this paper to diagnose first-order logical (FOL) reasoning of language models; semi-automatically generated NLI-style instances that disentangle logical reasoning from commonsense and include multi-hop proofs and a Paradox label.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": "Dataset constructed via automated logic-expression generation (templates over subjects and predicates) + rule-based natural language realization with manual revision; provides facts, rules, statements, human-constructed proofs, and labels (Entailment/Contradiction/Neutral/Paradox); contains ~16K training, 2K dev, 2K in-domain Test-A plus large robustness (Test-R), generalization (Test-G) and traceability (Test-T) splits.",
            "model_size": null,
            "logical_reasoning_task": "First-order logical reasoning diagnosis (NLI-style) covering seven fundamental FOL operators and their combinations",
            "task_description": "LogicNLI requires models to determine the logical relation between a premise (facts and rules) and a statement under open world assumption; designed tests assess accuracy, robustness to irrelevant information, generalization to more-hop reasoning, and proof-based traceability; includes Paradox label for instances where both s and ¬s are entailed along different paths.",
            "method_or_approach": "Semi-automatic generation pipeline: (1) logic generation from templates with controlled FOL combinations and subjects/predicates, ensuring validity of FOL expressions; (2) natural language generation via rule-based rendering plus manual correction for fluency/diversity; dataset splits created to probe robustness (varying number of irrelevant sentences), generalization (k-hop training / &gt;k-hop testing), and traceability (Test-T contains 6-hop instances with proofs).",
            "performance": "Baseline model performances reported: RoBERTa best (Dev 65.0%, Test-A 68.3%), XLNet middle (Dev 64.0%, Test-A 65.4%), BERT weakest (Dev 57.0%, Test-A 55.9%); humans on a sampled set ≈ 77.5%; per-FOL single-set results show strong model performance on existential/disjunction but weaker on negation/universal; proof-traceability P-EM reveals only RoBERTa can fully validate ~53.1% of predicted instances' proofs.",
            "limitations_or_failure_cases": "Dataset intentionally simplifies some aspects (only cause→effect reasoning; neglects predicate real-world meaning) so it does not capture all aspects of real-world reasoning; Paradox label is uncommon in natural text (artificial), though included to reduce spurious correlations; open-world assumption and removal of domain predicates reduce realism; dataset may not evaluate predicate semantics or deep commonsense reasoning.",
            "comparison": "Table compares LogicNLI to related FOL datasets: LogicNLI covers 7 FOLs and provides proofs and natural language, unlike some prior datasets (LogiQA, ReClor include domain knowledge; CLUTRR focuses on predicate relations; LTL is propositional and not natural language; SoftReasoner covers fewer FOL combinations). The paper shows that models trained on LogicNLI generalize better and achieve higher traceability than when trained on d-LogicNLI (degraded variant without Paradox).",
            "ablation_or_analysis_results": "Key analyses include: (1) per-FOL performance breakdown showing systematic weaknesses (negation, universal); (2) robustness curves and computed degradation rates delta_R across models; (3) generalization degradation delta_{A-&gt;G} when moving from ≤5-hop training to 6–10 hop testing; (4) comparison between LogicNLI and d-LogicNLI demonstrating the positive role of Paradox examples in improving traceability and generalization; (5) proof-based metrics introduced (P-Acc and P-EM) to quantify traceability.",
            "uuid": "e5106.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 2
        },
        {
            "paper_title": "CLUTRR: A diagnostic benchmark for inductive reasoning from text",
            "rating": 2
        },
        {
            "paper_title": "Teaching temporal logics to neural networks",
            "rating": 2
        },
        {
            "paper_title": "Measuring systematic generalization in neural proof generation with transformers",
            "rating": 2
        },
        {
            "paper_title": "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "Reclor: A reading comprehension dataset requiring logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "SoftReasoner (Transformers as soft reasoners over language) -- Clark et al. series",
            "rating": 1
        },
        {
            "paper_title": "Hy-nli: a hybrid system for natural language inference",
            "rating": 1
        }
    ],
    "cost": 0.014773749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI</h1>
<p>Jidong Tian ${ }^{1,2 \dagger}$, Yitian $\mathbf{L i}^{1,2 \dagger}$, Wenqing Chen ${ }^{1,2}$, Liqiang Xiao ${ }^{1,2}$, Hao $\mathbf{H e}^{1,2 \ddagger}$ and Yaohui Jin ${ }^{1,2}$<br>${ }^{1}$ MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University<br>${ }^{2}$ State Key Lab of Advanced Optical Communication System and Network, Shanghai Jiao Tong University<br>{frank92, yitian_li, wenqingchen,<br>xiaoliqiang, hehao, jinyh}@sjtu.edu.cn</p>
<h4>Abstract</h4>
<p>Recently, language models (LMs) have achieved significant performance on many NLU tasks, which has spurred widespread interest for their possible applications in the scientific and social area. However, LMs have faced much criticism of whether they are truly capable of reasoning in NLU. In this work, we propose a diagnostic method for first-order logic (FOL) reasoning with a new proposed benchmark, LogicNLI. LogicNLI is an NLI-style dataset that effectively disentangles the target FOL reasoning from commonsense inference and can be used to diagnose LMs from four perspectives: accuracy, robustness, generalization, and traceability. Experiments on BERT, RoBERTa, and XLNet, have uncovered the weaknesses of these LMs on FOL reasoning, which motivates future exploration to enhance the reasoning ability.</p>
<h2>1 Introduction</h2>
<p>Recently, Transformers-based (Vaswani et al., 2017) language models (LMs), such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), have achieved great success on natural language understanding (NLU). However, there are growing concerns about whether LMs can truly understand natural language or not. Tasks with complex reasoning have provided evidence that LMs lack expected reasoning abilities (Liu et al., 2020; Bhagavatula et al., 2020). Even if neural models can make correct predictions, they tend to make decisions through spurious statistical correlations rather than reasoning abilities (Kaushik and Lipton, 2018; Ribeiro et al., 2019; Jiang and Bansal, 2019; McCoy et al., 2019). Therefore, an increasing number of studies have focused on diagnosing specific reasoning abilities of state-of-the-art LMs (Sugawara et al., 2020; Gontier et al., 2020).</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>First-order logical (FOL) reasoning is one of the most widely used reasoning forms in natural language (Davis, 2017; Yu et al., 2020), which has a simple paradigm consisting of combinations of seven fundamental logics (FOLs, including conjunction $\wedge$, disjunction $\vee$, negation $\neg$, implication $\rightarrow$, equation $\equiv$, universal quantifier $\forall$, and existential quantifier $\exists$ ) with simple propositions (Davis, 2017). Nevertheless, whether LMs can truly make FOL reasoning is still inconclusive in NLP (Hahn et al., 2021; Clark et al., 2020).</p>
<p>As a result, we propose a systematic diagnostic method for FOL reasoning by proposing a novel benchmark, named Logical Natural Language Inference (LogicNLI). The proposed benchmark follows three principles: 1) It includes abundant logical expressions covering all seven FOLs and their commonly used combinations in texts; 2) The instances of the benchmark conform to natural language; 3) It introduces as little commonsense as possible to prevent the targeting FOL reasoning and commonsense inference from being entangled with each other (Clark et al., 2020). According to the principles, LogicNLI is an NLI-style dataset (Bowman et al., 2015; Talmor et al., 2020), including triplets of facts, rules, and a statement. The objective is to determine the logical relation (entailment, contradiction, or neutral in NLI (Bowman et al., 2015)) between the premise (facts and rules) and its corresponding hypothesis (statement) by FOL reasoning shown in Figure 1. In practice, we have introduced an additional logical relation, "Paradox", to represent the situation where the hypothesis and its negative proposition can be logically entailed to the premise simultaneously based on different reasoning paths (bottom of Figure 1). This novel logical relation forces the model to search at least two reasoning paths to infer the authenticity of two opposing propositions, thereby effectively avoiding spurious correlations caused by dataset bias.</p>
<p>Based on LogicNLI, we propose a systematic</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Reasoning processes in LogicNLI. Given a set of facts (Blue) and rules (Orange), The first step is to translate the language expressions into the FOL expressions. Based on expressions, logical reasoning is made step by step, where proofs (Grey) are the intermediate results of each step. Finally, the proposed statements (Green) are judged based on multi-step reasoning. Besides, LogicNLI provides a new condition of "PARADOX" that both the positive and negative propositions can be inferred simultaneously (shown in the dotted frame).
diagnostic approach by comprehensively considering four perspectives: accuracy, robustness to irrelevant information, more-hop generalization, and proof-based traceability. We perform diagnosis on three state-of-the-art LMs, BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019). Results reveal that LMs can neither fully understand the logical rules nor apply them to reason like humans. In conclusion, our main contributions include: 1) We design a novel benchmark, LogicNLI, following three basic principles to diagnose LMs' FOL reasoning ability. This method of benchmark construction is general for different reasoning types in NLU. 2) Based on LogicNLI, we design a diagnostic approach composed of accuracy, robustness, generalization, and traceability, which measures LMs' FOL reasoning ability from different perspectives. 3) Results on three LMs show that even the best performing model on LogicNLI, RoBERTa, cannot fully infer according to logic and generalize to different scenarios. Analysis could inspire the further exploration of incomprehensible logic.</p>
<h2>2 Related Work</h2>
<h3>2.1 NLU Benchmark</h3>
<p>With the development of language models, many traditional NLU datasets, such as SQuAD (Rajpurkar et al., 2016, 2018), HotpotQA (Yang et al., 2018), and MNLI (Williams et al., 2018), seem
to have been resolved. However, new concerns about spurious correlations (Ribeiro et al., 2019; Jiang and Bansal, 2019) motivate novel datasets to benchmark specific NLU abilities. Some of these datasets concentrated on commonsense or domain knowledge, such as CosmosQA (Huang et al., 2019), PiQA (Bisk et al., 2020), CommonsenseQA (Talmor et al., 2019), and SocialIQA (Sap et al., 2019). Other datasets focused on specific reasoning in NLU, including numerical reasoning (Amini et al., 2019; Dua et al., 2019; Tafjord et al., 2019; Ravichander et al., 2019), coreferential reasoning (Dasigi et al., 2019; Sakaguchi et al., 2020), abductive reasoning based on commonsense (Bhagavatula et al., 2020), and pragmatic reasoning that is originated from linguistics (Jeretic et al., 2020). These studies provided diverse views to benchmark how machines understand language.</p>
<h3>2.2 FOL Reasoning Benchmark</h3>
<p>Among these NLU abilities, FOL reasoning is a fundamental reasoning ability that attracts an increasing number of studies to benchmark. LogiQA (Liu et al., 2020) and ReClor (Yu et al., 2020) are two comprehensive datasets with domain knowledge. However, even if a model performs poorly on these datasets, it is inconclusive that the model lacks the FOL reasoning ability because the targeting ability cannot be disentangled from other reasoning abilities, such as commonsense in-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Logic</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Natural</th>
<th style="text-align: center;">Commonsense</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#FOLs</td>
<td style="text-align: center;">Proof</td>
<td style="text-align: center;">Language</td>
<td style="text-align: center;">Domain</td>
<td style="text-align: center;">Predicate</td>
</tr>
<tr>
<td style="text-align: center;">LogiQA</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
</tr>
<tr>
<td style="text-align: center;">ReClor</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
</tr>
<tr>
<td style="text-align: center;">CLUTRR</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
</tr>
<tr>
<td style="text-align: center;">LTL</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
</tr>
<tr>
<td style="text-align: center;">SoftReasoner</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
</tr>
<tr>
<td style="text-align: center;">LogicNLI</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\sqrt{ }$</td>
<td style="text-align: center;">$\times$</td>
<td style="text-align: center;">$\times$</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparisons among FOL datasets. Logic, Natural Language, and Commonsense correspond to three principles. #FOLs means how many FOLs are covered in the dataset, while Domain/Predicate indicates whether plenty of domain knowledge/predicate relations is/are required to solve the task.
ference. In addition, these two datasets do not provide proofs to trace back the reasoning process. CLUTRR (Sinha et al., 2019) also requires two FOLs but focuses more on the predicate relation (belongs to commonsense) understanding. LTL (Hahn et al., 2021) is a propositional logical benchmark containing five FOLs but does not conform to natural language. Clark et al. (2020) propose a series of novel FOL benchmarks (named SoftReasoner) that introduce as little commonsense as possible. It concentrates on a specific FOL combination, conjunctive implication with negation, rather than on diverse FOL forms. Inspired by SoftReasoner (Clark et al., 2020), we construct LogicNLI with common combinations of all seven FOLs to diagnose the FOL reasoning ability. Compared with other datasets (shown in Table 1), LogicNLI covers the most comprehensive FOL forms and effectively separates logic and commonsense. Furthermore, LogicNLI also provides all proofs for each instance so that we can evaluate LMs' FOL reasoning from different perspectives.</p>
<h2>3 Task Definition</h2>
<p>In this section, we introduce how the task on LogicNLI is defined. On the basis, we also exhibit how FOL reasoning is embodied in LogicNLI. We first define elements in LogicNLI: Facts $F=$ $\left{f_{1}, f_{2}, \cdots, f_{n}\right}$ are composed of simple propositions; Rules $R=\left{r_{1}, r_{2}, \cdots, r_{m}\right}$ are always compound propositions with FOL; Statement $s$ is the targeting proposition; Premise $P=(F, R)$ includes all facts and rules.</p>
<p>Based on the above definitions, the final objective of LogicNLI is to determine the logical relation between $P$ and $s$ under two assumptions: 1) World assumption is open (OWA); 2) The statement $s$ and</p>
<p>Facts: (F1) Harold is distinct. (F2) Daisy is not distinct. (F3) Alan is not distinct.</p>
<p>Rules: (R1) If someone is alive, then he is neither grieving nor worrisome. (R2) If there is at least one people who is distinct, then Alan is grieving. (R3) Harold being alive is equivalent to Alan being grieving. (R4) Someone being both worrisome and drab is equivalent to being colorful and distinct.</p>
<p>Statement: (S) Harold is grieving.
Proofs: (P1) Alan is grieving. (P2) Harold is alive.
Path: F1 + R2 $\rightarrow \mathbf{P 1}+\mathrm{R} 3 \rightarrow \mathbf{P 2}+\mathrm{R} 1 \rightarrow \neg \mathrm{~S}$
Label: Contradiction
Figure 2: An instance in LogicNLI, including facts, rules, a statement, proofs, the path, and the label.
its negative expression $\neg s$ are independent conditioning on $P(\neg s \perp s \mid P)$. The logical relations include "Entailment", "Contradiction", "Neutral", and "Paradox", whose conditions are shown in Equation 1, where $\vdash$ means syntactic consequence.</p>
<p>$$
y= \begin{cases}\text { Entailment, } &amp; P \vdash s \wedge P \nvdash \neg s \ \text { Contradiction, } &amp; P \nvdash s \wedge P \vdash \neg s \ \text { Neutral, } &amp; P \nvdash s \wedge P \nvdash \neg s \ \text { Paradox, } &amp; P \vdash s \wedge P \vdash \neg s\end{cases}
$$</p>
<h2>4 LogicNLI</h2>
<h3>4.1 Overview</h3>
<p>LogicNLI includes more than 30 K instances consisting of facts, rules, a statement to be judged, proofs, the reasoning path, and the label (shown in Figure 2). For each instance, it requires a multihop FOL reasoning process to reason out the final answer. To simplify the reasoning process, we set two limitations: 1) only considering the reasoning from cause to effect; 2) neglecting the true meanings of predicates. Therefore, LogicNLI is more suitable for benchmarking the specific (FOL) reasoning ability instead of serving as a comprehensive NLU task. As a result, we leave open the question of how LMs perform in real reasoning scenarios with FOLs because it is difficult to disentangle multiple influencing factors.</p>
<p>LogicNLI also provides four kinds of test sets that correspond to four diagnostic abilities in diagnosis, including total accuracy, robustness to irrelevant information, more-hop generalization, and proof-based traceability. Specifically, we attempt</p>
<p>to answer the following questions relevant to the FOL reasoning ability based on these evaluations: Q1: Do models truly perform FOL reasoning automatically in diverse scenarios? Q2: Do reasoning results accord with reasonable logic? Accuracy, robustness, and generalization are adopted to answer Q1 from different conditions. Accuracy is the most common in-domain evaluation that measures the overall performance of LMs. Compared with accuracy, the robustness test offers a scenario that increases/decreases non-proof sentences. As robustness does not change the reasoning process, it can be regarded as an in-domain evaluation. The generalization test offers a scenario that increases the reasoning hop and therefore increases proofs, so it is an out-of-domain evaluation. Traceability test is introduced to answer Q2 by validating the whole reasoning process according to the proofs.</p>
<h3>4.2 Dataset Gerneration and Statistics</h3>
<p>We adopt a semi-automatic method to generate LogicNLI with two steps: 1) logic generation, and 2) natural language generation. As for the logic generation, we adopt an automatic method to generate each logic expression to ensure the validity of FOL reasoning. Specifically, We first select a list of subjects, $S=\left{s_{i}\right}, i \leq n$, and a list of adjectives as predicates, $P=\left{p_{j}\right}, j \leq m$, and define a set of logical templates $T$ in advance. For each instance, we randomly select logic expressions from $T$ and the corresponding subjects and predicates from $S$ and $P$. In terms of the natural language generation, we first adopt a rule-based method to generate initial language expressions and then make manual revisions. Manual correction aims to fix grammatical errors and semantic ambiguities. Besides, it also enhances the diversity of expressions. As for test sets of different abilities, we add additional limitations to generate data that meets different needs based on the above generation method.</p>
<p>Statistics of LogicNLI are listed in Table 2. LogicNLI includes 9 training sets, 9 development sets, and 15 test sets. We adopt different subjects and predicates for independently constructed training sets, development sets, and test sets to avoid the spurious correlations between subjects and predicates. To undermine the label bias, we ensure the balance of different labels in each dataset.</p>
<h3>4.3 Diagnosis</h3>
<p>Total Accuracy is the most intuitive indicator to measure the performance of a model in most</p>
<p>NLU tasks (Storks et al., 2019), but it may not be sufficient as it cannot avoid the impacts of spurious correlations. In this work, the accuracy-test set (Test-A) has a similar distribution to the training set and the development set, except that the subjects and predicates are zero-shot.</p>
<p>Robustness to Irrelevant Information is an indomain evaluation that measures the model's ability to extract relevant information from noisy data, which is typically the first step in many NLU tasks. Unlike Sinha et al. (2019), our work focuses on the amount of noise, rather than its taxonomy. Therefore, we adopt an elimination method to generate training sets (Train-R), development sets (Dev-R), and test sets (Test-R). Firstly, facts and rules are classified into relevant sentences (R1, R2, and R3 in Figure 2) and irrelevant sentences (R4 in Figure 2). Secondly, we fix the relevant sentences to ensure that the label remains unchanged and gradually eliminate irrelevant ones. We finally acquire robustness sets with different numbers of facts and rules (from 10 to 24 in steps of 2).</p>
<p>More-hop Generalization is an out-of-domain indicator to judge whether a model truly understands the logic rules and applies them to reasoning instances. Following the setting in CLUTRR (Sinha et al., 2019), generalization can be measured by training a model on examples with $\leq \mathrm{k}$-hop reasoning and evaluated on ones with $&gt;\mathrm{k}$ hop reasoning. Therefore, we generate a series of the more-hop test sets (Test-G) only by controlling the generation iterations during the logic generation.</p>
<p>Proof-based Traceability is used to post-verify whether a model infers the correct answer according to the human-understandable logic. In multihop reasoning tasks, it is reasonable to measure traceability through proofs (Yang et al., 2018; Gontier et al., 2020). Therefore, we propose proofbased traceability (the example of proofs is shown in Figure 2) based on the intuitive that if a model can infer the correct answer according to the right reasoning paths, it will correctly validate each proof. Specifically, we construct an traceabilitytest set (Test-T) with 6-hop instances to make the final task an out-of-domain evaluation while ensuring the judgments of proofs are in-domain. Since "Neutral" samples do not provide any proofs, we remove them. To perform the diagnosis, we first train the model on the training set and test it on Test-T.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Data</th>
<th style="text-align: center;">Statistics</th>
<th style="text-align: center;">Train</th>
<th style="text-align: center;">Dev.</th>
<th style="text-align: center;">Test-A</th>
<th style="text-align: center;">Train-R(s)</th>
<th style="text-align: center;">Dev-R(s)</th>
<th style="text-align: center;">Test-R(s)</th>
<th style="text-align: center;">Test-G(s)</th>
<th style="text-align: center;">Test-T</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">d-LogicNLI</td>
<td style="text-align: center;">#Instances</td>
<td style="text-align: center;">12000</td>
<td style="text-align: center;">1500</td>
<td style="text-align: center;">1500</td>
<td style="text-align: center;">72000</td>
<td style="text-align: center;">9000</td>
<td style="text-align: center;">9000</td>
<td style="text-align: center;">9396</td>
<td style="text-align: center;">6094</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Avg. Length</td>
<td style="text-align: center;">184</td>
<td style="text-align: center;">182</td>
<td style="text-align: center;">183</td>
<td style="text-align: center;">63/ 87/ 111/ 136/ 160/ 184*</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">342</td>
<td style="text-align: center;">340</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Max. Length</td>
<td style="text-align: center;">215</td>
<td style="text-align: center;">212</td>
<td style="text-align: center;">212</td>
<td style="text-align: center;">133/ 140/ 167/ 195/ 206/ 232*</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">389</td>
<td style="text-align: center;">391</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Hop</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">6/ 7/ 8/ 9/ 10</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#(Facts+Rules)</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">5/ 7/ 9/ 11/ 13/ 15</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Subjects(n)</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Predicates(m)</td>
<td style="text-align: center;">379</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">379</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\%Labels</td>
<td style="text-align: center;">Entailment: Contradiction: Neutral $=1: 1: 1$ (1:1:0 for Test-T)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">LogicNLI</td>
<td style="text-align: center;">#Instances</td>
<td style="text-align: center;">16000</td>
<td style="text-align: center;">2000</td>
<td style="text-align: center;">2000</td>
<td style="text-align: center;">96000</td>
<td style="text-align: center;">16000</td>
<td style="text-align: center;">16000</td>
<td style="text-align: center;">4124</td>
<td style="text-align: center;">6039</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Avg. Length</td>
<td style="text-align: center;">245</td>
<td style="text-align: center;">245</td>
<td style="text-align: center;">245</td>
<td style="text-align: center;">104/ 125/ 145/ 165/ 185/ 205/ 225/ 245*</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">330</td>
<td style="text-align: center;">339</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Max. Length</td>
<td style="text-align: center;">291</td>
<td style="text-align: center;">279</td>
<td style="text-align: center;">272</td>
<td style="text-align: center;">167/ 188/ 227/ 230/ 250/ 274/ 283/ 291*</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">395</td>
<td style="text-align: center;">401</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Hop</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;">$\leq 5$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">6/ 7/ 8/ 9/ 10</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#(Facts+Rules)</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">10/ 12/ 14/ 16/ 18/ 20/ 22/ 24</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Subjects(n)</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">382</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">#Predicates(m)</td>
<td style="text-align: center;">379</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">379</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\%Labels</td>
<td style="text-align: center;">Entailment: Contradiction: Neutral: Paradox $=1: 1: 1: 1$ (1:1:0:1 for Test-T)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 2: Statistical information for d-LogicNLI and LogicNLI datasets. A, R, G, and T represent accuracy, robustness, generalization, and traceability, respectively. *Length information under different #(Rules+Facts) is provided as the length distributions are different in robustness sets.</p>
<p>Next, we extract the instances that are correctly predicted to form the target set. We then revise all proofs of the target set to positive expressions to avoid the "negation" logic's impact on the evaluation and re-annotate them. Finally, inspired by the exact match metric (Yang et al., 2018), we define a proof-based extract match (P-EM) to calculate the percentage of instances whose proofs are completely correctly predicted. We adopt P-EM and proof accuracy (P-Acc) to measure the traceability.</p>
<h3>4.4 Degraded LogicNLI</h3>
<p>"Paradox" provides a virtual scenario that is not common in texts, so most classic NLI tasks do not have this condition. To further understand why we introduce "Paradox" to LogicNLI, we construct a degraded dataset, named d-LogicNLI, as a comparison. Compared with LogicNLI, d-LogicNLI only contains premises and hypotheses with logical relations of "Entailment", "Contradiction", and "Neutral". From the perspective of dataset construction, we only need to set a filter in the logic generation stage to filter out paradox propositions. The statistics of d-LogicNLI are listed in Table 2.</p>
<h2>5 Experiments</h2>
<h3>5.1 Experimental Settings</h3>
<p>We conduct experiments on three state-of-the-art language models (LMs), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019), to systematically measure their FOL reasoning ability. For a fair compari-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Paras.</th>
<th style="text-align: center;">BERT</th>
<th style="text-align: center;">RoBERTa</th>
<th style="text-align: center;">XLNET</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">batch size</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: center;">lr</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$1 e^{-5}$</td>
<td style="text-align: center;">$1 e^{-3}$</td>
</tr>
<tr>
<td style="text-align: center;">lr for BERT</td>
<td style="text-align: center;">$5 e^{-6}$</td>
<td style="text-align: center;">$5 e^{-6}$</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">decay rate</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.8</td>
</tr>
<tr>
<td style="text-align: center;">12 coeff.</td>
<td style="text-align: center;">$1 e^{-5}$</td>
<td style="text-align: center;">$1 e^{-5}$</td>
<td style="text-align: center;">$1 e^{-5}$</td>
</tr>
<tr>
<td style="text-align: center;">early stop</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">epochs</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">optimizer</td>
<td style="text-align: center;">ADAMW</td>
<td style="text-align: center;">ADAMW</td>
<td style="text-align: center;">ADAMW</td>
</tr>
</tbody>
</table>
<p>Table 3: Hyper-parameter settings.
son, we fine-tune the large versions of LMs with the same hidden size (1024) and adopt a two-layer perceptron to predict the logical relation. Following the input form of NLI tasks, the inputs look like "[CLS] facts rules [SEP] statement [SEP]" for BERT and RoBERTa, and "facts rules [SEP] statement [SEP] [CLS]" for XLNet. The hyperparameters are shown in Table 3. We set random selection and human performance as the lower and upper boundaries of accuracy. As for human performance evaluation, we employ four Ph.D. students and five post-graduate students of different majors, reporting the average scores on 500 randomly selected instances from the development and test sets. We consider a question as being correctly answered if one of the students gives the correct answer.</p>
<h3>5.2 Results</h3>
<p>Total Accuracy. From Table 4, all three LMs perform better than random guess ( $25.0 \%$ ) but worse than humans ( $77.5 \%$ ). RoBERTa performs the best</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Robustness analysis on LogicNLI. All LMs are trained on Train-R with different number of sentences and tested on the Test-R. Line graphs show changes of accuracies with increasing number of sentences. Dashed lines are linear fitting equations.</p>
<p>on both the development dataset (65.0%) and Test-A (68.3%), with a gap of fewer than ten points compared with humans on Test-A. XLNet is slightly inferior to RoBERTa with the accuracies of 64.0% and 65.4% on the development dataset and Test-A, respectively. BERT, the worst LMs of the three, only achieves only 57.0% and 55.9% accuracies on two datasets, which are significantly poorer than humans. Overall, from the perspective of accuracy, all three LMs cannot reach the human level.</p>
<p><strong>Robustness to Irrelevant Information.</strong> Table 4 shows the average results on all Dev-R(s) and Test-R(s). Similar to accuracy, RoBERTa's performance is slightly better than XLNet, but the gap between the two is not significant. BERT still performs the worst on both Dev-R and Test-R.</p>
<p>Average accuracy on Test-R(s) cannot effectively reflect the robustness directly. We plot the line graph that describes the trend of the result on Test-R(s) with the change of the number of sentences (facts+rules) in Figure 3. All three LMs show downward trends as the number of irrelevant sentences increases. The performances of BERT and RoBERTa decrease evenly with the noise increasing, while the performance of XLNet is fluctuating in the former period but declines rapidly in the latter. Furthermore, we calculate the degradation rate $$ \delta_R $$ from the 10-sentence Test-R to 24-sentence Test-R to measure robustness. Since the descent process is non-linear, we replace original polylines with their fitting lines (dotted lines in Figure 3) to ensure that the degradation rate includes all test points' information. The final degradation rates of BERT, RoBERTa, and XLNet are 24.6%, 25.2%,</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Generalization analysis based on LogicNLI. Results on 6, 7, 8, 9, and 10-hop sets are regarded as out-of-domain results, while it on ≤5-hop set is an in-domain result.</p>
<p>and 21.5%, which shows that XLNet's robustness is slightly better than BERT and RoBERTa.</p>
<p><strong>More-hop Generalization.</strong> We plot accuracies on Test-A and each Test-G in Figure 4 and show the total accuracy on Test-G in Table 4. From Figure 4, all three LMs' performances have dramatically dropped when transferring from in-domain scenarios to out-of-domain scenarios. However, their out-of-domain accuracies can almost keep stable as the number of hops continues to increase (up to 10). To further compare the generalization, we define an indicator, $$ \delta_{A \rightarrow G} = \frac{M_1 - M_2}{M_1} \times 100\% $$, to reflect the percentage of performance degradation when transferring from in-domain scenarios to out-of-domain scenarios, where $$ M_1 $$ is the in-domain result on Test-A and $$ M_2 $$ is the average out-of-domain result on Test-G. The performance degradation rates of BERT, RoBERTa, and XLNet are 43.5%, 26.9%, and 34.3%, respectively. Therefore, RoBERTa shows the best generalization when transferring to more-hop reasoning, while BERT cannot effectively understand logical rules and apply them to out-of-domain instances.</p>
<p><strong>Proof-based Traceability.</strong> Considering P-Acc on Test-T (Table 4), it seems that 87.6% of proofs can be validated when adopting RoBERTa to make the prediction. Even BERT can explain more than 60% proofs. However, we usually judge whether an instance is understood logically by verifying the completeness of the whole logical chain instead of the ratio of understandable proofs. Therefore, P-EM is more suitable than P-Acc to measure traceability. Considering EM, RoBERTa can validate 53.1% correctly predicted instances, while BERT and XLNet can only validate 9.3% and</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Models</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Robustness</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Generalization</th>
<th style="text-align: center;">traceability</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Dev.</td>
<td style="text-align: center;">Test-A</td>
<td style="text-align: center;">Dev-R</td>
<td style="text-align: center;">Test-R</td>
<td style="text-align: center;">Test-G</td>
<td style="text-align: center;">#Target</td>
<td style="text-align: center;">Test-T(P-EM)</td>
<td style="text-align: center;">#Proof</td>
<td style="text-align: center;">Test-T(P-Acc.)</td>
</tr>
<tr>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">77.5</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">BERT</td>
<td style="text-align: center;">57.0</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">66.0</td>
<td style="text-align: center;">31.6</td>
<td style="text-align: center;">2143</td>
<td style="text-align: center;">9.3</td>
<td style="text-align: center;">12706</td>
<td style="text-align: center;">61.1</td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">49.9</td>
<td style="text-align: center;">3529</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">21728</td>
<td style="text-align: center;">87.6</td>
</tr>
<tr>
<td style="text-align: center;">XLNet</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">43.0</td>
<td style="text-align: center;">2495</td>
<td style="text-align: center;">28.6</td>
<td style="text-align: center;">15112</td>
<td style="text-align: center;">77.0</td>
</tr>
</tbody>
</table>
<p>Table 4: Diagnostic results of LMs on LogicNLI. All information provide the percentage (\%) of each evaluation except for #Target and #Proof.
$28.6 \%$ instances, respectively. This result means that RoBERTa is the only LM that can perform FOL reasoning to some extent, which has significantly better proof-based traceability than BERT and XLNet. However, even the best model, RoBERTa, can only explain approximately half of the predictions, indicating that the overall predictions made by LMs do not conform to human logic.</p>
<h3>5.3 Overall Diagnosis</h3>
<p>Considering four evaluations comprehensively, RoBERTa has the best FOL reasoning ability in complex scenarios and is the only one of three LMs that can provide a certain degree of traceability. Considering accuracy (in-domain evaluation) and generalization (out-of-domain evaluation), RoBERTa performs significantly better than BERT and XLNet. Especially when transferring from the in-domain scenarios to the out-of-domain, RoBERTa's degradation ratio is significantly lower than BERT's and XLNet's, which means that RoBERTa is better at understanding logical rules and applying them than the other two LMs. This conclusion can also be proven by the traceability test. In reality, although BERT and XLNet can make correct predictions to some extent, most of these results cannot be traced back by the validation of proofs. A certain percentage of prediction results of RoBERTa can be explained. Finally, as for robustness, RoBERTa is indeed more susceptible to irrelevant information than XLNet. Even though, RoBERTa still performs better than XLNet on robustness test, as XLNet's performance drops rapidly after reaching a threshold.</p>
<p>In general, even for RoBERTa, there is still a long way to the real FOL reasoning. On the one hand, its performance needs to be improved in both in-domain and out-of-domain scenarios. On the other hand, even if RoBERTa makes the correct prediction, nearly half of its prediction results are</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Statistics</th>
<th style="text-align: right;">$\wedge$</th>
<th style="text-align: right;">$\vee$</th>
<th style="text-align: right;">$\neg$</th>
<th style="text-align: right;">$\rightarrow$</th>
<th style="text-align: right;">$\equiv$</th>
<th style="text-align: right;">$\forall$</th>
<th style="text-align: right;">$\exists$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">#Instances</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
<td style="text-align: right;">1500</td>
</tr>
<tr>
<td style="text-align: left;">Ave.Length</td>
<td style="text-align: right;">358</td>
<td style="text-align: right;">330</td>
<td style="text-align: right;">270</td>
<td style="text-align: right;">246</td>
<td style="text-align: right;">253</td>
<td style="text-align: right;">275</td>
<td style="text-align: right;">292</td>
</tr>
<tr>
<td style="text-align: left;">Max.Length</td>
<td style="text-align: right;">411</td>
<td style="text-align: right;">364</td>
<td style="text-align: right;">299</td>
<td style="text-align: right;">292</td>
<td style="text-align: right;">279</td>
<td style="text-align: right;">333</td>
<td style="text-align: right;">321</td>
</tr>
<tr>
<td style="text-align: left;">#(Facts+Rules)</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">24</td>
<td style="text-align: right;">24</td>
<td style="text-align: right;">30</td>
<td style="text-align: right;">22</td>
</tr>
<tr>
<td style="text-align: left;">#Subjects(n)</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td style="text-align: left;">#Predicatex(n)</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td style="text-align: left;">\%Labels</td>
<td style="text-align: right;">Entailment: Contradiction: Neutral $=1$ : 1: 1</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>
<p>Table 5: Statistical information for each FOL.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Models</th>
<th style="text-align: center;">Performance on Each FOL</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\wedge$</td>
<td style="text-align: center;">$\vee$</td>
<td style="text-align: center;">$\neg$</td>
<td style="text-align: center;">$\rightarrow$</td>
<td style="text-align: center;">$\equiv$</td>
<td style="text-align: center;">$\forall$</td>
<td style="text-align: center;">$\exists$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">BERT</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">62.8</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">64.9</td>
<td style="text-align: center;">66.8</td>
<td style="text-align: center;">76.9</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa</td>
<td style="text-align: center;">82.1</td>
<td style="text-align: center;">94.7</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">XLNet</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">90.6</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.1</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 6: Performance on each FOLs (\%). Except for $\neg$, other FOLs cannot imply "Paradox", so we remove "Paradox" and the random accuracy is $33.3 \%$.
still unexplainable. The gap between LMs and humans motivates us to explore more effective ways to make more effective reasoning in NLU. Maybe neural symbolic models are solutions to FOL reasoning (Kalouli et al., 2020).</p>
<h3>5.4 Analysis of Each FOLs</h3>
<p>To further understand the FOL reasoning ability, we perform the analysis on how LMs understand each FOL. Specifically, we are required to disentangle the target FOL from other FOLs by adding logical filters when selecting filters. Among seven FOLs, only implication and equivalence can be fully entangled from other FOLs and directly used for reasoning, while others alone cannot constitute complete reasoning. Therefore, we combine the other five FOLs with the implication logic to make the reasoning process effective. Statistics are shown in Table 5.</p>
<p>Results of FOLs experiments are shown in Ta-</p>
<p>ble 6. RoBERTa outperforms the other two LMs on all FOLs. Considering each FOL, the performance of LMs is almost difficult to surpass humans, except on the existential logic. In reality, existential logic is difficult for humans (with the lowest human performance) because it requires traversing all information to extract relevant information. However, it is not difficult for LMs as existential logic provides weak constraints that are easy to satisfy. As a result, most LMs perform better than humans on such logic. On the contrary, LMs' performances on universal logic and negation logic are significantly worse than humans'. As for universal logic, its complexity may come from its ambiguity in language. For example, comparing $\forall x F(x) \rightarrow G(a)$ and $\forall x(F(x) \rightarrow G(x))$, although both use universal logic for reasoning, the former requires stronger conditions but can only provide simpler conclusions than the latter. This phenomenon makes universal logic difficult to understand consistently. In terms of negation, many studies (Hossain et al., 2020b,c,a) have proved that negation logic itself is critical but difficult to be understood by neural networks, which results in more auxiliary methods to identify and process in natural language. In addition, we find that all LMs perform better on single FOL datasets than on Test-A, which is evidence that LMs suffer from the coupling of different FOLs. Therefore, the analysis of FOLs motivates us to modify LMs by 1) focusing on specific logic types (negation and universal logic), and 2) disentangling the different logical forms.</p>
<h3>5.5 Analysis of "Paradox"</h3>
<p>In this section, we provide further analysis on why to introduce the virtual label "Paradox" into LogicNLI by comparing d-LogicNLI and LogicNLI. As shown in Figure 5, d-LogicNLI is a particular case of LogicNLI under the mutually exclusive condition of "Entailment" and "Contradiction". Therefore, although "Paradox" is usually a virtual label in most scenarios, it is critical to complement the space of the logical relation.</p>
<p>In practice, we can summarize two effects of "Paradox": 1) "Paradox" provides more accurate FOL information for model training, thereby effectively suppressing the impacts of spurious correlations caused by dataset bias; 2) "Paradox" makes the diagnostic scenarios more complete and complex, so it can better distinguish the FOL reasoning abilities of different LMs. We will illustrate
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Comparison of logical relation spaces of dLogicNLI and LogicNLI.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Models</th>
<th style="text-align: center;">Data</th>
<th style="text-align: center;">P-Acc</th>
<th style="text-align: center;">$\delta_{R}$</th>
<th style="text-align: center;">$\delta_{A \rightarrow G}$</th>
<th style="text-align: center;">P-EM</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">BERT</td>
<td style="text-align: center;">d-LogicNLI</td>
<td style="text-align: center;">$\mathbf{7 3 . 1}$</td>
<td style="text-align: center;">$\mathbf{2 3 . 7}$</td>
<td style="text-align: center;">44.0</td>
<td style="text-align: center;">1.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LogicNLI</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">24.6</td>
<td style="text-align: center;">$\mathbf{4 3 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 . 3}$</td>
</tr>
<tr>
<td style="text-align: center;">RoBERTa</td>
<td style="text-align: center;">d-LogicNLI</td>
<td style="text-align: center;">$\mathbf{8 0 . 7}$</td>
<td style="text-align: center;">$\mathbf{1 7 . 0}$</td>
<td style="text-align: center;">40.0</td>
<td style="text-align: center;">0.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LogicNLI</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">25.2</td>
<td style="text-align: center;">$\mathbf{2 6 . 9}$</td>
<td style="text-align: center;">$\mathbf{5 3 . 1}$</td>
</tr>
<tr>
<td style="text-align: center;">XLNet</td>
<td style="text-align: center;">d-LogicNLI</td>
<td style="text-align: center;">$\mathbf{8 5 . 7}$</td>
<td style="text-align: center;">$\mathbf{7 . 2}$</td>
<td style="text-align: center;">36.8</td>
<td style="text-align: center;">4.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LogicNLI</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">$\mathbf{3 4 . 3}$</td>
<td style="text-align: center;">$\mathbf{2 8 . 6}$</td>
</tr>
</tbody>
</table>
<p>Table 7: Comparison of important indicators on dLogicNLI and LogicNLI. $\delta_{R}$ and $\delta_{A \rightarrow G}$ are degradation rates introduced in the results of robustness and generalization, respectively. P-EM is a metric to measure traceability.
these two statements by comparing important indicators on d-LogicNLI and LogicNLI (shown in Table 7). Firstly, the in-domain results (Accuracy and $\delta_{R}$ ) of all three LMs (and human performance) on d-LogicNLI are overall better than those on LogicNLI, proving that either d-LogicNLI provides much simpler evaluation datasets than LogicNLI does, or d-LogicNLI provides more precise and unbiased training instances than LogicNLI provides. Secondly, we observe that LMs trained on dLogicNLI are hardly traceable based on Test-T (the maximum P-EM achieved by XLNet is only 4.1\%), while LMs trained on LogicNLI have significantly better traceability. This phenomenon support that dLogicNLI does not provide sufficient information for LMs to master the FOL reasoning ability. Finally, the generalization indicators $\delta_{A \rightarrow G}$ of BERT, RoBERTa, and XLNet trained on d-LogicNLI are $44.0 \%, 40.0 \%$, and $36.8 \%$, respectively, showing that the transferring ability of LMs trained on dLogicNLI is not as good as those trained on LogicNLI. This is implicit evidence to support that LogicNLI provides more information for LMs to understand FOL rules.</p>
<h3>5.6 Discussion</h3>
<p>From Table 4, RoBERTa performs the best on LogicNLI while XLNet outperforms the other two LMs</p>
<p>on d-LogicNLI. According to the original work of these LMs (Liu et al., 2019; Yang et al., 2019), XLNet modifies the architecture of BERT, while RoBERTa mainly introduces a larger corpus to train the model. In most simple reasoning scenarios, such as RACE (Lai et al., 2017) and SQuAD (Rajpurkar et al., 2016), the performance of XLNet is usually better than RoBERTa's. However, in other scenarios that require more complicated reasoning processes, such as LogiQA (Liu et al., 2020) and datasets defined in GLUE (Wang et al., 2019b) and SuperGLUE (Wang et al., 2019a), RoBERTa, trained on a larger corpus, usually outperforms XLNet. Based on the above analysis, LogicNLI provides more complex reasoning scenarios than d-LogicNLI. Therefore, RoBERTa can highlight its advantages even more on LogicNLI.</p>
<h2>6 Conclusion</h2>
<p>In this paper, we propose a diagnostic method to diagnose LMs' FOL reasoning ability. This method introduces a novel proposed benchmark, LogicNLI, that disentangles the FOL reasoning from commonsense inference. Specifically, it includes four evaluations to measure the FOL reasoning ability from different perspectives. Results on three LMs show that although some LMs (RoBERTa) own a certain interpretable FOL reasoning ability, they still cannot make sensible FOL reasoning like humans. Detailed analysis motivates us to enhance specific reasoning abilities or explore new methods to make neural models understand more refined logic.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by the National Key Research and Development Program of China (2018YFC0830400), the ECNU-SJTU joint grant from the Basic Research Project of Shanghai Science and Technology Commission (19JC1410102), the Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102), and the Shanghai Science and Technology Innovation Action Plan (20511102600).</p>
<h2>References</h2>
<p>Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. 2019. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. In NAACL-HLT.</p>
<p>Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen-tau Yih, and Yejin Choi. 2020. Abductive commonsense reasoning. In $I C L R$.</p>
<p>Yonatan Bisk, Rowan Zellers, Ronan LeBras, Jianfeng Gao, and Yejin Choi. 2020. PIQA: reasoning about physical commonsense in natural language. In AAAI, pages 7432-7439.</p>
<p>Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In EMNLP.</p>
<p>Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over language. In IJCAI.</p>
<p>Pradeep Dasigi, Nelson F. Liu, Ana Marasovic, Noah A. Smith, and Matt Gardner. 2019. Quoref: A reading comprehension dataset with questions requiring coreferential reasoning. In EMNLPIJCNLP.</p>
<p>Ernest Davis. 2017. Logical formalizations of commonsense reasoning: A survey. JAIR, 59:651-723.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT.</p>
<p>Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In NAACL$H L T$.</p>
<p>Nicolas Gontier, Koustuv Sinha, Siva Reddy, and Christopher Pal. 2020. Measuring systematic generalization in neural proof generation with transformers. In NeurIPS.</p>
<p>Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus Norman Rabe, and Bernd Finkbeiner. 2021. Teaching temporal logics to neural networks. In $I C L R$.</p>
<p>Md Mosharaf Hossain, Antonios Anastasopoulos, Eduardo Blanco, and Alexis Palmer. 2020a. It's not a non-issue: Negation as a source of error in machine translation. In EMNLP(Findings).</p>
<p>Md Mosharaf Hossain, Kathleen E. Hamilton, Alexis Palmer, and Eduardo Blanco. 2020b. Predicting the focus of negation: Model and error analysis. In $A C L$.</p>
<p>Md Mosharaf Hossain, Venelin Kovatchev, Pranoy Dutta, Tiffany Kao, Elizabeth Wei, and Eduardo Blanco. 2020c. An analysis of natural language inference benchmarks through the lens of negation. In EMNLP.</p>
<p>Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Cosmos QA: machine reading comprehension with contextual commonsense reasoning. In EMNLP-IJCNLP, pages 2391-2401.</p>
<p>Paloma Jeretic, Alex Warstadt, Suvrat Bhooshan, and Adina Williams. 2020. Are natural language inference models imppressive? learning implicature and presupposition. In $A C L$.</p>
<p>Yichen Jiang and Mohit Bansal. 2019. Avoiding reasoning shortcuts: Adversarial evaluation, training, and model development for multi-hop QA. In $A C L$.</p>
<p>Aikaterini-Lida Kalouli, Richard S. Crouch, and Valeria de Paiva. 2020. Hy-nli: a hybrid system for natural language inference. In COLING.</p>
<p>Divyansh Kaushik and Zachary C. Lipton. 2018. How much reading does reading comprehension require? A critical investigation of popular benchmarks. In ACL.</p>
<p>Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard H. Hovy. 2017. RACE: large-scale reading comprehension dataset from examinations. In EMNLP.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In IJCAI.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining approach. CoRR.</p>
<p>Tom McCoy, Ellie Pavlick, and Tal Linzen. 2019. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. In $A C L$.</p>
<p>Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don't know: Unanswerable questions for squad. In $A C L$.</p>
<p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100, 000+ questions for machine comprehension of text. In EMNLP.</p>
<p>Abhilasha Ravichander, Aakanksha Naik, Carolyn Penstein Rosé, and Eduard H. Hovy. 2019. EQUATE: A benchmark evaluation framework for quantitative reasoning in natural language inference. In CoNLL.</p>
<p>Marco Túlio Ribeiro, Carlos Guestrin, and Sameer Singh. 2019. Are red roses red? evaluating consistency of question-answering models. In $A C L$.</p>
<p>Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020. Winogrande: An adversarial winograd schema challenge at scale. In AAAI.</p>
<p>Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. 2019. Socialiqa: Commonsense reasoning about social interactions. CoRR.</p>
<p>Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. 2019. CLUTRR: A diagnostic benchmark for inductive reasoning from text. In $A C L$.</p>
<p>Shane Storks, Qiaozi Gao, and Joyce Y. Chai. 2019. Recent advances in natural language inference: A survey of benchmarks, resources, and approaches. CoRR.</p>
<p>Saku Sugawara, Pontus Stenetorp, Kentaro Inui, and Akiko Aizawa. 2020. Assessing the benchmarking capacity of machine reading comprehension datasets. In AAAI.</p>
<p>Oyvind Tafjord, Matt Gardner, Kevin Lin, and Peter Clark. 2019. Quartz: An open-domain dataset of qualitative relationship questions. In EMNLPIJCNLP.</p>
<p>Alon Talmor, Yanai Elazar, Yoav Goldberg, and Jonathan Berant. 2020. olmpics - on what language model pre-training captures. TACL.</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. Commonsenseqa: A question answering challenge targeting commonsense knowledge. In NAACL-HLT.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS.</p>
<p>Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019a. Superglue: A stickier benchmark for general-purpose language understanding systems. In NeurIPS.</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019b. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In ICLR.</p>
<p>Adina Williams, Nikita Nangia, and Samuel R. Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In NAACL-HLT.</p>
<p>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In NeurIPS.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. In EMNLP.</p>
<p>Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: A reading comprehension dataset requiring logical reasoning. In ICLR.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{\dagger}$ These authors contributed equally.
${ }^{\ddagger}$ Corresponding author.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>