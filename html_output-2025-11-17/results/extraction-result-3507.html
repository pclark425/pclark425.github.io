<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3507 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3507</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3507</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-78.html">extraction-schema-78</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-392b0c87a40ba12fe6182d042005ff0ab9582df9</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/392b0c87a40ba12fe6182d042005ff0ab9582df9" target="_blank">HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning</a></p>
                <p><strong>Paper Venue:</strong> International Workshop on Semantic Evaluation</p>
                <p><strong>Paper TL;DR:</strong> A new dataset, called HELP, is introduced for handling entailments with lexical and logical phenomena and it is found that some types of inferences can be improved by the data augmentation while others are immune to it.</p>
                <p><strong>Paper Abstract:</strong> Large crowdsourced datasets are widely used for training and evaluating neural models on natural language inference (NLI). Despite these efforts, neural models have a hard time capturing logical inferences, including those licensed by phrase replacements, so-called monotonicity reasoning. Since no large dataset has been developed for monotonicity reasoning, it is still unclear whether the main obstacle is the size of datasets or the model architectures themselves. To investigate this issue, we introduce a new dataset, called HELP, for handling entailments with lexical and logical phenomena. We add it to training data for the state-of-the-art neural models and evaluate them on test sets for monotonicity phenomena. The results showed that our data augmentation improved the overall accuracy. We also find that the improvement is better on monotonicity inferences with lexical replacements than on downward inferences with disjunction and modification. This suggests that some types of inferences can be improved by our data augmentation while others are immune to it.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3507.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3507.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained deep bidirectional Transformer model fine-tuned for NLI; used here as a strong neural baseline to test monotonicity reasoning after additional training data augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BERT: Pre-training of deep bidirectional transformers for language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Bidirectional Transformer encoder pre-trained with masked language modeling and next-sentence prediction, then fine-tuned for NLI classification. In this paper it is fine-tuned on MultiNLI and on augmented variants (MultiNLI+MQ, MultiNLI+HELP).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Strict logical entailment/contradiction/neutral classification focusing on monotonicity-driven inferences (upward, downward, non-monotone, conjunction, disjunction), the FraCaS quantifier problems, and general NLI test sets (SICK, MultiNLI).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Fine-tuning on MultiNLI augmented with HELP (HELP: large monotonicity-driven NLI dataset created by lexical and syntactic replacements). Comparison condition: MultiNLI baseline and MultiNLI+MQ (multiple-quantifier synthetic dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>GLUE diagnostic (Matthews correlation): Up 50.4 (MNLI baseline) -> 67.0 (+16.6) with HELP; Down -67.5 -> 29.8 (+97.3) with HELP; Non 23.1 -> 47.9 (+24.8); Conj 52.5 -> 72.1 (+19.6); Disj -6.1 -> -4.1 (+2.0); Total GLUE diagnostic 17.8 -> 51.2 (+33.4). FraCaS accuracy: 65.0 -> 68.8 (+3.8). SICK accuracy: 55.4 -> 60.0 (+4.6). MNLI accuracy (match/mismatch): 84.6/83.4 -> 84.4/83.1 (small decreases).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>MultiNLI-only fine-tune baseline: GLUE diagnostic total 17.8 (Up 50.4, Down -67.5, Non 23.1, Conj 52.5, Disj -6.1), FraCaS 65.0, SICK 55.4, MNLI match 84.6 / mismatch 83.4.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Substantial improvement on GLUE diagnostic overall (+33.4 Matthews points) driven especially by upward and downward monotonicity subsections (Up +16.6, Down +97.3). Smaller gains on FraCaS (+3.8) and SICK (+4.6). Minimal or negligible change on MNLI accuracy (slight decreases of 0.2-0.3 points).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Limited improvement for disjunction problems (small to no gain, Disj remained negative Matthews values). Some downward inferences involving disjunctions and modifiers remained misclassified. HELP contains some unnatural pairs (noise) due to WordNet substitutions, which the authors included in training; possible remaining domain mismatch for SICK.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Compared MultiNLI+HELP vs MultiNLI+MQ: HELP (much smaller than MQ) yielded larger, more stable improvements, suggesting targeted data augmentation for specific reasoning types matters more than dataset size. Analysis of misclassified GLUE/FraCaS items: 68 problems all models missed (44 neutral with hypothesis words in premise; 13 entailment with extra hypothesis words), indicating difficulty with non-lexical downward inferences (disjunction/modification).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning', 'publication_date_yy_mm': '2019-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3507.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3507.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BiLSTM+ELMo+Attn</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BiLSTM with ELMo embeddings and attention (as reported in GLUE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recurrent neural NLI model using ELMo contextual embeddings and attention over BiLSTM encodings, evaluated as a baseline neural architecture for monotonicity reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GLUE: A multi-task benchmark and analysis platform for natural language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BiLSTM+ELMo+Attn</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Bidirectional LSTM sentence encoder using pretrained contextual ELMo embeddings plus an attention mechanism for cross-sentence interaction; trained/fine-tuned on MultiNLI and augmented variants in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same NLI and monotonicity-focused benchmarks as above; evaluates capability to perform strict phrase-replacement logical inferences (monotonicity: upward/downward), conjunction/disjunction behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Fine-tuning on MultiNLI supplemented with HELP dataset (MultiNLI+HELP) and comparison with MultiNLI and MultiNLI+MQ.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>GLUE diagnostic (Matthews correlation): MultiNLI baseline total -3.5 -> +17.0 (+20.5) with HELP. Subsections with HELP: Up 32.4 (+10.2 over baseline 22.2), Down 22.9 (+32.3 over -9.4), Non 3.7 (+6.4), Conj 45.6 (+3.2), Disj -9.9 (no change). FraCaS accuracy: 68.9 -> 71.3 (+2.4). SICK accuracy: 53.8 -> 54.0 (+0.2). MNLI match/mismatch: 76.4/76.1 -> 75.2/74.1 (small decreases).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>MultiNLI-only baseline: GLUE diagnostic total -3.5 (Up 22.2, Down -9.4, Non -2.7, Conj 42.4, Disj -9.9), FraCaS 68.9, SICK 53.8, MNLI match 76.4 / mismatch 76.1.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Notable improvement on GLUE diagnostic overall (+20.5 Matthews points), particularly on downward monotone subsections (+32.3). Modest FraCaS improvement (+2.4). MNLI accuracy slightly reduced.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Persistent failure on disjunction-related downward inferences (Disj remained -9.9 Matthews). Some NLI domain mismatch for SICK. Models (including this one) misclassified many disjunction/modifier downward problems despite HELP augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Direct comparison with MultiNLI+MQ shows MQ does not provide stable improvements (MQ often smaller or mixed gains); HELP's targeted lexical replacements appear more effective. No further ablation of model components reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning', 'publication_date_yy_mm': '2019-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3507.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3507.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ESIM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ESIM: Enhanced LSTM for Natural Language Inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LSTM-based NLI architecture with local inference modeling (attention, subtraction/multiplication) designed for sentence-pair reasoning; evaluated as a model for monotonicity reasoning and shows large relative gains from HELP augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhanced lstm for natural language inference</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ESIM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Enhanced Sequential Inference Model (ESIM): BiLSTM-based sentence encoders with attention-based local inference modeling and composition layers; trained/fine-tuned on MultiNLI and augmented training sets in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same NLI/monotonicity-focused benchmarks used to probe strict logical inference capabilities (upward/downward monotonicity, conjunction, disjunction, FraCaS quantifiers).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Fine-tuning on MultiNLI+HELP (data augmentation). Comparison with MultiNLI baseline and MultiNLI+MQ.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>GLUE diagnostic (Matthews correlation): MultiNLI baseline total 1.1 -> 27.0 (+25.9) with HELP. Subsections with HELP: Up 31.4 (+16.5 over baseline 14.9), Down 24.7 (+38.7 over -14.0), Non 8.0 (+2.0), Conj 32.6 (+2.8), Disj 7.1 (+12.7 over -5.6). FraCaS accuracy: 47.5 -> 48.8 (+1.3). SICK accuracy: 43.9 -> 56.6 (+12.7). MNLI match/mismatch: 71.3/70.7 -> 71.1/70.1 (small decreases).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>MultiNLI-only baseline: GLUE diagnostic total 1.1 (Up 14.9, Down -14.0, Non 6.0, Conj 29.8, Disj -5.6), FraCaS 47.5, SICK 43.9, MNLI match 71.3 / mismatch 70.7.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Substantial improvements particularly on downward monotonicity and overall GLUE diagnostic (+25.9 Matthews points). ESIM showed larger relative gains than other tested architectures, supporting that tree/structured architectures can better learn some logical inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Despite gains, disjunction and modifier-related downward inferences remained challenging in absolute terms (though Disj improved from negative to small positive). Domain mismatch persists for SICK in baseline; HELP helped SICK more for ESIM than for other models.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Authors note ESIM's greater improvement supports claims (Bowman et al., 2015b) that tree-like architectures better capture logical inferences. Comparison with MQ shows HELP (targeted lexical monotonicity data) yields larger gains than MQ despite smaller size, suggesting the content of augmentation matters more than scale. No model-component ablation reported beyond dataset comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning', 'publication_date_yy_mm': '2019-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3507.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3507.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models performing strict logical reasoning tasks, including the models used, logical reasoning tasks or benchmarks, methods or interventions applied to improve logical reasoning, performance results, comparisons to baselines, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HELP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HELP: A dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 36K-example NLI dataset automatically constructed from the Parallel Meaning Bank (PMB) to target lexical and logical phenomena underlying monotonicity reasoning (upward/downward, conjunction, disjunction, non-monotone).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>HELP (dataset / intervention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dataset created by detecting monotone operators and argument polarities via CCG analyses of PMB sentences, then generating premise-hypothesis pairs via controlled lexical replacements (hypernym/hyponym using WordNet senses) and syntactic eliminations; used for fine-tuning NLI models to improve monotonicity reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>Monotonicity-driven NLI training augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Training data intended to teach models phrase-replacement logical inference patterns (monotonicity), covering upward, downward, non-monotone, conjunction, and disjunction cases with 36K inference pairs and ~15K vocabulary.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Used as additional fine-tuning data (MultiNLI+HELP) to augment model exposure to monotonicity inferences; compared against MultiNLI baseline and MultiNLI+MQ augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>When used to augment MultiNLI, HELP improved GLUE diagnostic total Matthews correlation by +33.4 (BERT), +20.5 (BiLSTM+ELMo+Attn), +25.9 (ESIM). Specific large gains on downward monotonicity: e.g., BERT Down +97.3 Matthews points; ESIM Down +38.7; BiLSTM Down +32.3. Also improved FraCaS and SICK modestly (varies by model).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Compared against baseline augmentation MQ (multiple-quantifier dataset) and MultiNLI-only: HELP (smaller than MQ) produced larger and more stable improvements, indicating targeted data composition matters.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_over_baseline</strong></td>
                            <td>Consistently improved monotonicity-related evaluation metrics across models, often markedly (especially on lexical monotonicity). Improved downward/lexical replacement performance that models previously failed completely on (models without HELP failed on 68 monotonicity-with-lexical-replacement problems).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>HELP leads to smaller or no improvement on disjunction/modification downward inferences; about 146/500 sampled pairs judged unnatural due to WordNet substitution context mismatches, introducing noise into training. Some types of non-lexical downward inferences remained misclassified even though HELP contains many such examples (21K), implying dataset augmentation alone may not suffice for these phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Authors compared MultiNLI+HELP vs MultiNLI+MQ and MultiNLI-only, showing HELP's targeted content (lexical replacements + polarity control) is more effective than larger but less focused datasets (MQ). Error analysis on 68 universally-misclassified GLUE/FraCaS problems identified categories (neutral-within-premise words, entailment-with-extra-words) indicating that disjunction and modifier interactions in downward contexts remain hard; authors hypothesize these require different interventions beyond dataset augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning', 'publication_date_yy_mm': '2019-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Recursive neural networks can learn logical semantics <em>(Rating: 2)</em></li>
                <li>Stress-testing neural models of natural language inference with multiplyquantified sentences <em>(Rating: 2)</em></li>
                <li>Breaking NLI systems with sentences that require simple lexical inferences <em>(Rating: 2)</em></li>
                <li>Enhanced lstm for natural language inference <em>(Rating: 2)</em></li>
                <li>FraCaS-a framework for computational semantics <em>(Rating: 1)</em></li>
                <li>GLUE: A multi-task benchmark and analysis platform for natural language understanding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3507",
    "paper_id": "paper-392b0c87a40ba12fe6182d042005ff0ab9582df9",
    "extraction_schema_id": "extraction-schema-78",
    "extracted_data": [
        {
            "name_short": "BERT",
            "name_full": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "brief_description": "A pretrained deep bidirectional Transformer model fine-tuned for NLI; used here as a strong neural baseline to test monotonicity reasoning after additional training data augmentation.",
            "citation_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "mention_or_use": "use",
            "model_name": "BERT",
            "model_description": "Bidirectional Transformer encoder pre-trained with masked language modeling and next-sentence prediction, then fine-tuned for NLI classification. In this paper it is fine-tuned on MultiNLI and on augmented variants (MultiNLI+MQ, MultiNLI+HELP).",
            "model_size": null,
            "reasoning_task_name": "Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI",
            "reasoning_task_description": "Strict logical entailment/contradiction/neutral classification focusing on monotonicity-driven inferences (upward, downward, non-monotone, conjunction, disjunction), the FraCaS quantifier problems, and general NLI test sets (SICK, MultiNLI).",
            "method_or_intervention": "Fine-tuning on MultiNLI augmented with HELP (HELP: large monotonicity-driven NLI dataset created by lexical and syntactic replacements). Comparison condition: MultiNLI baseline and MultiNLI+MQ (multiple-quantifier synthetic dataset).",
            "performance": "GLUE diagnostic (Matthews correlation): Up 50.4 (MNLI baseline) -&gt; 67.0 (+16.6) with HELP; Down -67.5 -&gt; 29.8 (+97.3) with HELP; Non 23.1 -&gt; 47.9 (+24.8); Conj 52.5 -&gt; 72.1 (+19.6); Disj -6.1 -&gt; -4.1 (+2.0); Total GLUE diagnostic 17.8 -&gt; 51.2 (+33.4). FraCaS accuracy: 65.0 -&gt; 68.8 (+3.8). SICK accuracy: 55.4 -&gt; 60.0 (+4.6). MNLI accuracy (match/mismatch): 84.6/83.4 -&gt; 84.4/83.1 (small decreases).",
            "baseline_performance": "MultiNLI-only fine-tune baseline: GLUE diagnostic total 17.8 (Up 50.4, Down -67.5, Non 23.1, Conj 52.5, Disj -6.1), FraCaS 65.0, SICK 55.4, MNLI match 84.6 / mismatch 83.4.",
            "improvement_over_baseline": "Substantial improvement on GLUE diagnostic overall (+33.4 Matthews points) driven especially by upward and downward monotonicity subsections (Up +16.6, Down +97.3). Smaller gains on FraCaS (+3.8) and SICK (+4.6). Minimal or negligible change on MNLI accuracy (slight decreases of 0.2-0.3 points).",
            "limitations_or_failures": "Limited improvement for disjunction problems (small to no gain, Disj remained negative Matthews values). Some downward inferences involving disjunctions and modifiers remained misclassified. HELP contains some unnatural pairs (noise) due to WordNet substitutions, which the authors included in training; possible remaining domain mismatch for SICK.",
            "ablation_or_analysis": "Compared MultiNLI+HELP vs MultiNLI+MQ: HELP (much smaller than MQ) yielded larger, more stable improvements, suggesting targeted data augmentation for specific reasoning types matters more than dataset size. Analysis of misclassified GLUE/FraCaS items: 68 problems all models missed (44 neutral with hypothesis words in premise; 13 entailment with extra hypothesis words), indicating difficulty with non-lexical downward inferences (disjunction/modification).",
            "uuid": "e3507.0",
            "source_info": {
                "paper_title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
                "publication_date_yy_mm": "2019-04"
            }
        },
        {
            "name_short": "BiLSTM+ELMo+Attn",
            "name_full": "BiLSTM with ELMo embeddings and attention (as reported in GLUE)",
            "brief_description": "A recurrent neural NLI model using ELMo contextual embeddings and attention over BiLSTM encodings, evaluated as a baseline neural architecture for monotonicity reasoning.",
            "citation_title": "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
            "mention_or_use": "use",
            "model_name": "BiLSTM+ELMo+Attn",
            "model_description": "Bidirectional LSTM sentence encoder using pretrained contextual ELMo embeddings plus an attention mechanism for cross-sentence interaction; trained/fine-tuned on MultiNLI and augmented variants in this paper.",
            "model_size": null,
            "reasoning_task_name": "Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI",
            "reasoning_task_description": "Same NLI and monotonicity-focused benchmarks as above; evaluates capability to perform strict phrase-replacement logical inferences (monotonicity: upward/downward), conjunction/disjunction behaviors.",
            "method_or_intervention": "Fine-tuning on MultiNLI supplemented with HELP dataset (MultiNLI+HELP) and comparison with MultiNLI and MultiNLI+MQ.",
            "performance": "GLUE diagnostic (Matthews correlation): MultiNLI baseline total -3.5 -&gt; +17.0 (+20.5) with HELP. Subsections with HELP: Up 32.4 (+10.2 over baseline 22.2), Down 22.9 (+32.3 over -9.4), Non 3.7 (+6.4), Conj 45.6 (+3.2), Disj -9.9 (no change). FraCaS accuracy: 68.9 -&gt; 71.3 (+2.4). SICK accuracy: 53.8 -&gt; 54.0 (+0.2). MNLI match/mismatch: 76.4/76.1 -&gt; 75.2/74.1 (small decreases).",
            "baseline_performance": "MultiNLI-only baseline: GLUE diagnostic total -3.5 (Up 22.2, Down -9.4, Non -2.7, Conj 42.4, Disj -9.9), FraCaS 68.9, SICK 53.8, MNLI match 76.4 / mismatch 76.1.",
            "improvement_over_baseline": "Notable improvement on GLUE diagnostic overall (+20.5 Matthews points), particularly on downward monotone subsections (+32.3). Modest FraCaS improvement (+2.4). MNLI accuracy slightly reduced.",
            "limitations_or_failures": "Persistent failure on disjunction-related downward inferences (Disj remained -9.9 Matthews). Some NLI domain mismatch for SICK. Models (including this one) misclassified many disjunction/modifier downward problems despite HELP augmentation.",
            "ablation_or_analysis": "Direct comparison with MultiNLI+MQ shows MQ does not provide stable improvements (MQ often smaller or mixed gains); HELP's targeted lexical replacements appear more effective. No further ablation of model components reported.",
            "uuid": "e3507.1",
            "source_info": {
                "paper_title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
                "publication_date_yy_mm": "2019-04"
            }
        },
        {
            "name_short": "ESIM",
            "name_full": "ESIM: Enhanced LSTM for Natural Language Inference",
            "brief_description": "An LSTM-based NLI architecture with local inference modeling (attention, subtraction/multiplication) designed for sentence-pair reasoning; evaluated as a model for monotonicity reasoning and shows large relative gains from HELP augmentation.",
            "citation_title": "Enhanced lstm for natural language inference",
            "mention_or_use": "use",
            "model_name": "ESIM",
            "model_description": "Enhanced Sequential Inference Model (ESIM): BiLSTM-based sentence encoders with attention-based local inference modeling and composition layers; trained/fine-tuned on MultiNLI and augmented training sets in this paper.",
            "model_size": null,
            "reasoning_task_name": "Monotonicity reasoning (GLUE diagnostic monotonicity sections), FraCaS generalized quantifier section, SICK, MultiNLI",
            "reasoning_task_description": "Same NLI/monotonicity-focused benchmarks used to probe strict logical inference capabilities (upward/downward monotonicity, conjunction, disjunction, FraCaS quantifiers).",
            "method_or_intervention": "Fine-tuning on MultiNLI+HELP (data augmentation). Comparison with MultiNLI baseline and MultiNLI+MQ.",
            "performance": "GLUE diagnostic (Matthews correlation): MultiNLI baseline total 1.1 -&gt; 27.0 (+25.9) with HELP. Subsections with HELP: Up 31.4 (+16.5 over baseline 14.9), Down 24.7 (+38.7 over -14.0), Non 8.0 (+2.0), Conj 32.6 (+2.8), Disj 7.1 (+12.7 over -5.6). FraCaS accuracy: 47.5 -&gt; 48.8 (+1.3). SICK accuracy: 43.9 -&gt; 56.6 (+12.7). MNLI match/mismatch: 71.3/70.7 -&gt; 71.1/70.1 (small decreases).",
            "baseline_performance": "MultiNLI-only baseline: GLUE diagnostic total 1.1 (Up 14.9, Down -14.0, Non 6.0, Conj 29.8, Disj -5.6), FraCaS 47.5, SICK 43.9, MNLI match 71.3 / mismatch 70.7.",
            "improvement_over_baseline": "Substantial improvements particularly on downward monotonicity and overall GLUE diagnostic (+25.9 Matthews points). ESIM showed larger relative gains than other tested architectures, supporting that tree/structured architectures can better learn some logical inferences.",
            "limitations_or_failures": "Despite gains, disjunction and modifier-related downward inferences remained challenging in absolute terms (though Disj improved from negative to small positive). Domain mismatch persists for SICK in baseline; HELP helped SICK more for ESIM than for other models.",
            "ablation_or_analysis": "Authors note ESIM's greater improvement supports claims (Bowman et al., 2015b) that tree-like architectures better capture logical inferences. Comparison with MQ shows HELP (targeted lexical monotonicity data) yields larger gains than MQ despite smaller size, suggesting the content of augmentation matters more than scale. No model-component ablation reported beyond dataset comparisons.",
            "uuid": "e3507.2",
            "source_info": {
                "paper_title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
                "publication_date_yy_mm": "2019-04"
            }
        },
        {
            "name_short": "HELP",
            "name_full": "HELP: A dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
            "brief_description": "A 36K-example NLI dataset automatically constructed from the Parallel Meaning Bank (PMB) to target lexical and logical phenomena underlying monotonicity reasoning (upward/downward, conjunction, disjunction, non-monotone).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "HELP (dataset / intervention)",
            "model_description": "Dataset created by detecting monotone operators and argument polarities via CCG analyses of PMB sentences, then generating premise-hypothesis pairs via controlled lexical replacements (hypernym/hyponym using WordNet senses) and syntactic eliminations; used for fine-tuning NLI models to improve monotonicity reasoning.",
            "model_size": null,
            "reasoning_task_name": "Monotonicity-driven NLI training augmentation",
            "reasoning_task_description": "Training data intended to teach models phrase-replacement logical inference patterns (monotonicity), covering upward, downward, non-monotone, conjunction, and disjunction cases with 36K inference pairs and ~15K vocabulary.",
            "method_or_intervention": "Used as additional fine-tuning data (MultiNLI+HELP) to augment model exposure to monotonicity inferences; compared against MultiNLI baseline and MultiNLI+MQ augmentation.",
            "performance": "When used to augment MultiNLI, HELP improved GLUE diagnostic total Matthews correlation by +33.4 (BERT), +20.5 (BiLSTM+ELMo+Attn), +25.9 (ESIM). Specific large gains on downward monotonicity: e.g., BERT Down +97.3 Matthews points; ESIM Down +38.7; BiLSTM Down +32.3. Also improved FraCaS and SICK modestly (varies by model).",
            "baseline_performance": "Compared against baseline augmentation MQ (multiple-quantifier dataset) and MultiNLI-only: HELP (smaller than MQ) produced larger and more stable improvements, indicating targeted data composition matters.",
            "improvement_over_baseline": "Consistently improved monotonicity-related evaluation metrics across models, often markedly (especially on lexical monotonicity). Improved downward/lexical replacement performance that models previously failed completely on (models without HELP failed on 68 monotonicity-with-lexical-replacement problems).",
            "limitations_or_failures": "HELP leads to smaller or no improvement on disjunction/modification downward inferences; about 146/500 sampled pairs judged unnatural due to WordNet substitution context mismatches, introducing noise into training. Some types of non-lexical downward inferences remained misclassified even though HELP contains many such examples (21K), implying dataset augmentation alone may not suffice for these phenomena.",
            "ablation_or_analysis": "Authors compared MultiNLI+HELP vs MultiNLI+MQ and MultiNLI-only, showing HELP's targeted content (lexical replacements + polarity control) is more effective than larger but less focused datasets (MQ). Error analysis on 68 universally-misclassified GLUE/FraCaS problems identified categories (neutral-within-premise words, entailment-with-extra-words) indicating that disjunction and modifier interactions in downward contexts remain hard; authors hypothesize these require different interventions beyond dataset augmentation.",
            "uuid": "e3507.3",
            "source_info": {
                "paper_title": "HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning",
                "publication_date_yy_mm": "2019-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Recursive neural networks can learn logical semantics",
            "rating": 2
        },
        {
            "paper_title": "Stress-testing neural models of natural language inference with multiplyquantified sentences",
            "rating": 2
        },
        {
            "paper_title": "Breaking NLI systems with sentences that require simple lexical inferences",
            "rating": 2
        },
        {
            "paper_title": "Enhanced lstm for natural language inference",
            "rating": 2
        },
        {
            "paper_title": "FraCaS-a framework for computational semantics",
            "rating": 1
        },
        {
            "paper_title": "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
            "rating": 1
        }
    ],
    "cost": 0.01330825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>HELP: A Dataset for Identifying Shortcomings of Neural Models in Monotonicity Reasoning</h1>
<p>Hitomi Yanaka ${ }^{1,2}$, Koji Mineshima ${ }^{2}$, Daisuke Bekki ${ }^{2}$, Kentaro Inui ${ }^{1,3}$, Satoshi Sekine ${ }^{1}$, Lasha Abzianidze ${ }^{4}$, and Johan Bos ${ }^{4}$<br>${ }^{1}$ RIKEN, ${ }^{2}$ Ochanomizu University, ${ }^{3}$ Tohoku University, Japan<br>${ }^{4}$ University of Groningen, Netherlands<br>{hitomi.yanaka, satoshi.sekine}@riken.jp,<br>mineshima.koji@ocha.ac.jp, bekki@is.ocha.ac.jp,<br>inui@ecei.tohoku.ac.jp, {l.abzianidze, johan.bos}@rug.nl</p>
<h4>Abstract</h4>
<p>Large crowdsourced datasets are widely used for training and evaluating neural models on natural language inference (NLI). Despite these efforts, neural models have a hard time capturing logical inferences, including those licensed by phrase replacements, socalled monotonicity reasoning. Since no large dataset has been developed for monotonicity reasoning, it is still unclear whether the main obstacle is the size of datasets or the model architectures themselves. To investigate this issue, we introduce a new dataset, called HELP, for handling entailments with lexical and logical phenomena. We add it to training data for the state-of-the-art neural models and evaluate them on test sets for monotonicity phenomena. The results showed that our data augmentation improved the overall accuracy. We also find that the improvement is better on monotonicity inferences with lexical replacements than on downward inferences with disjunction and modification. This suggests that some types of inferences can be improved by our data augmentation while others are immune to it.</p>
<h2>1 Introduction</h2>
<p>Natural language inference (NLI) has been proposed as a benchmark task for natural language understanding. This task is to determine whether a given statement (premise) semantically entails another statement (hypothesis) (Dagan et al., 2013). Large crowdsourced datasets such as SNLI (Bowman et al., 2015a) and MultiNLI (Williams et al., 2018) have been created from naturally-occurring texts for training and testing neural models on NLI. Recent reports showed that these crowdsourced datasets contain undesired biases that allow prediction of entailment labels only from hypothesis sentences (Gururangan et al., 2018; Poliak et al., 2018b; Tsuchiya, 2018). Moreover, these standard datasets come with the so-called</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Upward</th>
<th style="text-align: left;">Some changes in personal values are simply part of growing older</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">(MultiNLI)</td>
<td style="text-align: left;">$\Rightarrow$ Some changes in values are a part of growing older</td>
</tr>
<tr>
<td style="text-align: left;">Downward</td>
<td style="text-align: left;">At most ten commissioners spend time at home</td>
</tr>
<tr>
<td style="text-align: left;">(FraCaS)</td>
<td style="text-align: left;">$\Rightarrow$ At most ten female commissioners spend time at home</td>
</tr>
</tbody>
</table>
<p>Table 1: Upward and downward inferences.
upward monotonicity inferences (see Table 1), i.e., inferences from subsets to supersets (changes in personal values $\sqsubseteq$ changes in values), but they rarely come with downward monotonicity inferences, i.e., inferences from supersets to subsets (commissioners $\sqsupseteq$ female commissioners). Downward monotonicity inferences are interesting in that they allow to replace a phrase with a more specific one and thus the resulting sentence can become longer, yet the inference is valid.</p>
<p>FraCaS (Cooper et al., 1994) contains such logically challenging problems as downward inferences. However, it is small in size (only 346 examples) for training neural models, and it covers only simple syntactic patterns with severely restricted vocabularies. The lack of such a dataset on a large scale is due to at least two factors: it is hard to instruct crowd workers without deep knowledge of natural language syntax and semantics, and it is also unfeasible to employ experts to obtain a large number of logically challenging inferences.</p>
<p>Bowman et al. (2015b) proposed an artificial dataset for logical reasoning, whose premise and hypothesis are automatically generated from a simple English-like grammar. Following this line of work, Geiger et al. (2018) presented a method to construct a complex dataset for multiple quantifiers (e.g., Every dwarf licks no rifle $\Rightarrow$ No ugly dwarf licks some rifle). These datasets contain downward inferences, but they are designed not to require lexical knowledge. There are also NLI datasets which expand lexical knowledge by replacing words using lexical rules (Monz and de Rijke, 2001; Glockner et al., 2018; Naik et al., 2018;</p>
<p>Poliak et al., 2018a). In these works, however, little attention has been paid to downward inferences.</p>
<p>The GLUE leaderboard (Wang et al., 2019) reported that neural models did not perform well on downward inferences, and this leaves us guessing whether the lack of large datasets for such kind of inferences that involve the interaction between lexical and logical inferences is an obstacle of understanding inferences for neural models.</p>
<p>To shed light on this problem, this paper makes the following three contributions: (a) providing a method to create a large NLI dataset ${ }^{1}$ that embodies the combination of lexical and logical inferences focusing on monotonicity (i.e., phrase replacement-based reasoning) (Section 3), (b) measuring to what extent the new dataset helps neural models to learn monotonicity inferences, and (c) by analyzing the results, revealing which types of logical inferences are solved with our training data augmentation and which ones are immune to it (Section 4.2).</p>
<h2>2 Monotonicity Reasoning</h2>
<p>Monotonicity reasoning is a sort of reasoning based on word replacement. Based on the monotonicity properties of words, it determines whether a certain word replacement results in a sentence entailed from the original one (van Benthem, 1983; Icard and Moss, 2014). A polarity is a characteristic of a word position imposed by monotone operators. Replacements with more general (or specific) phrases in $\uparrow$ (or $\downarrow$ ) polarity positions license entailment. Polarities are determined by a function which is always upward monotone ( + ) (i.e., an order preserving function that licenses entailment from specific to general phrases), always downward monotone ( - ) (i.e., an order reversing function) or neither, non-monotone.</p>
<p>Determiners are modeled as binary operators, taking noun and verb phrases as the first and second arguments, respectively, and they entail sentences with their arguments narrowed or broadened according to their monotonicity properties. For example, the determiner some is upward monotone both in its first and second arguments, and the concepts can be broadened by replacing its hypernym (people $\sqsupseteq$ boy), removing modifiers (dancing $\sqsupseteq$ happily dancing), or adding</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>disjunction. The concepts can be narrowed by replacing its hyponym (schoolboy $\sqsubseteq$ boy), adding modifiers, or adding conjunction.
(1) Some [NP boys $\uparrow]^{+}\left[\mathrm{vp}\right.$ are happily dancing $\left.\uparrow\right]^{+}$
$\Rightarrow$ Some [NP people] [VP are dancing]
$\Rightarrow$ Some [NP schoolboys] [VP are dancing and singing]
If a sentence contains negation, the polarity of words over the scope of negation is reversed:
(2) No [NP boys $\downarrow]^{-}\left[\mathrm{vp}\right.$ are happily dancing $\left.\downarrow\right]^{-}$
$\Rightarrow$ No [NP one] [VP is dancing]
$\Rightarrow$ No [NP schoolboys] [VP are dancing and singing]
If the propositional object is embedded in another negative or conditional context, the polarity of words over its scope can be reversed again:
(3) If [there are no [NP boys $\uparrow]^{-}\left[\mathrm{vp}\right.$ dancing happily $\left.\uparrow\right]^{-]^{-}}$, [the party might be canceled] ${ }^{+}$
$\Rightarrow$ If [there is no [NP one] [VP dancing] ], [the party might be canceled]
In this way, the polarity of words is determined by monotonicity operators and syntactic structures.</p>
<h2>3 Data Creation</h2>
<p>We address three issues when creating the inference problems: (a) Detect the monotone operators and their arguments; (b) Based on the syntactic structure, induce the polarity of the argument positions; (c) Using lexical knowledge or logical connectives, narrow or broaden the arguments.</p>
<h3>3.1 Source corpus</h3>
<p>We use sentences from the Parallel Meaning Bank (PMB, Abzianidze et al., 2017) as a source while creating the inference dataset. The reason behind choosing the PMB is threefold. First, the finegrained annotations in the PMB facilitate our automatic monotonicity-driven construction of inference problems. In particular, semantic tokenization and WordNet (Fellbaum, 1998) senses make narrow and broad concept substitutions easy while the syntactic analyses in Combinatory Categorial Grammar (CCG, Steedman, 2000) format and semantic tags (Abzianidze and Bos, 2017) contribute to monotonicity and polarity detection. Second, the PMB contains lexically and syntactically diverse texts from a wide range of genres. Third, the gold (silver) documents are fully (partially) manually verified, which control noise in the automated generated dataset. To prevent easy inferences, we use the sentences with more than five tokens from 5 K gold and 5 K silver portions of the PMB.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Step 1. Select a sentence using semantic tags from the PMB</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">All kids were dancing on the floor</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">AND</td>
<td style="text-align: center;">CON</td>
<td style="text-align: center;">FST</td>
<td style="text-align: center;">EKS</td>
<td style="text-align: center;">REL</td>
<td style="text-align: center;">DEF</td>
</tr>
<tr>
<td style="text-align: center;">Step 2. Detect the polarity of constituents via CCG analysis</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">All [up kids $\downarrow]$ were [up dancing on the floor $\uparrow$ ]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Step 3. Replace expressions based on monotonicity</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$P$ : All [up kids $\downarrow]$ [up were dancing on the floor $\uparrow$ ]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$H_{1}$ : All [up foster children] [up were dancing on the floor] $\mathrm{ENTAIL}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$H_{2}$ : All [up kids] [up were dancing]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Step 4. Create another inference pair by swapping sentences</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$P_{1}^{\prime}\left(=H_{1}\right)$ : All [up foster children] [up were dancing on the floor]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$P_{2}^{\prime}\left(=H_{2}\right)$ : All [up kids] [up were dancing]</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$H^{\prime}\left(=P\right)$ : All [up kids] [up were dancing on the floor] NEUTRAL</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 1: Illustration for creating the HELP dataset.</p>
<h3>3.2 Methodology</h3>
<p>Figure 1 illustrates the method of creating the HELP dataset. We use declarative sentences from the PMB containing monotone operators, conjunction, or disjunction as a source (Step 1). These target words can be identified by their semantic tags: AND (all, every, each, and), DIS (some, several, or), NEG (no, not, neither, without), DEF (both), QUV (many, few), and IMP (if, when, unless). In Step 2, after locating the first (NP) and the second (VP) arguments of the monotone operator via a CCG derivation, we detect their polarities with the possibility of reversing a polarity if an argument appears in a downward environment.</p>
<p>In Step 3, to broaden or narrow the first and the second arguments, we consider two types of operations: (i) lexical replacement, i.e., substituting the argument with its hypernym/hyponym (e.g., $H_{1}$ ) and (ii) syntactic elimination, i.e., dropping a modifier or a conjunction/disjunction phrase in the argument (e.g., $H_{2}$ ). Given the polarity of the argument position ( $\uparrow$ or $\downarrow$ ) and the type of replacement (with more general or specific phrases), the gold label (entailment or neutral) of a premisehypothesis pair is automatically determined; e.g., both $\left(P, H_{1}\right)$ and $\left(P, H_{2}\right)$ in Step 3 are assigned entailment. For lexical replacements, we use WordNet senses from the PMB and their ISA relations with the same part-of-speech to control naturalness of the obtained sentence. To compensate missing word senses from the silver documents, we use the Lesk algorithm (Lesk, 1986). In Step 4, by swapping the premise and the hypothesis, we create another inference pair and assign its gold label; e.g., $\left(P_{1}^{\prime}, H^{\prime}\right)$ and $\left(P_{2}^{\prime}, H^{\prime}\right)$ are created and assigned neutral. By swapping a sentence pair created by syntactic elimination, we can create a pair</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Section</th>
<th style="text-align: center;">Size</th>
<th style="text-align: center;">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Up</td>
<td style="text-align: center;">7784</td>
<td style="text-align: center;">Tom bought some Mexican sunflowers for Mary <br> $\Rightarrow$ Tom bought some flowers for Mary*</td>
</tr>
<tr>
<td style="text-align: center;">Down</td>
<td style="text-align: center;">21192</td>
<td style="text-align: center;">If there's no water, there's no whisky* <br> $\Rightarrow$ If there's no facility, there's no whisky</td>
</tr>
<tr>
<td style="text-align: center;">Non</td>
<td style="text-align: center;">1105</td>
<td style="text-align: center;">Shakespeare wrote both tragedy and comedy* <br> $\Rightarrow$ Shakespeare wrote both tragedy and drama</td>
</tr>
<tr>
<td style="text-align: center;">Conj</td>
<td style="text-align: center;">6076</td>
<td style="text-align: center;">Tom removed his glasses <br> $\Rightarrow$ Tom removed his glasses and rubbed his eyes*</td>
</tr>
<tr>
<td style="text-align: center;">Disj</td>
<td style="text-align: center;">438</td>
<td style="text-align: center;">The trees are barren <br> $\Rightarrow$ The trees are barren or bear only small fruit*</td>
</tr>
</tbody>
</table>
<p>Table 2: Examples in HELP. The sentence with an asterisk is the original sentence from the PMB.
such as $\left(P_{2}^{\prime}, H^{\prime}\right)$ in which the hypothesis is more specific than the premise.</p>
<h3>3.3 The HELP dataset</h3>
<p>The resulting dataset has 36 K inference pairs consisting of upward monotone, downward monotone, non-monotone, conjunction, and disjunction. Table 2 shows some examples. The number of vocabulary items is 15 K . We manually checked the naturalness of randomly sampled 500 sentence pairs, of which 146 pairs were unnatural. As mentioned in previous work (Glockner et al., 2018), there are some cases where WordNet for substitution leads to unnatural sentences due to the context mismatch; e.g., an example such as $P$ : You have no driving happening $\Rightarrow H$ : You have no driving experience, where $P$ is obtained from $H$ by replacing experience by its hypernym happening. Since our intention is to explore possible ways to augment training data for monotonicity reasoning, we include these cases in the training dataset.</p>
<h2>4 Experiments</h2>
<p>We use HELP as additional training material for three neural models for NLI and evaluate them on test sets dealing with monotonicity reasoning.</p>
<h3>4.1 Experimental settings</h3>
<p>Models We used three models: BERT (Devlin et al., 2019), BiLSTM+ELMo+Attn (Wang et al., 2019), and ESIM (Chen et al., 2017).</p>
<p>Training data We used three different training sets and compared their performance; MultiNLI (392K), MultiNLI+MQ (the dataset for multiple quantifiers introduced in Section 1; Geiger et al., 2018) (892K), and MultiNLI+HELP (429K).</p>
<p>Test data We used four test sets: (i) the GLUE diagnostic dataset (Wang et al., 2019) (upward monotone, downward monotone, non-monotone,</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Train Data</th>
<th style="text-align: center;">GLUE diagnostic</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">FraCaS</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">SICK</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">MNLI</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\begin{gathered} \hline \mathrm{Up} \ (30) \end{gathered}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Down <br> (30)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Non <br> (22)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Conj <br> (32)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Disj <br> (38)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Total <br> (152)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(80)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(4927)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">match <br> (10000)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">mismatch <br> (10000)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">BERT</td>
<td style="text-align: center;">MNLI</td>
<td style="text-align: center;">50.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-67.5$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">23.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">52.5</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-6.1$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">55.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">84.6</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">83.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">+MQ</td>
<td style="text-align: center;">59.6</td>
<td style="text-align: center;">$+9.2$</td>
<td style="text-align: center;">$-49.3$</td>
<td style="text-align: center;">$+18.2$</td>
<td style="text-align: center;">14.0</td>
<td style="text-align: center;">$-9.1$</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">$+9.6$</td>
<td style="text-align: center;">$-18.8$</td>
<td style="text-align: center;">$-12.7$</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">$+8.5$</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">$+3.8$</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">$+2.8$</td>
<td style="text-align: center;">78.4</td>
<td style="text-align: center;">$-6.2$</td>
<td style="text-align: center;">78.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">+HELP</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">$+16.6$</td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;">$+97.3$</td>
<td style="text-align: center;">47.9</td>
<td style="text-align: center;">$+24.8$</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">$+19.6$</td>
<td style="text-align: center;">$-4.1$</td>
<td style="text-align: center;">$+2.0$</td>
<td style="text-align: center;">51.2</td>
<td style="text-align: center;">$+33.4$</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">$+3.8$</td>
<td style="text-align: center;">60.0</td>
<td style="text-align: center;">$+4.6$</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">$-0.2$</td>
<td style="text-align: center;">83.1</td>
</tr>
<tr>
<td style="text-align: center;">BiLSTM</td>
<td style="text-align: center;">MNLI</td>
<td style="text-align: center;">22.2</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-9.4$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-2.7$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-9.9$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-3.5$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">68.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">53.8</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">76.1</td>
</tr>
<tr>
<td style="text-align: center;">+ELMo</td>
<td style="text-align: center;">+MQ</td>
<td style="text-align: center;">22.2</td>
<td style="text-align: center;">$-0.0$</td>
<td style="text-align: center;">8.1</td>
<td style="text-align: center;">$+17.5$</td>
<td style="text-align: center;">$-5.7$</td>
<td style="text-align: center;">$-3.0$</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">$-0.0$</td>
<td style="text-align: center;">$-9.8$</td>
<td style="text-align: center;">$+0.1$</td>
<td style="text-align: center;">5.7</td>
<td style="text-align: center;">$+9.2$</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">$-3.0$</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">$+0.2$</td>
<td style="text-align: center;">71.4</td>
<td style="text-align: center;">$-5.0$</td>
<td style="text-align: center;">70.7</td>
</tr>
<tr>
<td style="text-align: center;">+Aita</td>
<td style="text-align: center;">+HELP</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">$+10.2$</td>
<td style="text-align: center;">22.9</td>
<td style="text-align: center;">$+32.3$</td>
<td style="text-align: center;">3.7</td>
<td style="text-align: center;">$+6.4$</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">$+3.2$</td>
<td style="text-align: center;">$-9.9$</td>
<td style="text-align: center;">$-0.0$</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">$+20.5$</td>
<td style="text-align: center;">71.3</td>
<td style="text-align: center;">$+2.4$</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">$+0.2$</td>
<td style="text-align: center;">75.2</td>
<td style="text-align: center;">$-1.2$</td>
<td style="text-align: center;">74.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MNLI</td>
<td style="text-align: center;">14.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-14.0$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">29.8</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$-5.6$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">47.5</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">71.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">70.7</td>
</tr>
<tr>
<td style="text-align: center;">ESIM</td>
<td style="text-align: center;">+MQ</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">$+12.3$</td>
<td style="text-align: center;">$-7.8$</td>
<td style="text-align: center;">$+6.2$</td>
<td style="text-align: center;">3.4</td>
<td style="text-align: center;">$-2.6$</td>
<td style="text-align: center;">5.2</td>
<td style="text-align: center;">$-24.6$</td>
<td style="text-align: center;">$-13.0$</td>
<td style="text-align: center;">$-9.4$</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">$+5.7$</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">$-3.8$</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">$+9.2$</td>
<td style="text-align: center;">68.6</td>
<td style="text-align: center;">$-3.7$</td>
<td style="text-align: center;">68.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">+HELP</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">$+16.5$</td>
<td style="text-align: center;">24.7</td>
<td style="text-align: center;">$+38.7$</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">$+2.0$</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">$+2.8$</td>
<td style="text-align: center;">7.1</td>
<td style="text-align: center;">$+10.7$</td>
<td style="text-align: center;">27.0</td>
<td style="text-align: center;">$+25.9$</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">$+1.3$</td>
<td style="text-align: center;">56.6</td>
<td style="text-align: center;">$+12.7$</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">$-0.2$</td>
<td style="text-align: center;">70.1</td>
</tr>
</tbody>
</table>
<p>Table 3: Evaluation results on the GLUE diagnostic dataset, FraCaS, SICK, and MultiNLI (MNLI). The number in parentheses is the number of problems in each test set. $\triangle$ is the difference from the model trained on MNLI.
conjunction, and disjunction sections), (ii) FraCaS (the generalized quantifier section), (iii) the SICK (Marelli et al., 2014) test set, and (iv) MultiNLI matched/mismatched test set. We used the Matthews correlation coefficient (ranging $[-1,1])$ as the evaluation metric for GLUE. Regarding other datasets, we used accuracy as the metric. We also check if our data augmentation does not decrease the performance on MultiNLI.</p>
<h3>4.2 Results and discussion</h3>
<p>Table 3 shows that adding HELP to MultiNLI improved the accuracy of all models on GLUE, FraCaS, and SICK. Regarding MultiNLI, note that adding data for downward inference can be harmful for performing upward inference, because lexical replacements work in an opposite way in downward environments. However, our data augmentation minimized the decrease in performance on MultiNLI. This suggests that models managed to learn the relationships between downward operators and their arguments from HELP.</p>
<p>The improvement in accuracy is better with HELP than that with MQ despite the fact that the size of HELP is much smaller than MQ. MQ does not deal with lexical replacements, and thus the improvement is not stable. This indicates that the improvement comes from carefully controlling the target reasoning of the training set rather than from its size. ESIM showed a greater improvement in accuracy compared with the other models when we added HELP. This result arguably supports the finding in Bowman et al. (2015b) that a tree architecture is better for learning some logical inferences. Regarding the evaluation on SICK, Talman and Chatzikyriakidis (2018) reported a drop in accuracy of $40-50 \%$ when BiLSTM and ESIM were trained on MultiNLI because SICK is out of the domain of MultiNLI. Indeed, the accuracy of each model, including BERT, was low at $40-60 \%$.</p>
<p>When compared among linguistic phenomena,
the improvement by adding HELP was better for upward and downward monotone. In particular, all models except models trained with HELP failed to answer 68 problems for monotonicity inferences with lexical replacements. This indicates that such inferences can be improved by adding HELP.</p>
<p>The improvement for disjunction was smaller than other phenomena. To investigate this, we conducted error analysis on 68 problems of GLUE and FraCaS, which all the models misclassified. 44 problems are neutral problems in which all words in the hypothesis occur in the premise (e.g., He is either in London or in Paris $\Rightarrow$ He is in London). 13 problems are entailment problems in which the hypothesis contains a word or a phrase not occurring in the premise (e.g., I don't want to have to keep entertaining people $\Rightarrow$ I don't want to have to keep entertaining people who don't value my time). These problems contain disjunction or modifiers in downward environments where either (i) the premise $P$ contains all words in the hypothesis $H$ yet the inference is invalid or (ii) $H$ contains more words than those in $P$ yet the inference is valid. ${ }^{2}$ Although HELP contains 21 K such problems, the models nevertheless misclassified them. This indicates that the difficulty in learning these non-lexical downward inferences might not come from the lack of training datasets.</p>
<h2>5 Conclusion and Future Work</h2>
<p>We introduced a monotonicity-driven NLI data augmentation method. The experiments showed that neural models trained on HELP obtained the higher overall accuracy. However, the improvement tended to be small on downward monotone inferences with disjunction and modification, which suggests that some types of inferences can</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>be improved by adding data while others might require different kind of help.</p>
<p>For future work, our data augmentation can be used for multilingual corpora. Since the PMB annotations sufficed for creating HELP, applying our method to the non-English PMB documents seems straightforward. Additionally, it is interesting to verify the quality and contribution of a dataset which will be created by using our method on an automatically annotated and parsed corpus.</p>
<h2>Acknowledgement</h2>
<p>We thank our three anonymous reviewers for helpful suggestions.</p>
<h2>References</h2>
<p>Lasha Abzianidze, Johannes Bjerva, Kilian Evang, Hessel Haagsma, Rik van Noord, Pierre Ludmann, Duc-Duy Nguyen, and Johan Bos. 2017. The Parallel Meaning Bank: Towards a multilingual corpus of translations annotated with compositional meaning representations. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, pages 242-247.</p>
<p>Lasha Abzianidze and Johan Bos. 2017. Towards universal semantic tagging. In Proceedings of the 12th International Conference on Computational Semantics (IWCS 2017), pages 1-6.</p>
<p>Johan van Benthem. 1983. Determiners and logic. Linguistics and Philosophy, 6(4):447-478.</p>
<p>Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015a. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages $632-642$.</p>
<p>Samuel R. Bowman, Christopher Potts, and Christopher D. Manning. 2015b. Recursive neural networks can learn logical semantics. In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, pages 12-21.</p>
<p>Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017. Enhanced lstm for natural language inference. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1657-1668.</p>
<p>Robin Cooper, Richard Crouch, Jan van Eijck, Chris Fox, Josef van Genabith, Jan Jaspers, Hans Kamp, Manfred Pinkal, Massimo Poesio, Stephen Pulman, et al. 1994. FraCaS-a framework for computational semantics. Deliverable, D6.</p>
<p>Ido Dagan, Dan Roth, Mark Sammons, and Fabio Massimo Zanzotto. 2013. Recognizing Textual Entailment: Models and Applications. Synthesis Lectures on Human Language Technologies. Morgan \&amp; Claypool Publishers.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</p>
<p>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. Language, Speech, and Communication. MIT Press.</p>
<p>Atticus Geiger, Ignacio Cases, Lauri Karttunen, and Christopher Potts. 2018. Stress-testing neural models of natural language inference with multiplyquantified sentences. CoRR, abs/1810.13033.</p>
<p>Bart Geurts and Frans van der Slik. 2005. Monotonicity and processing load. Journal of Semantics, 22(1):97-117.</p>
<p>Max Glockner, Vered Shwartz, and Yoav Goldberg. 2018. Breaking NLI systems with sentences that require simple lexical inferences. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 650-655.</p>
<p>Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith. 2018. Annotation artifacts in natural language inference data. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 107-112.</p>
<p>Thomas Icard and Lawrence Moss. 2014. Recent progress in monotonicity. LILT, 9(7):167-194.</p>
<p>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual International Conference on Systems Documentation, pages 24-26.</p>
<p>Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Roberto Zamparelli. 2014. A SICK cure for the evaluation of compositional distributional semantic models. In Proceedings of the 9th International Conference on Language Resources and Evaluation, pages 216223.</p>
<p>Christof Monz and Maarten de Rijke. 2001. Lightweight entailment checking for computational semantics. In Proceedings of the 3rd International Workshop on Inference in Computational Semantics, pages $1-15$.</p>
<p>Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, and Graham Neubig. 2018. Stress test evaluation for natural language inference. In Proceedings of the 27th International Conference on Computational Linguistics, pages 2340-2353.</p>
<p>Adam Poliak, Aparajita Haldar, Rachel Rudinger, J. Edward Hu, Ellie Pavlick, Aaron Steven White, and Benjamin Van Durme. 2018a. Collecting diverse natural language inference problems for sentence representation evaluation. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 337-340.</p>
<p>Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin Van Durme. 2018b. Hypothesis only baselines in natural language inference. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 180-191.</p>
<p>Mark Steedman. 2000. The Syntactic Process. MIT Press.</p>
<p>Aarne Talman and Stergios Chatzikyriakidis. 2018. Testing the generalization power of neural network models across NLI benchmarks. CoRR, abs/1810.09774.</p>
<p>Masatoshi Tsuchiya. 2018. Performance impact caused by hidden bias of training data for recognizing textual entailment. In Proceedings of the 11th International Conference on Language Resources and Evaluation.</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In International Conference on Learning Representations.</p>
<p>Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages $1112-1122$.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ Interestingly, certain logical inferences including disjunction and downward monotonicity are difficult also for humans to get (Geurts and van der Slik, 2005).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>