<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1098 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1098</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1098</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-58004748</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1901.04436v2.pdf" target="_blank">Bayesian Learning of Neural Network Architectures</a></p>
                <p><strong>Paper Abstract:</strong> In this paper we propose a Bayesian method for estimating architectural parameters of neural networks, namely layer size and network depth. We do this by learning concrete distributions over these parameters. Our results show that regular networks with a learnt structure can generalise better on small datasets, while fully stochastic networks can be more robust to parameter initialisation. The proposed method relies on standard neural variational learning and, unlike randomised architecture search, does not require a retraining of the model, thus keeping the computational overhead at minimum.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1098.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1098.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adaptive Bayesian Bandit Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive-architecture Bayesian Neural Network agent using Thompson sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A contextual bandit agent that learns a Bayesian neural network reward model while concurrently adapting the network architecture (layer size, optionally depth) via learned concrete distributions; action selection uses Thompson sampling over the Bayesian reward posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Adaptive-architecture Bayesian Bandit Agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Reward model is a Bayesian neural network (BNN) with variational Gaussian weight posteriors; architecture (per-layer size, optionally per-layer bypass/skip) is treated as discrete latent variables parameterised with concrete (Gumbel-Softmax / concrete Bernoulli) distributions and learned jointly with weights via the ELBO. In experiments the BNN is 2 layers with ReLU and either rigid 100-unit layers or adaptively learned sizes (prior mean 50, std 20); online updates fine-tune the variational posterior on a buffer of recent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Thompson sampling (Bayesian posterior-driven action selection) with adaptive model architecture (Bayesian architecture learning using concrete distributions)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>The agent updates a variational posterior q(W) over weights and q(α) over architectural variables after each interaction (practically: fine-tune one epoch on a sliding buffer of up to 4096 samples). Thompson sampling draws weight samples from q(W) to select actions that maximise expected reward; concurrently q(α) (concrete categorical for layer sizes, concrete Bernoulli for skips) is updated via gradient-based variational inference using reparameterisation (concrete distributions). Architectural adaptation modulates model capacity over time based on the ELBO: data likelihood pulls capacity up, KL penalties (priors) penalise excess capacity.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Mushroom UCI contextual bandit (consuming vs rejecting mushrooms)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Contextual bandit with independent contexts (categorical feature vectors), stochastic rewards (poisonous-consume => reward randomly −35 or +5 with 50% each; edible-consume => +5; reject => 0), discrete action space (consume vs reject), unknown reward function, non-episodic online interactions, i.i.d. contexts (no temporal dependence). Not explicitly partially observable in the POMDP sense beyond stochastic rewards and uncertainty in mapping context→reward.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Context vectors from Mushroom UCI (>8000 samples), discrete context features mapped to actions in A={consume, reject} (|A|=2); experiments run for 30,000 interactions, agent maintains a replay buffer up to 4096 most recent samples; each update is one epoch over buffer for computational efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Adaptive-size Bayesian agent exhibited stable behavior across 30,000 interactions and lower cumulative regret than the rigid Bayesian agent (plots show adaptive remains stable up to 30k interactions; exact regret values not reported). Adaptive agent's learned architecture (two layers of 34 and 20 units when reinitialised) achieved best performance among Bayesian approaches and outperformed the unstable rigid-Bayesian variant; reported results are averages over 5 runs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Rigid Bayesian agent (2 layers × 100 units) suffered numerical instability and escalating prediction error after ≈17k–20k interactions, leading to large cumulative regret and eventual collapse to always rejecting; purely greedy and 0.05-epsilon-greedy baselines are reported as additional baselines (purely greedy surprisingly had best performance in that run but is not principled). Exact numeric regret/RMSE values are not provided in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Agent processes 30,000 interactions in experiments; updates are one epoch on a buffer of up to 4096 samples per interaction (for computational efficiency). No explicit sample-efficiency curves with numeric thresholds are provided, but adaptive agent reaches and maintains low-regret behavior earlier and remains stable across the 30k horizon compared to rigid Bayesian.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Exploration is governed by Thompson sampling: at each decision the agent samples weights from the posterior q(W) and picks the action that maximises sampled-model reward — this yields principled, posterior-driven exploration that decays as posterior uncertainty reduces; architectural adaptation influences model uncertainty and thus indirectly affects exploration rate (smaller models yield larger model uncertainty/regularisation via KL).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against: rigid Bayesian neural network (same BNN without adaptive architecture), adapted-rigid (rigid network initialised from converged adaptive posterior architecture), purely greedy agent, epsilon-greedy (ε=0.05) agent. All Bayesian agents used same Bayesian training settings except for architecture adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) Jointly learning architecture (layer size via concrete categorical, and optionally depth via concrete Bernoulli skips) with Bayesian weight posteriors produces more robust online behavior in contextual bandits: the adaptive-size agent avoided catastrophic instability observed in a rigid BNN and achieved lower cumulative regret over 30k interactions. 2) The adaptive architecture acts as a regulariser that prevents runaway gradients/noise in a fully Bayesian model under online updates. 3) Exporting the converged adaptive architecture to a rigid BNN (reinitialised rigid model) yields strong performance, showing learned structural priors are transferable. 4) Thompson sampling provides effective exploration when used with the adaptive Bayesian model; the adaptive model transitions from exploration to exploitation as posterior uncertainty decreases.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>1) Rigid Bayesian BNNs experienced numerical instability under online updates (huge gradients from wrong reward estimates) causing collapse to suboptimal policy — a failure mode alleviated by adaptive architecture. 2) The experimental setting (Mushroom UCI) is relatively simple and contexts are i.i.d.; results may not generalise to highly non-stationary or partially observable sequential environments. 3) Temperature τ for concrete distributions must be tuned (too small leads to optimisation instability); adaptive skips only implement convex combinations so cannot be applied where input/output dimensionality differs without extra mechanisms. 4) Exact numeric performance metrics (regret values, RMSE numbers) are not reported in the paper text — only qualitative and plotted results.</td>
                        </tr>
                        <tr>
                            <td><strong>additional_notes</strong></td>
                            <td>Experimental hyperparameters: 2-layer BNNs with 100 units & ReLU for rigid agents; adaptive prior for size centred at 50 units with std 20; buffer size 4096; learning rate 0.0005; Bayesian weight initial std 0.02; fine-tune one epoch per interaction; experiments averaged over 5 independent runs; horizon 30,000 interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayesian Learning of Neural Network Architectures', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>On the likelihood that one unknown probability exceeds another in view of the evidence of two samples <em>(Rating: 2)</em></li>
                <li>Weight uncertainty in neural networks <em>(Rating: 2)</em></li>
                <li>Categorical reparameterization with gumbel-softmax <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1098",
    "paper_id": "paper-58004748",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "Adaptive Bayesian Bandit Agent",
            "name_full": "Adaptive-architecture Bayesian Neural Network agent using Thompson sampling",
            "brief_description": "A contextual bandit agent that learns a Bayesian neural network reward model while concurrently adapting the network architecture (layer size, optionally depth) via learned concrete distributions; action selection uses Thompson sampling over the Bayesian reward posterior.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Adaptive-architecture Bayesian Bandit Agent",
            "agent_description": "Reward model is a Bayesian neural network (BNN) with variational Gaussian weight posteriors; architecture (per-layer size, optionally per-layer bypass/skip) is treated as discrete latent variables parameterised with concrete (Gumbel-Softmax / concrete Bernoulli) distributions and learned jointly with weights via the ELBO. In experiments the BNN is 2 layers with ReLU and either rigid 100-unit layers or adaptively learned sizes (prior mean 50, std 20); online updates fine-tune the variational posterior on a buffer of recent interactions.",
            "adaptive_design_method": "Thompson sampling (Bayesian posterior-driven action selection) with adaptive model architecture (Bayesian architecture learning using concrete distributions)",
            "adaptation_strategy_description": "The agent updates a variational posterior q(W) over weights and q(α) over architectural variables after each interaction (practically: fine-tune one epoch on a sliding buffer of up to 4096 samples). Thompson sampling draws weight samples from q(W) to select actions that maximise expected reward; concurrently q(α) (concrete categorical for layer sizes, concrete Bernoulli for skips) is updated via gradient-based variational inference using reparameterisation (concrete distributions). Architectural adaptation modulates model capacity over time based on the ELBO: data likelihood pulls capacity up, KL penalties (priors) penalise excess capacity.",
            "environment_name": "Mushroom UCI contextual bandit (consuming vs rejecting mushrooms)",
            "environment_characteristics": "Contextual bandit with independent contexts (categorical feature vectors), stochastic rewards (poisonous-consume =&gt; reward randomly −35 or +5 with 50% each; edible-consume =&gt; +5; reject =&gt; 0), discrete action space (consume vs reject), unknown reward function, non-episodic online interactions, i.i.d. contexts (no temporal dependence). Not explicitly partially observable in the POMDP sense beyond stochastic rewards and uncertainty in mapping context→reward.",
            "environment_complexity": "Context vectors from Mushroom UCI (&gt;8000 samples), discrete context features mapped to actions in A={consume, reject} (|A|=2); experiments run for 30,000 interactions, agent maintains a replay buffer up to 4096 most recent samples; each update is one epoch over buffer for computational efficiency.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Adaptive-size Bayesian agent exhibited stable behavior across 30,000 interactions and lower cumulative regret than the rigid Bayesian agent (plots show adaptive remains stable up to 30k interactions; exact regret values not reported). Adaptive agent's learned architecture (two layers of 34 and 20 units when reinitialised) achieved best performance among Bayesian approaches and outperformed the unstable rigid-Bayesian variant; reported results are averages over 5 runs.",
            "performance_without_adaptation": "Rigid Bayesian agent (2 layers × 100 units) suffered numerical instability and escalating prediction error after ≈17k–20k interactions, leading to large cumulative regret and eventual collapse to always rejecting; purely greedy and 0.05-epsilon-greedy baselines are reported as additional baselines (purely greedy surprisingly had best performance in that run but is not principled). Exact numeric regret/RMSE values are not provided in the text.",
            "sample_efficiency": "Agent processes 30,000 interactions in experiments; updates are one epoch on a buffer of up to 4096 samples per interaction (for computational efficiency). No explicit sample-efficiency curves with numeric thresholds are provided, but adaptive agent reaches and maintains low-regret behavior earlier and remains stable across the 30k horizon compared to rigid Bayesian.",
            "exploration_exploitation_tradeoff": "Exploration is governed by Thompson sampling: at each decision the agent samples weights from the posterior q(W) and picks the action that maximises sampled-model reward — this yields principled, posterior-driven exploration that decays as posterior uncertainty reduces; architectural adaptation influences model uncertainty and thus indirectly affects exploration rate (smaller models yield larger model uncertainty/regularisation via KL).",
            "comparison_methods": "Compared against: rigid Bayesian neural network (same BNN without adaptive architecture), adapted-rigid (rigid network initialised from converged adaptive posterior architecture), purely greedy agent, epsilon-greedy (ε=0.05) agent. All Bayesian agents used same Bayesian training settings except for architecture adaptation.",
            "key_results": "1) Jointly learning architecture (layer size via concrete categorical, and optionally depth via concrete Bernoulli skips) with Bayesian weight posteriors produces more robust online behavior in contextual bandits: the adaptive-size agent avoided catastrophic instability observed in a rigid BNN and achieved lower cumulative regret over 30k interactions. 2) The adaptive architecture acts as a regulariser that prevents runaway gradients/noise in a fully Bayesian model under online updates. 3) Exporting the converged adaptive architecture to a rigid BNN (reinitialised rigid model) yields strong performance, showing learned structural priors are transferable. 4) Thompson sampling provides effective exploration when used with the adaptive Bayesian model; the adaptive model transitions from exploration to exploitation as posterior uncertainty decreases.",
            "limitations_or_failures": "1) Rigid Bayesian BNNs experienced numerical instability under online updates (huge gradients from wrong reward estimates) causing collapse to suboptimal policy — a failure mode alleviated by adaptive architecture. 2) The experimental setting (Mushroom UCI) is relatively simple and contexts are i.i.d.; results may not generalise to highly non-stationary or partially observable sequential environments. 3) Temperature τ for concrete distributions must be tuned (too small leads to optimisation instability); adaptive skips only implement convex combinations so cannot be applied where input/output dimensionality differs without extra mechanisms. 4) Exact numeric performance metrics (regret values, RMSE numbers) are not reported in the paper text — only qualitative and plotted results.",
            "additional_notes": "Experimental hyperparameters: 2-layer BNNs with 100 units & ReLU for rigid agents; adaptive prior for size centred at 50 units with std 20; buffer size 4096; learning rate 0.0005; Bayesian weight initial std 0.02; fine-tune one epoch per interaction; experiments averaged over 5 independent runs; horizon 30,000 interactions.",
            "uuid": "e1098.0",
            "source_info": {
                "paper_title": "Bayesian Learning of Neural Network Architectures",
                "publication_date_yy_mm": "2019-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples",
            "rating": 2,
            "sanitized_title": "on_the_likelihood_that_one_unknown_probability_exceeds_another_in_view_of_the_evidence_of_two_samples"
        },
        {
            "paper_title": "Weight uncertainty in neural networks",
            "rating": 2,
            "sanitized_title": "weight_uncertainty_in_neural_networks"
        },
        {
            "paper_title": "Categorical reparameterization with gumbel-softmax",
            "rating": 1,
            "sanitized_title": "categorical_reparameterization_with_gumbelsoftmax"
        }
    ],
    "cost": 0.008484,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Bayesian Learning of Neural Network Architectures</p>
<p>Georgi Dikov 
AI Research
Volkswagen Group
MunichGermany</p>
<p>Patrick Van Der Smagt 
AI Research
Volkswagen Group
MunichGermany</p>
<p>Justin Bayer 
AI Research
Volkswagen Group
MunichGermany</p>
<p>Ai 
AI Research
Volkswagen Group
MunichGermany</p>
<p>Bayesian Learning of Neural Network Architectures</p>
<p>In this paper we propose a Bayesian method for estimating architectural parameters of neural networks, namely layer size and network depth. We do this by learning concrete distributions over these parameters. Our results show that regular networks with a learnt structure can generalise better on small datasets, while fully stochastic networks can be more robust to parameter initialisation. The proposed method relies on standard neural variational learning and, unlike randomised architecture search, does not require a retraining of the model, thus keeping the computational overhead at minimum.</p>
<p>INTRODUCTION</p>
<p>One of the reasons for the success of modern deep learning models is attributed to the development of powerful architectures that exploit certain regularities in the data (e.g., convolutional networks such as [Simonyan andZisserman, 2014, Szegedy et al., 2015]) and alleviate issues with numerical optimisation (e.g., learning an identity mapping in very deep networks [He et al., 2016]). In fact, it has been shown [Saxe et al., 2011] that architecture alone can improve representation learning even with randomly initialised weights.</p>
<p>Traditionally, the architecture of a neural network is treated as a set of static hyperparameters, which are tuned based on an observed performance on a held-out validation set. This viewpoint, however, requires that a network is initialised, trained until convergence and evaluated at each modification of the architecture-a time-consuming procedure which does not allow for an In this work, we propose a scalable Bayesian method to structure optimisation by treating hyperparameters, such as the layer size and network depth, as random variables whose parameterised distributions are learnt together with the rest of the network weights. Taking a Bayesian probabilistic approach to architecture learning is good for two main reasons: (i) the posterior distribution over the architectural parameters reveals whether or not the model has the capacity to represent the training data well; and (ii) imposing prior beliefs over the parameters naturally allows for expert knowledge to be incorporated into the model, without imposing any unbreakable constraints as a side effect. However, obtaining the correct posterior distribution in closed form is not possible due to the highly nonlinear nature of deep neural networks; also residing to a Markov Chain Monte Carlo sampling technique is computationally prohibitive. Instead, we apply the framework of approximate variational inference in order to estimate a posterior distribution over the architectural variables and maintain the differentiability of the model by the means of a continuous relaxation on the discrete categorical (concrete) distribution [Maddison et al., 2016, Jang et al., 2016. Thus we are able to efficiently evaluate a continuum of architectures. We will show empirically that ensembling predictions from networks of sampled architectures acts as a regulariser and mitigates overfitting.</p>
<p>In the next section we review the necessary background in approximate variational inference, present our model from a Bayesian viewpoint and briefly introduce the concrete categorical distribution. In Section 3 we show the mechanism of layer size and network depth learning and give an intuitive interpretation of the approach. Section 4 compares our method to existing ones and discusses their shortcomings. In Section 5 we evaluate multiple models in regression, classification and bandits tasks and finally we discuss potential consequences in Section 6. arXiv:1901.04436v2 [stat.ML] 27 Jan 2019 2 BACKGROUND AND MODEL STATEMENT</p>
<p>Approximate Variational Inference</p>
<p>Let W = {W 1 , W 2 , . . . , W n } denote the weights of an n-layer network and α the architectural parameters which are going to be learnt. Further, let (X, Y) be a labelled dataset. Then, in the framework of Bayesian reasoning, we define a prior distribution p(W, α) = p(W)p(α), a likelihood model p(Y | X, W, α) and we seek to infer the posterior distribution p(W, α | X, Y). The latter, however, cannot be evaluated precisely due to the intractability of the normalisation constant p(Y | X). The variational Bayes approach reframes the problem of inferring the posterior distribution into an optimisation one, by minimising an approximation error between a parameterised surrogate distribution q(W, α | X, Y) and the posterior distribution. For the sake of computational simplicity, throughout this work we will assume that the approximate posterior is fully factorisable, i. e.:
q(W, α | X, Y) = n l=1 q W l X, Y α∈α q(α | X, Y)
(1) and that the network weights in each layer l, W l , are independent and Gaussian distributed with parameters µ, σ ∈ R |W l | , i. e. q W l X, Y = N W l µ, diag(σ 2 ) . Note that relaxing the independence and/or the functional form assumption on the network weights can improve modelling performance, as shown by [Cremer et al., 2018, Pawlowski et al., 2017. Nevertheless, we leave the extension of architecture learning in Bayesian neural networks with more sophisticated posterior approximation to future work. The prior distribution over the weights W l will be a zero-mean factorised Gaussian with the same fixed variance σ 2 0 for each weight, i. e. p W l = N W l 0, σ 2 0 I . The specific form of q(α) and p(α) will be elaborated in detail in Section 3 where we will consider learning the layer sizes and the overall network depth. Due to the discrete nature of these parameters, we cannot use backpropagation to learn their posteriors. We will show in Sections 2.2 and 2.3 how we could circumvent this issue.</p>
<p>Let η and θ represent the sets of variational parameters for the approximate marginals q η (W | X, Y) and q θ (α | X, Y) which we denote as q η (W) and q θ (α) respectively. One way to quantify the approximation error between the surrogate q and the true posterior p is to measure their Kullback-Leibler divergence [Kullback and Leibler, 1951]. It can be shown that the following relation holds [Jordan et al., 1999]:
η * , θ * = arg min η,θ KL(q η (W)q θ (α) || p(W, α | X, Y)) (2) = arg min η,θ − E qη(W)q θ (α) [log p(Y | X, W, α)] + KL(q η (W) || p(W)) + KL(q θ (α) || p(α)) (3) = arg min η,θ −L ELBO (η, θ, X, Y).(4)
The quantity in Eq. (4), L ELBO , is called the Evidence Lower Bound and will be approximated with Monte Carlo (MC) sampling since the prior, the approximate posterior and the likelihood distributions will have known densities as we will see in Section 3. Also, given that the prior distribution p(W) is a Gaussian, the KL-divergence term for the network weights will be computed analytically and thus will reduce the variance in the gradient estimates. However, the KLdivergence for the architectural parameters α will be estimated using MC sampling. Finally, using the approximations q η (W) and q θ (α) we can define a posterior predictive distribution over the labels Y and approximate it with MC sampling:
p(Y | X) = p(Y | X, W, α)q η (W)q θ (α)dWdα.(5)
Note that even if we treat the network weights W as point estimates we can still compute an approximate posterior distribution over α and optimise it using the ELBO objective while performing a MAP estimate over W. That is, the approach of Bayesian architecture learning is applicable to regular neural networks as well and we will show such an example in Section 5.</p>
<p>The Reparameterisation Trick</p>
<p>The reparameterisation trick [Kingma and Welling, 2013] refers to a technique of representing sampling from a probability distribution as a deterministic operation over the distributional parameters and an external source of independent noise. In the context of architecture learning we would like to show that such a reparameterisation is possible for the architectural random variable α of some θ-parameterised distribution α ∼ q θ (α). Then, if there is a deterministic and differentiable function g such that α = g(θ, ) with ∼ p( ) guaranteeing that E q θ (α) [α] = E p( ) [g(θ, )], we can compute the gradient w. r. t. θ on g and use standard backpropagation to learn θ.</p>
<p>The Concrete Categorical Distribution</p>
<p>Proposed by [Jang et al., 2016, Maddison et al., 2016 the Gumbel-softmax or concrete categorical distribution is a continuous extension of its discrete counterpart. It is fully reparameterisable as sampling Kdimensional probability vectors s ∈ ∆ K−1 can be expressed as a deterministic function of its parametersthe probability vector π-and an external source of randomness which is Gumbel-distributed:
s i = exp((log π i + i )/τ ) j exp((log π j + j )/τ ) , i ∼ − log(− log Uniform(0, 1)) .
Here τ is a temperature hyperparameter controlling the smoothness of the approximation. For τ → 0 the samples become one-hot vectors and for τ → ∞ : s i = s j , ∀i, j. In this work we will consider τ fixed. The density of the concrete categorical distribution is
p(s | π, τ ) = (K − 1)!τ K−1 K i=1 π i s −τ −1 i K i=1 π i s −τ i K .(6)
Analogously for the binary case (s ∈ [0, 1]), one can express a sample from a concrete Bernoulli distribution by perturbing the logit with noise from a Logistic distribution and squashing it through a sigmoid:
s = 1 1 + exp(−(log(π) − log(1 − π) + )/τ ) , ∼ Logistic(0, 1).
The functional form of its density function is given as:
p(s | π, τ ) = τ πs −τ −1 (1 − s) −τ −1 (πs −τ + (1 − s) −τ ) 2 .(7)
For more properties of the concrete distributions see the appendices in [Jang et al., 2016, Maddison et al., 2016.</p>
<p>ADAPTIVE NETWORK ARCHITECTURE</p>
<p>In this work we will focus on two important architectural hyperparameters but analogous extensions to others are possible. First we will look into learning the size of an arbitrary layer l denoted with s l and then we will proceed with estimating the optimal depth of a network by means of independent layer-wise skip connections γ l . Following the independence assumption from Eq. (1) for a network of n layers we have:
q(α) = n l=1 q s l q γ l .(8)
Analogous factorisation applies for the prior p(α) as well. In our work, it has the same functional form as the approximate posterior but has fixed parameters.</p>
<p>Layer Size</p>
<p>Let s l ∈ ∆ K−1 be a concrete-categorically distributed random variable encoding the size of an arbitrary fullyconnected layer l with maximum capacity of K units 1 .</p>
<p>Then the integer number representing the layer size encoded in a sample is given as k = arg max i s l i . In order to enforce the sampled size on the layer, we propose building a soft and differentiable mask m(s l ) ∈ ∆ K−1 which multiplicatively gates the output of l:
y l = f (W l y l−1 ) m(s l )(9)
where we omit the bias b l for the sake of notational brevity and use f to denote the activation function.</p>
<p>Due to the fully-connected nature of the layer, there is in general no preference for which k units should be used. However, one has to be consistent in selecting them across different gradient updates, as this subset of units will represent the reduced in size layer and all others should be discarded, e.g. by deleting K −k rows of W l . To do this, we construct the mask such that the top k rows are approximately 1s (letting through gradient updates) and the rest 0s (blocking gradient updates). E. g., m(s l ) = Us l where U ∈ {0, 1} K×K is an upper triangular matrix of ones. Since s l will never be a one-hot vector in practice, the resulting mask will be soft. Note that in a fully Bayesian neural network, the approximate posterior on the parameters of all redundant (blocked) units will conform to the prior, essentially paying a portion of the divergence debt borrowed by the active units.</p>
<p>Before giving explicitly the form of the approximate posterior q s l we argue that (i) the learnt distribution should be unimodal, such that a unique optimal layer size can be deduced, and (ii) it should provide us with a meaningful uncertainty estimate. As the probabilities of the concrete categorical distribution are not constrained to express unimodality, we suggest to limit the degrees of freedom by coupling π i through a deterministic and differentiable function. One such candidate is the renormalised density of the truncated Normal distribution which we denote as N µ, σ 2 , 1, K . By abuse of notation we express π as a function of µ and σ and evaluate it at points {1, 2, . . . , K}:
π(µ, σ) i = N i µ, σ 2 , 1, K K j=1 N(j | µ, σ 2 , 1, K) for i ∈ [K],(10)
q µ, σ s l = ConcreteCategorical(π(µ, σ)).</p>
<p>Besides the unimodality, this parameterisation is also advantageous for requiring a constant number of variational parameters w. r. t. the layer size. Throughout this work, the prior p µ0,σ0 s l assumes the same parameterisation as q µ,σ s l and µ 0 and σ 0 are specified in advance. Care must be taken, however, when setting the temperature τ . Since the gradient is scaled with the inverse of τ , small values, e.g. in the order of 0.01, can lead to optimisation instability. We have observed a good performance with a constant temperature in the range of 1.0 to 3.0, which we found empirically. Finally, we note that the gradients w. r. t. the weights and biases are multiplicatively stretched by the sampled mask vector. Therefore, our method can be interpreted as an auxiliary per-unit learning rate, modulating the error signal coming from the data loglikelihood term in the ELBO objective.</p>
<p>Network Depth</p>
<p>Inspired by [He et al., 2016], we infer the optimal depth of a feed-forward neural network by learning a bypass variable γ l for each layer independently. Using the notation from above, we can express the layer output y l as
y l = (1 − γ l )f (W l y l−1 ) + γ l y l−1 .(12)
We treat γ l in a Bayesian manner and assume a concrete Bernoulli distribution for the form of the approximate posterior. Thus we learn a single variational parameter π per layer and, again, keep the temperature hyperparameter τ fixed:
q π γ l = ConcreteBernoulli(γ l ).(13)
We set the prior p π0 γ l to be another concrete Bernoulli distribution with fixed parameter π 0 . Similarly to the concrete categorical distribution, the temperature hyperparameter τ cannot be small enough so that the sampled bypass coefficient γ l becomes a numerical 1 or 0. Therefore, in the process of training, the outputs of the skipped layer are only strongly inhibited and not completely shut off but as we will see, this still allows to detect an optimal layer count.</p>
<p>One drawback of the presented approach is its limited applicability to those layers only which do not change the dimensionality of their inputs. The reason is that the skip connection is implemented as a simple convex combination of the layer's input and output as given in Eq. (12). Nevertheless, this method can be used in parallel with the adaptive layer size and thus enable intermediate dimensionality fluctuations. Analogously to the per-unit learning rate argument, we can view the skip connection as a modulation on the gradients to all units and we interpret this method as an adaptive perlayer learning rate.</p>
<p>RELATED WORK</p>
<p>Neural network architecture search has long been a topic of research and diverse methods such as evolutionary algorithms [Todd, 1988, Miller et al., 1989, Kitano, 1990, reinforcement learning [Zoph and Le, 2016] or Bayesian optimisation [Bergstra et al., 2013, Mendoza et al., 2016 have been applied. Despite the underlying differences, all these approaches share a common trait in the fact that they decouple the architecture design from the training. Consequently, this has a significant computational burden and to the best of our knowledge, we are the first to oppose to this paradigm and merge weight and architectural hyperparameter optimisation using the forward-and backpropagation cycle of neural network training.</p>
<p>In [LeCun et al., 1990, Hassibi andStork, 1993] unimportant weights are identified and removed from the architecture. A major limitation is that the initial network architecture can only be reduced. Our approach is similar in the sense that it has an upper limit on the network size, but it also allows for growth after initial contraction, should there be new evidence supporting it. Furthermore the method presented in this work is principled in the inclusion of expert knowledge in the form of fixed prior probability for each layer and only requires the manual tuning of the temperature constant τ .</p>
<p>EXPERIMENTS</p>
<p>Regression on Toy Data</p>
<p>Point-estimate Weights In this first toy data experiment we demonstrate learning a suitable layer size in a single-layer neural network with 50 units and ReLU activation functions. We set a very conservative prior on the size variable p µ0,σ0 (s) with µ 0 = 1 and σ 0 = 2 and record the change in the approximate posterior over time. Figure 1 depicts qualitatively the probabilities of the concrete categorical distribution and three snapshots show the current fit over the dataset.</p>
<p>In this example, we generate 2000 points from a onedimensional noisy periodic function. Due to the large number of data points, the total loss is largely dominated by the data likelihood term and the increasing divergence between the approximate posterior and the prior is acting as a weak regulariser. Consequently, the allocation of more units stops after the data is well approximated. Note that this would not happen, should the prior parameter µ 0 be set to a large value, e.g. 40, as there is no incentive for the model to converge to a Step ( 10) and (11)). Below the diagram, three snapshots show the fit of the training data: the more units are released, the better the network is able to account for the non-linearity of the data. The optimisation converges to parameters µ = 21.99 and σ = 0.16. The temperature hyperparameter τ is set to 3.0.</p>
<p>simpler solution. We will see in short that this is no longer the case once we treat the network weights W in a Bayesian way as well.</p>
<p>Next, we initialise a deep neural network with 11 layers, 10 of which are subject to the bypassing mechanism. In order to enforce the usage of more than one layer we limit the size of each to 5 units and we use again a ReLU activation function. Figure 2 shows the change in the probability of skipping a layer over time.</p>
<p>The posterior allows for a clear interpretation that a rigid network of 5 layers will be able to reliably fit the data. Step (x300)  Change in the posterior probabilities {π 1 , . . . , π 10 } for the skip variables {γ l } l∈{1,2,...,10} (see Eq. (13)) over time. Five of the layers are bypassed with high probability, indicating that a network with 5 hidden layers of 5 units each is enough to fit the data. The temperature hyperparameter τ is set to 1.0 for each layer.</p>
<p>Bayesian Weights</p>
<p>We now construct a fully Bayesian neural network with independently normally distributed weights and biases. In Bayesian neural networks the KL-divergence between the approximate posterior and the prior is acting as a strong regulariser on the parameters and in cases of small data size and overly parameterised models, the noise in the parameters dominates. The aim of this experiment is to show that the presented framework of architecture optimisation mitigates this issue by not only extending inadequately small architectures but also reducing oversized ones. Figures 3a and 3b show the change in posterior for two different priors: one with µ 0 = 250 and σ 0 = 20 and another with µ 0 = 500 and σ 0 = 50. Notice that in both cases the variational parameter µ converges to approximately the same value, suggesting that the method is robust to setting inappropriate prior distributions. In addition, we performed experiments where the layer size and the network depth are jointly learnt. In the cases where the architectural prior is on very few units and layers, as in Figure 1, the network first allocates more layers. This is an easier way to increase capacity in comparison to adding more units to a layer. It has, however, one important consequence-having a very deep but narrow Bayesian neural network can be computationally inconvenient, as the variance in the output becomes intractably large. One way to alleviate this problem would be to balance the network depth and layer size, e.g. by choosing an appropriate prior connecting the size and skip variables. We leave this to future research.</p>
<p>Regression on UCI Datasets</p>
<p>We explored the robustness in performance of Bayesian neural networks on several real-world datasets [Dheeru and Karra Taniskidou, 2017] and the deep one stacks 5 of them. In all cases the prior distributions over the structural variables were initialised with parameters µ 0 = 25, σ 0 = 10 for the size mechanism, π 0 = 0.1 for the layer bypassing one. All network weights have a standard normal prior. The posterior approximation over the weights is initialised from the prior as well. As in the previous experiments, the temperature parameters τ are kept fixed at 3.0 and 1.0 for the layer size and network depth respectively. The datasets chosen for this experiment are multidimensional (varying between 6 and 13 features) and contain a fairly small amount of samples (between 300 and 1500), which results in very noisy predictions on the overparameterised models.</p>
<p>We show that learning the structure has significant benefits in performance measured as a root mean squared error (RMSE) and log-likelihood on a heldout test set. The experiments have been repeated 20 times. In Fig. 4 the RMSE of the depth and size adaptive models are lower meaning that they generalise better and the standard deviations narrower, signifying a robustness to initialisations. The results for the loglikelihood in Fig. 5 show that the structure-regularised models are less uncertain about the predictions. Deep rigid models however, fail to fit the data as the noise in the network weights is prevailing. Moreover, both rigid models are highly dependent of the particular parameter initialisation, which is reflected in the large standard deviations in the box plots. On the other hand, the performance of the adaptive models is consistent throughout independent experiment repetitions. </p>
<p>Contextual Bandits</p>
<p>In this experiment we set up a discrete decision making task where an agent's action a ∈ A triggers a reward r ∈ R from the environment, i.e. the bandit. At each time step the agent's action is conditioned on a context c ∈ C which is independent of all previous ones.</p>
<p>Hereby we aim to show the versatility of the adaptive architecture approach in an online learning scenario as changing the quality and quantity of the data changes the requirements for a network structure.</p>
<p>In the bandit task the goal of the agent is to maximise the expected received reward, or equivalently, to minimise the expected regret. The latter is defined as the difference in the rewards received by an oracle and the agent. In order to perform optimally, the agent learns an approximation f (a, c) : (A × C) → R to the bandit's intrinsic reward function and uses it to pick an action. The current context, performed action and received reward are then kept in a data buffer.</p>
<p>The reward approximation function f is parameterised as a Bayesian neural network with weights W and a prior p(W). Furthermore, let p(r | a, c, W) be the likelihood of a reward r under f W . Then, using variational inference we can define a Bayesian objective and learn an approximate posterior q θ (W). Using the likelihood term p(r | a, c, W), we can now define the optimal action as the one that maximises the expected reward. After performing the action we then update q θ (W) and repeat for the next context sample. This iterative approach is called Thompson sampling [Thompson, 1933] and was developed as an efficient way to tradeoff exploration for exploitation in the framework of Bayesian decision making.</p>
<p>In the following we compare agents with purely greedy, randomised and (adaptive) Bayesian reward estimation models. The purely greedy agent is deterministic in nature and always picks the action with highest reward estimate for a given context. The randomised or -greedy agent performs the estimated best action with probability 1 − , otherwise a random one is chosen. This way, despite the agent's deterministic reward model it will still explore potentially better options. Nevertheless, if is not annealed during the interaction with the bandit, the agent will never achieve a 0 expected regret, even with a perfect reward model. The Bayesian agent, however, will explore more actively in the beginning when few data are seen, and will transition automatically into an exploitation regime once the uncertainty in the posterior becomes small enough. The speed at which this transition happens depends on the prior, the initialisation and the variance in the gradients.</p>
<p>Following [Blundell et al., 2015] we evaluate the agents on the Mushroom UCI dataset [Dheeru and Karra Taniskidou, 2017] consisting of more than 8000 mushrooms, described as categorical vectors of features. T he task is then to decide whether or not to consume a given mushroom. If it is labelled as poisonous and is being consumed the agent receives a randomised reward of either −35 or 5 with 50% chance each. If the consumed mushroom is edible the reward is positive 5. All rejected samples receive a reward of 0. In this experiment we measure the cumulative regret over the course of 30 000 interactions. Both the greedy and Bayesian agents are parameterised by 2-layer neural networks with 100 units and ReLU activations in each layer. The adaptive Bayesian agent has a prior centred at 50 units and a broad standard deviation of 20. For the sake of computational efficiency, we do not retrain the reward model at each new bandit interaction but only fine-tune it with one epoch on the current dataset buffer whose size is limited to the last 4096 samples. We used a learning rate of 0.0005 and initialised the standard deviations of the Bayesian weights at 0.02. The reported results are the average of 5 independent runs of the experiment.</p>
<p>Throughout the experiments, the Bayesian rigid agent consistently encountered stability issues and after about 20 000 interactions the reward estimates became so unreliable, that the model settled for the suboptimal solution of picking the reject action for all observed mushrooms. Fig. 6 shows the cumulative regret over time. The failure of the rigid Bayesian model is due to a numerical instability arising from huge gradients caused by wrong reward guesses as it can be seen in the plot of the reward RMSE in Fig. 7. Clearly, the suboptimal behaviour of the Bayesian rigid agent is remedied by the adaptive size regularisation.</p>
<p>In addition, we show the benefits of the learnt architecture by initialising a new one from the converged posterior approximation over the size, in this case-two layers with 34 and 20 units accordingly. It has best performance among the Bayesian and greedy agents with the only exception being the purely greedy agent. We attribute its surprising success to chance and claim without proof that a more challenging dataset will be able to display its lack of principled exploration skills. Cumulative regret</p>
<p>Rigid</p>
<p>Adaptive size Adapted rigid Purely greedy agent 0.05 -greedy agent Figure 6: Cumulative regret, aggregated over 30 000 randomly presented context vectors. The estimated reward is modelled by 2-layer rigid and adaptive size Bayesian neural networks. The rigid network consistently exhibits instability after about 17 000 steps, while the adaptive one remains stable. The best performance among all Bayesian models is obtained by a rigid network whose architecture is initialised from the converged structural parameters of the adaptive network. As a baseline 0.05 − and purely greedy agents are evaluated.  The instability in the estimate results in suboptimal behaviour in action picking and hence a substantial increase in cumulative regret.</p>
<p>Image Classification</p>
<p>To demonstrate the broad applicability of the proposed adaptive architecture method, we apply it on the filter count hyperparameter in Bayesian convolutional neural networks. The extension from the fully connected layers to the output channels of a convolutional layer is straightforward. Similarly, the adaptive network depth regularisation remains unchanged. In this case though, the number of channels from the previous layer should match the one from the current. All experiments are performed on three popular 10-class datasets of increasing discrimination difficulty: MNIST [LeCun et al., 2010], Fashion MNIST [Xiao et al., 2017] and CIFAR-10 [Krizhevsky et al., 2014]. The training sets of these are comprised of 60 000, 60 000 and 50 000 samples respectively and all results presented are based on the average of 100 samples form the model predictive distribution over the held-out 10 000 test samples.</p>
<p>We check the advantage of the adaptive size regularisation in a fairly "wide" model architecture consisting of three Bayesian convolutional layers, each followed by a ReLU non-linearity and a max pooling operation and two Bayesian fully-connected layers. The first two layers have a window size of 5 and the third of 3. The layers host 81, 64, and 64 filters respectively and padding is added to preserve the input dimensionality. After the convolutional layers, the data is flattened and processed by a ReLU-activated fully-connected layer of size 64 and fed into a softmax output layer. For the adaptive network we apply the size regularisation after each convolutional layer. The priors over the size parameters are set to 80% of the maximum filter count and we set τ = 3.0. All configurations are trained for 200 epochs using early stopping, the Bayesian layers have a standard normal prior and the standard deviations of the network weights are initialised to 0.05. Additionally, we create a deep architecture with 9 convolutional layers grouped into 3 blocks of 3 consecutive layers with 32 filters (16 for the first block only) and a max-pooling operation at the end. For the adaptive depth networks, the second and third layer in each block are skipped. We set a very conservative skip prior probability π 0 = 0.1 and keep the temperature constant at τ = 1.0. At the end of the third block, the data is flattened and passed through the fully-connected ReLU and softmax output layers as described above. All other training configurations remain the same.</p>
<p>We evaluate all four neural network configurations in two experimental scenarios. In the first one we learn the parameters from the full training dataset and in the second we reduce each to 1000 randomly chosen samples. Table 1 shows the test set accuracy on the full dataset size (top) and on the reduced one (bottom) for the Bayesian models. There is a clear advantage of the adaptive networks over the rigid ones and it is only amplified by the difficulty of the dataset-the improvement in test set accuracy on the reduced CIFAR-10 is almost 4%. We remark, however, that even the best of these results are not representative for the stateof-the-art and that the purpose of the experiment is to compare the influence of the adaptive architecture method in a rather generic setup.  Table 1: Test set accuracy on the full (top) and reduced (bottom) datasets for "wide" rigid and adaptive as well as "deep" rigid and adaptive Bayesian convolutional neural networks.</p>
<p>CONCLUSION</p>
<p>In this work we introduced a novel method for learning a neural network architecture by including discrete hyperparameters such as the layer size and the network depth into the Bayesian framework. We used parameterised concrete distributions over the architectural variables and variational inference to approximate their posterior distributions. T his allowed us to learn the network structure without significant computational overhead, to sweep through a continuous hyperparameter space and to incorporate external knowledge in the form of prior distributions. The interpretability of the approximate posterior distribution over the layer size and network depth parameters gave us a tool to identify architectural misspecifications and choose optimal values for the layer dimensions. We showed empirically the benefits of the methods in predictive tasks on regression and classification datasets where regularised network structures demonstrated superior test set performance.</p>
<p>Proceedings of the 22 nd International Conference on Artificial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR: Volume 89. Copyright 2019 by the author(s). efficient, exhaustive hyperparameter search.</p>
<p>Figure 1 :
1Change in the posterior probabilities π over time (as used in Eqs. (</p>
<p>Figure 2 :
2Figure 2:</p>
<p>Figure 3 :
3Change in posterior over the size of a singlelayer Bayesian neural network. Prior parameters: (a) µ0 = 250 and σ0 = 20 and (b) µ0 = 500 and σ0 = 50. The temperature hyperparameter τ is set to 3.0.</p>
<p>Figure 5 :
5Test set log-likelihood performance on 5 UCI datasets for single-layer rigid and adaptive and deep rigid and adaptive Bayesian neural networks. Higher is better.</p>
<p>Figure 7 :
7Reward RMSE for the rigid and adaptive agents.</p>
<p>DatasetRigid Adaptive size Deep rigid Adaptive depthMNIST 
99.34 
99.40 
99.46 
99.42 
Fashion 
91.41 
91.13 
91.14 
91.22 
CIFAR-10 73.31 
74.06 
68.51 
69.63 </p>
<p>MNIST 
94.47 
95.67 
95.72 
94.81 
Fashion 
79.69 
81.18 
80.32 
80.83 
CIFAR-10 34.98 
38.95 
33.83 
37.49 </p>
<p>Or K filters if the layer is convolutional.
[Thompson, 1933]  Thompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the evidence of two samples.
AcknowledgementsWe thank Botond Cseke and Atanas Mirchev for their astute remarks and invaluable advice for improving the quality of this work.
Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. [ References, Bergstra, References [Bergstra et al., 2013] Bergstra, J., Yamins, D., and Cox, D. D. (2013). Making a science of model search: Hyperparameter optimization in hundreds of dimen- sions for vision architectures.</p>
<p>Weight uncertainty in neural networks. [ Blundell, Proceedings of the 32Nd International Conference on International Conference on Machine Learning. the 32Nd International Conference on International Conference on Machine LearningJMLR.org37[Blundell et al., 2015] Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015). Weight uncertainty in neural networks. In Proceedings of the 32Nd International Conference on Interna- tional Conference on Machine Learning -Volume 37, ICML'15, pages 1613-1622. JMLR.org.</p>
<p>[ Cremer, arXiv:1801.03558Inference suboptimality in variational autoencoders. arXiv preprint[Cremer et al., 2018] Cremer, C., Li, X., and Du- venaud, D. (2018). Inference suboptimality in variational autoencoders. arXiv preprint arXiv:1801.03558.</p>
<p>UCI machine learning repository. [ Dheeru, Karra Taniskidou ; Dheeru, D Karra Taniskidou, E , [Dheeru and Karra Taniskidou, 2017] Dheeru, D. and Karra Taniskidou, E. (2017). UCI machine learning repository.</p>
<p>Blagodaria ti, V. Proceedings of the 5th annual conference on the curse of rationality. the 5th annual conference on the curse of rationalityGD, 2018] GD[GD, 2018] GD (2018). Blagodaria ti, V. In Proceed- ings of the 5th annual conference on the curse of rationality, pages 2409-1507.</p>
<p>Second order derivatives for network pruning: Optimal brain surgeon. B Hassibi, D G Stork, Advances in neural information processing systems. Hassibi and Stork[Hassibi and Stork, 1993] Hassibi, B. and Stork, D. G. (1993). Second order derivatives for network prun- ing: Optimal brain surgeon. In Advances in neural information processing systems, pages 164-171.</p>
<p>Identity mappings in deep residual networks. [ He, European Conference on Computer Vision. Springer[He et al., 2016] He, K., Zhang, X., Ren, S., and Sun, J. (2016). Identity mappings in deep residual net- works. In European Conference on Computer Vi- sion, pages 630-645. Springer.</p>
<p>[ Jang, arXiv:1611.01144Categorical reparameterization with gumbel-softmax. arXiv preprint[Jang et al., 2016] Jang, E., Gu, S., and Poole, B. (2016). Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144.</p>
<p>An introduction to variational methods for graphical models. [ Jordan, Machine learning. 372[Jordan et al., 1999] Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., and Saul, L. K. (1999). An intro- duction to variational methods for graphical models. Machine learning, 37(2):183-233.</p>
<p>Welling ; Kingma, D P Kingma, M Welling, arXiv:1312.6114Auto-encoding variational bayes. arXiv preprint[Kingma and Welling, 2013] Kingma, D. P. and Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.</p>
<p>Designing neural networks using genetic algorithms with graph generation system. H Kitano ; Kitano, Complex systems. 4Kitano, 1990] Kitano, H. (1990). Designing neural networks using genetic algorithms with graph gen- eration system. Complex systems, 4(4):461-476.</p>
<p>On information and sufficiency. The annals of mathematical statistics. [ Krizhevsky, 22The cifar-10 dataset[Krizhevsky et al., 2014] Krizhevsky, A., Nair, V., and Hinton, G. (2014). The cifar-10 dataset. on- line: http://www. cs. toronto. edu/kriz/cifar. html. [Kullback and Leibler, 1951] Kullback, S. and Leibler, R. A. (1951). On information and sufficiency. The annals of mathematical statistics, 22(1):79-86.</p>
<p>. [ Lecun, [LeCun et al., 2010] LeCun, Y., Cortes, C., and Burges, C. (2010).</p>
<p>Optimal brain damage. Lecun, Advances in neural information processing systems. 2Mnist handwritten digit database. AT&amp;T LabsMnist handwritten digit database. AT&amp;T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist, 2. [LeCun et al., 1990] LeCun, Y., Denker, J. S., and Solla, S. A. (1990). Optimal brain damage. In Advances in neural information processing systems, pages 598-605.</p>
<p>The concrete distribution: A continuous relaxation of discrete random variables. [ Maddison, arXiv:1611.00712Workshop on Automatic Machine Learning. arXiv preprintTowards automatically-tuned neural networks[Maddison et al., 2016] Maddison, C. J., Mnih, A., and Teh, Y. W. (2016). The concrete distribution: A continuous relaxation of discrete random variables. arXiv preprint arXiv:1611.00712. [Mendoza et al., 2016] Mendoza, H., Klein, A., Feurer, M., Springenberg, J. T., and Hutter, F. (2016). Towards automatically-tuned neural networks. In Workshop on Automatic Machine Learning, pages 58-65.</p>
<p>Designing neural networks using genetic algorithms. [ Miller, ICGA. 89[Miller et al., 1989] Miller, G. F., Todd, P. M., and Hegde, S. U. (1989). Designing neural networks us- ing genetic algorithms. In ICGA, volume 89, pages 379-384.</p>
<p>On random weights and unsupervised feature learning. [ Pawlowski, arXiv:1711.01297ICML. arXiv preprintImplicit weight uncertainty in neural networks[Pawlowski et al., 2017] Pawlowski, N., Rajchl, M., and Glocker, B. (2017). Implicit weight un- certainty in neural networks. arXiv preprint arXiv:1711.01297. [Saxe et al., 2011] Saxe, A. M., Koh, P. W., Chen, Z., Bhand, M., Suresh, B., and Ng, A. Y. (2011). On random weights and unsupervised feature learning. In ICML, pages 1089-1096.</p>
<p>Zisserman ; Simonyan, K Simonyan, A Zisserman, arXiv:1409.1556Very deep convolutional networks for large-scale image recognition. arXiv preprint[Simonyan and Zisserman, 2014] Simonyan, K. and Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.</p>
<p>. [ Szegedy, Going deeper with convolutions. Cvpr[Szegedy et al., 2015] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., et al. (2015). Going deeper with convolutions. Cvpr.</p>
<p>. Biometrika. 25Biometrika, 25(3/4):285-294.</p>
<p>Evolutionary methods for connectionist architectures. P Todd, H Xiao, K Rasul, R Vollgraf, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. Psychology Dept. Stanford UniversityTodd, 1988. unpublished Manuscript[Todd, 1988] Todd, P. (1988). Evolutionary methods for connectionist architectures. Psychology Dept. Stanford University, unpublished Manuscript. [Xiao et al., 2017] Xiao, H., Rasul, K., and Vollgraf, R. (2017). Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.</p>
<p>Le ; Zoph, B Zoph, Q V Le, arXiv:1611.01578Neural architecture search with reinforcement learning. arXiv preprint[Zoph and Le, 2016] Zoph, B. and Le, Q. V. (2016). Neural architecture search with reinforcement learn- ing. arXiv preprint arXiv:1611.01578.</p>            </div>
        </div>

    </div>
</body>
</html>