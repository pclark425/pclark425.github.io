<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1292 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1292</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1292</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-209337564</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1912.08001v1.pdf" target="_blank">Sim-to-Real Domain Adaptation For High Energy Physics</a></p>
                <p><strong>Paper Abstract:</strong> Particle physics or High Energy Physics (HEP) studies the elementary constituents of matter and their interactions with each other. Machine Learning (ML) has played an important role in HEP analysis and has proven extremely successful in this area. Usually, the ML algorithms are trained on numerical simulations of the experimental setup and then applied to the real experimental data. However, any discrepancy between the simulation and real data may lead to dramatic consequences concerning the performances of the algorithm on real data. In this paper, we present an application of domain adaptation using a Domain Adversarial Neural Network trained on public HEP data. We demonstrate the success of this approach to achieve sim-to-real transfer and ensure the consistency of the ML algorithms performances on real and simulated HEP datasets.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1292.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1292.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LHCb simulation (HEP MC + detector)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LHCb numerical simulation of high-energy physics processes and detector response (Monte Carlo + detector simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Numerical simulation used as the labeled source domain for training ML classifiers; it models high-energy collision processes and the detector response but contains approximations that produce dataset shifts relative to real experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sim-to-Real Domain Adaptation For High Energy Physics</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>LHCb numerical simulation (high-energy physics event generator + detector simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Simulation of particle collisions (generation of physics processes) and the detector response producing reconstructed features; used to provide labeled training examples (source domain) for ML classifiers. The simulation is the Monte Carlo-produced portion of the Kaggle LHCb dataset (signal simulated, background from real data).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>high energy physics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>approximate / medium-fidelity: models physics-process generation and detector response but includes approximations that cause covariate and other dataset shifts relative to real experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes event generation (particle production and decay kinematics) and modeling of detector measurements resulting in reconstructed features (positions, times, energy deposits); approximates detector performance and geometry and does not perfectly reproduce all experimental processes (leading to covariate shifts and potential concept-shift omissions). No detailed quantitative fidelity parameters (e.g., physics lists, digitization detail, or timestep) are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Neural Network (NN) and Domain-Adversarial Neural Network (DANN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Feed-forward neural network: input layer sized to 58 features, one hidden layer with 100 neurons, tanh activations, cross-entropy loss, Adam optimizer; DANN augments this architecture with a gradient reversal layer and an adversarial domain classifier (two-domain-output) trained on control-channel examples to align feature representations between simulation and real data.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Supervised classification to select signal events (identify τ → 3µ decay) from detector-reconstructed features; also domain-discrimination used as adversarial auxiliary task (control process D_s → φπ → 3µ used for domain alignment).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>On simulation (source) accuracy: standard NN 88.1% (simulation); DANN 84.0% (simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real experimental data from LHCb (target domain), evaluated using a control channel (D_s → φπ → 3µ) and the process-of-interest (τ → 3µ) distributions</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Measured as Kolmogorov–Smirnov (KS) distance between classifier output distributions on simulation vs real: standard NN KS = 0.19 (above acceptance threshold 0.09, indicating mismatch / degraded transfer); DANN KS = 0.06 (below 0.09 threshold, indicating successful sim-to-real alignment and preserved performance). The paper does not report explicit numeric accuracy on real data, only KS similarity and the statement that DANN preserves performance between simulation and real data.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>The paper discusses types of dataset shift (prior, covariate, concept shift) and states the simulation contains covariate shift relative to reality; it does not specify a minimum simulator fidelity or list which specific simulator features are strictly required for successful transfer, instead advocating domain-adaptation (DANN) using control processes to compensate for simulation/real discrepancies.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>A standard NN trained on simulation fails to transfer: its output distribution differs from real data (KS = 0.19 > 0.09 threshold), indicating that the simulation's approximations (covariate shift) lead to degraded real-world performance. The paper attributes transfer failure to dataset shift but does not pinpoint particular missing simulator features.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sim-to-Real Domain Adaptation For High Energy Physics', 'publication_date_yy_mm': '2019-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sim-to-real transfer of robotic control with dynamics randomization <em>(Rating: 2)</em></li>
                <li>Sim-to-real robot learning from pixels with progressive nets <em>(Rating: 2)</em></li>
                <li>Sim-to-real transfer with neural-augmented robot simulation <em>(Rating: 2)</em></li>
                <li>Sim-to-real transfer learning using robustified controllers in robotic tasks involving complex dynamics <em>(Rating: 2)</em></li>
                <li>Transfer learning to model inertial confinement fusion experiments <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1292",
    "paper_id": "paper-209337564",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "LHCb simulation (HEP MC + detector)",
            "name_full": "LHCb numerical simulation of high-energy physics processes and detector response (Monte Carlo + detector simulation)",
            "brief_description": "Numerical simulation used as the labeled source domain for training ML classifiers; it models high-energy collision processes and the detector response but contains approximations that produce dataset shifts relative to real experimental data.",
            "citation_title": "Sim-to-Real Domain Adaptation For High Energy Physics",
            "mention_or_use": "use",
            "simulator_name": "LHCb numerical simulation (high-energy physics event generator + detector simulation)",
            "simulator_description": "Simulation of particle collisions (generation of physics processes) and the detector response producing reconstructed features; used to provide labeled training examples (source domain) for ML classifiers. The simulation is the Monte Carlo-produced portion of the Kaggle LHCb dataset (signal simulated, background from real data).",
            "scientific_domain": "high energy physics",
            "fidelity_level": "approximate / medium-fidelity: models physics-process generation and detector response but includes approximations that cause covariate and other dataset shifts relative to real experimental data",
            "fidelity_characteristics": "Includes event generation (particle production and decay kinematics) and modeling of detector measurements resulting in reconstructed features (positions, times, energy deposits); approximates detector performance and geometry and does not perfectly reproduce all experimental processes (leading to covariate shifts and potential concept-shift omissions). No detailed quantitative fidelity parameters (e.g., physics lists, digitization detail, or timestep) are provided in the paper.",
            "model_or_agent_name": "Neural Network (NN) and Domain-Adversarial Neural Network (DANN)",
            "model_description": "Feed-forward neural network: input layer sized to 58 features, one hidden layer with 100 neurons, tanh activations, cross-entropy loss, Adam optimizer; DANN augments this architecture with a gradient reversal layer and an adversarial domain classifier (two-domain-output) trained on control-channel examples to align feature representations between simulation and real data.",
            "reasoning_task": "Supervised classification to select signal events (identify τ → 3µ decay) from detector-reconstructed features; also domain-discrimination used as adversarial auxiliary task (control process D_s → φπ → 3µ used for domain alignment).",
            "training_performance": "On simulation (source) accuracy: standard NN 88.1% (simulation); DANN 84.0% (simulation).",
            "transfer_target": "Real experimental data from LHCb (target domain), evaluated using a control channel (D_s → φπ → 3µ) and the process-of-interest (τ → 3µ) distributions",
            "transfer_performance": "Measured as Kolmogorov–Smirnov (KS) distance between classifier output distributions on simulation vs real: standard NN KS = 0.19 (above acceptance threshold 0.09, indicating mismatch / degraded transfer); DANN KS = 0.06 (below 0.09 threshold, indicating successful sim-to-real alignment and preserved performance). The paper does not report explicit numeric accuracy on real data, only KS similarity and the statement that DANN preserves performance between simulation and real data.",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": null,
            "minimal_fidelity_discussion": "The paper discusses types of dataset shift (prior, covariate, concept shift) and states the simulation contains covariate shift relative to reality; it does not specify a minimum simulator fidelity or list which specific simulator features are strictly required for successful transfer, instead advocating domain-adaptation (DANN) using control processes to compensate for simulation/real discrepancies.",
            "failure_cases": "A standard NN trained on simulation fails to transfer: its output distribution differs from real data (KS = 0.19 &gt; 0.09 threshold), indicating that the simulation's approximations (covariate shift) lead to degraded real-world performance. The paper attributes transfer failure to dataset shift but does not pinpoint particular missing simulator features.",
            "uuid": "e1292.0",
            "source_info": {
                "paper_title": "Sim-to-Real Domain Adaptation For High Energy Physics",
                "publication_date_yy_mm": "2019-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Sim-to-real transfer of robotic control with dynamics randomization",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_of_robotic_control_with_dynamics_randomization"
        },
        {
            "paper_title": "Sim-to-real robot learning from pixels with progressive nets",
            "rating": 2,
            "sanitized_title": "simtoreal_robot_learning_from_pixels_with_progressive_nets"
        },
        {
            "paper_title": "Sim-to-real transfer with neural-augmented robot simulation",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_with_neuralaugmented_robot_simulation"
        },
        {
            "paper_title": "Sim-to-real transfer learning using robustified controllers in robotic tasks involving complex dynamics",
            "rating": 2,
            "sanitized_title": "simtoreal_transfer_learning_using_robustified_controllers_in_robotic_tasks_involving_complex_dynamics"
        },
        {
            "paper_title": "Transfer learning to model inertial confinement fusion experiments",
            "rating": 2,
            "sanitized_title": "transfer_learning_to_model_inertial_confinement_fusion_experiments"
        }
    ],
    "cost": 0.00630825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Sim-to-Real Domain Adaptation For High Energy Physics</p>
<p>Marouen Baalouch 
CEA
LIST
91191Gif-sur-Yvette cedexFrance</p>
<p>Jean-Philippe Poli 
CEA
LIST
91191Gif-sur-Yvette cedexFrance</p>
<p>Maxime Defurne 
CEA
Irfu</p>
<p>Université Paris-Saclay
91191Gif-sur-Yvette cedexFrance</p>
<p>Noëlie Cherrier 
CEA
Irfu</p>
<p>Université Paris-Saclay
91191Gif-sur-Yvette cedexFrance</p>
<p>Sim-to-Real Domain Adaptation For High Energy Physics</p>
<p>Particle physics or High Energy Physics (HEP) studies the elementary constituents of matter and their interactions with each other. Machine Learning (ML) has played an important role in HEP analysis and has proven extremely successful in this area. Usually, the ML algorithms are trained on numerical simulations of the experimental setup and then applied to the real experimental data. However, any discrepancy between the simulation and real data may lead to dramatic consequences concerning the performances of the algorithm on real data. In this paper, we present an application of domain adaptation using a Domain Adversarial Neural Network trained on public HEP data. We demonstrate the success of this approach to achieve sim-to-real transfer and ensure the consistency of the ML algorithms performances on real and simulated HEP datasets.</p>
<p>Introduction</p>
<p>Elementary particles and the way they interact with each other are studied in particle collider facilities such as the Large Hadron Collider (LHC) [1]. Out of the collision between two particles, new particles will emerge and interact with the detectors placed around the collision site. These detectors provide information such as the particle position, the arrival time and its energy deposit inside the detector which allow to reconstruct the particle trajectory and identify it. Between the produced particles, various correlations and quantities are computed to classify the collision. Classically based on advanced statistics, physicists study patterns and/or compare the results of this classification to Standard Model predictions, hoping to find a deviation hinting "New Physics".</p>
<p>However, in the recent years, Machine Leaning (ML) brought new levels of performance in the classification exercise. In real experimental data, the labels are rarely available and, as a consequence, ML classifiers are usually trained on numerical simulations. The simulation is divided into two main parts: simulation of the high-energy physics processes, e.g., collision/production of particles, and simulation of the detector responses to the produced particles. Both parts may need approximations due to the complexity of the physics processes, causing discrepancies between simulated and experimental data which could dramatically lower the classifier performances with real data.</p>
<p>In this work, we are performing the classification of a LHCb public dataset 1 with a Domain-Adversarial Neural Network (DANN), a Transfer Learning (TL) technique, and compare it to the performances of a regular Neural Network both trained on the same simulation.</p>
<p>Dataset</p>
<p>The dataset studied in this paper was produced for the LHCb experiment at CERN [2]. The main goal of the LHCb experiment is the search for possible contributions from physics beyond the Standard Model by performing precision measurements of CP violating observables and rare decays of hadrons containing a b quark or a c quark. LHCb collaboration posted a data challenge on Kaggle site, for ML application purpose, whose aim is to find charged lepton flavour violation, a possible signal of new physics. The main task of this analysis is to design a ML classifier to select the data of interest (signal) consisting of the decay of the elementary lepton particle τ to the three quasi-stable lepton particle µ. The LHCb dataset available for the training consists of mixture of simulated and real data which are respectively used to describe the signal and background. The dataset feature space is composed by 58 variables, reconstructed from the detector responses and representing physical quantities that describe τ -decay. The dataset contains 67533 examples, where 62% are signal events.</p>
<p>Another dataset, called control sample, was provided to evaluate the agreement of the classifier on simulated and real data. This dataset contains simulated and real events from the channel decay D s → φπ → 3µ, that has a similar topology as the signal channel decay τ → 3µ and the same feature space. The simulation (source) contains 8205 examples and the real data (target) contains 322942 examples with weight values. The weights are estimated using sP lot method [3]. The weight of each example describes a probability to be signal or background: higher (resp. lower) weights mean this event is likely to be signal (resp. background). The agreement of the trained classifier is evaluated using the Kolmogorov Smirnov distance between the classifier probability output from source control (simulation) and target control (real data).</p>
<p>Since the same framework was used to collect the examples for both training and control samples, the shifts between real data and simulation for the process of interest τ → 3µ are expected to be similar to the shifts for the control process D s → φπ → 3µ. The goal is then to learn simulation/real experiment discrepancies with the control process and then transfer this knowledge to the classifier searching for the τ → 3µ process in experimental data.</p>
<p>Related Work</p>
<p>Transfer learning consists in reusing a pre-trained model on a new problem that is, in a certain way, more or less related to the first one. It has been carried out successfully in several fields as image recognition [4,5,6], sentiment classification [7,8] or robotics [9,10,11]. Sim-to-real transfer has been particularly studied in robotics [11,12]: it is a sub-domain of transfer learning that aims at transferring a model trained on simulated data to real data. This is a paramount approach for HEP data. Indeed, the simulation modeling solves real-world problems safely and efficiently and allows the generation of unlimited size datasets. For ML application, learning from a simulation and applying the acquired knowledge to the real world can provide a robust ML models with less time-consuming and data search, specially for ML application related to hardware interaction. However, the simulation is not able to fully replicate all reactions in the real world, which can create a dataset shift between the two domains, simulation and reality. The application of transfer learning in physics is growing due the wide use of the computing simulation in different analysis. It has been applied as example in the modeling of inertial confinement fusion experiments [13], galaxy detection [14,15], or gravitational wave detection [16].</p>
<p>HEP experiments are growing in size and complexity and computer simulation of these experiments are essential for analyzing and interpreting experimental data.</p>
<p>The dataset shift between HEP simulation and real experimental data is also present, and is mainly relying on the complexity of the physics interactions at this level of energy and scale. The first motivation of this work is that simulations provide a lot of labeled data whereas there are very few real labeled data. So far, the process of real data is unavoidable. Applying a classifier trained on simulations on real data decreases indeed the performance of classification, while mainly increasing the systematic uncertainty which lowers the significance of the results.</p>
<p>To achieve that, characterizing the dataset shift between simulation and real experiment gives an idea about the appropriate transfer learning technique for a specific learning task. The transfer of ML algorithm trained on HEP simulation represents a task of Domain Adaptation (DA) [17,18,19]. In this case of DA, the source with labels is provided by the HEP simulation and the target without label by the events from the detector response. We aim in this ML application study at selecting an event of interest by physics process classification, with an ML model trained on simulation and targeted to real data. In this HEP study context, the dataset shift can be categorized under three types [20]:</p>
<p>• the prior probability shift occurs when the estimation of the total rate of background or data of interest in the simulation is not the same as in the reality;</p>
<p>• the covariate shift occurs when the geometry of the physics process, for instance the angular or energy distribution of the produced particles, is approximate or when the performance of the detector is not ideally realistic in the simulation framework. However the rate of data of interest with respect to the background is correctly defined;</p>
<p>• the concept shift occurs when the simulation are not considering all the categories of physics processes in the real data, thus are counted as a form of signal or background.</p>
<p>In the case of fully unlabeled target, the prior probability and covariate shift can be corrected. However, the concept shift requires labeled target data since this type of shift is related to data drift, where classifiers are deployed in non-stationary environments [21].</p>
<p>The studied dataset, described in section 2, is expected to contain a covariate shift between the source and target domain. In this case, the two related domains, described by the same input and output space X and Y, have an equivalent posterior distribution p(x|y), but different probability input distributions p(x).</p>
<p>Domain Adaptation with Adversarial Network</p>
<p>Domain adaptation is achieved by training a model on labeled data S from a source domain D S while minimizing test error on a target domain D T , for which no labels in the target data T are available at training time. Driven by a simple assumption, the source risk R DS is expected to be a good indicator of the target risk R DT when both distributions are similar. This approach is validated by the theory obtained by Ben David et al. [17,22], proving that for an effective domain transfer to be achieved, predictions must be made based on a data representation that cannot discriminate between the source and target domains.</p>
<p>Several DA approaches implement this idea of domain similarity space (feature alignment) in the context of neural network architectures, by minimizing statistical distance between distributions [23,24] or by adversarial domain alignment [25,26].</p>
<p>A Domain-Adversarial Neural Network (DANN) [25] represents an appropriate approach to learn a HEP classifier that can generalize well from simulation to real experimental context. It consists in a feed-forward network with added standard layers and a gradient reversal layer.</p>
<p>This method is easy to implement since DANN can be trained with standard backpropagation and stochastic gradient descent (available in every deep learning libraries), less time-consuming with respect to domain distribution alignment with statistical distance minimization and can easy handle weighted examples, which motivated the use of this approach in the current HEP data analysis. The feature alignment can then be performed with the control process: in the DANN, the network hidden layer working adversarially towards output connections predicting domain membership learns from control process examples instead of the process-of-interest examples.</p>
<p>Experiment and results</p>
<p>To demonstrate the performance of DANN on LHCb dataset, we trained a benchmark classifier based on standard feedforward neural network, containing one input layer with the size of the input space, one hidden layer with 100 neurons and an output layer with two neurons. In this architecture, we use hyperbolic tangent as activation function and the cross-entropy as a cost function. In the other hand, the DANN model is designed with the same architecture of the benchmark model but in addition to the output layer, the hidden layer is linked to a gradient reversal layer with two output neurons used to classify the domain (simulation or real data) using control channel examples. Both ML architectures are trained using standard backpropagation and stochastic gradient-based optimizer</p>
<p>Adam. The standard NN is trained only on the training dataset and the DANN is trained on training (class) and control (domain) data.</p>
<p>For both classification tasks, with and without adversarial network, the datasets are split into two subsets, one for the training, containing 70% of the initial data, and one for the evaluation, named testing dataset. During the optimization, the training dataset is divided into 22 batches with size of 3000 examples. Figure 1 shows the evolution of the accuracy for both models function of the epoch iteration. Simply based on accuracy and convergence speed, the NN classifier outperforms the DANN classifier, with an accuracy of 88.1% against 84.0% on simulation as shown by Figure 1.</p>
<p>To ensure the conservation of these performances with real data, a Kolmogorov Smirnov distance between the output probability distributions of the classifiers on source and target for the process of interest (displayed in Figure 1) must be found below 0.09: for the standard NN, the distance is 0.19 and for the DANN, it is 0.06. The performances of the DANN-classifier are therefore conserved between simulation and experimental data while they are not for the standard NN. </p>
<p>Conclusion</p>
<p>Since HEP simulation is never exactly representative of experiments, a robust characterization of the ML classifier performances on unlabeled real data is hard to achieve. Such a characterization being mandatory for publication, domain adaptation from HEP simulation to real HEP experimental data is essential.</p>
<p>In this paper, we categorized the possible sources of dataset shifts between simulation and real data in a realistic HEP data challenge. Domain adaptation is achieved by training a DANN: trained with a control physics process with similar geometry as the process-of-interest, its adversarial part ensures that the resulting ML classifier is as little biased as possible by shifts between simulation and reality.</p>
<p>A Kolmogorov-Smirnov test between the output probability distribution of the classifier on simulation and on real data for the process-of-interest confirms that the classifier is unbiased and, therefore, its performances are identical on simulation and real data unlike a standard NN-classifier. In other words, any signal found in the experimental data by the DANN-classifier would be directly validated as a discovery of physics beyond the standard model.</p>
<p>Figure 1 :
1Left: Accuracy values along NN (top) and DANN (bottom) models optimization. Right: Output prediction probability using trained NN (top) and DANN (bottom). The overlap of source and target curve for DANN demonstrates the effectiveness of the domain adaptation.
Flavours of Physics: finding τ → µµµ. www.kaggle.com/c/flavours-of-physics/overview Second Workshop on Machine Learning and the Physical Sciences (NeurIPS 2019), Vancouver, Canada.</p>
<p>LHC machine. Lyndon Evans, Philip Bryant, Journal of Instrumentation. 308Lyndon Evans and Philip Bryant. LHC machine. Journal of Instrumentation, 3(08):S08001- S08001, aug 2008.</p>
<p>The LHCb Detector at the LHC. A Alves, Jr , JINST. 38005A. Augusto Alves, Jr. et al. The LHCb Detector at the LHC. JINST, 3:S08005, 2008.</p>
<p>splot: A quick introduction. Muriel Pivk, Physics. Muriel Pivk. splot: A quick introduction. Physics, 2006.</p>
<p>Image style transfer using convolutional neural networks. Leon A Gatys, Alexander S Ecker, Matthias Bethge, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge. Image style transfer using convolu- tional neural networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.</p>
<p>Domain adaptation for object recognition: An unsupervised approach. R Gopalan, Ruonan Li, R Chellappa, 2011 International Conference on Computer Vision. R. Gopalan, Ruonan Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised approach. In 2011 International Conference on Computer Vision, pages 999-1006, Nov 2011.</p>
<p>Learning and transferring midlevel image representations using convolutional neural networks. Maxime Oquab, Leon Bottou, Ivan Laptev, Josef Sivic, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Maxime Oquab, Leon Bottou, Ivan Laptev, and Josef Sivic. Learning and transferring mid- level image representations using convolutional neural networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2014.</p>
<p>Domain adaptation for large-scale sentiment classification: A deep learning approach. Xavier Glorot, Antoine Bordes, Yoshua Bengio, Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML'11. the 28th International Conference on International Conference on Machine Learning, ICML'11USAOmnipressXavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment classification: A deep learning approach. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML'11, pages 513-520, USA, 2011. Omnipress.</p>
<p>Deep learning for emotion recognition on small datasets using transfer learning. Hong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis, Stefan Winkler, Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, ICMI '15. the 2015 ACM on International Conference on Multimodal Interaction, ICMI '15New York, NY, USAACMHong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis, and Stefan Winkler. Deep learning for emotion recognition on small datasets using transfer learning. In Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, ICMI '15, pages 443-449, New York, NY, USA, 2015. ACM.</p>
<p>Sim-to-real transfer of robotic control with dynamics randomization. X B Peng, M Andrychowicz, W Zaremba, P Abbeel, 2018 IEEE International Conference on Robotics and Automation (ICRA). X. B. Peng, M. Andrychowicz, W. Zaremba, and P. Abbeel. Sim-to-real transfer of robotic control with dynamics randomization. In 2018 IEEE International Conference on Robotics and Automation (ICRA), pages 1-8, May 2018.</p>
<p>Sim-to-real robot learning from pixels with progressive nets. Andrei A Rusu, Matej Vecerik, Thomas Rothörl, Nicolas Heess, Razvan Pascanu, Raia Hadsell, abs/1610.04286CoRRAndrei A. Rusu, Matej Vecerik, Thomas Rothörl, Nicolas Heess, Razvan Pascanu, and Raia Hadsell. Sim-to-real robot learning from pixels with progressive nets. CoRR, abs/1610.04286, 2016.</p>
<p>Sim-to-real transfer learning using robustified controllers in robotic tasks involving complex dynamics. Alan Jeroen Van Baar, Radu Sullivan, Cordorel, K Devesh, Diego Jha, Daniel Romeres, Nikovski, abs/1809.04720CoRRJeroen van Baar, Alan Sullivan, Radu Cordorel, Devesh K. Jha, Diego Romeres, and Daniel Nikovski. Sim-to-real transfer learning using robustified controllers in robotic tasks involving complex dynamics. CoRR, abs/1809.04720, 2018.</p>
<p>Sim-to-real transfer with neural-augmented robot simulation. Florian Golemo, Adrien Ali Taiga, Aaron Courville, Pierre-Yves Oudeyer, PMLRProceedings of The 2nd Conference on Robot Learning. Aude Billard, Anca Dragan, Jan Peters, and Jun MorimotoThe 2nd Conference on Robot Learning87Florian Golemo, Adrien Ali Taiga, Aaron Courville, and Pierre-Yves Oudeyer. Sim-to-real transfer with neural-augmented robot simulation. In Aude Billard, Anca Dragan, Jan Peters, and Jun Morimoto, editors, Proceedings of The 2nd Conference on Robot Learning, volume 87 of Proceedings of Machine Learning Research, pages 817-828. PMLR, 29-31 Oct 2018.</p>
<p>Transfer learning to model inertial confinement fusion experiments. Kelli D Humbird, Jayson Luc Peterson, Ryan G Mcclarren, abs/1812.06055CoRRKelli D. Humbird, Jayson Luc Peterson, and Ryan G. McClarren. Transfer learning to model inertial confinement fusion experiments. CoRR, abs/1812.06055, 2018.</p>
<p>Using transfer learning to detect galaxy mergers. Sandro Ackermann, Kevin Schawinski, Ce Zhang, Anna K Weigel, M Dennis Turp, Monthly Notices of the Royal Astronomical Society. 479Sandro Ackermann, Kevin Schawinski, Ce Zhang, Anna K Weigel, and M Dennis Turp. Using transfer learning to detect galaxy mergers. Monthly Notices of the Royal Astronomical Society, 479:415-425, 09 2018.</p>
<p>Deep learning at scale for the construction of galaxy catalogs in the dark energy survey. Asad Khan, E A Huerta, Sibo Wang, Robert Gruendl, Elise Jennings, Huihuo Zheng, Physics Letters B. 795Asad Khan, E.A. Huerta, Sibo Wang, Robert Gruendl, Elise Jennings, and Huihuo Zheng. Deep learning at scale for the construction of galaxy catalogs in the dark energy survey. Physics Letters B, 795:248 -258, 2019. ISSN 0370-2693.</p>
<p>Classification and unsupervised clustering of ligo data with deep transfer learning. Daniel George, Hongyu Shen, E A Huerta, Phys. Rev. D. 97101501Daniel George, Hongyu Shen, and E. A. Huerta. Classification and unsupervised clustering of ligo data with deep transfer learning. Phys. Rev. D, 97:101501, May 2018.</p>
<p>A theory of learning from different domains. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman Vaughan, Machine Learning. 79Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jen- nifer Wortman Vaughan. A theory of learning from different domains. Machine Learning, 79 (1):151-175, May 2010.</p>
<p>Visual domain adaptation: A survey of recent advances. M Vishal, Raghuraman Patel, Ruonan Gopalan, Rama Li, Chellappa, IEEE Signal Processing Magazine. 32Vishal M. Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation: A survey of recent advances. IEEE Signal Processing Magazine, 32:53-69, 2015.</p>
<p>A survey on transfer learning. Qiang Sinno Jialin Pan, Yang, IEEE Trans. on Knowl. and Data Eng. 2210Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans. on Knowl. and Data Eng., 22(10):1345-1359, October 2010.</p>
<p>Dataset shift in machine learning. Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, Neil D Lawrence, 01Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. Dataset shift in machine learning. 01 2009.</p>
<p>Learning in the presence of concept drift and hidden contexts. Gerhard Widmer, Miroslav Kubat, Machine Learning. 23Gerhard Widmer and Miroslav Kubat. Learning in the presence of concept drift and hidden contexts. Machine Learning, 23(1):69-101, Apr 1996.</p>
<p>Analysis of representations for domain adaptation. Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, Advances in Neural Information Processing Systems. B. Schölkopf, J. C. Platt, and T. HoffmanMIT Press19Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In B. Schölkopf, J. C. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 137-144. MIT Press, 2007.</p>
<p>Learning transferable features with deep adaptation networks. Mingsheng Long, Yue Cao, Jianmin Wang, Michael Jordan, PMLRProceedings of the 32nd International Conference on Machine Learning. Francis Bach and David Bleithe 32nd International Conference on Machine LearningLille, France37Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation networks. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37, pages 97-105, Lille, France, 07-09 Jul 2015. PMLR.</p>
<p>Deep CORAL: correlation alignment for deep domain adaptation. Baochen Sun, Kate Saenko, abs/1607.01719CoRRBaochen Sun and Kate Saenko. Deep CORAL: correlation alignment for deep domain adaptation. CoRR, abs/1607.01719, 2016.</p>
<p>Unsupervised Domain Adaptation by Backpropagation. Yaroslav Ganin, Victor Lempitsky, arXiv:1409.7495arXiv e-prints, artYaroslav Ganin and Victor Lempitsky. Unsupervised Domain Adaptation by Backpropagation. arXiv e-prints, art. arXiv:1409.7495, Sep 2014.</p>
<p>Simultaneous deep transfer across domains and tasks. Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko, abs/1510.02192CoRREric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks. CoRR, abs/1510.02192, 2015.</p>            </div>
        </div>

    </div>
</body>
</html>