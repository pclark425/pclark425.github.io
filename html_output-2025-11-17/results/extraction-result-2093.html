<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2093 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2093</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2093</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-53.html">extraction-schema-53</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <p><strong>Paper ID:</strong> paper-278636629</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.10012v1.pdf" target="_blank">Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering</a></p>
                <p><strong>Paper Abstract:</strong> Recent advances in artificial intelligence (AI) and quantum computing are accelerating automation in scientific and engineering processes, fundamentally reshaping research methodologies. This perspective highlights parallels between scientific automation and established Computer-Aided Engineering (CAE) practices, introducing Quantum CAE as a framework that leverages quantum algorithms for simulation, optimization, and machine learning within engineering design. Practical implementations of Quantum CAE are illustrated through case studies for combinatorial optimization problems. Further discussions include advancements toward higher automation levels, highlighting the critical role of specialized AI agents proficient in quantum algorithm design. The integration of quantum computing with AI raises significant questions about the collaborative dynamics among human scientists and engineers, AI systems, and quantum computational resources, underscoring a transformative future for automated discovery and innovation.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2093.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2093.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>digital scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>digital scientist (coined)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conceptual AI/agent that conducts research tasks within computational environments (hypothesis generation, experiment design, simulation, analysis, manuscript drafting) under human-defined objectives; presented here as a way to frame scientific automation levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>digital scientist (concept)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>mixed — autonomous agent / pipeline (conceptual)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific research / computational science</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses, experimental protocols, simulation configurations, manuscripts</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>not quantified in this paper; envisioned to range from incremental to highly novel depending on agent capability and domain</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>automated hypothesis generation via optimization/search over hypothesis/design space, model-based prediction, and generative models as components of an agentic pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>simulation or computational experiments where possible, laboratory experiments where needed, and human expert review; iterated simulation-then-model-update cycles are recommended</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>not reported (this paper is a perspective; no empirical metrics provided)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>not reported in quantitative terms; authors state validation capacity depends strongly on domain (easier where first-principles simulation is available)</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>not quantified; paper argues validation reliability generally decreases as novelty increases because validation often requires more expensive or unavailable experiments/simulations</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper argues an asymmetry: generation (idea/candidate creation) can be automated and scaled faster than validation, especially for novel/out-of-distribution outputs; no quantitative comparison provided</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Discussed at a high level — recommends use of probabilistic models and iterative model updates; no specific uncertainty metrics reported</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported; paper highlights challenges validating transformational or out-of-distribution discoveries</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — paper describes use of proxy metrics in design automation (cost functions, QUBO objective values, simulation-derived characteristics, plausibility/feasibility constraints)</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not numerically specified; paper suggests humans remain necessary at Level 3 oversight and would be required more frequently as outputs become more novel (Levels 4–5 need further work)</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>varies by domain — ranges from 'highly formal' (e.g., mathematics) to 'empirical' (e.g., drug discovery); paper notes better automatic validation in domains with strong first-principles simulators</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Iterative simulation+model update loops, probabilistic/distributional modeling (BOCS) vs point-estimate models (FM), developing specialized agents (quantum-algorithm specialists), integrating quantum simulation and ML, and human-in-the-loop oversight</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Qualitative arguments: (1) encoding classical data into quantum states and extracting information is exponentially costly in worst case, limiting validation throughput; (2) prediction-model construction can become a bottleneck as quantum annealers scale; (3) paper explicitly states generation (automated hypothesis/design candidate creation) can outpace validation resources</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Examples where validation is tractable: materials science workflows using first-principles calculations can be fully computational and hence validate automatically; case studies (e.g., PCB mounting optimization, noise filter design) show automated optimization methods finding practical, validated solutions</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; qualitatively stated that validation (simulation or experiment) is often more computationally and resource expensive than generation, and this ratio may increase with output novelty due to more expensive simulations or need for physical experiments</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2093.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientist (King et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early embodied automation system that generated hypotheses in functional genomics, designed and executed laboratory experiments to test them, and analyzed results, demonstrating automated wet-lab hypothesis-to-validation cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>robot scientist (King et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>robotic automation integrating hypothesis-generation algorithms with laboratory robotics and data-analysis pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>functional genomics / experimental biology</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses and experimental results</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>demonstrated ability to generate nontrivial hypotheses within the explored experimental domain (paper cites this work as Level 3 automation); novelty quantified in original King et al. paper, not in this perspective</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>rule- and model-based hypothesis generation using domain knowledge and experimental data; closed-loop design of experiments</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>automated physical experiments executed by laboratory robots and subsequent data analysis</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>not reported here; original cited work demonstrated practical hypothesis generation but this perspective gives no quantitative rates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>not reported in this paper; original work validated hypotheses experimentally, demonstrating successful closures of hypothesis-experiment loops</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not quantified here; implicit point that physical experiment validation constrains novelty because experiments are costly/time-consuming</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper uses King et al. as an example where generation and validation were integrated successfully (closed-loop), but notes such systems remain Level 3 and require human oversight; implies validation throughput limited by experimental costs</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not described in this perspective; original robot scientist incorporated statistical analysis for experimental results (not quantified here)</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported here</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>No — validation was direct experimental measurement rather than proxy</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Human oversight recommended (Level 3); exact frequency not specified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (wet-lab biology)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Closed-loop laboratory automation to couple generation and validation directly; human oversight to handle ambiguous outcomes</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Perspective notes such systems are demonstrative but limited to Level 3; scaling to higher autonomy is restricted by experimental cost and complexity</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>The King et al. example itself shows that generation and validation can be integrated in practice within a domain</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not reported; experimental validation (wet lab) is implied to be substantially costlier/time-consuming than computational generation</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2093.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Highly accurate protein structure prediction with AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning system for protein structure prediction that produced highly accurate models of protein 3D structure from sequence, cited here as an example of AI-driven scientific impact.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Highly accurate protein structure prediction with alphafold</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>deep learning model (neural network-based structure predictor)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>structural biology / computational protein folding</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>predicted protein 3D structures</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>substantially novel relative to prior computational methods; produced near-experimental accuracy on many targets (as reported in the AlphaFold paper, but not re-reported here)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>end-to-end neural network trained on sequence and structural databases, leveraging attention/representation learning to predict coordinates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>comparison against experimentally-determined structures (e.g., CASP benchmarks) and downstream biochemical/biophysical validation; referenced as evidence of AI impact in science</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>not quantified in this perspective (original AlphaFold paper reports high accuracy on CASP with specific metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>not quantified here; original work reported GDT/other structural accuracy metrics</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not discussed in detail here; AlphaFold cited as example of AI producing high-quality, practically useful novel predictions that have been experimentally validated</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>AlphaFold is presented as an instance where generation quality (predicted structures) matched experimental validation sufficiently to be broadly useful, showing generation can in some domains meet validation standards</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>AlphaFold includes predicted LDDT/confidence measures in its outputs (not re-described quantitatively in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported here; original AlphaFold includes per-residue confidence estimates which serve as calibration indicators</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported in this perspective</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Comparison to experimental structures (ground truth) — direct validation rather than proxy</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified; in practice experimental confirmation is used for critical cases</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>semi-formal — computational predictions compared to experimental ground truth</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Providing confidence scores with predictions; integration with experimental validation pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Paper cites AlphaFold as an example where AI accelerated discovery but does not present AlphaFold as evidence of a validation gap; rather it demonstrates successful bridging when reliable validation is available</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>AlphaFold is used as a counterexample showing generation can match validation standards when ground-truth data and strong models exist</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not reported here</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2093.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BOCS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Optimization of Combinatorial Structures (BOCS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A combinatorial Bayesian optimization method that constructs probabilistic prediction models by sampling posterior distributions over model parameters to search discrete design spaces efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bayesian optimization of combinatorial structures</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BOCS (Bayesian optimization of combinatorial structures)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic surrogate-model-based optimizer (Bayesian optimization for discrete spaces)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>combinatorial design optimization / engineering design</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>candidate discrete designs (e.g., layouts, selection of design variables)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>aimed at exploring combinatorial spaces; novelty depends on exploration strategy — distribution-based modeling promotes exploratory, potentially more novel candidate proposals relative to point-estimate methods</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>posterior-sampling over model parameters and acquisition-driven selection over discrete design variables (BOCS uses probabilistic modelling akin to Gaussian process but for discrete structures)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>evaluated/costed via simulation or domain-specific evaluation functions (e.g., FEM/CFD or domain cost functions in cited applications)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>This paper reports qualitative statements: BOCS facilitates broader exploratory search and can find feasible solutions efficiently; no quantitative generation metrics reported here</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantitatively reported in this perspective; validation conducted via simulations in the cited case studies</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>BOCS's distribution-based modeling is argued to better support exploration and thus potentially higher novelty outputs, but no quantitative tradeoff/validation accuracy vs novelty is provided</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper contrasts BOCS (distributional) with FMQA (point-estimate) and notes exploration-exploitation tradeoffs affecting novelty and validation difficulty; no numerical gap reported</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Yes — BOCS models posterior distributions over parameters, enabling probabilistic uncertainty estimates that guide exploration</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported here</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — uses surrogate model predictions and acquisition functions as proxies to select candidates for (costly) simulation validation</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified; human oversight implied in Level 3 workflows</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>engineering design (semi-formal; simulation-based validation available in many cases)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Use of probabilistic/distributional models to maintain exploration and avoid premature convergence to local optima, thereby improving discovery of feasible/practical designs</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors note prediction-model construction may become a bottleneck as optimization hardware scales, implying potential gaps between candidate generation and ability to validate them rapidly</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Case studies referenced show BOCS finding practical solutions validated by simulation, indicating validation can keep pace in some problems</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; paper suggests that constructing surrogate models and running simulations for validation are significant costs but gives no ratio</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2093.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FMQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Factorization Machine Quantum Annealing (FMQA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid method combining Factorization Machines as surrogate prediction models with quantum annealing for optimization to solve discrete design problems with faster convergence from fewer data points but higher risk of local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Designing metamaterials with quantum annealing and factorization machines</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FMQA (Factorization Machine + Quantum Annealing)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>hybrid surrogate model (factorization machine) + quantum annealer for optimization</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>combinatorial materials/design optimization</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>candidate discrete designs (e.g., metamaterial layouts, component placements)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>typically finds high-quality solutions efficiently; novelty characterized as potentially lower exploratory diversity compared to distributional methods because FM uses point estimation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>train factorization-machine surrogate from limited data (point estimates) and use quantum annealer to search the surrogate's landscape for optimization candidates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>simulation-based evaluation of candidate designs (domain-specific simulation tools) and iterative data acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Paper states FM converges faster with fewer data points (qualitative); no numerical success/diversity metrics provided in this perspective</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantitatively reported; validated via simulations in cited case studies</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>FMQA's point-estimate approach risks converging to local optima, which can reduce novel/out-of-distribution candidate generation and thus may make validation easier but less exploratory; no metrics provided</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Qualitative comparison: FMQA faster at convergence but may produce less novel candidates than BOCS, implying differing validation burdens</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Limited — FM uses point estimation rather than full posterior distributions, so explicit uncertainty estimates are reduced compared to BOCS</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — uses surrogate model outputs as proxies (FM predictions) to select candidates for costly simulation validation</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>engineering/materials design (semi-formal with simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Combine FM surrogate with iterative data acquisition and possibly hybridize with distributional methods to balance exploration</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Point-estimate surrogates may under-represent uncertainty, increasing the risk that generated candidates appear promising but fail validation when evaluated with more accurate simulations or experiments</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Case studies reported practical success of FMQA in finding viable designs validated by simulations (paper cites successful applications)</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2093.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Quantum annealing / Ising solvers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Quantum annealing / Ising solver approaches used for combinatorial optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Quantum annealers and Ising-model solvers are used as optimization engines to generate candidate designs (encoded as QUBO/Ising problems) for discrete-variable engineering and scientific problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>quantum annealer / Ising solver</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>quantum annealing hardware / Ising-model solver (specialized quantum or quantum-inspired hardware)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>combinatorial optimization across engineering, materials, chemistry, drug design</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>optimized discrete configurations / candidate solutions (encoded as QUBO/Ising states)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>capable of finding high-quality combinatorial solutions; novelty depends on problem encoding and annealer scale — paper notes practical benefits at small scales and potential scaling advantages</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>map discrete optimization problem to QUBO/Ising Hamiltonian and use annealing (or simulated annealing / digital annealer) to sample low-energy (high-quality) solutions</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>candidates evaluated by domain-specific simulations or experimental tests; sometimes integrated with surrogate-assisted black-box optimization loops</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Paper describes successful small-scale demonstrations and practical benefits but provides no quantitative metrics for solution quality, speed, or success rates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantitatively reported; validation done via simulations in cited case studies</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not reported quantitatively; paper cautions that as annealers scale, surrogate/modeling and validation may become bottlenecks</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper points out potential mismatch: annealers can generate many candidate states quickly, but validating them (simulations, experiments, or extracting classical info from quantum states) can be costly and limit throughput</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not described in this perspective; individual annealer-based workflows may include sampling statistics as implicit uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — QUBO objective values and energy levels from annealer used as proxies for candidate quality prior to full validation</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified; implied necessary especially for novel candidates</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>engineering and applied sciences (semi-formal; relies on mapping to combinatorial formulations)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Hybrid approaches integrating annealing outputs with quantum-gate processing, using annealers to propose states with reduced rejection in Monte Carlo, and improving surrogate models to reduce wasted validation effort</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors note prediction-model construction and data-extraction/encoding costs could become bottlenecks as annealer scale grows, creating a generation-validation gap</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Numerous small-scale practical successes in case studies showing annealers can produce useful validated designs</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; qualitatively validation (simulation/experimental) and data encoding/extraction can dominate cost</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2093.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GQE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Quantum Eigensolver (GQE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative-model-driven method that uses a decoder-only Transformer to automatically design quantum circuits aimed at preparing molecular ground states, demonstrating automated quantum circuit generation for scientific outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The generative quantum eigensolver (gqe) and its application for ground state search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Generative Quantum Eigensolver (GQE)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>generative model (decoder-only Transformer) producing quantum circuits</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>quantum chemistry / quantum algorithm design</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>quantum circuit designs intended to prepare molecular ground states (quantum states) and thus predictions of ground-state energies</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>Designed to produce novel circuit ansätze tailored to targets; novelty depends on model capacity and training data — no quantitative novelty metrics provided here</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Transformer-based decoder generates parameterized quantum-circuit structures conditioned on objectives; generation guided by a learned mapping from objectives to circuit templates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Validation via quantum-circuit simulators and evaluation of ground-state energies; reinforcement learning or performance-guided training was used in related circuit-generation work</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Paper states GQE can compute molecular ground states via automated circuit generation (cites original arXiv work); no numeric performance metrics presented in this perspective</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantified here; validation in cited work performed with simulators comparing energies to reference values</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not reported; paper indicates performance assessments using simulators guide RL strategies but no numeric trend vs novelty</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper indicates generated circuits are evaluated using simulators and that performance-guided RL loops are used to close the loop; no explicit discussion of asymmetry magnitude</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not described here; validation uses simulator evaluation metrics rather than uncertainty estimates</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — simulator-calculated ground-state energy and circuit-simulator fidelity act as proxies for circuit quality</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>semi-formal (quantum chemistry with rigorous simulation tools but also approximations)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Use of simulator-based performance feedback and reinforcement learning to improve generated circuits; integration of domain-specific validators in the training loop</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>The need for simulator-guided RL suggests generation is easy but high-fidelity validation requires expensive simulation; paper warns about data encoding/extraction costs in quantum workflows</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Demonstrations where generated circuits are validated by simulators show that, at least at small scales, generation and validation can be effectively coupled</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; simulating quantum circuits for validation can be computationally expensive relative to circuit generation</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2093.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Minami et al. generative circuit agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI agent that autonomously generates quantum circuits for solving combinatorial optimization problems by encoding QUBO matrices as graphs, using a GNN encoder and Transformer decoder, and training with simulator-guided reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GNN+Transformer quantum-circuit generator (Minami et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>encoder-decoder neural network (GNN encoder + Transformer decoder) trained with reinforcement learning using quantum circuit simulators</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>quantum algorithm design / combinatorial optimization</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>quantum circuit ansätze intended to solve QUBO/combinatorial problems</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>Designed to generate novel circuit architectures for given optimization instances; novelty metrics not provided in this perspective</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Graph encoding of QUBO matrices (GNN) followed by Transformer decoding to generate circuit descriptions; reinforcement learning guided by simulator performance</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Performance assessment using quantum-circuit simulators (simulated objective values) to guide RL and evaluate candidate circuits</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Paper reports that performance assessments using simulators guided RL strategies, demonstrating the agent's effectiveness qualitatively; no numeric success rates provided here</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantitatively reported in this perspective; validation done via simulators in the cited work</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not reported; simulation-guided RL implies validation performance depends on simulator fidelity and thus may degrade for circuits targeting larger/out-of-distribution instances</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper notes the agent generates circuits and uses simulators for validation, indicating a coupled loop; also highlights potential bottlenecks as problem sizes scale</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not discussed explicitly; simulator performance used as objective feedback rather than probabilistic uncertainty estimates</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — simulator-provided objective or reward functions serve as proxy validation metrics during training</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>semi-formal (quantum algorithm design with simulator-based evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Use of simulator-guided reinforcement learning, architectural inductive biases (GNN encoder for graphs), and integrating domain knowledge to improve generator reliability</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors comment that simulator-based validation is used because real quantum hardware/simulation at scale is costly, implying generation may outpace feasible validation as problem size grows</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Simulated demonstrations show the approach can produce valid/performant circuits at small-to-moderate scales</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; implies validation (simulation of candidate circuits) is more costly than generating candidate circuit descriptions</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2093.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sakka et al. LLM feature-map design</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automating quantum feature map design via large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI scientist workflow that uses large language models to propose quantum feature-map designs, implement and validate code, and analyze results — demonstrating LLMs used to automate algorithmic idea generation and validation in quantum ML.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automating quantum feature map design via large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-driven quantum feature-map generator (Sakka et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language model (LLM) used as a generative agent combined with code execution and analysis loops</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>quantum machine learning / quantum algorithm design</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>conceptual algorithmic ideas and executable code (quantum feature maps), experimental results and analyses</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>LLMs can propose novel algorithmic designs; precise novelty characterization not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM prompts and generative outputs to propose designs, followed by implementation (code) and empirical testing</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Implementing and running generated code (simulators/hardware) and analyzing results; end-to-end workflow where generation and immediate code validation are coupled</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Not reported quantitatively in this perspective; paper cites Sakka et al. as a practical example of AI-driven idea generation and in-situ validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Not quantified here; validation achieved by executing code and analyzing outputs in cited work</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not reported; however, immediate code execution feedback is used to assess viability, implying a loop that can expose poor novel proposals quickly</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>This example illustrates a tighter coupling between generation and validation (LLM generates code, code executed to validate), reducing but not eliminating the gap; no quantitative gap reported</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not described in perspective; LLMs typically do not provide calibrated uncertainties for generated code/ideas</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — empirical performance of generated code (simulation outputs, benchmark metrics) used as direct validation rather than mere plausibility</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Not specified; perspective suggests human oversight remains important</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>semi-formal (algorithm design with executable validation)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>End-to-end agent workflows that generate code and immediately validate by execution; integrating LLMs with execution environments to close the loop</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Paper highlights that even with such workflows, validation resources and simulator/hardware fidelity constrain scaling to more novel outputs</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>The cited Sakka et al. work provides a concrete example where generation and validation were directly coupled and effective in practice</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically reported; immediate code execution reduces the generation-to-validation turnaround but simulation/hardware costs still apply</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2093.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2093.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-authored papers passing peer review</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-authored or AI-assisted manuscripts passing peer review (cited examples)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Reports and studies showing AI agents have authored or co-authored manuscripts that could pass peer review, cited as evidence of AI capability to produce research outputs that meet community standards.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-authored manuscripts (various LLMs/agents)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language models / generative agents</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>scholarly communication / general research output generation</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>manuscripts, papers, reviews</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>varies; can produce coherent, novel text and claims but novelty relative to scientific content not quantified here</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM text generation trained on large corpora, sometimes integrated with tools for data analysis/code execution</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Peer review process and human editorial checks; sometimes empirical or code-based checks if included</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Not quantified here; perspective mentions instances of AI-authored papers passing peer review without giving metrics</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Peer review served as a validation step in cited anecdotes; no aggregated metrics are provided</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not analyzed quantitatively; concern expressed that superficial plausibility can pass peer review even for novel or incorrect claims</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper raises concern that generative capability (writing plausible manuscripts) can exceed critical validation capabilities (peer reviewers may not detect fabricated or incorrect claims), implying a fabrication-validation gap in scholarly publishing</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Generally absent in generated manuscripts unless the system is augmented with explicit uncertainty reporting</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>not reported</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — peer review and editorial checks act as proxies for scientific validity; these proxies can be imperfect</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Peer review is required for publication; frequency of additional human checks not specified</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>varies by field; social/scientific impact depends on domain</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Promoting human oversight, better tooling for reproducibility checks, and tighter integration of code/data verification in publication pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Anecdotal reports of AI-authored papers passing peer review are cited as evidence that generative quality may exceed the community's validation sensitivity</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>No systematic counter-evidence provided here; paper calls for dialogue and infrastructure to address validation needs</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not applicable / not reported</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with alphafold <em>(Rating: 2)</em></li>
                <li>Bayesian optimization of combinatorial structures <em>(Rating: 2)</em></li>
                <li>Designing metamaterials with quantum annealing and factorization machines <em>(Rating: 2)</em></li>
                <li>Application of qubo solver using black-box optimization to structural design for resonance avoidance <em>(Rating: 2)</em></li>
                <li>Design optimization of noise filter using quantum annealer <em>(Rating: 2)</em></li>
                <li>The generative quantum eigensolver (gqe) and its application for ground state search <em>(Rating: 2)</em></li>
                <li>Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver <em>(Rating: 2)</em></li>
                <li>Automating quantum feature map design via large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2093",
    "paper_id": "paper-278636629",
    "extraction_schema_id": "extraction-schema-53",
    "extracted_data": [
        {
            "name_short": "digital scientist",
            "name_full": "digital scientist (coined)",
            "brief_description": "A conceptual AI/agent that conducts research tasks within computational environments (hypothesis generation, experiment design, simulation, analysis, manuscript drafting) under human-defined objectives; presented here as a way to frame scientific automation levels.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "digital scientist (concept)",
            "system_type": "mixed — autonomous agent / pipeline (conceptual)",
            "scientific_domain": "general scientific research / computational science",
            "output_type": "scientific hypotheses, experimental protocols, simulation configurations, manuscripts",
            "novelty_level": "not quantified in this paper; envisioned to range from incremental to highly novel depending on agent capability and domain",
            "generation_method": "automated hypothesis generation via optimization/search over hypothesis/design space, model-based prediction, and generative models as components of an agentic pipeline",
            "validation_method": "simulation or computational experiments where possible, laboratory experiments where needed, and human expert review; iterated simulation-then-model-update cycles are recommended",
            "generation_performance": "not reported (this paper is a perspective; no empirical metrics provided)",
            "validation_performance": "not reported in quantitative terms; authors state validation capacity depends strongly on domain (easier where first-principles simulation is available)",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "not quantified; paper argues validation reliability generally decreases as novelty increases because validation often requires more expensive or unavailable experiments/simulations",
            "generation_validation_comparison": "Paper argues an asymmetry: generation (idea/candidate creation) can be automated and scaled faster than validation, especially for novel/out-of-distribution outputs; no quantitative comparison provided",
            "uncertainty_quantification": "Discussed at a high level — recommends use of probabilistic models and iterative model updates; no specific uncertainty metrics reported",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported; paper highlights challenges validating transformational or out-of-distribution discoveries",
            "validation_proxy_metrics": "Yes — paper describes use of proxy metrics in design automation (cost functions, QUBO objective values, simulation-derived characteristics, plausibility/feasibility constraints)",
            "human_validation_required": true,
            "human_validation_frequency": "Not numerically specified; paper suggests humans remain necessary at Level 3 oversight and would be required more frequently as outputs become more novel (Levels 4–5 need further work)",
            "formal_verification_used": null,
            "domain_formalization_level": "varies by domain — ranges from 'highly formal' (e.g., mathematics) to 'empirical' (e.g., drug discovery); paper notes better automatic validation in domains with strong first-principles simulators",
            "gap_mitigation_strategies": "Iterative simulation+model update loops, probabilistic/distributional modeling (BOCS) vs point-estimate models (FM), developing specialized agents (quantum-algorithm specialists), integrating quantum simulation and ML, and human-in-the-loop oversight",
            "evidence_supporting_gap": "Qualitative arguments: (1) encoding classical data into quantum states and extracting information is exponentially costly in worst case, limiting validation throughput; (2) prediction-model construction can become a bottleneck as quantum annealers scale; (3) paper explicitly states generation (automated hypothesis/design candidate creation) can outpace validation resources",
            "evidence_contradicting_gap": "Examples where validation is tractable: materials science workflows using first-principles calculations can be fully computational and hence validate automatically; case studies (e.g., PCB mounting optimization, noise filter design) show automated optimization methods finding practical, validated solutions",
            "computational_cost_ratio": "Not numerically reported; qualitatively stated that validation (simulation or experiment) is often more computationally and resource expensive than generation, and this ratio may increase with output novelty due to more expensive simulations or need for physical experiments",
            "uuid": "e2093.0"
        },
        {
            "name_short": "Robot Scientist (King et al.)",
            "name_full": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "brief_description": "An early embodied automation system that generated hypotheses in functional genomics, designed and executed laboratory experiments to test them, and analyzed results, demonstrating automated wet-lab hypothesis-to-validation cycles.",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "mention_or_use": "mention",
            "system_name": "robot scientist (King et al.)",
            "system_type": "robotic automation integrating hypothesis-generation algorithms with laboratory robotics and data-analysis pipelines",
            "scientific_domain": "functional genomics / experimental biology",
            "output_type": "scientific hypotheses and experimental results",
            "novelty_level": "demonstrated ability to generate nontrivial hypotheses within the explored experimental domain (paper cites this work as Level 3 automation); novelty quantified in original King et al. paper, not in this perspective",
            "generation_method": "rule- and model-based hypothesis generation using domain knowledge and experimental data; closed-loop design of experiments",
            "validation_method": "automated physical experiments executed by laboratory robots and subsequent data analysis",
            "generation_performance": "not reported here; original cited work demonstrated practical hypothesis generation but this perspective gives no quantitative rates",
            "validation_performance": "not reported in this paper; original work validated hypotheses experimentally, demonstrating successful closures of hypothesis-experiment loops",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not quantified here; implicit point that physical experiment validation constrains novelty because experiments are costly/time-consuming",
            "generation_validation_comparison": "Paper uses King et al. as an example where generation and validation were integrated successfully (closed-loop), but notes such systems remain Level 3 and require human oversight; implies validation throughput limited by experimental costs",
            "uncertainty_quantification": "Not described in this perspective; original robot scientist incorporated statistical analysis for experimental results (not quantified here)",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported here",
            "validation_proxy_metrics": "No — validation was direct experimental measurement rather than proxy",
            "human_validation_required": true,
            "human_validation_frequency": "Human oversight recommended (Level 3); exact frequency not specified",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (wet-lab biology)",
            "gap_mitigation_strategies": "Closed-loop laboratory automation to couple generation and validation directly; human oversight to handle ambiguous outcomes",
            "evidence_supporting_gap": "Perspective notes such systems are demonstrative but limited to Level 3; scaling to higher autonomy is restricted by experimental cost and complexity",
            "evidence_contradicting_gap": "The King et al. example itself shows that generation and validation can be integrated in practice within a domain",
            "computational_cost_ratio": "Not reported; experimental validation (wet lab) is implied to be substantially costlier/time-consuming than computational generation",
            "uuid": "e2093.1"
        },
        {
            "name_short": "AlphaFold",
            "name_full": "Highly accurate protein structure prediction with AlphaFold",
            "brief_description": "A deep learning system for protein structure prediction that produced highly accurate models of protein 3D structure from sequence, cited here as an example of AI-driven scientific impact.",
            "citation_title": "Highly accurate protein structure prediction with alphafold",
            "mention_or_use": "mention",
            "system_name": "AlphaFold",
            "system_type": "deep learning model (neural network-based structure predictor)",
            "scientific_domain": "structural biology / computational protein folding",
            "output_type": "predicted protein 3D structures",
            "novelty_level": "substantially novel relative to prior computational methods; produced near-experimental accuracy on many targets (as reported in the AlphaFold paper, but not re-reported here)",
            "generation_method": "end-to-end neural network trained on sequence and structural databases, leveraging attention/representation learning to predict coordinates",
            "validation_method": "comparison against experimentally-determined structures (e.g., CASP benchmarks) and downstream biochemical/biophysical validation; referenced as evidence of AI impact in science",
            "generation_performance": "not quantified in this perspective (original AlphaFold paper reports high accuracy on CASP with specific metrics)",
            "validation_performance": "not quantified here; original work reported GDT/other structural accuracy metrics",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not discussed in detail here; AlphaFold cited as example of AI producing high-quality, practically useful novel predictions that have been experimentally validated",
            "generation_validation_comparison": "AlphaFold is presented as an instance where generation quality (predicted structures) matched experimental validation sufficiently to be broadly useful, showing generation can in some domains meet validation standards",
            "uncertainty_quantification": "AlphaFold includes predicted LDDT/confidence measures in its outputs (not re-described quantitatively in this paper)",
            "calibration_quality": "Not reported here; original AlphaFold includes per-residue confidence estimates which serve as calibration indicators",
            "out_of_distribution_performance": "Not reported in this perspective",
            "validation_proxy_metrics": "Comparison to experimental structures (ground truth) — direct validation rather than proxy",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified; in practice experimental confirmation is used for critical cases",
            "formal_verification_used": false,
            "domain_formalization_level": "semi-formal — computational predictions compared to experimental ground truth",
            "gap_mitigation_strategies": "Providing confidence scores with predictions; integration with experimental validation pipelines",
            "evidence_supporting_gap": "Paper cites AlphaFold as an example where AI accelerated discovery but does not present AlphaFold as evidence of a validation gap; rather it demonstrates successful bridging when reliable validation is available",
            "evidence_contradicting_gap": "AlphaFold is used as a counterexample showing generation can match validation standards when ground-truth data and strong models exist",
            "computational_cost_ratio": "Not reported here",
            "uuid": "e2093.2"
        },
        {
            "name_short": "BOCS",
            "name_full": "Bayesian Optimization of Combinatorial Structures (BOCS)",
            "brief_description": "A combinatorial Bayesian optimization method that constructs probabilistic prediction models by sampling posterior distributions over model parameters to search discrete design spaces efficiently.",
            "citation_title": "Bayesian optimization of combinatorial structures",
            "mention_or_use": "mention",
            "system_name": "BOCS (Bayesian optimization of combinatorial structures)",
            "system_type": "probabilistic surrogate-model-based optimizer (Bayesian optimization for discrete spaces)",
            "scientific_domain": "combinatorial design optimization / engineering design",
            "output_type": "candidate discrete designs (e.g., layouts, selection of design variables)",
            "novelty_level": "aimed at exploring combinatorial spaces; novelty depends on exploration strategy — distribution-based modeling promotes exploratory, potentially more novel candidate proposals relative to point-estimate methods",
            "generation_method": "posterior-sampling over model parameters and acquisition-driven selection over discrete design variables (BOCS uses probabilistic modelling akin to Gaussian process but for discrete structures)",
            "validation_method": "evaluated/costed via simulation or domain-specific evaluation functions (e.g., FEM/CFD or domain cost functions in cited applications)",
            "generation_performance": "This paper reports qualitative statements: BOCS facilitates broader exploratory search and can find feasible solutions efficiently; no quantitative generation metrics reported here",
            "validation_performance": "Not quantitatively reported in this perspective; validation conducted via simulations in the cited case studies",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "BOCS's distribution-based modeling is argued to better support exploration and thus potentially higher novelty outputs, but no quantitative tradeoff/validation accuracy vs novelty is provided",
            "generation_validation_comparison": "Paper contrasts BOCS (distributional) with FMQA (point-estimate) and notes exploration-exploitation tradeoffs affecting novelty and validation difficulty; no numerical gap reported",
            "uncertainty_quantification": "Yes — BOCS models posterior distributions over parameters, enabling probabilistic uncertainty estimates that guide exploration",
            "calibration_quality": "Not reported here",
            "out_of_distribution_performance": "Not reported",
            "validation_proxy_metrics": "Yes — uses surrogate model predictions and acquisition functions as proxies to select candidates for (costly) simulation validation",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified; human oversight implied in Level 3 workflows",
            "formal_verification_used": false,
            "domain_formalization_level": "engineering design (semi-formal; simulation-based validation available in many cases)",
            "gap_mitigation_strategies": "Use of probabilistic/distributional models to maintain exploration and avoid premature convergence to local optima, thereby improving discovery of feasible/practical designs",
            "evidence_supporting_gap": "Authors note prediction-model construction may become a bottleneck as optimization hardware scales, implying potential gaps between candidate generation and ability to validate them rapidly",
            "evidence_contradicting_gap": "Case studies referenced show BOCS finding practical solutions validated by simulation, indicating validation can keep pace in some problems",
            "computational_cost_ratio": "Not numerically reported; paper suggests that constructing surrogate models and running simulations for validation are significant costs but gives no ratio",
            "uuid": "e2093.3"
        },
        {
            "name_short": "FMQA",
            "name_full": "Factorization Machine Quantum Annealing (FMQA)",
            "brief_description": "A hybrid method combining Factorization Machines as surrogate prediction models with quantum annealing for optimization to solve discrete design problems with faster convergence from fewer data points but higher risk of local optima.",
            "citation_title": "Designing metamaterials with quantum annealing and factorization machines",
            "mention_or_use": "mention",
            "system_name": "FMQA (Factorization Machine + Quantum Annealing)",
            "system_type": "hybrid surrogate model (factorization machine) + quantum annealer for optimization",
            "scientific_domain": "combinatorial materials/design optimization",
            "output_type": "candidate discrete designs (e.g., metamaterial layouts, component placements)",
            "novelty_level": "typically finds high-quality solutions efficiently; novelty characterized as potentially lower exploratory diversity compared to distributional methods because FM uses point estimation",
            "generation_method": "train factorization-machine surrogate from limited data (point estimates) and use quantum annealer to search the surrogate's landscape for optimization candidates",
            "validation_method": "simulation-based evaluation of candidate designs (domain-specific simulation tools) and iterative data acquisition",
            "generation_performance": "Paper states FM converges faster with fewer data points (qualitative); no numerical success/diversity metrics provided in this perspective",
            "validation_performance": "Not quantitatively reported; validated via simulations in cited case studies",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "FMQA's point-estimate approach risks converging to local optima, which can reduce novel/out-of-distribution candidate generation and thus may make validation easier but less exploratory; no metrics provided",
            "generation_validation_comparison": "Qualitative comparison: FMQA faster at convergence but may produce less novel candidates than BOCS, implying differing validation burdens",
            "uncertainty_quantification": "Limited — FM uses point estimation rather than full posterior distributions, so explicit uncertainty estimates are reduced compared to BOCS",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — uses surrogate model outputs as proxies (FM predictions) to select candidates for costly simulation validation",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified",
            "formal_verification_used": false,
            "domain_formalization_level": "engineering/materials design (semi-formal with simulation)",
            "gap_mitigation_strategies": "Combine FM surrogate with iterative data acquisition and possibly hybridize with distributional methods to balance exploration",
            "evidence_supporting_gap": "Point-estimate surrogates may under-represent uncertainty, increasing the risk that generated candidates appear promising but fail validation when evaluated with more accurate simulations or experiments",
            "evidence_contradicting_gap": "Case studies reported practical success of FMQA in finding viable designs validated by simulations (paper cites successful applications)",
            "computational_cost_ratio": "Not numerically reported",
            "uuid": "e2093.4"
        },
        {
            "name_short": "Quantum annealing / Ising solvers",
            "name_full": "Quantum annealing / Ising solver approaches used for combinatorial optimization",
            "brief_description": "Quantum annealers and Ising-model solvers are used as optimization engines to generate candidate designs (encoded as QUBO/Ising problems) for discrete-variable engineering and scientific problems.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "quantum annealer / Ising solver",
            "system_type": "quantum annealing hardware / Ising-model solver (specialized quantum or quantum-inspired hardware)",
            "scientific_domain": "combinatorial optimization across engineering, materials, chemistry, drug design",
            "output_type": "optimized discrete configurations / candidate solutions (encoded as QUBO/Ising states)",
            "novelty_level": "capable of finding high-quality combinatorial solutions; novelty depends on problem encoding and annealer scale — paper notes practical benefits at small scales and potential scaling advantages",
            "generation_method": "map discrete optimization problem to QUBO/Ising Hamiltonian and use annealing (or simulated annealing / digital annealer) to sample low-energy (high-quality) solutions",
            "validation_method": "candidates evaluated by domain-specific simulations or experimental tests; sometimes integrated with surrogate-assisted black-box optimization loops",
            "generation_performance": "Paper describes successful small-scale demonstrations and practical benefits but provides no quantitative metrics for solution quality, speed, or success rates",
            "validation_performance": "Not quantitatively reported; validation done via simulations in cited case studies",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not reported quantitatively; paper cautions that as annealers scale, surrogate/modeling and validation may become bottlenecks",
            "generation_validation_comparison": "Paper points out potential mismatch: annealers can generate many candidate states quickly, but validating them (simulations, experiments, or extracting classical info from quantum states) can be costly and limit throughput",
            "uncertainty_quantification": "Not described in this perspective; individual annealer-based workflows may include sampling statistics as implicit uncertainty",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — QUBO objective values and energy levels from annealer used as proxies for candidate quality prior to full validation",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified; implied necessary especially for novel candidates",
            "formal_verification_used": false,
            "domain_formalization_level": "engineering and applied sciences (semi-formal; relies on mapping to combinatorial formulations)",
            "gap_mitigation_strategies": "Hybrid approaches integrating annealing outputs with quantum-gate processing, using annealers to propose states with reduced rejection in Monte Carlo, and improving surrogate models to reduce wasted validation effort",
            "evidence_supporting_gap": "Authors note prediction-model construction and data-extraction/encoding costs could become bottlenecks as annealer scale grows, creating a generation-validation gap",
            "evidence_contradicting_gap": "Numerous small-scale practical successes in case studies showing annealers can produce useful validated designs",
            "computational_cost_ratio": "Not numerically reported; qualitatively validation (simulation/experimental) and data encoding/extraction can dominate cost",
            "uuid": "e2093.5"
        },
        {
            "name_short": "GQE",
            "name_full": "Generative Quantum Eigensolver (GQE)",
            "brief_description": "A generative-model-driven method that uses a decoder-only Transformer to automatically design quantum circuits aimed at preparing molecular ground states, demonstrating automated quantum circuit generation for scientific outputs.",
            "citation_title": "The generative quantum eigensolver (gqe) and its application for ground state search",
            "mention_or_use": "mention",
            "system_name": "Generative Quantum Eigensolver (GQE)",
            "system_type": "generative model (decoder-only Transformer) producing quantum circuits",
            "scientific_domain": "quantum chemistry / quantum algorithm design",
            "output_type": "quantum circuit designs intended to prepare molecular ground states (quantum states) and thus predictions of ground-state energies",
            "novelty_level": "Designed to produce novel circuit ansätze tailored to targets; novelty depends on model capacity and training data — no quantitative novelty metrics provided here",
            "generation_method": "Transformer-based decoder generates parameterized quantum-circuit structures conditioned on objectives; generation guided by a learned mapping from objectives to circuit templates",
            "validation_method": "Validation via quantum-circuit simulators and evaluation of ground-state energies; reinforcement learning or performance-guided training was used in related circuit-generation work",
            "generation_performance": "Paper states GQE can compute molecular ground states via automated circuit generation (cites original arXiv work); no numeric performance metrics presented in this perspective",
            "validation_performance": "Not quantified here; validation in cited work performed with simulators comparing energies to reference values",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not reported; paper indicates performance assessments using simulators guide RL strategies but no numeric trend vs novelty",
            "generation_validation_comparison": "Paper indicates generated circuits are evaluated using simulators and that performance-guided RL loops are used to close the loop; no explicit discussion of asymmetry magnitude",
            "uncertainty_quantification": "Not described here; validation uses simulator evaluation metrics rather than uncertainty estimates",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — simulator-calculated ground-state energy and circuit-simulator fidelity act as proxies for circuit quality",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified",
            "formal_verification_used": false,
            "domain_formalization_level": "semi-formal (quantum chemistry with rigorous simulation tools but also approximations)",
            "gap_mitigation_strategies": "Use of simulator-based performance feedback and reinforcement learning to improve generated circuits; integration of domain-specific validators in the training loop",
            "evidence_supporting_gap": "The need for simulator-guided RL suggests generation is easy but high-fidelity validation requires expensive simulation; paper warns about data encoding/extraction costs in quantum workflows",
            "evidence_contradicting_gap": "Demonstrations where generated circuits are validated by simulators show that, at least at small scales, generation and validation can be effectively coupled",
            "computational_cost_ratio": "Not numerically reported; simulating quantum circuits for validation can be computationally expensive relative to circuit generation",
            "uuid": "e2093.6"
        },
        {
            "name_short": "Minami et al. generative circuit agent",
            "name_full": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
            "brief_description": "An AI agent that autonomously generates quantum circuits for solving combinatorial optimization problems by encoding QUBO matrices as graphs, using a GNN encoder and Transformer decoder, and training with simulator-guided reinforcement learning.",
            "citation_title": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
            "mention_or_use": "mention",
            "system_name": "GNN+Transformer quantum-circuit generator (Minami et al.)",
            "system_type": "encoder-decoder neural network (GNN encoder + Transformer decoder) trained with reinforcement learning using quantum circuit simulators",
            "scientific_domain": "quantum algorithm design / combinatorial optimization",
            "output_type": "quantum circuit ansätze intended to solve QUBO/combinatorial problems",
            "novelty_level": "Designed to generate novel circuit architectures for given optimization instances; novelty metrics not provided in this perspective",
            "generation_method": "Graph encoding of QUBO matrices (GNN) followed by Transformer decoding to generate circuit descriptions; reinforcement learning guided by simulator performance",
            "validation_method": "Performance assessment using quantum-circuit simulators (simulated objective values) to guide RL and evaluate candidate circuits",
            "generation_performance": "Paper reports that performance assessments using simulators guided RL strategies, demonstrating the agent's effectiveness qualitatively; no numeric success rates provided here",
            "validation_performance": "Not quantitatively reported in this perspective; validation done via simulators in the cited work",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not reported; simulation-guided RL implies validation performance depends on simulator fidelity and thus may degrade for circuits targeting larger/out-of-distribution instances",
            "generation_validation_comparison": "Paper notes the agent generates circuits and uses simulators for validation, indicating a coupled loop; also highlights potential bottlenecks as problem sizes scale",
            "uncertainty_quantification": "Not discussed explicitly; simulator performance used as objective feedback rather than probabilistic uncertainty estimates",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — simulator-provided objective or reward functions serve as proxy validation metrics during training",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified",
            "formal_verification_used": false,
            "domain_formalization_level": "semi-formal (quantum algorithm design with simulator-based evaluation)",
            "gap_mitigation_strategies": "Use of simulator-guided reinforcement learning, architectural inductive biases (GNN encoder for graphs), and integrating domain knowledge to improve generator reliability",
            "evidence_supporting_gap": "Authors comment that simulator-based validation is used because real quantum hardware/simulation at scale is costly, implying generation may outpace feasible validation as problem size grows",
            "evidence_contradicting_gap": "Simulated demonstrations show the approach can produce valid/performant circuits at small-to-moderate scales",
            "computational_cost_ratio": "Not numerically reported; implies validation (simulation of candidate circuits) is more costly than generating candidate circuit descriptions",
            "uuid": "e2093.7"
        },
        {
            "name_short": "Sakka et al. LLM feature-map design",
            "name_full": "Automating quantum feature map design via large language models",
            "brief_description": "An AI scientist workflow that uses large language models to propose quantum feature-map designs, implement and validate code, and analyze results — demonstrating LLMs used to automate algorithmic idea generation and validation in quantum ML.",
            "citation_title": "Automating quantum feature map design via large language models",
            "mention_or_use": "mention",
            "system_name": "LLM-driven quantum feature-map generator (Sakka et al.)",
            "system_type": "large language model (LLM) used as a generative agent combined with code execution and analysis loops",
            "scientific_domain": "quantum machine learning / quantum algorithm design",
            "output_type": "conceptual algorithmic ideas and executable code (quantum feature maps), experimental results and analyses",
            "novelty_level": "LLMs can propose novel algorithmic designs; precise novelty characterization not provided here",
            "generation_method": "LLM prompts and generative outputs to propose designs, followed by implementation (code) and empirical testing",
            "validation_method": "Implementing and running generated code (simulators/hardware) and analyzing results; end-to-end workflow where generation and immediate code validation are coupled",
            "generation_performance": "Not reported quantitatively in this perspective; paper cites Sakka et al. as a practical example of AI-driven idea generation and in-situ validation",
            "validation_performance": "Not quantified here; validation achieved by executing code and analyzing outputs in cited work",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not reported; however, immediate code execution feedback is used to assess viability, implying a loop that can expose poor novel proposals quickly",
            "generation_validation_comparison": "This example illustrates a tighter coupling between generation and validation (LLM generates code, code executed to validate), reducing but not eliminating the gap; no quantitative gap reported",
            "uncertainty_quantification": "Not described in perspective; LLMs typically do not provide calibrated uncertainties for generated code/ideas",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — empirical performance of generated code (simulation outputs, benchmark metrics) used as direct validation rather than mere plausibility",
            "human_validation_required": true,
            "human_validation_frequency": "Not specified; perspective suggests human oversight remains important",
            "formal_verification_used": false,
            "domain_formalization_level": "semi-formal (algorithm design with executable validation)",
            "gap_mitigation_strategies": "End-to-end agent workflows that generate code and immediately validate by execution; integrating LLMs with execution environments to close the loop",
            "evidence_supporting_gap": "Paper highlights that even with such workflows, validation resources and simulator/hardware fidelity constrain scaling to more novel outputs",
            "evidence_contradicting_gap": "The cited Sakka et al. work provides a concrete example where generation and validation were directly coupled and effective in practice",
            "computational_cost_ratio": "Not numerically reported; immediate code execution reduces the generation-to-validation turnaround but simulation/hardware costs still apply",
            "uuid": "e2093.8"
        },
        {
            "name_short": "AI-authored papers passing peer review",
            "name_full": "AI-authored or AI-assisted manuscripts passing peer review (cited examples)",
            "brief_description": "Reports and studies showing AI agents have authored or co-authored manuscripts that could pass peer review, cited as evidence of AI capability to produce research outputs that meet community standards.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AI-authored manuscripts (various LLMs/agents)",
            "system_type": "large language models / generative agents",
            "scientific_domain": "scholarly communication / general research output generation",
            "output_type": "manuscripts, papers, reviews",
            "novelty_level": "varies; can produce coherent, novel text and claims but novelty relative to scientific content not quantified here",
            "generation_method": "LLM text generation trained on large corpora, sometimes integrated with tools for data analysis/code execution",
            "validation_method": "Peer review process and human editorial checks; sometimes empirical or code-based checks if included",
            "generation_performance": "Not quantified here; perspective mentions instances of AI-authored papers passing peer review without giving metrics",
            "validation_performance": "Peer review served as a validation step in cited anecdotes; no aggregated metrics are provided",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not analyzed quantitatively; concern expressed that superficial plausibility can pass peer review even for novel or incorrect claims",
            "generation_validation_comparison": "Paper raises concern that generative capability (writing plausible manuscripts) can exceed critical validation capabilities (peer reviewers may not detect fabricated or incorrect claims), implying a fabrication-validation gap in scholarly publishing",
            "uncertainty_quantification": "Generally absent in generated manuscripts unless the system is augmented with explicit uncertainty reporting",
            "calibration_quality": "not reported",
            "out_of_distribution_performance": "not reported",
            "validation_proxy_metrics": "Yes — peer review and editorial checks act as proxies for scientific validity; these proxies can be imperfect",
            "human_validation_required": true,
            "human_validation_frequency": "Peer review is required for publication; frequency of additional human checks not specified",
            "formal_verification_used": false,
            "domain_formalization_level": "varies by field; social/scientific impact depends on domain",
            "gap_mitigation_strategies": "Promoting human oversight, better tooling for reproducibility checks, and tighter integration of code/data verification in publication pipelines",
            "evidence_supporting_gap": "Anecdotal reports of AI-authored papers passing peer review are cited as evidence that generative quality may exceed the community's validation sensitivity",
            "evidence_contradicting_gap": "No systematic counter-evidence provided here; paper calls for dialogue and infrastructure to address validation needs",
            "computational_cost_ratio": "Not applicable / not reported",
            "uuid": "e2093.9"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "rating": 2
        },
        {
            "paper_title": "Highly accurate protein structure prediction with alphafold",
            "rating": 2
        },
        {
            "paper_title": "Bayesian optimization of combinatorial structures",
            "rating": 2
        },
        {
            "paper_title": "Designing metamaterials with quantum annealing and factorization machines",
            "rating": 2
        },
        {
            "paper_title": "Application of qubo solver using black-box optimization to structural design for resonance avoidance",
            "rating": 2
        },
        {
            "paper_title": "Design optimization of noise filter using quantum annealer",
            "rating": 2
        },
        {
            "paper_title": "The generative quantum eigensolver (gqe) and its application for ground state search",
            "rating": 2
        },
        {
            "paper_title": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
            "rating": 2
        },
        {
            "paper_title": "Automating quantum feature map design via large language models",
            "rating": 2
        }
    ],
    "cost": 0.0215265,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering
15 May 2025</p>
<p>Tadashi Kadowaki 
Global R&amp;D Center for Business by Quantum-AI Technology
National Institute of Advanced Industrial Science and Technology
IbarakiJapan</p>
<p>DENSO CORPORATION
TokyoJapan</p>
<p>Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering
15 May 2025B5AE5C65A7CB6CC2A24FE003C03B9510arXiv:2505.10012v1[quant-ph]AI4ScienceQuantum CAEComputer-Aided EngineeringDigital scientists
Recent advances in artificial intelligence (AI) and quantum computing are accelerating automation in scientific and engineering processes, fundamentally reshaping research methodologies.This perspective highlights parallels between scientific automation and established Computer-Aided Engineering (CAE) practices, introducing Quantum CAE as a framework that leverages quantum algorithms for simulation, optimization, and machine learning within engineering design.Practical implementations of Quantum CAE are illustrated through case studies for combinatorial optimization problems.Further discussions include advancements toward higher automation levels, highlighting the critical role of specialized AI agents proficient in quantum algorithm design.The integration of quantum computing with AI raises significant questions about the collaborative dynamics among human scientists and engineers, AI systems, and quantum computational resources, underscoring a transformative future for automated discovery and innovation.</p>
<p>I. INTRODUCTION</p>
<p>Machine learning traces its origins to the perceptron introduced by Rosenblatt in 1958, marking the inception of its development within artificial intelligence [1].Initially constrained by the simplicity of linear classifiers, progress stagnated until breakthroughs in multilayer neural networks and the popularization of the backpropagation algorithm in the late 1980s [2].Subsequent innovations, including support vector machines (SVM) by Cortes and Vapnik [3], decision trees [4], and ensemble methods such as random forests [5] and gradient boosting [6], significantly enhanced performance in practical applications.</p>
<p>The 2010s witnessed an explosive growth in deep learning, driven by massive datasets and increased computational capabilities provided by GPUs, which led to outstanding successes in image and speech recognition tasks [7].Architectures like convolutional neural networks (CNNs) demonstrated by Krizhevsky et al. [8], recurrent neural networks (RNNs) by Hochreiter and Schmidhuber [9], and Transformers by Vaswani et al. [10] have substantially outperformed previous methods.Particularly in natural language processing (NLP), Transformers facilitated major advancements exemplified by large language models such as GPT [11] and BERT [12].Utilizing self-supervised learning and enormous text datasets, these models excel in text generation, dialogue systems, and other diverse applications, reshaping the landscape of AI research.</p>
<p>Additionally, advancements in deep reinforcement learning enabled AI to surpass human experts in highly complex games like Go [13].Despite its enormous combinational complexity, Go is a complete-information game.Current AI technologies now surpass top human players in even more complex scenarios, such as competitive racing games [14].</p>
<p>Practical industrial applications of AI include advanced driver-assistance systems that enhance automotive safety through onboard cameras and sophisticated feedback mechanisms.Research and development in selfdriving technology actively involve automotive manufacturers and IT companies alike, integrating cutting-edge AI techniques, including deep reinforcement learning and large language models.</p>
<p>The ability of AI to exceed human capabilities in specialized tasks suggests transformative potential across scientific and industrial domains.Recognizing this significance, organizations such as the Japan Science and Technology Agency (JST), the National Academies of Sciences (NAS), and the Organisation for Economic Co-operation and Development (OECD) have released strategic proposals concerning AI's integration into scientific discovery and research methodologies [15][16][17].These initiatives, labeled as "Novel Turing Challenge," "Accelerated Discovery," or "AI for Science (AI4Science)," emphasize automating scientific discovery processes, wherein humans define objectives, and AI autonomously formulates hypotheses, performs experiments, and iteratively verifies outcomes.</p>
<p>The notion of scientific automation questions which research activities can be delegated to AI and robotics and explores the resulting efficiencies.AI endows systems with sensory and cognitive capabilities, whereas robotics provides mechanical movement and physical interaction abilities.This technological convergence could ultimately lead to AI-enabled robots assuming roles traditionally reserved for human scientists.Such possibilities have long been explored in science fiction, exemplified by The Greatest Robot on Earth in Osamu Tezuka's Astro Boy, in which a robot scientist surpasses human scientists in both intellect and capability [18].</p>
<p>As AI and robotics technologies mature, their realworld application in scientific research is anticipated to accelerate, influencing both technical methodologies and societal interactions.Currently, many scientists and engineers operate under corporate or national interests, driving increased demands for productivity and discovery.Integrating AI and robotics to enhance research efficiency thus becomes increasingly essential.The 2024 Nobel Prize in Chemistry awarded to scientists involved in AlphaFold further underscores this emerging trend [19].</p>
<p>Scientific discovery involves extracting novel insights from an expansive space of hypotheses, analogous to mathematician Paul Erdős's metaphor of discovering theorems recorded in "The Book" [20].Similar to mining gold, the ease of discovery diminishes over time, necessitating innovation to sustain productivity.As long as scientific discoveries promise economic returns exceeding their investment, research will continue, fostering advances in supporting technologies.</p>
<p>King et al. introduced the concept of robot scientists, demonstrating their effectiveness in functional genomics research [21].Automation leveraging AI and robotics has become prevalent, especially in resource-intensive research areas like genome sequencing and compound library screening.</p>
<p>Similar to the disruptive impact IT had on service sectors, recent AI advancements are poised to extend automation into various scientific fields beyond life sciences, making automation indispensable for scientists and engineers across disciplines and scales.</p>
<p>This paper specifically discusses research activities entirely executable within computational environments for two reasons: firstly, improvements in computational power and simulation algorithms have increased the feasibility of replacing physical experiments; secondly, the practical realization of quantum computing promises to further enhance these capabilities.</p>
<p>Fully automated computational research processesspanning topic selection, programming and debugging, conducting computational experiments, data analysis, manuscript drafting, and even peer review -are already underway [22].Subsequent studies have demonstrated instances of AI-authored papers successfully passing peer review, highlighting the potential for AI agents to efficiently handle demanding research tasks within projects.</p>
<p>In this paper, we overview the concept of scientific automation, explore its parallels with widely adopted Computer-Aided Engineering (CAE), introduce strategies and examples of quantum computing applications within CAE, discuss advancements towards higher automation levels, and conclude with future perspectives.</p>
<p>II. AUTOMATION IN SCIENCE AND ENGINEERING</p>
<p>As generative AI approaches human-like capabilities, the concept of "digital humans" emerges.Analogously, AI systems conducting research and development through computer simulations can be termed "dig-ital scientists."Unlike digital humans, digital scientists do not require communication skills.Instead, they must possess the capability for rapid logical decision-making grounded in scientific knowledge.Consequently, digital scientists neither require distinct personalities nor can autonomously undertake undesired research beyond the scope of human oversight.</p>
<p>Using the term "digital scientist" strategically positions AI as a supportive tool rather than a replacement for human scientists, thereby mitigating social concerns.The automation of scientific research thus fosters collaborative frameworks between human scientists and digital scientists.</p>
<p>But what capabilities must digital scientists possess?The strategic report from JST categorizes scientific automation into six levels (from Level 0 to Level 5), analogous to the autonomy levels for self-driving vehicles defined by SAE International.Level 3 automation corresponds to full autonomy under well-defined conditions, often referred to as "perfect information."</p>
<p>The scientific discovery process, illustrated by the work of King et al., typically involves (1) hypothesis generation based on existing knowledge, (2) experimental design and execution to verify these hypotheses, and (3) data analysis to validate hypotheses.This cyclic process continuously updates knowledge and generates new hypotheses, constituting scientific automation.</p>
<p>At Level 3 in self-driving technology, human oversight ensures AI properly manages steering, acceleration, and braking, intervening only when necessary.Similarly, scientific automation requires human scientists to provide sufficient information and evaluation criteria to AI, automating routine tasks while humans interpret the purpose and implications of results.</p>
<p>Levels 4 and 5 automation require complete adaptability to dynamically changing conditions, capabilities currently beyond practical realization.Analogously, in science, comprehensive automation remains in foundational research stages.Nevertheless, pioneering studies aim at fully automated scientific processes from topic selection to manuscript preparation, as described in the previous section.</p>
<p>King et al. demonstrated Level 3 scientific automation in life sciences, a field inherently reliant on experiments.Conversely, disciplines like materials science employ firstprinciples calculations enabling complete computational workflow, broadly facilitating scientific automation.</p>
<p>This automated methodology closely parallels Computer-Aided Engineering (CAE), widely employed in manufacturing and product design.CAE employs numerical techniques -such as the finite element method (FEM), boundary element method (BEM), and computational fluid dynamics (CFD) -to predict product characteristics based on design parameters.Widely adopted across automotive, aerospace, electronics, material industries, CAE optimizes designs, reduces prototype costs, shortens development cycles, ensures quality control, and supports digital transformation (DX).Here, automation in product design will be termed "design automation."</p>
<p>In design automation, numerical parameters termed "design variables (x)" are simulated to determine their relationship with "product characteristics (y)."Machine learning then models these characteristics from data, creating predictive models analogous to scientific knowledge.Solving inverse problems identifies optimal values of design variables (x * ) that yield desired (maximized or minimized) product characteristics (y * ).Iteratively refining this optimization process drives design automation forward.</p>
<p>Comparatively, scientific automation parallels design automation: (1) Optimization corresponds directly to hypothesis generation, (2) simulation parallels experimental verification, and (3) machine learning aligns with the analysis of resulting data.Initially limited data yields low model accuracy, which progressively improves with iterative simulations and model updates.Figure 1 illustrates this cyclic workflow.</p>
<p>This optimization method, "black-box optimization," addresses unknown input-output relations, with Bayesian optimization often applied for continuous variables.Conversely, combinatorial optimization problems involving discrete variables pose greater challenges and have primarily relied on relaxation techniques until recently.</p>
<p>The subsequent chapters will explore quantum computing applications within CAE and examples of their implementation, advancing the discourse on automation in science and engineering.</p>
<p>III. QUANTUM CAE</p>
<p>Quantum computing presents significant opportunities for enhancing CAE by leveraging quantum algorithms [23] in simulation, machine learning, and optimization, which together are termed Quantum CAE.Integrating quantum computing into product design automation could significantly reduce development lead times, resulting in improved productivity, cost-efficiency, and market responsiveness.</p>
<p>Implementing Quantum CAE requires the development of quantum algorithms tailored to typical CAE simulations, as well as quantum machine learning models and quantum optimization methods to process simulation results efficiently.Quantum optimization is particularly promising for handling discrete design variables commonly encountered in engineering design.Furthermore, seamlessly integrating these quantum tasks through coherent quantum information processing technologies is critical.</p>
<p>Initial stages of Quantum CAE involve executing one of the key tasks (simulation, machine learning, or optimization) using quantum computers.For example, employing quantum annealing for optimization tasks to identify candidate designs (hypotheses) represents a practical starting point.Leveraging existing technologies such as quantum gate simulators or Ising solvers can demonstrate short-term, practical benefits on small-scale problems.</p>
<p>Quantum-inspired classical algorithms, such as those developed by Tang derived from quantum recommendation techniques, demonstrate efficient performance on conventional computers, illustrating how quantum research advances classical computing [24].</p>
<p>The long-term goal of Quantum CAE is fully quantumintegrated CAE processes.However, significant challenges persist, especially the exponential computational cost associated with encoding classical data into quantum states and extracting useful information back into classical form in the worst case.Overcoming these limitations necessitates methods facilitating efficient quantum state information exchange among tasks.Current research efforts focus on facilitating direct quantum-state exchanges between quantum simulations and quantum machine learning models, and developing quantum machine learning techniques capable of learning from limited quantum data [25].Additionally, methods integrating quantum annealing outputs with quantum gate processing to improve optimization effectiveness have been demonstrated [26].</p>
<p>Quantum CAE algorithms fundamentally solve complex optimization problems, aligned with general quantum search algorithms such as Grover adaptive search [27] and quantum walks [28].Unlike abstract quantum oracle-based algorithms, Quantum CAE emphasizes direct integration of concrete physical simulations and evaluation of product characteristics, creating practical, efficient quantum circuits suitable for real-world applications.Such developments highlight the practical realization of foundational quantum computing research, potentially driving entirely new algorithmic approaches.</p>
<p>Quantum CAE at Level 3 automation can address highly complex design challenges, including optimizing fusion reactor designs through advanced plasma simulations and comprehensive design optimizations for inter-stellar spacecraft.Higher automation levels (Levels 4 and 5) will require tackling complex, uncontrollable societal challenges and investigating scientific frontiers beyond current human cognitive capacities.Quantum computing could become indispensable, propelled by Quantum CAE-derived knowledge and technologies.</p>
<p>IV. QUANTUM CAE FOR MANUFACTURING</p>
<p>This chapter presents practical examples of Quantum CAE applications at Level 3 automation, focusing specifically on discrete-variable design problems solved using black-box optimization methods.</p>
<p>Baptista and Poloczek introduced Bayesian Optimization of Combinatorial Structures (BOCS), a method that constructs probabilistic prediction models by sampling from the posterior distribution over model parameters [29].Kitai et al. proposed Factorization Machine Quantum Annealing (FMQA), employing Factorization Machines (FM) as prediction models and quantum annealing for optimization [30].FM differs from Gaussian process methods used in continuous optimization by employing point estimation techniques, enabling faster convergence with fewer data points but increasing the risk of convergence to local optima.Conversely, BOCS utilizes distribution-based modeling similar to Gaussian processes, facilitating broader exploratory searches.</p>
<p>These methods rely on discrete design variables and evaluation approaches, such as simulations, to assess product characteristics.Design optimization problems involving discrete variables are typically NP-hard, complicating the task of obtaining high-quality solutions.Both BOCS and FMQA efficiently derive feasible solutions from limited iterations.</p>
<p>Two case studies illustrate the practical application of these methods:</p>
<p>First, Matsumori et al. addressed mounting-point optimization in automotive electronic control boards [31].To mitigate vibration-related risks in automotive engine rooms, the board's lowest natural frequency must be maximized to avoid resonance and minimize displacement.Increasing the lowest natural frequency typically necessitates additional mounting points, creating trade-offs between improved stability, design flexibility, and manufacturing cost.Formulating this as a multiobjective optimization problem, BOCS and FMQA efficiently identified optimal number of mounting points and their locations.</p>
<p>Next, Okada et al. considered the design of highfrequency noise filters [32].High-frequency circuits require evaluation as distributed-element circuits, accounting for interactions between printed circuit patterns and electronic components.Traditional rule-based methods, AI-based approaches, and topology optimization [33] techniques have been previously applied.Multiple candidates of printed circuit patterns between components were prepared, formulating the design as a combinatorial FIG. 2. Optimization results for a noise filter.Similar solutions were obtained using topology optimization (left, reproduced from [33] with permission) and black-box optimization (right, reproduced from [32]).optimization problem.A cost function employing constraints aligned with Quadratic Unconstrained Binary Optimization (QUBO) was developed to efficiently exclude impractical printed circuit patterns.As a result, practical and optimal printed circuit patterns were effectively identified.Figure 2 shows that the solutions obtained by topology optimization and black-box optimization methods are essentially similar.Figure 3 demonstrates that iterative data acquisition leads to an exploration shift from impractical to practical printed circuit patterns.</p>
<p>Beyond these case studies, potential applications have been explored in various fields, including pharmaceuticals [34][35][36], chemistry [37], optics [38][39][40], magnetic materials [41,42], electronics [43,44], and data science [45,46].These case studies highlight the effectiveness of quantum annealing as well as Ising solvers in enhancing automation frameworks in both manufacturing and scientific fields.If larger-scale quantum annealers become available, prediction model construction could become a bottleneck.Therefore, while quantum algorithms represent a long-term research goal, improving conventional computing algorithms remains an important short-term objective [46,47].</p>
<p>Furthermore, Quantum CAE realization also demands quantum algorithm implementations for simulations.Inspired by quantum algorithms for the Boltzmann equa-tion [48], Igarashi et al. developed a quantum algorithm for solving radiative transfer equations, a class of linear differential equations, which allows efficient implementation via quantum circuits [49].Nonlinear equations, frequently encountered in real-world simulations, require tailored quantum algorithm development [50,51].Additionally, research into implementations using quantum circuits [52] and quantum annealers [53] to generate proposal states with reduced rejection rates for accelerating Monte Carlo simulations exemplifies ongoing advancements in quantum-enhanced computational methods.</p>
<p>V. PERSPECTIVES FOR ADVANCED AUTOMATION</p>
<p>The previous chapters focused primarily on Level 3 automation within scientific and engineering contexts.Advancing to higher automation levels (Levels 4 and 5) necessitates developing sophisticated teams of AI agents capable of autonomously conducting comprehensive research activities -from formulating research topics and conducting experiments to data analysis and manuscript writing.Achieving this goal requires enhancing individual agent capabilities and developing advanced technologies for effective collaboration and communication among agents within an integrated framework.</p>
<p>Developing practical AI agents requires a combination of versatile, general-purpose agents and highly specialized agents equipped with expert knowledge or specialized skills.Quantum computing's role in accelerating scientific and design processes underscores the importance of developing specialized agents proficient in quantum algorithms and quantum circuit design.Recent research has explored generative models that autonomously design quantum circuits tailored to specific objectives.For instance, Nakaji et al. introduced the Generative Quantum Eigensolver (GQE), employing a decoder-only Transformer to compute molecular ground states through automated quantum circuit generation [54].Extending this concept further, Minami et al. introduced an AI agent capable of autonomously generating quantum circuits specifically designed for solving optimization problems [55].</p>
<p>Discrete optimization problems are commonly formulated using Quadratic Unconstrained Binary Optimization (QUBO).Since QUBO matrices generalize adjacency matrices used in graph theory, these problems naturally lend themselves to graphical representations.Capitalizing on this graphical representation, an AI agent employing an encoder-decoder neural network architecture was developed.Specifically, the encoder uses a Graph Neural Network (GNN) to process input graph data, while the decoder employs a Transformer to generate quantum circuits for solving optimization problems.Performance assessments using quantum circuit simulators guided reinforcement learning strategies, demonstrating the AI agent's effectiveness in generating quantum cir-... cuits (Fig. 4).Sakka et al. provide a practical example of an AI scientist applying automated quantum machine learning for feature map design by generating ideas, implementing and validating code, and analyzing results, thereby demonstrating the potential of AI-driven quantum algorithm development in practical settings [56].</p>
<p>Circuit Generation
Output State Transformer Decoder Feed Forward Graph Encoder
Developing specialized agents for quantum computing increasingly demands interdisciplinary collaboration between quantum computing specialists and AI experts, alongside integrating advancements from broader AI research.Quantum computing and AI are both developing technologies, and advancements in each independently contribute to automating scientific and engineering processes.Additionally, AI applications are actively being employed to facilitate advancements in quantum computing itself [57].</p>
<p>VI. SUMMARY AND FUTURE PERSPECTIVES</p>
<p>Rapid advancements in AI technology have significantly accelerated automation across various scientific and engineering domains.This paper highlighted how current technological capabilities enable Level 3 automation, comparable to widely established CAE practices in industry.Furthermore, integrating quantum computing into these automated processes offers the potential to significantly enhance their efficiency.Specific examples were presented illustrating how Quantum CAE can deliver tangible benefits even at small scales.</p>
<p>Future research should prioritize two main strategies: First, practical application of existing quantum technologies to specific product development and engineering problems.Second, further development of advanced quantum algorithms in anticipation of future improvements in quantum computing capabilities.Insights and technologies gained through Quantum CAE will not only facilitate advanced scientific research automation but also expand the role of quantum computing toward achieving higher automation levels (Levels 4 and 5).</p>
<p>Central to this vision is the development of advanced AI agents, or "digital scientists," designed to handle specialized tasks and actively collaborate with human scientists.To advance this direction, it is essential to establish integrated infrastructure supporting joint quantum computing and AI research.The current adoption of quantum computing at supercomputing centers worldwide presents an opportunity to build robust, integrated research communities focused on quantum computing and AI.</p>
<p>Lastly, we are approaching an era in which AI surpasses human capabilities in various research domains.Concurrently, AI is gaining access to computational resources that provide quantum acceleration.However, fundamental questions remain regarding how scientists and engineers, businesses, nations, and society will establish effective collaboration frameworks with AI.Answers to these questions will progressively emerge through continuous dialogue between humans and AI systems.Such interactions will leverage AI to efficiently navigate hu-manity's extensive knowledge base, stimulate innovative discoveries, foster deeper intellectual engagement, and support ethical approaches to scientific and technological development.</p>
<p>FIG. 1 .
1
FIG.1.Process of automation in science and product design.Hypotheses are automatically generated based on existing knowledge and validated through experiments or simulations, producing new findings.These findings are integrated into the knowledge base, enabling iterative hypothesis generation.Parentheses indicate specific information processing tasks involved in the automation process.This process parallels design automation workflows such as those found in Computer-Aided Engineering (CAE).</p>
<p>FIG. 3 .
3
FIG. 3. Relationship between the number of data acquisitions (x-axis) and the cost function (y-axis).Feasible solutions emerge as the number of data acquisitions increases.(reproduced from[32])</p>
<p>[</p>
<p>FIG.4.Encoder-decoder model for generating quantum circuits to solve optimization problems.The QUBO matrix, which encodes an optimization problem, is first converted into a graph and then processed using a graph neural network as the encoder and a transformer as the decoder.(reproduced from[55] with modifications)</p>
<p>ACKNOWLEDGMENTSThe author gratefully acknowledges Mitsuru Ambai, Tadayoshi Matsumori, Masato Taki, Akihisa Okada, Asuka Igarashi, Shiro Kawabata, Shunya Minami, Kohei Nakaji, Yoichi Suzuki, Alán Aspuru-Guzuk, Shunta Arai, and Tatsuya Ishigaki for fruitful collaboration and insightful discussions in joint research activities.This work was partly performed for Council for Science, Technology and Innovation (CSTI), Cross-ministerial Strategic Innovation Promotion Program (SIP), "Promoting the application of advanced quantum technology platforms to social issues"(Funding agency: QST).This paper was partly based on results obtained from a project, JPNP16007, commissioned by the New Energy and Industrial Technology Development Organization (NEDO), Japan.
The perceptron: A probabilistic model for information storage and organization in the brain. F Rosenblatt, 10.1037/h0042519Psychological Review. 653861958</p>
<p>Learning representations by back-propagating errors. D E Rumelhart, G E Hinton, R J Williams, 10.1038/323533A0;KWRD=SCIENCENature. 3235331986</p>
<p>Support-vector networks. C Cortes, V Vapnik, 10.1023/A:1022627411411/METRICSMachine Learning. 202731995</p>
<p>Induction of decision trees. J R Quinlan, 10.1007/BF00116251Machine Learning. 1811986</p>
<p>Random forests. L Breiman, 10.1023/A:1010933404324/METRICSMachine Learning. 452001</p>
<p>Greedy function approximation: A gradient boosting machine. J H Friedman, The Annals of Statistics. 2911892001</p>
<p>Y Lecun, Y Bengio, G Hinton, 10.1038/NATURE14539;SUBJMETA=117,639,705;KWRD=COMPUTER+SCIENCE,MATHEMATICS+AND+COMPUTINGDeep learning. 2015521436</p>
<p>Imagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in Neural Information Processing Systems. 252012</p>
<p>Long short-term memory. S Hochreiter, J Schmidhuber, 10.1162/NECO.1997.9.8.1735Neural Computation. 917351997</p>
<p>Polosukhin, Attention is all you need. A Vaswani, G Brain, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Lukasz Kaiser, I , Advances in Neural Information Processing Systems. 302017</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, Advances in Neural Information Processing Systems. 3318772020</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K T Google, A I Language, 10.18653/V1/N19-1423Proceedings of the 2019 Conference of the North. the 2019 Conference of the North20194171</p>
<p>Mastering the game of go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G V D Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, S Dieleman, D Grewe, J Nham, N Kalchbrenner, I Sutskever, T Lillicrap, M Leach, K Kavukcuoglu, T Graepel, D Hassabis, 10.1038/NATURE16961;SUBJMETA=1042,117,1788,378,631,639,705;KWRD=COMPUTATIONAL+SCIENCE,COMPUTER+SCIENCE,REWARDNature. 5294842016</p>
<p>Outracing champion gran turismo drivers with deep reinforcement learning. P R Wurman, S Barrett, K Kawamoto, J Mac-Glashan, K Subramanian, T J Walsh, R Capobianco, A Devlic, F Eckert, F Fuchs, L Gilpin, P Khandelwal, V Kompella, H C Lin, P Macalpine, D Oller, T Seno, C Sherstan, M D Thomure, H Aghabozorgi, L Barrett, R Douglas, D Whitehead, P Dürr, P Stone, M Spranger, H Kitano, 10.1038/S41586-021-04357-7;SUBJMETA=1041,117,639,705;KWRD=APPLIED+MATHEMATICS,COMPUTER+SCIENCENature. 6022232022</p>
<p>Artificial Intelligence and Science -Toward discovery and understanding by AI-driven science. Research Center For, Development Strategy, 2021Japan Science and Technology Agency</p>
<p>. 10.17226/265322022National Academies PressNational Academies of Sciences, Engineering, and Medicine, Automated Research Workflows for Accelerated Discovery</p>
<p>10.1787/a8d820bd-enArtificial Intelligence in Science: Challenges, Opportunities and the Future of Research. OECD Publishing2023</p>
<p>O Tezuka, Astro boy: The greatest robot on earth. Shonen1964</p>
<p>Highly accurate protein structure prediction with alphafold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, A Bridgland, C Meyer, S A Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 5965832021. 2021</p>
<p>P Hoffman, The Man Who Loved Only Numbers. Hyperion Books1998</p>
<p>Functional genomic hypothesis generation and experimentation by a robot scientist. R D King, K E Whelan, F M Jones, P G Reiser, C H Bryant, S H Muggleton, D B Kell, S G Oliver, 10.1038/NATURE02236;KWRD=SCIENCENature. 4272472004</p>
<p>The ai scientist: Towards fully automated openended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, arXiv:2408.062922024</p>
<p>A M Dalzell, S Mcardle, M Berta, P Bienias, C.-F Chen, A Gilyén, C T Hann, M J Kastoryano, E T Khabiboulline, A Kubica, G Salton, S Wang, F G S L Brandão, Quantum Algorithms: A Survey of Applications and End-to-end Complexities. Cambridge University Press2025</p>
<p>A quantum-inspired classical algorithm for recommendation systems. E Tang, 10.1145/3313276.3316310;PAGE:STRING:ARTICLE/CHAPTERProceedings of the Annual ACM Symposium on Theory of Computing. the Annual ACM Symposium on Theory of Computing2019217</p>
<p>H Y Huang, M Broughton, J Cotler, S Chen, J Li, M Mohseni, H Neven, R Babbush, R Kueng, J Preskill, J R Mcclean, 10.1126/SCIENCE.ABN7293/SUPPL_FILE/SCIENCE.ABN7293_SM.PDFQuantum advantage in learning from experiments. 20223761182</p>
<p>Enhancing quantum annealing in digital-analog quantum computing. T Kadowaki, 10.1063/5.0179540/3280427APL Quantum. 1261012024</p>
<p>Grover adaptive search for constrained polynomial binary optimization. A Gilliam, S Woerner, C Gonciulea, 10.22331/q-2021-04-08-42820215428</p>
<p>Combinatorial optimization via highly efficient quantum walks. S Marsh, J B Wang, 10.1103/PHYSREVRESEARCH.2.023302/FIGURES/8/MEDIUMPhysical Review Research. 2233022020</p>
<p>R Baptista, M Poloczek, Bayesian optimization of combinatorial structures, 35th International Conference on Machine Learning, ICML. 2018. 20182782</p>
<p>Designing metamaterials with quantum annealing and factorization machines. K Kitai, J Guo, S Ju, S Tanaka, K Tsuda, J Shiomi, R Tamura, 10.1103/PhysRevResearch.2.013319Physical Review Research. 2133192020</p>
<p>Application of qubo solver using black-box optimization to structural design for resonance avoidance. T Matsumori, M Taki, T Kadowaki, 10.1038/s41598-022-16149-8Scientific Reports. 1212022</p>
<p>Design optimization of noise filter using quantum annealer. A Okada, H Yoshida, K Kidono, T Matsumori, T Takeno, T Kadowaki, 10.1109/ACCESS.2023.3271969IEEE Access. 11443432023</p>
<p>Layout design of components and conductors in noise filter by integrative optimization of structural topology and external variables. S Maruyama, S Yamasaki, K Nomura, K Yaji, K Fujita, 10.11421/JSCES.2021.20210007Transactions of the Japan Society for Computational Engineering and Science. 2021202100072021</p>
<p>Toward realworld automated antibody design with combinatorial bayesian optimization. A Khan, A I Cowen-Rivers, A Grosnit, D.-G.-X Deik, P A Robert, V Greiff, E Smorodina, P Rawat, R Akbar, K Dreczkowski, R Tutunov, D Bou-Ammar, J Wang, A Storkey, H Bou-Ammar, 10.1016/j.crmeth.2022.100374Cell Reports Methods. 31003742023</p>
<p>Quantum annealing designs nonhemolytic antimicrobial peptides in a discrete latent space. A Tučs, F Berenger, A Yumoto, R Tamura, T Uzawa, K Tsuda, 10.1021/ACSMEDCHEMLETT.2C00487/ASSET/IMAGES/LARGE/ML2C00487_0003.JPEGACS Medicinal Chemistry Letters. 145772023</p>
<p>Chemical design with gpu-based ising machines. Z Mao, Y Matsuda, R Tamura, K Tsuda, 10.1039/D3DD00047HDigital Discovery. 210982023</p>
<p>Quantum-classical computational molecular design of deuterated high-efficiency oled emitters. Q Gao, G O Jones, T Kobayashi, M Sugawara, H Yamashita, H Kawaguchi, S Tanaka, N Yamamoto, 10.34133/icomputing.0037Intelligent Computing. 22023</p>
<p>High-performance transparent radiative cooler designed by quantum computing. S Kim, W Shang, S Moon, T Pastega, E Lee, T Luo, 10.1021/ACSENERGYLETT.2C01969/SUPPL_FILE/NZ2C01969_SI_001.PDFACS Energy Letters. 741342022</p>
<p>Designing thermal radiation metamaterials via a hybrid adversarial autoencoder and bayesian optimization. D Zhu, J Guo, G Yu, C Y Zhao, H Wang, S Ju, S Ju, 10.1364/OL.453442Optics Letters. 471433952022</p>
<p>Towards optimization of photonic-crystal surface-emitting lasers via quantum annealing. T Inoue, Y Seki, K Ishizaki, S Noda, N Togawa, S Tanaka, 10.1364/OE.476839Optics Express. 30435032022</p>
<p>Quantum annealing optimization method for the design of barrier materials in magnetic tunnel junctions. K Nawa, T Suzuki, K Masuda, S Tanaka, Y Miura, 10.1103/PHYSREVAPPLIED.20.024044/FIGURES/11/MEDIUMPhysical Review Applied. 20240442023</p>
<p>Topology optimization of electromagnetic devices using digital annealer. A Maruo, T Soeda, H Igarashi, 10.1109/TMAG.2022.3184325IEEE Transactions on Magnetics. 582022</p>
<p>Method for analyzing bit error rates (bers) of nonlinear circuits and systems for high-performance signaling. Y Dou, D Jiao, J Yan, J Zhu, 10.1109/TMTT.2021.3125022IEEE Transactions on Microwave Theory and Techniques. 707322022</p>
<p>. C Oh, R Bondesan, D Kianfar, R Ahmed, R Khurana, P Agarwal, R Lepert, M Sriram, M Welling, 2022Bayesian optimization for macro placement</p>
<p>Surrogate-assisted asynchronous multiobjective algorithm for nuclear power plant operations. V Drouet, S Verel, J M Do, 10.1145/3377930.3390206;TOPIC:TOPIC:CONFERENCE-COLLECTIONS&gt;GECCO;PAGE:STRING:ARTICLE/CHAPTERGECCO 2020 -Proceedings of the 2020 Genetic and Evolutionary Computation Conference. 20201073</p>
<p>Lossy compression of matrices by black box optimisation of mixed integer nonlinear programming. T Kadowaki, M Ambai, 10.1038/S41598-022-19763-8;SUBJMETA=117,481,483,639,705,766;KWRD=COMPUTER+SCIENCE,QUANTUM+INFORMATIONScientific Reports. 1212022</p>
<p>A black-box optimization method with polynomial-based kernels and quadratic-optimization annealing. Y Minamoto, Y Sakamoto, arXiv:2501.042252025</p>
<p>Quantum algorithm for the advection-diffusion equation simulated with the lattice boltzmann method. L Budinski, 10.1007/S11128-021-02996-3/FIGURES/10Quantum Information Processing. 2012021</p>
<p>Quantum algorithm for the radiative-transfer equation. A Igarashi, T Kadowaki, S Kawabata, 10.1103/PHYSREVAPPLIED.21.034010/FIGURES/9/MEDIUMPhysical Review Applied. 21340102024</p>
<p>Efficient quantum algorithm for dissipative nonlinear differential equations, Proceedings of the National Academy of. J P Liu, H Øie Kolden, H K Krovi, N F Loureiro, K Trivisa, A M Childs, 10.1073/PNAS.2026805118/SUPPL_FILE/PNAS.2026805118.SAPP.PDFSciences of the United States of America. 118e20268051182021</p>
<p>Koopman-von neumann approach to quantum simulation of nonlinear classical dynamics. I Joseph, 10.1103/PHYSREVRESEARCH.2.043102/FIGURES/3/MEDIUMPhysical Review Research. 2431022020</p>
<p>Quantumenhanced markov chain monte carlo. D Layden, G Mazzola, R V Mishmash, M Motta, P Wocjan, J S Kim, S Sheldon, 10.1038/s41586-023-06095-4Nature. 6192822023. 2023</p>
<p>Quantum annealing enhanced markov-chain monte carlo. S Arai, T Kadowaki, arXiv:2502.080602025</p>
<p>The generative quantum eigensolver (gqe) and its application for ground state search. K Nakaji, L B Kristensen, J A Campos-Gonzalez-Angulo, M G Vakili, H Huang, M Bagherimehrab, C Gorgulla, F Wong, A Mccaskey, J.-S Kim, T Nguyen, P Rao, A Aspuru-Guzik, arXiv:2401.092532024</p>
<p>Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver. S Minami, K Nakaji, Y Suzuki, A Aspuru-Guzik, T Kadowaki, arXiv:2501.169862025</p>
<p>Automating quantum feature map design via large language models. K Sakka, K Mitarai, K Fujii, arXiv:2504.073962025</p>
<p>. Y Alexeev, M H Farag, T L Patti, M E Wolf, N Ares, A Aspuru-Guzik, S C Benjamin, Z Cai, Z Chandani, F Fedele, N Harrigan, J.-S Kim, E Kyoseva, J G Lietz, T Lubowe, A Mccaskey, R G Melko, K Nakaji, A Peruzzo, S Stanwyck, N M Tubman, H Wang, T Costa, arXiv:2411.09131Artificial intelligence for quantum computing. 2024</p>            </div>
        </div>

    </div>
</body>
</html>