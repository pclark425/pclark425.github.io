<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4406 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4406</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4406</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-100.html">extraction-schema-100</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-281496866</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.19125v1.pdf" target="_blank">Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering</a></p>
                <p><strong>Paper Abstract:</strong> The rapid growth of scientific literature demands efficient methods to organize and synthesize research findings. Existing taxonomy construction methods, leveraging unsupervised clustering or direct prompting of large language models (LLMs), often lack coherence and granularity. We propose a novel context-aware hierarchical taxonomy generation framework that integrates LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages LLMs to identify key aspects of each paper (e.g., methodology, dataset, evaluation) and generates aspect-specific paper summaries, which are then encoded and clustered along each aspect to form a coherent hierarchy. In addition, we introduce a new evaluation benchmark of 156 expert-crafted taxonomies encompassing 11.6k papers, providing the first naturally annotated dataset for this task. Experimental results demonstrate that our method significantly outperforms prior approaches, achieving state-of-the-art performance in taxonomy coherence, granularity, and interpretability.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4406.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4406.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Aspects-guided Top-Down Clustering</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context-Aware Hierarchical Taxonomy Generation via LLM-Guided Multi-Aspect Top-Down Clustering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A taxonomy-construction pipeline that uses LLMs to (1) generate corpus-specific semantic aspects, (2) create aspect-guided summaries per paper, (3) encode aspect vectors, and (4) perform aspect-specific clustering with a dynamic search to produce hierarchical taxonomy trees tailored to the input corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Aspects-guided LLM-based Top-Down Clustering</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Top-down iterative taxonomy generator: (1) LLM-based dynamic aspect generator produces salient semantic aspects A_v for a node's paper set D_v; (2) LLMs generate aspect-guided summaries s_d^a for every paper-aspect pair; (3) embeddings (text-embedding-3-large) encode summaries into aspect-specific vector matrices e_a; (4) aspect-wise clustering (Gaussian Mixture Models) yields per-aspect cluster probabilities f_a(e,i); (5) a dynamic combinatorial search picks k_v aspect-cluster pairs to partition papers into child nodes; (6) LLM (GPT-4o) generates human-readable topic facets for nodes; repeat top-down until stopping conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-4o (aspect generation & facet naming), LLaMA-3.1-8B (aspect-guided summarization), text-embedding-3-large (embedding)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM-guided aspect discovery + aspect-guided summarization (prompting) followed by embedding-based encoding</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Aspect-wise clustering + dynamic combinatorial search to synthesize multi-aspect cluster assignments into a coherent hierarchical taxonomy; LLMs generate node facet labels</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>Applied to TaxoBench-CS: 11.6k papers across 156 human-authored taxonomies (avg ~74.4 papers per taxonomy)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Computer science (survey/review papers from arXiv) / scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Hierarchical taxonomies (tree of topic facets and paper partitions), node facet labels, aspect-guided summaries</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Clustering: NMI, ARI, Purity; Structure/heading: CEDS, Heading Soft Recall (HSR); Human: Coverage, Relevance, Structure, Validity, Adequacy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported best results on TaxoBench-CS: NMI=60.1, ARI=19.1, Purity=62.2, CEDS=23.8, HSR=74.5; human-eval improvements across five dimensions (Coverage 50.6, Structure 59.6, Adequacy 54.4 average scores reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against pure LLM-based pipelines (e.g., CHIME, TnT-LLM, GoalEx) and clustering-incorporated systems (e.g., Knowledge Navigator, SCYCHIC, KN).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Outperforms listed baselines on NMI/ARI/Purity and structural metrics (e.g., NMI 60.1 vs TnT-LLM 51.6; ARI 19.1 vs KN 16.2), and highest human-evaluation scores across metrics reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Dynamic, corpus-aware aspect discovery combined with aspect-specific representations and a dynamic search over aspect-cluster assignments yields more coherent, fine-grained, and interpretable taxonomies and improved robustness to noisy inputs compared to single-aspect or end-to-end LLM label-first methods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Dependence on LLM quality (hallucination risk), computational overhead from multi-aspect encoding and repeated clustering/search, limited scalability to extremely large corpora, current strict non-overlapping hierarchical partitioning (no multi-label nodes), benchmark limited to CS survey papers.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td>Observed: increasing per-node cluster count k_v raises categorization metrics (e.g., higher NMI) but harms structural alignment (CEDS) and increases node fragmentation; adaptive k_v yields balanced metrics but is computationally costly; tested robustness to 5â€“30% injected noise and reported relative stability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4406.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CHIME</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CHIME: LLM-assisted hierarchical organization of scientific studies for literature review support</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pure LLM-based system that produces a taxonomy and assigns papers in a single pass using LLM prompting to induce labels and assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chime: Llm-assisted hierarchical organization of scientific studies for literature review support</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CHIME</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An end-to-end LLM-driven taxonomy pipeline that prompts an LLM to generate hierarchical labels and assign papers to labels in one pass (label-first, direct prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Direct prompting / end-to-end taxonomy induction and label assignment by LLM</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Single-pass label generation and direct paper-to-label assignment (no separate aspect-specific clustering)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific literature / literature review support</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Hierarchical taxonomy and paper assignments (labels + membership)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>NMI, ARI, Purity, CEDS, HSR, human evaluation (as used in this paper's comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported in paper's Table 2 (example values): NMI ~35.4 (lower than multi-aspect method); specific numbers reported in the shared evaluation table.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against other pure LLM-based and clustering-incorporated methods in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Per the paper's experiments, CHIME underperforms the proposed multi-aspect clustering approach on categorization and structural alignment metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>One-pass LLM label-first approaches can be flexible but risk hallucinated or missing categories and produce imbalanced hierarchies without corpus-aware constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Tends to miss fine-grained, domain-specific distinctions and can hallucinate categories; less corpus-context awareness than clustering-integrated approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4406.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TnT-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TnT-LLM: Text Mining at Scale with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An iterative LLM-based system that generates and updates label taxonomies while processing documents, designed for large-scale text mining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TnT-LLM: Text Mining at Scale with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TnT-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An iterative label-first pipeline where the LLM generates and refines taxonomy labels over multiple iterations, updating paper assignments and taxonomy structure progressively.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Iterative LLM prompting to generate/update labels and assign papers</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Iterative taxonomy refinement (label generation + reassignment across iterations)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General text mining / literature</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Taxonomy labels and paper clusters/assignments</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>NMI, ARI, Purity, CEDS, HSR, human evaluation (as used in this paper's comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported NMI in this paper: ~51.6 (baseline value cited in main text), lower than the proposed method's 60.1.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against multi-aspect clustering method and other LLM-based approaches in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Underperforms the proposed approach on NMI and structural metrics per reported results (e.g., NMI 51.6 vs 60.1).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Iterative label updating helps improve taxonomy quality over one-shot label induction, but still lacks corpus-tailored multi-aspect representations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Susceptible to hallucinated labels and limited corpus-context awareness; label-first pipelines can produce redundant or missing categories.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4406.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GoalEx</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GoalEx (Goal-driven explainable clustering via language descriptions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Aligns LLM-generated natural-language explanations with papers and uses integer linear programming to select a non-overlapping consistent set of assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Goal-driven explainable clustering via language descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GoalEx</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Generates explanations/descriptions for candidate clusters via LLMs and formulates an integer linear program to pick a non-overlapping, globally consistent set of cluster-to-paper assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM-generated language descriptions/explanations used to connect papers to cluster descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Optimization (integer linear programming) to reconcile LLM outputs into a globally consistent assignment</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General text / document clustering</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Cluster assignments with explainable descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Clustering metrics (NMI, ARI, Purity) and structural/heading metrics in comparative evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported NMI in paper table: ~46.7 (lower than the proposed multi-aspect method's 60.1).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared alongside other LLM-based and clustering methods in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Per the paper's evaluation, GoalEx underperforms the multi-aspect approach on several clustering and structural metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining LLM explanations with a global optimization can reduce local inconsistencies, but explanation alignment alone is insufficient for fine-grained, corpus-aware taxonomy generation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>May still produce inconsistent or redundant labels if explanations lack corpus-level context; optimization overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4406.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge Navigator (KN)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Navigator: LLM-guided browsing framework for exploratory search in scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-guided exploratory search/browsing framework that helps users navigate scientific literature and can be used to cluster or organize papers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge navigator: LLM-guided browsing framework for exploratory search in scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Knowledge Navigator (KN)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LLM-guided exploratory search and browsing tool that supports document organization; used as a baseline single-stage flat clustering method in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM-guided retrieval and explanation; used to support clustering or browsing</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Single-stage flat clustering with LLM guidance and manual/automated label extraction</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific literature exploration / computer science (in comparative experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Flat clusters, browsing aids, taxonomy-like structures</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>NMI, ARI, Purity, structural metrics and human evaluation (per paper comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported ARI in main text for KN: ~16.2 (compared to the proposed method's ARI 19.1); NMI and other metrics lower than proposed method.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Benchmarked in the paper against the proposed multi-aspect method and other baselines</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Underperforms the multi-aspect dynamic clustering method on clustering and structure alignment metrics in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Single-stage flat clustering guided by LLMs can be useful for exploratory search but may lack hierarchical coherence and fine-grained separation captured by multi-aspect approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Flat clustering lacks hierarchical structure; may not capture multi-faceted distinctions among papers.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4406.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ClusterLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ClusterLLM: Large language models as a guide for text clustering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that uses LLMs to guide text clustering, typically by generating summaries or labels that inform clustering steps or centroids.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Clusterllm: Large language models as a guide for text clustering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ClusterLLM</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses LLMs to produce language-based guidance (summaries, labels, constraints) to steer unsupervised clustering algorithms; acts as a bridge between LLM semantic knowledge and clustering methods.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM-generated summaries/labels used as clustering guidance</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Combine language descriptions with clustering algorithms (e.g., using descriptions as centroids or constraints)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General text/document clustering</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Cluster assignments with human-readable labels/descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Clustering metrics (NMI, ARI, Purity) in original work (cited here as related work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-produced textual guidance can improve clustering interpretability and semantic alignment, but requires careful integration with vector-space methods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Potential mismatch between text descriptions and embedding geometry; cost of LLM calls for many clusters or documents.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4406.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>k-llmmeans</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>k-llmmeans: Summaries as centroids for interpretable and scalable LLM-based text clustering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that uses LLM-generated summaries as cluster centroids to produce interpretable and scalable clustering outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>k-llmmeans: Summaries as centroids for interpretable and scalable llm-based text clustering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>k-llmmeans</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses LLM-generated summary texts to represent centroids in a clustering algorithm, enabling interpretable clusters and scalable summary-based centroid updates.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>LLM summaries used as centroid representations; embedding-based similarity to assign documents</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Summary-centroid-based clustering (iteratively update centroids via LLM summaries and assign papers by embedding similarity)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>General text clustering</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Interpretable clusters with summary centroids</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Clustering quality and interpretability (as discussed in cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using summaries as centroids provides interpretable cluster anchors and can scale clustering while leveraging LLM abstraction capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Dependent on summary fidelity and embedding alignment; cost of generating many summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4406.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoSurvey</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoSurvey: Large language models can automatically write surveys</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated survey-generation pipelines that draft hierarchical outlines of target topics and attach relevant papers, replacing explicit taxonomies with structured outlines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autosurvey: Large language models can automatically write surveys</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoSurvey (and related pipelines: Storm, SurveyForge)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Outline-first pipelines: LLM drafts a hierarchical outline of topics, then retrieval modules attach supporting papers/paragraphs to each outline entry to produce an automated literature survey.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Prompted LLM outline generation plus retrieval to attach papers (retrieval+generation)</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Outline-driven retrieval and hierarchical assembly of summaries and citations (hierarchical summarization / assembly)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Automated literature survey generation across domains (cited as related work)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured survey outlines and assembled literature reviews</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Human evaluation, readability/coherence metrics, and task-specific measures in the cited works</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Outline-first strategies can produce usable survey drafts but risk redundant labels, hallucinated or missing categories, and imbalanced hierarchies without corpus-aware constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Label hallucination, redundancy, and potential retrieval-attachment mismatches; limited structural fidelity to expert taxonomies.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4406.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TaxoAdapt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An incremental multidimensional taxonomy expansion system that analyzes papers one-by-one and frames taxonomy construction as iterative multi-label classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TaxoAdapt</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Incremental taxonomy expander using LLM analysis of individual papers to add or adjust taxonomy nodes; frames the problem as iterative multi-label classification across multiple semantic dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td>Per-document LLM analysis to infer labels/aspects (incremental classification)</td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td>Incremental expansion and multi-label assignments aggregated across documents</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Evolving research corpora / domain-agnostic</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Evolving multidimensional taxonomies (multi-label possible)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Incremental and multidimensional framing can adapt to evolving corpora but requires careful handling of label proliferation and consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Potential label drift, scalability concerns when processing many documents sequentially.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4406.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e4406.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems, methods, or approaches that use large language models (LLMs) to extract information from, synthesize, or generate theories from multiple scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCYCHIC / Science Hierarchography</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Science Hierarchography: Hierarchical Organization of Science Literature (SCYCHIC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent system for hierarchical organization of scientific literature (cited as SCYCHIC) that constructs hierarchical structures of literature at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Science Hierarchography: Hierarchical Organization of Science Literature</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SCYCHIC (Science Hierarchography)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system for large-scale hierarchical structuring of scientific literature; cited as a recent contribution in hierarchical organization of science literature.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>synthesis_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_topic</strong></td>
                            <td>Scientific literature (general)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Hierarchical organization/taxonomies of scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as an example of recent hierarchical organization approaches; specifics not elaborated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scaling_behavior</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering', 'publication_date_yy_mm': '2025-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chime: Llm-assisted hierarchical organization of scientific studies for literature review support <em>(Rating: 2)</em></li>
                <li>TnT-LLM: Text Mining at Scale with Large Language Models <em>(Rating: 2)</em></li>
                <li>Goal-driven explainable clustering via language descriptions <em>(Rating: 2)</em></li>
                <li>Knowledge navigator: LLM-guided browsing framework for exploratory search in scientific literature <em>(Rating: 2)</em></li>
                <li>Autosurvey: Large language models can automatically write surveys <em>(Rating: 2)</em></li>
                <li>Clusterllm: Large language models as a guide for text clustering <em>(Rating: 2)</em></li>
                <li>k-llmmeans: Summaries as centroids for interpretable and scalable llm-based text clustering <em>(Rating: 2)</em></li>
                <li>TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4406",
    "paper_id": "paper-281496866",
    "extraction_schema_id": "extraction-schema-100",
    "extracted_data": [
        {
            "name_short": "Aspects-guided Top-Down Clustering",
            "name_full": "Context-Aware Hierarchical Taxonomy Generation via LLM-Guided Multi-Aspect Top-Down Clustering",
            "brief_description": "A taxonomy-construction pipeline that uses LLMs to (1) generate corpus-specific semantic aspects, (2) create aspect-guided summaries per paper, (3) encode aspect vectors, and (4) perform aspect-specific clustering with a dynamic search to produce hierarchical taxonomy trees tailored to the input corpus.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Aspects-guided LLM-based Top-Down Clustering",
            "system_description": "Top-down iterative taxonomy generator: (1) LLM-based dynamic aspect generator produces salient semantic aspects A_v for a node's paper set D_v; (2) LLMs generate aspect-guided summaries s_d^a for every paper-aspect pair; (3) embeddings (text-embedding-3-large) encode summaries into aspect-specific vector matrices e_a; (4) aspect-wise clustering (Gaussian Mixture Models) yields per-aspect cluster probabilities f_a(e,i); (5) a dynamic combinatorial search picks k_v aspect-cluster pairs to partition papers into child nodes; (6) LLM (GPT-4o) generates human-readable topic facets for nodes; repeat top-down until stopping conditions.",
            "llm_model_used": "GPT-4o (aspect generation & facet naming), LLaMA-3.1-8B (aspect-guided summarization), text-embedding-3-large (embedding)",
            "extraction_technique": "LLM-guided aspect discovery + aspect-guided summarization (prompting) followed by embedding-based encoding",
            "synthesis_technique": "Aspect-wise clustering + dynamic combinatorial search to synthesize multi-aspect cluster assignments into a coherent hierarchical taxonomy; LLMs generate node facet labels",
            "number_of_papers": "Applied to TaxoBench-CS: 11.6k papers across 156 human-authored taxonomies (avg ~74.4 papers per taxonomy)",
            "domain_or_topic": "Computer science (survey/review papers from arXiv) / scientific literature",
            "output_type": "Hierarchical taxonomies (tree of topic facets and paper partitions), node facet labels, aspect-guided summaries",
            "evaluation_metrics": "Clustering: NMI, ARI, Purity; Structure/heading: CEDS, Heading Soft Recall (HSR); Human: Coverage, Relevance, Structure, Validity, Adequacy",
            "performance_results": "Reported best results on TaxoBench-CS: NMI=60.1, ARI=19.1, Purity=62.2, CEDS=23.8, HSR=74.5; human-eval improvements across five dimensions (Coverage 50.6, Structure 59.6, Adequacy 54.4 average scores reported).",
            "comparison_baseline": "Compared against pure LLM-based pipelines (e.g., CHIME, TnT-LLM, GoalEx) and clustering-incorporated systems (e.g., Knowledge Navigator, SCYCHIC, KN).",
            "performance_vs_baseline": "Outperforms listed baselines on NMI/ARI/Purity and structural metrics (e.g., NMI 60.1 vs TnT-LLM 51.6; ARI 19.1 vs KN 16.2), and highest human-evaluation scores across metrics reported in the paper.",
            "key_findings": "Dynamic, corpus-aware aspect discovery combined with aspect-specific representations and a dynamic search over aspect-cluster assignments yields more coherent, fine-grained, and interpretable taxonomies and improved robustness to noisy inputs compared to single-aspect or end-to-end LLM label-first methods.",
            "limitations_challenges": "Dependence on LLM quality (hallucination risk), computational overhead from multi-aspect encoding and repeated clustering/search, limited scalability to extremely large corpora, current strict non-overlapping hierarchical partitioning (no multi-label nodes), benchmark limited to CS survey papers.",
            "scaling_behavior": "Observed: increasing per-node cluster count k_v raises categorization metrics (e.g., higher NMI) but harms structural alignment (CEDS) and increases node fragmentation; adaptive k_v yields balanced metrics but is computationally costly; tested robustness to 5â€“30% injected noise and reported relative stability.",
            "uuid": "e4406.0",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "CHIME",
            "name_full": "CHIME: LLM-assisted hierarchical organization of scientific studies for literature review support",
            "brief_description": "A pure LLM-based system that produces a taxonomy and assigns papers in a single pass using LLM prompting to induce labels and assignments.",
            "citation_title": "Chime: Llm-assisted hierarchical organization of scientific studies for literature review support",
            "mention_or_use": "use",
            "system_name": "CHIME",
            "system_description": "An end-to-end LLM-driven taxonomy pipeline that prompts an LLM to generate hierarchical labels and assign papers to labels in one pass (label-first, direct prompting).",
            "llm_model_used": null,
            "extraction_technique": "Direct prompting / end-to-end taxonomy induction and label assignment by LLM",
            "synthesis_technique": "Single-pass label generation and direct paper-to-label assignment (no separate aspect-specific clustering)",
            "number_of_papers": null,
            "domain_or_topic": "Scientific literature / literature review support",
            "output_type": "Hierarchical taxonomy and paper assignments (labels + membership)",
            "evaluation_metrics": "NMI, ARI, Purity, CEDS, HSR, human evaluation (as used in this paper's comparison)",
            "performance_results": "Reported in paper's Table 2 (example values): NMI ~35.4 (lower than multi-aspect method); specific numbers reported in the shared evaluation table.",
            "comparison_baseline": "Compared against other pure LLM-based and clustering-incorporated methods in the paper",
            "performance_vs_baseline": "Per the paper's experiments, CHIME underperforms the proposed multi-aspect clustering approach on categorization and structural alignment metrics.",
            "key_findings": "One-pass LLM label-first approaches can be flexible but risk hallucinated or missing categories and produce imbalanced hierarchies without corpus-aware constraints.",
            "limitations_challenges": "Tends to miss fine-grained, domain-specific distinctions and can hallucinate categories; less corpus-context awareness than clustering-integrated approaches.",
            "scaling_behavior": null,
            "uuid": "e4406.1",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "TnT-LLM",
            "name_full": "TnT-LLM: Text Mining at Scale with Large Language Models",
            "brief_description": "An iterative LLM-based system that generates and updates label taxonomies while processing documents, designed for large-scale text mining.",
            "citation_title": "TnT-LLM: Text Mining at Scale with Large Language Models",
            "mention_or_use": "use",
            "system_name": "TnT-LLM",
            "system_description": "An iterative label-first pipeline where the LLM generates and refines taxonomy labels over multiple iterations, updating paper assignments and taxonomy structure progressively.",
            "llm_model_used": null,
            "extraction_technique": "Iterative LLM prompting to generate/update labels and assign papers",
            "synthesis_technique": "Iterative taxonomy refinement (label generation + reassignment across iterations)",
            "number_of_papers": null,
            "domain_or_topic": "General text mining / literature",
            "output_type": "Taxonomy labels and paper clusters/assignments",
            "evaluation_metrics": "NMI, ARI, Purity, CEDS, HSR, human evaluation (as used in this paper's comparisons)",
            "performance_results": "Reported NMI in this paper: ~51.6 (baseline value cited in main text), lower than the proposed method's 60.1.",
            "comparison_baseline": "Compared against multi-aspect clustering method and other LLM-based approaches in the paper",
            "performance_vs_baseline": "Underperforms the proposed approach on NMI and structural metrics per reported results (e.g., NMI 51.6 vs 60.1).",
            "key_findings": "Iterative label updating helps improve taxonomy quality over one-shot label induction, but still lacks corpus-tailored multi-aspect representations.",
            "limitations_challenges": "Susceptible to hallucinated labels and limited corpus-context awareness; label-first pipelines can produce redundant or missing categories.",
            "scaling_behavior": null,
            "uuid": "e4406.2",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "GoalEx",
            "name_full": "GoalEx (Goal-driven explainable clustering via language descriptions)",
            "brief_description": "Aligns LLM-generated natural-language explanations with papers and uses integer linear programming to select a non-overlapping consistent set of assignments.",
            "citation_title": "Goal-driven explainable clustering via language descriptions",
            "mention_or_use": "use",
            "system_name": "GoalEx",
            "system_description": "Generates explanations/descriptions for candidate clusters via LLMs and formulates an integer linear program to pick a non-overlapping, globally consistent set of cluster-to-paper assignments.",
            "llm_model_used": null,
            "extraction_technique": "LLM-generated language descriptions/explanations used to connect papers to cluster descriptions",
            "synthesis_technique": "Optimization (integer linear programming) to reconcile LLM outputs into a globally consistent assignment",
            "number_of_papers": null,
            "domain_or_topic": "General text / document clustering",
            "output_type": "Cluster assignments with explainable descriptions",
            "evaluation_metrics": "Clustering metrics (NMI, ARI, Purity) and structural/heading metrics in comparative evaluation",
            "performance_results": "Reported NMI in paper table: ~46.7 (lower than the proposed multi-aspect method's 60.1).",
            "comparison_baseline": "Compared alongside other LLM-based and clustering methods in the paper",
            "performance_vs_baseline": "Per the paper's evaluation, GoalEx underperforms the multi-aspect approach on several clustering and structural metrics.",
            "key_findings": "Combining LLM explanations with a global optimization can reduce local inconsistencies, but explanation alignment alone is insufficient for fine-grained, corpus-aware taxonomy generation.",
            "limitations_challenges": "May still produce inconsistent or redundant labels if explanations lack corpus-level context; optimization overhead.",
            "scaling_behavior": null,
            "uuid": "e4406.3",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "Knowledge Navigator (KN)",
            "name_full": "Knowledge Navigator: LLM-guided browsing framework for exploratory search in scientific literature",
            "brief_description": "An LLM-guided exploratory search/browsing framework that helps users navigate scientific literature and can be used to cluster or organize papers.",
            "citation_title": "Knowledge navigator: LLM-guided browsing framework for exploratory search in scientific literature",
            "mention_or_use": "use",
            "system_name": "Knowledge Navigator (KN)",
            "system_description": "LLM-guided exploratory search and browsing tool that supports document organization; used as a baseline single-stage flat clustering method in comparisons.",
            "llm_model_used": null,
            "extraction_technique": "LLM-guided retrieval and explanation; used to support clustering or browsing",
            "synthesis_technique": "Single-stage flat clustering with LLM guidance and manual/automated label extraction",
            "number_of_papers": null,
            "domain_or_topic": "Scientific literature exploration / computer science (in comparative experiments)",
            "output_type": "Flat clusters, browsing aids, taxonomy-like structures",
            "evaluation_metrics": "NMI, ARI, Purity, structural metrics and human evaluation (per paper comparisons)",
            "performance_results": "Reported ARI in main text for KN: ~16.2 (compared to the proposed method's ARI 19.1); NMI and other metrics lower than proposed method.",
            "comparison_baseline": "Benchmarked in the paper against the proposed multi-aspect method and other baselines",
            "performance_vs_baseline": "Underperforms the multi-aspect dynamic clustering method on clustering and structure alignment metrics in this paper's experiments.",
            "key_findings": "Single-stage flat clustering guided by LLMs can be useful for exploratory search but may lack hierarchical coherence and fine-grained separation captured by multi-aspect approaches.",
            "limitations_challenges": "Flat clustering lacks hierarchical structure; may not capture multi-faceted distinctions among papers.",
            "scaling_behavior": null,
            "uuid": "e4406.4",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "ClusterLLM",
            "name_full": "ClusterLLM: Large language models as a guide for text clustering",
            "brief_description": "A framework that uses LLMs to guide text clustering, typically by generating summaries or labels that inform clustering steps or centroids.",
            "citation_title": "Clusterllm: Large language models as a guide for text clustering",
            "mention_or_use": "mention",
            "system_name": "ClusterLLM",
            "system_description": "Uses LLMs to produce language-based guidance (summaries, labels, constraints) to steer unsupervised clustering algorithms; acts as a bridge between LLM semantic knowledge and clustering methods.",
            "llm_model_used": null,
            "extraction_technique": "LLM-generated summaries/labels used as clustering guidance",
            "synthesis_technique": "Combine language descriptions with clustering algorithms (e.g., using descriptions as centroids or constraints)",
            "number_of_papers": null,
            "domain_or_topic": "General text/document clustering",
            "output_type": "Cluster assignments with human-readable labels/descriptions",
            "evaluation_metrics": "Clustering metrics (NMI, ARI, Purity) in original work (cited here as related work)",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "LLM-produced textual guidance can improve clustering interpretability and semantic alignment, but requires careful integration with vector-space methods.",
            "limitations_challenges": "Potential mismatch between text descriptions and embedding geometry; cost of LLM calls for many clusters or documents.",
            "scaling_behavior": null,
            "uuid": "e4406.5",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "k-llmmeans",
            "name_full": "k-llmmeans: Summaries as centroids for interpretable and scalable LLM-based text clustering",
            "brief_description": "An approach that uses LLM-generated summaries as cluster centroids to produce interpretable and scalable clustering outcomes.",
            "citation_title": "k-llmmeans: Summaries as centroids for interpretable and scalable llm-based text clustering",
            "mention_or_use": "mention",
            "system_name": "k-llmmeans",
            "system_description": "Uses LLM-generated summary texts to represent centroids in a clustering algorithm, enabling interpretable clusters and scalable summary-based centroid updates.",
            "llm_model_used": null,
            "extraction_technique": "LLM summaries used as centroid representations; embedding-based similarity to assign documents",
            "synthesis_technique": "Summary-centroid-based clustering (iteratively update centroids via LLM summaries and assign papers by embedding similarity)",
            "number_of_papers": null,
            "domain_or_topic": "General text clustering",
            "output_type": "Interpretable clusters with summary centroids",
            "evaluation_metrics": "Clustering quality and interpretability (as discussed in cited work)",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Using summaries as centroids provides interpretable cluster anchors and can scale clustering while leveraging LLM abstraction capabilities.",
            "limitations_challenges": "Dependent on summary fidelity and embedding alignment; cost of generating many summaries.",
            "scaling_behavior": null,
            "uuid": "e4406.6",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "AutoSurvey",
            "name_full": "AutoSurvey: Large language models can automatically write surveys",
            "brief_description": "Automated survey-generation pipelines that draft hierarchical outlines of target topics and attach relevant papers, replacing explicit taxonomies with structured outlines.",
            "citation_title": "Autosurvey: Large language models can automatically write surveys",
            "mention_or_use": "mention",
            "system_name": "AutoSurvey (and related pipelines: Storm, SurveyForge)",
            "system_description": "Outline-first pipelines: LLM drafts a hierarchical outline of topics, then retrieval modules attach supporting papers/paragraphs to each outline entry to produce an automated literature survey.",
            "llm_model_used": null,
            "extraction_technique": "Prompted LLM outline generation plus retrieval to attach papers (retrieval+generation)",
            "synthesis_technique": "Outline-driven retrieval and hierarchical assembly of summaries and citations (hierarchical summarization / assembly)",
            "number_of_papers": null,
            "domain_or_topic": "Automated literature survey generation across domains (cited as related work)",
            "output_type": "Structured survey outlines and assembled literature reviews",
            "evaluation_metrics": "Human evaluation, readability/coherence metrics, and task-specific measures in the cited works",
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Outline-first strategies can produce usable survey drafts but risk redundant labels, hallucinated or missing categories, and imbalanced hierarchies without corpus-aware constraints.",
            "limitations_challenges": "Label hallucination, redundancy, and potential retrieval-attachment mismatches; limited structural fidelity to expert taxonomies.",
            "scaling_behavior": null,
            "uuid": "e4406.7",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "TaxoAdapt",
            "name_full": "TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora",
            "brief_description": "An incremental multidimensional taxonomy expansion system that analyzes papers one-by-one and frames taxonomy construction as iterative multi-label classification.",
            "citation_title": "TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora",
            "mention_or_use": "mention",
            "system_name": "TaxoAdapt",
            "system_description": "Incremental taxonomy expander using LLM analysis of individual papers to add or adjust taxonomy nodes; frames the problem as iterative multi-label classification across multiple semantic dimensions.",
            "llm_model_used": null,
            "extraction_technique": "Per-document LLM analysis to infer labels/aspects (incremental classification)",
            "synthesis_technique": "Incremental expansion and multi-label assignments aggregated across documents",
            "number_of_papers": null,
            "domain_or_topic": "Evolving research corpora / domain-agnostic",
            "output_type": "Evolving multidimensional taxonomies (multi-label possible)",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Incremental and multidimensional framing can adapt to evolving corpora but requires careful handling of label proliferation and consistency.",
            "limitations_challenges": "Potential label drift, scalability concerns when processing many documents sequentially.",
            "scaling_behavior": null,
            "uuid": "e4406.8",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        },
        {
            "name_short": "SCYCHIC / Science Hierarchography",
            "name_full": "Science Hierarchography: Hierarchical Organization of Science Literature (SCYCHIC)",
            "brief_description": "A recent system for hierarchical organization of scientific literature (cited as SCYCHIC) that constructs hierarchical structures of literature at scale.",
            "citation_title": "Science Hierarchography: Hierarchical Organization of Science Literature",
            "mention_or_use": "mention",
            "system_name": "SCYCHIC (Science Hierarchography)",
            "system_description": "A system for large-scale hierarchical structuring of scientific literature; cited as a recent contribution in hierarchical organization of science literature.",
            "llm_model_used": null,
            "extraction_technique": null,
            "synthesis_technique": null,
            "number_of_papers": null,
            "domain_or_topic": "Scientific literature (general)",
            "output_type": "Hierarchical organization/taxonomies of scientific literature",
            "evaluation_metrics": null,
            "performance_results": null,
            "comparison_baseline": null,
            "performance_vs_baseline": null,
            "key_findings": "Cited as an example of recent hierarchical organization approaches; specifics not elaborated in this paper.",
            "limitations_challenges": null,
            "scaling_behavior": null,
            "uuid": "e4406.9",
            "source_info": {
                "paper_title": "Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering",
                "publication_date_yy_mm": "2025-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chime: Llm-assisted hierarchical organization of scientific studies for literature review support",
            "rating": 2,
            "sanitized_title": "chime_llmassisted_hierarchical_organization_of_scientific_studies_for_literature_review_support"
        },
        {
            "paper_title": "TnT-LLM: Text Mining at Scale with Large Language Models",
            "rating": 2,
            "sanitized_title": "tntllm_text_mining_at_scale_with_large_language_models"
        },
        {
            "paper_title": "Goal-driven explainable clustering via language descriptions",
            "rating": 2,
            "sanitized_title": "goaldriven_explainable_clustering_via_language_descriptions"
        },
        {
            "paper_title": "Knowledge navigator: LLM-guided browsing framework for exploratory search in scientific literature",
            "rating": 2,
            "sanitized_title": "knowledge_navigator_llmguided_browsing_framework_for_exploratory_search_in_scientific_literature"
        },
        {
            "paper_title": "Autosurvey: Large language models can automatically write surveys",
            "rating": 2,
            "sanitized_title": "autosurvey_large_language_models_can_automatically_write_surveys"
        },
        {
            "paper_title": "Clusterllm: Large language models as a guide for text clustering",
            "rating": 2,
            "sanitized_title": "clusterllm_large_language_models_as_a_guide_for_text_clustering"
        },
        {
            "paper_title": "k-llmmeans: Summaries as centroids for interpretable and scalable llm-based text clustering",
            "rating": 2,
            "sanitized_title": "kllmmeans_summaries_as_centroids_for_interpretable_and_scalable_llmbased_text_clustering"
        },
        {
            "paper_title": "TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora",
            "rating": 2,
            "sanitized_title": "taxoadapt_aligning_llmbased_multidimensional_taxonomy_construction_to_evolving_research_corpora"
        }
    ],
    "cost": 0.023345750000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering
23 Sep 2025</p>
<p>Kun Zhu kzhu@ir.hit.edu 
Harbin Institute of Technology</p>
<p>Lizi Liao lzliao@smu.edu.sg 
Singapore Management University</p>
<p>Yuxuan Gu yxgu@ir.hit.edu 
Harbin Institute of Technology</p>
<p>Lei Huang lhuang@ir.hit.edu 
Harbin Institute of Technology</p>
<p>Xiaocheng Feng xcfeng@ir.hit.edu 
Harbin Institute of Technology</p>
<p>Peng Cheng Laboratory</p>
<p>Bing Qin 
Harbin Institute of Technology</p>
<p>Peng Cheng Laboratory</p>
<p>Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering
23 Sep 20252B2D0501D30C5FCB7F8E693E9B66405AarXiv:2509.19125v1[cs.CL]
The rapid growth of scientific literature demands efficient methods to organize and synthesize research findings.Existing taxonomy construction methods, leveraging unsupervised clustering or direct prompting of large language models (LLMs), often lack coherence and granularity.We propose a novel context-aware hierarchical taxonomy generation framework that integrates LLM-guided multi-aspect encoding with dynamic clustering.Our method leverages LLMs to identify key aspects of each paper (e.g., methodology, dataset, evaluation) and generates aspect-specific paper summaries, which are then encoded and clustered along each aspect to form a coherent hierarchy.In addition, we introduce a new benchmark of 156 expert-crafted taxonomies encompassing 11.6 k papers, providing the first naturally annotated dataset for this task.Experimental results demonstrate that our method significantly outperforms prior approaches, achieving stateof-the-art performance in taxonomy coherence, granularity, and interpretability. 1 * Work was done during an internship at SMU.</p>
<p>Introduction</p>
<p>The rapid expansion of academic publications has created an overwhelming amount of information, making it increasingly challenging for researchers to stay up-to-date and systematically organize domain knowledge (Reisz et al., 2022;Hanson et al., 2024;Vineis, 2024).As a result, there is a growing demand for structured and concise taxonomies that can support the exploration and synthesis of more efficient literature (Shen et al., 2018;Zhu et al., 2023).Traditional approaches to building taxonomies of scientific papers typically rely on manual or narrowly defined schemes.Common solutions include supervised classification into a pre- Recent approaches incorporate LLMs to replace or enhance key components within these pipelines (purple).Our approach uniquely integrates LLMs with clustering in a context-aware multi-aspect framework, resulting in coherent and precise hierarchical taxonomies.defined hierarchy (e.g., ACM CCS) (Zhang et al., 2021;Sadat and Caragea, 2022;Rao et al., 2023) and unsupervised clustering of papers followed by post-hoc keyword-based label extraction (Zhang et al., 2018;Shang et al., 2020).These methods often require substantial human curation or yield coarse topic structures, limiting their usefulness for in-depth literature understanding.</p>
<p>Recent advances utilize LLMs to automate the taxonomy construction.LLMs demonstrate strong capabilities in long-text understanding and abstraction (Achiam et al., 2023; Grattafiori et al., 2024), leading to approaches that generate taxonomy trees or assign papers to categories in an end-to-end fashion (Hsu et al., 2024;Wan et al., 2024).Hybrid strategies first cluster papers and then prompt LLMs to produce summaries or category labels for each cluster (Katz et al., 2024;Hu et al., 2025).</p>
<p>While these LLM-based methods have shown promise, studies have found that they struggle to capture highly specialized knowledge and finegrained concepts specific to scientific domains.Moreover, taxonomies produced solely by LLMs are not guaranteed to align with the content of a given corpus, often resulting in missing or hallucinated categories.Effective taxonomy construction inherently demands context-aware representations, wherein the characterization of each paper dynamically adapts based on its relationships and similarities to surrounding papers.Without this context awareness, papers focusing on distinct aspects (e.g., methodologies v.s.datasets) might be incorrectly categorized, leading to incoherent taxonomy structures.This gap calls for new techniques that consider multiple content dimensions and their corpuslevel context during taxonomy generation.</p>
<p>In this paper, we propose a novel framework for paper taxonomy generation that leverages LLMguided, multi-aspect representations in conjunction with adaptive clustering.Specifically, our approach uses a dynamic aspect generator to automatically determine salient semantic aspects (such as research objective, methodology, or data source) for a given collection of papers.Guided by these, the LLM produces aspect-specific summaries for each paper, ensuring that each document is represented in a manner that is both facet-specific and context-aware.We then employ a dynamic clustering algorithm to search for an optimal grouping of papers for each aspect dimension.By iteratively applying multi-aspect encoding and clustering in a top-down fashion, our framework constructs a hierarchical taxonomy tree that is tailored to the corpus at each level.This design allows the taxonomy to capture different facets of the literature at different branches, yielding more coherent and interpretable category structures.</p>
<p>In addition to methodological innovations, a significant bottleneck in this area has been the lack of high-quality, naturally annotated datasets for evaluating taxonomy construction.Most existing benchmarks are synthetic (Hsu et al., 2024) or rely on coarse (Katz et al., 2024), predefined categories that fail to reflect the nuanced hierarchies.To bridge this gap, we construct a new dataset of academic taxonomies TaxoBench-CS, by collecting 156 human-authored taxonomy trees (covering 11.6 k research papers) from survey and review articles on arXiv.These taxonomies, created by domain experts, provide realistic hierarchical structures that mirror a deep understanding of topic decomposition.This dataset offers a valuable resource for training and evaluating taxonomy generation methods under more natural conditions, and we will release it to foster further research.</p>
<p>In summary, our contributions are threefold:</p>
<p>â€¢ We curate a high-quality benchmark consisting of 156 expert-annotated taxonomies of 11.6 k papers, facilitating future research.</p>
<p>â€¢ We propose to combine multi-aspect paper encoding with a dynamic clustering algorithm, enabling context-aware, hierarchical organization of research papers.â€¢ Our approach outperforms existing state-ofthe-art methods, yielding interpretable and human-readable taxonomy trees with significantly improved coherence and granularity.</p>
<p>Preliminary</p>
<p>Here, we first formalize the task of taxonomy construction for scientific literature.We then describe the creation of a new benchmark dataset derived from human-authored taxonomies in survey papers.</p>
<p>Task Definition</p>
<p>Given a specific topic x and a collection of corresponding scientific papers D = {d 1 , d 2 , . . ., d N }, the objective is to generate a hierarchical taxonomy T (V, E) that organizes these papers into a tree structure of semantically coherent categories.</p>
<p>In detail, the taxonomy of depth L starts from a root node r âˆˆ V (0) and each node v âˆˆ V (l) corresponds to a depth l, where V = L l=0 V (l) .In addition, each node v is associated with a subset of papers D v âŠ† D and a topic facet x v (e.g., highlevel methodological approaches, underlying mechanisms or learning paradigms, or specific research tasks and evaluation scenarios).The root node r represents the overarching topic x and encompasses all papers D r = D.For every non-leaf node v âˆˆ V (l&lt;L) , its k v child nodes Child(v) form a complete, non-overlapping partition of the papers subset D v , satisfying the constraints:
Child(v) = v 1 , v 2 , . . . , v kv âŠ† V (l+1) , with ï£± ï£² ï£³ kv t=1 D vt = D v D vt D v t â€² = âˆ…, âˆ€t Ì¸ = t â€² . (1)
Edges typically represent hierarchical semantic relations (e.g., isA, instanceOf ) and are restricted to link nodes across adjacent layers, where  1: Comparison of existing taxonomy datasets: Datasets are evaluated based on three key criteria: clustering annotations, hierarchical structures, and ground-truth labels.We also distinguish whether datasets are synthetic or naturally derived.Our dataset uniquely meets all three criteria while being naturally sourced.
E = Lâˆ’1 l=0 E (l) , E (l) âŠ† V (l) Ã— V (l+1
In our framework, the taxonomy is built iteratively by partitioning each subset D v from the depth l into disjoint subsets assigned to its children.</p>
<p>Dataset Construction</p>
<p>Existing datasets for evaluating taxonomy generation methods generally rely on either topic-based retrieval followed by manual annotation (Katz et al., 2024) or LLM-assisted taxonomy creation and filtering (Hsu et al., 2024; Gao et al., 2025).However, these approaches often introduce noise into the structure and lack high-quality, reliably annotated ground-truth hierarchies.</p>
<p>To address these limitations, we introduce a new benchmark dataset, TaxoBench-CS, constructed from naturally annotated taxonomy trees found in computer science review papers on arXiv 2 .We start by systematically selecting survey papers that contain explicit hierarchical taxonomy diagrams.By parsing the corresponding L A T E X source files, we extract citation identifiers directly linked to taxonomy structures, which are then mapped to their full titles using the citation metadata provided in each paper's associated .bibor .bblfiles.Next, we retrieve detailed paper metadata from Semantic Scholar 3 .To ensure the dataset's accuracy and reliability, we manually verify all citation mappings, eliminating any incorrect or ambiguous entries.</p>
<p>The final TaxoBench-CS dataset consists of 156 author-curated taxonomy trees, serving as robust hierarchical annotations.Each taxonomy contains, on average, 74.4 referenced papers and spans 3.1 levels in depth.Excluding the paper citation indicators connected to the leaf-level nodes, each tree includes around 24.8 nodes that represent structured semantic categories, providing a rich and structurally sound resource.As shown in Table 1, our proposed TaxoBench-CS uniquely combines explicit clustering structures, hierarchical organization, and authoritative annotations derived 2 https://arxiv.org/ 3 https://www.semanticscholar.org/me/researchdirectly from naturally occurring expert-curated taxonomies.This combination makes it an ideal benchmark for evaluating and developing taxonomy generation methods under realistic conditions.</p>
<p>Method</p>
<p>The core of our method lies in appropriately decomposing the given node v of depth l according to the structure and semantics of its associated paper set D v .We first represent papers in the associated paper set d i âˆˆ D v using multi-aspect encoding ( Â§3.1).Given the clustering results over the multiaspect vectors of D v , we apply a dynamic search algorithm to determine the most appropriate partitioning strategy ( Â§3.2).Therefore, we can iteratively partition the paper set D v and get the child nodes Child(v) of node v from a top-down manner to construct the taxonomy tree ( Â§3.3).</p>
<p>Multi-Aspect Paper Encoding</p>
<p>In this part, our goal is to obtain a global representation of the paper set D v that captures its overall semantic structure.To this end, we propose to automatically generate a set of candidate aspects A v using an LLM based on all papers in D v .These aspects are then used in a parallel manner to guide the encoding of individual papers.The aspect generator is defined as follows:
A v âˆ¼ p LLM (A|v, D v ),(3)
where we prompt the LLM such as GPT-4o to analyze the paper distribution in D v according to the global trace of current node v (topic facets of v and all its ancestor nodes) before generating the detailed content of aspects A v .In addition, the LLM is required to infer the number of aspects |A v | automatically.We demand the LLM to identify a set of salient semantic dimensions that can effectively characterize and classify the papers, such as research problem and application domain.</p>
<p>Given the discovered aspects a âˆˆ A v , we parallelly generate aspect-guided summaries s d a for each
For all a, d âˆˆ A v Ã— D v in parallel : e d a = Enc(s d a ), s d a âˆ¼ p LLM (s|a, d) .(4)
We collect the encoding of paper set D v for each aspect and obtain e a = {e d a | âˆ€d âˆˆ D v }, which can also be regarded as a matrix e a âˆˆ R |Dv|Ã—n .</p>
<p>Clustering with Dynamic Search</p>
<p>Given that encoding across different aspects may reside in heterogeneous semantic spaces with varying structures and scales, directly aggregating all representation vectors e = {e d a | âˆ€d âˆˆ D v , âˆ€a âˆˆ A v } into a unified space for clustering would be inappropriate.Therefore, we perform clustering independently within each aspect space e a : For all a âˆˆ A v in parallel :
f a : e a Ã— {1, 2, . . . , k} â†’ [0, 1] Expectation : âˆ€i âˆˆ {1, 2, . . . , k}, C i a = e d a arg max j f a (e d a , j) = i, âˆ€d âˆˆ D v Maximization : L cluster a = âˆ’ k i=1 eâˆˆC i a f a (e, i),(5)
where C i a is the temporary allocation of the cluster index i and f a is the clustering model that maps the encoding vector e to the cluster i with a probability of f a (e, i), k i=1 f a (e, i) = 1.In addition, k is a hyperparameter that determines the number of clusters, where
k v â‰¤ |A v | Ã— k.
Given the cluster assignment probabilities for each aspect, we need to select for each paper d âˆˆ D v a unique pair (a, i), where a is an aspect and i is a cluster index within that aspect, such that: (1) Each paper d will be assigned to only one cluster i. (2) The total number of unique pairs (a, i) used in the paper set D v is k v .(3) The total assignment probability is maximized.Therefore, we define a binary indicator Î´ d a,i âˆˆ {0, 1} and the objective:
max Î´ dâˆˆDv aâˆˆAv k i=1 Î´ d a,i â€¢ f a (e d a , i),(6)
which is subject to:
aâˆˆAv k i=1 Î´ d a,i = 1, âˆ€d âˆˆ D v (a, i) âˆƒd âˆˆ D v s.t. Î´ d a,i = 1 = k v .(7)
As a result, we have the search process as illustrated in the algorithm 1, where we directly define a search space S containing all possible combinations S âŠ† A v Ã— {1, 2, . . ., k} that satisfy |S| = k v .Each S encodes a specific clustering scheme with k v unique aspect-cluster assignments (a, i).We adopt a real-time strategy that the score of every combination S is updated as each paper d âˆˆ D v arrives, where we trace the optimal assignment Algorithm 1 Search with Pruning trajectory via the state variable.Optionally, we can randomize the iterative order of the papers and prune the low-scoring combinations during the process to reduce search space and improve efficiency.After processing all documents, the algorithm returns the highest score combination S * along with its trajectory optimal_state.</p>
<p>We can extract the partitioned paper sets D vt from the trajectory optimal_state and generate the topic facet x vt with LLM as follows: For all (a, i) âˆˆ S * , t âˆˆ {1, . . ., k v } in parallel :
D vt = {d | âˆ€d âˆˆ optimal_state[(a, i)]} x vt âˆ¼ p LLM (x|v, D vt , S * ) v t â‰œ âŸ¨x vt , D vt âŸ©, E (l) â† E (l) âˆª {(v, v t )},(8)
where the node v t is connected to its parent v.</p>
<p>Iterative Structure Generation</p>
<p>As illustrated in Figure 2, our method constructs the taxonomy in a top-down manner, starting from the root node r and iteratively expanding the child nodes Child(v) for node v from each depth l, this is decomposing the associated paper set D v and generating a corresponding topic facet x v that characterizes the semantic focus of its substructure.</p>
<p>During each expansion step, we dynamically generate new aspects based on the current distribution of the papers in D v .This process is tailored to capture the updated salient semantic dimensions and key distinctions among papers within the new partitioned subset.It is worth noting that we incorporate the topic facets of all ancestor nodes into the prompt context.This ensures that the newly generated aspects reflect not only local document features, but also the global structural direction of the taxonomy, thereby better understanding the direction in which the current node needs to be expanded.The expansion process continues until a stopping condition is met, such as reaching a maximum depth L or encountering the number of papers in the node below a predefined threshold.Once the expansion is complete, the resulting tree constitutes the taxonomy of given topic and papers.</p>
<p>Experiments</p>
<p>Baselines</p>
<p>We compare our approach with two categories of methods: pure LLM-based and clusteringincorporated taxonomy generation.</p>
<p>Experimental Settings</p>
<p>We employ GPT-4o (2024-08-06) for aspect generation (eq. 3) and topic facet generation (eq.8), due to its superior reasoning and abstraction capabilities.Besides, we use LLaMA-3.1-8B to generate aspect-guided summaries (eq.4), as it requires less complex reasoning to locate and extract relevant information from the paper.This division enables a balance between generation quality and computational cost across the pipeline.Following Katz et al. ( 2024), we adopt textembedding-3-large for paper encoding (eq.4) and use Gaussian Mixture Models (GMMs) as the aspect-specific clustering model f a (e, i) (eq.5).In the main experiments, the number of clusters per aspect k and the number of child nodes per parent node k v are both empirically set as 4. The maximum taxonomy depth is limited to L = 3. See the prompts that we use in the Appendix C. Due to computational and manual costs, we randomly sample 25 of the 156 taxonomy instances for human evaluation and ablation studies.Each configuration was executed once with a fixed random seed, and results are averaged over the sampled instances.</p>
<p>Evaluation Metrics</p>
<p>We evaluate taxonomy generation from two complementary perspectives: papers categorization and topic structure, using both automatic and human evaluation.Full metric definitions and annotation guidelines are provided in Appendix A. Automatic Evaluation.To assess papers categorization, we report three widely used clustering metrics: Normalized Mutual Information (NMI), Adjusted Rand Index (ARI), and Purity.For topic quality and structural alignment, we adopt Heading Soft Recall (HSR) (FrÃ¤nti and Mariescu-Istodor, 2023) and Catalogue Edit Distance Similarity (CEDS) (Zhu et al., 2023).In addition, we use a normalized Nodes Ratio, defined as the number of generated nodes divided by the number of nodes in the oracle taxonomy, as an auxiliary metric to monitor coarse-grained structural discrepancies.Human Evaluation.Following Hu et al. (2024), we conduct human evaluation on five dimensions: Coverage, Relevance, Structure, Validity, and Adequacy.Each dimension is rated on a scale of 1 to 100 to allow fine-grained comparisons.The evaluation is performed by six reviewers: three PhD students in computer science and three advanced LLMs: GPT-4o (2024-11-20), Claude 3.7 Sonnet (2025-02-19), and LLaMA-3.3-70BInstruct.</p>
<p>Main Results</p>
<p>Best categorization performance.We obtain the best categorization performance, with NMI (60.1),ARI (19.1), and Purity (62.2), surpassing both pure LLM-based baselines (e.g., TnT-LLM with NMI of 51.6) and clustering-incorporated baselines (e.g., KN with ARI of 16.2).This proves the superiority of our multi-aspect framework in producing more coherent and well-separated clusters, offering a more reliable foundation for semantic organization.Superior structure alignment.We achieve the highest CEDS score of 23.8, indicating strong structural consistency with oracle taxonomies.The HSR score of 74.5 confirms that our method possesses the ability to recover coherent hierarchical relations.In addition, the node ratio of 1.2 suggests a balanced taxonomy size, avoiding the situation of both over-fragmentation and under-segmentation.Preferred by human evaluators.As shown in Table 2, our method receives the highest human evaluation scores in all five dimensions, with notable improvements in Coverage (50.6), Structure (59.6), and Adequacy (54.4).This indicates that our generated taxonomies cover more comprehensive contents and exhibit a more coherent organization of the structure, thereby enhancing the usability.The agreement between the annotators measured by Fleiss's Kappa on discretized scores (converted from a scale of 1 to 100 to a scale of Table 3: Ablation results on aspect generation and dynamic search."Dynamic Aspects" means our dynamic aspect generation process, while "Fixed Aspects" is using fixed manual aspects."Search" denotes dynamic clusters search and "Prune" is the pruning strategy in the search process."Abstract" means only using the paper abstracts without aspect guidance.</p>
<p>5 points) is 0.24, indicating moderate consistency among the evaluators.</p>
<p>Ablation Study on Aspect Generation and Dynamic Search</p>
<p>We conduct an ablation study to examine the impact of aspect generation methods and clustering strategies on taxonomy quality in Table 3. Dynamic v.s.Fixed Aspects.We first compare our proposed dynamic aspect generation (Dynamic Aspects) with a manually defined aspect template shared across all paper sets (Fixed Aspects).The results show that the dynamic aspects achieve consistently better performance in both categorization (e.g., NMI 57.8 v.s.55.2) and structural alignment (e.g., HSR 69.9 v.s.68.6).This highlights the benefit of tailoring semantic dimensions to each paper set, which better captures latent topical variations and improves clustering quality.Full v.s.Pruning Search.Within each setting, we compare two clustering strategies: Full Search and Pruning Search.For the fixed-aspect setting, pruning significantly reduces categorization and structure performance, indicating that simple greedy filtering may break high-quality groupings formed under strong human priors.In contrast, under the dynamic aspect setting, pruning yields comparable performance to full dynamic search.This suggests that while LLM-generated aspects offer higher representational flexibility, they also introduce variability and redundancy, where pruning can help remove outliers with little degradation.Effect of Using Abstracts Only.Finally, we include a baseline that uses only abstracts of papers  without aspects.Although it performs reasonably well in ARI (22.3), its overall categorization and structure scores remain lower than our full model.This underscores the importance of aspect-guided representation beyond manual summarization.</p>
<p>Effect of Hyperparameter k v</p>
<p>We analyze the influence of the hyperparameter k v , which controls the number of clusters generated at each node during hierarchical taxonomy construction.The adaptive strategy achieves relatively balanced performance across all metrics rather than a significant improvement in any individual metric (NMI 56.2, ARI 21.5, CEDS 23.9).Moreover, the adaptive strategy requires repeated clustering operations for all k v , resulting in substantially higher computational overhead.Coupled with only marginal improvements, the high cost suggests that silhouette-based selection may offer limited practical benefit in taxonomy generation.</p>
<p>Robustness to Noisy Inputs</p>
<p>To evaluate the robustness of our method under more realistic settings, where the initial set of relevant papers is not perfectly curated, we conducted additional experiments simulating noisy input conditions, as suggested by Reviewer RHVv.Specifically, we injected 5%-30% unrelated papers into the curated dataset to mimic potential noise introduced by retrieval-based pipelines.Experimental results (see Table 5) show that our method consistently outperforms baseline approaches and maintains superior performance and structural stability across all noise levels.In contrast, TnT-LLM suffers from significant performance fluctuations, and SCYCHIC experiences moderate degradation.</p>
<p>We attribute this robustness to two key design choices in our framework: Aspect-aware clustering with dynamic search, which selectively identifies the most relevant combination of aspect dimensions for each paper, effectively filtering out noise; Expanded representation space of aspect-cluster combinations, which allows noisy or outlier papers to be isolated into peripheral nodes without disrupting the core taxonomy structure.</p>
<p>These findings highlight the error-tolerant nature of our approach and demonstrate its effectiveness even when applied to noisy, less curated document sets.We believe this provides strong evidence of the method's practical applicability beyond oraclelike experimental conditions.</p>
<p>Case-Study</p>
<p>Comparison with Human-Annotated Taxonomy. 1 At the top level, both taxonomies adopt a method-based categorization (e.g., quantization, pruning, distillation), which is largely consistent.Only one paper (28) is misclassified.In deeper layers, our taxonomy introduces more fine-grained and diverse subtopics.While these differ from the human taxonomy, they reflect alternative yet valid grouping strategies based on implementation details or use cases.This highlights the subjectivity of deeperlevel structuring and the model's ability to surface meaningful semantic distinctions.</p>
<p>Related Work</p>
<p>Organizing the ever-growing scientific literature into coherent, hierarchical categories remains a core challenge in scholar knowledge management.Traditional approaches typically rely on manually curated taxonomies, where each paper is mapped to one or more predefined categories within a multilevel hierarchy (Zhang et  In the classification paradigm, an LLM first induces a taxonomy, and papers are subsequently assigned (Pham et 2025) explore hierarchical strategies (bottom-up, top-down, and bi-direction).However, these approaches often rely on local, per-cluster descriptions in isolation, yielding redundant or inconsistent labels due to missing global context and weak structural constraints.In contrast, our method proposes dynamic and structure-aware hierarchical clustering with global aspects, maintaining the semantic distinctiveness and structural fidelity of the taxonomies.</p>
<p>Conclusion</p>
<p>In this work, we propose a novel framework for taxonomy generation that leverages multi-dimensional representations and dynamic clustering.By dynamically generating semantic aspects tailored to each document set and searching for optimal clustering configurations via dynamic search, our method constructs taxonomies that are both semantically coherent and structurally faithful.We further introduce a high-quality benchmark of 156 annotated taxonomies derived from CS survey papers to facilitate reliable evaluation.Extensive experiments demonstrate that our approach outperforms existing pure LLM-based and clustering-incorporated methods in both automatic and human evaluations.Ablation studies confirm the effectiveness of dynamic aspect modeling and adaptive clustering strategies.</p>
<p>Limitations</p>
<p>Although our method demonstrates strong performance, several limitations remain:</p>
<p>1.In practical applications, the system must first retrieve candidate papers from a broad and potentially noisy corpus, which introduces additional challenges such as incomplete coverage, irrelevant documents, and retrieval errors.Our framework focuses on a controllable experimental environment with oracle papers.Developing retrieval-integrated taxonomy construction methods that are robust to these issues constitutes an important direction for future work.</p>
<ol>
<li>
<p>The quality of aspect extraction and summarization depends on the capabilities of the underlying LLM, which affects the generalization of our framework.</p>
</li>
<li>
<p>The combination of multi-aspect encoding and iterative clustering introduces computational overhead, which may limit scalability to very large corpora.We plan to explore more efficient clustering strategies and scalable approximations to support deployment on a greater scale.</p>
</li>
<li>
<p>Our evaluation benchmark focuses on survey papers in computer science, where its applicability to other domains or less-structured corpora remains to be explored.In future work, we will extend our framework to cross-domain settings.</p>
</li>
<li>
<p>We find that silhouette-based k-selection is not well suited for clustering in complex and semantic-driven tasks such as taxonomy generation, which leaves the development of more effective task-specific clustering selection strategies for future work.</p>
</li>
<li>
<p>Our current framework employs hierarchical clustering, which enforces a strict, nonoverlapping partitioning of papers at each level.In contrast, expert-authored taxonomies (e.g., the oracle trees in our benchmark) sometimes allow a paper to be assigned to multiple branches.Enabling multi-label taxonomy construction is thus an important and challenging extension that we leave for future research.</p>
</li>
</ol>
<p>the goal of assisting researchers and beginners in understanding domain knowledge, tracking research trends, and improving reading efficiency.</p>
<p>While this technology has the potential to support scientific discovery and education, it also carries risks that warrant ethical consideration.</p>
<p>Use of LLMs and Potential Risks Our framework relies on LLMs to generate semantic aspects and organize papers into a hierarchical taxonomy.We acknowledge that LLMs are susceptible to hallucinations, which may lead to factually incorrect or misleading taxonomy structures.Nevertheless, any downstream use of the generated taxonomy for scientific analysis or educational purposes should be critically verified, especially in high-stakes or sensitive applications.Dataset Collection and Licensing We construct our dataset using publicly available metadata and content from arXiv and Semantic Scholar, both of which provide research access under open licenses.The dataset used in this study includes paper titles, metadata (e.g., authors, publication years), and taxonomy structures extracted from the L A T E X source files of review papers collected from arXiv.Specifically, we target survey papers that explicitly include taxonomy structures in their source files.From these files, we extract the taxonomy tree as well as the titles of cited papers mentioned within the taxonomy.</p>
<p>For each cited paper in the taxonomy, we obtain its metadata using the Semantic Scholar API.In cases where the cited papers are also publicly available on arXiv, we further retrieve their L A T E X source files and extract their Introduction sections.This allows us to enrich the representation of each paper beyond the abstract and metadata, enabling more informed and semantically grounded taxonomy construction.</p>
<p>All data were obtained through open APIs and publicly accessible sources, and their use is restricted to academic research.We confirm that our use of these artifacts complies with their intended use and access conditions.No redistribution of full-text content outside permitted use cases has been conducted.The resulting dataset, including derived taxonomy annotations, is shared under a research-only license and should not be repurposed for commercial or non-academic use.</p>
<p>Privacy and Anonymization</p>
<p>We conducted a manual check to ensure that the dataset does not contain personally identifiable information (PII) beyond standard academic author metadata, which are already publicly accessible through the original platforms.No sensitive personal content, usergenerated data, or non-consensual information is included.Our system does not process or generate user data, and all derived outputs (e.g., cluster labels, taxonomy facets) are generated from published research papers.Human Annotation and Consent We recruited voluntary annotators to evaluate the quality of the generated taxonomies.All annotators were fully informed about the purpose of the study, the nature of the data, and how their assessments would be used.No personal information was collected from annotators, and consent was obtained prior to their participation.</p>
<p>A Evaluation Metrics</p>
<p>We evaluate taxonomy generation from two complementary perspectives: clustering structure and heading quality.In addition to automatic evaluation, we also conduct human evaluation to assess the practical quality of the generated taxonomies.</p>
<p>A.1 Clustering Evaluation</p>
<p>Hierarchical Mutual Information (HMI) extends mutual information to hierarchical structures by evaluating consistency across multiple levels of the taxonomy.It provides a structure-aware measure that rewards alignment not only at the leaf level but also across internal nodes.Adjusted Rand Index (ARI) measures the agreement between the predicted and gold cluster assignments, correcting for random chance.It is widely used in clustering evaluation and is robust to varying cluster sizes.Purity quantifies the extent to which each predicted cluster contains documents from a single groundtruth category.While intuitive, this metric may favor solutions with a large number of small clusters.</p>
<p>A.2 Heading Evaluation</p>
<p>Heading Soft Recall.We follow the calculation of Shao et al. (2024).This metric measures the proportion of ground-truth headings that are approximately matched by generated node names using soft string similarity.It allows for minor lexical variations and captures semantic overlap.It is worth noting that, in theory, longer generated outputs tend to achieve higher scores under soft matching metrics such as Soft Heading Recall.This is because longer outputs are more likely to semantically overlap with the reference headings, thereby increasing the chance of a successful match under relaxed similarity thresholds.However, this improvement may not necessarily reflect better quality, as it can be attributed to over-generation rather than more accurate content selection.Catalogue Edit Distance Similarity (CEDS) (Zhu et al., 2023) evaluates the overall similarity between the generated taxonomy and the gold taxonomy by computing a normalized tree edit distance.It accounts for both structural alignment (e.g., insertion, deletion, reordering of nodes) and heading-level similarity, offering a holistic assessment of taxonomy quality.</p>
<p>A.3 Human Evaluation</p>
<p>To complement automatic metrics, we conduct a human evaluation based on five criteria followed Hu et al. (2025):</p>
<p>â€¢ Coverage: Does the taxonomy comprehensively cover the major themes and subtopics within the document collection?</p>
<p>â€¢ Relevance: Are the identified categories appropriate and meaningful for the given set of documents?</p>
<p>â€¢ Structure: Is the overall organization coherent and logically structured as a hierarchy?</p>
<p>â€¢ Usefulness: How helpful is the taxonomy for readers trying to understand or navigate the domain?</p>
<p>â€¢ Validity: Does the taxonomy align with expert expectations or established domain knowledge?</p>
<p>Each aspect is rated on a scale of 1 to 100 by multiple annotators with relevant domain expertise, and the final scores are averaged among the raters.To link the evaluation protocol with concrete outcomes, we further analyze inter-rater reliability by discretizing the scores into five bins of equal width and computing consistency both within and across rater groups.Inter-annotator agreement, measured by Fleiss' Îº on the discretized ratings, shows the following: Human-Human = 0.31, LLM-LLM = 0.38, and Human-LLM = 0.24.Taken together, these results indicate that both human annotators and LLMs exhibit comparable levels of consistency within the group, while their agreement between groups remains relatively low, suggesting systematic differences in rating behavior between the two.</p>
<p>B Case Study</p>
<p>To qualitatively evaluate the effectiveness of our method, we conduct a case study on the topic of "Model Compression".baseline methods are shown in Figures 6-10.As illustrated, our method produces a more coherent and semantically meaningful taxonomy structure, with clearer topic hierarchies and better alignment to the source papers, compared to other approaches.</p>
<p>B.1 Taxonomy Trees</p>
<p>A Survey on Model Compression for Large Language Models</p>
<p>B.2 Generation Process</p>
<p>To complement the quantitative results in Table 3, we provide several representative case studies that qualitatively illustrate the role of aspect generation, aspect-guided summarization, and facet identification.These examples highlight how different components contribute to clustering outcomes and taxonomy construction.</p>
<p>Figure 11 shows the aspects generated under the topic "Model Compression â†’ Quantization Techniques for LLM Compression".The resulting aspects capture salient semantic dimensions that effectively characterize and differentiate relevant papers (e.g., Quantization Framework Type, Hardware Efficiency Techniques).</p>
<p>These aspects are then used in parallel to guide the encoding of individual papers.Figure 12 presents the aspect-guided summary for the paper "Flash-LLM: Enabling Low-Cost and Highly-Efficient Large Generative Model Inference With Unstructured Sparsity".Compared with the original abstract, the aspect-based summary selectively foregrounds details aligned with the identified aspects, facilitating clearer alignment with clustering.</p>
<p>Figure 13 illustrates how facets are identified within the topic "Model Compression" and the selected aspects after clustering with dynamic search.The system generates corresponding topic facets that summarize the semantic focus of each substructure and render the resulting taxonomy more interpretable and navigable.</p>
<p>C Prompts</p>
<p>The prompts we used are shown in Figures 14-18.</p>
<p>Model Compression Model Compression Techniques</p>
<p>ASPECT-BASED SUMMARY</p>
<p>â€¢ "Compression Technique": "The paper employs unstructured model pruning as a compression technique to reduce GPU memory usage and computational demands while maintaining model accuracy.This approach selectively removes less significant connections in neural networks, allowing for efficient deployment of large generative models."</p>
<p>â€¢ "Reasoning Capability": "Not applicable"</p>
<p>â€¢ "Quantization Strategy": "Not applicable"</p>
<p>â€¢ "Sparsity Utilization": "Flash-LLM leverages unstructured sparsity to enhance the efficiency of large generative model inference.By implementing a Load-as-Sparse and Compute-as-Dense methodology, it addresses memory bandwidth bottlenecks and optimizes the performance of skinny matrix multiplications on tensor cores."</p>
<p>â€¢ "Distillation Process": "Not applicable"</p>
<p>â€¢ "Efficiency Improvement": "The paper presents Flash-LLM as a highly efficient software framework that significantly improves inference speed and reduces resource costs.It achieves up to 3.8X and 3.6X enhancements in performance over existing frameworks like DeepSpeed and FasterTransformer, respectively."</p>
<p>â€¢ "Model Adaptation": "Not applicable"</p>
<p>â€¢ "Training Paradigm": "Not applicable"</p>
<p>Summary Case</p>
<p>Figure 12: Aspect-based summary generated for the paper "Flash-LLM: Enabling Low-Cost and Highly-Efficient Large Generative Model Inference With Unstructured Sparsity".</p>
<p>TOPIC Model Compression</p>
<p>Aspect-&gt;Facet  { "Research Problem": "A brief statement of the problem addressed in this study and its significance.","Key Contributions": "A summary of the main innovations and improvements introduced by this study.","Method": "A concise summary of the methodological approach employed in the study", "Datasets": "The datasets used in the study, their sources, and their characteristics (size, type, domain).","Experimental Setup": "Key details of the experiment, including training strategies, hyperparameter tuning, hardware setup, and baseline implementations.","Evaluation Metrics": "The metrics used to assess performance (e.g., accuracy, BLEU, ROUGE, F1-score, MSE).", "Results &amp; Findings": "Summary of the main experimental outcomes and how they compare with state-of-the-art methods."}</p>
<p>Fixed Aspects</p>
<p>Figure 14: Fixed aspects we used.</p>
<p>System</p>
<p>You are an expert in research survey writing and taxonomy design.</p>
<p>Your goal is to abstract and design high-level, generalizable dimensions to characterize a set of research papers collectively.Focus on identifying abstract dimensions, not on listing concrete topics, methods, or datasets.</p>
<p>Each dimension should have:</p>
<p>-A clear and concise name -A short explanation of what the dimension captures (no more than 20 words) Prioritize coherence and coverage when selecting dimensions: they should jointly cover the main aspects of the research without significant overlap.</p>
<p>You must output the results in strict JSON format: {"Dimension Name": "Explanation"}.</p>
<p>Be concise, formal, and highly structured.Avoid free text explanations.Avoid mentioning any specific methods, dataset names, model architectures, task examples, or experimental details.</p>
<p>User</p>
<p>Here is a list of paper titles related to [TITLE]:</p>
<p>[PAPERS]</p>
<p>Analyze these papers based on their titles only.Design and output a set of general, abstract dimensions (no more than 10 and no less than 4) suitable for characterizing the research collectively according to the given instructions.</p>
<p>-Do not list topics, methods, or datasets individually.</p>
<p>-Keep each explanation within 20 words.</p>
<p>-Output only the dimension names and their explanations in JSON format.</p>
<p>First Level Aspects Generation System</p>
<p>You are an expert in research survey writing and taxonomy design.</p>
<p>Your task is to refine and extend an existing high-level analysis dimension by proposing a finer-grained categorization suitable for organizing research papers more precisely.</p>
<p>Given:</p>
<p>-A selected high-level analysis dimension (e.g., Research Focus, Methodology, or Evaluation Setting) -A set of research papers, each with a brief description relevant to the selected dimension Your task is to: -Analyze the papers and their descriptions -Propose several finer-grained sub-dimensions under the given high-level dimension -Each sub-dimension must have:</p>
<p>-A clear and concise name -A short explanation of what it captures Guidelines:</p>
<p>-Sub-dimensions should be specific enough to differentiate papers within the topic -They must be generalizable and reusable, not overly tied to individual papers -Maintain formal academic tone -Avoid listing specific paper names or copying text from descriptions -Output must be structured strictly in JSON format: {"Sub-Dimension Name": "Short explanation"}</p>
<p>User</p>
<p>Here is the list of papers related to [TITLE] and their corresponding descriptions about high-level dimension [TOPIC]:</p>
<p>[PAPERS]</p>
<p>Task:</p>
<p>-Based on the descriptions, generate 2-6 sub-dimensions that fall under the given high-level dimension.</p>
<p>-Each sub-dimension should have a concise name and a short explanation.</p>
<p>-Output only the structured JSON as specified.</p>
<p>Other Level Aspects Generation</p>
<p>User</p>
<p>Here is a list of paper titles related to [TITLE]:</p>
<p>[PAPERS]</p>
<p>Analyze these papers based on their titles only.Design and output a set of general, abstract dimensions (no more than 10 and no less than 4) suitable for characterizing the research collectively according to the given instructions.</p>
<p>-Do not list topics, methods, or datasets individually.</p>
<p>-Keep each explanation within 20 words.</p>
<p>-Output only the dimension names and their explanations in JSON format.-Sub-dimensions should be specific enough to differentiate papers within the topic -They must be generalizable and reusable, not overly tied to individual papers -Maintain formal academic tone -Avoid listing specific paper names or copying text from descriptions -Output must be structured strictly in JSON format: {"Sub-Dimension Name": "Short explanation"}</p>
<p>First Level Aspects Generation</p>
<p>User</p>
<p>Here is the list of papers related to [TITLE] and their corresponding descriptions about high-level dimension [TOPIC]:</p>
<p>[PAPERS]</p>
<p>Task:</p>
<p>-Based on the descriptions, generate 2-6 sub-dimensions that fall under the given high-level dimension.</p>
<p>-Each sub-dimension should have a concise name and a short explanation.</p>
<p>-Output only the structured JSON as specified.</p>
<p>Other Level Aspects Generation</p>
<p>ation System</p>
<p>You are a research analysis assistant tasked with generating concise, structured summaries of academic papers under specific analytical dimensions.</p>
<p>Given:</p>
<p>-A paper's title, abstract, and optionally its introduction -One or more predefined analytical dimensions (e.g., Research Focus, Methodology, Evaluation Setting) -For each dimension, you may optionally be given a more specific sub-dimension (e.g., Research Focus â†’ Hallucination Detection) Your goal is to: -Generate for each paper a short, informative, and targeted description under each given (sub-)dimension -The description should be:</p>
<p>-Specific to the dimension -Expressive of what the paper contributes, investigates, or demonstrates under that angle -No longer than 100 words per dimension -Not copied or directly paraphrased from the abstract If no meaningful content relates to a dimension, return <code>"Not applicable"</code> as the value for that field.</p>
<p>Output must be structured JSON: {"Dimension Name or Sub-Dimension Name": "Short description"}  Task: -Based on the descriptions, generate 2-6 sub-dimensions that fall under the given high-level dimension.</p>
<p>User</p>
<p>Other Level Aspects Generation</p>
<p>-Each sub-dimension should have a concise name and a short explanation.</p>
<p>-Output only the structured JSON as specified.</p>
<p>Topic Facets Generation</p>
<p>Figure 18: Prompt used for topic facets generation.</p>
<p>Figure 1 :
1
Figure 1: Comparison of taxonomy construction paradigms.Traditional methods typically use supervised classification or clustering with term extraction.Recent approaches incorporate LLMs to replace or enhance key components within these pipelines (purple).Our approach uniquely integrates LLMs with clustering in a context-aware multi-aspect framework, resulting in coherent and precise hierarchical taxonomies.</p>
<p>Figure 2 :
2
Figure 2: Our proposed Aspects-guided LLM-based Top-Down Clustering framework.Specifically, we dynamically generate multiple semantic aspects to represent each paper, and perform aspect-specific clustering via dynamic search.The abstract aspects are instantiated into concrete topic facets, which serves as the heading of nodes.This process is iteratively applied to construct a coherent and semantically meaningful taxonomy.</p>
<p>(b) Generated by our method</p>
<p>Figure 3 :
3
Figure 3: Taxonomy of "Model Compression methods for Large Language Models".</p>
<p>Figure 3 (
3
a) shows the human-annotated taxonomy from Zhu et al. (2024) on "Model Compression Methods for Large Language Models," and Figure 3(b) presents our generated result.For comparison, additional case studies produced by baseline methods are included in the Appendix B.</p>
<p>al., 2024).CHIME (Hsu et al., 2024) produces the taxonomy and assigns papers in one pass.GoalEx (Wang et al., 2023b) aligns LLM-generated explanations with papers and applies integer linear programming to finalize a nonoverlapping set of assignments.To better handle long-document settings, TnT-LLM (Wan et al., 2024) iteratively generates and updates the label taxonomy.More recently, TaxoAdapt (Kargupta et al., 2025) incrementally expands the taxonomy by analyzing papers one by one, formulating multidimensional taxonomy construction as iterative multi-label classification.Automatic literature review generation pipelines such as AutoSurvey (Wang et al., 2024), Storm (Shao et al., 2024), and SurveyForge (Yan et al., 2025) replace taxonomies with hierarchically structured outlines, i.e., they first draft an outline of target topics and then retrieve and attach relevant papers to each entry.Despite their flexibility, label-first pipelines often produce redundant labels, hallucinated or missing categories, and imbalanced hierarchies.Clustering-based methods organize papers in the representation space, then leverage inter-paper relations to enforce global coherence and balance, and finally add labels respectively.A related line integrates clustering with LLM generation, where papers are first grouped by unsupervised methods and then semantic labels are produced for each cluster (Diaz-Rodriguez, 2025; Hu et al., 2024).Knowledge Navigator (Katz et al., 2024) performs singlestage flat clustering, while Gao et al. (</p>
<p>Figures 5 (
5
Figures 5(a) and 4 show the human-authored taxonomy tree and the corresponding set of papers from the survey paper "A Survey on Model Compression for Large Language Models" (Zhu et al., 2024).Our generated taxonomy is presented in Figure 5(b), while the taxonomies produced by other</p>
<p>Figure 4 :
4
Figure 4: Papers in the taxonomy built by Zhu et al. (2024)</p>
<p>Figure 4 : 3 Figure 6 :
436
Figure 4: Taxonomy of "Model Compression methods for Large Language Models" generated by KN.</p>
<p>Figure 5 :
5
Figure 5: Taxonomy of "Model Compression methods for Large Language Models" generated by TnTLLM.4</p>
<p>Figure 7 :
7
Figure 7: Taxonomy of "Model Compression methods for Large Language Models" generated by TnTLLM (Wan et al., 2024).</p>
<p>introduces a method for compressing matrices via randomized low rank and low precision factorization Paper ID: 11 introduces a task-aware layer-wise distillation approach for language model compression Paper ID: 9 proposes an approach for enabling low-cost and efficient inference of large generative models with un-</p>
<p>Figure 7 : 6 Figure 8 :
768
Figure 7: Taxonomy of "Model Compression methods for Large Language Models" generated by GoalEx.</p>
<p>Figure 3 :
3
Figure 3: Taxonomy of "Model Compression methods for Large Language Models" generated by Chime.</p>
<p>Figure 4 : 3 Figure 9 :
439
Figure 4: Taxonomy of "Model Compression methods for Large Language Models" generated by KN.</p>
<p>Figure 10 :
10
Figure 10: Taxonomy of "Model Compression methods for Large Language Models".</p>
<p>Figure 10 :
10
Figure 10: Taxonomy of "Model Compression methods for Large Language Models" generated by SCYCHIC (Gao et al., 2025).</p>
<p>Figure 11 :
11
Figure 11: Aspect generation under a specific topic.</p>
<p>Figure 13 :
13
Figure 13: Facet identification within a topic.</p>
<p>to provide the target paper as follows, extract and summarize the details: â€¢ Target aspects: [ASPECTS] â€¢ Target paper title: [TITLE] â€¢ Target paper abstract: [ABSTRACT] â€¢ (Optional) Target paper introduction: [INTRODUCTION] Aspect-based Summary Generation System You are an expert in scientific research analysis.Your task is to generate meaningful and consistent names for multiple paper clusters under the same semantic topic path.<strong>Input Information</strong> -Title: [TITLE] -the broader research theme (e.g., LLMs for Causal Reasoning) -Topic Path: [TOPIC] -the current semantic layer (e.g., Methodology or Methodology â†’ LLMs as Reasoning Engines) -Input: A dictionary of clusters, where each key is a cluster topic, and the value is a list of paper summaries { "cluster_1": [ {'Title': '...', 'Abstract': '...'}, ...], "cluster_2": [{'Title': '...', 'Abstract': '...'}, ...], ... } <strong>Your Tasks</strong> For each cluster, you must: 1. Carefully examine the topic path and understand the expected granularity: -If the topic path is broad (e.g., Methodology), your output should be cluster names that describe the role, use, or behavior of LLMs, such as: + LLMs as Reasoning Engines + LLMs as Planning Assistants + LLMs as Helpers to Traditional Methods -If the topic path is already specific (e.g., Methodology â†’ LLMs as Reasoning Engines), your cluster names should reflect specific modeling or training strategies, such as: + Prompt Engineering + Chain-of-Thought Tuning + Knowledge-Augmented Fine-Tuning 2. Generate one precise and specific name for each cluster that captures its unifying theme.<strong>Output format (JSON)</strong>: { "cluster_1": "LLMs as Symbolic Reasoning Agents",</p>
<p>Figure 17 :
17
Figure 17: Prompt used for aspect-based summary generation.</p>
<p>Table
DatasetsClustering Hierachy Ground TruthSourceCLUSTREC-COVID (Katz et al., 2024)âœ“âœ—âœ“syntheticSCITOC (Katz et al., 2024)âœ—âœ“âœ“naturalSciPile (Gao et al., 2025)âœ“âœ“âœ—syntheticCHIME (Hsu et al., 2024)âœ“âœ“âœ—syntheticTaxoBench-CS (Ours)âœ“âœ“âœ“natural
(2)(2)</p>
<p>Table 2 :
2
Automatic and human evaluation results on taxonomy generation.We report categorization quality (NMI, ARI, Purity), structural consistency (CEDS, HSR), and normalized node count (Nodes), where 1.0 of Nodes indicates an exact match with the gold taxonomy in terms of node count.Human evaluation is conducted on five dimensions, Coverage, Relevance, Structure, Validity, and Adequacy, each rated on a scale of 1 to 100.
Categorization NMI ARI Purity CEDS HSR StructureNodesHuman Assessment Cov. Rel. Str. Val. Ade.Pure LLM-basedCHIME35.40.941.823.374.71.143.2 50.3 54.5 47.6 47.6TnT-LLM51.62.357.619.169.91.541.1 47.3 48.1 46.0 46.6GoalEx46.78.847.623.270.51.045.9 53.3 57.0 48.6 46.8Clustering-incorporatedKN44.716.242.418.849.50.547.5 57.0 55.0 52.0 47.0SCYCHIC 49.89.050.623.066.41.547.3 50.7 55.2 48.4 46.8Ours60.119.162.223.874.51.250.6 57.1 59.6 52.9 54.4</p>
<p>Table 4 :
4
Performance under different values of hyperparameter k v , which controls the number of clusters per node."S" denotes an adaptive selection strategy from our baseline.Fixed larger k v improves purity but harms structural consistency (CEDS and Nodes), while adaptive k v achieves a balanced yet unremarkable performance across all metrics.</p>
<p>Table 4
4
(Katz et al., 2024) under fixed values of k v âˆˆ {3, 4, 5, 6}, as well as an adaptive strategy ("S")(Katz et al., 2024)where the model dynamically selects from 3, 4, 5, 6 based on the clustering result with the highest silhouette score.Fixed v.s.Adaptive k v .As k v increases, we observe a steady improvement in categorization performance, with NMI rising from 55.1 (at k v = 3) to 61.2 (at k v = 6).Purity also increases substantially, reflecting finer-grained clustering.However, this comes at the cost of structural quality: CEDS decline and the normalized node count (Nodes) increase, indicating over-fragmented taxonomies with reduced alignment to the gold standard.</p>
<p>Table 5 :
5
Performance comparison under different noise levels.</p>
<p>al., 2021; Sadat and Caragea, 2022; Rao et al., 2023).Recent advances in LLMs have significantly reshaped the landscape of topic modeling and document clustering by semantically rich and context-aware representations, allowing for more interpretable and scalable taxonomy construction (Zhang et al., 2023; Pham et al., 2024; Wang et al., 2023a; Qiu et al., 2024; Viswanathan et al., 2024).In general, there are two technical paradigms for taxonomy construction: classification-based and clustering-based, where each of them offers distinct advantages and trade-offs.</p>
<p>Taxonomy of "Model Compression methods for Large Language Models".
Advanced Post-Paper ID: 7, 15,Training Quantization16, 18, 20, 21, 22,Techniques for LLMs32, 33, 37, 39, 41quantization-aware train-ingPaper ID: 20, 28, 29Post-Training Quantiza-cient LLM Deployment tion Strategies for Effi-Knowledge Distillation 1-Bit Quantization viaPaper ID: 29quantizationweight-only quantizationPaper ID: 7, 21, 22, 32, 33, 39Quantization for LLM Com-TechniquesKV Cache Quanti-Efficient LLM Inference zation Strategies forPaper ID: 25, 26, 30post-training quantizationweight-activation quantizationPaper ID: 0, 37, 41, 45 15, 16, 18,pressiontion Techniques for LLMs Outlier-Aware Quantiza-Paper ID: 0, 45kv cache quantization25, 26, 30 Paper ID:for Efficient LLM Inference Unstructured Sparsity TechniquesPaper ID: 1, 2, 4, 23, 48unstructured pruningPaper ID: 1, 2, 4, 43, 48Strategies for PruningLLMs Without Retraining Structured Pruning Methods forPaper ID: 3, 35, 38, 43, 47pruningstructured pruningPaper ID: 3,Efficient LLMsOrthogonal Transformations forPaper ID: 31Model31, 35, 38, 47ModelLLM CompressionCom-semi-structured pruningPaper ID:Com-Distillation TechniquesPaper ID: 5,pression4, 23, 43pressionfor Enhanced Reason-10, 12, 13,ing in Smaller Models19, 36, 40knowledge distillationwhite-box kd black-box kdPaper ID: 9 instruction following in-context learning chain-of-thought34, 44, 46 Paper ID: 27, Paper ID: 17 Paper ID: 5, 6, 8, 10, 12, 13, 14, 19, 36, 40ing LLM Reason-Simplified Methods for Distillationand Instruction-Tuning Task-Aware Distillation Chain-of-Thought Distil-soning lation for Enhanced Rea-27, 28, 34, 44, 46 Paper ID: 6, 9, 17, for Reasoning Distillation Negative Sample Utilization for Faithful Reasoning Self-Consistent DistillationPaper ID: 8 Paper ID: 14low-rank fac-Paper ID:Low-Rank FactorizationPaper ID: 11, 24, 42torization11, 24, 42for LLM Compression(a) Built by Zhu et al. (2024)(b) Generated by our methodCompression Figure 5: Model Matrix Multiplication Effi-ciency Efficiency Im-provement Distillation Methods Reasoning Ca-pability En-hancement Reasoning Distillation Efficient Quan-tization Mixed-Precision Quantiza-tion Weight and Activation Quantization Knowledge Distillation for Quantization KV Cache QuantizationMulti-step Reasoning Distillation LUT-GEMM Kernel Fine-tune-CoT Method E-Sparse Method Fine-tune-CoT Method In-context Learning Distillation Paper ID: 7 SCOTT Method Paper ID: 19 Paper ID: 25, 30Paper ID: 40 Paper ID: 39 Paper ID: 5 Paper ID: 23 Paper ID: 5, 12 Paper ID: 17 Paper ID: 14PerformanceKnowledge DistillationEnhancementTask-aware DistillationPaper ID: 9Speed and Energy Effi-Outlier Suppression+ (OS+)Paper ID: 45ciencyCompression EfficiencyDSnoT ApproachPaper ID: 48Matrix CompressionPaper ID: 11QuantizationKnowledge Distilla-Paper ID: 4, 48tion for QuantizationModel Com-pressionWanda Method forPaper ID: 43Structured PruningLarge Language ModelsFLAP Structured PruningPaper ID: 3Mixed Sparsity PruningHessian Sensitivity-AwarePaper ID: 2Mixed Sparsity PruningFigure 3: Taxonomy of "Model Compression methods for Large Language Mod-els" generated by Chime.Sparsity andSparsity and PruningPaper ID: 1, 2,Pruning Ap-Techniques for Model3, 4, 23, 31, 35,proachesCompression of Large Lan-38, 42, 43, 47, 48guage ModelsModelKnowledgeKnowledge Distillation andPaper ID: 5, 6,CompressionDistillationModel Compression Tech-8, 9, 10, 12, 13,Methodsniques for Large Language14, 17, 19, 27,Models34, 36, 40, 44, 46QuantizationQuantization TechniquesPaper ID: 0, 7,Techniquesfor Compressing Large11, 15, 16, 18,Language Models20, 21, 22, 24, 25,26, 28, 29, 30, 32,33, 37, 39, 41, 45
AcknowledgmentsThis work was supported by the National Natural Science Foundation of China (NSFC) (grant 62276078, U22B2059), the Key R&amp;D Program of Heilongjiang via grant 2022ZX01A32, and the Fundamental Research Funds for the Central Universities (XNJKKGYDJ2024013).It was also supported by the Ministry of Education, Singapore, under its AcRF Tier 2 Funding (Proposal ID: T2EP20123-0052).Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of the Ministry of Education, Singapore.We thank the iFLYTEK Spark AI Assistant Team for providing application requirements and highvalue feedback.Ethics StatementThis work focuses on constructing paper taxonomies using large language models (LLMs), with
Josh References, Steven Achiam, Sandhini Adler, Lama Agarwal, Ilge Ahmad, Florencia Akkaya, Diogo Leoni Aleman, Janko Almeida, Sam Altenschmidt, Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint</p>
<p>Jairo Diaz-Rodriguez, arXiv:2502.096672025. k-llmmeans: Summaries as centroids for interpretable and scalable llm-based text clustering. arXiv preprint</p>
<p>Soft precision and recall. Pasi FrÃ¤nti, Radu Mariescu-Istodor, Pattern Recognition Letters. 1672023</p>
<p>Science Hierarchography: Hierarchical Organization of Science Literature. Muhan Gao, Jash Shah, Weiqi Wang, Daniel Khashabi, 10.48550/arXiv.2504.13834arXiv:2504.138342025Preprint</p>
<p>Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, The llama 3 herd of models. arXiv e-prints. 20242407</p>
<p>Chime: Llm-assisted hierarchical organization of scientific studies for literature review support. Mark A Hanson, Pablo GÃ³mez Barreiro, Paolo Crosetto, Dan Brockington, ; Chao-Chun, Erin Hsu, Jenna Bransom, Bailey Sparks, Chenhao Kuehl, David Tan, Lucy Lu Wadden, Aakanksha Wang, Naik, 10.1162/qss_a_00327Findings of the Association for Computational Linguistics ACL 2024. 2024. 20245The strain on scientific publishing</p>
<p>Yuntong Hu, Zhuofeng Li, Zheng Zhang, Chen Ling, Raasikh Kanjiani, Boxin Zhao, Liang Zhao, arXiv:2410.03761Taxonomy tree generation from citation graph. 2024arXiv preprint</p>
<p>Taxonomy Tree Generation from Citation Graph. Yuntong Hu, Zhuofeng Li, Zheng Zhang, Chen Ling, Raasikh Kanjiani, Boxin Zhao, Liang Zhao, 10.48550/arXiv.2410.03761arXiv:2410.037612025Preprint</p>
<p>TaxoAdapt: Aligning LLM-based multidimensional taxonomy construction to evolving research corpora. Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han, Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 63rd Annual Meeting of the Association for Computational LinguisticsVienna, AustriaAssociation for Computational Linguistics20251</p>
<p>Knowledge navigator: LLM-guided browsing framework for exploratory search in scientific literature. Uri Katz, Mosh Levy, Yoav Goldberg, 10.18653/v1/2024.findings-emnlp.516Findings of the Association for Computational Linguistics: EMNLP 2024. Miami, Florida, USAAssociation for Computational Linguistics2024</p>
<p>Topicgpt: A promptbased topic modeling framework. Chau Pham, Alexander Hoyle, Simeng Sun, Philip Resnik, Mohit Iyyer, Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesLong Papers20241</p>
<p>A topic modeling based on prompt learning. Mingjie Qiu, Wenzhong Yang, Fuyuan Wei, Mingliang Chen, 2024Electronics133212</p>
<p>Hierarchical classification of research fields in the" web of science. Susie Xi Rao, Peter H Egger, Ce Zhang, arXiv:2302.003902023using deep learning. arXiv preprint</p>
<p>Loss of sustainability in scientific work. Niklas Reisz, D P Vito, Vittorio Servedio, William Loreto, Schueller, Stefan MÃ¡rcia R Ferreira, Thurner, 10.1088/1367-2630/ac6ca1New Journal of Physics. 245530412022</p>
<p>Hierarchical multi-label classification of scientific documents. Mobashir Sadat, Cornelia Caragea, 10.18653/v1/2022.emnlp-main.610Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>NetTaxo: Automated Topic Taxonomy Construction from Text-Rich Network. Jingbo Shang, Xinyang Zhang, Liyuan Liu, Sha Li, Jiawei Han, 10.1145/3366423.3380259Proceedings of The Web Conference 2020. The Web Conference 2020Taipei TaiwanACM2020</p>
<p>Assisting in writing Wikipedia-like articles from scratch with large language models. Yijia Shao, Yucheng Jiang, Theodore Kanell, Peter Xu, Omar Khattab, Monica Lam, 10.18653/v1/2024.naacl-long.347Proceedings of the 2024 Conference of the North American Chapter. Long Papers. the 2024 Conference of the North American ChapterMexico City, MexicoAssociation for Computational Linguistics20241</p>
<p>HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree Expansion. Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle T Vanni, Brian M Sadler, Jiawei Han, 10.1145/3219819.3220115Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data MiningLondon United KingdomACM2018</p>
<p>Scientific publishing: crisis, challenges, and new opportunities. Paolo Vineis, Frontiers in Public Health. 1214170192024</p>
<p>Large Language Models Enable Few-Shot Clustering. Vijay Viswanathan, Kiril Gashteovski, Kiril Gashteovski, Carolin Lawrence, Tongshuang Wu, Graham Neubig, 10.1162/tacl_a_00648Transactions of the Association for Computational Linguistics. 122024</p>
<p>TnT-LLM: Text Mining at Scale with Large Language Models. Mengting Wan, Tara Safavi, Sujay Kumar Jauhar, Yujin Kim, Scott Counts, Jennifer Neville, Siddharth Suri, Chirag Shah, Ryen W White, Longqi Yang, Reid Andersen, Georg Buscher, Dhruv Joshi, Nagu Rangan, 10.1145/3637528.3671647Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 30th ACM SIGKDD Conference on Knowledge Discovery and Data MiningBarcelona SpainACM2024</p>
<p>Prompting large language models for topic modeling. Han Wang, Nirmalendu Prakash, Khoi Nguyen, Ming Hoang, Usman Shan Hee, Roy Ka-Wei Naseem, Lee, 2023 IEEE International Conference on Big Data (BigData). 2023a</p>
<p>Autosurvey: Large language models can automatically write surveys. Yidong Ieee, Qi Wang, Wenjin Guo, Hongbo Yao, Xin Zhang, Zhen Zhang, Meishan Wu, Xinyu Zhang, Min Dai, Qingsong Zhang, Wei Wen, Shikun Ye, Yue Zhang, Zhang, The Thirtyeighth Annual Conference on Neural Information Processing Systems. 2024</p>
<p>Goal-driven explainable clustering via language descriptions. Zihan Wang, Jingbo Shang, Ruiqi Zhong, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023b</p>
<p>SUR-VEYFORGE : On the outline heuristics, memorydriven generation, and multi-dimensional evaluation for automated survey writing. Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, Lei Bai, Bo Zhang, 10.18653/v1/2025.acl-long.609Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 63rd Annual Meeting of the Association for Computational LinguisticsVienna, AustriaAssociation for Computational Linguistics20251</p>
<p>TaxoGen: Unsupervised Topic Taxonomy Construction by Adaptive Term Embedding and Clustering. Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian Sadler, Michelle Vanni, Jiawei Han, 10.1145/3219819.3220064Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data MiningLondon United KingdomACM2018</p>
<p>Hierarchical metadata-aware document categorization under weak supervision. Yu Zhang, Xiusi Chen, Yu Meng, Jiawei Han, Proceedings of the 14th ACM International Conference on Web Search and Data Mining. the 14th ACM International Conference on Web Search and Data Mining2021</p>
<p>Clusterllm: Large language models as a guide for text clustering. Yuwei Zhang, Zihan Wang, Jingbo Shang, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Hierarchical catalogue generation for literature review: A benchmark. Kun Zhu, Xiaocheng Feng, Xiachong Feng, Yingsheng Wu, Bing Qin, 10.18653/v1/2023.findings-emnlp.453Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023</p>
<p>A survey on model compression for large language models. Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang, 10.1162/tacl_a_00704Transactions of the Association for Computational Linguistics. 122024</p>
<p>Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization. Olive, </p>
<p>Flash-LLM: Enabling Low-Cost and Highly-Efficient Large Generative Model Inference With Unstructured Sparsity. </p>
<p>One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. </p>
<p>Fluctuation-based Adaptive Structured Pruning for Large Language Models. </p>
<p>Massive Language Models Can Be Accurately Pruned in One-Shot. Sparsegpt, </p>
<p>Large Language Models Are Reasoning Teachers. </p>
<p>Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes [7] OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models. </p>
<p>Turning Dust into Gold: Distilling Complex Reasoning Capabilities from LLMs by Leveraging Negative Data [9] Less is More: Task-aware Layer-wise Distillation for Language Model Compression. </p>
<p>Teaching Small Language Models to Reason. </p>
<p>Matrix Compression via Randomized Low Rank and Low Precision Factorization. </p>
<p>Distilling Reasoning Capabilities into Smaller Language Models. </p>
<p>Democratizing Reasoning Ability: Tailored Learning from Large Language Model [14] SCOTT: Self-Consistent Chain-of-Thought Distillation. </p>
<p>SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models. ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers. </p>
<p>RPTQ: Reorder-based Post-training Quantization for Large Language Models [19] PaD: Program-aided Distillation Can Teach Small Models Reasoning Better than Chain-of-thought Fine-tuning. context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models. 18</p>
<p>Data-Free Quantization Aware Training for Large Language Models [21] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration. Llm-Qat , SqueezeLLM: Dense-and-Sparse Quantization. 22</p>
<p>ASVD: Activation-aware Singular Value Decomposition for Compressing Large Language Models [25] KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization [26] KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache. E-Sparse , Boosting the Large Language Model Inference through Entropy-based N: M Sparsity. 24</p>
<p>Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning. </p>
<p>Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation. Bitdistiller, </p>
<p>Towards Extremely Low-bit Large Language Models [30] WKVQuant: Quantizing Weight and Key/Value Cache for Large Language Models Gains More [31] SliceGPT: Compress Large Language Models by Deleting Rows and Columns [32] QuIP: 2-Bit Quantization of Large Language Models With Guarantees [33] SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression [34] Lion: Adversarial Distillation of Proprietary Large Language Models. Onebit, </p>
<p>A Simple Depth Pruning for Large Language Models [36] Explanations from Large Language Models Make Small Reasoners Better. Shortened Llama, </p>
<p>LLM-FP4: 4-Bit Floating-Point Quantized Transformers. </p>
<p>Llm-Pruner, On the Structural Pruning of Large Language Models. </p>
<p>Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models. Lut-Gemm, </p>
<p>Specializing Smaller Language Models towards Multi-Step Reasoning. </p>
<p>Omnidirectionally Calibrated Quantization for Large Language Models [42] The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction. Omniquant, </p>
<p>A Simple and Effective Pruning Approach for Large Language Models. </p>
<p>Self-Instruct: Aligning Language Models with Self-Generated Instructions. </p>
<p>Accurate quantization of large language models by equivalent and effective shifting and scaling. Outlier Suppression+, </p>
<p>Lamini-Lm , Diverse Herd of Distilled Models from Large-Scale Instructions. </p>
<p>Sheared Llama, Accelerating Language Model Pre-training via Structured Pruning. </p>
<p>Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs. </p>            </div>
        </div>

    </div>
</body>
</html>