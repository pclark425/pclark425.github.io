<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1280 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1280</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1280</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6" target="_blank">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Machine Learning</p>
                <p><strong>Paper TL;DR:</strong> A new theoretical framework is developed casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes, which mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy.</p>
                <p><strong>Paper Abstract:</strong> Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1280.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1280.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dropout Q-Network (Thompson)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dropout Q-network using Thompson sampling for exploration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Q-value function approximator that uses Monte Carlo dropout to approximate posterior uncertainty over network weights and performs Thompson sampling (posterior sampling) by taking a single stochastic forward pass per decision to trade off exploration and exploitation in an online RL task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Dropout Q-network with Thompson sampling</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A convolutional/fully-connected Q-network (same small network structure as the baseline implementation replicating Mnih et al.'s simplified 2D code) with Bernoulli dropout applied before every weight layer (dropout probability 0.1 in the experiment). At decision time the agent draws a single dropout mask (MC dropout sample) to obtain a sampled Q-function and selects the greedy action under this sampled Q; during replay a single stochastic forward pass is used and backpropagation is performed with the sampled Bernoulli variables.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Thompson sampling (posterior sampling using MC dropout)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each action decision the agent samples a realization of the network via dropout (one stochastic forward pass) to obtain a sampled Q-value for each action, then selects the action with maximal sampled Q (posterior-greedy). This implicitly adapts exploration according to model uncertainty: more uncertain states yield higher variance across samples and thus more exploratory action choices. The sampled masks are also used during replay/backpropagation.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>2D navigation / maze-like task (Karpathy / simplified Mnih-style 2D simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable (agent has 9 'eyes' sensing single-pixel intensities in 3 colour channels), discrete action space, shaped rewards (positive reward for red circles, negative for green circles, penalties for looking at walls, reward for walking straight). Environment is a simulated 2D continuous-space world discretized to sensory inputs; dynamics not explicitly stated as stochastic, but perception is partial.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Observation: 9 eyes × 3 colour channels (27-dimensional sensory vector). Action space: 5 discrete motor actions controlling two motors. Episode/interaction sizing reported in 'batches' (training uses batches and replay); burn-in of 25 batches used. The environment and agent are intentionally small/simple compared to full Atari setups.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Thompson-sampling dropout agent attains average reward > 1 within 25 batches after burn-in (25 burn-in batches excluded). Learning curve: faster early improvement and higher sample efficiency compared to epsilon-greedy baseline; improvement plateaus after ~1,000 batches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Baseline (epsilon-greedy) required ~175 batches to reach average reward > 1 (i.e., much slower than Thompson sampling). No further detailed cumulative-reward curves or numerical asymptotic scores provided.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Substantially improved: reaching reward > 1 in ~25 batches vs ~175 batches for epsilon-greedy (≈7× faster to this benchmark). Beyond early phase, performance plateaus for the Thompson approach by ≈1,000 batches in this experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Handled via Thompson sampling: sampling from the approximate posterior induced by MC dropout produces action-value variability proportional to epistemic uncertainty; the agent acts greedily w.r.t. the sampled Q, thus exploration emerges where uncertainty is high and exploitation where posterior concentrates. No explicit epsilon parameter is used while Thompson sampling is applied.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared directly against the original implementation's epsilon-greedy exploration (baseline replicating Mnih et al. simplified code).</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Using MC dropout to obtain posterior uncertainty and performing Thompson sampling yields markedly faster learning in this 2D navigation task (reaching a modest reward threshold ≈7× faster than epsilon-greedy). The method requires only a single stochastic forward pass per decision (cheap) and integrates naturally into replay/backprop by using the same sampled dropout masks. The approach can avoid some overfitting and improves sample efficiency in early learning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Observed plateau of improvement after ≈1,000 batches, attributed to continued random moves (replay/learning protocol) rather than model convergence; experiment uses a small intentionally simple environment and small network, so generalization to larger, stochastic, or high-dimensional partially observable tasks (e.g., Atari) is not demonstrated here. Exact episode lengths, stochasticity of transitions, and statistical significance beyond the illustrated learning curves are not fully reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning', 'publication_date_yy_mm': '2015-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1280.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1280.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian Optimization (BO) for hyperparameters</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian optimization over validation log-likelihood to tune model precision (tau) and related hyperparameters</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BO (Spearmint-style) is used to adaptively select hyperparameters (model precision tau and related prior length-scale) by optimizing validation predictive log-likelihood; BO is run for multiple iterations and used to set weight-decay via the Bayesian interpretation of dropout.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Hyperparameter tuning via Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An automated hyperparameter search procedure (Bayesian optimization over validation log-likelihood) to find the optimal model precision tau and set prior length-scale for dropout-based Bayesian interpretation; used with 40 initial BO iterations and additional runs (authors increased iterations beyond original 40 when necessary).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization (sequential model-based optimization using validation log-likelihood as objective)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>BO builds a surrogate (probabilistic) model of validation log-likelihood as a function of hyperparameters and sequentially proposes new hyperparameter settings to evaluate (initially 40 iterations, then extended) to maximize validation log-likelihood; chosen hyperparameters define weight decay via derived identity relating tau, p, l, N, and lambda.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Offline supervised validation datasets (regression tasks used for model selection)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Not a sequential or partially observable environment; these are offline regression datasets of varying sizes (small to large), used for validation of predictive log-likelihood and RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Datasets range in size (e.g., Boston Housing N=506 up to YearPredictionMSD N~515k); input dimensionalities vary (Q from 4 to 90). BO runs used 40 iterations (authors extended runs for better convergence).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>BO-selected hyperparameters enabled dropout models to achieve state-of-the-art or competitive RMSE and predictive log-likelihood on a suite of regression datasets (see reported tables); exact incremental effect of BO vs manual/tuned settings is not fully isolated numerically in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>BO initial runs used 40 iterations; authors note dropout training takes longer to converge so BO required more iterations to adequately evaluate candidates. No precise sample-efficiency numbers for BO itself are provided beyond these iteration counts.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Managed by the BO acquisition function (not detailed in full); BO balances exploring hyperparameter space and exploiting promising regions via its surrogate/acquisition strategy (standard practice in Spearmint-style BO).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>BO is used as the hyperparameter search method; no direct comparison in paper against other hyperparameter search strategies is provided, though runtimes are compared implicitly to PBP and VI training runtimes.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Using BO over validation log-likelihood to set model precision and length-scale allowed MC-dropout models to achieve strong predictive performance (RMSE and predictive log-likelihood) across multiple regression benchmarks; authors note BO needed more iterations for dropout due to slower convergence but overall runtime was comparable to competing probabilistic methods when including BO.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>BO runs of only 40 iterations were insufficient for fully converged dropout hyperparameter tuning due to slower convergence of dropout models; authors extended BO and training epochs to get improved results. The paper does not provide ablation isolating the benefit due solely to BO vs other factors (e.g., more epochs, architecture changes). BO here is applied offline to static validation sets, not to an online/partially-observable environment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning', 'publication_date_yy_mm': '2015-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Human-level control through deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Probabilistic backpropagation for scalable learning of bayesian neural networks <em>(Rating: 1)</em></li>
                <li>Practical Bayesian optimization of machine learning algorithms <em>(Rating: 2)</em></li>
                <li>A Javascript implementation of neural networks <em>(Rating: 2)</em></li>
                <li>On the likelihood that one unknown probability exceeds another in view of the evidence of two samples <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1280",
    "paper_id": "paper-f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "Dropout Q-Network (Thompson)",
            "name_full": "Dropout Q-network using Thompson sampling for exploration",
            "brief_description": "A Q-value function approximator that uses Monte Carlo dropout to approximate posterior uncertainty over network weights and performs Thompson sampling (posterior sampling) by taking a single stochastic forward pass per decision to trade off exploration and exploitation in an online RL task.",
            "citation_title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
            "mention_or_use": "use",
            "agent_name": "Dropout Q-network with Thompson sampling",
            "agent_description": "A convolutional/fully-connected Q-network (same small network structure as the baseline implementation replicating Mnih et al.'s simplified 2D code) with Bernoulli dropout applied before every weight layer (dropout probability 0.1 in the experiment). At decision time the agent draws a single dropout mask (MC dropout sample) to obtain a sampled Q-function and selects the greedy action under this sampled Q; during replay a single stochastic forward pass is used and backpropagation is performed with the sampled Bernoulli variables.",
            "adaptive_design_method": "Thompson sampling (posterior sampling using MC dropout)",
            "adaptation_strategy_description": "At each action decision the agent samples a realization of the network via dropout (one stochastic forward pass) to obtain a sampled Q-value for each action, then selects the action with maximal sampled Q (posterior-greedy). This implicitly adapts exploration according to model uncertainty: more uncertain states yield higher variance across samples and thus more exploratory action choices. The sampled masks are also used during replay/backpropagation.",
            "environment_name": "2D navigation / maze-like task (Karpathy / simplified Mnih-style 2D simulator)",
            "environment_characteristics": "Partially observable (agent has 9 'eyes' sensing single-pixel intensities in 3 colour channels), discrete action space, shaped rewards (positive reward for red circles, negative for green circles, penalties for looking at walls, reward for walking straight). Environment is a simulated 2D continuous-space world discretized to sensory inputs; dynamics not explicitly stated as stochastic, but perception is partial.",
            "environment_complexity": "Observation: 9 eyes × 3 colour channels (27-dimensional sensory vector). Action space: 5 discrete motor actions controlling two motors. Episode/interaction sizing reported in 'batches' (training uses batches and replay); burn-in of 25 batches used. The environment and agent are intentionally small/simple compared to full Atari setups.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Thompson-sampling dropout agent attains average reward &gt; 1 within 25 batches after burn-in (25 burn-in batches excluded). Learning curve: faster early improvement and higher sample efficiency compared to epsilon-greedy baseline; improvement plateaus after ~1,000 batches.",
            "performance_without_adaptation": "Baseline (epsilon-greedy) required ~175 batches to reach average reward &gt; 1 (i.e., much slower than Thompson sampling). No further detailed cumulative-reward curves or numerical asymptotic scores provided.",
            "sample_efficiency": "Substantially improved: reaching reward &gt; 1 in ~25 batches vs ~175 batches for epsilon-greedy (≈7× faster to this benchmark). Beyond early phase, performance plateaus for the Thompson approach by ≈1,000 batches in this experiment.",
            "exploration_exploitation_tradeoff": "Handled via Thompson sampling: sampling from the approximate posterior induced by MC dropout produces action-value variability proportional to epistemic uncertainty; the agent acts greedily w.r.t. the sampled Q, thus exploration emerges where uncertainty is high and exploitation where posterior concentrates. No explicit epsilon parameter is used while Thompson sampling is applied.",
            "comparison_methods": "Compared directly against the original implementation's epsilon-greedy exploration (baseline replicating Mnih et al. simplified code).",
            "key_results": "Using MC dropout to obtain posterior uncertainty and performing Thompson sampling yields markedly faster learning in this 2D navigation task (reaching a modest reward threshold ≈7× faster than epsilon-greedy). The method requires only a single stochastic forward pass per decision (cheap) and integrates naturally into replay/backprop by using the same sampled dropout masks. The approach can avoid some overfitting and improves sample efficiency in early learning.",
            "limitations_or_failures": "Observed plateau of improvement after ≈1,000 batches, attributed to continued random moves (replay/learning protocol) rather than model convergence; experiment uses a small intentionally simple environment and small network, so generalization to larger, stochastic, or high-dimensional partially observable tasks (e.g., Atari) is not demonstrated here. Exact episode lengths, stochasticity of transitions, and statistical significance beyond the illustrated learning curves are not fully reported.",
            "uuid": "e1280.0",
            "source_info": {
                "paper_title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
                "publication_date_yy_mm": "2015-06"
            }
        },
        {
            "name_short": "Bayesian Optimization (BO) for hyperparameters",
            "name_full": "Bayesian optimization over validation log-likelihood to tune model precision (tau) and related hyperparameters",
            "brief_description": "BO (Spearmint-style) is used to adaptively select hyperparameters (model precision tau and related prior length-scale) by optimizing validation predictive log-likelihood; BO is run for multiple iterations and used to set weight-decay via the Bayesian interpretation of dropout.",
            "citation_title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
            "mention_or_use": "use",
            "agent_name": "Hyperparameter tuning via Bayesian optimization",
            "agent_description": "An automated hyperparameter search procedure (Bayesian optimization over validation log-likelihood) to find the optimal model precision tau and set prior length-scale for dropout-based Bayesian interpretation; used with 40 initial BO iterations and additional runs (authors increased iterations beyond original 40 when necessary).",
            "adaptive_design_method": "Bayesian optimization (sequential model-based optimization using validation log-likelihood as objective)",
            "adaptation_strategy_description": "BO builds a surrogate (probabilistic) model of validation log-likelihood as a function of hyperparameters and sequentially proposes new hyperparameter settings to evaluate (initially 40 iterations, then extended) to maximize validation log-likelihood; chosen hyperparameters define weight decay via derived identity relating tau, p, l, N, and lambda.",
            "environment_name": "Offline supervised validation datasets (regression tasks used for model selection)",
            "environment_characteristics": "Not a sequential or partially observable environment; these are offline regression datasets of varying sizes (small to large), used for validation of predictive log-likelihood and RMSE.",
            "environment_complexity": "Datasets range in size (e.g., Boston Housing N=506 up to YearPredictionMSD N~515k); input dimensionalities vary (Q from 4 to 90). BO runs used 40 iterations (authors extended runs for better convergence).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "BO-selected hyperparameters enabled dropout models to achieve state-of-the-art or competitive RMSE and predictive log-likelihood on a suite of regression datasets (see reported tables); exact incremental effect of BO vs manual/tuned settings is not fully isolated numerically in the paper.",
            "performance_without_adaptation": null,
            "sample_efficiency": "BO initial runs used 40 iterations; authors note dropout training takes longer to converge so BO required more iterations to adequately evaluate candidates. No precise sample-efficiency numbers for BO itself are provided beyond these iteration counts.",
            "exploration_exploitation_tradeoff": "Managed by the BO acquisition function (not detailed in full); BO balances exploring hyperparameter space and exploiting promising regions via its surrogate/acquisition strategy (standard practice in Spearmint-style BO).",
            "comparison_methods": "BO is used as the hyperparameter search method; no direct comparison in paper against other hyperparameter search strategies is provided, though runtimes are compared implicitly to PBP and VI training runtimes.",
            "key_results": "Using BO over validation log-likelihood to set model precision and length-scale allowed MC-dropout models to achieve strong predictive performance (RMSE and predictive log-likelihood) across multiple regression benchmarks; authors note BO needed more iterations for dropout due to slower convergence but overall runtime was comparable to competing probabilistic methods when including BO.",
            "limitations_or_failures": "BO runs of only 40 iterations were insufficient for fully converged dropout hyperparameter tuning due to slower convergence of dropout models; authors extended BO and training epochs to get improved results. The paper does not provide ablation isolating the benefit due solely to BO vs other factors (e.g., more epochs, architecture changes). BO here is applied offline to static validation sets, not to an online/partially-observable environment.",
            "uuid": "e1280.1",
            "source_info": {
                "paper_title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning",
                "publication_date_yy_mm": "2015-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Human-level control through deep reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Probabilistic backpropagation for scalable learning of bayesian neural networks",
            "rating": 1
        },
        {
            "paper_title": "Practical Bayesian optimization of machine learning algorithms",
            "rating": 2
        },
        {
            "paper_title": "A Javascript implementation of neural networks",
            "rating": 2
        },
        {
            "paper_title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples",
            "rating": 1
        }
    ],
    "cost": 0.011512749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</h1>
<p>Yarin Gal<br>Zoubin Ghahramani<br>University of Cambridge</p>
<h4>Abstract</h4>
<p>Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.</p>
<h2>1. Introduction</h2>
<p>Deep learning has attracted tremendous attention from researchers in fields such as physics, biology, and manufacturing, to name a few (Baldi et al., 2014; Anjos et al., 2015; Bergmann et al., 2014). Tools such as neural networks (NNs), dropout, convolutional neural networks (convnets), and others are used extensively. However, these are fields in which representing model uncertainty is of crucial importance (Krzywinski \&amp; Altman, 2013; Ghahramani, 2015).</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>With the recent shift in many of these fields towards the use of Bayesian uncertainty (Herzog \&amp; Ostwald, 2013; Trafimow \&amp; Marks, 2015; Nuzzo, 2014), new needs arise from deep learning tools.</p>
<p>Standard deep learning tools for regression and classification do not capture model uncertainty. In classification, predictive probabilities obtained at the end of the pipeline (the softmax output) are often erroneously interpreted as model confidence. A model can be uncertain in its predictions even with a high softmax output (fig. 1). Passing a point estimate of a function (solid line 1a) through a softmax (solid line 1b) results in extrapolations with unjustified high confidence for points far from the training data. $x^{*}$ for example would be classified as class 1 with probability 1. However, passing the distribution (shaded area 1a) through a softmax (shaded area 1b) better reflects classification uncertainty far from the training data.</p>
<p>Model uncertainty is indispensable for the deep learning practitioner as well. With model confidence at hand we can treat uncertain inputs and special cases explicitly. For example, in the case of classification, a model might return a result with high uncertainty. In this case we might decide to pass the input to a human for classification. This can happen in a post office, sorting letters according to their zip code, or in a nuclear power plant with a system responsible for critical infrastructure (Linda et al., 2009). Uncertainty is important in reinforcement learning (RL) as well (Szepesvári, 2010). With uncertainty information an agent can decide when to exploit and when to explore its environment. Recent advances in RL have made use of NNs for Q-value function approximation. These are functions that estimate the quality of different actions an agent can take. Epsilon greedy search is often used where the agent selects its best action with some probability and explores otherwise. With uncertainty estimates over the agent's Q-value function, techniques such as Thompson sampling (Thompson, 1933) can be used to learn much faster.</p>
<p>Bayesian probability theory offers us mathematically grounded tools to reason about model uncertainty, but these usually come with a prohibitive computational cost. It is perhaps surprising then that it is possible to cast recent</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. A sketch of softmax input and output for an idealised binary classification problem. Training data is given between the dashed grey lines. Function point estimate is shown with a solid line. Function uncertainty is shown with a shaded area. Marked with a dashed red line is a point $x^{<em>}$ far from the training data. Ignoring function uncertainty, point $x^{</em>}$ is classified as class 1 with probability 1 .
deep learning tools as Bayesian models - without changing either the models or the optimisation. We show that the use of dropout (and its variants) in NNs can be interpreted as a Bayesian approximation of a well known probabilistic model: the Gaussian process (GP) (Rasmussen \&amp; Williams, 2006). Dropout is used in many models in deep learning as a way to avoid over-fitting (Srivastava et al., 2014), and our interpretation suggests that dropout approximately integrates over the models' weights. We develop tools for representing model uncertainty of existing dropout NNs - extracting information that has been thrown away so far. This mitigates the problem of representing model uncertainty in deep learning without sacrificing either computational complexity or test accuracy.</p>
<p>In this paper we give a complete theoretical treatment of the link between Gaussian processes and dropout, and develop the tools necessary to represent uncertainty in deep learning. We perform an extensive exploratory assessment of the properties of the uncertainty obtained from dropout NNs and convnets on the tasks of regression and classification. We compare the uncertainty obtained from different model architectures and non-linearities in regression, and show that model uncertainty is indispensable for classification tasks, using MNIST as a concrete example. We then show a considerable improvement in predictive loglikelihood and RMSE compared to existing state-of-theart methods. Lastly we give a quantitative assessment of model uncertainty in the setting of reinforcement learning, on a practical task similar to that used in deep reinforcement learning (Mnih et al., 2015). ${ }^{1}$</p>
<h2>2. Related Research</h2>
<p>It has long been known that infinitely wide (single hidden layer) NNs with distributions placed over their weights converge to Gaussian processes (Neal, 1995; Williams, 1997). This known relation is through a limit argument that does not allow us to translate properties from the Gaussian process to finite NNs easily. Finite NNs with distri-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>butions placed over the weights have been studied extensively as Bayesian neural networks (Neal, 1995; MacKay, 1992). These offer robustness to over-fitting as well, but with challenging inference and additional computational costs. Variational inference has been applied to these models, but with limited success (Hinton \&amp; Van Camp, 1993; Barber \&amp; Bishop, 1998; Graves, 2011). Recent advances in variational inference introduced new techniques into the field such as sampling-based variational inference and stochastic variational inference (Blei et al., 2012; Kingma \&amp; Welling, 2013; Rezende et al., 2014; Titsias \&amp; LázaroGredilla, 2014; Hoffman et al., 2013). These have been used to obtain new approximations for Bayesian neural networks that perform as well as dropout (Blundell et al., 2015). However these models come with a prohibitive computational cost. To represent uncertainty, the number of parameters in these models is doubled for the same network size. Further, they require more time to converge and do not improve on existing techniques. Given that good uncertainty estimates can be cheaply obtained from common dropout models, this might result in unnecessary additional computation. An alternative approach to variational inference makes use of expectation propagation (HernándezLobato \&amp; Adams, 2015) and has improved considerably in RMSE and uncertainty estimation on VI approaches such as (Graves, 2011). In the results section we compare dropout to these approaches and show a significant improvement in both RMSE and uncertainty estimation.</p>
<h2>3. Dropout as a Bayesian Approximation</h2>
<p>We show that a neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to the probabilistic deep Gaussian process (Damianou \&amp; Lawrence, 2013) (marginalised over its covariance function parameters). We would like to stress that no simplifying assumptions are made on the use of dropout in the literature, and that the results derived are applicable to any network architecture that makes use of dropout exactly as it appears in practical applications. Furthermore, our results carry to other variants of dropout as well (such as drop-connect</p>
<p>(Wan et al., 2013), multiplicative Gaussian noise (Srivastava et al., 2014), etc.). We show that the dropout objective, in effect, minimises the Kullback-Leibler divergence between an approximate distribution and the posterior of a deep Gaussian process (marginalised over its finite rank covariance function parameters). Due to space constraints we refer the reader to the appendix for an in depth review of dropout, Gaussian processes, and variational inference (section 2), as well as the main derivation for dropout and its variations (section 3). The results are summarised here and in the next section we obtain uncertainty estimates for dropout NNs.</p>
<p>Let $\widehat{\mathbf{y}}$ be the output of a NN model with $L$ layers and a loss function $E(\cdot, \cdot)$ such as the softmax loss or the Euclidean loss (square loss). We denote by $\mathbf{W}<em i="i">{i}$ the NN's weight matrices of dimensions $K</em>} \times K_{i-1}$, and by $\mathbf{b<em i="i">{i}$ the bias vectors of dimensions $K</em>}$ for each layer $i=1, \ldots, L$. We denote by $\mathbf{y<em i="i">{i}$ the observed output corresponding to input $\mathbf{x}</em>$ regularisation weighted by some weight decay $\lambda$, resulting in a minimisation objective (often referred to as cost),}$ for $1 \leq i \leq N$ data points, and the input and output sets as $\mathbf{X}, \mathbf{Y}$. During NN optimisation a regularisation term is often added. We often use $L_{2</p>
<p>$$
\mathcal{L}<em i="1">{\text {dropout }}:=\frac{1}{N} \sum</em>}^{N} E\left(\mathbf{y<em i="i">{i}, \widehat{\mathbf{y}}</em>}\right)+\lambda \sum_{i=1}^{L}\left(\left|\mathbf{W<em 2="2">{i}\right|</em>}^{2}+\left|\mathbf{b<em 2="2">{i}\right|</em>\right)
$$}^{2</p>
<p>With dropout, we sample binary variables for every input point and for every network unit in each layer (apart from the last one). Each binary variable takes value 1 with probability $p_{i}$ for layer $i$. A unit is dropped (i.e. its value is set to zero) for a given input if its corresponding binary variable takes value 0 . We use the same values in the backward pass propagating the derivatives to the parameters.</p>
<p>In comparison to the non-probabilistic NN, the deep Gaussian process is a powerful tool in statistics that allows us to model distributions over functions. Assume we are given a covariance function of the form</p>
<p>$$
\mathbf{K}(\mathbf{x}, \mathbf{y})=\int p(\mathbf{w}) p(b) \sigma\left(\mathbf{w}^{T} \mathbf{x}+b\right) \sigma\left(\mathbf{w}^{T} \mathbf{y}+b\right) \mathrm{d} \mathbf{w} \mathrm{~d} b
$$</p>
<p>with some element-wise non-linearity $\sigma(\cdot)$ and distributions $p(\mathbf{w}), p(b)$. In sections 3 and 4 in the appendix we show that a deep Gaussian process with $L$ layers and covariance function $\mathbf{K}(\mathbf{x}, \mathbf{y})$ can be approximated by placing a variational distribution over each component of a spectral decomposition of the GPs' covariance functions. This spectral decomposition maps each layer of the deep GP to a layer of explicitly represented hidden units, as will be briefly explained next.</p>
<p>Let $\mathbf{W}<em i="i">{i}$ be a (now random) matrix of dimensions $K</em>} \times$ $K_{i-1}$ for each layer $i$, and write $\boldsymbol{\omega}=\left{\mathbf{W<em i="1">{i}\right}</em>$. A priori,
we let each row of $\mathbf{W}}^{L<em i="i">{i}$ distribute according to the $p(\mathbf{w})$ above. In addition, assume vectors $\mathbf{m}</em>$ ) given some precision parameter $\tau&gt;0$ can be parametrised as}$ of dimensions $K_{i}$ for each GP layer. The predictive probability of the deep GP model (integrated w.r.t. the finite rank covariance function parameters $\boldsymbol{\omega</p>
<p>$$
\begin{gathered}
p(\mathbf{y} \mid \mathbf{x}, \mathbf{X}, \mathbf{Y})=\int p(\mathbf{y} \mid \mathbf{x}, \boldsymbol{\omega}) p(\boldsymbol{\omega} \mid \mathbf{X}, \mathbf{Y}) \mathrm{d} \boldsymbol{\omega} \
p(\mathbf{y} \mid \mathbf{x}, \boldsymbol{\omega})=\mathcal{N}\left(\mathbf{y} ; \widehat{\mathbf{y}}(\mathbf{x}, \boldsymbol{\omega}), \tau^{-1} \mathbf{I}<em 1="1">{D}\right) \
\widehat{\mathbf{y}}\left(\mathbf{x}, \boldsymbol{\omega}=\left{\mathbf{W}</em>}, \ldots, \mathbf{W<em L="L">{L}\right}\right) \
=\sqrt{\frac{1}{K</em>}}} \mathbf{W<em 1="1">{L} \sigma\left(\ldots \sqrt{\frac{1}{K</em>}}} \mathbf{W<em 1="1">{2} \sigma\left(\mathbf{W}</em>\right) \ldots\right)
\end{gathered}
$$} \mathbf{x}+\mathbf{m}_{1</p>
<p>The posterior distribution $p(\boldsymbol{\omega} \mid \mathbf{X}, \mathbf{Y})$ in eq. (2) is intractable. We use $q(\boldsymbol{\omega})$, a distribution over matrices whose columns are randomly set to zero, to approximate the intractable posterior. We define $q(\boldsymbol{\omega})$ as:</p>
<p>$$
\begin{aligned}
&amp; \mathbf{W}<em i="i">{i}=\mathbf{M}</em>} \cdot \operatorname{diag}\left(\left|\mathbf{z<em j="1">{i, j}\right|</em>\right) \
&amp; \mathbf{z}}^{K_{i}<em i="i">{i, j} \sim \operatorname{Bernoulli}\left(p</em>
\end{aligned}
$$}\right) \text { for } i=1, \ldots, L, j=1, \ldots, K_{i-1</p>
<p>given some probabilities $p_{i}$ and matrices $\mathbf{M}<em i_="i," j="j">{i}$ as variational parameters. The binary variable $\mathbf{z}</em>$ (which correspond to the frequencies in the sparse spectrum GP approximation).}=0$ corresponds then to unit $j$ in layer $i-1$ being dropped out as an input to layer $i$. The variational distribution $q(\boldsymbol{\omega})$ is highly multimodal, inducing strong joint correlations over the rows of the matrices $\mathbf{W}_{i</p>
<p>We minimise the KL divergence between the approximate posterior $q(\boldsymbol{\omega})$ above and the posterior of the full deep GP, $p(\boldsymbol{\omega} \mid \mathbf{X}, \mathbf{Y})$. This KL is our minimisation objective</p>
<p>$$
-\int q(\boldsymbol{\omega}) \log p(\mathbf{Y} \mid \mathbf{X}, \boldsymbol{\omega}) \mathrm{d} \boldsymbol{\omega}+\operatorname{KL}(q(\boldsymbol{\omega}) | p(\boldsymbol{\omega}))
$$</p>
<p>We rewrite the first term as a sum</p>
<p>$$
-\sum_{n=1}^{N} \int q(\boldsymbol{\omega}) \log p\left(\mathbf{y}<em n="n">{n} \mid \mathbf{x}</em>
$$}, \boldsymbol{\omega}\right) \mathrm{d} \boldsymbol{\omega</p>
<p>and approximate each term in the sum by Monte Carlo integration with a single sample $\widehat{\boldsymbol{\omega}}<em n="n">{n} \sim q(\boldsymbol{\omega})$ to get an unbiased estimate $-\log p\left(\mathbf{y}</em>} \mid \mathbf{x<em n="n">{n}, \widehat{\boldsymbol{\omega}}</em>}\right)$. We further approximate the second term in eq. (3) and obtain $\sum_{i=1}^{L}\left(\frac{p_{i} l^{2}}{2}\left|\mathbf{M<em 2="2">{i}\right|</em>}^{2}+\right.$ $\left.\frac{l^{2}}{2}\left|\mathbf{m<em 2="2">{i}\right|</em>\right)$ with prior length-scale $l$ (see section 4.2 in the appendix). Given model precision $\tau$ we scale the result by the constant $1 / \tau N$ to obtain the objective:}^{2</p>
<p>$$
\begin{aligned}
\mathcal{L}<em n="1">{\mathrm{GP} \text {-MC }} \propto &amp; \frac{1}{N} \sum</em>}^{N} \frac{-\log p\left(\mathbf{y<em n="n">{n} \mid \mathbf{x}</em>}, \widehat{\boldsymbol{\omega}<em i="1">{n}\right)}{\tau} \
&amp; \quad+\sum</em>}^{L}\left(\frac{p_{i} l^{2}}{2 \tau N}\left|\mathbf{M<em 2="2">{i}\right|</em>}^{2}+\frac{l^{2}}{2 \tau N}\left|\mathbf{m<em 2="2">{i}\right|</em>\right)
\end{aligned}
$$}^{2</p>
<p>Setting</p>
<p>$E\left(\mathbf{y}<em n="n">{n}, \widehat{\mathbf{y}}\left(\mathbf{x}</em>}, \widehat{\boldsymbol{\omega}<em n="n">{n}\right)\right)=-\log p\left(\mathbf{y}</em>} \mid \mathbf{x<em n="n">{n}, \widehat{\boldsymbol{\omega}}</em>\right) / \tau$
we recover eq. (1) for an appropriate setting of the precision hyper-parameter $\tau$ and length-scale $l$. The sampled $\widehat{\boldsymbol{\omega}}<em i_="i," j="j">{n}$ result in realisations from the Bernoulli distribution $\mathbf{z}</em>$.}^{n}$ equivalent to the binary variables in the dropout case ${ }^{2</p>
<h2>4. Obtaining Model Uncertainty</h2>
<p>We next derive results extending on the above showing that model uncertainty can be obtained from dropout NN models.</p>
<p>Following section 2.3 in the appendix, our approximate predictive distribution is given by</p>
<p>$$
q\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}\right)=\int p\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}, \boldsymbol{\omega}\right) q(\boldsymbol{\omega}) \mathrm{d} \boldsymbol{\omega}
$$</p>
<p>where $\boldsymbol{\omega}=\left{\mathbf{W}<em i="1">{i}\right}</em>$ is our set of random variables for a model with $L$ layers.}^{L</p>
<p>We will perform moment-matching and estimate the first two moments of the predictive distribution empirically. More specifically, we sample $T$ sets of vectors of realisations from the Bernoulli distribution $\left{\mathbf{z}<em L="L">{1}^{t}, \ldots, \mathbf{z}</em>\right}}^{t<em i="i">{t=1}^{T}$ with $\mathbf{z}</em>}^{t}=\left[\mathbf{z<em j="1">{i, j}^{t}\right]</em>}^{K_{i}}$, giving $\left{\mathbf{W<em L="L">{1}^{t}, \ldots, \mathbf{W}</em>$. We estimate}^{t}\right}_{t=1}^{T</p>
<p>$$
\mathbb{E}<em 1="1">{q\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}\right)}\left(\mathbf{y}^{<em>}\right) \approx \frac{1}{T} \sum_{t=1}^{T} \widehat{\mathbf{y}}^{</em>}\left(\mathbf{x}^{*}, \mathbf{W}</em>\right)
$$}^{t}, \ldots, \mathbf{W}_{L}^{t</p>
<p>following proposition C in the appendix. We refer to this Monte Carlo estimate as MC dropout. In practice this is equivalent to performing $T$ stochastic forward passes through the network and averaging the results.</p>
<p>This result has been presented in the literature before as model averaging. We have given a new derivation for this result which allows us to derive mathematically grounded uncertainty estimates as well. Srivastava et al. (2014, section 7.5) have reasoned empirically that MC dropout can be approximated by averaging the weights of the network (multiplying each $\mathbf{W}<em i="i">{i}$ by $p</em>$ at test time, referred to as standard dropout).</p>
<p>We estimate the second raw moment in the same way:</p>
<p>$$
\begin{aligned}
&amp; \mathbb{E}<em D="D">{q\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}\right)}\left(\left(\mathbf{y}^{<em>}\right)^{T}\left(\mathbf{y}^{</em>}\right)\right) \approx \tau^{-1} \mathbf{I}</em> \
&amp; \quad+\frac{1}{T} \sum_{t=1}^{T} \widehat{\mathbf{y}}^{<em>}\left(\mathbf{x}^{</em>}, \mathbf{W}<em L="L">{1}^{t}, \ldots, \mathbf{W}</em>^{}^{t}\right)^{T} \widehat{\mathbf{y}<em>}\left(\mathbf{x}^{</em>}, \mathbf{W}<em L="L">{1}^{t}, \ldots, \mathbf{W}</em>\right)
\end{aligned}
$$}^{t</p>
<p>following proposition D in the appendix. To obtain the model's predictive variance we have:</p>
<p>$$
\begin{aligned}
&amp; \operatorname{Var}<em q_left_mathbf_y="q\left(\mathbf{y">{q\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}\right)}\left(\mathbf{y}^{<em>}\right) \approx \tau^{-1} \mathbf{I}<em t="1">{D} \
&amp; \quad \frac{1}{T} \sum</em>^{}^{T} \widehat{\mathbf{y}</em>}\left(\mathbf{x}^{<em>}, \mathbf{W}<em L="L">{1}^{t}, \ldots, \mathbf{W}</em>^{}^{t}\right)^{T} \widehat{\mathbf{y}</em>}\left(\mathbf{x}^{<em>}, \mathbf{W}<em L="L">{1}^{t}, \ldots, \mathbf{W}</em>\right) \
&amp; \quad-\mathbb{E}_{q\left(\mathbf{y}^{}^{t</em>} \mid \mathbf{x}^{<em>}\right)}\left(\mathbf{y}^{</em>}\right)^{T} \mathbb{E}</em>^{<em>} \mid \mathbf{x}^{</em>}\right)}\left(\mathbf{y}^{*}\right)
\end{aligned}
$$</p>
<p>which equals the sample variance of $T$ stochastic forward passes through the NN plus the inverse model precision. Note that $\mathbf{y}^{*}$ is a row vector thus the sum is over the outerproducts. Given the weight-decay $\lambda$ (and our prior lengthscale $l$ ) we can find the model precision from the identity</p>
<p>$$
\tau=\frac{p l^{2}}{2 N \lambda}
$$</p>
<p>We can estimate our predictive log-likelihood by Monte Carlo integration of eq. (2). This is an estimate of how well the model fits the mean and uncertainty (see section 4.4 in the appendix). For regression this is given by:</p>
<p>$$
\begin{aligned}
\log p\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}, \mathbf{X}, \mathbf{Y}\right) \approx &amp; \operatorname{logsumexp}\left(-\frac{1}{2} \tau\left|\mathbf{y}-\widehat{\mathbf{y}}_{t}\right|^{2}\right) \
&amp; -\log T-\frac{1}{2} \log 2 \pi-\frac{1}{2} \log \tau^{-1}
\end{aligned}
$$</p>
<p>with a log-sum-exp of $T$ terms and $\widehat{\mathbf{y}}_{t}$ stochastic forward passes through the network.</p>
<p>Our predictive distribution $q\left(\mathbf{y}^{<em>} \mid \mathbf{x}^{</em>}\right)$ is expected to be highly multi-modal, and the above approximations only give a glimpse into its properties. This is because the approximating variational distribution placed on each weight matrix column is bi-modal, and as a result the joint distribution over each layer's weights is multi-modal (section 3.2 in the appendix).</p>
<p>Note that the dropout NN model itself is not changed. To estimate the predictive mean and predictive uncertainty we simply collect the results of stochastic forward passes through the model. As a result, this information can be used with existing NN models trained with dropout. Furthermore, the forward passes can be done concurrently, resulting in constant running time identical to that of standard dropout.</p>
<h2>5. Experiments</h2>
<p>We next perform an extensive assessment of the properties of the uncertainty estimates obtained from dropout NNs and convnets on the tasks of regression and classification. We compare the uncertainty obtained from different model architectures and non-linearities, both on tasks of extrapolation, and show that model uncertainty is important for classification tasks using MNIST (LeCun \&amp; Cortes, 1998) as an example. We then show that using dropout's uncertainty we can obtain a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods. We finish with an example use of the</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Predictive mean and uncertainties on the Mauna Loa CO<sub>2</sub> concentrations dataset, for various models. In red is the observed function (left of the dashed blue line); in blue is the predictive mean plus/minus two standard deviations (8 for fig. 2d). Different shades of blue represent half a standard deviation. Marked with a dashed red line is a point far away from the data: standard dropout confidently predicts an insensible value for the point; the other models predict insensible values as well but with the additional information that the models are uncertain about their predictions.</p>
<p>model's uncertainty in a Bayesian pipeline. We give a quantitative assessment of the model's performance in the setting of reinforcement learning on a task similar to that used in deep reinforcement learning (Mnih et al., 2015).</p>
<p>Using the results from the previous section, we begin by qualitatively evaluating the dropout NN uncertainty on two regression tasks. We use two regression datasets and model scalar functions which are easy to visualize. These are tasks one would often come across in real-world data analysis. We use a subset of the atmospheric CO<sub>2</sub> concentrations dataset derived from in situ air samples collected at Mauna Loa Observatory, Hawaii (Keeling et al., 2004) (referred to as CO<sub>2</sub>) to evaluate model extrapolation. In the appendix (section D.1) we give further results on a second dataset, the reconstructed solar irradiance dataset (Lean, 2004), to assess model interpolation. The datasets are fairly small, with each dataset consisting of about 200 data points. We centred and normalized both datasets.</p>
<h3>5.1. Model Uncertainty in Regression Tasks</h3>
<p>We trained several models on the CO<sub>2</sub> dataset. We use NNs with either 4 or 5 hidden layers and 1024 hidden units. We use either ReLU non-linearities or TanH non-linearities in each network, and use dropout probabilities of either 0.1 or 0.2. Exact experiment set-up is given in section E.1 in the appendix.</p>
<p>Extrapolation results are shown in figure 2. The model is trained on the training data (left of the dashed blue line), and tested on the entire dataset. Fig. 2a shows the results for standard dropout (i.e. with weight averaging and without assessing model uncertainty) for the 5 layer ReLU model. Fig. 2b shows the results obtained from a Gaussian process with a squared exponential covariance function for comparison. Fig. 2c shows the results of the same network as in fig. 2a, but with MC dropout used to evaluate the predictive mean and uncertainty for the training and test sets. Lastly, fig. 2d shows the same using the TanH network with 5 layers (plotted with 8 times the standard deviation for visualization purposes). The shades of blue represent model uncertainty: each colour gradient represents half a standard deviation (in total, predictive mean plus/minus 2 standard deviations are shown, representing 95% confidence). Not plotted are the models with 4 layers as these converge to the same results.</p>
<p>Extrapolating the observed data, none of the models can capture the periodicity (although with a suitable covariance function the GP will capture it well). The standard dropout NN model (fig. 2a) predicts value 0 for point z<sup>*</sup> (marked with a dashed red line) with high confidence, even though it is clearly not a sensible prediction. The GP model represents this by increasing its predictive uncertainty – in effect declaring that the predictive value might be 0 but the model is uncertain. This behaviour is captured in MC dropout as well. Even though the models in figures 2 have an incorrect predictive mean, the increased standard deviation expresses the models' uncertainty about the point.</p>
<p>Note that the uncertainty is increasing far from the data for the ReLU model, whereas for the TanH model it stays bounded.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Predictive mean and uncertainties on the Mauna Loa CO<sub>2</sub> concentrations dataset for the MC dropout model with ReLU non-linearities, approximated with 10 samples.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. A scatter of 100 forward passes of the softmax input and output for dropout LeNet. On the $X$ axis is a rotated image of the digit 1. The input is classified as digit 5 for images 6-7, even though model uncertainty is extremly large (best viewed in colour).</p>
<p>This is not surprising, as dropout's uncertainty draws its properties from the GP in which different covariance functions correspond to different uncertainty estimates. ReLU and TanH approximate different GP covariance functions (section 3.1 in the appendix) and TanH saturates whereas ReLU does not. For the TanH model we assessed the uncertainty using both dropout probability 0.1 and dropout probability 0.2 . Models initialised with dropout probability 0.1 initially exhibit smaller uncertainty than the ones initialised with dropout probability 0.2 , but towards the end of the optimisation when the model has converged the uncertainty is almost indistinguishable. It seems that the moments of the dropout models converge to the moments of the approximated GP model - its mean and uncertainty. It is worth mentioning that we attempted to fit the data with models with a smaller number of layers unsuccessfully.</p>
<p>The number of forward iterations used to estimate the uncertainty $(T)$ was 1000 for drawing purposes. A much smaller numbers can be used to get a reasonable estimation to the predictive mean and uncertainty (see fig. 3 for example with $T=10$ ).</p>
<h3>5.2. Model Uncertainty in Classification Tasks</h3>
<p>To assess model classification confidence in a realistic example we test a convolutional neural network trained on the full MNIST dataset (LeCun \&amp; Cortes, 1998). We trained the LeNet convolutional neural network model (LeCun et al., 1998) with dropout applied before the last fully connected inner-product layer (the usual way dropout is used in convnets). We used dropout probability of 0.5 . We trained the model for $10^{6}$ iterations with the same learning rate policy as before with $\gamma=0.0001$ and $p=0.75$. We used Caffe (Jia et al., 2014) reference implementation for this experiment.</p>
<p>We evaluated the trained model on a continuously rotated image of the digit 1 (shown on the $X$ axis of fig. 4). We
scatter 100 stochastic forward passes of the softmax input (the output from the last fully connected layer, fig. 4a), as well as of the softmax output for each of the top classes (fig. 4b). For the 12 images, the model predicts classes [1 111155777777].</p>
<p>The plots show the softmax input value and softmax output value for the 3 digits with the largest values for each corresponding input. When the softmax input for a class is larger than that of all other classes (class 1 for the first 5 images, class 5 for the next 2 images, and class 7 for the rest in fig 4a), the model predicts the corresponding class. Looking at the softmax input values, if the uncertainty envelope of a class is far from that of other classes' (for example the left most image) then the input is classified with high confidence. On the other hand, if the uncertainty envelope intersects that of other classes (such as in the case of the middle input image), then even though the softmax output can be arbitrarily high (as far as 1 if the mean is far from the means of the other classes), the softmax output uncertainty can be as large as the entire space. This signifies the model's uncertainty in its softmax output value - i.e. in the prediction. In this scenario it would not be reasonable to use probit to return class 5 for the middle image when its uncertainty is so high. One would expect the model to ask an external annotator for a label for this input. Model uncertainty in such cases can be quantified by looking at the entropy or variation ratios of the model prediction.</p>
<h3>5.3. Predictive Performance</h3>
<p>Predictive log-likelihood captures how well a model fits the data, with larger values indicating better model fit. Uncertainty quality can be determined from this quantity as well (see section 4.4 in the appendix). We replicate the experiment set-up in Hernández-Lobato \&amp; Adams (2015) and compare the RMSE and predictive log-likelihood of dropout (referred to as "Dropout" in the experiments) to that of Probabilistic Back-propagation (referred to as</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">$N$</th>
<th style="text-align: center;">$Q$</th>
<th style="text-align: center;">Avg. Test RMSE and Std. Errors</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Avg. Test LL and Std. Errors</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">VI</td>
<td style="text-align: center;">PBP</td>
<td style="text-align: center;">Dropout</td>
<td style="text-align: center;">VI</td>
<td style="text-align: center;">PBP</td>
<td style="text-align: center;">Dropout</td>
</tr>
<tr>
<td style="text-align: center;">Boston Housing</td>
<td style="text-align: center;">506</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">$4.32 \pm 0.29$</td>
<td style="text-align: center;">$3.01 \pm 0.18$</td>
<td style="text-align: center;">2.97 $\pm$ 0.19</td>
<td style="text-align: center;">$-2.90 \pm 0.07$</td>
<td style="text-align: center;">$-2.57 \pm 0.09$</td>
<td style="text-align: center;">$-2.46 \pm 0.06$</td>
</tr>
<tr>
<td style="text-align: center;">Concrete Strength</td>
<td style="text-align: center;">1,030</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$7.19 \pm 0.12$</td>
<td style="text-align: center;">$5.67 \pm 0.09$</td>
<td style="text-align: center;">5.23 $\pm$ 0.12</td>
<td style="text-align: center;">$-3.39 \pm 0.02$</td>
<td style="text-align: center;">$-3.16 \pm 0.02$</td>
<td style="text-align: center;">$-3.04 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: center;">Energy Efficiency</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$2.65 \pm 0.08$</td>
<td style="text-align: center;">$1.80 \pm 0.05$</td>
<td style="text-align: center;">1.66 $\pm$ 0.04</td>
<td style="text-align: center;">$-2.39 \pm 0.03$</td>
<td style="text-align: center;">$-2.04 \pm 0.02$</td>
<td style="text-align: center;">$-1.99 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: center;">Kin8nm</td>
<td style="text-align: center;">8,192</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$0.10 \pm 0.00$</td>
<td style="text-align: center;">$0.10 \pm 0.00$</td>
<td style="text-align: center;">$0.10 \pm 0.00$</td>
<td style="text-align: center;">$0.90 \pm 0.01$</td>
<td style="text-align: center;">$0.90 \pm 0.01$</td>
<td style="text-align: center;">$0.95 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: center;">Naval Propulsion</td>
<td style="text-align: center;">11,934</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">$0.01 \pm 0.00$</td>
<td style="text-align: center;">$0.01 \pm 0.00$</td>
<td style="text-align: center;">$0.01 \pm 0.00$</td>
<td style="text-align: center;">$3.73 \pm 0.12$</td>
<td style="text-align: center;">$3.73 \pm 0.01$</td>
<td style="text-align: center;">$3.80 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: center;">Power Plant</td>
<td style="text-align: center;">9,568</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">$4.33 \pm 0.04$</td>
<td style="text-align: center;">$4.12 \pm 0.03$</td>
<td style="text-align: center;">4.02 $\pm$ 0.04</td>
<td style="text-align: center;">$-2.89 \pm 0.01$</td>
<td style="text-align: center;">$-2.84 \pm 0.01$</td>
<td style="text-align: center;">$-2.80 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: center;">Protein Structure</td>
<td style="text-align: center;">45,730</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$4.84 \pm 0.03$</td>
<td style="text-align: center;">$4.73 \pm 0.01$</td>
<td style="text-align: center;">4.36 $\pm$ 0.01</td>
<td style="text-align: center;">$-2.99 \pm 0.01$</td>
<td style="text-align: center;">$-2.97 \pm 0.00$</td>
<td style="text-align: center;">$-2.89 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;">Wine Quality Red</td>
<td style="text-align: center;">1,599</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">$0.65 \pm 0.01$</td>
<td style="text-align: center;">$0.64 \pm 0.01$</td>
<td style="text-align: center;">0.62 $\pm$ 0.01</td>
<td style="text-align: center;">$-0.98 \pm 0.01$</td>
<td style="text-align: center;">$-0.97 \pm 0.01$</td>
<td style="text-align: center;">$-0.93 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: center;">Yacht Hydrodynamics</td>
<td style="text-align: center;">308</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">$6.89 \pm 0.67$</td>
<td style="text-align: center;">1.02 $\pm$ 0.05</td>
<td style="text-align: center;">$1.11 \pm 0.09$</td>
<td style="text-align: center;">$-3.43 \pm 0.16$</td>
<td style="text-align: center;">$-1.63 \pm 0.02$</td>
<td style="text-align: center;">$-1.55 \pm 0.03$</td>
</tr>
<tr>
<td style="text-align: center;">Year Prediction MSD</td>
<td style="text-align: center;">515,345</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">$9.034 \pm \mathrm{NA}$</td>
<td style="text-align: center;">$8.879 \pm \mathrm{NA}$</td>
<td style="text-align: center;">8.849 $\pm$ NA</td>
<td style="text-align: center;">$-3.622 \pm \mathrm{NA}$</td>
<td style="text-align: center;">$-3.603 \pm \mathrm{NA}$</td>
<td style="text-align: center;">$-3.588 \pm \mathrm{NA}$</td>
</tr>
</tbody>
</table>
<p>Table 1. Average test performance in RMSE and predictive log likelihood for a popular variational inference method (VI, Graves (2011)), Probabilistic back-propagation (PBP, Hernández-Lobato \&amp; Adams (2015)), and dropout uncertainty (Dropout). Dataset size $(N)$ and input dimensionality $(Q)$ are also given.
"PBP", (Hernández-Lobato \&amp; Adams, 2015)) and to a popular variational inference technique in Bayesian NNs (referred to as "VI", (Graves, 2011)). The aim of this experiment is to compare the uncertainty quality obtained from a naive application of dropout in NNs to that of specialised methods developed to capture uncertainty.</p>
<p>Following our Bayesian interpretation of dropout (eq. (4)) we need to define a prior length-scale, and find an optimal model precision parameter $\tau$ which will allow us to evaluate the predictive log-likelihood (eq. (8)). Similarly to (Hernández-Lobato \&amp; Adams, 2015) we use Bayesian optimisation (BO, (Snoek et al., 2012; Snoek \&amp; authors, 2015)) over validation log-likelihood to find optimal $\tau$, and set the prior length-scale to $10^{-2}$ for most datasets based on the range of the data. Note that this is a standard dropout NN, where the prior length-scale $l$ and model precision $\tau$ are simply used to define the model's weight decay through eq. (7). We used dropout with probabilities 0.05 and 0.005 since the network size is very small (with 50 units following (Hernández-Lobato \&amp; Adams, 2015)) and the datasets are fairly small as well. The BO runs used 40 iterations following the original setup, but after finding the optimal parameter values we used 10x more iterations, as dropout takes longer to converge. Even though the model doesn't converge within 40 iterations, it gives BO a good indication of whether a parameter is good or not. Finally, we used mini-batches of size 32 and the Adam optimiser (Kingma \&amp; Ba, 2014). Further details about the various datasets are given in (Hernández-Lobato \&amp; Adams, 2015).</p>
<p>The results are shown in table ${ }^{3} 1$. Dropout significantly outperforms all other models both in terms of RMSE as well as test log-likelihood on all datasets apart from Yacht, for which PBP obtains better RMSE. All experiments were averaged on 20 random splits of the data (apart from Pro-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>tein for which only 5 splits were used and Year for which one split was used). The median for most datasets gives much better performance than the mean. For example, on the Boston Housing dataset dropout achieves median RMSE of 2.68 with an IQR interval of [2.45, 3.35] and predictive log-likelihood median of -2.34 with IQR [-2.54, -2.29]. In the Concrete Strength dataset dropout achieves median RMSE of 5.15.</p>
<p>To implement the model we used Keras (Chollet, 2015), an open source deep learning package based on Theano (Bergstra et al., 2010). In (Hernández-Lobato \&amp; Adams, 2015) BO for VI seems to require a considerable amount of additional time compared to PBP. However our model's running time (including BO) is comparable to PBP's Theano implementation ${ }^{4}$. On Naval Propulsion for example our model takes 276 seconds on average per split (start-to-finish, divided by the number of splits). With the optimal parameters BO found, model training took 95 seconds. This is in comparison to PBP's 220 seconds. For Kin8nm our model requires 188 seconds on average including BO, 65 seconds without, compared to PBP's 156 seconds.</p>
<p>Dropout's RMSE in table 1 is given by averaging stochastic forward passes through the network following eq. (6) (MC dropout). We observed an improvement using this estimate compared to the standard dropout weight averaging, and also compared to much smaller dropout probabilities (near zero). For the Boston Housing dataset for example, repeating the same experiment with dropout probability 0 results in RMSE of 3.07 and predictive log-likelihood of</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>-2.59. This demonstrates that dropout significantly affects the predictive log-likelihood and RMSE, even though the dropout probability is fairly small.</p>
<p>We used dropout following the same way the method would be used in current research - without adapting model structure. This is to demonstrate the results that could be obtained from existing models when evaluated with MC dropout. Experimenting with different network architectures we expect the method to give even better uncertainty estimates.</p>
<h3>5.4. Model Uncertainty in Reinforcement Learning</h3>
<p>In reinforcement learning an agent receives various rewards from different states, and its aim is to maximise its expected reward over time. The agent tries to learn to avoid transitioning into states with low rewards, and to pick actions that lead to better states instead. Uncertainty is of great importance in this task - with uncertainty information an agent can decide when to exploit rewards it knows of, and when to explore its environment.</p>
<p>Recent advances in RL have made use of NNs to estimate agents' Q-value functions (referred to as Q-networks), a function that estimates the quality of different actions an agent can take at different states. This has led to impressive results on Atari game simulations, where agents superseded human performance on a variety of games (Mnih et al., 2015). Epsilon greedy search was used in this setting, where the agent selects the best action following its current Q-function estimation with some probability, and explores otherwise. With our uncertainty estimates given by a dropout Q-network we can use techniques such as Thompson sampling (Thompson, 1933) to converge faster</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Depiction of the reinforcement learning problem used in the experiments. The agent is in the lower left part of the maze, facing north-west. than epsilon greedy while avoiding over-fitting.
We use code by (Karpathy \&amp; authors, 2014-2015) that replicated the results by (Mnih et al., 2015) with a simpler 2D setting. We simulate an agent in a 2D world with 9 eyes pointing in different angles ahead (depicted in fig. 5). Each eye can sense a single pixel intensity of 3 colours. The agent navigates by using one of 5 actions controlling two motors at its base. An action turns the motors at different angles and different speeds. The environment consists of red circles which give the agent a positive reward for reaching, and green circles which result in a negative reward. The agent is further rewarded for not looking at (white) walls, and for walking in a straight line.</p>
<p>We trained the original model, and an additional model with dropout with probability 0.1 applied before the every weight layer. Note that both agents use the same network structure in this experiment for comparison purposes. In a real world scenario using dropout we would use a larger model (as the original model was intentially selected to be small to avoid over-fitting). To make use of the dropout Qnetwork's uncertainty estimates, we use Thompson sampling instead of epsilon greedy. In effect this means that we perform a single stochastic forward pass through the network every time we need to take an action. In replay, we perform a single stochastic forward pass and then backpropagate with the sampled Bernoulli random variables. Exact experiment set-up is given in section E. 2 in the appendix.</p>
<p>In fig. 6 we show a log plot of the average reward obtained by both the original implementation (in green) and our approach (in blue), as a function of the number of batches. Not plotted is the burn-in intervals of 25 batches (random</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6. Log plot of average reward obtained by both epsilon greedy (in green) and our approach (in blue), as a function of the number of batches.</p>
<p>moves). Thompson sampling gets reward larger than 1 within 25 batches from burn-in. Epsilon greedy takes 175 batches to achieve the same performance. It is interesting to note that our approach seems to stop improving after 1 K batches. This is because we are still sampling random moves, whereas epsilon greedy only exploits at this stage.</p>
<h2>6. Conclusions and Future Research</h2>
<p>We have built a probabilistic interpretation of dropout which allowed us to obtain model uncertainty out of existing deep learning models. We have studied the properties of this uncertainty in detail, and demonstrated possible applications, interleaving Bayesian models and deep learning models together. This extends on initial research studying dropout from the Bayesian perspective (Wang \&amp; Manning, 2013; Maeda, 2014).</p>
<p>Bernoulli dropout is only one example of a regularisation technique corresponding to an approximate variational distribution which results in uncertainty estimates. Other variants of dropout follow our interpretation as well and correspond to alternative approximating distributions. These would result in different uncertainty estimates, trading-off uncertainty quality with computational complexity. We explore these in follow-up work.</p>
<p>Furthermore, each GP covariance function has a one-toone correspondence with the combination of both NN nonlinearities and weight regularisation. This suggests techniques to select appropriate NN structure and regularisation based on our a priori assumptions about the data. For example, if one expects the function to be smooth and the uncertainty to increase far from the data, cosine nonlinearities and $L_{2}$ regularisation might be appropriate. The study of non-linearity-regularisation combinations and the corresponding predictive mean and variance are subject of current research.</p>
<h2>ACKNOWLEDGEMENTS</h2>
<p>The authors would like to thank Dr Yutian Chen, Mr Christof Angermueller, Mr Roger Frigola, Mr Rowan McAllister, Dr Gabriel Synnaeve, Mr Mark van der Wilk, Mr Yan Wu, and many other reviewers for their helpful comments. Yarin Gal is supported by the Google European Fellowship in Machine Learning.</p>
<h2>References</h2>
<p>Anjos, O, Iglesias, C, Peres, F, Martínez, J, García, Á, and Taboada, J. Neural networks applied to discriminate botanical origin of honeys. Food chemistry, 175: $128-136,2015$.</p>
<p>Baldi, P, Sadowski, P, and Whiteson, D. Searching for ex-
otic particles in high-energy physics with deep learning. Nature communications, 5, 2014.</p>
<p>Barber, D and Bishop, C M. Ensemble learning in Bayesian neural networks. NATO ASI SERIES F COMPUTER AND SYSTEMS SCIENCES, 168:215-238, 1998.</p>
<p>Bergmann, S, Stelzer, S, and Strassburger, S. On the use of artificial neural networks in simulation-based manufacturing control. Journal of Simulation, 8(1):76-90, 2014.</p>
<p>Bergstra, James, Breuleux, Olivier, Bastien, Frédéric, Lamblin, Pascal, Pascanu, Razvan, Desjardins, Guillaume, Turian, Joseph, Warde-Farley, David, and Bengio, Yoshua. Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy), June 2010. Oral Presentation.</p>
<p>Blei, D M, Jordan, M I, and Paisley, J W. Variational Bayesian inference with stochastic search. In ICML, 2012.</p>
<p>Blundell, C, Cornebise, J, Kavukcuoglu, K, and Wierstra, D. Weight uncertainty in neural networks. ICML, 2015.</p>
<p>Chen, W, Wilson, J T, Tyree, S, Weinberger, K Q, and Chen, Y. Compressing neural networks with the hashing trick. In ICML-15, 2015.</p>
<p>Chollet, François. Keras. https://github.com/ fchollet/keras, 2015.</p>
<p>Damianou, A and Lawrence, N. Deep Gaussian processes. In AISTATS, 2013.</p>
<p>Ghahramani, Z. Probabilistic machine learning and artificial intelligence. Nature, 521(7553), 2015.</p>
<p>Graves, A. Practical variational inference for neural networks. In NIPS, 2011.</p>
<p>Hernández-Lobato, J M and Adams, R P. Probabilistic backpropagation for scalable learning of bayesian neural networks. In ICML-15, 2015.</p>
<p>Herzog, S and Ostwald, D. Experimental biology: Sometimes Bayesian statistics are better. Nature, 494, 2013.</p>
<p>Hinton, G E and Van Camp, D. Keeping the neural networks simple by minimizing the description length of the weights. In Proceedings of the sixth annual conference on Computational learning theory, 1993.</p>
<p>Hoffman, M D, Blei, D M, Wang, C, and Paisley, J. Stochastic variational inference. The Journal of Machine Learning Research, 14(1):1303-1347, 2013.</p>
<p>Jia, Y, Shelhamer, E, Donahue, J, Karayev, S, Long, J, Girshick, R, Guadarrama, S, and Darrell, T. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.</p>
<p>Karpathy, A and authors. A Javascript implementation of neural networks. https://github.com/ karpathy/convnetjs, 2014-2015.</p>
<p>Keeling, C D, Whorf, T P, and the Carbon Dioxide Research Group. Atmospheric CO2 concentrations (ppmv) derived from in situ air samples collected at Mauna Loa Observatory, Hawaii, 2004.</p>
<p>Kingma, D P and Welling, M. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114, 2013.</p>
<p>Kingma, Diederik and Ba, Jimmy. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.</p>
<p>Krzywinski, M and Altman, N. Points of significance: Importance of being uncertain. Nature methods, 10(9), 2013.</p>
<p>Lean, J. Solar irradiance reconstruction. NOAA/NGDC Paleoclimatology Program, USA, 2004.</p>
<p>LeCun, Y and Cortes, C. The mnist database of handwritten digits, 1998.</p>
<p>LeCun, Y, Bottou, L, Bengio, Y, and Haffner, P. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.</p>
<p>Linda, O, Vollmer, T, and Manic, M. Neural network based intrusion detection system for critical infrastructures. In Neural Networks, 2009. IJCNN 2009. International Joint Conference on. IEEE, 2009.</p>
<p>MacKay, D J C. A practical Bayesian framework for backpropagation networks. Neural computation, 4(3), 1992.</p>
<p>Maeda, S. A Bayesian encourages dropout. arXiv preprint arXiv:1412.7003, 2014.</p>
<p>Mnih, V, Kavukcuoglu, K, Silver, D, Rusu, A A, Veness, J, et al. Human-level control through deep reinforcement learning. Nature, 518(7540):529-533, 2015.</p>
<p>Neal, R M. Bayesian learning for neural networks. PhD thesis, University of Toronto, 1995.</p>
<p>Nuzzo, Regina. Statistical errors. Nature, 506(13):150152, 2014.</p>
<p>Rasmussen, C E and Williams, C K I. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press, 2006.</p>
<p>Rezende, D J, Mohamed, S, and Wierstra, D. Stochastic backpropagation and approximate inference in deep generative models. In ICML, 2014.</p>
<p>Snoek, Jasper and authors. Spearmint. https:// github.com/JasperSnoek/spearmint, 2015.</p>
<p>Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan P. Practical Bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, pp. 2951-2959, 2012.</p>
<p>Srivastava, N, Hinton, G, Krizhevsky, A, Sutskever, I, and Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1), 2014.</p>
<p>Szepesvári, C. Algorithms for reinforcement learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 4(1), 2010.</p>
<p>Thompson, W R. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 1933.</p>
<p>Titsias, M and Lázaro-Gredilla, M. Doubly stochastic variational Bayes for non-conjugate inference. In ICML, 2014.</p>
<p>Trafimow, D and Marks, M. Editorial. Basic and Applied Social Psychology, 37(1), 2015.</p>
<p>Wan, L, Zeiler, M, Zhang, S, LeCun, Y, and Fergus, R. Regularization of neural networks using dropconnect. In ICML-13, 2013.</p>
<p>Wang, S and Manning, C. Fast dropout training. ICML, 2013.</p>
<p>Williams, C K I. Computing with infinite networks. NIPS, 1997.</p>
<h1>A. Appendix</h1>
<p>The appendix for the paper is given at http://arxiv. org/abs/1506.02157.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Avg. Test RMSE and Std. Errors</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Avg. Test LL and Std. Errors</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Dataset</td>
<td style="text-align: center;">Dropout</td>
<td style="text-align: center;">10x Epochs</td>
<td style="text-align: center;">2 Layers</td>
<td style="text-align: center;">Dropout</td>
<td style="text-align: center;">10x Epochs</td>
<td style="text-align: center;">2 Layers</td>
</tr>
<tr>
<td style="text-align: left;">Boston Housing</td>
<td style="text-align: center;">$2.97 \pm 0.19$</td>
<td style="text-align: center;">$2.80 \pm 0.19$</td>
<td style="text-align: center;">$2.80 \pm 0.13$</td>
<td style="text-align: center;">$-2.46 \pm 0.06$</td>
<td style="text-align: center;">$-2.39 \pm 0.05$</td>
<td style="text-align: center;">$-2.34 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;">Concrete Strength</td>
<td style="text-align: center;">$5.23 \pm 0.12$</td>
<td style="text-align: center;">$4.81 \pm 0.14$</td>
<td style="text-align: center;">$4.50 \pm 0.18$</td>
<td style="text-align: center;">$-3.04 \pm 0.02$</td>
<td style="text-align: center;">$-2.94 \pm 0.02$</td>
<td style="text-align: center;">$-2.82 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;">Energy Efficiency</td>
<td style="text-align: center;">$1.66 \pm 0.04$</td>
<td style="text-align: center;">$1.09 \pm 0.05$</td>
<td style="text-align: center;">$0.47 \pm 0.01$</td>
<td style="text-align: center;">$-1.99 \pm 0.02$</td>
<td style="text-align: center;">$-1.72 \pm 0.02$</td>
<td style="text-align: center;">$-1.48 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">Kin8nm</td>
<td style="text-align: center;">$0.10 \pm 0.00$</td>
<td style="text-align: center;">$0.09 \pm 0.00$</td>
<td style="text-align: center;">$0.08 \pm 0.00$</td>
<td style="text-align: center;">$0.95 \pm 0.01$</td>
<td style="text-align: center;">$0.97 \pm 0.01$</td>
<td style="text-align: center;">$1.10 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">Naval Propulsion</td>
<td style="text-align: center;">$0.01 \pm 0.00$</td>
<td style="text-align: center;">$0.00 \pm 0.00$</td>
<td style="text-align: center;">$0.00 \pm 0.00$</td>
<td style="text-align: center;">$3.80 \pm 0.01$</td>
<td style="text-align: center;">$3.92 \pm 0.01$</td>
<td style="text-align: center;">$4.32 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">Power Plant</td>
<td style="text-align: center;">$4.02 \pm 0.04$</td>
<td style="text-align: center;">$4.00 \pm 0.04$</td>
<td style="text-align: center;">$3.63 \pm 0.04$</td>
<td style="text-align: center;">$-2.80 \pm 0.01$</td>
<td style="text-align: center;">$-2.79 \pm 0.01$</td>
<td style="text-align: center;">$-2.67 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">Protein Structure</td>
<td style="text-align: center;">$4.36 \pm 0.01$</td>
<td style="text-align: center;">$4.27 \pm 0.01$</td>
<td style="text-align: center;">$3.62 \pm 0.01$</td>
<td style="text-align: center;">$-2.89 \pm 0.00$</td>
<td style="text-align: center;">$-2.87 \pm 0.00$</td>
<td style="text-align: center;">$-2.70 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">Wine Quality Red</td>
<td style="text-align: center;">$0.62 \pm 0.01$</td>
<td style="text-align: center;">$0.61 \pm 0.01$</td>
<td style="text-align: center;">$0.60 \pm 0.01$</td>
<td style="text-align: center;">$-0.93 \pm 0.01$</td>
<td style="text-align: center;">$-0.92 \pm 0.01$</td>
<td style="text-align: center;">$-0.90 \pm 0.01$</td>
</tr>
<tr>
<td style="text-align: left;">Yacht Hydrodynamics</td>
<td style="text-align: center;">$1.11 \pm 0.09$</td>
<td style="text-align: center;">$0.72 \pm 0.06$</td>
<td style="text-align: center;">$0.66 \pm 0.06$</td>
<td style="text-align: center;">$-1.55 \pm 0.03$</td>
<td style="text-align: center;">$-1.38 \pm 0.01$</td>
<td style="text-align: center;">$-1.37 \pm 0.02$</td>
</tr>
</tbody>
</table>
<p>Table 2. Average test performance in RMSE and predictive log likelihood for dropout uncertainty as above (Dropout), the same model optimised with 10 times the number of epochs and identical model precision (10x epochs), and the same model again with 2 layers instead of 1 (2 Layers).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ Update [October 2016]: Note that in an earlier version of this paper our reported dropout standard error was erroneously scaledup by a factor of 4.5 (i.e. for Boston RMSE we reported standard error 0.85 instead of 0.19 for example).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ Update [October 2016]: In the results above we attempted to match PBP's run time (hence used only 10x more epochs compared to PBP's 40 epochs). Experimenting with 100x more epochs compared to PBP (10x more epochs compared to the results in table 1) gives a considerable improvement both in terms of test RMSE as well as test log-likelihood over the results in table 1. We further assessed a model with two hidden layers instead of one (using the same number of units for the second layer). Both experiments are shown in table 2 at the end of this document.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>