<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2314 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2314</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2314</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-254246404</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2212.01493v1.pdf" target="_blank">Applications of AI in Astronomy</a></p>
                <p><strong>Paper Abstract:</strong> We provide a brief, and inevitably incomplete overview of the use of Machine Learning (ML) and other AI methods in astronomy, astrophysics, and cosmology. Astronomy entered the big data era with the first digital sky surveys in the early 1990s and the resulting Terascale data sets, which required automating of many data processing and analysis tasks, for example the star-galaxy separation, with billions of feature vectors in hundreds of dimensions. The exponential data growth continued, with the rise of synoptic sky surveys and the Time Domain Astronomy, with the resulting Petascale data streams and the need for a real-time processing, classification, and decision making. A broad variety of classification and clustering methods have been applied for these tasks, and this remains a very active area of research. Over the past decade we have seen an exponential growth of the astronomical literature involving a variety of ML/AI applications of an ever increasing complexity and sophistication. ML and AI are now a standard part of the astronomical toolkit. As the data complexity continues to increase, we anticipate further advances leading towards a collaborative human-AI discovery.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2314.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2314.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Star-Galaxy Separation (ANN/DT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Star-Galaxy Separation using Artificial Neural Networks and Decision Trees</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised morphological classification of unresolved (stars) vs resolved (galaxies) sources in digital sky surveys using feature vectors derived from image segmentation, employing Artificial Neural Networks and Decision Trees to automate large-scale catalog classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>astronomical source classification / sky surveys</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Separate point-like (stellar) sources from extended (galactic) sources in large imaging surveys to build clean catalogs for downstream science and remove instrumental artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>abundant — millions to billions of detected sources from digital sky surveys; labeled examples exist from prior human/algorithmic classifications though labels may be incomplete for rare classes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>structured tabular feature vectors (tens to hundreds of morphological and structural parameters) derived from images; high-dimensional</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>high dimensionality (tens to hundreds of features), large sample sizes (millions to billions), mostly morphological non-linear decision boundaries but relatively low intrinsic class complexity for the star vs galaxy task</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>well-established — early and standard task in survey pipelines with substantial prior work and domain expertise</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>low to medium — primary goal is accurate classification for downstream use; interpretability useful for diagnosing artifacts but black-box models acceptable in many pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Artificial Neural Networks (ANN), Decision Trees (DT)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised classifiers trained on labeled catalogs using morphological/structural features computed per detected source; decision trees provide rule-based splits, ANNs learn non-linear feature combinations to separate classes.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>high — methods are appropriate and were adopted early to automate repetitive classification tasks and artifact rejection; suited to large labeled data sets</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Described as effective for star-galaxy separation and artifact removal at survey scale; these methods enabled catalog-scale automation and replacement of manual classification.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — enabled conversion of terascale/petascale image data into usable catalogs, allowed prioritization of follow-up resources, and made large statistical studies feasible.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper notes supervised classifiers performed effectively compared to manual classification; no detailed quantitative comparisons provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Abundant labeled data, well-engineered morphological features from image segmentation, and the relatively well-posed two-class morphology problem.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>For large, well-labeled morphological classification tasks in surveys, classical supervised models (ANNs, DTs) are highly applicable because of abundant data and relatively low class complexity.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2314.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Time-Domain Transient Classification (ZTF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Real-time Transient Classification in Time-Domain Astronomy using DNNs, XGBoost and Binary Classifiers (ZTF example)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Machine learning pipelines (including deep neural networks, gradient-boosted trees like XGBoost, and binary classifiers) used to classify variable and transient events in real-time streams from synoptic surveys such as ZTF to prioritize follow-up observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Machine Learning for the Zwicky Transient Facility</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>time-domain astronomy / transient event classification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Fast, often real-time classification of transient and variable astronomical events from repeated sky imaging, dealing with heterogeneously sampled time series and the need to prioritize scarce follow-up resources.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>very large streaming datasets (petascale/data streams) from synoptic surveys; labeled examples exist for many classes but class imbalance is common and missing features arise when crossmatching external catalogs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>multidimensional time series, supplemented by tabular features and cross-matched catalog data (multimodal and often incomplete); high-dimensional feature spaces (tens to hundreds)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>high — high dimensionality, heterogenous and incomplete features, class imbalance, need for real-time processing and multi-class disambiguation under time constraints</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging-to-mature — active area of research with growing literature; domain expertise available but many open challenges remain (real-time decision making, anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>medium — accurate prioritization is primary, but interpretability and uncertainty estimates are valuable for resource allocation and for scientific validation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep Neural Networks (DNN), XGBoost, Binary Classifiers (ensemble approaches)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised learning pipelines train DNNs and gradient-boosted trees on feature vectors derived from light curves and contextual information; feature selection and dimensionality reduction are used to mitigate high dimensionality; active learning and model cards/data sheets are recommended for standardization.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (with feature engineering and active learning elements)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>high — methods are well suited to classification and prioritization in streaming time-domain data, though care is needed for missing features, class imbalance, and computational scaling.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as effective and widely used (ZTF example); DNNs and XGBoost help identify important features and support real-time classifications, but challenges include handling missing features and optimizing for many classes.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — enables real-time prioritization of follow-up, optimizes scarce observational resources, and scales transient discovery to petascale survey data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper notes GPR and RNNs as alternative approaches for time series interpolation/forecasting; DNNs and XGBoost are practical for classification and feature importance; no quantitative head-to-head metrics provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large streaming datasets enabling supervised training, careful feature engineering, use of ensemble methods and feature selection, and integration into real-time pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>For high-rate, high-dimensional transient streams, supervised DNNs and gradient-boosted trees provide practical, effective classification and prioritization when combined with feature selection and workflows that handle missing data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2314.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gaussian Process Regression (GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Regression for astronomical time series interpolation and uncertainty-aware prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Probabilistic non-parametric regression that models time series as draws from a multivariate Gaussian characterized by a covariance (kernel) and mean, used to interpolate irregularly sampled astronomical time series and provide predictive uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gaussian Processes for Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>time-series modeling / interpolation in time-domain astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Interpolate and predict values in irregular, multidimensional time series (e.g., light curves) and quantify uncertainties to support classification and follow-up decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>typical datasets include many individual time series with sparse/irregular sampling; can scale to thousands of samples but per-series data points may be limited or unevenly distributed.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>multidimensional time series with irregular timestamps and observational errors; sometimes complemented by contextual features</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>computationally intensive for large n because GPR involves inversion of n x n covariance matrices (O(n^3)); kernel choice and hyperparameter fitting add model selection complexity; non-linear temporal behavior possible.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>well-established statistical method with active application and research in astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>medium — uncertainty quantification is important for scientific decisions; interpretability of kernel selection helps map assumptions about process properties (stationarity, autoregression).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Gaussian Process Regression (GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Model each observed time series as a sample from a Gaussian process; select kernel forms reflecting stationarity or spectral properties; learn kernel hyperparameters from data and produce predictive distributions for missing timestamps, including uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>probabilistic regression / Bayesian non-parametrics</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>applicable but constrained — well suited for uncertainty-aware interpolation when series are moderate in size; scaling to very large and high-dimensional datasets is a major limitation without specialized approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Useful for filling gaps with uncertainty estimates; tends to regress to the mean for non-periodic kernels at long horizons and has scalability issues; certain optimized implementations and kernel choices improve performance for large data but are not universally adequate.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high — provides principled uncertainty-aware interpolation that aids downstream classification and follow-up decisions, but computational limits restrict applicability to very large surveys without approximation techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to recurrent neural networks (RNNs) and deep learning: RNNs can show better forecasting performance for some tasks, while GPR offers better principled uncertainties but worse scaling and long-horizon forecasts.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Proper kernel selection, problem-appropriate kernel simplifications or fast algorithmic implementations (e.g., structure-exploiting solvers), and tasks where uncertainty quantification is critical.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>GPR gives principled uncertainty-aware interpolation useful in time-domain astronomy, but computational scaling and regression-to-mean behavior limit its forecasting utility compared with some deep learning approaches.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2314.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Neural Networks (RNN) for Forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Neural Networks applied to astronomical time-series forecasting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sequence models (RNNs) used to forecast future points in astronomical time series, often outperforming GPR on short-term forecasting but primarily used for predicting next data points rather than extended horizon forecasts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>time-series forecasting in time-domain astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Forecast future measurements of variable sources to assist prioritization and observation planning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>many light curves available from synoptic surveys; individual series may have limited length or irregular sampling requiring preprocessing or feature engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>temporal sequence data (time series), sometimes multidimensional</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>non-linear dynamics in many sources, irregular sampling complicates sequence modeling, forecasting horizons vary; model complexity increases with desired horizon and multivariate inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging application — RNNs and other deep sequence models increasingly applied but not yet universally optimal for all forecasting tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>low to medium — black-box forecasts acceptable for operational scheduling, but interpretability is desirable for scientific insight</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Recurrent Neural Networks (RNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train RNN architectures on sequential observations to predict the next measurement or short sequence of future points; require handling irregular sampling (imputation or time-aware architectures) and can be combined with feature inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised sequence learning / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and often effective for short-term forecasting and sequence prediction; less certain for long-horizon forecasting where uncertainty quantification is crucial.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported to show better performance than GPR on some forecasting tasks (especially next-point prediction), but RNNs have been used more for next-point forecasting rather than extended interval prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate — improves short-term forecasts for scheduling and follow-up but may require more advanced architectures for complex non-linear long-term forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Qualitatively compared to GPR: RNNs may forecast better in some cases, while GPR provides principled uncertainties; no quantitative comparison presented here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of temporally dense training data for target classes, architectures that handle irregular sampling, and incorporation of contextual features when available.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>RNNs are practical for short-horizon forecasting in astronomical time series and can outperform GPR on next-point predictions, but they provide less principled uncertainty estimates and require careful handling of irregular sampling.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2314.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Photometric Redshift Estimation (photo-z)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning-based Photometric Redshift estimation (probabilistic and deep learning approaches)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of diverse ML methods (e.g., ANNs, quasi-Newton algorithms, ensemble methods, probabilistic models, deep learning image-based approaches) to estimate galaxy and quasar redshifts from multi-band photometry, often producing full probability density functions rather than single-point estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>cosmology / distance estimation for galaxies and quasars</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Estimate redshifts (distances) from multi-band photometry to enable large-scale cosmological analyses without expensive spectroscopic measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>very large photometric catalogs (millions of objects) available; labeled spectroscopic redshifts exist but are incomplete and may be biased or sparse in some regions of feature space.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>multiband photometric measurements (tabular), sometimes images for image-based deep learning; high-dimensional when including auxiliary features.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>non-linear mapping from photometry to redshift with degeneracies and domain shifts between spectroscopic training sets and photometric targets; high dimensionality and heterogeneous quality of labels.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>well-developed with extensive literature and many established methods; active area of refinement for probabilistic outputs and domain adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>medium — probabilistic outputs are important for downstream cosmological inference; interpretability of failure modes and biases is critical for scientific validity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Various ML methods (ANNs, quasi-Newton MLPQNA, probabilistic ensemble methods, deep learning image-based CNNs producing PDFs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised regression and probabilistic estimation methods trained on spectroscopic samples, with approaches that produce full redshift PDFs; some methods use image-based deep nets to bypass pre-classification and produce fully probabilistic, image-driven redshifts.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / probabilistic regression / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable — ML methods provide scalable, cost-saving redshift estimates for very large photometric surveys, though care is needed to handle training set biases and to output probabilistic estimates for scientific use.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Described as enabling significant advances and observational time savings; probabilistic photo-z’s are emphasized as an important conceptual advance over single-number estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — allows redshift estimation for orders of magnitude more objects than spectroscopy, enabling large cosmological and galaxy evolution studies; probabilistic outputs improve downstream inference.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to spectroscopic redshifts (ground truth) — ML/photo-z trades precision for scale and cost; various ML methods and ensemble/Bayesian combinations have been developed to improve reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large photometric data volumes, availability of spectroscopic training labels (even if incomplete), methodological focus on probabilistic outputs and hybrid approaches to mitigate biases.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>ML methods (including deep learning) make photometric redshift estimation scalable and practical for large surveys, with probabilistic outputs critical to retain scientific validity despite training-set limitations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2314.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gravitational Lens Discovery (ML)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning for detection of gravitational lenses from images and variability time series</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised ML applied to survey images and quasar variability time series to discover gravitational lens systems at scale, enabling the assembly of large, systematically selected samples for cosmological and dark matter studies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>observational cosmology / gravitational lens detection</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Identify multiply imaged quasars and galaxy-galaxy strong lens systems in large imaging surveys and via characteristic variability signatures.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>large imaging survey datasets; lens systems are rare so positive labels are scarce relative to negatives, making training challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>image data and time series (light curves) — multimodal; high-resolution imaging when available</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>detection of rare, subtle morphological signatures in images (low signal-to-noise, blending), class imbalance, need to disambiguate lensing from chance projections and artifacts</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging-to-mature — established interest and methods with growing, systematic samples enabled by ML</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>high for scientific exploitation — detection can be automated, but physical interpretation and lens modeling require interpretable follow-up and detailed modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Supervised image classifiers / ML on variability time series (convolutional and other classifiers implied)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train supervised classifiers on labeled examples (simulated and observed lenses) to detect morphological patterns or time-delay signatures in variability; can operate on single-epoch images or time series.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective for scanning large surveys to find candidates; ML is particularly useful to prioritize candidates for expensive follow-up and to create large homogeneous samples.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported as enabling discovery of large systematically selected samples of lenses; ML methods have been used successfully on imaging and variability data to find new candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — enables population studies of lenses to probe dark matter and the expansion rate, and scales discovery beyond what manual inspection can achieve.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to manual inspection and traditional selection cuts: ML provides scalability and sensitivity to subtle patterns, though follow-up confirmation is still required.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of simulations to augment rare positive examples, careful training to handle class imbalance, and integration into survey pipelines for candidate prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Supervised ML allows scalable discovery of rare lens systems from imaging and variability data, transforming sample construction needed for cosmological applications despite label scarcity.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2314.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid Physics-ML Surrogate Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid physics-ML surrogate modeling for accelerating numerical simulations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Combining classical physical simulation codes with ML surrogate models to replace computationally expensive steps, detect branching conditions, and adaptively refine resolution, thereby enabling larger-volume and higher-resolution simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>computational astrophysics / cosmological and hydrodynamical simulations</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Reduce computational cost of large-scale physical simulations by learning fast surrogate models for expensive subroutines and adaptively managing resolution while preserving essential physical fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>large volumes of simulated data (outputs from numerical simulations) are available to train surrogates; high-fidelity simulations may be expensive to produce but provide rich training data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>structured simulation data (gridded fields, particle catalogs, temporal sequences) possibly high-dimensional and spatially correlated</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>high — complex non-linear physics, high-dimensional state spaces, need to preserve conservation laws and critical branching behavior, sensitivity to small-scale features</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging — hybrid approaches are an active area with several recent examples demonstrating feasibility</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>high — scientific validity requires preserving mechanistic fidelity; physics-informed constraints or hybrid architectures are often necessary for trustworthiness.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Hybrid physics-ML surrogates / physics-informed ML / emulators</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train ML models as surrogate approximators for expensive computational kernels (e.g., subgrid physics), possibly embedding physical constraints or switching logic to detect branching and guide adaptive resolution; use ML to predict where to increase resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>hybrid / physics-informed machine learning / surrogate modeling</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and promising — surrogates can substantially reduce runtime and enable larger/higher-resolution simulations, but require careful validation and embedding of physical constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported that ML surrogates can replace time-consuming calculations with similar accuracy, and that adaptive detection of branching conditions preserves critical details; specific speedup numbers not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — enables exploration of larger parameter spaces, higher resolution simulations, and faster experiment cycles in computational astrophysics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to pure classical simulations: hybrid ML surrogates trade some interpretability for speed, but when validated provide similar accuracy with large computational savings.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of high-fidelity simulation outputs to train surrogates, appropriate incorporation of physics constraints, and reliable detection of regions requiring higher resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Embedding ML surrogates into simulation workflows can produce large computational savings while preserving scientific fidelity if physics constraints and adaptive mechanisms are properly integrated.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2314.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic Regression (AI Feynman, Memetic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic Regression methods (AI Feynman, Memetic Regression) for discovering analytic relationships</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Symbolic regression approaches that search for closed-form analytic expressions or relations in data, using physics-inspired heuristics (AI Feynman) and memetic (evolutionary + local search) algorithms to uncover potentially interpretable scientific relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AI Feynman: a Physics-Inspired Method for Symbolic Regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>machine-assisted discovery in astronomy and physics</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Discover compact analytic relationships present in observational or simulated data that can provide interpretable scientific laws or hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>application targets large observational and simulation-derived datasets; data-rich contexts are beneficial but noise and measurement errors complicate discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>tabular numerical data, possibly derived features from images or time series</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>search over combinatorial space of symbolic expressions; complexity grows with number of variables and expression depth; noise and overfitting are concerns</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging — symbolic regression is gaining traction as a tool for machine-assisted discovery but remains a specialized technique</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>high — goal is interpretable analytic expressions for mechanistic insight, so interpretability is central</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>AI Feynman (physics-inspired symbolic regression), Memetic Regression algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Algorithms combine heuristics from physics (e.g., dimensional analysis, functional decomposition) and evolutionary/local-search strategies to search the space of symbolic formulas, producing concise analytic forms consistent with data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>symbolic / program synthesis / evolutionary algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable when the underlying relationship is expressible in compact analytic form and data quality is sufficient; less applicable for highly stochastic or purely empirical mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Presented as promising for discovering interpretable relations; cited methods have produced analytic expressions in other contexts (references provided), but concrete astronomy examples are not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for interpretability and hypothesis generation — can produce human-understandable candidate laws that guide further investigation and modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternative is purely black-box ML which may fit but not provide interpretable formulas; symbolic methods trade broader function approximation power for interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Presence of underlying simple/formulable relationships, sufficient signal-to-noise, and incorporation of domain knowledge to constrain search.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Symbolic regression can translate data patterns into interpretable analytic relationships, offering a route from black-box fits to mechanistic hypotheses when the underlying physics admits compact expressions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2314.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Anomaly Detection (Deep / Active)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep-learning and Active Anomaly Detection approaches for live detection of unusual extragalactic transients (including ASTRONOMY personalized active anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods for detecting outliers or novel events in streaming survey data, combining deep learning for pattern recognition with active learning and personalized anomaly scoring to prioritize rare or novel transients for follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>time-domain astronomy / anomaly detection in survey streams</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Identify rare, unusual, or previously unknown classes of astronomical transients in high-rate survey streams to enable discovery and optimized allocation of follow-up observations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>very large streaming datasets from synoptic surveys; anomalous examples are by definition scarce and labels for novel classes are absent or limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>multidimensional time series and image-derived features in streaming form; high-dimensional and multimodal</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>very high — outlier definition ambiguous, class imbalance extreme, need for real-time detection with uncertainties and prioritization under limited follow-up resources</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging — active research with novel methods (deep anomaly detectors, active learning) being developed and deployed</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>high for scientific follow-up — detection alone is insufficient; interpretable characterization and uncertainty estimates are needed to design follow-up strategies and test new physics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep learning-based anomaly detectors, active learning frameworks (e.g., ASTRONOMY personalized active anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train deep models to model typical behavior and flag deviations (unsupervised or semi-supervised); incorporate active learning loops where human follow-up labels improve models and personalized scoring tailors anomalies to specific interests.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>unsupervised / semi-supervised learning with active learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and necessary for discovery in massive streams; methods must be integrated with follow-up optimization and uncertainty quantification to be operationally useful.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Methods are promising and have been implemented for live anomaly detection; paper emphasizes conceptual and operational challenges in defining anomalies and allocating follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — enables discovery of rare or novel astrophysical phenomena that manual inspection would miss, and helps optimize scarce follow-up resources.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to supervised classification which cannot discover unknown classes; anomaly detection provides a route to discover-of-new types whereas supervised methods cannot.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Streaming infrastructure, active learning to incorporate human feedback, robust uncertainty estimates, and integration into follow-up decision pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Unsupervised and active deep anomaly detection is essential for discovering novel phenomena in massive survey streams, but success depends on human-in-the-loop feedback and rigorous uncertainty handling.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2314.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GWSkyNet-Multi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised machine learning classifier designed to label LIGO-Virgo gravitational-wave alerts into multiple classes to support rapid prioritization and identification of likely electromagnetic counterparts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>multi-messenger astronomy / gravitational-wave alert classification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Classify gravitational-wave alerts (with poor localization and directionality) to prioritize electromagnetic counterpart searches across large sky areas.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>alerts are frequent but each alert has limited localization information; training data include simulated waveforms and past alerts, making labeled data somewhat limited and synthetic-augmented.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>sky maps (probabilistic spatial fields), associated metadata — structured but with high uncertainty and coarse angular resolution</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>high — poor localization leads to many candidate counterparts, multi-class classification under strong uncertainty and limited direct labels</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging — multi-messenger workflows are rapidly developing; automated classifiers are a recent innovation</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>medium — classifiers support operational decisions; physical interpretation of candidates requires full follow-up and modeling</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Supervised multi-class machine learning classifier (GWSkyNet-Multi)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train a classifier on features extracted from LIGO-Virgo public alerts (skymap properties and alert metadata) to assign probabilistic class labels to alerts for downstream prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and useful for rapid triage of alerts; helps focus limited EM follow-up on the most promising events.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Presented as an accepted/implemented tool (2022 reference) addressing real operational needs in multi-messenger follow-up; specific performance metrics not given in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate to high — streamlines EM counterpart search workflows and reduces wasted follow-up on low-priority alerts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to manual triage and ad-hoc heuristics; ML offers systematic multi-class scoring though precise comparative performance is not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Integration with real-time alert streams, feature engineering on skymap characteristics, and availability of simulated labeled data to train multi-class models.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Supervised multi-class ML classifiers provide practical, rapid triage for gravitational-wave alerts where localization uncertainties make naive follow-up infeasible.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2314.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2314.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feature Selection / High-Dim Classification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feature Selection Strategies and Use of XGBoost/DNNs for High-Dimensional Astronomical Data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods and strategies for selecting relevant features in very high-dimensional astronomical datasets (tens to hundreds of features) and using models such as XGBoost or deep nets to identify top discriminative features for classification tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>survey data classification / high-dimensional data analysis</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Mitigate the curse of dimensionality and noisy or irrelevant features in classification tasks across large survey-derived feature spaces to improve classifier performance and scalability.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>large catalogs with tens to hundreds of pre-extracted features per source; external features from crossmatches may introduce missingness.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>structured tabular high-dimensional features (tens to hundreds), possibly sparse or partially missing</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>high dimensionality leading to poor scaling of classifiers, presence of correlated and non-informative features, multiclass discrimination where features matter differently per class</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>well-recognized problem with many practical strategies and active research on scalable feature selection</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>medium — understanding which features drive classification aids scientific interpretation and robustness</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Feature selection strategies; feature importance extraction via XGBoost and Deep Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Employ feature selection algorithms and inspect model-derived feature importances (from XGBoost or DNNs) to reduce dimensionality and remove noisy/non-informative features; apply dimensionality reduction before or within supervised learning.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning with feature engineering and dimensionality reduction</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>High — essential preprocessing step to improve classifier performance and scalability on survey-derived high-dimensional feature sets.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Emphasized as a critical need; methods like XGBoost and DNNs are useful both as classifiers and as tools to identify top features; dimensionality reduction improves scalability and performance.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — better feature selection reduces noise, improves classifier accuracy, and reduces computation on massive catalogs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper suggests a range of approaches (feature selection algorithms, model-based importance) and highlights that not all features are independent; no single best algorithm specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of domain-informed candidate features, use of model-based importance measures, and handling of missing external features.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Feature selection is critical for high-dimensional survey classification — model-based importance (XGBoost/DNN) plus dimensionality reduction yields practical improvements in scalability and robustness.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Machine Learning for the Zwicky Transient Facility <em>(Rating: 2)</em></li>
                <li>Fast and scalable Gaussian process modeling with applications to astronomical time series <em>(Rating: 2)</em></li>
                <li>A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients <em>(Rating: 2)</em></li>
                <li>GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts <em>(Rating: 2)</em></li>
                <li>AI Feynman: a Physics-Inspired Method for Symbolic Regression <em>(Rating: 2)</em></li>
                <li>Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets <em>(Rating: 2)</em></li>
                <li>Gaussian Processes for Machine Learning <em>(Rating: 1)</em></li>
                <li>Photometric redshift estimation via deep learning. Generalized and pre-classification-less, image based, fully probabilistic redshifts <em>(Rating: 2)</em></li>
                <li>Machine learning and cosmological simulations -II. Hydrodynamical simulations <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2314",
    "paper_id": "paper-254246404",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Star-Galaxy Separation (ANN/DT)",
            "name_full": "Star-Galaxy Separation using Artificial Neural Networks and Decision Trees",
            "brief_description": "Supervised morphological classification of unresolved (stars) vs resolved (galaxies) sources in digital sky surveys using feature vectors derived from image segmentation, employing Artificial Neural Networks and Decision Trees to automate large-scale catalog classification.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "astronomical source classification / sky surveys",
            "problem_description": "Separate point-like (stellar) sources from extended (galactic) sources in large imaging surveys to build clean catalogs for downstream science and remove instrumental artifacts.",
            "data_availability": "abundant — millions to billions of detected sources from digital sky surveys; labeled examples exist from prior human/algorithmic classifications though labels may be incomplete for rare classes.",
            "data_structure": "structured tabular feature vectors (tens to hundreds of morphological and structural parameters) derived from images; high-dimensional",
            "problem_complexity": "high dimensionality (tens to hundreds of features), large sample sizes (millions to billions), mostly morphological non-linear decision boundaries but relatively low intrinsic class complexity for the star vs galaxy task",
            "domain_maturity": "well-established — early and standard task in survey pipelines with substantial prior work and domain expertise",
            "mechanistic_understanding_requirements": "low to medium — primary goal is accurate classification for downstream use; interpretability useful for diagnosing artifacts but black-box models acceptable in many pipelines",
            "ai_methodology_name": "Artificial Neural Networks (ANN), Decision Trees (DT)",
            "ai_methodology_description": "Supervised classifiers trained on labeled catalogs using morphological/structural features computed per detected source; decision trees provide rule-based splits, ANNs learn non-linear feature combinations to separate classes.",
            "ai_methodology_category": "supervised learning",
            "applicability": "high — methods are appropriate and were adopted early to automate repetitive classification tasks and artifact rejection; suited to large labeled data sets",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Described as effective for star-galaxy separation and artifact removal at survey scale; these methods enabled catalog-scale automation and replacement of manual classification.",
            "impact_potential": "High — enabled conversion of terascale/petascale image data into usable catalogs, allowed prioritization of follow-up resources, and made large statistical studies feasible.",
            "comparison_to_alternatives": "Paper notes supervised classifiers performed effectively compared to manual classification; no detailed quantitative comparisons provided here.",
            "success_factors": "Abundant labeled data, well-engineered morphological features from image segmentation, and the relatively well-posed two-class morphology problem.",
            "key_insight": "For large, well-labeled morphological classification tasks in surveys, classical supervised models (ANNs, DTs) are highly applicable because of abundant data and relatively low class complexity.",
            "uuid": "e2314.0"
        },
        {
            "name_short": "Time-Domain Transient Classification (ZTF)",
            "name_full": "Real-time Transient Classification in Time-Domain Astronomy using DNNs, XGBoost and Binary Classifiers (ZTF example)",
            "brief_description": "Machine learning pipelines (including deep neural networks, gradient-boosted trees like XGBoost, and binary classifiers) used to classify variable and transient events in real-time streams from synoptic surveys such as ZTF to prioritize follow-up observations.",
            "citation_title": "Machine Learning for the Zwicky Transient Facility",
            "mention_or_use": "use",
            "scientific_problem_domain": "time-domain astronomy / transient event classification",
            "problem_description": "Fast, often real-time classification of transient and variable astronomical events from repeated sky imaging, dealing with heterogeneously sampled time series and the need to prioritize scarce follow-up resources.",
            "data_availability": "very large streaming datasets (petascale/data streams) from synoptic surveys; labeled examples exist for many classes but class imbalance is common and missing features arise when crossmatching external catalogs.",
            "data_structure": "multidimensional time series, supplemented by tabular features and cross-matched catalog data (multimodal and often incomplete); high-dimensional feature spaces (tens to hundreds)",
            "problem_complexity": "high — high dimensionality, heterogenous and incomplete features, class imbalance, need for real-time processing and multi-class disambiguation under time constraints",
            "domain_maturity": "emerging-to-mature — active area of research with growing literature; domain expertise available but many open challenges remain (real-time decision making, anomaly detection)",
            "mechanistic_understanding_requirements": "medium — accurate prioritization is primary, but interpretability and uncertainty estimates are valuable for resource allocation and for scientific validation",
            "ai_methodology_name": "Deep Neural Networks (DNN), XGBoost, Binary Classifiers (ensemble approaches)",
            "ai_methodology_description": "Supervised learning pipelines train DNNs and gradient-boosted trees on feature vectors derived from light curves and contextual information; feature selection and dimensionality reduction are used to mitigate high dimensionality; active learning and model cards/data sheets are recommended for standardization.",
            "ai_methodology_category": "supervised learning (with feature engineering and active learning elements)",
            "applicability": "high — methods are well suited to classification and prioritization in streaming time-domain data, though care is needed for missing features, class imbalance, and computational scaling.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as effective and widely used (ZTF example); DNNs and XGBoost help identify important features and support real-time classifications, but challenges include handling missing features and optimizing for many classes.",
            "impact_potential": "High — enables real-time prioritization of follow-up, optimizes scarce observational resources, and scales transient discovery to petascale survey data.",
            "comparison_to_alternatives": "Paper notes GPR and RNNs as alternative approaches for time series interpolation/forecasting; DNNs and XGBoost are practical for classification and feature importance; no quantitative head-to-head metrics provided here.",
            "success_factors": "Large streaming datasets enabling supervised training, careful feature engineering, use of ensemble methods and feature selection, and integration into real-time pipelines.",
            "key_insight": "For high-rate, high-dimensional transient streams, supervised DNNs and gradient-boosted trees provide practical, effective classification and prioritization when combined with feature selection and workflows that handle missing data.",
            "uuid": "e2314.1"
        },
        {
            "name_short": "Gaussian Process Regression (GPR)",
            "name_full": "Gaussian Process Regression for astronomical time series interpolation and uncertainty-aware prediction",
            "brief_description": "Probabilistic non-parametric regression that models time series as draws from a multivariate Gaussian characterized by a covariance (kernel) and mean, used to interpolate irregularly sampled astronomical time series and provide predictive uncertainties.",
            "citation_title": "Gaussian Processes for Machine Learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "time-series modeling / interpolation in time-domain astronomy",
            "problem_description": "Interpolate and predict values in irregular, multidimensional time series (e.g., light curves) and quantify uncertainties to support classification and follow-up decisions.",
            "data_availability": "typical datasets include many individual time series with sparse/irregular sampling; can scale to thousands of samples but per-series data points may be limited or unevenly distributed.",
            "data_structure": "multidimensional time series with irregular timestamps and observational errors; sometimes complemented by contextual features",
            "problem_complexity": "computationally intensive for large n because GPR involves inversion of n x n covariance matrices (O(n^3)); kernel choice and hyperparameter fitting add model selection complexity; non-linear temporal behavior possible.",
            "domain_maturity": "well-established statistical method with active application and research in astronomy",
            "mechanistic_understanding_requirements": "medium — uncertainty quantification is important for scientific decisions; interpretability of kernel selection helps map assumptions about process properties (stationarity, autoregression).",
            "ai_methodology_name": "Gaussian Process Regression (GPR)",
            "ai_methodology_description": "Model each observed time series as a sample from a Gaussian process; select kernel forms reflecting stationarity or spectral properties; learn kernel hyperparameters from data and produce predictive distributions for missing timestamps, including uncertainties.",
            "ai_methodology_category": "probabilistic regression / Bayesian non-parametrics",
            "applicability": "applicable but constrained — well suited for uncertainty-aware interpolation when series are moderate in size; scaling to very large and high-dimensional datasets is a major limitation without specialized approximations.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Useful for filling gaps with uncertainty estimates; tends to regress to the mean for non-periodic kernels at long horizons and has scalability issues; certain optimized implementations and kernel choices improve performance for large data but are not universally adequate.",
            "impact_potential": "Moderate to high — provides principled uncertainty-aware interpolation that aids downstream classification and follow-up decisions, but computational limits restrict applicability to very large surveys without approximation techniques.",
            "comparison_to_alternatives": "Compared qualitatively to recurrent neural networks (RNNs) and deep learning: RNNs can show better forecasting performance for some tasks, while GPR offers better principled uncertainties but worse scaling and long-horizon forecasts.",
            "success_factors": "Proper kernel selection, problem-appropriate kernel simplifications or fast algorithmic implementations (e.g., structure-exploiting solvers), and tasks where uncertainty quantification is critical.",
            "key_insight": "GPR gives principled uncertainty-aware interpolation useful in time-domain astronomy, but computational scaling and regression-to-mean behavior limit its forecasting utility compared with some deep learning approaches.",
            "uuid": "e2314.2"
        },
        {
            "name_short": "Recurrent Neural Networks (RNN) for Forecasting",
            "name_full": "Recurrent Neural Networks applied to astronomical time-series forecasting",
            "brief_description": "Sequence models (RNNs) used to forecast future points in astronomical time series, often outperforming GPR on short-term forecasting but primarily used for predicting next data points rather than extended horizon forecasts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "time-series forecasting in time-domain astronomy",
            "problem_description": "Forecast future measurements of variable sources to assist prioritization and observation planning.",
            "data_availability": "many light curves available from synoptic surveys; individual series may have limited length or irregular sampling requiring preprocessing or feature engineering.",
            "data_structure": "temporal sequence data (time series), sometimes multidimensional",
            "problem_complexity": "non-linear dynamics in many sources, irregular sampling complicates sequence modeling, forecasting horizons vary; model complexity increases with desired horizon and multivariate inputs.",
            "domain_maturity": "emerging application — RNNs and other deep sequence models increasingly applied but not yet universally optimal for all forecasting tasks",
            "mechanistic_understanding_requirements": "low to medium — black-box forecasts acceptable for operational scheduling, but interpretability is desirable for scientific insight",
            "ai_methodology_name": "Recurrent Neural Networks (RNNs)",
            "ai_methodology_description": "Train RNN architectures on sequential observations to predict the next measurement or short sequence of future points; require handling irregular sampling (imputation or time-aware architectures) and can be combined with feature inputs.",
            "ai_methodology_category": "supervised sequence learning / deep learning",
            "applicability": "Applicable and often effective for short-term forecasting and sequence prediction; less certain for long-horizon forecasting where uncertainty quantification is crucial.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported to show better performance than GPR on some forecasting tasks (especially next-point prediction), but RNNs have been used more for next-point forecasting rather than extended interval prediction.",
            "impact_potential": "Moderate — improves short-term forecasts for scheduling and follow-up but may require more advanced architectures for complex non-linear long-term forecasting.",
            "comparison_to_alternatives": "Qualitatively compared to GPR: RNNs may forecast better in some cases, while GPR provides principled uncertainties; no quantitative comparison presented here.",
            "success_factors": "Availability of temporally dense training data for target classes, architectures that handle irregular sampling, and incorporation of contextual features when available.",
            "key_insight": "RNNs are practical for short-horizon forecasting in astronomical time series and can outperform GPR on next-point predictions, but they provide less principled uncertainty estimates and require careful handling of irregular sampling.",
            "uuid": "e2314.3"
        },
        {
            "name_short": "Photometric Redshift Estimation (photo-z)",
            "name_full": "Machine learning-based Photometric Redshift estimation (probabilistic and deep learning approaches)",
            "brief_description": "Use of diverse ML methods (e.g., ANNs, quasi-Newton algorithms, ensemble methods, probabilistic models, deep learning image-based approaches) to estimate galaxy and quasar redshifts from multi-band photometry, often producing full probability density functions rather than single-point estimates.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "cosmology / distance estimation for galaxies and quasars",
            "problem_description": "Estimate redshifts (distances) from multi-band photometry to enable large-scale cosmological analyses without expensive spectroscopic measurements.",
            "data_availability": "very large photometric catalogs (millions of objects) available; labeled spectroscopic redshifts exist but are incomplete and may be biased or sparse in some regions of feature space.",
            "data_structure": "multiband photometric measurements (tabular), sometimes images for image-based deep learning; high-dimensional when including auxiliary features.",
            "problem_complexity": "non-linear mapping from photometry to redshift with degeneracies and domain shifts between spectroscopic training sets and photometric targets; high dimensionality and heterogeneous quality of labels.",
            "domain_maturity": "well-developed with extensive literature and many established methods; active area of refinement for probabilistic outputs and domain adaptation.",
            "mechanistic_understanding_requirements": "medium — probabilistic outputs are important for downstream cosmological inference; interpretability of failure modes and biases is critical for scientific validity.",
            "ai_methodology_name": "Various ML methods (ANNs, quasi-Newton MLPQNA, probabilistic ensemble methods, deep learning image-based CNNs producing PDFs)",
            "ai_methodology_description": "Supervised regression and probabilistic estimation methods trained on spectroscopic samples, with approaches that produce full redshift PDFs; some methods use image-based deep nets to bypass pre-classification and produce fully probabilistic, image-driven redshifts.",
            "ai_methodology_category": "supervised learning / probabilistic regression / deep learning",
            "applicability": "Highly applicable — ML methods provide scalable, cost-saving redshift estimates for very large photometric surveys, though care is needed to handle training set biases and to output probabilistic estimates for scientific use.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Described as enabling significant advances and observational time savings; probabilistic photo-z’s are emphasized as an important conceptual advance over single-number estimates.",
            "impact_potential": "High — allows redshift estimation for orders of magnitude more objects than spectroscopy, enabling large cosmological and galaxy evolution studies; probabilistic outputs improve downstream inference.",
            "comparison_to_alternatives": "Compared conceptually to spectroscopic redshifts (ground truth) — ML/photo-z trades precision for scale and cost; various ML methods and ensemble/Bayesian combinations have been developed to improve reliability.",
            "success_factors": "Large photometric data volumes, availability of spectroscopic training labels (even if incomplete), methodological focus on probabilistic outputs and hybrid approaches to mitigate biases.",
            "key_insight": "ML methods (including deep learning) make photometric redshift estimation scalable and practical for large surveys, with probabilistic outputs critical to retain scientific validity despite training-set limitations.",
            "uuid": "e2314.4"
        },
        {
            "name_short": "Gravitational Lens Discovery (ML)",
            "name_full": "Machine learning for detection of gravitational lenses from images and variability time series",
            "brief_description": "Supervised ML applied to survey images and quasar variability time series to discover gravitational lens systems at scale, enabling the assembly of large, systematically selected samples for cosmological and dark matter studies.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "observational cosmology / gravitational lens detection",
            "problem_description": "Identify multiply imaged quasars and galaxy-galaxy strong lens systems in large imaging surveys and via characteristic variability signatures.",
            "data_availability": "large imaging survey datasets; lens systems are rare so positive labels are scarce relative to negatives, making training challenging.",
            "data_structure": "image data and time series (light curves) — multimodal; high-resolution imaging when available",
            "problem_complexity": "detection of rare, subtle morphological signatures in images (low signal-to-noise, blending), class imbalance, need to disambiguate lensing from chance projections and artifacts",
            "domain_maturity": "emerging-to-mature — established interest and methods with growing, systematic samples enabled by ML",
            "mechanistic_understanding_requirements": "high for scientific exploitation — detection can be automated, but physical interpretation and lens modeling require interpretable follow-up and detailed modeling.",
            "ai_methodology_name": "Supervised image classifiers / ML on variability time series (convolutional and other classifiers implied)",
            "ai_methodology_description": "Train supervised classifiers on labeled examples (simulated and observed lenses) to detect morphological patterns or time-delay signatures in variability; can operate on single-epoch images or time series.",
            "ai_methodology_category": "supervised learning",
            "applicability": "Applicable and effective for scanning large surveys to find candidates; ML is particularly useful to prioritize candidates for expensive follow-up and to create large homogeneous samples.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported as enabling discovery of large systematically selected samples of lenses; ML methods have been used successfully on imaging and variability data to find new candidates.",
            "impact_potential": "High — enables population studies of lenses to probe dark matter and the expansion rate, and scales discovery beyond what manual inspection can achieve.",
            "comparison_to_alternatives": "Compared implicitly to manual inspection and traditional selection cuts: ML provides scalability and sensitivity to subtle patterns, though follow-up confirmation is still required.",
            "success_factors": "Use of simulations to augment rare positive examples, careful training to handle class imbalance, and integration into survey pipelines for candidate prioritization.",
            "key_insight": "Supervised ML allows scalable discovery of rare lens systems from imaging and variability data, transforming sample construction needed for cosmological applications despite label scarcity.",
            "uuid": "e2314.5"
        },
        {
            "name_short": "Hybrid Physics-ML Surrogate Models",
            "name_full": "Hybrid physics-ML surrogate modeling for accelerating numerical simulations",
            "brief_description": "Combining classical physical simulation codes with ML surrogate models to replace computationally expensive steps, detect branching conditions, and adaptively refine resolution, thereby enabling larger-volume and higher-resolution simulations.",
            "citation_title": "",
            "mention_or_use": "use",
            "scientific_problem_domain": "computational astrophysics / cosmological and hydrodynamical simulations",
            "problem_description": "Reduce computational cost of large-scale physical simulations by learning fast surrogate models for expensive subroutines and adaptively managing resolution while preserving essential physical fidelity.",
            "data_availability": "large volumes of simulated data (outputs from numerical simulations) are available to train surrogates; high-fidelity simulations may be expensive to produce but provide rich training data.",
            "data_structure": "structured simulation data (gridded fields, particle catalogs, temporal sequences) possibly high-dimensional and spatially correlated",
            "problem_complexity": "high — complex non-linear physics, high-dimensional state spaces, need to preserve conservation laws and critical branching behavior, sensitivity to small-scale features",
            "domain_maturity": "emerging — hybrid approaches are an active area with several recent examples demonstrating feasibility",
            "mechanistic_understanding_requirements": "high — scientific validity requires preserving mechanistic fidelity; physics-informed constraints or hybrid architectures are often necessary for trustworthiness.",
            "ai_methodology_name": "Hybrid physics-ML surrogates / physics-informed ML / emulators",
            "ai_methodology_description": "Train ML models as surrogate approximators for expensive computational kernels (e.g., subgrid physics), possibly embedding physical constraints or switching logic to detect branching and guide adaptive resolution; use ML to predict where to increase resolution.",
            "ai_methodology_category": "hybrid / physics-informed machine learning / surrogate modeling",
            "applicability": "Applicable and promising — surrogates can substantially reduce runtime and enable larger/higher-resolution simulations, but require careful validation and embedding of physical constraints.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported that ML surrogates can replace time-consuming calculations with similar accuracy, and that adaptive detection of branching conditions preserves critical details; specific speedup numbers not provided here.",
            "impact_potential": "High — enables exploration of larger parameter spaces, higher resolution simulations, and faster experiment cycles in computational astrophysics.",
            "comparison_to_alternatives": "Compared implicitly to pure classical simulations: hybrid ML surrogates trade some interpretability for speed, but when validated provide similar accuracy with large computational savings.",
            "success_factors": "Availability of high-fidelity simulation outputs to train surrogates, appropriate incorporation of physics constraints, and reliable detection of regions requiring higher resolution.",
            "key_insight": "Embedding ML surrogates into simulation workflows can produce large computational savings while preserving scientific fidelity if physics constraints and adaptive mechanisms are properly integrated.",
            "uuid": "e2314.6"
        },
        {
            "name_short": "Symbolic Regression (AI Feynman, Memetic)",
            "name_full": "Symbolic Regression methods (AI Feynman, Memetic Regression) for discovering analytic relationships",
            "brief_description": "Symbolic regression approaches that search for closed-form analytic expressions or relations in data, using physics-inspired heuristics (AI Feynman) and memetic (evolutionary + local search) algorithms to uncover potentially interpretable scientific relationships.",
            "citation_title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "mention_or_use": "mention",
            "scientific_problem_domain": "machine-assisted discovery in astronomy and physics",
            "problem_description": "Discover compact analytic relationships present in observational or simulated data that can provide interpretable scientific laws or hypotheses.",
            "data_availability": "application targets large observational and simulation-derived datasets; data-rich contexts are beneficial but noise and measurement errors complicate discovery.",
            "data_structure": "tabular numerical data, possibly derived features from images or time series",
            "problem_complexity": "search over combinatorial space of symbolic expressions; complexity grows with number of variables and expression depth; noise and overfitting are concerns",
            "domain_maturity": "emerging — symbolic regression is gaining traction as a tool for machine-assisted discovery but remains a specialized technique",
            "mechanistic_understanding_requirements": "high — goal is interpretable analytic expressions for mechanistic insight, so interpretability is central",
            "ai_methodology_name": "AI Feynman (physics-inspired symbolic regression), Memetic Regression algorithms",
            "ai_methodology_description": "Algorithms combine heuristics from physics (e.g., dimensional analysis, functional decomposition) and evolutionary/local-search strategies to search the space of symbolic formulas, producing concise analytic forms consistent with data.",
            "ai_methodology_category": "symbolic / program synthesis / evolutionary algorithms",
            "applicability": "Applicable when the underlying relationship is expressible in compact analytic form and data quality is sufficient; less applicable for highly stochastic or purely empirical mappings.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Presented as promising for discovering interpretable relations; cited methods have produced analytic expressions in other contexts (references provided), but concrete astronomy examples are not detailed here.",
            "impact_potential": "High for interpretability and hypothesis generation — can produce human-understandable candidate laws that guide further investigation and modeling.",
            "comparison_to_alternatives": "Alternative is purely black-box ML which may fit but not provide interpretable formulas; symbolic methods trade broader function approximation power for interpretability.",
            "success_factors": "Presence of underlying simple/formulable relationships, sufficient signal-to-noise, and incorporation of domain knowledge to constrain search.",
            "key_insight": "Symbolic regression can translate data patterns into interpretable analytic relationships, offering a route from black-box fits to mechanistic hypotheses when the underlying physics admits compact expressions.",
            "uuid": "e2314.7"
        },
        {
            "name_short": "Anomaly Detection (Deep / Active)",
            "name_full": "Deep-learning and Active Anomaly Detection approaches for live detection of unusual extragalactic transients (including ASTRONOMY personalized active anomaly detection)",
            "brief_description": "Methods for detecting outliers or novel events in streaming survey data, combining deep learning for pattern recognition with active learning and personalized anomaly scoring to prioritize rare or novel transients for follow-up.",
            "citation_title": "A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients",
            "mention_or_use": "use",
            "scientific_problem_domain": "time-domain astronomy / anomaly detection in survey streams",
            "problem_description": "Identify rare, unusual, or previously unknown classes of astronomical transients in high-rate survey streams to enable discovery and optimized allocation of follow-up observations.",
            "data_availability": "very large streaming datasets from synoptic surveys; anomalous examples are by definition scarce and labels for novel classes are absent or limited.",
            "data_structure": "multidimensional time series and image-derived features in streaming form; high-dimensional and multimodal",
            "problem_complexity": "very high — outlier definition ambiguous, class imbalance extreme, need for real-time detection with uncertainties and prioritization under limited follow-up resources",
            "domain_maturity": "emerging — active research with novel methods (deep anomaly detectors, active learning) being developed and deployed",
            "mechanistic_understanding_requirements": "high for scientific follow-up — detection alone is insufficient; interpretable characterization and uncertainty estimates are needed to design follow-up strategies and test new physics.",
            "ai_methodology_name": "Deep learning-based anomaly detectors, active learning frameworks (e.g., ASTRONOMY personalized active anomaly detection)",
            "ai_methodology_description": "Train deep models to model typical behavior and flag deviations (unsupervised or semi-supervised); incorporate active learning loops where human follow-up labels improve models and personalized scoring tailors anomalies to specific interests.",
            "ai_methodology_category": "unsupervised / semi-supervised learning with active learning",
            "applicability": "Applicable and necessary for discovery in massive streams; methods must be integrated with follow-up optimization and uncertainty quantification to be operationally useful.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Methods are promising and have been implemented for live anomaly detection; paper emphasizes conceptual and operational challenges in defining anomalies and allocating follow-up.",
            "impact_potential": "High — enables discovery of rare or novel astrophysical phenomena that manual inspection would miss, and helps optimize scarce follow-up resources.",
            "comparison_to_alternatives": "Compared conceptually to supervised classification which cannot discover unknown classes; anomaly detection provides a route to discover-of-new types whereas supervised methods cannot.",
            "success_factors": "Streaming infrastructure, active learning to incorporate human feedback, robust uncertainty estimates, and integration into follow-up decision pipelines.",
            "key_insight": "Unsupervised and active deep anomaly detection is essential for discovering novel phenomena in massive survey streams, but success depends on human-in-the-loop feedback and rigorous uncertainty handling.",
            "uuid": "e2314.8"
        },
        {
            "name_short": "GWSkyNet-Multi",
            "name_full": "GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts",
            "brief_description": "A supervised machine learning classifier designed to label LIGO-Virgo gravitational-wave alerts into multiple classes to support rapid prioritization and identification of likely electromagnetic counterparts.",
            "citation_title": "GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts",
            "mention_or_use": "mention",
            "scientific_problem_domain": "multi-messenger astronomy / gravitational-wave alert classification",
            "problem_description": "Classify gravitational-wave alerts (with poor localization and directionality) to prioritize electromagnetic counterpart searches across large sky areas.",
            "data_availability": "alerts are frequent but each alert has limited localization information; training data include simulated waveforms and past alerts, making labeled data somewhat limited and synthetic-augmented.",
            "data_structure": "sky maps (probabilistic spatial fields), associated metadata — structured but with high uncertainty and coarse angular resolution",
            "problem_complexity": "high — poor localization leads to many candidate counterparts, multi-class classification under strong uncertainty and limited direct labels",
            "domain_maturity": "emerging — multi-messenger workflows are rapidly developing; automated classifiers are a recent innovation",
            "mechanistic_understanding_requirements": "medium — classifiers support operational decisions; physical interpretation of candidates requires full follow-up and modeling",
            "ai_methodology_name": "Supervised multi-class machine learning classifier (GWSkyNet-Multi)",
            "ai_methodology_description": "Train a classifier on features extracted from LIGO-Virgo public alerts (skymap properties and alert metadata) to assign probabilistic class labels to alerts for downstream prioritization.",
            "ai_methodology_category": "supervised learning",
            "applicability": "Applicable and useful for rapid triage of alerts; helps focus limited EM follow-up on the most promising events.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Presented as an accepted/implemented tool (2022 reference) addressing real operational needs in multi-messenger follow-up; specific performance metrics not given in this review.",
            "impact_potential": "Moderate to high — streamlines EM counterpart search workflows and reduces wasted follow-up on low-priority alerts.",
            "comparison_to_alternatives": "Compared implicitly to manual triage and ad-hoc heuristics; ML offers systematic multi-class scoring though precise comparative performance is not detailed here.",
            "success_factors": "Integration with real-time alert streams, feature engineering on skymap characteristics, and availability of simulated labeled data to train multi-class models.",
            "key_insight": "Supervised multi-class ML classifiers provide practical, rapid triage for gravitational-wave alerts where localization uncertainties make naive follow-up infeasible.",
            "uuid": "e2314.9"
        },
        {
            "name_short": "Feature Selection / High-Dim Classification",
            "name_full": "Feature Selection Strategies and Use of XGBoost/DNNs for High-Dimensional Astronomical Data",
            "brief_description": "Methods and strategies for selecting relevant features in very high-dimensional astronomical datasets (tens to hundreds of features) and using models such as XGBoost or deep nets to identify top discriminative features for classification tasks.",
            "citation_title": "Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets",
            "mention_or_use": "use",
            "scientific_problem_domain": "survey data classification / high-dimensional data analysis",
            "problem_description": "Mitigate the curse of dimensionality and noisy or irrelevant features in classification tasks across large survey-derived feature spaces to improve classifier performance and scalability.",
            "data_availability": "large catalogs with tens to hundreds of pre-extracted features per source; external features from crossmatches may introduce missingness.",
            "data_structure": "structured tabular high-dimensional features (tens to hundreds), possibly sparse or partially missing",
            "problem_complexity": "high dimensionality leading to poor scaling of classifiers, presence of correlated and non-informative features, multiclass discrimination where features matter differently per class",
            "domain_maturity": "well-recognized problem with many practical strategies and active research on scalable feature selection",
            "mechanistic_understanding_requirements": "medium — understanding which features drive classification aids scientific interpretation and robustness",
            "ai_methodology_name": "Feature selection strategies; feature importance extraction via XGBoost and Deep Neural Networks",
            "ai_methodology_description": "Employ feature selection algorithms and inspect model-derived feature importances (from XGBoost or DNNs) to reduce dimensionality and remove noisy/non-informative features; apply dimensionality reduction before or within supervised learning.",
            "ai_methodology_category": "supervised learning with feature engineering and dimensionality reduction",
            "applicability": "High — essential preprocessing step to improve classifier performance and scalability on survey-derived high-dimensional feature sets.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Emphasized as a critical need; methods like XGBoost and DNNs are useful both as classifiers and as tools to identify top features; dimensionality reduction improves scalability and performance.",
            "impact_potential": "High — better feature selection reduces noise, improves classifier accuracy, and reduces computation on massive catalogs.",
            "comparison_to_alternatives": "Paper suggests a range of approaches (feature selection algorithms, model-based importance) and highlights that not all features are independent; no single best algorithm specified here.",
            "success_factors": "Availability of domain-informed candidate features, use of model-based importance measures, and handling of missing external features.",
            "key_insight": "Feature selection is critical for high-dimensional survey classification — model-based importance (XGBoost/DNN) plus dimensionality reduction yields practical improvements in scalability and robustness.",
            "uuid": "e2314.10"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Machine Learning for the Zwicky Transient Facility",
            "rating": 2,
            "sanitized_title": "machine_learning_for_the_zwicky_transient_facility"
        },
        {
            "paper_title": "Fast and scalable Gaussian process modeling with applications to astronomical time series",
            "rating": 2,
            "sanitized_title": "fast_and_scalable_gaussian_process_modeling_with_applications_to_astronomical_time_series"
        },
        {
            "paper_title": "A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients",
            "rating": 2,
            "sanitized_title": "a_deeplearning_approach_for_live_anomaly_detection_of_extragalactic_transients"
        },
        {
            "paper_title": "GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts",
            "rating": 2,
            "sanitized_title": "gwskynetmulti_a_machine_learning_multiclass_classifier_for_ligovirgo_public_alerts"
        },
        {
            "paper_title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "rating": 2,
            "sanitized_title": "ai_feynman_a_physicsinspired_method_for_symbolic_regression"
        },
        {
            "paper_title": "Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets",
            "rating": 2,
            "sanitized_title": "feature_selection_strategies_for_classifying_high_dimensional_astronomical_data_sets"
        },
        {
            "paper_title": "Gaussian Processes for Machine Learning",
            "rating": 1,
            "sanitized_title": "gaussian_processes_for_machine_learning"
        },
        {
            "paper_title": "Photometric redshift estimation via deep learning. Generalized and pre-classification-less, image based, fully probabilistic redshifts",
            "rating": 2,
            "sanitized_title": "photometric_redshift_estimation_via_deep_learning_generalized_and_preclassificationless_image_based_fully_probabilistic_redshifts"
        },
        {
            "paper_title": "Machine learning and cosmological simulations -II. Hydrodynamical simulations",
            "rating": 2,
            "sanitized_title": "machine_learning_and_cosmological_simulations_ii_hydrodynamical_simulations"
        }
    ],
    "cost": 0.02150475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Applications of AI in Astronomy</p>
<p>S G Djorgovski 
California Institute of Technology
91125PasadenaCAUSA</p>
<p>A A Mahabal 
California Institute of Technology
91125PasadenaCAUSA</p>
<p>M J Graham 
California Institute of Technology
91125PasadenaCAUSA</p>
<p>K Polsterer 
Heidelberg Institute for Theoretical Studies
69118HeidelbergGermany</p>
<p>A Krone-Martins 
University of California
92697IrvineCAUSA</p>
<p>Applications of AI in Astronomy
1
We provide a brief, and inevitably incomplete overview of the use of Machine Learning (ML) and other AI methods in astronomy, astrophysics, and cosmology. Astronomy entered the big data era with the first digital sky surveys in the early 1990s and the resulting Terascale data sets, which required automating of many data processing and analysis tasks, for example the star-galaxy separation, with billions of feature vectors in hundreds of dimensions. The exponential data growth continued, with the rise of synoptic sky surveys and the Time Domain Astronomy, with the resulting Petascale data streams and the need for a real-time processing, classification, and decision making. A broad variety of classification and clustering methods have been applied for these tasks, and this remains a very active area of research. Over the past decade we have seen an exponential growth of the astronomical literature involving a variety of ML/AI applications of an ever increasing complexity and sophistication. ML and AI are now a standard part of the astronomical toolkit. As the data complexity continues to increase, we anticipate further advances leading towards a collaborative human-AI discovery.</p>
<p>astronomical cyberinfrastructure and data analytics tools have been developed by the individual research groups, captured under the Astroinformatics umbrella. Today, applications of Machine Learning (ML) and other AI methods are becoming commonplace and growing rapidly. During the 2021, according to the Astrophysics Data System (ADS; https://ui.adsabs.harvard.edu), there were about 1000 astronomy/astrophysics papers that involved ML or AI, and their numbers are growing exponentially, with a doubling time of about 20 months. AI is now a standard part of the astronomical toolkit.</p>
<p>ML/AI methods are used to create value-added higher level data products for follow-up research, and may include source detection and segmentation tasks, structural and morphological classification, as well as all kinds of ordinary classification and regression tasks. While supervised classification tools are by construction unable to detect any new types of objects that are not present in the training data sets, unsupervised clustering offers a possibility of discovering previously unknown classes, and enable detection of rare, unusual, or even previously unknown types of objects as outliers in some feature space.</p>
<p>Given the vast scope of the field, the goal of this chapter is not to provide a comprehensive review, but rather to give some illustrative examples where ML/AI have enabled significant advances in astronomy.</p>
<p>A useful didactic overview is by [4]. The monograph [5] gives an extensive and practical coverage of the subject. For some recent examples, see [6].</p>
<p>Early Applications: Digital Sky Surveys</p>
<p>While there have been some early experiments in the early 1990s, the use of ML/AI in astronomy really started growing in mid-1990s, with the advent of the first large digital sky surveys [7,8]. The initial applications were to automate repetitive tasks that were previously done by humans. A good example of the star-galaxy separation for the catalogs of objects detected in sky surveys. Following the image segmentation that identifies individual sources, several tens to hundreds morphological and structural parameters are evaluated for each one, thus forming feature vectors that can be analyzed using ML tools. Essentially, first Terabytes and now Petabytes of images are converted into database catalogs of many millions to billions of feature vectors, each representing an individual detected source, in data spaces of hundreds of dimensions, or even thousands once multiple catalogs are combined.</p>
<p>In the visible, UV, and IR wavelength regimes, the first order classification is between the unresolved sources ("stars") and resolved ones ("galaxies"), based purely on the image morphology. Supervised classification methods, such as the Artificial Neural Networks (ANN), or Decision Trees (DT) were used effectively for this task; see, e.g., [9,10]. Morphological classification can be used to identify and remove a variety of instrumental artifacts, that may appear as outliers in the feature space, [11]. The physical classification as objects of different types, e.g., Galactic stars vs. quasars, different types of galaxies, different types of stars, etc., requires additional data in a subsequent analysis.</p>
<p>Digital sky surveys opened a new, highly effective mode of astronomical discovery. Traditional mode of pointed observations focuses on the individual objects or small samples of objects. Sky surveys may detect billions of sources, and ML can be used to select and prioritize the most interesting targets for the follow-up with large and/or space-based telescopes, thus optimizing the use of these scarce resources. Applying supervised classifiers or cuts in the feature space informed by the domain expertise has been proved to be very effective in finding well-defined samples of relatively rare types of objects, such as high-redshift quasars or brown dwarfs [12,13,14].</p>
<p>Increasing Challenges: Time-Domain Astronomy</p>
<p>Improvements in the size, quality, and cost of astronomical detectors enabled much larger format imaging cameras, which in turn enabled the rise of the synoptic sky surveys, where large areas of sky are surveyed repeatedly. This opening of the Time Domain enabled systematic, scaled-up studies of various temporal phenomena, including variability of stars and active galactic nuclei, cosmic explosions of all kinds (e.g., many types of Supernovae, Gravitational Wave events, etc.), moving objects such as the potentially hazardous asteroids, etc. Time Domain -essentially a panoramic cosmic cinematography -touches all fields of astronomy, from the Solar System to cosmology.</p>
<p>This opens new scientific opportunities, but also brings new challenges in addition to those posed by the traditional sky surveys, by adding the variability information to the classification tasks, and often time-criticality due to the transitive nature of the observed events: the potentially most interesting ones have to be identified in real time, as they must be followed up before they fade away [14,15,16,17,18,19,63,64]. Figure 1 shows a conceptual illustration of some of these challenges.</p>
<p>In addition to the full electromagnetic (EM) spectrum, gravitational wave, high energy cosmic rays, and neutrino observatories are also now providing copious amounts of data, opening the field of Multi-messenger Astronomy. In general, the events detected by these non-EM channels have a very poor angular resolution and directionality but identifying their EM counterparts is essential for their physical interpretation. This leads to large area searches for counterparts, with many potential candidates. ML methods can be used to classify the possible candidate counterparts, e.g., [20,63,65,66], a n d o ther ML methods are being used to scrutinize and classify the non-EM signals themselves, e.g., [21,22].</p>
<p>Predicting the value of a time series between measurements is a common problem, particularly with multidimensional time series where values for all quantities at all timestamps are not available. In astronomy, this can pertain to prioritizing follow-up observations for interesting transient events. In the absence of a good theoretical model for the underlying process, a variety of interpolation schemes can be employed. However, these can also be a source of additional systematic errors. One critical issue in classification in general is the poor scaling of the classification algorithms with the dimensionality of the feature space. This is especially important in the Time Domain; some approaches have been discussed by [23,24]. Feature dimensionality from several tens to few hundreds are now routine. Not all of these are independent (orthogonal) and some even add to noise for specific classes, making dimensionality reduction a critical need. For multiclass classification, disambiguating features that are important for one class but not another can be non-trivial. An example is the use of binary classifiers for the Zwicky Transient Facility (ZTF) [25]. Tools like DNN and XGBoost can be also used to identify the top features. When external features (e.g., from crossmatches to other surveys) are being incorporated, there can be missing features, which further complicates the use of some of the ML techniques. Techniques like Data Sheets [26] and Model Cards [27] can be used to standardize data set creation and lead to reusable models [28].</p>
<p>An alternative is to adopt a probabilistic approach and regard the observed time series as a single draw from a multivariate Gaussian distribution fully characterized by a mean (normally assumed to be zero or constant) and a covariance function. Predicted points then just represent a subsequent draw and can be calculated with an associated uncertainty. Gaussian process regression (GPR) [31] uses the observed data to learn the hyperparameters of the underlying covariance kernel (and mean function if present). The form of the kernel function is a choice for the user but specific properties of the underlying process, such as stationarity, autoregressive behavior, or a spectral density representation, are easily represented. In fact, there is a theoretical duality between certain GPR kernels and neural network architectures [32] and neural networks can also be employed directly as kernels in some GPR implementations.</p>
<p>The main issue in using GPR, particularly with large multidimensional data sets with thousands of data points and/or comprising thousands of samples, is the speed of fitting since this typically involves extensive matrix inversion. Certain GPR implementations have achieved good performance by making very specific decisions on the functional form of the kernel function, e.g., it only uses exponential terms, and optimizing accordingly, but this is not a global solution [33].</p>
<p>It is also unclear how good GPR is at forecasting data. There is a tendency with non-periodic kernels to regress to the mean with increasing time past the last observed data point and increasing uncertainty. Recurrent neural networks seem to show better performance [34], but they have also been used more in forecasting a next data point rather data over an extended period of time. Obviously, if the underlying process is nonlinear, then forecasting presents a much bigger problem and more advanced deep learning architectures may be required.</p>
<p>Incorporating error-bars in ML analysis is a notoriously non-trivial challenge. That fact, combined with classifying objects near the detection limit, raises a very different kind of a challenge. Observing ever-fainter objects helps push the science into newer areas, but at the same time it comes with a greater risk of such objects turning out to be false positives (e.g., short lived transients that are below the quiescent limit that brighten into observable range for a short duration). Uncertainty quantification, e.g., [35], combined with emulators and simulators [29], along with models based on Bayesian techniques may be needed [36].</p>
<p>Looking for anomalies, i.e., objects or events that do not seem to belong to any of the known classes, poses additional challenges. It is difficult to define what an anomaly is in the first place: is it an out-of-distribution object, a completely independent or new class? Will more observations favor one interpretation or the other, and what kind of observations will be required? Active learning where newer observations are iteratively used to improve classification routinely indicate the requirement to revise classifications at the boundaries of ambiguity. However, the follow-up resources are limited, and with the ever-growing data rates it becomes critical to optimize their use. Some early efforts in this arena include [30,37,38,39,40], and others.</p>
<p>A Growing Applications Landscape</p>
<p>While classification and outlier search remail a staple of survey-based astronomy, there is now a much broader range of ML/AI applications.</p>
<p>One application area of ML tools is the estimation of photometric redshifts (photo-z's). In cosmology, redshift, reflecting the increase in the scale of the universe since the light was emitted by some distant object, due to the cosmic expansion is a measure of distance, and thus necessary in determining the physical parameters of distant galaxies and quasars, such as their luminosities, masses, etc. Traditionally, redshifts are measured spectroscopically, which is observationally expensive. Photo-z's are a way of estimating the redshifts from the multi-color photometry, which is observationally much cheaper, and thus can be done for vastly larger numbers of objects. This is a use case where ML has enabled significant advances and savings of observing time, by including instrumental characteristics and physical models implicitly expressed through the data. There is an extensive literature on this subject with a wide variety of ML methods [41,42,43,44,45,46,47,48,49,50], and many others). One important conceptual change was to replace a single number representation of an estimated photo-z with a probability density distribution.</p>
<p>ML has been also used as a method for the discovery of gravitational lenses, operating both on the images from sky surveys [51], and time series of quasar variability [52]. Such large, systematically selected samples of gravitational lenses can be used as probes of dark matter and the expansion rate of the universe.</p>
<p>In addition to the data obtained through observations, the output of large numerical simulations is another large source of data calling for an automated analysis. Current developments led to hybrid approaches of classically computing physical models in combination with ML models. By doing so, time-consuming calculations can be replaced through very quick ML models that act as a surrogate with a similar accuracy as the original code. Thereby, larger volumes, with higher spatial and temporal resolution, can be computed without requiring more resources. Another aspect is that critical branching conditions can be detected, and the resolutions of the simulation can be adaptively changed, ensuring that those details are not lost or overseen while simulating. Some examples include [53,54,55,56], and others. This is just a small sampling of the examples of the diverse, growing, and creative uses of AI/ML in astronomy.</p>
<p>Concluding Comments and Future Prospects</p>
<p>While the range and diversity of AI applications in astronomy continue to grow, most applications so far have been focused on the analysis of already acquired data sets and their derived data products, such as the tables of pre-extracted and expert engineered features. However, the landscape of ML/AI applications is also changing rapidly, affecting different stages of a data-centric approach, data acquisition, processing, and analysis.</p>
<p>The acquisition stage covers the process of planning and performing observations. For the most part this process was done by the individual experts, but based on specified quality criteria, AI systems can learn to perform this planning automatically. Based on the quick analysis of the initial data, instrument setup, exposure times, etc., can be used to close the loop between choosing the right observational setup and getting high quality science data. This kind of fast, AI-based observation planning and control systems will likely replace the current way of planning, scheduling, and observing, leading to an improved scientific outcome, both in quality and quantity of the observations. This will be critical in the arena of Time-Domain and Multi-Messenger Astronomy, where transient events may be detected and followed up by a number of different surveys and facilities, and their prioritization for the follow-up would be essential.</p>
<p>Incorporation of domain knowledge into ML/AI analysis, such as the 'physicsbased' AI is an active area of research, with many outstanding challenges remaining. Some examples include [57,58], and others.</p>
<p>Besides the analysis of scientific data, ML methods get utilized to access complex scientific content like scientific publications or to realize a natural language and chat-based access to data stored in catalogs. ML and AI based systems may transform the way of finding and accessing data soon. Likewise, ML can be used to sort through the literature given a set of user preferences; an example is http://www.arxiv-sanity.com/.</p>
<p>Another novel direction is in using AI not just to map the data spaces and find interesting objects, but to discover potentially interesting relationships that may be present in the data. One approach is to use symbolic regression, e.g., [59,60]. A related technique uses memetic regression [61,62].</p>
<p>As the data complexity continues to increase, use of AI to detect interesting patterns or behaviors present in the data, that may elude humans, e.g., due to the hyper-dimensionality of the data will keep on increasing. The interpretation of such AI-based discoveries still rests with the humans, but there is a possibility that some of them may simply exceed the human cognitive capabilities. We may increasingly see more examples of a collaborative human-AI discovery.</p>
<p>Figure 1 :
1The five major challenges facing TDA today (a) a representation of a data cube signifying multiple wavelengths and multiwavelength observation of the Crab Nebula, (b) multiplicity of data features, (c) GPRs as a way to bridgegaps in observing, (d) Understanding effect of noise on objects (from Caldeira &amp; Nord 2020), and (e) detecting anomalies (from Martínez-Galarza et al. 2021). Image credits: João Steiner, Stephen Todd, ROE and Douglas Pierce-Price, JAC for datacube; NRAO/AUI and M. Bietenholz; NRAO/AUI and J.M. Uson, T.J. Cornwell (radio); NASA/JPL-Caltech/R. Gehrz / University of Minnesota (infrared); NASA, ESA, J. Hester and A. Loll / Arizona State University (visible); NASA/Swift/E. Hoversten, PSU (ultraviolet); NASA/CXC/SAO/F. Seward et al.(X-rays); NASA/DOE/Fermi LAT/R. Buehler (gamma rays) for Crab Nebula images.</p>
<p>Sky Surveys. S G Djorgovski, A A Mahabal, A Drake, M J Graham, C Donalek, Astronomical Techniques, Software, and Data. 2, ser. ed. T. OswaltDordrechtSpringerPlanets, Stars, and Stellar SystemsDjorgovski, S. G., Mahabal, A. A., Drake, A., Graham, M. J., and Donalek, C. (2012). Sky Surveys, in: Astronomical Techniques, Software, and Data, ed. H. Bond, Planets, Stars, and Stellar Systems, 2, ser. ed. T. Oswalt, (Dordrecht: Springer), pp. 223-281.</p>
<p>Virtual Observatories of the Future. R J Brunner, S G Djorgovski, A S Szalay, Astronomical Society of the Pacific). 225A.S.P. Conf. Ser.Brunner, R. J., Djorgovski, S. G., and Szalay, A. S. (2001). Virtual Observatories of the Future, A.S.P. Conf. Ser. 225 (San Francisco: Astronomical Society of the Pacific).</p>
<p>Towards the National Virtual Observatory. S G Djorgovski, Nvo, National Science Foundation). Science Definition TeamDjorgovski, S. G., and the NVO Science Definition Team (2002). Towards the National Virtual Observatory, https://www.nsf.gov/mps/ast/sdt_final.pdf (Washington, DC: National Science Foundation).</p>
<p>Machine Learning in Astronomy: A Practical Overview. D Baron, Baron, D. (2019). Machine Learning in Astronomy: A Practical Overview, available online at https://arxiv.org/abs/1904.07248</p>
<p>Statistics, Data Mining, and Machine Learning in Astronomy: A Practical Python Guide for the Analysis of Survey Data. Ž Ivezić, A Connolly, J Vanderplas, A Gray, Princeton University PressPrincetonIvezić, Ž., Connolly, A., VanderPlas, J., and Gray, A. (2020). Statistics, Data Mining, and Machine Learning in Astronomy: A Practical Python Guide for the Analysis of Survey Data. (Princeton: Princeton University Press).</p>
<p>I Zelinka, M Brescia, D Baron, Intelligent Astrophysics, In: Emergence, Complexity and Computation. Springer Nature39Zelinka, I., Brescia, M., and Baron, D. (editors) (2021). Intelligent Astrophysics, In: Emergence, Complexity and Computation, 39, Springer Nature.</p>
<p>The SKICAT System for Processing and Analysing Digital Imaging Sky Surveys. N Weir, U Fayyad, S G Djorgovski, J Roden, Publ. Astron. Soc. Pacific. 107Weir, N., Fayyad, U., Djorgovski, S. G., and Roden, J. (1995a). The SKICAT System for Processing and Analysing Digital Imaging Sky Surveys, Publ. Astron. Soc. Pacific 107, 1243-1254.</p>
<p>Automated Analysis and Exploration of Image Databases: Results, Progress, and Challenges. U Fayyad, P Smyth, N Weir, S G Djorgovski, J. Intel. Inform. Sys. 47Fayyad, U., Smyth, P., Weir, N., and Djorgovski, S. G. (1995). Automated Analysis and Exploration of Image Databases: Results, Progress, and Challenges, J. Intel. Inform. Sys. 4, 7.</p>
<p>Automated Star/Galaxy Classification for Digitized POSS-II. N Weir, U Fayyad, S G Djorgovski, Astron. J. 109Weir, N., Fayyad, U., and Djorgovski, S. G. (1995b). Automated Star/Galaxy Classification for Digitized POSS-II, Astron. J. 109, 2401-2414.</p>
<p>The Digitized Second Palomar Observatory Sky Survey (DPOSS). III. Star-Galaxy Separation. S Odewahn, R De Carvalho, R Gal, S G Djorgovski, R Brunner, A Mahabal, P Lopes, J Kohl Moreira, B Stalder, Astron. J. 128Odewahn, S., de Carvalho, R., Gal, R., Djorgovski, S. G., Brunner, R., Mahabal, A., Lopes, P., Kohl Moreira, J., &amp; Stalder, B. (2004). The Digitized Second Palomar Observatory Sky Survey (DPOSS). III. Star-Galaxy Separation, Astron. J. 128, pp. 3092-3107.</p>
<p>New Approaches to Object Classification in Synoptic Sky Surveys. C Donalek, A Mahabal, S G Djorgovski, S Marney, A Drake, M Graham, E Glikman, Williams , R , AIP Conf. Ser. 1082Donalek, C., Mahabal, A., Djorgovski, S. G., Marney, S., Drake, A., Graham, M., Glikman, E., and Williams, R. (2008). New Approaches to Object Classification in Synoptic Sky Surveys, AIP Conf. Ser., 1082, pp. 252-256.</p>
<p>Searches for Rare and New Types of Objects, in: Virtual Observatories of the Future. S G Djorgovski, A Mahabal, R Brunner, R Gal, S Castro, R De Carvalho, S Odewahn, P. Conf. Ser. R. Brunner, S.G. Djorgovski, and A. Szalay, A.S.225Djorgovski, S. G., Mahabal, A., Brunner, R., Gal, R., Castro, S., de Carvalho, R., and Odewahn, S. (2001a). Searches for Rare and New Types of Objects, in: Virtual Observatories of the Future, eds. R. Brunner, S.G. Djorgovski, and A. Szalay, A.S.P. Conf. Ser. 225, pp. 52-63.</p>
<p>Exploration of Large Digital Sky Surveys, in: Mining the Sky. S G Djorgovski, R Brunner, A Mahabal, S Odewahn, R De Carvalho, R Gal, P Stolorz, R Granat, D Curkendall, J Jacob, S Castro, ESO Astrophysics Symposia. A. J. Banday et al.SpringerDjorgovski, S. G., Brunner, R., Mahabal, A., Odewahn, S., de Carvalho, R., Gal, R., Stolorz, P., Granat, R., Curkendall, D., Jacob, J., and Castro, S. (2001b). Exploration of Large Digital Sky Surveys, in: Mining the Sky, eds. A. J. Banday et al., ESO Astrophysics Symposia, (Berlin: Springer), pp. 305-322.</p>
<p>Exploration of Parameter Spaces in a Virtual Observatory. S G Djorgovski, A Mahabal, R Brunner, R Williams, R Granat, D Curkendall, J Jacob, P Stolorz, Astronomical Data Analysis. J.-L. Starck &amp; F. MurtaghProc. SPIE 4477Djorgovski, S.G., Mahabal, A., Brunner, R., Williams, R., Granat, R., Curkendall, D., Jacob, J., and Stolorz, P. (2001c). Exploration of Parameter Spaces in a Virtual Observatory, in: Astronomical Data Analysis, eds. J.-L. Starck &amp; F. Murtagh, Proc. SPIE 4477, pp. 43-52.</p>
<p>Discovery, Classification, and Scientific Exploration of Transient Events from the Catalina Real-Time Transient Survey. A Mahabal, S G Djorgovski, A Drake, C Donalek, M Graham, B Moghaddam, M Turmon, R Williams, E Beshore, S Larson, Bull. Astr. Soc. India. 39Mahabal, A., Djorgovski, S. G., Drake, A., Donalek, C., Graham, M., Moghaddam, B., Turmon, M., Williams, R., Beshore, E., and Larson, S. (2011). Discovery, Classification, and Scientific Exploration of Transient Events from the Catalina Real- Time Transient Survey, Bull. Astr. Soc. India, 39, 387-408.</p>
<p>Exploring the Time Domain with Synoptic Sky Surveys. S G Djorgovski, A Mahabal, A Drake, M Graham, C Donalek, R Williams, ; E Griffin, New Horizons in Time Domain Astronomy. CambridgeCambridge Univ. Press285Proc. IAU SympDjorgovski, S. G., Mahabal, A., Drake, A., Graham, M., Donalek, C., &amp; Williams, R., (2012a). Exploring the Time Domain with Synoptic Sky Surveys, in: Proc. IAU Symp. 285: New Horizons in Time Domain Astronomy, eds. E. Griffin et al., (Cambridge: Cambridge Univ. Press), pp. 141-146.</p>
<p>Flashes in a Star Stream: Automated Classification of Astronomical Transient Events. S G Djorgovski, A Mahabal, C Donalek, M Graham, A Drake, B Moghaddam, M Turmon, Proc. IEEE. IEEEIEEE press6404437Djorgovski, S. G., Mahabal, A., Donalek, C., Graham, M., Drake, A., Moghaddam, B., and Turmon, M. (2012b). Flashes in a Star Stream: Automated Classification of Astronomical Transient Events, Proc. IEEE e-Science 2012, (IEEE press), 6404437.</p>
<p>Data Challenges of Time Domain Astronomy, Distributed and Parallel Databases. M Graham, S G Djorgovski, A Mahabal, C Donalek, A Drake, G Longo, 30Graham, M., Djorgovski, S. G., Mahabal, A., Donalek, C., Drake, A., and Longo, G. (2012). Data Challenges of Time Domain Astronomy, Distributed and Parallel Databases, 30, pp. 371-384.</p>
<p>Challenges in the automated classification of variable stars in large databases. M Graham, A Drake, S G Djorgovski, A Mahabal, C Donalek, M Catelan, W Gieren, Wide-Field Variability Surveys: A 21st Century Perspective. 1523001Graham, M., Drake, A., Djorgovski, S. G., Mahabal, A., and Donalek, C. (2017). Challenges in the automated classification of variable stars in large databases, in: Wide-Field Variability Surveys: A 21st Century Perspective, eds. Catelan, M. and Gieren, W., EPJ Web of Conferences, 152, 03001.</p>
<p>. I Andreoni, M Coughlin, E Kool, M Kasliwal, H Kumar, V Bhalerao, A Carracedo, A Ho, P Pang, D Saraogi, Astrophys. J. 91863Andreoni, I., Coughlin, M., Kool, E., Kasliwal, M., Kumar, H., Bhalerao, V., Carracedo, A., Ho, A., Pang, P., Saraogi, D., et al. Astrophys. J. 918, 63 (2021).</p>
<p>. M Cabero, A Mahabal, J Mciver, 10.3847/2041-8213/abc5b5arXiv:2010.11829Astrophys. J. Lett. 9049gr-qcCabero, M., Mahabal, A., and McIver, J., Astrophys. J. Lett. 904, L9 (2020). doi:10.3847/2041-8213/abc5b5 [arXiv:2010.11829 [gr-qc]].</p>
<p>GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts. T C Abbott, E Buffaz, N Vieira, M Cabero, D Haggard, A Mahabal, J Mciver, Astrophys. J. Accepted toAbbott, T.C., Buffaz, E., Vieira, N., Cabero, M., Haggard, D., Mahabal, A. and McIver, J., Accepted to Astrophys. J., 2022. GWSkyNet-Multi: A Machine Learning Multi-Class Classifier for LIGO-Virgo Public Alerts. https://arxiv.org/abs/2111.04015.</p>
<p>Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets. C Donalek, A Kumar, S G Djorgovski, A Mahabal, M Graham, T Fuchs, M Turmon, N Sajeeth Philip, T.-C Yang, G Longo, Scalable Machine Learning: Theory and Applications. Donalek, C., Kumar, A., Djorgovski, S.G., Mahabal, A., Graham, M., Fuchs, T., Turmon, M., Sajeeth Philip, N., Yang, T.-C., and Longo, G. (2013). Feature Selection Strategies for Classifying High Dimensional Astronomical Data Sets, in: Scalable Machine Learning: Theory and Applications, IEEE BigData 2013, 35-40.</p>
<p>An Analysis of Feature Relevance in the Classification of. A D&apos;isanto, S Cavuoti, M Brescia, C Donalek, G Longo, G Riccio, S G Djorgovski, Astronomical Transients with Machine Learning Methods. 457MNRASD'Isanto, A., Cavuoti, S., Brescia, M., Donalek, C., Longo, G., Riccio, G., Djorgovski, S. G. (2016). An Analysis of Feature Relevance in the Classification of Astronomical Transients with Machine Learning Methods, MNRAS 457, pp. 3119- 3132.</p>
<p>. J Van Roestel, D A Duev, A A Mahabal, M W Coughlin, P Mr´oz, K Burdge, A Drake, Astron. J. 267van Roestel J., Duev D. A., Mahabal A. A., Coughlin M. W., Mr´oz P., Burdge K., Drake A., et al. (2021). Astron. J, 161, 267.</p>
<p>. T Gebru, J Morgenstern, B Vecchione, J Wortman Vaughan, H Wallach, H Daumé, K Crawford, Gebru T., Morgenstern J., Vecchione B., Wortman Vaughan J., Wallach H., Daumé H., Crawford, K. (2018). Online at https://arxiv.org/abs/1803.</p>
<p>M Mitchell, S Wu, A Zaldivar, P Barnes, L Vasserman, B Hutchinson, E Spitzer, FAT<em> '19: Conference on Fairness, Accountability, and Transparency. Mitchell M., Wu S., Zaldivar A., Barnes P., Vasserman, L., Hutchinson B., Spitzer E., et al., 2019, FAT</em> '19: Conference on Fairness, Accountability, and Transparency, https://arxiv.org/abs/1810.03993.</p>
<p>In-space Data Fusion for More Productive Missions. A Mahabal, T Hare, V Fox, G Hallinan, Bull. AAS. 453Mahabal, A., Hare, T., Fox, V., Hallinan, and G. (2021). In-space Data Fusion for More Productive Missions. Bull. AAS, 53 (4).</p>
<p>Deeply uncertain: comparing methods of uncertainty quantification in deep learning algorithms. J Caldeira, B Nord, Machine Learning: Science and Technology. 2115002Caldeira, J. and Nord, B., 2020. Deeply uncertain: comparing methods of uncertainty quantification in deep learning algorithms. Machine Learning: Science and Technology, 2(1), 015002.</p>
<p>. J R Martínez-Galarza, F B Bianco, D Crake, K Tirumala, A A Mahabal, M J Graham, D Giles, MNRAS. 5085734Martínez-Galarza J. R., Bianco F. B., Crake D., Tirumala K., Mahabal A. A., Graham M. J., Giles D., 2021, MNRAS, 508, 5734.</p>
<p>C Rasmussen, Williams , C , Gaussian Processes for Machine Learning. MIT PressRasmussen, C., and Williams, C., Gaussian Processes for Machine Learning (2006). MIT Press.</p>
<p>J Lee, Y Bahri, R Novak, S Schoenholz, J Pennington, Deep neural networks as gaussian processes. Lee, J., Bahri, Y., Novak, R., Schoenholz, S., Pennington, J., Sohl-Dickstein, (2017) Deep neural networks as gaussian processes https://arxiv.org/abs/1711.00165.</p>
<p>Fast and scalable Gaussian process modeling with applications to astronomical time series. D Foreman-Mackey, E Agol, S Ambikasaran, Angus , R , Astron. J. 154220Foreman-Mackey, D., Agol, E., Ambikasaran, S., and Angus, R. (2017). Fast and scalable Gaussian process modeling with applications to astronomical time series, Astron. J., 154, 220.</p>
<p>Deep Modeling of Quasar Variability. Y Tachibana, M Graham, N Kawai, S G Djorgovski, A Drake, A Mahabal, Astrophys. J. 90317Tachibana, Y., Graham, M., Kawai, N., Djorgovski, S. G., Drake, A., and Mahabal, A. (2020). Deep Modeling of Quasar Variability, Astrophys. J., 903, 17.</p>
<p>A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion. M Abdar, F Pourpanah, S Hussain, D Rezazadegan, L Liu, M Ghavamzadeh, P Fieguth, X Cao, A Khosravi, U R Acharya, V Makarenkov, 76Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D., Liu, L., Ghavamzadeh, M., Fieguth, P., Cao, X., Khosravi, A., Acharya, U.R. and Makarenkov, V. A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion, 76, 243-297 (2021).</p>
<p>Galaxy Zoo: probabilistic morphology through Bayesian CNNs and active learning. M Walmsley, L Smith, C Lintott, Y Gal, S Bamford, H Dickinson, L Fortson, MNRAS. 491Walmsley M., Smith L., Lintott C., Gal Y., Bamford S., Dickinson H., Fortson L., et al. (2020). Galaxy Zoo: probabilistic morphology through Bayesian CNNs and active learning, MNRAS, 491, 1554-1574.</p>
<p>. S Webb, M Lochner, D Muthukrishna, J Cooke, C Flynn, A Mahabal, S Goode, MNRAS. 4983077Webb S., Lochner M., Muthukrishna, D., Cooke J., Flynn, C., Mahabal A., Goode S., et al., 2020, MNRAS, 498, 3077.</p>
<p>A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients. V A Villar, M Cranmer, E Berger, G Contardo, S Ho, G Hosseinzadeh, J Lin, Astrophys. J. Suppl. Ser. 25524Villar, V. A., Cranmer, M., Berger, E., Contardo, G., Ho, S., Hosseinzadeh, G., Lin, J. (2021). A Deep-learning Approach for Live Anomaly Detection of Extragalactic Transients, Astrophys. J. Suppl. Ser., 255, 24.</p>
<p>. E E O Ishida, M V Kornilov, K L Malanchev, M V Pruzhinskaya, A A Volnova, V S Korolev, F Mondon, Astron, Astrophys. 650195Ishida E. E. O., Kornilov M. V., Malanchev K. L., Pruzhinskaya M. V., Volnova A. A., Korolev V. S., Mondon F., et al., 2021, Astron, Astrophys., 650, A195.</p>
<p>ASTRONOMALY: Personalised active anomaly detection in astronomical data. M Lochner, B Bassett, Astron. Computing. 36100481Lochner, M., and Bassett, B. (2021). ASTRONOMALY: Personalised active anomaly detection in astronomical data, Astron. Computing, 36, 100481.</p>
<p>Robust Machine Learning Applied to Astronomical Data Sets. III. Probabilistic Photometric Redshifts for Galaxies and Quasars. N Ball, R Brunner, A Myers, N Strand, S Alberts, D Tcheng, Astrophys. J. 683Ball, N., Brunner, R., Myers, A., Strand, N., Alberts, S., and Tcheng, D. (2008). Robust Machine Learning Applied to Astronomical Data Sets. III. Probabilistic Photometric Redshifts for Galaxies and Quasars, Astrophys. J., 683, 12-21.</p>
<p>Astroinformatics of galaxies and quasars: a new general method for photometric redshifts estimation. O Laurino, R D&apos;abrusco, G Longo, G Riccio, MNRAS. 418Laurino, O., D'Abrusco, R., Longo, G., and Riccio, G. (2011). Astroinformatics of galaxies and quasars: a new general method for photometric redshifts estimation, MNRAS 418, 2165-2195.</p>
<p>. M Brescia, S Cavuoti, R D&apos;abrusco, G Longo, A Mercurio, Brescia, M., Cavuoti, S., D'Abrusco, R., Longo, G., and Mercurio, A. (2013).</p>
<p>Photometric Redshifts for Quasars in Multi-band Surveys. Astrophys. J. 772140Photometric Redshifts for Quasars in Multi-band Surveys, Astrophys. J., 772, 140.</p>
<p>Exhausting the information: novel Bayesian combination of photometric redshift PDFs. M Carrasco Kind, R Brunner, MNRAS. 442Carrasco Kind, M., and Brunner, R. (2014). Exhausting the information: novel Bayesian combination of photometric redshift PDFs, MNRAS, 442, 3380-3399.</p>
<p>Photometric redshifts with the quasi-Newton algorithm (MLPQNA): Results in the PHAT1 contest. S Cavuoti, M Brescia, G Longo, A Mercurio, Astron. Astrophys. 54613Cavuoti, S., Brescia, M., Longo, G., and Mercurio, A. (2012). Photometric redshifts with the quasi-Newton algorithm (MLPQNA): Results in the PHAT1 contest, Astron. Astrophys., 546, A13.</p>
<p>METAPHOR: A machine-learning-based method for the probability density estimation of photometric redshifts. S Cavuoti, V Amaro, M Brescia, C Vellucci, C Tortora, G Longo, MNRAS. 465Cavuoti, S., Amaro, V., Brescia, M., Vellucci, C., Tortora, C., and Longo, G. (2017). METAPHOR: A machine-learning-based method for the probability density estimation of photometric redshifts, MNRAS, 465, 1959-1973.</p>
<p>Photometric redshift estimation via deep learning. Generalized and pre-classification-less, image based, fully probabilistic redshifts. A D&apos;isanto, K Polsterer, Astron. Astrophys. 609111D'Isanto, A., and Polsterer, K. (2018). Photometric redshift estimation via deep learning. Generalized and pre-classification-less, image based, fully probabilistic redshifts, Astron. Astrophys., 609, A111</p>
<p>The many flavours of photometric redshifts. M Salvato, O Ilbert, B Hoyle, Nature Astronomy. 3Salvato, M., Ilbert, O., and Hoyle, B. (2019). The many flavours of photometric redshifts, Nature Astronomy, 3, 212-222.</p>
<p>Evaluation of probabilistic photometric redshift estimation approaches for The Rubin Observatory Legacy Survey of Space and Time (LSST). S J Schmidt, LSST Dark Energy Science CollaborationMNRAS. 499Schmidt, S.J., et al., LSST Dark Energy Science Collaboration (2020). Evaluation of probabilistic photometric redshift estimation approaches for The Rubin Observatory Legacy Survey of Space and Time (LSST), MNRAS 499, 1587-1606.</p>
<p>Improving the reliability of photometric redshift with machine learning. O Razim, S Cavuoti, M Brescia, G Riccio, M Salvato, G Longo, MNRAS. 507Razim, O., Cavuoti, S., Brescia, M., Riccio, G., Salvato, M., and Longo, G. (2021). Improving the reliability of photometric redshift with machine learning, MNRAS, 507, 5034-5052.</p>
<p>Gaia GraL: Gaia DR2 gravitational lens systems. I. New quadruply imaged quasar candidates around known quasars. A Krone-Martins, L Delchambre, O Wertz, C Ducourant, F Mignard, R Teixeira, Astron. Astrophys. 61611Krone-Martins, A., Delchambre, L., Wertz, O., Ducourant, C., Mignard, F., Teixeira, R., et al. (2018). Gaia GraL: Gaia DR2 gravitational lens systems. I. New quadruply imaged quasar candidates around known quasars, Astron. Astrophys., 616, L11.</p>
<p>A Krone-Martins, M Graham, D Stern, S G Djorgovski, L Delchambre, C Ducourant, Gaia GraL: Gaia DR2 Gravitational Lens Systems.V.Doubly-imaged QSOs Discovered from Entropy and Wavelets. in pressKrone-Martins, A., Graham, M., Stern, D., Djorgovski, S. G., Delchambre, L., Ducourant, C., et al. (2022). Gaia GraL: Gaia DR2 Gravitational Lens Systems.V.Doubly-imaged QSOs Discovered from Entropy and Wavelets, Astron. Astrophys. in press.</p>
<p>Machine learning and cosmological simulations -II. Hydrodynamical simulations. H Kamdar, M Turk, R Brunner, MNRAS. 457Kamdar, H., Turk, M., and Brunner, R. (2016). Machine learning and cosmological simulations -II. Hydrodynamical simulations, MNRAS, 457, 1162-1179.</p>
<p>. Y Ni, Y Li, P Lachance, R Croft, T Di Matteo, S Bird, Y Feng, Ni, Y., Li, Y., Lachance, P., Croft, R., Di Matteo, T., Bird, S., and Feng, Y. (2021).</p>
<p>AI-assisted superresolution cosmological simulations -II. Halo substructures, velocities, and higher order statistics. MNRAS. 507AI-assisted superresolution cosmological simulations -II. Halo substructures, velocities, and higher order statistics, MNRAS, 507, 1021-1033.</p>
<p>A machine learning approach to mapping baryons on to dark matter haloes using the EAGLE and C-EAGLE simulations. C Lovell, S Wilkins, P Thomas, M Schaller, C Baugh, G Fabbian, Y Bahé, MNRAS. 509Lovell, C., Wilkins, S., Thomas, P., Schaller, M., Baugh, C., Fabbian, G., Bahé, Y. (2022). A machine learning approach to mapping baryons on to dark matter haloes using the EAGLE and C-EAGLE simulations, MNRAS, 509, 5046-5061.</p>
<p>Classification algorithms applied to structure formation simulations. J Chacón, J Vázquez, Almaraz , E , Astron. Computing. 38100527Chacón, J., Vázquez, J., and Almaraz, E. (2022). Classification algorithms applied to structure formation simulations, Astron. Computing, 38, 100527.</p>
<p>Physics-informed machine learning. G Karniadakis, I Kevrekidis, L Lu, P Perdikaris, S Wang, Yang , L , Nature Reviews Physics. 36Karniadakis, G., Kevrekidis, I., Lu, L., Perdikaris, P., Wang, S., and Yang, L. (2021). Physics-informed machine learning, Nature Reviews Physics, 3(6):422-440.</p>
<p>Z Liu, Y Chen, Y Du, M Tegmark, Physics-Augmented Learning: A New Paradigm Beyond Physics-Informed Learning. Liu, Z., Chen, Y., Du, Y., and Tegmark, M. (2021). Physics-Augmented Learning: A New Paradigm Beyond Physics-Informed Learning, https://arxiv.org/abs/2109.13901</p>
<p>Machine-Assisted Discovery of Relationships. M Graham, S G Djorgovski, A Mahabal, C Donalek, Drake , A , Astronomy. 2371MNRASGraham, M., Djorgovski, S. G., Mahabal, A., Donalek, C., and Drake, A. (2013). Machine-Assisted Discovery of Relationships in Astronomy, MNRAS, 431, 2371.</p>
<p>AI Feynman: a Physics-Inspired Method for Symbolic Regression. S.-M Udrescu, M Tegmark, Science Advances. 62631Udrescu, S.-M., and Tegmark, M. (2020). AI Feynman: a Physics-Inspired Method for Symbolic Regression, Science Advances, 6:2631.</p>
<p>A Memetic Algorithm for Symbolic Regression. H Sun, P Moscato, 2019 IEEE Congress on Evolutionary Computation (CEC). Sun, H., and Moscato, P. (2019). A Memetic Algorithm for Symbolic Regression, in: 2019 IEEE Congress on Evolutionary Computation (CEC), 2167-2174.</p>
<p>Analytic Continued Fractions for Regression: A Memetic Algorithm Approach. P Moscato, H Sun, M Haque, Expert Systems with Applications. 179115018Moscato, P., Sun, H., and Haque, M. (2021). Analytic Continued Fractions for Regression: A Memetic Algorithm Approach, Expert Systems with Applications, 179, 115018.</p>
<p>Real-Time Data Mining of Massive Data Streams from Synoptic Sky Surveys. S G Djorgovski, M Graham, C Donalek, A Mahabal, A Drake, M Turmon, T Fuchs, Future Gen. Comp. Sys. 59Djorgovski, S. G., Graham, M., Donalek, C., Mahabal, A., Drake, A., Turmon, M., and Fuchs, T. (2016). Real-Time Data Mining of Massive Data Streams from Synoptic Sky Surveys, Future Gen. Comp. Sys., 59, 95-104.</p>
<p>Automated Real-Time Classification and Decision Making in Massive Data Streams from Synoptic Sky Surveys. S G Djorgovski, A Mahabal, C Donalek, M Graham, A Drake, M Turmon, T Fuchs, Proc. IEEE e-Science. C. MedeirosIEEE e-ScienceIEEE pressDjorgovski, S. G., Mahabal, A., Donalek, C., Graham, M., Drake, A., Turmon, M., Fuchs, T. (2014). Automated Real-Time Classification and Decision Making in Massive Data Streams from Synoptic Sky Surveys, Proc. IEEE e-Science 2014, ed. C. Medeiros, (IEEE press), pp. 204-211.</p>
<p>Deep-Learnt Classification of Light Curves. A Mahabal, K Sheth, F Gieseke, A Pai, S G Djorgovski, A Drake, M Graham, Css/Crts/Ptf Teams, 2017 IEEE Symp. on Computational Intelligence (SSCI). Mahabal, A., Sheth, K., Gieseke, F., Pai, A., Djorgovski, S.G., Drake, A., Graham, M., and CSS/CRTS/PTF Teams (2017). Deep-Learnt Classification of Light Curves, in 2017 IEEE Symp. on Computational Intelligence (SSCI), 2757-2764.</p>
<p>Machine Learning for the Zwicky Transient Facility. A Mahabal, Publ. Astron. Soc. Pacific. 13138002ZTF TeamMahabal, A., et al. (ZTF Team) (2019). Machine Learning for the Zwicky Transient Facility, Publ. Astron. Soc. Pacific 131, 038002.</p>            </div>
        </div>

    </div>
</body>
</html>