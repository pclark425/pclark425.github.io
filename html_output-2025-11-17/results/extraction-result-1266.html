<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1266 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1266</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1266</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-269614170</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.04161v2.pdf" target="_blank">Decoding complexity: how machine learning is redefining scientific discovery</a></p>
                <p><strong>Paper Abstract:</strong> As modern scientific instruments generate vast amounts of data and the volume of information in the scientific literature continues to grow, machine learning (ML) has become an essential tool for organising, analysing, and interpreting these complex datasets. This paper explores the transformative role of ML in accelerating breakthroughs across a range of scientific disciplines. By presenting key examples -- such as brain mapping and exoplanet detection -- we demonstrate how ML is reshaping scientific research. We also explore different scenarios where different levels of knowledge of the underlying phenomenon are available, identifying strategies to overcome limitations and unlock the full potential of ML. Despite its advances, the growing reliance on ML poses challenges for research applications and rigorous validation of discoveries. We argue that even with these challenges, ML is poised to disrupt traditional methodologies and advance the boundaries of knowledge by enabling researchers to tackle increasingly complex problems. Thus, the scientific community can move beyond the necessary traditional oversimplifications to embrace the full complexity of natural systems, ultimately paving the way for interdisciplinary breakthroughs and innovative solutions to humanity's most pressing challenges.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1266.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1266.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Halicin (DL antibiotic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Halicin (discovered by a deep-learning antibiotic discovery pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novel antibiotic compound identified by a deep-learning model that screened large chemical spaces and whose activity was validated experimentally against antibiotic-resistant bacteria.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A deep learning approach to antibiotic discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep-learning antibiotic discovery pipeline (Stokes et al. style)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A supervised deep-learning model trained on molecular descriptors and known antibacterial activity to predict candidate small molecules; combined with in silico screening and experimental follow-up to validate biological activity. Described in the paper as an explainable deep-learning approach capable of prioritizing novel chemical scaffolds.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry / Biology (drug discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Identification of a previously unknown class of antibiotic molecules (exemplified by 'halicin') that show activity against antibiotic-resistant bacteria, discovered by screening large chemical libraries using a deep neural network and validated experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>groundbreaking discoveries</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper cites this work as an example of 'groundbreaking discoveries, such as a new class of antibiotics', justifying the label by the practical demonstration of a novel compound with experimentally validated antibacterial activity that was not previously known.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>In-silico screening performance (model ranking of candidates), retrospective analysis against known actives/inactives, and crucially experimental assays assessing antibacterial activity; publication and peer-review (Cell) as additional evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental biological validation (in vitro assays demonstrating bactericidal activity against resistant strains) followed by peer-reviewed publication; comparison of model predictions to experimental outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by the chemical novelty of predicted scaffolds relative to training data and by experimental demonstration of activity against resistant bacteria; the paper emphasizes that ML uncovered molecules unknown to prior literature.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: demonstration of activity against antibiotic-resistant strains and publication in a high-impact venue; no numerical discovery success rate presented in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review positions the ML-driven discovery as finding molecules that were not previously known, complementing human-led medicinal chemistry by prioritizing candidates not obvious to humans; ML is presented as able to navigate larger chemical spaces than manual approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review highlights issues such as dataset bias, explainability (black-box models), and the need for experimental follow-up; it notes ML may be biased towards patterns present in training data which can limit novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1266.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Hilbert (IBM 'AI scientist')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 'AI scientist' system that transforms theories and data into new, consistent mathematical models by automating hypothesis generation and testing, integrating background knowledge with data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evolving scientific discovery by unifying data and background knowledge with ai hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A framework combining background knowledge (axioms/theory) and data to produce derivable mathematical models; automates hypothesis generation, symbolic/model search and consistency checking against data, aiming to produce interpretable, derivable models.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>General scientific modelling / mathematics / physics</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Transforms existing theories and large datasets into new consistent mathematical models, uncovers patterns or models that reconcile data and theoretical constraints, and automates parts of the model-discovery pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformational</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review describes AI-Hilbert as an 'AI scientist' that 'transforms existing theories and data into new, consistent mathematical models' and as accelerating discovery by automating hypothesis generation and testing, motivating the 'transformational' label.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Assessment of consistency between discovered models and input data/theory, ability to rediscover known laws, model selection criteria that balance fit and derivability, and peer-reviewed demonstration (Nat. Commun. reference).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Benchmarking by rediscovery of known laws, comparison to alternative candidate formulas, logical/axiomatic consistency checks, and peer review/publication.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty judged by whether generated models go beyond rediscovering known relationships and by the system's ability to manage conflicting data to produce new consistent models; the review notes such systems often reproduce known laws which limits novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: capability to derive interpretable, derivable models and accelerate hypothesis formation; no numeric impact metrics provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper notes these systems can reproduce human-discovered laws (rediscoveries) and act as supportive/automating tools for scientists, but often confirm known theories rather than producing entirely novel insights without human interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include tendency to rediscover existing laws, dependence on encoded axioms/background knowledge, sensitivity to available data, and challenges in assessing when a model is genuinely novel versus a re-expression of known theory.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1266.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Descartes (Cornelio et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Descartes (combining data and theory for derivable discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method combining axiomatic knowledge with experimental data using symbolic regression and logical reasoning to derive scientific models and distinguish competing formulas, demonstrated by rediscovering known physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Combining data and theory for derivable scientific discovery with ai-descartes.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Hybrid approach that integrates axiomatic/theoretical constraints with data-driven symbolic regression to produce derivable formulae; employs logical reasoning to select among candidate symbolic models.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / mathematical model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Rediscovery of known physical laws (e.g., Kepler's third law, Einstein's time-dilation law) from limited data by combining axiomatic knowledge and symbolic regression, and the ability to discriminate between competing formulae.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>rediscovered (replicative)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review explicitly reports that such tools 'have rediscovered laws like Kepler's third law and Einstein's time-dilation law', indicating the primary outcome was reproducing known results rather than novel laws.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Comparative evaluation of candidate symbolic expressions against ground-truth physical laws, selection among competing formulas using logical/axiomatic consistency and fit to data, and case studies demonstrating recovery of established laws.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison to known analytical laws (ground truth), statistical fit to experimental data, and demonstration on limited-data scenarios showing correct recovery of known formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is low in the rediscovery examples (they reproduce established laws), but novelty lies in methodological ability to combine axioms with sparse data to derive interpretable formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative demonstration of rediscovery capability; no numeric impact metrics provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper frames these systems as often confirming known theories and acting supportively rather than replacing human creativity; their success is compared to the human achievement of deriving the same laws.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key limitations include tendency to favor existing patterns (bias towards rediscovery), dependence on the quality and completeness of axiomatic knowledge, and difficulty in demonstrating genuinely novel, non-derivable discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1266.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta neural theorem prover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta AI's neural theorem prover</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural theorem-proving system that automates aspects of mathematical proof search and has solved multiple International Math Olympiad (IMO) problems, surpassing previous ML systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Advancing mathematics by guiding human intuition with ai</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Meta neural theorem prover</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A neural-guided theorem-proving architecture (combining neural networks with symbolic/logic search heuristics) capable of proposing and checking proof steps, demonstrated on challenging benchmark problems (IMO problems).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (theorem proving)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automated solution and proof-generation for difficult competition-level math problems (10 IMO problems solved), illustrating automation of aspects of human mathematical creativity and guidance of human intuition.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>significant scientific breakthrough</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review highlights that the system 'successfully solved 10 International Math Olympiad (IMO) problems, far exceeding the performance of previous ML systems', framing this as a notable advance in automating theorem proving.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarking on standard problem sets (IMO problems), counting number of problems solved, and qualitative assessment of produced proofs' correctness and usefulness to mathematicians.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Formal verification of produced proofs (checking logical correctness), peer review and expert assessment by mathematicians, and comparisons to prior ML baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by the system's ability to handle problems substantially harder than prior benchmarks and to produce proofs that advance mathematical methods; novelty also in capacity to complement human intuition.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Number of IMO problems solved (10) is used as a concrete performance metric in the review; relative improvement over previous systems noted qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The system is described as guiding human intuition and automating aspects of theorem proving; comparisons emphasize that ML can complement human mathematicians rather than wholly replace them.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Solved 10 IMO problems (absolute count reported in review).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include interpretability of learned heuristics, dependence on curated problem distributions, and the gap between solving benchmark problems and producing original, human-level mathematical creativity.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1266.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepMind math collaboration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepMind collaboration yielding new mathematical methods (knot and representation theory)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A collaborative effort where ML techniques suggested proofs and discovered new connections in areas like knot theory and representation theory, complementing human mathematicians' work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Advancing mathematics by guiding human intuition with ai</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepMind mathematical-discovery systems</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ML systems (likely combining deep learning and symbolic methods) used to search mathematical structures, suggest conjectures/proofs, and uncover connections in advanced mathematical domains when paired with human expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (knot theory, representation theory)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>ML-assisted discovery of new connections and constructive suggestions for proofs in advanced mathematical areas; used as a complement to human-led research to accelerate insight generation.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>significant scientific breakthrough</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review reports that collaboration with DeepMind 'resulted in ML contributing to new mathematical methods' and 'discovered new connections', which is presented as a substantive advance in mathematical research capability.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Validation by mathematicians through rigorous proof construction, peer-reviewed publication of methods and results, and qualitative appraisal of novel insights generated.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Human verification of ML-suggested proofs/connections, formal mathematical proof when possible, and community acceptance via publication.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by whether ML-suggested connections were previously unknown and whether they led to publishable mathematical advances; novelty is established through human validation of new theorems or methods.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: ability to open new frontiers and produce methods that guided mathematicians; no numeric metrics provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper emphasizes ML as a complement to human intuition—ML suggests directions while human mathematicians refine and validate results; the discoveries are compared in terms of augmentation rather than replacement.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include translating ML outputs into rigorous human-understandable proofs and ensuring the originality of discovered connections rather than rediscoveries or reformulations.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1266.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold (DeepMind protein-structure predictor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep-learning model that predicts protein three-dimensional structures from amino-acid sequences with high accuracy by leveraging multiple-sequence alignment biases and equivariant architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Highly accurate protein structure prediction with alphafold.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A deep neural network architecture that integrates evolutionary information (MSAs), structural priors (3D equivariance), and attention-based components to predict atomic-level protein structures from sequence alone.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Structural biology / protein folding</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Accurate prediction of protein 3D structures at scale, enabling discoveries in biology and enabling downstream design and interpretation tasks; credited in the review as transformative for structural biology.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformative</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper cites AlphaFold as a major advance in structural biology and mentions the Chemistry Nobel prize as evidence of ML's transformative impact; AlphaFold's ability to reliably predict structures is presented as enabling new scientific work.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarking predictive accuracy against experimentally determined structures (implicit in the review), community challenges and comparative assessments, and downstream utility in structural biology tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison to experimentally solved structures (X-ray/cryo-EM/NMR), benchmarking challenges (e.g., CASP—implied), peer-reviewed publication and community uptake.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty judged by accuracy and breadth of predictions and the extent to which AlphaFold enabled new biological hypotheses and applications rather than incremental improvements over prior methods.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: described as 'highly accurate' and associated with major recognition (Nobel prize); no specific numeric success rates provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>AlphaFold's automated predictions supplanted many laborious experimental structure-determination steps, enabling discoveries that would be slow or infeasible manually; the review frames this as accelerating human science.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review notes that large pre-trained models may provide limited mechanistic insight; explainability and limits of generalization remain challenges despite high predictive accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1266.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous chemical research (LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Systems that combine large language models with laboratory automation to design, plan and execute chemical experiments in a closed-loop, enabling autonomous hypothesis generation and testing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-driven autonomous chemical research systems</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Architectures that use LLMs to parse literature, propose experimental plans, translate proposals into lab instructions and close the loop with automated experimentation platforms; combines generative language models, task-specific tools, and lab automation.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry / automated experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automation of the design and execution of chemical experiments, generation of novel candidate reactions or molecules and iterative optimization of experiments with reduced human intervention; presented as accelerating discovery in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformative</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review treats autonomous, LLM-driven research as extending the frontier of how experiments are planned and executed, enabling faster exploration of chemical space and thus being characterized as transformative in approach.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Improvement of experimental objectives (e.g., materials properties or reaction yields), movement of Pareto front (self-driving lab example), comparison to human-designed experiments, and demonstration of automation efficacy.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental validation of suggested reactions/compounds, comparison of automated optimization results to human benchmarks, and publication/peer review of autonomous lab outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by the degree to which the autonomous system discovers candidates or experimental strategies not previously reported and by improvement in experimental objectives through closed-loop optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative claims of accelerating research and moving Pareto fronts (self-driving lab example); specific numeric metrics are reported in the cited primary works but not enumerated in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review positions these systems as augmenting human experimenters by automating routine parts and exploring larger experimental spaces; they may produce candidates humans would not prioritize but typically require human validation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include safe and reliable lab automation, LLM hallucinations or incorrect plans, data scarcity/quality, and the need for rigorous experimental validation and ethical oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1266.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPOCK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SPOCK (supervised classifier for multi-planet system stability)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised classifier that predicts the long-term dynamical stability of compact multi-planet systems using short-term simulations, enabling efficient assessment of system stability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting the long-term stability of compact multiplanet systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SPOCK</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A supervised ML classifier trained on short-term orbital simulation data to predict long-term stability outcomes for multi-planet systems, generalizing to larger or different configurations than those in training.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Astrophysics / planetary dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Enables prediction of long-term dynamical stability without needing costly long integrations, thus facilitating studies of planetary system architectures and aiding exoplanet detection/characterization workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>incremental</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review frames SPOCK as an efficiency/enabling tool ('predicts long-term stability... using short-term simulations') that improves computational feasibility rather than as producing fundamentally new physical laws, aligning with an 'incremental' categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmarking classifier accuracy against long-term N-body integrations, testing generalization to different system sizes and configurations, and computational performance comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison of ML-predicted stability labels to results from long-term numerical integrations (ground-truth simulations) and cross-validation on simulated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by generalization capability (predicting stability for larger systems) and computational speedups enabling new parameter scans; not novel as a physical discovery but novel as a methodological tool.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Reported improvements in computational efficiency and successful generalization in demonstrations (specific numeric values are in the cited primary work but not detailed in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include ensuring classifier accuracy across wide parameter regimes, interpretability of failure modes, and the need for careful benchmarking against full integrations to avoid false conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1266.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LHC automated algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated algorithms used in Large Hadron Collider analyses (event selection/analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated and ML-driven algorithms used to process extremely large particle-collision datasets, which were central to discoveries like the Higgs boson and will be essential at higher collision rates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LHC event-analysis ML algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A suite of automated algorithms and ML classifiers used for event selection, background rejection and signal extraction in high-energy physics datasets; architectures include supervised classifiers and anomaly detection tailored to detector outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>High-energy physics (particle physics)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>These automated systems were central to the analysis pipelines that led to discoveries such as the Higgs boson and are expected to be critical for future discoveries as data volumes increase significantly.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>supportive</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review describes automated algorithms as 'central to the discovery of the Higgs boson' and essential for processing data volumes; their role is described as enabling and supportive of human-driven scientific inference rather than as independent discovery agents.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Statistical significance testing (p-values, sigma levels), classifier performance metrics (ROC, precision/recall), and reproducibility across detectors/analyses in collaborations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Rigorous statistical analysis, cross-checks, independent analyses by different teams, and peer-review culminating in experimental confirmation (collaborative publications).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by the capability to find signals in massive noisy datasets and by enabling discoveries that would be impractical with manual methods; not typically novel in terms of new physical laws produced by the algorithms alone.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Experimentally reported statistical significance levels for discoveries (e.g., Higgs observation at ~5σ in original studies—cited conceptually but original numbers not given in this review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The review positions automated algorithms as essential to achieving discoveries that would be impossible or impractically slow by human analysis alone, emphasizing a collaborative relationship.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include managing biases, explainability of classifiers, ensuring robustness to detector/systematic effects, and the need for thorough validation to avoid false discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1266.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e1266.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Google brain-mapping AI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Google AI brain-tissue reconstruction pipeline (300M images)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI pipeline used by Google researchers to process ~300 million brain images to produce the largest-ever interactive 3D brain tissue model, enabling large-scale connectomics and brain-mapping research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Google brain-tissue image-processing AI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Large-scale image-recognition and reconstruction pipeline (likely convolutional neural networks and large-scale stitching/segmentation methods) to assemble serial-section brain microscopy into a coherent 3D model at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Neuroscience / connectomics</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Construction of a highly accurate 3D brain tissue model from hundreds of millions of images, supporting pattern detection relevant to neurological disorders and providing a resource for downstream scientific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformative</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The review describes this effort as producing 'the largest-ever interactive 3D brain tissue model' and considers it 'crucial for understanding neurological disorders', indicating transformative impact on data availability and scale of analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Assessment of reconstruction fidelity, segmentation accuracy against human annotations, downstream utility in neuroscientific analyses, and public availability of the dataset for community use.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Comparison to manual/human annotation benchmarks, biological plausibility checks, and enabling subsequent experimentally-validated hypotheses in neuroscience.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty comes from unprecedented scale and integration of imaging data to produce resources not previously available rather than from a single theoretical insight.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative: scale of dataset (300 million images) and community availability; no further numeric impact metrics provided in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Paper highlights that ML enables reconstruction at scales impossible manually, reducing direct human observation and interpretation but requiring human oversight for scientific interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Concerns noted include reduced human understanding of ML-made discoveries, difficulty interpreting black-box segmentation decisions, and the need for validation against experimental/biological ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Decoding complexity: how machine learning is redefining scientific discovery', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A deep learning approach to antibiotic discovery. <em>(Rating: 2)</em></li>
                <li>Evolving scientific discovery by unifying data and background knowledge with ai hilbert <em>(Rating: 2)</em></li>
                <li>Combining data and theory for derivable scientific discovery with ai-descartes. <em>(Rating: 2)</em></li>
                <li>Advancing mathematics by guiding human intuition with ai <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with alphafold. <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Predicting the long-term stability of compact multiplanet systems. <em>(Rating: 2)</em></li>
                <li>Discovery of a structural class of antibiotics with explainable deep learning. <em>(Rating: 2)</em></li>
                <li>A self-driving laboratory advances the pareto front for material properties. <em>(Rating: 1)</em></li>
                <li>Magnetic control of tokamak plasmas through deep reinforcement learning. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1266",
    "paper_id": "paper-269614170",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "Halicin (DL antibiotic)",
            "name_full": "Halicin (discovered by a deep-learning antibiotic discovery pipeline)",
            "brief_description": "A novel antibiotic compound identified by a deep-learning model that screened large chemical spaces and whose activity was validated experimentally against antibiotic-resistant bacteria.",
            "citation_title": "A deep learning approach to antibiotic discovery.",
            "mention_or_use": "mention",
            "system_name": "Deep-learning antibiotic discovery pipeline (Stokes et al. style)",
            "system_description": "A supervised deep-learning model trained on molecular descriptors and known antibacterial activity to predict candidate small molecules; combined with in silico screening and experimental follow-up to validate biological activity. Described in the paper as an explainable deep-learning approach capable of prioritizing novel chemical scaffolds.",
            "discovery_domain": "Chemistry / Biology (drug discovery)",
            "discovery_description": "Identification of a previously unknown class of antibiotic molecules (exemplified by 'halicin') that show activity against antibiotic-resistant bacteria, discovered by screening large chemical libraries using a deep neural network and validated experimentally.",
            "discovery_type": "groundbreaking discoveries",
            "discovery_type_justification": "The paper cites this work as an example of 'groundbreaking discoveries, such as a new class of antibiotics', justifying the label by the practical demonstration of a novel compound with experimentally validated antibacterial activity that was not previously known.",
            "evaluation_methods": "In-silico screening performance (model ranking of candidates), retrospective analysis against known actives/inactives, and crucially experimental assays assessing antibacterial activity; publication and peer-review (Cell) as additional evaluation.",
            "validation_approaches": "Experimental biological validation (in vitro assays demonstrating bactericidal activity against resistant strains) followed by peer-reviewed publication; comparison of model predictions to experimental outcomes.",
            "novelty_assessment": "Novelty is assessed by the chemical novelty of predicted scaffolds relative to training data and by experimental demonstration of activity against resistant bacteria; the paper emphasizes that ML uncovered molecules unknown to prior literature.",
            "impact_metrics": "Qualitative: demonstration of activity against antibiotic-resistant strains and publication in a high-impact venue; no numerical discovery success rate presented in this review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The review positions the ML-driven discovery as finding molecules that were not previously known, complementing human-led medicinal chemistry by prioritizing candidates not obvious to humans; ML is presented as able to navigate larger chemical spaces than manual approaches.",
            "success_rate": null,
            "challenges_limitations": "The review highlights issues such as dataset bias, explainability (black-box models), and the need for experimental follow-up; it notes ML may be biased towards patterns present in training data which can limit novelty.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.0",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "AI-Hilbert",
            "name_full": "AI-Hilbert (IBM 'AI scientist')",
            "brief_description": "An 'AI scientist' system that transforms theories and data into new, consistent mathematical models by automating hypothesis generation and testing, integrating background knowledge with data.",
            "citation_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert",
            "mention_or_use": "mention",
            "system_name": "AI-Hilbert",
            "system_description": "A framework combining background knowledge (axioms/theory) and data to produce derivable mathematical models; automates hypothesis generation, symbolic/model search and consistency checking against data, aiming to produce interpretable, derivable models.",
            "discovery_domain": "General scientific modelling / mathematics / physics",
            "discovery_description": "Transforms existing theories and large datasets into new consistent mathematical models, uncovers patterns or models that reconcile data and theoretical constraints, and automates parts of the model-discovery pipeline.",
            "discovery_type": "transformational",
            "discovery_type_justification": "The review describes AI-Hilbert as an 'AI scientist' that 'transforms existing theories and data into new, consistent mathematical models' and as accelerating discovery by automating hypothesis generation and testing, motivating the 'transformational' label.",
            "evaluation_methods": "Assessment of consistency between discovered models and input data/theory, ability to rediscover known laws, model selection criteria that balance fit and derivability, and peer-reviewed demonstration (Nat. Commun. reference).",
            "validation_approaches": "Benchmarking by rediscovery of known laws, comparison to alternative candidate formulas, logical/axiomatic consistency checks, and peer review/publication.",
            "novelty_assessment": "Novelty judged by whether generated models go beyond rediscovering known relationships and by the system's ability to manage conflicting data to produce new consistent models; the review notes such systems often reproduce known laws which limits novelty.",
            "impact_metrics": "Qualitative: capability to derive interpretable, derivable models and accelerate hypothesis formation; no numeric impact metrics provided in the review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper notes these systems can reproduce human-discovered laws (rediscoveries) and act as supportive/automating tools for scientists, but often confirm known theories rather than producing entirely novel insights without human interpretation.",
            "success_rate": null,
            "challenges_limitations": "Limitations include tendency to rediscover existing laws, dependence on encoded axioms/background knowledge, sensitivity to available data, and challenges in assessing when a model is genuinely novel versus a re-expression of known theory.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.1",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "AI-Descartes (Cornelio et al.)",
            "name_full": "AI-Descartes (combining data and theory for derivable discovery)",
            "brief_description": "A method combining axiomatic knowledge with experimental data using symbolic regression and logical reasoning to derive scientific models and distinguish competing formulas, demonstrated by rediscovering known physical laws.",
            "citation_title": "Combining data and theory for derivable scientific discovery with ai-descartes.",
            "mention_or_use": "mention",
            "system_name": "AI-Descartes",
            "system_description": "Hybrid approach that integrates axiomatic/theoretical constraints with data-driven symbolic regression to produce derivable formulae; employs logical reasoning to select among candidate symbolic models.",
            "discovery_domain": "Physics / mathematical model discovery",
            "discovery_description": "Rediscovery of known physical laws (e.g., Kepler's third law, Einstein's time-dilation law) from limited data by combining axiomatic knowledge and symbolic regression, and the ability to discriminate between competing formulae.",
            "discovery_type": "rediscovered (replicative)",
            "discovery_type_justification": "The review explicitly reports that such tools 'have rediscovered laws like Kepler's third law and Einstein's time-dilation law', indicating the primary outcome was reproducing known results rather than novel laws.",
            "evaluation_methods": "Comparative evaluation of candidate symbolic expressions against ground-truth physical laws, selection among competing formulas using logical/axiomatic consistency and fit to data, and case studies demonstrating recovery of established laws.",
            "validation_approaches": "Comparison to known analytical laws (ground truth), statistical fit to experimental data, and demonstration on limited-data scenarios showing correct recovery of known formulas.",
            "novelty_assessment": "Novelty is low in the rediscovery examples (they reproduce established laws), but novelty lies in methodological ability to combine axioms with sparse data to derive interpretable formulas.",
            "impact_metrics": "Qualitative demonstration of rediscovery capability; no numeric impact metrics provided in the review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper frames these systems as often confirming known theories and acting supportively rather than replacing human creativity; their success is compared to the human achievement of deriving the same laws.",
            "success_rate": null,
            "challenges_limitations": "Key limitations include tendency to favor existing patterns (bias towards rediscovery), dependence on the quality and completeness of axiomatic knowledge, and difficulty in demonstrating genuinely novel, non-derivable discoveries.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.2",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Meta neural theorem prover",
            "name_full": "Meta AI's neural theorem prover",
            "brief_description": "A neural theorem-proving system that automates aspects of mathematical proof search and has solved multiple International Math Olympiad (IMO) problems, surpassing previous ML systems.",
            "citation_title": "Advancing mathematics by guiding human intuition with ai",
            "mention_or_use": "mention",
            "system_name": "Meta neural theorem prover",
            "system_description": "A neural-guided theorem-proving architecture (combining neural networks with symbolic/logic search heuristics) capable of proposing and checking proof steps, demonstrated on challenging benchmark problems (IMO problems).",
            "discovery_domain": "Mathematics (theorem proving)",
            "discovery_description": "Automated solution and proof-generation for difficult competition-level math problems (10 IMO problems solved), illustrating automation of aspects of human mathematical creativity and guidance of human intuition.",
            "discovery_type": "significant scientific breakthrough",
            "discovery_type_justification": "The review highlights that the system 'successfully solved 10 International Math Olympiad (IMO) problems, far exceeding the performance of previous ML systems', framing this as a notable advance in automating theorem proving.",
            "evaluation_methods": "Benchmarking on standard problem sets (IMO problems), counting number of problems solved, and qualitative assessment of produced proofs' correctness and usefulness to mathematicians.",
            "validation_approaches": "Formal verification of produced proofs (checking logical correctness), peer review and expert assessment by mathematicians, and comparisons to prior ML baselines.",
            "novelty_assessment": "Novelty is assessed by the system's ability to handle problems substantially harder than prior benchmarks and to produce proofs that advance mathematical methods; novelty also in capacity to complement human intuition.",
            "impact_metrics": "Number of IMO problems solved (10) is used as a concrete performance metric in the review; relative improvement over previous systems noted qualitatively.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The system is described as guiding human intuition and automating aspects of theorem proving; comparisons emphasize that ML can complement human mathematicians rather than wholly replace them.",
            "success_rate": "Solved 10 IMO problems (absolute count reported in review).",
            "challenges_limitations": "Limitations include interpretability of learned heuristics, dependence on curated problem distributions, and the gap between solving benchmark problems and producing original, human-level mathematical creativity.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.3",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DeepMind math collaboration",
            "name_full": "DeepMind collaboration yielding new mathematical methods (knot and representation theory)",
            "brief_description": "A collaborative effort where ML techniques suggested proofs and discovered new connections in areas like knot theory and representation theory, complementing human mathematicians' work.",
            "citation_title": "Advancing mathematics by guiding human intuition with ai",
            "mention_or_use": "mention",
            "system_name": "DeepMind mathematical-discovery systems",
            "system_description": "ML systems (likely combining deep learning and symbolic methods) used to search mathematical structures, suggest conjectures/proofs, and uncover connections in advanced mathematical domains when paired with human expertise.",
            "discovery_domain": "Mathematics (knot theory, representation theory)",
            "discovery_description": "ML-assisted discovery of new connections and constructive suggestions for proofs in advanced mathematical areas; used as a complement to human-led research to accelerate insight generation.",
            "discovery_type": "significant scientific breakthrough",
            "discovery_type_justification": "The review reports that collaboration with DeepMind 'resulted in ML contributing to new mathematical methods' and 'discovered new connections', which is presented as a substantive advance in mathematical research capability.",
            "evaluation_methods": "Validation by mathematicians through rigorous proof construction, peer-reviewed publication of methods and results, and qualitative appraisal of novel insights generated.",
            "validation_approaches": "Human verification of ML-suggested proofs/connections, formal mathematical proof when possible, and community acceptance via publication.",
            "novelty_assessment": "Novelty assessed by whether ML-suggested connections were previously unknown and whether they led to publishable mathematical advances; novelty is established through human validation of new theorems or methods.",
            "impact_metrics": "Qualitative: ability to open new frontiers and produce methods that guided mathematicians; no numeric metrics provided in the review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper emphasizes ML as a complement to human intuition—ML suggests directions while human mathematicians refine and validate results; the discoveries are compared in terms of augmentation rather than replacement.",
            "success_rate": null,
            "challenges_limitations": "Challenges include translating ML outputs into rigorous human-understandable proofs and ensuring the originality of discovered connections rather than rediscoveries or reformulations.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.4",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "AlphaFold",
            "name_full": "AlphaFold (DeepMind protein-structure predictor)",
            "brief_description": "A deep-learning model that predicts protein three-dimensional structures from amino-acid sequences with high accuracy by leveraging multiple-sequence alignment biases and equivariant architectures.",
            "citation_title": "Highly accurate protein structure prediction with alphafold.",
            "mention_or_use": "mention",
            "system_name": "AlphaFold",
            "system_description": "A deep neural network architecture that integrates evolutionary information (MSAs), structural priors (3D equivariance), and attention-based components to predict atomic-level protein structures from sequence alone.",
            "discovery_domain": "Structural biology / protein folding",
            "discovery_description": "Accurate prediction of protein 3D structures at scale, enabling discoveries in biology and enabling downstream design and interpretation tasks; credited in the review as transformative for structural biology.",
            "discovery_type": "transformative",
            "discovery_type_justification": "The paper cites AlphaFold as a major advance in structural biology and mentions the Chemistry Nobel prize as evidence of ML's transformative impact; AlphaFold's ability to reliably predict structures is presented as enabling new scientific work.",
            "evaluation_methods": "Benchmarking predictive accuracy against experimentally determined structures (implicit in the review), community challenges and comparative assessments, and downstream utility in structural biology tasks.",
            "validation_approaches": "Comparison to experimentally solved structures (X-ray/cryo-EM/NMR), benchmarking challenges (e.g., CASP—implied), peer-reviewed publication and community uptake.",
            "novelty_assessment": "Novelty judged by accuracy and breadth of predictions and the extent to which AlphaFold enabled new biological hypotheses and applications rather than incremental improvements over prior methods.",
            "impact_metrics": "Qualitative: described as 'highly accurate' and associated with major recognition (Nobel prize); no specific numeric success rates provided in the review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "AlphaFold's automated predictions supplanted many laborious experimental structure-determination steps, enabling discoveries that would be slow or infeasible manually; the review frames this as accelerating human science.",
            "success_rate": null,
            "challenges_limitations": "The review notes that large pre-trained models may provide limited mechanistic insight; explainability and limits of generalization remain challenges despite high predictive accuracy.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.5",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Autonomous chemical research (LLMs)",
            "name_full": "Autonomous chemical research with large language models",
            "brief_description": "Systems that combine large language models with laboratory automation to design, plan and execute chemical experiments in a closed-loop, enabling autonomous hypothesis generation and testing.",
            "citation_title": "Autonomous chemical research with large language models.",
            "mention_or_use": "mention",
            "system_name": "LLM-driven autonomous chemical research systems",
            "system_description": "Architectures that use LLMs to parse literature, propose experimental plans, translate proposals into lab instructions and close the loop with automated experimentation platforms; combines generative language models, task-specific tools, and lab automation.",
            "discovery_domain": "Chemistry / automated experimentation",
            "discovery_description": "Automation of the design and execution of chemical experiments, generation of novel candidate reactions or molecules and iterative optimization of experiments with reduced human intervention; presented as accelerating discovery in chemistry.",
            "discovery_type": "transformative",
            "discovery_type_justification": "The review treats autonomous, LLM-driven research as extending the frontier of how experiments are planned and executed, enabling faster exploration of chemical space and thus being characterized as transformative in approach.",
            "evaluation_methods": "Improvement of experimental objectives (e.g., materials properties or reaction yields), movement of Pareto front (self-driving lab example), comparison to human-designed experiments, and demonstration of automation efficacy.",
            "validation_approaches": "Experimental validation of suggested reactions/compounds, comparison of automated optimization results to human benchmarks, and publication/peer review of autonomous lab outcomes.",
            "novelty_assessment": "Novelty is assessed by the degree to which the autonomous system discovers candidates or experimental strategies not previously reported and by improvement in experimental objectives through closed-loop optimization.",
            "impact_metrics": "Qualitative claims of accelerating research and moving Pareto fronts (self-driving lab example); specific numeric metrics are reported in the cited primary works but not enumerated in this review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The review positions these systems as augmenting human experimenters by automating routine parts and exploring larger experimental spaces; they may produce candidates humans would not prioritize but typically require human validation.",
            "success_rate": null,
            "challenges_limitations": "Challenges include safe and reliable lab automation, LLM hallucinations or incorrect plans, data scarcity/quality, and the need for rigorous experimental validation and ethical oversight.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.6",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "SPOCK",
            "name_full": "SPOCK (supervised classifier for multi-planet system stability)",
            "brief_description": "A supervised classifier that predicts the long-term dynamical stability of compact multi-planet systems using short-term simulations, enabling efficient assessment of system stability.",
            "citation_title": "Predicting the long-term stability of compact multiplanet systems.",
            "mention_or_use": "mention",
            "system_name": "SPOCK",
            "system_description": "A supervised ML classifier trained on short-term orbital simulation data to predict long-term stability outcomes for multi-planet systems, generalizing to larger or different configurations than those in training.",
            "discovery_domain": "Astrophysics / planetary dynamics",
            "discovery_description": "Enables prediction of long-term dynamical stability without needing costly long integrations, thus facilitating studies of planetary system architectures and aiding exoplanet detection/characterization workflows.",
            "discovery_type": "incremental",
            "discovery_type_justification": "The review frames SPOCK as an efficiency/enabling tool ('predicts long-term stability... using short-term simulations') that improves computational feasibility rather than as producing fundamentally new physical laws, aligning with an 'incremental' categorization.",
            "evaluation_methods": "Benchmarking classifier accuracy against long-term N-body integrations, testing generalization to different system sizes and configurations, and computational performance comparisons.",
            "validation_approaches": "Comparison of ML-predicted stability labels to results from long-term numerical integrations (ground-truth simulations) and cross-validation on simulated datasets.",
            "novelty_assessment": "Novelty assessed by generalization capability (predicting stability for larger systems) and computational speedups enabling new parameter scans; not novel as a physical discovery but novel as a methodological tool.",
            "impact_metrics": "Reported improvements in computational efficiency and successful generalization in demonstrations (specific numeric values are in the cited primary work but not detailed in the review).",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": null,
            "challenges_limitations": "Challenges include ensuring classifier accuracy across wide parameter regimes, interpretability of failure modes, and the need for careful benchmarking against full integrations to avoid false conclusions.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.7",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "LHC automated algorithms",
            "name_full": "Automated algorithms used in Large Hadron Collider analyses (event selection/analysis)",
            "brief_description": "Automated and ML-driven algorithms used to process extremely large particle-collision datasets, which were central to discoveries like the Higgs boson and will be essential at higher collision rates.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "LHC event-analysis ML algorithms",
            "system_description": "A suite of automated algorithms and ML classifiers used for event selection, background rejection and signal extraction in high-energy physics datasets; architectures include supervised classifiers and anomaly detection tailored to detector outputs.",
            "discovery_domain": "High-energy physics (particle physics)",
            "discovery_description": "These automated systems were central to the analysis pipelines that led to discoveries such as the Higgs boson and are expected to be critical for future discoveries as data volumes increase significantly.",
            "discovery_type": "supportive",
            "discovery_type_justification": "The review describes automated algorithms as 'central to the discovery of the Higgs boson' and essential for processing data volumes; their role is described as enabling and supportive of human-driven scientific inference rather than as independent discovery agents.",
            "evaluation_methods": "Statistical significance testing (p-values, sigma levels), classifier performance metrics (ROC, precision/recall), and reproducibility across detectors/analyses in collaborations.",
            "validation_approaches": "Rigorous statistical analysis, cross-checks, independent analyses by different teams, and peer-review culminating in experimental confirmation (collaborative publications).",
            "novelty_assessment": "Novelty is assessed by the capability to find signals in massive noisy datasets and by enabling discoveries that would be impractical with manual methods; not typically novel in terms of new physical laws produced by the algorithms alone.",
            "impact_metrics": "Experimentally reported statistical significance levels for discoveries (e.g., Higgs observation at ~5σ in original studies—cited conceptually but original numbers not given in this review).",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The review positions automated algorithms as essential to achieving discoveries that would be impossible or impractically slow by human analysis alone, emphasizing a collaborative relationship.",
            "success_rate": null,
            "challenges_limitations": "Limitations include managing biases, explainability of classifiers, ensuring robustness to detector/systematic effects, and the need for thorough validation to avoid false discoveries.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.8",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Google brain-mapping AI",
            "name_full": "Google AI brain-tissue reconstruction pipeline (300M images)",
            "brief_description": "An AI pipeline used by Google researchers to process ~300 million brain images to produce the largest-ever interactive 3D brain tissue model, enabling large-scale connectomics and brain-mapping research.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Google brain-tissue image-processing AI",
            "system_description": "Large-scale image-recognition and reconstruction pipeline (likely convolutional neural networks and large-scale stitching/segmentation methods) to assemble serial-section brain microscopy into a coherent 3D model at scale.",
            "discovery_domain": "Neuroscience / connectomics",
            "discovery_description": "Construction of a highly accurate 3D brain tissue model from hundreds of millions of images, supporting pattern detection relevant to neurological disorders and providing a resource for downstream scientific discoveries.",
            "discovery_type": "transformative",
            "discovery_type_justification": "The review describes this effort as producing 'the largest-ever interactive 3D brain tissue model' and considers it 'crucial for understanding neurological disorders', indicating transformative impact on data availability and scale of analysis.",
            "evaluation_methods": "Assessment of reconstruction fidelity, segmentation accuracy against human annotations, downstream utility in neuroscientific analyses, and public availability of the dataset for community use.",
            "validation_approaches": "Comparison to manual/human annotation benchmarks, biological plausibility checks, and enabling subsequent experimentally-validated hypotheses in neuroscience.",
            "novelty_assessment": "Novelty comes from unprecedented scale and integration of imaging data to produce resources not previously available rather than from a single theoretical insight.",
            "impact_metrics": "Qualitative: scale of dataset (300 million images) and community availability; no further numeric impact metrics provided in the review.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Paper highlights that ML enables reconstruction at scales impossible manually, reducing direct human observation and interpretation but requiring human oversight for scientific interpretation.",
            "success_rate": null,
            "challenges_limitations": "Concerns noted include reduced human understanding of ML-made discoveries, difficulty interpreting black-box segmentation decisions, and the need for validation against experimental/biological ground truth.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1266.9",
            "source_info": {
                "paper_title": "Decoding complexity: how machine learning is redefining scientific discovery",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A deep learning approach to antibiotic discovery.",
            "rating": 2,
            "sanitized_title": "a_deep_learning_approach_to_antibiotic_discovery"
        },
        {
            "paper_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert",
            "rating": 2,
            "sanitized_title": "evolving_scientific_discovery_by_unifying_data_and_background_knowledge_with_ai_hilbert"
        },
        {
            "paper_title": "Combining data and theory for derivable scientific discovery with ai-descartes.",
            "rating": 2,
            "sanitized_title": "combining_data_and_theory_for_derivable_scientific_discovery_with_aidescartes"
        },
        {
            "paper_title": "Advancing mathematics by guiding human intuition with ai",
            "rating": 2,
            "sanitized_title": "advancing_mathematics_by_guiding_human_intuition_with_ai"
        },
        {
            "paper_title": "Highly accurate protein structure prediction with alphafold.",
            "rating": 2,
            "sanitized_title": "highly_accurate_protein_structure_prediction_with_alphafold"
        },
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Predicting the long-term stability of compact multiplanet systems.",
            "rating": 2,
            "sanitized_title": "predicting_the_longterm_stability_of_compact_multiplanet_systems"
        },
        {
            "paper_title": "Discovery of a structural class of antibiotics with explainable deep learning.",
            "rating": 2,
            "sanitized_title": "discovery_of_a_structural_class_of_antibiotics_with_explainable_deep_learning"
        },
        {
            "paper_title": "A self-driving laboratory advances the pareto front for material properties.",
            "rating": 1,
            "sanitized_title": "a_selfdriving_laboratory_advances_the_pareto_front_for_material_properties"
        },
        {
            "paper_title": "Magnetic control of tokamak plasmas through deep reinforcement learning.",
            "rating": 1,
            "sanitized_title": "magnetic_control_of_tokamak_plasmas_through_deep_reinforcement_learning"
        }
    ],
    "cost": 0.0248465,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Decoding complexity: how machine learning is redefining scientific discovery
25 Apr 2025</p>
<p>Ricardo Vinuesa rvinuesa@mech.kth.se 
FLOW, Engineering Mechanics
KTH Royal Institute of Technology
StockholmSweden</p>
<p>Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Paola Cinnella 
Institut Jean le Rond D'Alembert
Sorbonne Universit é
France</p>
<p>Jean Rabault 
IT Department
Norwegian Meteorological Institute
0313OsloNorway</p>
<p>Hossein Azizpour 
Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Robotics, Perception and Learning
KTH Royal Institute of Technology
StockholmSweden</p>
<p>Stefan Bauer 
Information and Technology
TUM School of Computation
Technical University Munich
MunichGermany</p>
<p>Helmholtz AI
Helmholtz Center Munich
MunichGermany</p>
<p>Bingni W Brunton sbrunton@uw.edu 
Department of Biology
University of Washington
98195SeattleWAUSA</p>
<p>Arne Elofsson 
Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Dept. of Biochemistry and Biophysics and Science for Life Laboratory
Stockholm University
171 21Solna</p>
<p>Elias Jarlebring 
Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Dept. Mathematics
KTH Royal Institute of Technology
100 44 StockholmSweden</p>
<p>Hedvig Kjellstr Öm 
Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Robotics, Perception and Learning
KTH Royal Institute of Technology
StockholmSweden</p>
<p>Stefano Markidis 
Swedish e-Science Research Centre
StockholmSeRCSweden</p>
<p>Department of Computer Science
KTH Royal Institute of Technology
StockholmSweden</p>
<p>David Marlevi 
Dept. Molecular Medicine and Surgery
Karolinska Institutet
171 77StockholmSweden</p>
<p>Inst. for Medical Engineering and Science
Massachusetts Institute of Technology
02139CambridgeMAUSA</p>
<p>Javier García-Martínez 
Departamento de Química Inorg ánica
Universidad de Alicante
AlicanteSpain</p>
<p>Steven L Brunton 
Department of Mechanical Engineering
University of Washington
98195SeattleWAUSA</p>
<p>Decoding complexity: how machine learning is redefining scientific discovery
25 Apr 202582E77CE8EC2CF84630DCADD3824E98ADarXiv:2405.04161v2[cs.LG]machine learning (ML)deep learning (DL)artificial intelligence (AI)scientific discoverycomplexityphysicslife sciencescomputer science
As modern scientific instruments generate vast amounts of data and the volume of information in the scientific literature continues to grow, machine learning (ML) has become an essential tool for organising, analysing, and interpreting these complex datasets.This paper explores the transformative role of ML in accelerating breakthroughs across a range of scientific disciplines.By presenting key examples -such as brain mapping and exoplanet detection -we demonstrate how ML is reshaping scientific research.We also explore different scenarios where different levels of knowledge of the underlying phenomenon are available, identifying strategies to overcome limitations and unlock the full potential of ML.Despite its advances, the growing reliance on ML poses challenges for research applications and rigorous validation of discoveries.We argue that even with these challenges, ML is poised to disrupt traditional methodologies and advance the boundaries of knowledge by enabling researchers to tackle increasingly complex problems.Thus, the scientific community can move beyond the necessary traditional oversimplifications to embrace the full complexity of natural systems, ultimately paving the way for interdisciplinary breakthroughs and innovative solutions to humanity's most pressing challenges.</p>
<p>Introduction</p>
<p>Machines have played a critical role in scientific discovery (ı.e. to obtain fundamental and formalized knowledge about Nature) by providing the tools to observe, measure, and analyze natural phenomena.Scientific instruments, such as telescopes and microscopes, have historically enabled groundbreaking discoveries by revealing details invisible to the naked eye, expanding our understanding of the universe and the microscopic world [1].With the advent of modern scientific instruments, including DNA sequencers, astronomical observatories, and highresolution imaging devices, research facilities are producing terabytes or even petabytes of information.As data volumes grow, computers play a critical role in organizing, analyzing, and interpreting this information.Advanced computational methods help to reduce the complexity of the data, making it possible to extract meaningful insights [2,3].However, even with the most advanced computers, the sheer volume of data generated by large-scale projects such as the Large Hadron Collider (LHC) and the Square Kilometre Array (SKA), and the vast amount of information available in the scientific literature, make traditional analysis methods impractical.Complex problems such as weather forecasting, drug discovery, and genomic analysis often involve highly complex data sets and processes that cannot be efficiently managed without the assistance of machine learning (ML), which can help sift through massive data streams, identify patterns, and extract valuable insights that would be impossible for humans or traditional computational methods alone.Complexity in these problems arises from non-linearity, high dimensionality, and multiscale dynamics, posing significant challenges for traditional mathematical tools and even recent simulation-based approaches.Despite advancements in simulations and big data, we still struggle to fully understand phenomena like turbulence or biological processes at a deeper level.Advanced ML tools are also improving decision-making, enabling faster and more accurate interpretations of complex phenomena, and addressing challenges in diverse scientific fields [4].However, it also introduces some challenges and the need for ethical guidelines to ensure the appropriate use of ML for scientific research [5].A key issue is algorithmic bias, which can distort outcomes and lead to incorrect conclusions, particularly in areas like health care, where biased predictions can impact patient care or drug development.Additionally, the black-box nature of ML models complicates transparency, making it hard for researchers to verify decisions.Lastly, data ownership and privacy concerns arise, especially with sensitive data like genetic or health records.These issues require the development of robust ethical guidelines to ensure that ML contributes to science in a fair, transparent, and socially responsible way [6].</p>
<p>In this work, we explore the potential of ML and artificial intelligence (AI) in three types of scientific problems: (i) those where all governing equations are known, (ii) those with partial knowledge and (iii) those where little is known.We illustrate this with examples from the physical and life sciences, including turbulent flows, dark matter, drug discovery, and brain research.Figure 1 summarizes how different uses of ML help address complexity in these areas.As discussed below, when the system complexity grows, the distinction between full, partial, and no knowledge of the governing equations becomes increasingly blurred, but ML plays a crucial role in tackling these challenges.A good example of a complex system with vast amounts of data that traditional tools cannot process efficiently is brain research.ML enables the reconstruction of countless brain slices into highly accurate three-dimensional (3D) maps.In a recent study, Google researchers used AI to process 300 million brain images from Harvard, creating the largest-ever interactive 3D brain tissue model, now available online.This innovation is crucial for understanding neurological disorders, as ML can detect patterns that traditional methods might miss, supporting early diagnosis and treatment planning [7].One of the most widespread applications of ML is in drug discovery, addressing the time and cost challenges of traditional methods.The drug-development process can take over a decade and billions of dollars due to the complexity of identifying viable candidates.ML is transforming this by rapidly analyzing vast biological and chemical data, uncovering patterns that might remain hidden, and streamlining the identification of promising candidates.Additionally, ML enhances predictive modeling, allowing researchers to forecast drug efficacy and safety earlier in the process.By enabling virtual screening of drug-target interactions, ML reduces the need for costly lab experiments and helps design more efficient clinical trials, accelerating development and optimizing resources [8].</p>
<p>Figure 2 provides a comprehensive visualisation of the key themes discussed in this paper, focusing on the role of machine learning (ML) in scientific discovery and the challenges it presents, particularly with respect to data.The top-left panel illustrates the significant increase in data generated by modern scientific instrumentation over time.Initially, humans organised and interpreted the data through manual analysis and generalisation.Since then, computational methods have facilitated the management of large amounts of data, contributing significantly to fields such as genomics, chemistry and mathematics.More recently, with the advent of large-scale scientific facilities such as CERN, ML techniques have become essential for processing vast amounts of data.This shift has reduced human involvement in direct observation and interpretation, raising concerns about our diminishing understanding of the discoveries made by these technologies.The top-right panel outlines four key challenges related to ML in science: data quality and availability, inherent biases, explainability, and the risk of overfitting.The bottom-left panel highlights a conceptual dilemma: while ML accelerates discovery, there is growing debate about what constitutes a true scientific breakthrough, and whether ML can only "rediscover" existing concepts rather than uncover new insights.Finally, the bottom-right panel emphasises the increasing need for high-quality data to enable new discoveries through ML, while highlighting the limitations imposed by our current gaps in scientific knowledge.All of these issues are discussed in detail in the following sections of this paper.</p>
<p>Artificial Intelligence is playing a transformative role in physics by improving data analysis, model development, and experimental interpretation.In astronomy, ML is improving the search for exoplanets by boosting the accuracy and efficiency of data analysis.AI-powered algorithms, particularly convolutional neural networks, can process massive data sets from telescopes to detect Earth-like exoplanets in noisy signals more precisely than traditional  methods.The transit method, which detects exoplanets by observing mini-eclipses as they pass in front of their stars, can be complicated by planetary interactions that disrupt periodicity.To address this, researchers from the University of Geneva, University of Bern, and Disaitek applied ML and image recognition techniques to predict these interactions.By training a neural network on numerous examples, they built a model capable of detecting subtle exoplanet signals that might be missed by traditional methods.Their work led to the discovery of exoplanets Kepler-1705b and Kepler-1705c, advancing our understanding of planetary systems [9].ML is also crucial in areas like the Standard Model of particle physics [9].Automated algorithms were central to the discovery of the Higgs boson [10], and future experiments will need to operate at higher energies and intensities, generating data volumes too large for traditional methods to handle.For instance, it is expected that the Large-Hadron Collider (LHC) will increase proton collision rates by an order of magnitude in the next decade, requiring data analysis tools such as ML, to identify trends, uncover hidden relationships, and design more effective experiments.</p>
<p>Another scientific area in which ML is increasingly assisting research is mathematics, in this case by improving the process of theorem proving, mathematical method development and discovery.ML systems have already demonstrated their ability to automate aspects of theorem proving; for example, Meta AI's neural theorem prover successfully solved 10 International Math Olympiad (IMO) problems, far exceeding the performance of previous ML systems.Another notable example is DeepMind's collaboration with mathematicians, which has resulted in ML contributing to new mathematical methods in knot theory and representation theory.Specifically, in 2021, ML was used in a new constructive way to suggest mathematical proofs.A collaboration between mathematicians and DeepMind demonstrated that ML can complement human intuition in proving or suggesting complex theorems.The team used ML to investigate long-standing conjectures, including the Kazhdan-Lusztig polynomials, and discovered new connections in knot theory.This illustrates AI's potential to accelerate mathematical research and open new frontiers [11].</p>
<p>Embracing complexity</p>
<p>Machine learning comprises a growing set of algorithms, enabled by high-performance computing and increasingly vast data, that show incredible promise for handling complexity [12,13].Neural networks, despite being governed by simple rules, can perform complex tasks for which no traditional algorithms exist.Although they are fully The need to have more and better data to be able to make scientific discoveries with ML as we have less knowledge on the subject of study observable and deterministic, we often cannot explain their decisions.However, they have led to groundbreaking discoveries, such as a new class of antibiotics [14].This creates challenges, such as the need for explainable AI (XAI) [15,16].Symbolic approaches, such as gene-expression programming, sparse regression, and sparse Bayesian learning [17][18][19], have been successful, but their complexity grows exponentially with the search-space size.Recent efforts to combine symbolic and deep-learning approaches have enabled advances, such as discovering new materials [20].This raises fundamental questions about the limits of ML in scientific discovery; for example, can a complex system understand its own complexity?And how much can AI discover beyond its training data [21]?These issues highlight the opportunities and challenges that data-driven methods bring to science.Some believe in the "unreasonable effectiveness of data" [22], particularly in deep learning [23], but the practical implications for future discoveries remain uncertain.A key question is whether ML can provide not only computational solutions but also fundamental scientific understanding.Note that ML's applications in science are not limited to discovery.For example, AI is revolutionizing optimization, laboratory automation, and solving governing equations, such as partial differential equations (PDEs).Recent studies [24] have focused on the potential of self-supervised learning in experiments and simulations (including representations of scientific data), while others [25] are exploring AI's role in formulating scientific questions.Note that the unique contribution of this work is the study of how ML can tackle complexity to reach scientific discoveries, acknowledging that different levels of knowledge of the governing equations (see Figure 1) will require completely different ML approaches.This may constitute a revolution in how we organize disciplines when using ML for scientific discovery, where apparently different communities may share many similarities in terms of how much is known regarding the governing equations and therefore in terms of the ML methods to be developed.</p>
<p>The emergence of scientific foundation models (SFMs) and large language models (LLMs) is further pushing the boundaries of ML methods.Foundation models are large machine-learning or deep-learning generative models trained on vast amounts of data so they can be applied on a wide range of cases.They predict masked data regions to learn associations, excelling in multiple tasks without large, labeled datasets.Despite risks like bias and transparency issues [26], foundation models have revolutionized AI, especially through chatbots like ChatGPT [27].LLMs now assist with tasks from writing and coding to guiding scientific experiments [28,29] and generating ideas [30].Foundation models also show promise in non-text-focused areas, such as protein-structure prediction [31], protein design [32] and climate simulations [33].An intriguing feature of foundation models, and particularly LLMs, is that they demostrate so-called "emergent abilities" [34,35].The term refers to unexpected, not explicitly programmed, capabilities that arise as model scale increases, and do not consist in mere extrapolations of smaller models' performance.Such abilities were first observed in complex natural systems, e.g.phase changes in materials, complex behavior in flocks of birds or fishes, as well as in computational systems such as cellular automata and agent-based models, and the term was originally popularized by the Nobel-prize winner P.W. Anderson [36].Examples of LLM emergent abilities include in-context learning, complex reasoning, and multi-step problem-solving, which are highly valuable for scientific research.Thank to this, LLMs are found to generalize to new tasks without prior examples (zero-shot learning) or with minimal data (few-shot learning), making them particularly useful in domains where data is scarce or highly specialized.More in general, they have the potential to aid hypothesis generation, automate literature reviews, predict protein structures, and accelerate scientific discovery, especially when combined with reinforcement learning (RL) and a suitable system of rewards/penalties to optimize specific scientific tasks, such as designing experiments or iteratively refining hypotheses based on feedback.Synergy with scientists may allow to leverage the models' reasoning capabilities in dynamic, real-world scenarios, enabling more efficient exploration of complex scientific problems.On the other hand, these abilities are often unpredictable and non-linear, raising challenges in reliability, interpretability, and ethical use.Careful oversight is then needed to ensure these models align with scientific goals and produce trustworthy results.Risks include the potential for generating misleading or incorrect outputs, amplifying biases present in training data, and over-reliance on automated systems without sufficient human validation.Additionally, the opacity of how these models arrive at their conclusions can hinder their adoption in critical scientific applications, raising important questions about their benefits and risks in science [37].Fajardo-Fontiveros et al. [38] discuss when it is possible to learn models from data and the acceptable noise levels for accurate learning.</p>
<p>Discovery versus re-discovery by machine learning</p>
<p>While ML has proven invaluable in refining existing knowledge, its real potential lies in detecting patterns and correlations that may not be immediately apparent due to the vast amounts of data involved.This raises the question of whether ML is truly discovering new insights or merely reinterpreting existing knowledge.Historically, scientific discovery has been rooted in inquiry, observation, and experimentation, with creativity playing a crucial role in generating new insights into phenomena or theories [39,40].While ML excels at analyzing large datasets, identifying patterns, and generating hypotheses (which are key components of discovery), its ability to make truly autonomous, original discoveries is still debated.ML models operate without a genuine understanding of the underlying mechanisms they analyze, meaning that their "discoveries" tend to be instrumental rather than original.Groundbreaking discoveries usually require creativity, broader contextual understanding and sometimes leaps beyond available data, all of which ML currently lacks.Although ML is revolutionizing research by uncovering complex trends, the idea that it can independently produce original scientific discoveries remains controversial.Several studies have explored this question [41], and workshops, such as the one organized by the National Academies on How ML Is Shaping Scientific Discovery, have debated the issue [42].Nevertheless, ML has already contributed to significant scientific breakthroughs.In drug discovery, ML identified new antibiotics, such as halicin, which were unknown and can kill antibiotic-resistant bacteria [43].ML also plays a crucial role in materials science, predicting new materials for batteries and superconductors using physical and experimental data.These achievements highlight AI's potential to navigate uncharted scientific territory [44].</p>
<p>One of the most significant advancements in AI-driven scientific discovery is AI-Hilbert.Developed by IBM researchers, AI-Hilbert acts as an "AI scientist" that transforms existing theories and data into new, consistent mathematical models.Its goal is to accelerate scientific discovery by automating hypothesis generation and testing.</p>
<p>5/19</p>
<p>AI-Hilbert helps scientists uncover new knowledge by analyzing large scientific datasets and revealing patterns overlooked by traditional methods.It also refines theories by managing conflicting data [45].Furthermore, Cornelio et al. [46] have developed a new ML tool which combines axiomatic knowledge with experimental data to derive scientific models.By integrating logical reasoning and symbolic regression, it has rediscovered laws like Kepler's third law and Einstein's time-dilation law.This tool can distinguish between competing formulas, even with limited data.While efficient at replicating human discoveries, these tools often confirm known theories rather than offering new insights.ML can be biased towards existing patterns, limiting its ability to generate novel hypotheses.In these cases, AI's role is more supportive, validating established knowledge rather than challenging it [47].ML holds immense potential for making groundbreaking discoveries, particularly in fields like drug development and astrophysics.However, its frequent rediscovery of known scientific principles illustrates the current limitations of its creativity.For ML to drive new knowledge, it must evolve beyond confirming human findings.Currently, ML lacks an intrinsic understanding of the mechanisms it analyzes, so its discoveries often complement human expertise, relying on human interpretation and creativity to fully appreciate and exploit the insights gained.</p>
<p>Machine-learning-driven scientific discovery when complete information is available</p>
<p>There are several applications within Physical Sciences where the underlying governing equations are known perfectly but the high-level global dynamics are still not well understood.For instance, while we know the quantum equations behind biomolecular dynamics, complexity makes biology a partial-knowledge problem since only limited biological systems can be measured or simulated, and simulating the full human brain is impossible.Similarly, turbulent flows, described by the Navier-Stokes equations, are only partially understood due to their chaotic nature as the Reynolds number increases [48].While the large scales in the flow can be simulated, the smaller scales are much more difficult to simulate, making turbulence a major challenge [49].However, some ML techniques, such as symbolic regression and reduced-order modeling, can help uncover unknown flow features and physical properties from large direct-numerical-simulation (DNS) datasets [50,51], as indicated in Figure 3. Advances in turbulence modeling using supervised ML have also improved closure models for Reynolds-averaged Navier-Stokes (RANS) and large-eddy-simulation (LES) turbulence models [52,53].In astrophysics, the supervised classifier SPOCK predicts long-term stability in multi-planet systems (which requires integration of the laws of gravitation over billions of orbital periods) using short-term simulations and effectively generalizing to larger systems [54].</p>
<p>Optimal control of complex physical and biological systems is another challenging area where ML, particularly deep reinforcement learning (DRL), shows promise.DRL has led to breakthroughs in quantum physics, astronomy, turbulence control, and tokamak-instability control, offering insights into complex systems and discovering novel strategies [55].DRL has even uncovered previously unknown thermodynamic cycles [56].ML can dramatically accelerate simulations of complex systems with known equations.Autoencoders can be used to discover latentspace representations that enable faster time integrators and simulations, leading to better optimization and systematic studies [57,58].For instance, high-energy physics relies on comparing observed particle detector data with simulations, which are computationally intensive.Fast generative models like generative adversarial networks (GANs) and variational autoencoders (VAEs) offer a faster alternative, although on-going research aims at ensuring that the required accuracy is achieved [59,60].In climate science, foundation models for weather forecasting are revolutionizing climate studies, offering potential breakthroughs in understanding climate change and paleoclimates [13].In applied mathematics, DRL and large language models (LLMs) are generating novel algorithms and optimizations.Notable examples include matrix operations [61] and combinatorial problems, where AI aids in discovering new strategies that can be validated with classical algorithms [62].In these cases, AI provides valuable heuristic methods, although it must be highlighted that finding adequate solutions still remains challenging.</p>
<p>Machine-learning-driven scientific discovery when only partial information is available</p>
<p>In contrast to systems with well-understood governing equations, in some scientific problems we only have access to partial knowledge of the underlying mechanisms, as seen in complex materials (e.g., composites or textured materials) and certain fluids (e.g., granular or multiphase flows).These systems can exhibit simple microscopic behaviors yet result in complex macroscopic phenomena, such as the spread of infectious diseases or "active turbulence" in biological matter [63,64].In these cases, inductive biases, like frame invariance or symmetry constraints, can be incorporated into ML models to improve the discovery process [65,66].Physical constraints (e.g., thermodynamics) help create more generalizable models.For example, Moya et al. [67] proposed a neural 6/19 Figure 3. Schematic representation of ML directions to enable scientific discoveries when complete information about the governing equations is available.In such a case, both supervised, unsupervised, and reinforcement-learning methodologies can be used.Supervised and unsupervised methodologies are made possible by generating large datasets of synthetic data simulated from the governing equations.This allows the deployment of a variety of ML techniques that can discover complex hidden relations, nonlinear coordinate systems, hidden dynamics or solve otherwise intractable problems.Reinforcement learning can also be used by coupling it to the physics simulator, which has already proven successful at discovering previously unknown control strategies and regimes of complex systems or generating high-quality heuristic guesses that can be tested in the case of problems where solution verification is easy, but the suggestion of good candidate solutions is hard.network constrained by known thermodynamic properties, enabling broader applications across physical systems.It is also important to highlight digital twins, where only some data are available, and they combine data-driven aspects with simulations while preserving generalization properties [68].Another example of taking advantage of known physical properties of the system is embedding symmetries in autoencoders, intending to develop reducedorder models (ROMs) in physical systems invariant to input transformations [69,70].These data-driven and physics-informed techniques are crucial for scientific discovery; for instance, ML is helping to derive constitutive laws for materials with complex rheologies.De Lorenzis and collaborators [71] introduced a hybrid framework (EUCLID) to learn constitutive equations for hyperelastic solids, and the SpaRTA framework for data-driven turbulence modeling [72] has been adapted to model elastic solids [73].Such approaches have also been used to infer constitutive equations from crystal structures and rheology of complex fluids [74] (see Figure 4).</p>
<p>In the context of Life Sciences, structural biology is a field where ML has made significant advances despite partial knowledge of the phenomena.AlphaFold [75], for instance, folds proteins into their three-dimensional (3D) native form from a one-dimensional(1D) amino acid sequence using deep learning with embedded biases like multiple sequence alignment (MSA) and 3D equivariance.AlphaFold has also spurred innovations in ML, including single-sequence methods like ESMfold [76] and generative models for protein design [77,78].Diffusion models are also being used to generate protein-backbone structures and molecular ensembles, bypassing the need for simulations [79,80].Furthermore, generative models have also been used to discover physical models, integrating prior knowledge with data to generalize to new scenarios [81].Transformers, for instance, are now used in Chemistry to complete chemical reactions and predict reaction yields [82].When it comes to quantum systems, deep reinforcement learning (DRL) has enabled new approaches to manipulate quantum states, providing insights into quantum mechanics [83].Additionally, ML aids in reducing noise in quantum-computing systems, while quantum computing improves ML performance [84].In climate modeling, ML has developed new LES Figure 4. Example of machine learning applied to a case where partial knowledge is available about the underlying system, illustrating a model (for instance a flow with complex rheology or a flow through a porous medium, top right of the picture) which depends on a set of known inputs x (e.g.geometry, boundary conditions, etc.) as well as on a set of hidden (unobservable) variables α α α describing, e.g., the fluid constitutive behavior.The latter may involve small-scale phenomena that can be difficult or impossible to describe.In such conditions, experimental or numerical data for observable quantities (e.g.velocity fields or stresses y) can be used to infer the unknown field by training a machine learning model (here represented as a neural network, although other ML approaches are possible), subjected to physical constraints (e.g.positivity, symmetries or invariances).The whole process allows, on the one hand, to train a data-driven closure model for the hidden variables α α α and, on the other hand, to gain a-posteriori physical knowledge of the fluid constitutive properties.models to ensure stable long-term forecasts [85].ML has also been shown to enhance traditional weather-prediction systems [86].</p>
<p>Machine-learning-driven scientific discovery when little information is available</p>
<p>There are numerous phenomena across scientific disciplines whose origins and underlying principles remain elusive.In these cases, the absence of well-established governing equations or foundational physical models makes it difficult to fully capture and understand their critical dynamics.For example, neuroscience has no first-principle equations, as there are no known conservation laws or symmetries to derive generalizable differential equations.Even with equations describing molecules or cells, the brain's complexity makes full-scale simulation unfeasible.Despite this, advances in neural data acquisition, such as large-scale neural recordings and connectomics, produce unprecedented datasets, promising a new era of ML-driven discovery in neuroscience and behavior [87,88].Although full brain simulations remain beyond reach, data-driven models can replicate key input-output relationships, generating predictions vital for discovery.In neuroscience, perturbation experiments (such as activating neuron populations during visual tasks) provide insights into visual perception.Data-driven models can generate testable hypotheses and refine their predictions iteratively through experiments.ML also synthesizes diverse experimental data, such as the MICrONS dataset, which links functional imaging with structural reconstructions of cortical neurons [89].</p>
<p>ML can learn dynamics where no a-priori knowledge exists, as seen in the Hodgkin-Huxley equations modeling neural dynamics [90].Approaches like SINDy (sparse identification of nonlinear dynamics) [19], genetic algorithms [91] and reinforcement learning [92] can help uncover system dynamics.Neural ordinary differential equations (NODEs) [93] are another method for modeling continuous dynamics, although they often lack scientific insight.Hybrid models relying on transformers [94] or SINDy-inspired architectures [95] aim to bridge this gap.Interpretable-ML models can also discover biomarkers for diseases or predict treatment outcomes from patient data [96].In systems lacking governing equations, interventional data like CRISPR-Ko experiments in single-cell biology [97] are enabling ML to identify some of the underlying mechanisms.Automated setups are advancing [98], leading to research in designing experiments for system identification, especially for non-linear models like NODEs [99].Representation-learning techniques, such as variational autoencoders [100], are essential for simplifying the characterization of complex systems by identifying latent spaces that reduce dimensionality and reveal causal structures [101].Causality and its application to dynamical systems have gained prominence [102], especially in Earth sciences [103] and molecular biology [104], with some studies using invariance from heterogeneous experiments as a signal to identify causal ODEs [105].Learning structured latent spaces is of crucial importance since it provides an effective coordinate system in which the dynamics have a simple representation, which is a key requirement for generalization and interpretability [106].In Figure 5 we provide a schematic representation of the identification of an underlying causal structure from observations where the variables of interest are not directly observed.</p>
<p>Figure 5. Schematic representation of a model (for instance, the observed symptoms of an unknown or complex disease within a population, or observed opinion dynamics within a social network) where the behavior as observed in data depends on an unknown dynamic or causal structure.The observed behavior or dynamics might occur on several different spatial and temporal scales, and the observed data might reflect more or fewer aspects of the underlying system.In such conditions, representation-learning methods can be employed to distil out an explanation of the observed data in the form of a system of ODEs or as a causal-graph representation.</p>
<p>Recent research has also explored improving diffusion models and solvers [107], which are useful for generating state-of-the-art results in areas like image generation [108], protein modeling [109] and materials science [110].Despite their success, large pre-trained models provide limited scientific insights [111], and therefore constitute an opportunity for future research.Machine learning has also enhanced data collection and processing in systems with indirect or incomplete measurements.ML imputation and generative modeling can complete time-series data, improving downstream applications [112].Furthermore, computer-vision techniques have also automated previously manual tasks, such as segmentation in microscopy, enabling large-scale analysis of cell populations [113].In ethology, ML has transformed video data into animal kinematics and poses, linking behavior to underlying neural computations [114].Notably, large language models (LLMs) and scientific foundation models (SFMs) are opening new avenues for extracting scientific insights directly from data.Genome-scale language models (GenSLMs), for instance, are helping to learn the evolutionary landscape of SARS-CoV-2 genomes [115], while LLMs are enhancing neuroscience research by integrating diverse datasets and summarizing insights across isolated subfields [116].</p>
<p>In sum, it is hard to overstate the ongoing impact of machine learning as a critical tool that, when used in conjunction with other approaches (e.g.experiments, causality analysis, development of an adequate coordinate system, etc.), catalyzes advances in scientific fields where no information on the phenomenon under study is available.</p>
<p>9/19</p>
<p>The drawbacks, limitations and challenges of machine learning for scientific discovery Despite the significant advances that ML has brought to scientific discovery, there are key areas that need to be addressed to accelerate its contributions and realize its full potential while minimizing some clear risks, as discussed below:</p>
<p>• Data-related challenges: The success of ML in scientific discovery relies on large high-quality, structured datasets, but scientific data is often incomplete, noisy, or imbalanced, leading to biased models.Unstructured data, especially in fields like biology, chemistry, and geology, complicate the use of ML applications, since these algorithms are not inherently designed to handle such data.However, it was recently shown that foundation models could help for prediction tasks in small general datasets [117].Furthermore, the absence of labeled data complicates the use of supervised-ML techniques [118].</p>
<p>• Bias and ethical issues: ML models are prone to data bias, distorting results and hindering scientific discovery.Bias in data collection or model training can reinforce existing assumptions instead of revealing novel insights [119].This is especially concerning in fields such as drug discovery, where existing models might overlook demographic groups, making the discoveries less generalizable [120].Ethical concerns, especially in medicine, highlight risks in applying ML to decisions affecting human life [121].</p>
<p>• Explainability and interpretability: ML models, particularly those based on deep learning, often function as "black boxes", making accurate predictions without revealing their decision-making processes [16].This lack of transparency is problematic in fields like drug discovery, where understanding why a model predicts a certain interaction is crucial [122].Advances in explainable AI (XAI) have improved interpretability in areas like materials science [123], chemistry [124], and medicine [125].</p>
<p>• Overfitting and generalization: ML models often overfit their training data, performing poorly on unseen data, a fact that limits their ability to generalize.In scientific contexts, this can produce misleading results and fail to capture complex, nonlinear relationships, as seen in chemistry, biology, and astronomy [126][127][128].Overfitting restricts the potential of ML to develop universal theories essential for broad scientific understanding [129].</p>
<p>Improving data quality and diversity is critical for ML models to generalize across disciplines.Initiatives like the Open Reaction Database [130] and the Crystallography Open Database [131] aim to enhance data management under the FAIR (findability, accessibility, interoperability and reusability) principles [132,133].Incorporating bias detection and fairness-aware algorithms can reduce biased data impacts [134].XAI methods are being developed to improve the transparency of ML models, particularly in healthcare applications like brain-tumor segmentation [135].Hybrid approaches that combine ML with physics-based models yield promising results by ensuring that the predictions adhere to known scientific principles [136,137].It is also important to note that ethical frameworks are also needed to ensure fairness, transparency, and accountability, especially in medicine [138,139].</p>
<p>While AI has shown great potential in scientific discovery, significant challenges remain.Issues related to data quality, bias, interpretability, and overfitting must be addressed to harness the full potential of AI in advancing science.By improving data access, enhancing model transparency, and developing hybrid models, the scientific community can overcome these obstacles and drive meaningful, trustworthy discoveries using AI which may play an instrumental role in areas as far-reaching as gravitational waves [140], space exploration [141] or even the discovery of extraterrestrial life [142].</p>
<p>Conclusions and outlook</p>
<p>Karl Popper famously stated in The Open Universe: An Argument for Indeterminism from the Postscript to The Logic of Scientific Discovery that "science can be described as the art of systematic oversimplification" [143] and this remains true due to the historical limitations in processing and analyzing vast amounts of data.As a result, scientists have been forced to simplify their objects of study by focusing on isolated phenomena or simple models.While simplification has benefits, for example in the teaching and the systematization of science, oversimplification carries significant risks, as essential information and key aspects of problems may be lost in the process.For example, in ecological research, studies often focus on individual species interactions without considering the broader dynamics of ecosystems or other effects, such as climate change [144].</p>
<p>ML methods have already enabled several scientific and technological advancements, from solving image classification to winning at Go.This article highlights how modern data-driven methods are enabling breakthroughs in scientific discovery, focusing on state-of-the-art techniques that push beyond previous limitations.We categorize these approaches by how much knowledge about the underlying mechanisms is available, ranging from wellunderstood systems to those with unknown governing principles.As shown in Table 1, ML's potential spans a wide spectrum of applications, including discovering physical laws, evaluating complex systems, inferring unknown behaviors, and uncovering multiscale principles.These advances apply across fields like Physics, Mathematics, Chemistry, and Life Sciences, promising faster scientific progress than ever before.However, using ML for scientific discovery brings challenges.A key advantage of ML is its ability to model complex systems, but this often requires extensive training data.In areas like astrophysics, rare diseases, or new pharmaceuticals, data scarcity is a frequent obstacle.Fortunately, complementary ML methods can either generate needed data or bypass large datasets through techniques like self-supervised learning.Even when ML does not directly result in discoveries, it can facilitate breakthroughs where data are limited.Validation is another challenge, especially in cases where the governing principles are unknown.But ML-driven discoveries can be confirmed using traditional scientific methods, such as hypothesis testing, observational confirmation and benchmarking.Additionally, ML models often function as "black boxes", making it hard to derive formal knowledge from their results.This is a significant issue for science, where understanding is key.However, explainable-and interpretable-ML methods offer solutions, helping to achieve discoveries in the context of established scientific principles.Despite these challenges, ML is becoming an essential tool across disciplines, and its continued evolution promises even more opportunities for scientific discovery.With further refinement, ML techniques are likely to address the current limitations, enabling even greater advancements.</p>
<p>The recent Nobel Prizes in Physics [145] and Chemistry [146] underscore the transformative impact of machine learning, demonstrating its ability to revolutionise scientific discovery.By providing cutting-edge tools for data analysis, ML is accelerating breakthroughs across multiple fields, deepening our understanding and tackling complex challenges in ways previously unimaginable.This capability is crucial, as only by embracing this complexity can we connect the dots in science, grasp the intricate interdependencies of natural systems, and facilitate breakthrough, unpredictable discoveries.The real challenge -and opportunity -of AI-driven scientific discovery lies in moving beyond solving narrow, well-defined problems to tackling complex, open-ended questions.This shift calls for the development of artificial general intelligence (AGI) or even artificial superintelligence (ASI), which possesses the potential to engage in multifaceted problem-solving across diverse domains.AGI for scientific discovery could connect seemingly disparate areas of knowledge, leading to breakthroughs that single-focused AI cannot achieve.For instance, an AGI model could integrate insights from pharmacology, neuroscience, and data science to not only propose novel drug candidates but also predict their interactions and effects on complex biological systems.This capacity for interdisciplinary connections would facilitate original contributions to scientific knowledge, allowing for innovative solutions to intricate challenges.Ultimately, harnessing AGI's multifaceted problem-solving abilities presents a transformative opportunity to revolutionize how we approach scientific discovery and address some of humanity's most pressing challenges.Table 1.Summarizing overview of the opportunities for machine learning in scientific discovery.Based on the differentiation presented in our work, the level of prior, deterministic knowledge (left) can be used to differentiate methods (second right) and applications (right) across which scientific advancements can be made by means of dedicated AI systems.This also allows for various modes of discovery (second left), ranging from cases where machine learning enables discovery by allowing for efficient computational usage, parametric sweeps, etc., to cases where machine learning is used to causally infer underlying mechanistic behaviours in complex multidisciplinary systems.</p>
<p>Figure 1 .
1
Figure 1.Schematic representation of the various applications of ML for scientific discovery, depending on the amount of knowledge available in each category.A number of examples are provided, including brain research, drug discovery, dark matter and fluid mechanics.</p>
<p>Figure 2 .
2
Figure 2. Visual summary of the paper illustrating some of its main ideas.(Top left) The increase in the amount of data generated by scientific instrumentation over time and the shift from data organization by humans, computers, and finally by machine-learning techniques, which translates into less observation, intervention and understanding of humans on scientific discoveries.(Top right) The four challenges we have identified in the paper on the use of ML techniques for scientific discovery, these being: data quality and availability, potential biases, explainability and overfitting.(Bottom left) What constitutes a scientific discovery and the possibility of ML making original breakthroughs versus simply rediscovering known ideas, concepts or laws.(Bottom right) The need to have more and better data to be able to make scientific discoveries with ML as we have less knowledge on the subject of study</p>
<p>/19 
/19 
/19 
AcknowledgementsThe following researchers are acknowledged for helpful discussions during the preparation of this article: Frida Bender, Annica Ekman, Inga Koszalka, Romit Maulik, Henrik Nielsen, Gunilla Svensson, Björn Wallner.RV and HA acknowledge SeRC and Digital Futures for funding the workshop that initiated this work.RV acknowledges financial support from ERC grant no.'2021-CoG-101043998, DEEPCONTROL'.DM acknowledges financial support from ERC grant no.2022-StG-101075494, MultiPRESS.Views and opinions expressed are, however, those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council.Neither the European Union nor the granting authority can be held responsible.AE was funded by the Vetenskapsrådet Grant No. 2021-03979 and the Knut and Alice Wallenberg Foundation and by SeRC.SLB acknowledges funding support from the US National Science Foundation AI Institute in Dynamic Systems (grant number 2112085) and from The Boeing Company.Author contributionsRV and HA initiated the idea for this article following a workshop celebrated in November 2022 at KTH.All the authors contributed equally to the rest of this work.Competing interestsThe authors declare no competing interests.Publisher's noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.19/19
History of scientific instrumentation and history of science. P Tucci, 10.1007/978-3-031-26174-9_6A History of Physics: Phenomena, Ideas and Mechanisms. R Pisano, ChamSpringer202542</p>
<p>Science in an exponential world. A Szalay, J Gray, 10.1038/440413aNature. 4402006</p>
<p>Big data: The power of petabytes. M Eisenstein, 10.1038/527S2aNature. 5272015</p>
<p>Artificial intelligence-a new knowledge and decision-making paradigm?. L Huang, W Peissl, 10.1007/978-3-031-10617-0_9Technology Assessment in a Globalized World. Hennen, L. et al.2023Springer</p>
<p>The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool. D Resnik, M Hosseini, 10.1007/s43681-024-00493-8AI Ethics. 2024</p>
<p>Recommendation on the ethics of artificial intelligence. UNESCO. 2022</p>
<p>Machine learning and artificial intelligence in neuroscience: A primer for researchers. F Badrulhisham, E Pogatzki-Zahn, D Segelcke, T Spisak, J Vollert, 10.1016/j.bbi.2023.11.005Brain, Behav. Immun. 1152024</p>
<p>How ai is being used to accelerate clinical trials. M Hutson, Nature. 6272024</p>
<p>Alleviating the transit timing variation bias in transit surveys -i. rivers: Method and detection of a pair of resonant super-earths around kepler-1705. A Leleu, 10.1051/0004-6361/202141471Astron. &amp; Astrophys. 6552021</p>
<p>Machine learning at the energy and intensity frontiers of particle physics. A Radovic, M Williams, D Rousseau, 10.1038/s41586-018-0361-2Nature. 5602018</p>
<p>Advancing mathematics by guiding human intuition with ai. A Davies, P Veličković, L Buesing, 10.1038/s41586-021-04086-xNature. 6002021</p>
<p>Magnetic control of tokamak plasmas through deep reinforcement learning. Degrave, Nature. 6022022</p>
<p>How AI is improving climate forecasts. C Wong, Nature. 2024</p>
<p>Discovery of a structural class of antibiotics with explainable deep learning. F Wong, 10.1038/s41586-023-06887-8Nature. 6262024</p>
<p>Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. C Rudin, Nat. Mach. Intell. 12019</p>
<p>Interpretable deep-learning models to help achieve the Sustainable Development Goals. R Vinuesa, B Sirmacek, Nat. Mach. Intell. 39262021</p>
<p>Gene expression programming: mathematical modeling by an artificial intelligence. C Ferreira, 2006Springer21</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 3242009</p>
<p>Discovering governing equations from data by sparse identification of nonlinear dynamical systems. S L Brunton, J L Proctor, J N Kutz, Proc. Natl. Acad. Sci. 1132016</p>
<p>Scaling deep learning for materials discovery. A Merchant, 10.1038/s41586-023-06735-9Nature. 6242023</p>
<p>Does the sun rise for ChatGPT? Scientific discovery in the age of generative AI. D Leslie, AI Ethics. 2023</p>
<p>The unreasonable effectiveness of data. A Halevy, P Norvig, F Pereira, IEEE intelligent systems. 242009</p>
<p>The unreasonable effectiveness of deep learning in artificial intelligence. T J Sejnowski, Proc. Natl. Acad. Sci. Natl. Acad. Sci2020117</p>
<p>Scientific discovery in the age of artificial intelligence. H Wang, Nature. 6202023</p>
<p>The future of fundamental science led by generative closed-loop artificial intelligence. H Zenil, arXiv:2307.075222023Prepr.</p>
<p>Chatgpt: five priorities for research. E A Van Dis, J Bollen, W Zuidema, R Van Rooij, C L Bockting, Nature. 6142023</p>
<p>Optimizing language models for dialogue. Openai, Chatgpt, 2022</p>
<p>Augmenting large language models with chemistry tools. A Bran, 10.1038/s42256-024-00832-8Nat Mach Intell. 62024</p>
<p>Autonomous chemical research with large language models. D Boiko, R Macknight, B Kline, G Gomes, 10.1038/s41586-023-06792-0Nature. 6242023</p>
<p>Q Wang, D Downey, H Ji, T Hope, Scimon, arXiv:2305.14259Scientific inspiration machines optimized for novelty. 2023arXiv preprint</p>
<p>Evolutionary-scale prediction of atomic-level protein structure with a language model. Z Lin, Science. 3792023</p>
<p>Learning inverse folding from millions of predicted structures. C Hsu, 10.1101/2022.04.10.4877792022</p>
<p>Foundation models for weather and climate data understanding: A comprehensive survey. S Chen, G Long, J Jiang, D Liu, C Zhang, arXiv:2312.030142023arXiv preprint</p>
<p>J Wei, arXiv:2206.07682Emergent abilities of large language models. 2022arXiv preprint</p>
<p>Are emergent abilities of large language models a mirage?. R Schaeffer, B Miranda, S Koyejo, Adv. Neural Inf. Process. Syst. 362024</p>
<p>More is different: Broken symmetry and the nature of the hierarchical structure of science. P W Anderson, Science. 1771972</p>
<p>Science in the age of large language models. A Birhane, A Kasirzadeh, D Leslie, S Wachter, Nat. Rev. Phys. 52023</p>
<p>Fundamental limits to learning closed-form mathematical models from data. O Fajardo-Fontiveros, Nat. Commun. 1410432023</p>
<p>W Bechtel, R Richardson, Discovering Complexity. PrincetonPrinceton University Press1993</p>
<p>Y Ben-Menahem, Causation in Science. PrincetonPrinceton University Press2018</p>
<p>On scientific understanding with artificial intelligence. M Krenn, R Pollice, S Y Guo, 10.1038/s42254-022-00518-3Nat. Rev. Phys. 42022</p>
<p>How ai is shaping scientific discovery. N A Of Sciences, Proceedings of a Workshop. a Workshop2023. 2024AI for Scientific Discovery</p>
<p>A deep learning approach to antibiotic discovery. J M Stokes, K Yang, K Swanson, 10.1016/j.cell.2020.01.021Cell. 1802020</p>
<p>AI and the new age of AI. 2023</p>
<p>Evolving scientific discovery by unifying data and background knowledge with ai hilbert. Cory-Wright , R Cornelio, C Dash, S , 10.1038/s41467-024-50074-wNat. Commun. 152024</p>
<p>Combining data and theory for derivable scientific discovery with ai-descartes. C Cornelio, S Dash, V Austel, 10.1038/s41467-023-37236-yNat. Commun. 142023</p>
<p>Artificial intelligence in science: An emerging general method of invention. S Bianchini, M Müller, P Pelletier, 10.1016/j.respol.2022.104604Res. Policy. 511046042022</p>
<p>The mathematical theory of non-uniform gases: an account of the kinetic theory of viscosity, thermal conduction and diffusion in gases. S Chapman, T G Cowling, 1990Cambridge university press</p>
<p>Existence and smoothness of the Navier-Stokes equation. The millennium prize problems. C L Fefferman, 20005767</p>
<p>Identifying regions of importance in wall-bounded turbulence through explainable deep learning. A Cremades, Nat. Commun. 1538642024</p>
<p>Information-theoretic formulation of dynamical systems: Causality, modeling, and control. A Lozano-Durán, G Arranz, Phys. Rev. Res. 4231952022</p>
<p>Turbulence modeling in the age of data. K Duraisamy, G Iaccarino, H Xiao, Annu. Rev. Fluid Mech. 512019</p>
<p>Machine learning for fluid mechanics. S L Brunton, B R Noack, P Koumoutsakos, Annu. Rev. Fluid Mech. 522020</p>
<p>Predicting the long-term stability of compact multiplanet systems. D Tamayo, Proc. Natl. Acad. Sci. Natl. Acad. Sci2020117</p>
<p>Mastering the game of Go with deep neural networks and tree search. Silver, Nature. 5292016</p>
<p>Optimizing thermodynamic trajectories using evolutionary and gradient-based reinforcement learning. C Beeler, Phys. Rev. E. 104641282021</p>
<p>β -Variational autoencoders and transformers for reduced-order modelling of fluid flows. A Solera-Rico, Nat. Commun. 1513612014</p>
<p>Optimization of physical quantities in the autoencoder latent space. S Park, Sci. Reports. 1290032022</p>
<p>Generative adversarial networks. J Goodfellow, arXiv:1406.26612014Prepr.</p>
<p>Machine learning in high energy physics community white paper. K Albertsson, Journal of Physics: Conference Series. IOP Publishing2018108522008</p>
<p>A. Discovering faster matrix multiplication algorithms with reinforcement learning. Fawzi, Nature. 6102022</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, Nature. 6252024</p>
<p>Relating SARS-CoV-2 variants using cellular automata imaging. L F Souza, T M Rocha Filho, M A Moret, Sci. Reports. 12102972022</p>
<p>Active turbulence. R Alert, J Casademunt, J.-F Joanny, Annu. Rev. Condens. Matter Phys. 132022</p>
<p>Discovering symbolic models from deep learning with inductive biases. M Cranmer, 34th Conf. on Neural Inf. Vancouver, CanNeurIPS 2020. 2020</p>
<p>Z Liu, Y Chen, Y Du, M Tegmark, arXiv:2109.13901Physics-augmented learning: A new paradigm beyond physicsinformed learning. 2021arXiv preprint</p>
<p>A thermodynamics-informed active learning approach to perception and reasoning about fluids. B Moya, A Badías, D González, F Chinesta, E Cueto, Comput. Mech. 722023</p>
<p>A probabilistic graphical model foundation for enabling predictive digital twins at scale. M G Kapteyn, J V R Pretorius, K E Willcox, Nat. Comput. Sci. 12021</p>
<p>Symmetry-aware autoencoders: s-PCA and s-NLPCA. S Kneer, T Sayadi, D Sipp, P Schmid, G Rigas, arXiv:2111.02893v32022</p>
<p>A unified framework to enforce, discover, and promote symmetry in machine learning. S E Otto, N Zolman, J N Kutz, S L Brunton, arXiv:2311.00212Prepr. 2023</p>
<p>Automated discovery of generalized standard material models with euclid. M Flaschel, S Kumar, L De Lorenzis, Comput. Methods Appl. Mech. Eng. 4051158672023</p>
<p>Discovery of algebraic Reynolds-stress models using sparse symbolic regression. Flow. M Schmelzer, R P Dwight, P Cinnella, Turbul. Combust. 1042020</p>
<p>Establish algebraic data-driven constitutive models for elastic solids with a tensorial sparse symbolic regression method and a hybrid feature selection technique. M Wang, C Chen, W Liu, J. Mech. Phys. Solids. 1591047422022</p>
<p>Digital rheometer twins: Learning the hidden rheology of complex fluids through rheology-informed graph neural networks. M Mahmoudabadbozchelou, K M Kamani, S A Rogers, S Jamali, Proc. Natl. Acad. Sci. Natl. Acad. Sci2022119e2202234119</p>
<p>Highly accurate protein structure prediction with alphafold. J Jumper, 15/19Nature. 5962021</p>
<p>Evolutionary-scale prediction of atomic-level protein structure with a language model. Z Lin, Science. 3792023</p>
<p>Large language models generate functional protein sequences across diverse families. A Madani, 10.1038/s41587-022-01618-2Nat Biotechnol. 412023</p>
<p>Robust deep learning-based protein sequence design using ProteinMPNN. J Dauparas, 10.1126/science.add2187Science. 3782022</p>
<p>De novo design of protein structure and function with RFdiffusion. J Watson, 10.1038/s41586-023-06415-8Nature. 6202023</p>
<p>Illuminating protein space with a programmable generative model. J Ingraham, 10.1038/s41586-023-06728-8Nature. 6232023</p>
<p>Combining data and theory for derivable scientific discovery with ai-descartes. C Cornelio, Nat. Commun. 1417772023</p>
<p>Chemformer: a pre-trained transformer for computational chemistry. R Irwin, S Dimitriadis, J He, E J Bjerrum, Mach. Learn. Sci. Technol. 3150222022</p>
<p>Active learning machine learns to create new quantum experiments. A A Melnikov, Proc. Natl. Acad. Sci. Natl. Acad. Sci2018115</p>
<p>Quantum machine learning: from physics to software engineering. A Melnikov, M Kordzanganeh, A Alodjants, R.-K Lee, Adv. Physics: X. 821654522023</p>
<p>A posteriori learning for quasi-geostrophic turbulence parametrization. H Frezat, J Sommer, R Fablet, G Balarac, R Lguensat, J. Adv. Model. Earth Syst. 142022</p>
<p>A review of recent and emerging machine learning applications for climate variability and weather phenomena. M J Molina, Artif. Intell. for Earth Syst. 22200862023</p>
<p>Distributed coding of choice, action and engagement across the mouse brain. N A Steinmetz, P Zatka-Haas, M Carandini, K D Harris, 10.1038/s41586-019-1787-xNature. 5762019Nature Publishing GroupNumber: 7786 Publisher</p>
<p>A whole-brain monosynaptic input connectome to neuron classes in mouse visual cortex. S Yao, Nat. neuroscience. 262023</p>
<p>Functional connectomics spanning multiple areas of mouse visual cortex. M Consortium, BioRxiv. 72021. 2021</p>
<p>The Hodgkin-Huxley model. The Book Genes. M Nelson, J Rinzel, 1995</p>
<p>Symbolic genetic algorithm for discovering open-form partial differential equations (sga-pde). Y Chen, Y Luo, Q Liu, H Xu, D Zhang, Phys. Rev. Res. 4231742022</p>
<p>Discover: Deep identification of symbolic open-form PDEs via enhanced reinforcement-learning. M Du, Y Chen, D Zhang, arXiv:2210.021812022</p>
<p>Neural ordinary differential equations. Adv. neural information processing systems. R T Chen, Y Rubanova, J Bettencourt, D K Duvenaud, 201831</p>
<p>Predicting ordinary differential equations with transformers. S Becker, M Klein, A Neitz, G Parascandolo, N Kilbertus, International Conference on Machine Learning. 1978-2002 (PMLR, 2023</p>
<p>Learning equations for extrapolation and control. S Sahoo, C Lampert, G Martius, International Conference on Machine Learning. Pmlr2018</p>
<p>Development and validation of an interpretable deep learning framework for alzheimer's disease classification. S Qiu, 16/19Brain. 1432020</p>
<p>Machine learning for perturbational single-cell omics. Y Ji, M Lotfollahi, F A Wolf, F J Theis, Cell Syst. 122021</p>
<p>A self-driving laboratory advances the pareto front for material properties. B P Macleod, Nat. Commun. 139952022</p>
<p>Model-based reinforcement learning for semi-Markov decision processes with neural ODEs. J Du, J Futoma, F Doshi-Velez, Adv. Neural Inf. Process. Syst. 332020</p>
<p>Representation learning: A review and new perspectives. Y Bengio, A Courville, P Vincent, 201335</p>
<p>Toward causal representation learning. B Schölkopf, Proc. IEEE. IEEE2021109</p>
<p>Discovering causal relations and equations from data. G Camps-Valls, Phys. Reports. 10442023</p>
<p>Inferring causation from time series in Earth system sciences. J Runge, Nat. Commun. 1025532019</p>
<p>Molecular causality in the advent of foundation models. S Lobentanzer, P Rodriguez-Mier, S Bauer, J Saez-Rodriguez, arXiv:2401.095582024Prepr</p>
<p>Learning stable and predictive structures in kinetic systems. N Pfister, S Bauer, J Peters, Proc. Natl. Acad. Sci. Natl. Acad. Sci2019116</p>
<p>Data-driven discovery of coordinates and governing equations. K Champion, B Lusch, J N Kutz, S L Brunton, Proc. Natl. Acad. Sci. Natl. Acad. Sci2019116</p>
<p>Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. C Lu, Adv. Neural Inf. Process. Syst. 352022</p>
<p>High-resolution image synthesis with latent diffusion models. R Rombach, A Blattmann, D Lorenz, P Esser, B Ommer, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2022</p>
<p>De novo design of protein structure and function with rfdiffusion. J L Watson, Nature. 6202023</p>
<p>Mattergen: a generative model for inorganic materials design. C Zeni, arXiv:2312.036872023Prepr.</p>
<p>How transformers learn causal structure with gradient descent. E Nichani, A Damian, J D Lee, arXiv:2402.147352024Prepr.</p>
<p>Generating realistic neurophysiological time series with denoising diffusion probabilistic models. J Vetter, J H Macke, R Gao, 2023</p>
<p>Segment anything. A Kirillov, 2304.026432023</p>
<p>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. A Mathis, 10.1038/s41593-018-0209-yNat. Neurosci. 212018Nature Publishing GroupNumber: 9 Publisher</p>
<p>Genome-scale language models reveal sars-cov-2 evolutionary dynamics. M Zvyagin, The Int. J. High Perform. Comput. Appl. 372023</p>
<p>Data science opportunities of large language models for neuroscience and biomedicine. D Bzdok, Neuron. 1122024</p>
<p>Accurate predictions on small data with a tabular foundation model. N Hollmann, 10.1038/s41586-024-08328-6Nature. 6372025</p>
<p>A study of challenges and limitations to applying machine learning to highly unstructured data. S Singh, S Hooda, 10.1109/ICCUBEA58933.2023.1039211517/192023 7th International Conference On Computing, Communication, Control And Automation (ICCUBEA). Pune, India2023</p>
<p>A causal perspective on dataset bias in machine learning for medical imaging. C Jones, D C Castro, F De Sousa Ribeiro, 10.1038/s42256-024-00797-8Nat. Mach. Intell. 62024</p>
<p>Demographic bias in misdiagnosis by computational pathology models. A Vaidya, R J Chen, D F K Williamson, 10.1038/s41591-024-02885-zNat. Medicine. 302024</p>
<p>Overcoming the pitfalls and perils of algorithms: A classification of machine learning biases and mitigation methods. B Van Giffen, D Herhausen, T Fahse, 10.1016/j.jbusres.2022.01.076J. Bus. Res. 1442022</p>
<p>Breaking into the black box of artificial intelligence. N Savage, 10.1038/d41586-022-00858-1Nature. 2022</p>
<p>Explainable machine learning in materials science. X Zhong, B Gallagher, S Liu, 10.1038/s41524-022-00884-7npj Comput. Mater.. 82022</p>
<p>Explainable chemical artificial intelligence from accurate machine learning of real-space chemical descriptors. M Gallegos, V Vassilev-Galindo, I Poltavsky, 10.1038/s41467-024-48567-9Nat. Commun. 152024</p>
<p>Explainable machine learning can outperform cox regression predictions and provide insights in breast cancer survival. A Moncada-Torres, M C Van Maaren, M P Hendriks, 10.1038/s41598-021-86327-7Sci. Reports. 112021</p>
<p>Model selection and overfitting. J Lever, M Krzywinski, N Altman, 10.1038/nmeth.3968Nat. Methods. 132016</p>
<p>Welcome to the ai future?. 10.1038/s41550-023-01891-4Nat. Astron. 712023</p>
<p>Current progress and open challenges for applying deep learning across the biosciences. N Sapoval, A Aghazadeh, M G Nute, 10.1038/s41467-022-29268-7Nat. Commun. 132022</p>
<p>Generalizing ai: Challenges and opportunities for plug and play ai solutions. I A Ridhawi, S Otoum, M Aloqaily, A Boukerche, 10.1109/MNET.011.200037IEEE Netw. 352021</p>
<p>The open reaction database. 10.1021/jacs.1c09820J. Am. Chem. Soc. 1432021</p>
<p>An open-access database and analysis tool for perovskite solar cells based on the FAIR data principles. T J Jacobsson, A Hultqvist, A García-Fernández, 10.1038/s41560-021-00941-3Nat. Energy. 72022</p>
<p>Crystallography open database-an open-access collection of crystal structures. S Gražulis, J. Appl. Crystallogr. 422009</p>
<p>Reproducibility and replicability in science. L Barba, 2019National Academies Press</p>
<p>Systematic review of data-centric approaches in artificial intelligence and machine learning. P Singh, 10.1016/j.dsm.2023.06.001Data Sci. Manag. 62023</p>
<p>Algorithmic fairness and bias mitigation for clinical machine learning with deep reinforcement learning. J Yang, A A S Soltan, D W Eyre, 10.1038/s42256-023-00697-3Nat. Mach. Intell. 52023</p>
<p>Considerations for addressing bias in artificial intelligence for health equity. npj Digit. M D Abràmoff, M E Tarver, N Loyo-Berrios, 10.1038/s41746-023-00913-9Medicine. 62023</p>
<p>Artificial intelligence-enhanced quantum chemical method with broad applicability. P Zheng, R Zubatyuk, W Wu, 10.1038/s41467-021-27082-9Nat. Commun. 1270222021</p>
<p>Program good ethics into artificial intelligence. J Davies, 10.1038/538291aNature. 2016</p>
<p>Machine learning and algorithmic fairness in public and population health. V Mhasawade, Y Zhao, R Chunara, 10.1038/s42256-021-00373-4Nat. Mach. Intell. 3</p>
<p>Accelerated, scalable and reproducible ai-driven gravitational wave detection. E A Huerta, A Khan, X Huang, 10.1038/s41550-021-01405-0Nat. Astron. 52021</p>
<p>Space missions out of this world with ai. 10.1038/s42256-023-00643-3Nat. Mach. Intell. 52023</p>
<p>A deep-learning search for technosignatures from 820 nearby stars. P X Ma, C Ng, L Rizk, 10.1038/s41550-022-01872-zNat. Astron. 72023</p>
<p>The Open Universe: An Argument for Indeterminism From the Postscript to The Logic of Scientific Discovery. K Popper, 1992Routledge</p>
<p>The importance of species interactions in eco-evolutionary community dynamics under climate change. A Åkesson, A Curtsdotter, A Eklöf, 10.1038/s41467-021-24977-xNat. Commun. 1247592021</p>
<p>Physics Nobel scooped by machine-learning pioneers. Nature. 2024</p>
<p>Chemistry Nobel goes to developers of AlphaFold AI that predicts protein structures. Nature. 2024</p>            </div>
        </div>

    </div>
</body>
</html>