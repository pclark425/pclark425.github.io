<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1205 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1205</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1205</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7" target="_blank">Graph Constrained Reinforcement Learning for Natural Language Action Spaces</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> KG-A2C, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space is presented, arguing that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions.</p>
                <p><strong>Paper Abstract:</strong> Interactive Fiction games are text-based simulations in which an agent interacts with the world purely through natural language. They are ideal environments for studying how to extend reinforcement learning agents to meet the challenges of natural language understanding, partial observability, and action generation in combinatorially-large text-based action spaces. We present KG-A2C, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. Results across a wide variety of IF games show that KG-A2C outperforms current IF agents despite the exponential increase in action space size.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1205.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1205.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zork1</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zork I</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A canonical human-made interactive-fiction (text-adventure) dungeon-crawler used as a testbed in this paper; features a labyrinthine map, sparse rewards (treasures), environmental hazards (darkness/grue), and locked/blocked doors/trap-doors that require specific actions or items to traverse.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Zork1</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Fantasy/dungeon text-adventure where the player explores rooms, collects treasures, solves puzzles and fights NPCs; partial observability via text descriptions and inventory; domain: classic interactive fiction/dungeon exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td>Multiple forms of constrained passage are present in-game and mentioned in transcripts: nailed-shut wooden door (cannot be opened), closed trap door (can be opened via actions), dark areas requiring a light source (lantern) to safely traverse, chasms and unclimbable ramps; some doors or accesses require prior actions/tools rather than being freely traversable.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse, labyrinthine topology typical of dungeon crawlers (many rooms connected by directional exits, some narrow passages and one-way or conditional connections inferred from navigation verbs); connectivity described qualitatively as 'vast labyrinth' and 'complex, interconnected web' but not numerically characterized.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not given as number of rooms in paper; the paper reports template and vocabulary sizes for Zork1: |T| = 237 templates, |V| = 697 vocabulary tokens; Max reward (game) listed as 350 points.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KG-A2C (compared to TDQN, A2C and ablations)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An on-policy Advantage Actor Critic using a dynamically built knowledge graph as state representation (triples), Graph Attention Networks (GAT) to embed the graph, a template-based action decoding policy (template then object slots), and a graph-derived mask that restricts object choices to entities present in the knowledge graph; supervised valid-action auxiliary losses are used to bias template/object decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Learning speed / convergence (reward as function of training steps), sample efficiency (how quickly score increases), and final game score (asymptotic reward).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Qualitative: KG-A2C (and ablations with either GAT or graph mask) converge slightly faster than pure A2C; KG-A2C achieves asymptotic score ≈34 on Zork1 while TDQN achieves ≈9.9 (numbers are raw game scores). No explicit numeric 'steps-to-cover' or coverage rates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Graph-augmented memory policy / template-decoding actor-critic: policies that use an explicit knowledge-graph memory and that constrain generation with template+graph-mask perform best in these environments.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Reported relationships: (1) Using the knowledge graph to constrain action generation (graph mask) and using graph attention to embed graph state both speed learning (convergence) compared to agents without them; (2) valid-action supervision (using Jericho's valid-action oracle during training) is critical—without it KG-A2C-unsupervised fails to learn, indicating that constraining actions (which interacts with topology via seen objects/rooms) strongly affects exploration efficiency; (3) template-based action space (structured action space) is necessary for tractable exploration—seq (word-level) decoding in full vocabulary performed much worse. The paper does not provide quantitative correlations between topological metrics (diameter/clustering) and performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Empirical findings: policies that incorporate a learned graph-like memory (knowledge graph) and use that memory to mask action generation (graph mask) learn faster and perform better than purely observation-based policies; removing the GAT (KG-A2C-no-gat) or removing the mask (KG-A2C-no-mask) slows learning but can reach similar asymptotic scores in some cases, indicating the graph components primarily aid exploration speed rather than exclusively determining asymptotic capability. Valid-action supervision and template action structure are also essential for effective exploration in these high-branching text-action spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph Constrained Reinforcement Learning for Natural Language Action Spaces', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1205.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1205.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Jericho suite</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Jericho interactive-fiction benchmark suite</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A collection/framework of human-authored interactive-fiction games and an API (Jericho) used to evaluate agents on diverse IF games; provides tooling such as valid-action detection and access to templates/vocabulary for each game.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Jericho-supported IF games (suite of 28 games tested)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A diverse set of human-made text-adventure games spanning genres and world structures (puzzles, dungeon crawlers, adventure games), used to test generality of agents across different topologies and game mechanics.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Varied across games (games in the suite exhibit different structures); paper treats each game as its own environment but does not report explicit graph-topology statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>28 human-made IF games evaluated; per-game metadata in paper includes template counts |T| and vocabulary sizes |V| (examples in Table 1), e.g., many games with |T| between ~140–330 and |V| between ~296–2257.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KG-A2C (and baselines: Template-DQN, A2C, ablations)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>KG-A2C is an on-policy A2C variant that builds an online knowledge graph from observations (triples), embeds it with GATs, uses template-based action decoding with object masking via the knowledge graph, and uses valid-action supervised losses; baselines include Template-DQN (TDQN) which extends LSTM-DQN to template-actions.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Per-game raw score as function of training steps (learning curves), win/performance comparisons across games (mean scores), and convergence speed.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>KG-A2C matches or outperforms TDQN on 23/28 games in raw-score comparisons; specific numeric improvements per game are listed in Table 1 (e.g., zork1: TDQN 9.9 vs KGA2C 34). No per-game 'steps-to-cover' or formal coverage metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Knowledge-graph-augmented actor-critic with template-actions and valid-action supervision performs best across this heterogeneous set.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Authors report that the knowledge graph and graph-mask broadly improve exploration/generalization across diverse game structures; however, they did not compute formal topology measures (diameter, clustering) across games nor regress performance onto those metrics—thus the relationship is qualitative (graph components help in many but not all games).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Across the suite, graph-augmented policies that constrain action generation (via graph mask) and use valid-action supervision are empirically more effective; removing the mask or GAT reduces learning speed or final performance on some games, indicating that policy structure that encodes memory and uses it to reduce action branching is valuable for navigation/exploration in IF.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph Constrained Reinforcement Learning for Natural Language Action Spaces', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1205.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1205.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TextWorld (mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TextWorld: A learning environment for text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework for procedurally generating parser-based text games used in prior work to study text-based game learning; mentioned in the related work as a tool for controlling difficulty of generated games.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Textworld: A learning environment for text-based games</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>TextWorld (framework / generated text games)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Procedurally-generated parser-based text-adventure games; can control difficulty and properties of generated worlds (useful for studying navigation and language-action mapping).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Varies by generated instance; not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph Constrained Reinforcement Learning for Natural Language Action Spaces', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1205.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1205.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge Graph State Space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Graph-based State Representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dynamic knowledge graph built from observations during play (triples of <subject, relation, object>) used as the agent's state representation to mitigate partial observability and to provide memory of visited locations, encountered objects and inferred relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Interactive Fiction games (Jericho suite, e.g., Zork1)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to human-authored IF games to capture entities (rooms, objects, inventory, relations) and navigational triples inferred from movement commands (e.g., <kitchen, down, cellar>).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Graph is constructed incrementally from observations and navigation actions; topology depends on the underlying game world and is not summarized numerically in the paper. The KG captures room-to-room relations inferred by navigation, and links interactive objects to the current room and to a 'you' node.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Size varies with game and exploration; not given numerically.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>KG-A2C (uses the knowledge graph as state)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Knowledge graph triples are updated each step (OpenIE + heuristic rules), node features are subword-embedding averages, and a Graph Attention Network (GAT) produces a compact embedding used by the actor-critic and the template/object decoders; the KG is also used to create a graph mask restricting object candidates during action decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Learning speed (training curve), constrained action branching (qualitative), downstream reward/sample efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Qualitative: Using the KG to mask object choices dramatically reduces effective action branching and improves exploration, enabling KG-A2C to reach higher scores and faster convergence than baselines on many games; no exact numeric branching-factor reduction or coverage metrics supplied.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>KG-augmented policies that exploit the KG both as state input (via GAT) and as a constraint (graph mask) during action decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>The paper demonstrates that constraining action generation with the KG (objects present in the KG) improves exploration efficiency and speed of learning; however, it does not provide explicit empirical links between canonical graph-topology metrics (diameter, clustering coefficient, average degree) and agent performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Key findings: (1) KG as memory mitigates partial observability and aids commonsense/affordance reasoning; (2) using KG for action masking reduces the combinatorial action branching and enables more efficient exploration; (3) GAT-based embedding of KG helps learning speed—agents with either KG embedding or mask converge faster than ones without; (4) KG alone (without valid-action supervision) is insufficient—valid-action training signals remain important.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Graph Constrained Reinforcement Learning for Natural Language Action Spaces', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Playing text-adventure games with graph-based deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Interactive fiction games: A colossal adventure <em>(Rating: 2)</em></li>
                <li>Textworld: A learning environment for text-based games <em>(Rating: 2)</em></li>
                <li>Learn what not to learn: Action elimination with deep reinforcement learning <em>(Rating: 1)</em></li>
                <li>Language understanding for text-based games using deep reinforcement learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1205",
    "paper_id": "paper-028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "Zork1",
            "name_full": "Zork I",
            "brief_description": "A canonical human-made interactive-fiction (text-adventure) dungeon-crawler used as a testbed in this paper; features a labyrinthine map, sparse rewards (treasures), environmental hazards (darkness/grue), and locked/blocked doors/trap-doors that require specific actions or items to traverse.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "Zork1",
            "environment_description": "Fantasy/dungeon text-adventure where the player explores rooms, collects treasures, solves puzzles and fights NPCs; partial observability via text descriptions and inventory; domain: classic interactive fiction/dungeon exploration.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": true,
            "dead_ends_count": null,
            "door_constraints_present": true,
            "door_constraints_description": "Multiple forms of constrained passage are present in-game and mentioned in transcripts: nailed-shut wooden door (cannot be opened), closed trap door (can be opened via actions), dark areas requiring a light source (lantern) to safely traverse, chasms and unclimbable ramps; some doors or accesses require prior actions/tools rather than being freely traversable.",
            "graph_connectivity": "Sparse, labyrinthine topology typical of dungeon crawlers (many rooms connected by directional exits, some narrow passages and one-way or conditional connections inferred from navigation verbs); connectivity described qualitatively as 'vast labyrinth' and 'complex, interconnected web' but not numerically characterized.",
            "environment_size": "Not given as number of rooms in paper; the paper reports template and vocabulary sizes for Zork1: |T| = 237 templates, |V| = 697 vocabulary tokens; Max reward (game) listed as 350 points.",
            "agent_name": "KG-A2C (compared to TDQN, A2C and ablations)",
            "agent_description": "An on-policy Advantage Actor Critic using a dynamically built knowledge graph as state representation (triples), Graph Attention Networks (GAT) to embed the graph, a template-based action decoding policy (template then object slots), and a graph-derived mask that restricts object choices to entities present in the knowledge graph; supervised valid-action auxiliary losses are used to bias template/object decoding.",
            "exploration_efficiency_metric": "Learning speed / convergence (reward as function of training steps), sample efficiency (how quickly score increases), and final game score (asymptotic reward).",
            "exploration_efficiency_value": "Qualitative: KG-A2C (and ablations with either GAT or graph mask) converge slightly faster than pure A2C; KG-A2C achieves asymptotic score ≈34 on Zork1 while TDQN achieves ≈9.9 (numbers are raw game scores). No explicit numeric 'steps-to-cover' or coverage rates provided.",
            "success_rate": null,
            "optimal_policy_type": "Graph-augmented memory policy / template-decoding actor-critic: policies that use an explicit knowledge-graph memory and that constrain generation with template+graph-mask perform best in these environments.",
            "topology_performance_relationship": "Reported relationships: (1) Using the knowledge graph to constrain action generation (graph mask) and using graph attention to embed graph state both speed learning (convergence) compared to agents without them; (2) valid-action supervision (using Jericho's valid-action oracle during training) is critical—without it KG-A2C-unsupervised fails to learn, indicating that constraining actions (which interacts with topology via seen objects/rooms) strongly affects exploration efficiency; (3) template-based action space (structured action space) is necessary for tractable exploration—seq (word-level) decoding in full vocabulary performed much worse. The paper does not provide quantitative correlations between topological metrics (diameter/clustering) and performance.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Empirical findings: policies that incorporate a learned graph-like memory (knowledge graph) and use that memory to mask action generation (graph mask) learn faster and perform better than purely observation-based policies; removing the GAT (KG-A2C-no-gat) or removing the mask (KG-A2C-no-mask) slows learning but can reach similar asymptotic scores in some cases, indicating the graph components primarily aid exploration speed rather than exclusively determining asymptotic capability. Valid-action supervision and template action structure are also essential for effective exploration in these high-branching text-action spaces.",
            "uuid": "e1205.0",
            "source_info": {
                "paper_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Jericho suite",
            "name_full": "Jericho interactive-fiction benchmark suite",
            "brief_description": "A collection/framework of human-authored interactive-fiction games and an API (Jericho) used to evaluate agents on diverse IF games; provides tooling such as valid-action detection and access to templates/vocabulary for each game.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "Jericho-supported IF games (suite of 28 games tested)",
            "environment_description": "A diverse set of human-made text-adventure games spanning genres and world structures (puzzles, dungeon crawlers, adventure games), used to test generality of agents across different topologies and game mechanics.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Varied across games (games in the suite exhibit different structures); paper treats each game as its own environment but does not report explicit graph-topology statistics.",
            "environment_size": "28 human-made IF games evaluated; per-game metadata in paper includes template counts |T| and vocabulary sizes |V| (examples in Table 1), e.g., many games with |T| between ~140–330 and |V| between ~296–2257.",
            "agent_name": "KG-A2C (and baselines: Template-DQN, A2C, ablations)",
            "agent_description": "KG-A2C is an on-policy A2C variant that builds an online knowledge graph from observations (triples), embeds it with GATs, uses template-based action decoding with object masking via the knowledge graph, and uses valid-action supervised losses; baselines include Template-DQN (TDQN) which extends LSTM-DQN to template-actions.",
            "exploration_efficiency_metric": "Per-game raw score as function of training steps (learning curves), win/performance comparisons across games (mean scores), and convergence speed.",
            "exploration_efficiency_value": "KG-A2C matches or outperforms TDQN on 23/28 games in raw-score comparisons; specific numeric improvements per game are listed in Table 1 (e.g., zork1: TDQN 9.9 vs KGA2C 34). No per-game 'steps-to-cover' or formal coverage metrics reported.",
            "success_rate": null,
            "optimal_policy_type": "Knowledge-graph-augmented actor-critic with template-actions and valid-action supervision performs best across this heterogeneous set.",
            "topology_performance_relationship": "Authors report that the knowledge graph and graph-mask broadly improve exploration/generalization across diverse game structures; however, they did not compute formal topology measures (diameter, clustering) across games nor regress performance onto those metrics—thus the relationship is qualitative (graph components help in many but not all games).",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Across the suite, graph-augmented policies that constrain action generation (via graph mask) and use valid-action supervision are empirically more effective; removing the mask or GAT reduces learning speed or final performance on some games, indicating that policy structure that encodes memory and uses it to reduce action branching is valuable for navigation/exploration in IF.",
            "uuid": "e1205.1",
            "source_info": {
                "paper_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "TextWorld (mention)",
            "name_full": "TextWorld: A learning environment for text-based games",
            "brief_description": "A framework for procedurally generating parser-based text games used in prior work to study text-based game learning; mentioned in the related work as a tool for controlling difficulty of generated games.",
            "citation_title": "Textworld: A learning environment for text-based games",
            "mention_or_use": "mention",
            "environment_name": "TextWorld (framework / generated text games)",
            "environment_description": "Procedurally-generated parser-based text-adventure games; can control difficulty and properties of generated worlds (useful for studying navigation and language-action mapping).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": null,
            "environment_size": "Varies by generated instance; not specified in this paper.",
            "agent_name": "",
            "agent_description": "",
            "exploration_efficiency_metric": null,
            "exploration_efficiency_value": null,
            "success_rate": null,
            "optimal_policy_type": null,
            "topology_performance_relationship": null,
            "comparison_across_topologies": null,
            "topology_comparison_results": null,
            "policy_structure_findings": null,
            "uuid": "e1205.2",
            "source_info": {
                "paper_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Knowledge Graph State Space",
            "name_full": "Knowledge Graph-based State Representation",
            "brief_description": "A dynamic knowledge graph built from observations during play (triples of &lt;subject, relation, object&gt;) used as the agent's state representation to mitigate partial observability and to provide memory of visited locations, encountered objects and inferred relations.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "Interactive Fiction games (Jericho suite, e.g., Zork1)",
            "environment_description": "Applied to human-authored IF games to capture entities (rooms, objects, inventory, relations) and navigational triples inferred from movement commands (e.g., &lt;kitchen, down, cellar&gt;).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Graph is constructed incrementally from observations and navigation actions; topology depends on the underlying game world and is not summarized numerically in the paper. The KG captures room-to-room relations inferred by navigation, and links interactive objects to the current room and to a 'you' node.",
            "environment_size": "Size varies with game and exploration; not given numerically.",
            "agent_name": "KG-A2C (uses the knowledge graph as state)",
            "agent_description": "Knowledge graph triples are updated each step (OpenIE + heuristic rules), node features are subword-embedding averages, and a Graph Attention Network (GAT) produces a compact embedding used by the actor-critic and the template/object decoders; the KG is also used to create a graph mask restricting object candidates during action decoding.",
            "exploration_efficiency_metric": "Learning speed (training curve), constrained action branching (qualitative), downstream reward/sample efficiency.",
            "exploration_efficiency_value": "Qualitative: Using the KG to mask object choices dramatically reduces effective action branching and improves exploration, enabling KG-A2C to reach higher scores and faster convergence than baselines on many games; no exact numeric branching-factor reduction or coverage metrics supplied.",
            "success_rate": null,
            "optimal_policy_type": "KG-augmented policies that exploit the KG both as state input (via GAT) and as a constraint (graph mask) during action decoding.",
            "topology_performance_relationship": "The paper demonstrates that constraining action generation with the KG (objects present in the KG) improves exploration efficiency and speed of learning; however, it does not provide explicit empirical links between canonical graph-topology metrics (diameter, clustering coefficient, average degree) and agent performance.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Key findings: (1) KG as memory mitigates partial observability and aids commonsense/affordance reasoning; (2) using KG for action masking reduces the combinatorial action branching and enables more efficient exploration; (3) GAT-based embedding of KG helps learning speed—agents with either KG embedding or mask converge faster than ones without; (4) KG alone (without valid-action supervision) is insufficient—valid-action training signals remain important.",
            "uuid": "e1205.3",
            "source_info": {
                "paper_title": "Graph Constrained Reinforcement Learning for Natural Language Action Spaces",
                "publication_date_yy_mm": "2020-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Playing text-adventure games with graph-based deep reinforcement learning",
            "rating": 2,
            "sanitized_title": "playing_textadventure_games_with_graphbased_deep_reinforcement_learning"
        },
        {
            "paper_title": "Interactive fiction games: A colossal adventure",
            "rating": 2,
            "sanitized_title": "interactive_fiction_games_a_colossal_adventure"
        },
        {
            "paper_title": "Textworld: A learning environment for text-based games",
            "rating": 2,
            "sanitized_title": "textworld_a_learning_environment_for_textbased_games"
        },
        {
            "paper_title": "Learn what not to learn: Action elimination with deep reinforcement learning",
            "rating": 1,
            "sanitized_title": "learn_what_not_to_learn_action_elimination_with_deep_reinforcement_learning"
        },
        {
            "paper_title": "Language understanding for text-based games using deep reinforcement learning",
            "rating": 1,
            "sanitized_title": "language_understanding_for_textbased_games_using_deep_reinforcement_learning"
        }
    ],
    "cost": 0.01666575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Graph Constrained Reinforcement Learning for Natural Language Action Spaces</h1>
<p>Prithviraj Ammanabrolu<br>Georgia Institute of Technology<br>raj.ammanabrolu@gatech.edu<br>Matthew Hausknecht<br>Microsoft Research<br>matthew.hausknecht@microsoft.com</p>
<h4>Abstract</h4>
<p>Interactive Fiction games are text-based simulations in which an agent interacts with the world purely through natural language. They are ideal environments for studying how to extend reinforcement learning agents to meet the challenges of natural language understanding, partial observability, and action generation in combinatorially-large text-based action spaces. We present KG-A2C ${ }^{1}$, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. Results across a wide variety of IF games show that KG-A2C outperforms current IF agents despite the exponential increase in action space size.</p>
<h2>1 INTRODUCTION</h2>
<p>Natural language communication has long been considered a defining characteristic of human intelligence. We are motivated by the question of how learning agents can understand and generate contextually relevant natural language in service of achieving a goal. In pursuit of this objective we study Interactive Fiction (IF) games, or text-adventures: simulations in which an agent interacts with the world purely through natural language-"seeing" and "talking" to the world using textual descriptions and commands. To progress in these games, an agent must generate natural language actions that are coherent, contextually relevant, and able to effect the desired change in the world.</p>
<p>Complicating the problem of generating contextually relevant language in these games is the issue of partial observability: the fact that the agent never has access to the true underlying world state. IF games are structured as puzzles and often consist of an complex, interconnected web of distinct locations, objects, and characters. The agent needs to thus reason about the complexities of such a world solely through the textual descriptions that it receives, descriptions that are often incomplete. Further, an agent must be able to perform commonsense reasoning-IF games assume that human players possess prior commonsense and thematic knowledge-e.g. knowing that swords can kill trolls or that trolls live in dark places. Knowledge graphs provide us with an intuitive way of representing these partially observable worlds. Prior works have shown how using knowledge graphs aid in the twin issues of partial observability (Ammanabrolu \&amp; Riedl, 2019a) and commonsense reasoning (Ammanabrolu \&amp; Riedl, 2019b), but do not use them in the context of generating natural language.
To gain a sense for the challenges surrounding natural language generation, we need to first understand how large this space really is. In order to solve solve a popular IF game such as Zorkl it's necessary to generate actions consisting of up to five-words from a relatively modest vocabulary of 697 words recognized by Zork's parser. Even this modestly sized vocabulary leads to $\mathcal{O}\left(697^{5}\right)=1.64 \times 10^{14}$ possible actions at every step-a dauntingly-large combinatorially-sized action space for a learning agent to explore. In order to reduce the size of this space while maintaining expressiveness, Hausknecht et al. (2019a) propose the use of template-actions in which the agent first selects a template (e.g. $[p u t] \ldots$ [in] $\left.\ldots\right)$ then fills in the blanks using vocabulary words. There are 237 templates in Zorkl, each with up to two blanks, yielding a template-action space of size</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>$\mathcal{O}\left(237 \times 697^{2}\right)=1.15 \times 10^{8}$. This space is six orders of magnitude smaller than the word-based space, but still six orders of magnitude larger than the action spaces used by previous text-based agents (Narasimhan et al., 2015; Zahavy et al., 2018). We demonstrate how these templates provide the structure required to further constrain our action space via our knowledge graph-and make the argument that the combination of these approaches allows us to generate meaningful natural language commands.</p>
<p>Our contributions are as follows: We introduce an novel agent that utilizes both a knowledge graph based state space and template based action space and show how to train such an agent. We then conduct an empirical study evaluating our agent across a diverse set of IF games followed by an ablation analysis studying the effectiveness of various components of our algorithm as well as its overall generalizability. Remarkably we show that our agent achieves state-of-the-art performance on a large proportion of the games despite the exponential increase in action space size.</p>
<h1>2 Related Work</h1>
<p>We examine prior work in three broad categories: text-based game playing agents and frameworks as well as knowledge graphs used for natural language generation and game playing agents.</p>
<p>LSTM-DQN (Narasimhan et al., 2015), considers verb-noun actions up to two-words in length. Separate Q-Value estimates are produced for each possible verb and object, and the action consists of pairing the maximally valued verb combined with the maximally valued object. The DRRN algorithm for choice-based games (He et al., 2016; Zelinka, 2018) estimates Q-Values for a particular action from a particular state. Fulda et al. (2017) use Word2Vec (Mikolov et al., 2013) to aid in extracting affordances for items in these games and use this information to produce relevant action verbs. Zahavy et al. (2018) reduce the combinatorially-sized action space into a discrete form using a walkthrough of the game and introduce the Action Elimination DQN, which learns to eliminate actions unlikely to cause a world change.</p>
<p>Côté et al. (2018) introduce TextWorld, a framework for procedurally generating parser-based games, allowing a user to control the difficulty of a generated game.Yuan et al. (2019) introduce the concept of interactive question-answering in the form of QAit-modeling QA tasks in TextWorld. Urbanek et al. (2019) introduce Light, a dataset of crowdsourced text-adventure game dialogs focusing on giving collaborative agents the ability to generate contextually relevant dialog and emotes. Hausknecht et al. (2019a) have open-sourced Jericho ${ }^{2}$, an optimized interface for playing human-made IF games-formalizing this task. They further provide a comparative study of various types of agents on their set of games, testing the performance of heuristic based agents such as NAIL (Hausknecht et al., 2019b) and various reinforcement learning agents are benchmarked. We use Jericho and the tools that it provides to develop our agents.</p>
<p>Knowledge graphs have been shown to be useful representations for a variety of tasks surrounding natural language generation and interactive fiction. Ghazvininejad et al. (2017) and Guan et al. (2018) effectively use knowledge graph representations to improve neural conversational and story ending prediction models respectively. Ammanabrolu et al. (2019) explore procedural content generation in text-adventure games-looking at constructing a quest for a given game world, and use knowledge graphs to ground generative systems trained to produce quest content. From the perspective of text-game playing agent and most in line with the spirit of our work, Ammanabrolu \&amp; Riedl (2019a) present the Knowledge Graph DQN or KG-DQN, an approach where a knowledge graph built during exploration is used as a state representation for a deep reinforcement learning based agent. Ammanabrolu \&amp; Riedl (2019b) further expand on this work, exploring methods of transferring control policies in text-games, using knowledge graphs to seed an agent with useful commonsense knowledge and to transfer knowledge between different games within a domain. Both of these works, however, identify a discrete set of actions required to play the game beforehand and so do not fully tackle the issue of the combinatorial action space.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>3 State and Action Spaces</h1>
<p>Formally, IF games are partially observable Markov decision processes (POMDP), represented as a 7-tuple of $\langle S, T, A, \Omega, O, R, \gamma\rangle$ representing the set of environment states, mostly deterministic conditional transition probabilities between states, the vocabulary or words used to compose text commands, observations returned by the game, observation conditional probabilities, reward function, and the discount factor respectively (Côté et al., 2018; Hausknecht et al., 2019a). To deal with the resulting twin challenges of partial observability and combinatorial actions, we use a knowledge graph based state space and a template-based action space-each described in detail below.
Knowledge Graph State Space. Building on Ammanabrolu \&amp; Riedl (2019a), we use a knowledge graph as a state representation that is learnt during exploration. The knowledge graph is stored as a set of 3-tuples of 〈subject, relation, object $\rangle$. These triples are extracted from the observations using Stanford's Open Information Extraction (OpenIE) (Angeli et al., 2015). Human-made IF games often contain relatively complex semi-structured information that OpenIE is not designed to parse and so we add additional rules to ensure that we are parsing the relevant information.</p>
<p>Updated after every action, the knowledge graph helps the agent form a map of the world that it is exploring, in addition to retaining information that it has learned such as the affordances associated with an object, the properties of a character, current inventory, etc. Nodes relating to such information are shown on the basis of their relation to the agent which is presented on the graph using a "you" node (see example in Fig. 2a).
Ammanabrolu \&amp; Riedl (2019a) build a knowledge graph in a similar manner but restrict themselves to a single domain. In contrast, we test our methods on a much more diverse set of games defined in the Jericho framework (Hausknecht et al., 2019a). These games are each structured differentlycovering a wider variety of genres-and so to be able to extract the same information from all of them in a general manner, we relax many of the rules found in Ammanabrolu \&amp; Riedl (2019a). To aid in the generalizability of graph building, we introduce the concept of interactive objects-items that an agent is able to directly interact with in the surrounding environment. These items are directly linked to the "you" node, indicating that the agent can interact with them, and the node for the current room, showing their relative position. All other triples built from the graph are extracted by OpenIE. Further details regarding knowledge graph updates are found in Appendix B. 1 An example of a graph built using these rules is seen in Fig. 2a.</p>
<p>Template Action Space. Templates are subroutines used by the game's parser to interpret the player's action. They consist of interchangeable verbs phrases $(V P)$ optionally followed by prepositional phrases $(V P P P)$, e.g. ([carry/hold/take] $\qquad$ ) and ([drop/throw/discard/pnt] $\qquad$ [at/against/on/onto] $\qquad$ ), where the verbs and prepositions within [.] are aliases. As shown in Figure 2b, actions may be constructed from templates by filling in the template's blanks using words in the game's vocabulary. Templates and vocabulary words are programmatically accessible through the Jericho framework and are thus available for every IF game. Further details about how we prioritize interchangeable verbs and prepositions are available in Appendix B.2.</p>
<h2>4 Knowledge Graph Advantage Actor Critic</h2>
<p>Combining the knowledge-graph state space with the template action space, Knowledge Graph Advantage Actor Critic or KG-A2C, is an on-policy reinforcement learning agent that collects experience from many parallel environments. We first discuss the architecture of KG-A2C, then detail the training algorithm. As seen in Fig. 1, KG-A2C's architecture can broadly be described in terms of encoding a state representation and then using this encoded representation to decode an action. We describe each of these processes below.</p>
<p>Input Representation. The input representation network is broadly divided into three parts: an observation encoder, a score encoder, and the knowledge graph. At every step an observation consisting of several components is received: $o_{t}=\left(o_{t_{\text {desc }}}, o_{t_{\text {game }}}, o_{t_{\text {line }}}, a_{t-1}\right)$ corresponding to the room description, game feedback, inventory, and previous action, and total score $R_{t}$. The room description $o_{t_{\text {desec }}}$ is a textual description of the agent's location, obtained by executing the command "look." The game feedback $o_{t_{\text {game }}}$ is the simulators response to the agent's previous action and con-</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The full KG-A2C architecture. Solid lines represent computation flow along which the gradient can be back-propagated.
sists of narrative and flavor text. The inventory $o_{t_{\text {two }}}$ and previous action $a_{t-1}$ components inform the agent about the contents of its inventory and the last action taken respectively.</p>
<p>The observation encoder processes each component of $o_{t}$ using a separate GRU encoder. As we are not given the vocabulary that $o_{t}$ is comprised of, we use subword tokenization-specifically using the unigram subword tokenization method described in Kudo \&amp; Richardson (2018). This method predicts the most likely sequence of subword tokens for a given input using a unigram language model which, in our case, is trained on a dataset of human playthroughs of IF games ${ }^{3}$ and contains a total vocabulary of size 8000 . For each of the GRUs, we pass in the final hidden state of the GRU at step $t-1$ to initialize the hidden state at step $t$. We concatenate each of the encoded components and use a linear layer to combine them into the final encoded observation $\mathbf{o}<em t="t">{t}$.
At each step, we update our knowledge graph $G</em>}$ using $o_{t}$ as described in Sec. 3 and it is then embedded into a single vector $\mathbf{g<em _mathbf_1="\mathbf{1">{\mathbf{t}}$. Following Ammanabrolu \&amp; Riedl (2019a) we use Graph Attention networks or GATs (Veličković et al., 2018) with an attention mechanism similar to that described in Bahdanau et al. (2014). Node features are computed as $H=\left{\mathbf{h}</em>}}, \mathbf{h<em _mathbf_N="\mathbf{N">{\mathbf{2}}, \ldots, \mathbf{h}</em>}}\right}, \mathbf{h<em i="i" j="j">{\mathbf{i}} \in \mathbb{R}^{F}$, where $N$ is the number of nodes and $F$ the number of features in each node, consist of the average subword embeddings of the entity and of the relations for all incoming edges using our unigram language model. Self-attention is then used after a learnable linear transformation $W \in \mathbb{R}^{2 \mathrm{~F} \times \mathrm{F}}$ applied to all the node features. Attention coefficients $\alpha</em>$.}$ are then computed by softmaxing $k \in \mathcal{N}$ with $\mathcal{N}$ being the neighborhood in which we compute the attention coefficients and consists of all edges in $G_{t</p>
<p>$$
\begin{aligned}
e_{i j} &amp; =\operatorname{LeakyReLU}\left(\mathbf{p} \cdot W\left(\mathbf{h}<em _mathbf_j="\mathbf{j">{\mathbf{i}} \oplus \mathbf{h}</em>\right)\right) \
\alpha_{i j} &amp; =\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}} \exp \left(e_{i k}\right)}
\end{aligned}
$$}</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Living Room
You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. A batterypowered brass lantern is on the trophy case.
You are carrying:
A glass bottle
The glass bottle contains:
A quantity of water.
(a) The extracted knowledge graph for the corresponding state. Bolded words in the observation indicate interactive objects.
<img alt="img-2.jpeg" src="img-2.jpeg" />
(b) Visualization of the action decoding process using templates and objects. Objects consist of the entire game input vocabulary. Greyed out words indicate objects masked out by the knowledge graph.</p>
<p>Figure 2: An overall example of the knowledge graph building and subsequent action decoding process for a given state in Zork1, illustrating the use of interactive objects and the graph mask.
where $\mathbf{p} \in \mathbb{R}^{2 \mathrm{~F}}$ is a learnable parameter. The final knowledge graph embedding vector $\mathbf{g}_{\mathbf{t}}$ is computed as:</p>
<p>$$
\mathbf{g}<em g="g">{\mathbf{t}}=f\left(W</em>}\left(\bigoplus_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}} \alpha_{i j}^{(k)} \mathbf{W}^{(k)} \mathbf{h<em g="g">{j}\right)\right)+b</em>\right)
$$</p>
<p>where $k$ refers to the parameters of the $k^{t h}$ independent attention mechanism, $W_{g}$ and $b_{g}$ the weights and biases of the output linear layer, and $\bigoplus$ represents concatenation. The final component of state embedding vector is a binary encoding $\mathbf{c}<em _mathbf_t="\mathbf{t">{t}$ of the total score obtained so far in the game-giving the agent a sense for how far it has progressed in the game even when it is not collecting reward. The state embedding vector is then calculated as $\mathbf{s}</em>}}=\mathbf{g<em _mathbf_t="\mathbf{t">{\mathbf{t}} \oplus \mathbf{o}</em>}} \oplus \mathbf{c<em _mathbf_t="\mathbf{t">{\mathbf{t}}$.
Action Decoder. The state embedding vector $\mathbf{s}</em>}}$ is then used to sequentially construct an action by first predicting a template and then picking the objects to fill into the template using a series of Decoder GRUs. This gives rise to a template policy $\pi_{\mathrm{T}}$ and a policy for each object $\pi_{\mathrm{O<em t="t">{t}}$. Architecture wise, at every decoding step all previously predicted parts of the action are encoded and passed along with $\mathbf{s}</em>$ remains separate.}$ through an attention layer which learns to attend over these representations-conditioning every predicted object on all the previously predicted objects and template. All the object decoder GRUs share parameters while the template decoder $\mathrm{GRU}_{T</p>
<p>To effectively constrain the space of template-actions, we introduce the concept of a graph mask, leveraging our knowledge graph at that timestep $G_{t}$ to streamline the object decoding process. Formally, the graph mask $m_{t}=\left{o: o \in G_{t} \wedge o \in V\right}$, consists of all the entities found within the knowledge graph $G_{t}$ and vocabulary $V$ and is applied to the outputs of the object decoder GRUsrestricting them to predict objects in the mask. Generally, in an IF game, it is impossible to interact with an object that you never seen or that are not in your inventory and so the mask lets us explore the action space more efficiently. To account for cases where this assumption does not hold, i.e. when an object that the agent has never interacted with before must be referenced in order to progress in the game, we randomly add objects $o \in V$ to $m_{t}$ with a probability $p_{m}$. An example of the graph-constrained action decoding process is illustrated in Fig. 2b.</p>
<h1>4.1 TRAINING</h1>
<p>We adapt the Advantage Actor Critic (A2C) method (Mnih et al., 2016) to train our network, using multiple workers to gather experiences from the simulator, making several significant changes along the way-as described below.</p>
<p>Valid Actions. Using a template-action space there are millions of possible actions at each step. Most of these actions do not make sense, are ungrammatical, etc. and an even fewer number of them actually cause the agent effect change in the world. Without any sense for which actions present valid interactions with the world, the combinatorial action space becomes prohibitively large for effective exploration.</p>
<p>We thus use the concept of valid actions, actions that can change the world in a particular state. These actions can usually be recognized through the game feedback, with responses like "Nothing happens" or "That phrase is not recognized." In practice, we follow Hausknecht et al. (2019a) and use the valid action detection algorithm provided by Jericho. Formally, $\operatorname{Valid}\left(s_{t}\right)=\left{a_{0}, a_{1} \ldots a_{N}\right}$ and from this we can construct the corresponding set of valid templates $\mathcal{T}<em t="t">{\text {valid }}\left(s</em>}\right)=\left{\tau_{0}, \tau_{1} \ldots \tau_{N}\right}$. We further define a set of valid objects $\mathcal{O<em t="t">{\text {valid }}\left(s</em>}\right)=\left{o_{0}, o_{1} \ldots o_{M}\right}$ which consists of all objects in the graph mask as defined in Sec. 4. This lets us introduce two cross-entropy loss terms to aid the action decoding process. The template loss given a particular state and current network parameters is applied to the decoder $\mathrm{GRU<em O="O">{T}$. Similarly, the object loss is applied across the decoder $\mathrm{GRU}</em>$ and is calculated by summing cross-entropy loss from all the object decoding steps.</p>
<p>$$
\begin{gathered}
\mathcal{L}<em t="t">{\mathbb{T}}\left(s</em>\right)\right)\right. \
\mathcal{L}}, a_{t} ; \theta_{t}\right)=\frac{1}{N} \sum_{i=1}^{N}\left(y_{\tau_{i}} \log \pi_{\mathbb{T}}\left(\tau_{i} \mid s_{t}\right)+\left(1-y_{\tau_{i}}\right)\left(1-\log \pi_{\mathbb{T}}\left(\tau_{i} \mid s_{t<em t="t">{\mathbb{O}}\left(s</em>}, a_{t} ; \theta_{t}\right)=\sum_{j=1}^{n} \frac{1}{M} \sum_{i=1}^{M}\left(y_{o_{i}} \log \pi_{\mathbb{O<em i="i">{j}}\left(o</em>} \mid s_{t}\right)+\left(1-y_{o_{i}}\right)\left(1-\log \pi_{\mathbb{O<em i="i">{j}}\left(o</em>\right)\right)\right) \
y_{\tau_{i}}=\left{\begin{array}{ll}
1 &amp; \tau_{i} \in \mathcal{T}} \mid s_{t<em t="t">{\text {valid }}\left(s</em>\right) \
0 &amp; \text { else }
\end{array} y_{o_{i}}=\left{\begin{array}{ll}
1 &amp; o_{i} \in \mathcal{O}<em t="t">{\text {valid }}\left(s</em>\right) \
0 &amp; \text { else }
\end{array}\right.\right.
\end{gathered}
$$</p>
<p>Updates. A2C training starts with calculating the advantage of taking an action in a state $A\left(s_{t}, a_{t}\right)$, defined as the value of taking an action $Q\left(s_{t}, a_{t}\right)$ compared to the average value of taking all possible valid actions in that state $V\left(s_{t}\right)$ :</p>
<p>$$
\begin{aligned}
&amp; A\left(s_{t}, a_{t}\right)=Q\left(s_{t}, a_{t}\right)-V\left(s_{t}\right) \
&amp; Q\left(s_{t}, a_{t}\right)=\mathbb{E}\left[r_{t}+\gamma V\left(s_{t+1}\right)\right]
\end{aligned}
$$</p>
<p>$V\left(s_{t}\right)$ is predicted by the critic as shown in Fig. 1 and $r_{t}$ is the reward received at step $t$.
The action decoder or actor is then updated according to the gradient:</p>
<p>$$
-\nabla_{\theta}\left(\log \pi_{\mathbb{T}}\left(\tau \mid s_{t} ; \theta_{t}\right)+\sum_{i=1}^{n} \log \pi_{\mathbb{O}<em i="i">{i}}\left(o</em>\right)
$$} \mid s_{t}, \tau, \ldots, o_{i-1} ; \theta_{t}\right)\right) A\left(s_{t}, a_{t</p>
<p>updating the template policy $\pi_{\mathbb{T}}$ and object policies $\pi_{\mathbb{O}_{i}}$ based on the fact that each step in the action decoding process is conditioned on all the previously decoded portions. The critic is updated with respect to the gradient:</p>
<p>$$
\frac{1}{2} \nabla_{\theta}\left(Q\left(s_{t}, a_{t} ; \theta_{t}\right)-V\left(s_{t} ; \theta_{t}\right)\right)^{2}
$$</p>
<p>bringing the critic's prediction of the value of being in a state closer to its true underlying value. We further add an entropy loss over the valid actions, designed to prevent the agent from prematurely converging on a trajectory.</p>
<p>$$
\mathcal{L}<em t="t">{\mathbb{E}}\left(s</em>\right)
$$}, a_{t} ; \theta_{t}\right)=\sum_{a \in V\left(s_{t}\right)} P\left(a \mid s_{t}\right) \log P\left(a \mid s_{t</p>
<h1>5 EXPERIMENTAL RESULTS</h1>
<p>The KG-A2C is tested on a suite of Jericho supported games and is compared to strong, established baselines. Additionally, as encouraged by Hausknecht et al. (2019a), we present the set of handicaps used by our agents: (1) Jericho's ability to identify valid actions and (2) the Load, Save handicap in order to acquire $o_{t_{A u s c}}$ and $o_{t_{s a c c}}$ using the look and inventory commands without changing the game state. Hyperparameters are provided in Appendix C.</p>
<p>Template DQN Baseline. We compare KG-A2C against Template-DQN, a strong baseline also utilizing the template based action space. TDQN (Hausknecht et al., 2019a) is an extension of LSTM-DQN (Narasimhan et al., 2015) to template-based action spaces. This is accomplished using three output heads: one for estimating the Q-Values over templates $Q\left(s_{t}, u\right) \forall u \in \mathcal{T}$ and two for estimating Q-Values $Q\left(s_{t}, o_{1}\right), Q\left(s_{t}, o_{2}\right) \forall o_{i} \in \mathcal{O}$ over vocabulary to fill in the blanks of the template. The final executed action is constructed by greedily sampling from the predicted Q-values. Importantly, TDQN uses the same set of handicaps as KG-A2C allowing a fair comparison between these two algorithms.</p>
<p>Table 1 shows how KG-A2C fares across a diverse set of games supported by Jericho-testing the agent's ability to generalize to different genres, game structures, reward functions, and state-action spaces. KG-A2C matches or outperforms TDQN on 23 out of the 28 games that we test on. Our agent is thus shown to be capable of extracting a knowledge graph that can sufficiently constrain the template based action space to enable effective exploration in a broad range of games.</p>
<h2>6 Ablation Study</h2>
<p>In order to understand the contributions of different components of KG-A2C's architecture, we ablate KG-A2C's knowledge graph, template-action space, and valid-action loss. These ablations are performed on Zork1 ${ }^{4}$ and result in the following agents:
A2C removes all components of KG-A2C's knowledge graph. In particular, the state embedding vector is now computed as $\mathbf{s}<em _mathbf_t="\mathbf{t">{\mathbf{t}}=\mathbf{o}</em>$ and the graph mask is not used to constrain action decoding.}} \odot \mathbf{c}_{\mathbf{t}</p>
<p>KG-A2C-no-gat remove's the Graph Attention network, but retains the graph masking components. The knowledge graph is still constructed as usual but the agent uses the same state embedding vector as A2C.
KG-A2C-no-mask ablates the graph mask for purposes of action decoding. The knowledge graph is constructed as usual and the agent retains graph attention.</p>
<p>On Zork1 as shown in Figure 3, we observe similar asymptotic performance between the all of the ablations - all reach approximately 34 points. This level of performance corresponds to a local optima where the agent collects the majority of available rewards without fighting the troll. Several other authors also report scores at this threshold (Jain et al., 2019; Zahavy et al., 2018). In terms of learning speed, the methods which have access to either the graph attention or the graph mask converge slightly faster than pure A2C which has neither.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Game</th>
<th style="text-align: center;">$|T|$</th>
<th style="text-align: center;">$|V|$</th>
<th style="text-align: center;">TDQN</th>
<th style="text-align: center;">KGA2C</th>
<th style="text-align: center;">MaxRew</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">905</td>
<td style="text-align: center;">82</td>
<td style="text-align: center;">296</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">acorncourt</td>
<td style="text-align: center;">151</td>
<td style="text-align: center;">343</td>
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td style="text-align: center;">advent $^{1}$</td>
<td style="text-align: center;">189</td>
<td style="text-align: center;">786</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">350</td>
</tr>
<tr>
<td style="text-align: center;">adventureland</td>
<td style="text-align: center;">156</td>
<td style="text-align: center;">398</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">anchor</td>
<td style="text-align: center;">260</td>
<td style="text-align: center;">2257</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: center;">awaken</td>
<td style="text-align: center;">159</td>
<td style="text-align: center;">505</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">50</td>
</tr>
<tr>
<td style="text-align: center;">balances</td>
<td style="text-align: center;">156</td>
<td style="text-align: center;">452</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">51</td>
</tr>
<tr>
<td style="text-align: center;">deephome</td>
<td style="text-align: center;">173</td>
<td style="text-align: center;">760</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">300</td>
</tr>
<tr>
<td style="text-align: center;">detective</td>
<td style="text-align: center;">197</td>
<td style="text-align: center;">344</td>
<td style="text-align: center;">169</td>
<td style="text-align: center;">207.9</td>
<td style="text-align: center;">360</td>
</tr>
<tr>
<td style="text-align: center;">dragon</td>
<td style="text-align: center;">177</td>
<td style="text-align: center;">1049</td>
<td style="text-align: center;">-5.3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">25</td>
</tr>
<tr>
<td style="text-align: center;">enchanter</td>
<td style="text-align: center;">290</td>
<td style="text-align: center;">722</td>
<td style="text-align: center;">8.6</td>
<td style="text-align: center;">12.1</td>
<td style="text-align: center;">400</td>
</tr>
<tr>
<td style="text-align: center;">inhumane</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">409</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">300</td>
</tr>
<tr>
<td style="text-align: center;">jewel</td>
<td style="text-align: center;">161</td>
<td style="text-align: center;">657</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">90</td>
</tr>
<tr>
<td style="text-align: center;">karn</td>
<td style="text-align: center;">161</td>
<td style="text-align: center;">657</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">90</td>
</tr>
<tr>
<td style="text-align: center;">library</td>
<td style="text-align: center;">173</td>
<td style="text-align: center;">510</td>
<td style="text-align: center;">6.3</td>
<td style="text-align: center;">14.3</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td style="text-align: center;">ludicorp</td>
<td style="text-align: center;">187</td>
<td style="text-align: center;">503</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">150</td>
</tr>
<tr>
<td style="text-align: center;">moonlit</td>
<td style="text-align: center;">166</td>
<td style="text-align: center;">669</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">omniquext</td>
<td style="text-align: center;">207</td>
<td style="text-align: center;">460</td>
<td style="text-align: center;">16.8</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">50</td>
</tr>
<tr>
<td style="text-align: center;">pentari</td>
<td style="text-align: center;">155</td>
<td style="text-align: center;">472</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">50.7</td>
<td style="text-align: center;">70</td>
</tr>
<tr>
<td style="text-align: center;">snacktime</td>
<td style="text-align: center;">201</td>
<td style="text-align: center;">468</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">50</td>
</tr>
<tr>
<td style="text-align: center;">sorcerer</td>
<td style="text-align: center;">288</td>
<td style="text-align: center;">1013</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">5.8</td>
<td style="text-align: center;">400</td>
</tr>
<tr>
<td style="text-align: center;">spellbekr</td>
<td style="text-align: center;">333</td>
<td style="text-align: center;">844</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">21.3</td>
<td style="text-align: center;">600</td>
</tr>
<tr>
<td style="text-align: center;">spirit</td>
<td style="text-align: center;">169</td>
<td style="text-align: center;">1112</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">1.3</td>
<td style="text-align: center;">250</td>
</tr>
<tr>
<td style="text-align: center;">temple</td>
<td style="text-align: center;">175</td>
<td style="text-align: center;">622</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">35</td>
</tr>
<tr>
<td style="text-align: center;">zenon</td>
<td style="text-align: center;">149</td>
<td style="text-align: center;">401</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3.9</td>
<td style="text-align: center;">350</td>
</tr>
<tr>
<td style="text-align: center;">zork1</td>
<td style="text-align: center;">237</td>
<td style="text-align: center;">697</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">34</td>
<td style="text-align: center;">350</td>
</tr>
<tr>
<td style="text-align: center;">zork3</td>
<td style="text-align: center;">214</td>
<td style="text-align: center;">564</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">.1</td>
<td style="text-align: center;">7</td>
</tr>
<tr>
<td style="text-align: center;">ztnu</td>
<td style="text-align: center;">186</td>
<td style="text-align: center;">607</td>
<td style="text-align: center;">4.9</td>
<td style="text-align: center;">9.2</td>
<td style="text-align: center;">100</td>
</tr>
</tbody>
</table>
<p>Table 1: Raw scores comparing KG-A2C to TDQN across a wide set of games supported by Jericho. ${ }^{1}$ Advent starts at a score of 36 .</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: Ablation results on Zork1, averaged across 5 independent runs.</p>
<p>To further understand these differences we performed a larger study across the full set of games comparing KG-A2C-full with KG-A2C-no-mask. The results in Table 2 show KG-A2C-full outperforms KG-A2C-no-mask on 10 games and is outperformed by KG-A2C-no-mask on 6. From this larger study we thus conclude the graph mask and knowledge graph are broadly useful components.</p>
<p>We perform two final ablations to study the importance of the supervised valid-action loss and the template action space:</p>
<p>KG-A2C-unsupervised In order to understand the importance of training with valid-actions, KG-A2C-unsupervised is not allowed to access the list of valid actions-the valid-action-losses $\mathcal{L}<em _mathrm_O="\mathrm{O">{\mathrm{T}}$ and $\mathcal{L}</em>$ now based on the full action set. Thus, the agent must explore the template action space manually. KG-A2C-unsupervised, when trained for the same number of steps as all the other agents, fails to achieve any score. We can infer that the valid action auxiliary loss remains an important part of the overall algorithm, and access to the knowledge graph alone is not yet sufficient for removing this auxiliary loss.}}$ are disabled and $\mathcal{L}_{\mathbb{E}</p>
<p>KG-A2C-seq discards the template action space and instead decodes actions word by word up to a maximum of four words. A supervised cross-entropy-based valid action loss $\mathcal{L}<em _valid="{valid" t__text="t_{\text">{\text {Valid }}$ is now calculated by selecting a random valid action $a</em>=0.5$ and the decoded action otherwise. All other components remain the same as in the full KG-A2C.}}} \in \operatorname{Valid}\left(s_{t}\right)$ and using each token in it as a target label. As this action space is orders of magnitude larger than template actions, we use teacher-forcing to enable more effective exploration while training the agent-executing $a_{t_{\text {valid }}}$ with a probability $p_{\text {valid }</p>
<p>KG-A2C-seq reaches a relatively low asymptotic performance of 8 points. This agent, using a action space consisting of the full vocabulary, performs significantly worse than the rest of the agents even when given the handicaps of teacher forcing and being allowed to train for significantly longerindicating that the template based action space is also necessary for effective exploration.</p>
<h1>7 CONCLUSION</h1>
<p>Tabula rasa reinforcement learning offers an intuitive paradigm for exploring goal driven, contextually aware natural language generation. The sheer size of the natural language action space, however, has proven to be out of the reach of existing algorithms. In this paper we introduced KG-A2C, a novel learning agent that demonstrates the feasibility of scaling reinforcement learning towards natural language actions spaces with hundreds of millions of actions. The key insight to being able to efficiently explore such large spaces is the combination of a knowledge-graph-based state space and a template-based action space. The knowledge graph serves as a means for the agent to understand its surroundings, accumulate information about the game, and disambiguate similar textual observations while the template-based action space lends a measure of structure that enables us to exploit that same knowledge graph for language generation. Together they constrain the vast space of possible actions into the compact space of sensible ones. A suite of experiments across a diverse set of 28 human-made IF games shows wide improvement over TDQN, the current state-of-the-art templatebased agent. Finally, an ablation study replicates state-of-the-art performance on Zork1 even though KG-A2C is using an action space six orders of magnitude larger than previous agents-indicating the overall efficacy of our combined state-action space.</p>
<h1>REFERENCES</h1>
<p>Prithviraj Ammanabrolu and Mark O. Riedl. Playing text-adventure games with graph-based deep reinforcement learning. In Proceedings of 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACLHLT 2019, 2019a.</p>
<p>Prithviraj Ammanabrolu and Mark O. Riedl. Transfer in deep reinforcement learning using knowledge graphs. CoRR, abs/1908.06556, 2019b.</p>
<p>Prithviraj Ammanabrolu, William Broniec, Alex Mueller, Jeremy Paul, and Mark O. Riedl. Toward automated quest generation in text-adventure games. CoRR, abs/1909.06283, 2019.</p>
<p>Gabor Angeli, Johnson Premkumar, Melvin Jose, and Christopher D. Manning. Leveraging Linguistic Structure For Open Domain Information Extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2015.</p>
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv:1409.0473, 2014.</p>
<p>Marc-Alexandre Côté, Ákos Kádár, Xingdi Yuan, Ben Kybartas, Tavian Barnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri, Mahmoud Adada, Wendy Tay, and Adam Trischler. Textworld: A learning environment for text-based games. CoRR, abs/1806.11532, 2018.</p>
<p>Nancy Fulda, Daniel Ricks, Ben Murdoch, and David Wingate. What can you do with a rock? affordance extraction via word embeddings. In IJCAI, pp. 1039-1045, 2017. doi: 10.24963/ijcai. 2017/144.</p>
<p>Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, William B. Dolan, Jianfeng Gao, Wen tau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI, 2017.</p>
<p>Jian Guan, Yansen Wang, and Minlie Huang. Story Ending Generation with Incremental Encoding and Commonsense Knowledge. arXiv:1808.10113v1, 2018.</p>
<p>Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Côté, and Xingdi Yuan. Interactive fiction games: A colossal adventure. CoRR, abs/1909.05398, 2019a.</p>
<p>Matthew J. Hausknecht, Ricky Loynd, Greg Yang, Adith Swaminathan, and Jason D. Williams. NAIL: A general interactive fiction agent. CoRR, abs/1902.04259, 2019b.</p>
<p>Ji He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Lihong Li, Li Deng, and Mari Ostendorf. Deep reinforcement learning with a natural language action space. In ACL, 2016.</p>
<p>Vishal Jain, William Fedus, Hugo Larochelle, Doina Precup, and Marc G. Bellemare. Algorithmic improvements for deep reinforcement learning applied to interactive fiction, 2019.</p>
<p>Taku Kudo and John Richardson. Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing. CoRR, abs/1808.06226, 2018.</p>
<p>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781, 2013.</p>
<p>Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International conference on machine learning, pp. 1928-1937, 2016.</p>
<p>Karthik Narasimhan, Tejas D. Kulkarni, and Regina Barzilay. Language understanding for textbased games using deep reinforcement learning. In EMNLP, pp. 1-11, 2015.</p>
<p>Jack Urbanek, Angela Fan, Siddharth Karamcheti, Saachi Jain, Samuel Humeau, Emily Dinan, Tim Rocktschel, Douwe Kiela, Arthur Szlam, and Jason Weston. Learning to speak and act in a fantasy text adventure game. CoRR, abs/1903.03094, 2019.</p>
<p>Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph Attention Networks. International Conference on Learning Representations (ICLR), 2018.</p>
<p>Xusen Yin and Jonathan May. Comprehensible context-driven text game playing. CoRR, abs/1905.02265, 2019.</p>
<p>Xingdi Yuan, Marc-Alexandre Côté, Jie Fu, Zhouhan Lin, Christopher Pal, Yoshua Bengio, and Adam Trischler. Interactive language learning by question answering. In EMNLP, 2019.</p>
<p>Tom Zahavy, Matan Haroush, Nadav Merlis, Daniel J Mankowitz, and Shie Mannor. Learn what not to learn: Action elimination with deep reinforcement learning. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31, pp. 3562-3573. Curran Associates, Inc., 2018.</p>
<p>Mikulás Zelinka. Using reinforcement learning to learn how to play text-based games. CoRR, abs/1801.01999, 2018.</p>
<h1>A Ablation ReSults</h1>
<p>| Game | $|T|$ | $|V|$ | KGA2C-Full | KGA2C-unmasked | MaxRew |
| :--: | :--: | :--: | :--: | :--: |
| 905 | 82 | 296 | 0 | 0 |
| acorncourt | 151 | 343 | 0.3 | 0.3 |
| advent $^{1}$ | 189 | 786 | 36 | 36 |
| adventureland | 156 | 398 | 0 | 0 |
| anchor | 260 | 2257 | 0 | 0 |
| awaken | 159 | 505 | 0 | 0 |
| balances | 156 | 452 | 10 | 10 |
| deephome | 173 | 760 | 1 | 29.2 |
| detective | 197 | 344 | 207.9 | 141 |
| dragon | 177 | 1049 | 0 | -.2 |
| enchanter | 290 | 722 | 12.1 | 7.6 |
| inhumane | 141 | 409 | 3 | 10.2 |
| jewel | 161 | 657 | 1.8 | 1.3 |
| karn | 161 | 657 | 0 | 0 |
| library | 173 | 510 | 14.3 | 9.6 |
| ludicorp | 187 | 503 | 17.8 | 17.9 |
| moonlit | 166 | 669 | 0 | 0 |
| omniquest | 207 | 460 | 3 | 5.4 |
| pentari | 155 | 472 | 50.7 | 50.4 |
| snacktime | 201 | 468 | 0 | 0 |
| sorcerer | 288 | 1013 | 5.8 | 16.8 |
| spellbrkr | 333 | 844 | 21.3 | 30.1 |
| spirit | 169 | 1112 | 1.3 | 1.3 |
| temple | 175 | 622 | 7.6 | 6.4 |
| zenon | 149 | 401 | 3.9 | 3.1 |
| zork1 | 237 | 697 | 34 | 27 |
| zork3 | 214 | 564 | .1 | .1 |
| ztuu | 186 | 607 | 9.2 | 5 |</p>
<p>Table 2: Ablations</p>
<h2>B IMPLEMENTATION DETAILS</h2>
<h2>B. 1 KNOWLEDGE GRAPH UpDATE RULES</h2>
<p>Candidate interactive objects are identified by performing part-of-speech tagging on the current observation, identifying singular and proper nouns as well as adjectives, and are then filtered by checking if they can be examined using the command examine $O B J$. Only the interactive objects not found in the inventory are linked to the node corresponding to the current room and the inventory items are linked to the "you" node. The only other rule applied uses the navigational actions performed by the agent to infer the relative positions of rooms, e.g. $\langle$ kitchen, down, cellar $\rangle$ when the agent performs go down when in the kitchen to move to the cellar.</p>
<h2>B. 2 TEMPLATE PREPROCESSING</h2>
<p>Templates are processed by selecting a single verb and preposition from the aliases. For the sake of agent explainability, we pick the verb and preposition that are most likely to be used by humans when playing IF games. This is done by assessing token frequencies from a dataset of human playthroughs such as those given in ClubFloyd ${ }^{5}$. This dataset consists of 425 unique play sessions and 273,469 state-action pairs. The examples given earlier, ([carry/hold/take] $\qquad$ ) and ([drop/throw/discard/put] $\qquad$ [at/against/on/onto] $\qquad$ ), would then be converted to take $\qquad$ and put $\qquad$ on $\qquad$ .</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Figure 4: Learning curves for KGA2C-full. Shaded regions indicate standard deviations.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: A map of the world of Zork1 with some initial rewards annotated. The blue arrow indicates a connection between the left and right maps, corresponding to the overworld and the dungeon.</p>
<h1>D ZORK1</h1>
<p>Zork1 was identified by Hausknecht et al. (2019a) to be one of the most difficult games in their suite and the subject of much prior work (Zahavy et al., 2018; Yin \&amp; May, 2019). Zork1 is one of the earliest IF games and is a dungeon-crawler-a player must explore a vast labyrinth while fighting off enemies and complete puzzles in order to collect treasures. It features a relatively sparse reward for collecting a treasure or moving along the right path to one, and stochasticity in terms of random enemy movements.</p>
<p>To understand how humans progress in Zork1, a group of 10 human players-familiar with IF games-were asked to play Zork1 for the first time (with no access to walkthroughs). Half of the players reached a game score of around 40 before dying to the first beatable NPC, a troll, mostly due to neglecting to collect a weapon to fight it with beforehand. Three of the remaining players died to hidden traps even before reaching this point, achieving scores between 5 and 15 . The final two players made it significantly past the troll gaining scores of around 70 .
The following transcript of KG-A2C playing Zork1, shows top predicted probabilities for templates and objects.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Obs</span><span class="o">:</span><span class="w"> </span><span class="n">Desc</span><span class="o">:</span><span class="w"> </span><span class="n">West</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">House</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">standing</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="n">west</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">white</span><span class="w"> </span><span class="n">house</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">boarded</span><span class="w"> </span><span class="n">front</span><span class="w"> </span><span class="n">door</span><span class="o">.</span>
<span class="w">    </span><span class="n">There</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">mailbox</span><span class="w"> </span><span class="n">here</span><span class="o">.</span><span class="w"> </span><span class="n">Inv</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">emptyhanded</span><span class="o">.</span><span class="w"> </span><span class="n">Feedback</span><span class="o">:</span><span class="w"> </span><span class="n">West</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">House</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">standing</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span>
<span class="w">    </span><span class="n">open</span><span class="w"> </span><span class="n">field</span><span class="w"> </span><span class="n">west</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">white</span><span class="w"> </span><span class="n">house</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">boarded</span><span class="w"> </span><span class="n">front</span><span class="w"> </span><span class="n">door</span><span class="o">.</span><span class="w"> </span><span class="n">There</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">small</span><span class="w"> </span><span class="n">mailbox</span><span class="w"> </span><span class="n">here</span><span class="o">.</span>
<span class="n">Template</span><span class="w"> </span><span class="n">probs</span><span class="o">:</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.339</span><span class="o">,</span><span class="w"> </span><span class="n">east</span><span class="o">:</span><span class="w"> </span><span class="mf">0.271</span><span class="o">,</span><span class="w"> </span><span class="n">south</span><span class="o">:</span><span class="w"> </span><span class="mf">0.215</span><span class="o">,</span><span class="w"> </span><span class="n">west</span><span class="o">:</span><span class="w"> </span><span class="mf">0.094</span><span class="o">,</span><span class="w"> </span><span class="n">north</span><span class="o">:</span><span class="w"> </span><span class="mf">0.031</span><span class="o">,</span><span class="w"> </span><span class="n">go</span><span class="w"> </span><span class="n">around</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.013</span><span class="o">,</span>
<span class="w">        </span><span class="n">blow</span><span class="w"> </span><span class="n">out</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.011</span><span class="o">,</span><span class="w"> </span><span class="k">throw</span><span class="w"> </span><span class="n">OBJ</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.01</span><span class="o">,</span><span class="w"> </span><span class="n">northwest</span><span class="o">:</span><span class="w"> </span><span class="mf">0.009</span>
<span class="n">Object</span><span class="w"> </span><span class="n">probs</span><span class="o">:</span><span class="w"> </span><span class="n">window</span><span class="o">:</span><span class="w"> </span><span class="mf">0.7</span><span class="o">,</span><span class="w"> </span><span class="n">small</span><span class="o">:</span><span class="w"> </span><span class="mf">0.299</span>
<span class="n">Interactive</span><span class="w"> </span><span class="n">objects</span><span class="o">:</span><span class="w"> </span><span class="n">boarded</span><span class="o">,</span><span class="w"> </span><span class="n">small</span><span class="o">,</span><span class="w"> </span><span class="n">front</span><span class="o">,</span><span class="w"> </span><span class="n">door</span><span class="o">,</span><span class="w"> </span><span class="n">white</span><span class="o">,</span><span class="w"> </span><span class="n">mailbox</span><span class="o">,</span><span class="w"> </span><span class="n">house</span><span class="o">,</span><span class="w"> </span><span class="n">all</span>
<span class="n">Action</span><span class="o">:</span><span class="w"> </span><span class="n">west</span>
<span class="n">Score</span><span class="o">:</span><span class="w"> </span><span class="mi">0</span>
<span class="n">Obs</span><span class="o">:</span><span class="w"> </span><span class="n">Desc</span><span class="o">:</span><span class="w"> </span><span class="n">Forest</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">forest</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">trees</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">directions</span><span class="o">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span><span class="o">,</span><span class="w"> </span><span class="n">there</span><span class="w"> </span><span class="n">appears</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">sunlight</span><span class="o">.</span>
<span class="w">    </span><span class="n">Inv</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">emptyhanded</span><span class="o">.</span><span class="w"> </span><span class="n">Feedback</span><span class="o">:</span><span class="w"> </span><span class="n">Forest</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">forest</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">trees</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">directions</span><span class="o">.</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">east</span><span class="o">,</span>
<span class="w">    </span><span class="n">there</span><span class="w"> </span><span class="n">appears</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">sunlight</span><span class="o">.</span>
<span class="n">Template</span><span class="w"> </span><span class="n">probs</span><span class="o">:</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.49</span><span class="o">,</span><span class="w"> </span><span class="n">south</span><span class="o">:</span><span class="w"> </span><span class="mf">0.304</span><span class="o">,</span><span class="w"> </span><span class="n">east</span><span class="o">:</span><span class="w"> </span><span class="mf">0.116</span><span class="o">,</span><span class="w"> </span><span class="n">west</span><span class="o">:</span><span class="w"> </span><span class="mf">0.04</span><span class="o">,</span><span class="w"> </span><span class="n">north</span><span class="o">:</span><span class="w"> </span><span class="mf">0.016</span><span class="o">,</span><span class="w"> </span><span class="n">go</span><span class="w"> </span><span class="n">around</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.011</span><span class="o">,</span>
<span class="w">        </span><span class="k">throw</span><span class="w"> </span><span class="n">OBJ</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.006</span><span class="o">,</span><span class="w"> </span><span class="n">northwest</span><span class="o">:</span><span class="w"> </span><span class="mf">0.006</span><span class="o">,</span><span class="w"> </span><span class="n">blow</span><span class="w"> </span><span class="n">out</span><span class="w"> </span><span class="n">OBJ</span><span class="o">:</span><span class="w"> </span><span class="mf">0.006</span>
<span class="n">Object</span><span class="w"> </span><span class="n">probs</span><span class="o">:</span><span class="w"> </span><span class="n">window</span><span class="o">:</span><span class="w"> </span><span class="mf">0.7</span><span class="o">,</span><span class="w"> </span><span class="n">small</span><span class="o">:</span><span class="w"> </span><span class="mf">0.3</span>
<span class="n">Interactive</span><span class="w"> </span><span class="n">objects</span><span class="o">:</span><span class="w"> </span><span class="n">forest</span><span class="o">,</span><span class="w"> </span><span class="n">all</span><span class="o">,</span><span class="w"> </span><span class="n">trees</span>
<span class="n">Action</span><span class="o">:</span><span class="w"> </span><span class="n">east</span>
<span class="n">Score</span><span class="o">:</span><span class="w"> </span><span class="mi">0</span>
<span class="n">Obs</span><span class="o">:</span><span class="w"> </span><span class="n">Desc</span><span class="o">:</span><span class="w"> </span><span class="n">Forest</span><span class="w"> </span><span class="n">Path</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="n">winding</span><span class="w"> </span><span class="n">through</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dimly</span><span class="w"> </span><span class="n">lit</span><span class="w"> </span><span class="n">forest</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="n">heads</span><span class="w"> </span><span class="n">northsouth</span><span class="w"> </span><span class="n">here</span><span class="o">.</span><span class="w"> </span><span class="n">One</span>
<span class="w">    </span><span class="n">particularly</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">tree</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">low</span><span class="w"> </span><span class="n">branches</span><span class="w"> </span><span class="n">stands</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">edge</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">path</span><span class="o">.</span><span class="w"> </span><span class="n">Inv</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">emptyhanded</span><span class="o">.</span>
<span class="w">    </span><span class="n">Feedback</span><span class="o">:</span><span class="w"> </span><span class="n">Forest</span><span class="w"> </span><span class="n">Path</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="n">winding</span><span class="w"> </span><span class="n">through</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dimly</span><span class="w"> </span><span class="n">lit</span><span class="w"> </span><span class="n">forest</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="n">heads</span><span class="w"> </span><span class="n">northsouth</span><span class="w"> </span><span class="n">here</span>
<span class="w">    </span><span class="o">.</span><span class="w"> </span><span class="n">One</span><span class="w"> </span><span class="n">particularly</span><span class="w"> </span><span class="n">large</span><span class="w"> </span><span class="n">tree</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">low</span><span class="w"> </span><span class="n">branches</span><span class="w"> </span><span class="n">stands</span><span class="w"> </span><span class="n">at</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">edge</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">path</span><span class="o">.</span>
</code></pre></div>

<p>Template probs: up: 0.386, open OBJ: 0.358, east: 0.123, west: 0.06, north: 0.023, go around OBJ: 0.014, blow out OBJ: 0.01, northwest: 0.009, throw OBJ at OBJ: 0.008
Object probs: window: 0.701, small: 0.299
Interactive objects: tree, path, branches, forest, large, all
Action: up
Score: 0
Obs: Desc: Up a Tree You are about 10 feet above the ground nestled among some large branches. The nearest branch above you is above your reach. Beside you on the branch is a small birds nest. In the birds nest is a large egg encrusted with precious jewels, apparently scavenged by a childless songbird. The egg is covered with fine gold inlay, and ornamented in lapis lazuli and motherofpearl. Unlike most eggs, this one is hinged and closed with a delicate looking clasp. The egg appears extremely fragile. Inv: You are emptyhanded. Feedback: Up a Tree You are about 10 feet above the ground nestled among some large branches. The nearest branch above you is above your reach. Beside you on the branch is a small birds nest. In the birds nest is a large egg encrusted with precious jewels, apparently scavenged by a childless songbird. The egg is covered with fine gold inlay, and ornamented in lapis lazuli and motherofpearl. Unlike most eggs, this one is hinged and closed with a delicate looking clasp. The egg appears extremely fragile.
Template probs: west: 0.43 , open OBJ: 0.18 , go around OBJ: 0.074 , east: 0.064 , north: 0.063 , south: 0.052 , take OBJ: 0.041 , put down OBJ: 0.023 , down: 0.014 , close OBJ: 0.009
Object probs: small: 0.213 , window: 0.184 , house: 0.116 , egg: 0.068 , white: 0.067 , path: 0.062 , branch: 0.042 , kitche: 0.024 , nest: 0.018 , ground: 0.009
Interactive objects: nest, large, egg, ground, branches, all, branch, tree
Action: open nest
Score: 0
Obs: Desc: Up a Tree You are about 10 feet above the ground nestled among some large branches. The nearest branch above you is above your reach. Beside you on the branch is a small birds nest. In the birds nest is a large egg encrusted with precious jewels, apparently scavenged by a childless songbird. The egg is covered with fine gold inlay, and ornamented in lapis lazuli and motherofpearl. Unlike most eggs, this one is hinged and closed with a delicate looking clasp. The egg appears extremely fragile. You hear in the distance the chirping of a song bird. Inv: You are emptyhanded. You hear in the distance the chirping of a song bird. Feedback: It is already open.
Template probs: west: 0.347 , open OBJ: 0.182 , go around OBJ: 0.085 , east: 0.077 , north: 0.073 , south: 0.058 , take OBJ: 0.045 , put down OBJ: 0.026 , down: 0.018 , close OBJ: 0.013
Object probs: small: 0.213 , window: 0.183 , house: 0.117 , egg: 0.068 , white: 0.067 , path: 0.062 , branch: 0.042 , kitche: 0.024 , nest: 0.018 , ground: 0.009
Interactive objects: nest, large, egg, ground, branches, all, branch, tree
Action: take egg
Score: 0
Obs: Desc: Up a Tree You are about 10 feet above the ground nestled among some large branches. The nearest branch above you is above your reach. Beside you on the branch is a small birds nest. Inv: You are carrying A jewelencrusted egg Feedback: Taken.
Template probs: down: 0.417 , open OBJ: 0.181 , go around OBJ: 0.076 , east: 0.065 , north: 0.063 , south: 0.053 , take OBJ: 0.042 , put down OBJ: 0.025 , down: 0.014 , close OBJ: 0.01
Object probs: small: 0.213 , window: 0.184 , house: 0.116 , egg: 0.068 , white: 0.067 , path: 0.062 , branch: 0.042 , kitche: 0.024 , nest: 0.018 , ground: 0.009
Interactive objects: nest, large, egg, ground, branches, all, branch, tree
Action: down
Score: 5
Obs: Desc: Forest Path This is a path winding through a dimly lit forest. The path heads northsouth here. One particularly large tree with some low branches stands at the edge of the path. Inv: You are emptyhanded. Feedback: Forest Path
Template probs: south: 0.386 , open OBJ: 0.358 , east: 0.123 , west: 0.06 , north: 0.023 , go around OBJ: 0.014 , blow out OBJ: 0.01 , northwest: 0.009 , throw OBJ at OBJ: 0.008
Object probs: window: 0.701, small: 0.299
Interactive objects: tree, path, branches, forest, large, all
Action: south
Score: 5
Obs: Desc: North of House You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees. Inv: You are emptyhanded. Feedback: North of House You are facing the north side of a white house. There is no door here, and all the windows are boarded up. To the north a narrow path winds through the trees.
Template probs: west: 0.502 , open OBJ: 0.177 , west: 0.147 , north: 0.094 , south: 0.035 , throw OBJ at OBJ: 0.012 , go around OBJ: 0.012 , northwest: 0.01 , blow out OBJ: 0.005</p>
<p>Object probs: window: 0.724 , small: 0.243 , trap: 0.014 , kitche: 0.009 , rug: 0.003
Interactive objects: path, windows, narrow, white, house, all
Action: west
Score: 5
Obs: Desc: West of House You are standing in an open field west of a white house, with a boarded front door. There is a small mailbox here. Inv: You are emptyhanded. Feedback:
Template probs: open OBJ: 0.536 , south: 0.241 , east: 0.121 , west: 0.053 , north: 0.015 , go around OBJ: 0.011 , throw OBJ at OBJ: 0.007 , blow out OBJ: 0.006 , northwest: 0.005
Object probs: window: 0.7 , small: 0.3
Interactive objects: boarded, small, front, door, white, mailbox, house, all
Action: open white
Score: 5
Obs: Desc: West of House You are standing in an open field west of a white house, with a boarded front door. There is a small mailbox here. Inv: You are emptyhanded. Feedback: I cant see how to get in from here.
Template probs: open OBJ: 0.339 , east: 0.271 , south: 0.215 , west: 0.094 , north: 0.031 , go around OBJ: 0.013 , blow out OBJ: 0.011 , throw OBJ at OBJ: 0.01 , northwest: 0.009
Object probs: window: 0.7 , small: 0.299
Interactive objects: boarded, small, front, door, white, mailbox, house, all
Action: west
Score: 5</p>
<p>Obs: Desc: Forest This is a forest, with trees in all directions. To the east, there appears to be sunlight. Inv: You are emptyhanded. Feedback: Forest This is a forest, with trees in all directions. To the east, there appears to be sunlight.
Template probs: open OBJ: 0.49, south: 0.304, east: 0.116, west: 0.04, north: 0.016, go around OBJ: 0.011, throw OBJ at OBJ: 0.006, northwest: 0.006, blow out OBJ: 0.006
Object probs: window: 0.7, small: 0.3
Interactive objects: forest, all, trees
Action: east
Score: 5
Obs: Desc: Forest Path This is a path winding through a dimly lit forest. The path heads northsouth here. One particularly large tree with some low branches stands at the edge of the path. Inv: You are emptyhanded. Feedback: Forest Path This is a path winding through a dimly lit forest. The path heads northsouth here . One particularly large tree with some low branches stands at the edge of the path.
Template probs: south: 0.386, open OBJ: 0.358, east: 0.123, west: 0.06, north: 0.023, go around OBJ: 0.014, blow out OBJ: 0.01, northwest: 0.009 , throw OBJ at OBJ: 0.008
Object probs: window: 0.701, small: 0.298
Interactive objects: tree, path, branches, forest, large, all
Action: open all
Score: 5
Obs: Desc: Forest Path This is a path winding through a dimly lit forest. The path heads northsouth here. One particularly large tree with some low branches stands at the edge of the path. Inv: You are emptyhanded. Feedback: Its not clear what youre referring to.
Template probs: open OBJ: 0.331, south: 0.255, east: 0.24, west: 0.087, north: 0.031, go around OBJ: 0.013, blow out OBJ: 0.011, northwest: 0.01, throw OBJ at OBJ: 0.009
Object probs: window: 0.701, small: 0.299
Interactive objects: tree, path, branches, forest, large, all
Action: east
Score: 5
Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. You hear in the distance the chirping of a song bird. Feedback: Forest This is a dimly lit forest, with large trees all around. You hear in the distance the chirping of a song bird.
Template probs: south: 0.38, open OBJ: 0.281, east: 0.174, west: 0.072, north: 0.034, go around OBJ: 0.015, blow out OBJ: 0.013, northwest: 0.012, throw OBJ at OBJ: 0.008
Object probs: window: 0.7, small: 0.299
Interactive objects: forest, large, all, trees
Action: south
Score: 5
Obs: Desc: Clearing You are in a small clearing in a well marked forest path that extends to the east and west . Inv: You are emptyhanded. Feedback: Clearing You are in a small clearing in a well marked forest path that extends to the east and west.
Template probs: open OBJ: 0.451, east: 0.364, west: 0.164, north: 0.008, throw OBJ at OBJ: 0.005
Object probs: window: 0.592, small: 0.405, kitches: 0.002
Interactive objects: forest, path, all
Action: east
Score: 5
Obs: Desc: Canyon View You are at the top of the Great Canyon on its west wall. From here there is a marvelous view of the canyon and parts of the Frigid River upstream. Across the canyon, the walls of the White Cliffs join the mighty ramparts of the Flathead Mountains to the east. Following the Canyon upstream to the north, Aragain Falls may be seen, complete with rainbow. The mighty Frigid River flows out from a great dark cavern. To the west and south can be seen an immense forest, stretching for miles around. A path leads northwest. It is possible to climb down into the canyon from here. Inv: You are emptyhanded. Feedback: Canyon View You are at the top of the Great Canyon on its west wall. From here there is a marvelous view of the canyon and parts of the Frigid River upstream. Across the canyon, the walls of the White Cliffs join the mighty ramparts of the Flathead Mountains to the east. Following the Canyon upstream to the north, Aragain Falls may be seen, complete with rainbow. The mighty Frigid River flows out from a great dark cavern. To the west and south can be seen an immense forest, stretching for miles around. A path leads northwest. It is possible to climb down into the canyon from here.
Template probs: west: 0.444, take OBJ: 0.204, open OBJ: 0.147, blow out OBJ: 0.118, turn on OBJ: 0.027, east: 0.026, down: 0.009, go around OBJ: 0.005, push OBJ: 0.004</p>
<p>Object probs: window: 0.693, small: 0.307
Interactive objects: path, walls, frigid, river, rainbow, wall, all
Action: west
Score: 5
Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. Feedback: Forest This is a dimly lit forest, with large trees all around.
Template probs: south: 0.494, open OBJ: 0.241, east: 0.105, west: 0.053, north: 0.038, go around OBJ: 0.018, northwest: 0.015, blow out OBJ: 0.014, throw OBJ at OBJ: 0.007, down: 0.005
Object probs: window: 0.699, small: 0.301
Interactive objects: forest, large, all, trees
Action: south
Score: 5
Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. Feedback: Stormtossed trees block your way.
Template probs: east: 0.722, north: 0.067, west: 0.061, open OBJ: 0.061, south: 0.048, blow out OBJ: 0.011, northwest: 0.01, go around OBJ: 0.007, throw OBJ at OBJ: 0.005
Object probs: window: 0.7, small: 0.3
Interactive objects: storm, forest, trees, large, all
Action: east
Score: 5
Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. Feedback: The rank undergrowth prevents eastward movement.
Template probs: south: 0.434, open OBJ: 0.339, east: 0.076, west: 0.065, north: 0.024, go around OBJ: 0.02, northwest: 0.012, blow out OBJ: 0.011, throw OBJ at OBJ: 0.009
Object probs: window: 0.701, small: 0.299</p>
<h1>Interactive objects: forest, large, all, trees</h1>
<p>Action: jump
Score: 5</p>
<p>Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. Feedback: Whassessssss!!!!! You hear in the distance the chirping of a song bird.
Template probs: south: 0.438 , open OBJ: 0.292 , east: 0.098 , west: 0.075 , north: 0.03 , go around OBJ: 0.019 , northwest: 0.013 , blow out OBJ: 0.012 , throw OBJ at OBJ: 0.01
Object probs: window: 0.7, small: 0.299
Interactive objects: forest, large, all, trees
Action: south
Score: 5
Obs: Desc: Forest This is a dimly lit forest, with large trees all around. Inv: You are emptyhanded. Feedback: Stormtossed trees block your way.
Template probs: east: 0.694 , west: 0.081 , north: 0.07 , open OBJ: 0.067 , south: 0.043 , northwest: 0.012 , blow out OBJ: 0.011 , go around OBJ: 0.007 , throw OBJ at OBJ: 0.006
Object probs: window: 0.7, small: 0.3
Interactive objects: storm, forest, trees, large, all
Action: north
Score: 5
Obs: Desc: Clearing You are in a small clearing in a well marked forest path that extends to the east and west - Inv: You are emptyhanded. Feedback: Clearing</p>
<p>Template probs: west: 0.437 , east: 0.311 , open OBJ: 0.171 , north: 0.026 , throw OBJ at OBJ: 0.015 , south: 0.013 , blow out OBJ: 0.011 , go around OBJ: 0.006 , northwest: 0.006</p>
<p>Object probs: window: 0.699 , small: 0.301
Interactive objects: forest, path, all
Action: throw path at forest
Score: 5
Obs: Desc: Clearing You are in a small clearing in a well marked forest path that extends to the east and west - Inv: You are emptyhanded. Feedback: You dont have the way.
Template probs: open OBJ: 0.377 , west: 0.341 , east: 0.149 , south: 0.057 , north: 0.022 , throw OBJ at OBJ: 0.018 , blow out OBJ: 0.011 , go around OBJ: 0.011 , northwest: 0.008</p>
<p>Object probs: window: 0.7, small: 0.299
Interactive objects: forest, path, all
Action: west
Score: 5
Obs: Desc: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar. Inv: You are emptyhanded. Feedback: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar.
Template probs: open OBJ: 0.953 , west: 0.036 , south: 0.006
Object probs: small: 0.898 , window: 0.102
Interactive objects: path, window, small, white, house, all
Action: open house
Score: 5
Obs: Desc: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar. Inv: You are emptyhanded. Feedback: The window is closed.
Template probs: open OBJ: 0.943 , west: 0.047
Object probs: small: 0.88 , window: 0.12
Interactive objects: path, window, small, white, house, all
Action: open path
Score: 5
Obs: Desc: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is slightly ajar. Inv: You are emptyhanded. Feedback: You must tell me how to do that to a way.
Template probs: open OBJ: 0.899 , east: 0.048 , west: 0.044 , south: 0.004
Object probs: window: 0.58, small: 0.417 , kitche: 0.002
Interactive objects: path, window, small, white, house, all
Action: open window
Score: 5
Obs: Desc: Behind House You are behind the white house. A path leads into the forest to the east. In one corner of the house there is a small window which is open. Inv: You are emptyhanded. Feedback: With great effort, you open the window far enough to allow entry.
Template probs: west: 0.997
Object probs: small: 0.951 , window: 0.049
Interactive objects: path, window, small, white, house, all
Action: west
Score: 5
Obs: Desc: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains A quantity of water Inv: You are emptyhanded. Feedback: Kitchen You are in the kitchen of the white house. A table seems to have been used recently for the preparation of food. A passage leads to the west and a dark staircase can be seen leading upward. A dark chimney leads down and to the east is a small window which is open. On the table is an elongated brown sack, smelling of hot peppers. A bottle is sitting on the table. The glass bottle contains A quantity of water
Template probs: take OBJ: 0.47 , west: 0.351 , turn on OBJ: 0.061 , blow out OBJ: 0.052 , down: 0.023 , open OBJ: 0.012 , east: 0.008 , close OBJ: 0.006 , throw OBJ at OBJ: 0.006</p>
<p>Object probs: window: 0.683 , small: 0.317
Interactive objects: kitchen, window, passage, staircase, glass, sack, water, small, table, chimney, bottle, quantity, brown, all
Action: west</p>
<p>Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. A batterypowered brass lantern is on the trophy case. Inv: You are emptyhanded. Feedback: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. A batterypowered brass lantern is on the trophy case.
Template probs: take OBJ: 0.454, west: 0.241, turn on OBJ: 0.107, open OBJ: 0.053, down: 0.05, blow out OBJ: 0.034, close OBJ: 0.016, throw OBJ at OBJ: 0.011, east: 0.009, north: 0.005
Object probs: window: 0.685, small: 0.315
Interactive objects: elvish, strange, trophy, brass, wooden, rug, oriental, lettering, antiquity, sword, gothic, west, door, large, lantern, case, all
Action: take brass
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern Feedback: Taken.
Template probs: open OBJ: 0.48, push OBJ: 0.138, west: 0.088, take OBJ: 0.067, turn on OBJ: 0.059, throw OBJ at OBJ: 0.031, put down OBJ: 0.023, put OBJ in OBJ: 0.018, put OBJ on OBJ: 0.016, down: 0.015
Object probs: window: 0.685, small: 0.315
Interactive objects: elvish, strange, trophy, brass, wooden, rug, oriental, lettering, antiquity, sword, gothic, west, door, large, lantern, case, all
Action: turn on brass
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The brass lantern is now on.
Template probs: open OBJ: 0.438, push OBJ: 0.141, west: 0.088, take OBJ: 0.081, turn on OBJ: 0.061, throw OBJ at OBJ: 0.036, put down OBJ: 0.023, put OBJ in OBJ: 0.019, down: 0.018, put OBJ on OBJ: 0.018
Object probs: window: 0.685, small: 0.315
Interactive objects: brass, strange, trophy, elvish, rug, oriental, light, lettering, antiquity, sword, gothic , west, door, large, wooden, lantern, case, all
Action: take trophy
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The trophy case is securely fastened to the wall. Template probs: open OBJ: 0.437, push OBJ: 0.141, west: 0.087, take OBJ: 0.082, turn on OBJ: 0.061, throw OBJ at OBJ: 0.035, put down OBJ: 0.024, down: 0.019, put OBJ on OBJ: 0.018, put OBJ in OBJ: 0.018
Object probs: window: 0.684, small: 0.315
Interactive objects: strange, trophy, case, antiquity, lantern, lettering, sword, gothic, wooden, wall, elvish , brass, west, rug, oriental, door, large, light, all
Action: push case
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: Pushing the trophy case has no effect.
Template probs: open OBJ: 0.487, push OBJ: 0.145, take OBJ: 0.09, west: 0.085, turn on OBJ: 0.062, throw OBJ at OBJ: 0.037, put down OBJ: 0.024, down: 0.021, put OBJ on OBJ: 0.019, put OBJ in OBJ: 0.019
Object probs: window: 0.686, small: 0.314
Interactive objects: elvish, strange, trophy, brass, wooden, rug, oriental, case, lettering, antiquity, sword, gothic, west, door, large, lantern, light, all
Action: push lanter
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: Pushing the brass lantern isnt notably helpful. Template probs: open OBJ: 0.405, push OBJ: 0.144, west: 0.093, take OBJ: 0.089, turn on OBJ: 0.062, throw OBJ at OBJ: 0.038, put down OBJ: 0.025, put OBJ on OBJ: 0.02, down: 0.019, put OBJ in OBJ: 0.019
Object probs: window: 0.685, small: 0.315
Interactive objects: brass, strange, trophy, elvish, rug, oriental, light, lettering, antiquity, sword, gothic , west, door, large, wooden, lantern, case, all
Action: open wooden
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door cannot be opened.
Template probs: open OBJ: 0.438, push OBJ: 0.142, take OBJ: 0.081, west: 0.08, turn on OBJ: 0.062, throw OBJ at OBJ: 0.035, put down OBJ: 0.024, down: 0.02, put OBJ in OBJ: 0.018, put OBJ on OBJ: 0.018
Object probs: window: 0.685, small: 0.315
Interactive objects: elvish, strange, trophy, brass, wooden, rug, oriental, case, lettering, antiquity, sword, gothic, west, door, large, lantern, light, all
Action: open brass
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a large oriental rug</p>
<p>in the center of the room. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: You must tell me how to do that to a brass lantern. Template probs: open OBJ: 0.503, push OBJ: 0.129, west: 0.1, take OBJ: 0.053, turn on OBJ: 0.051, throw OBJ at OBJ: 0.041, put down OBJ: 0.029, put OBJ in OBJ: 0.021, put OBJ on OBJ: 0.02, down: 0.009
Object probs: window: 0.677, small: 0.323
Interactive objects: brass, strange, trophy, elvish, rug, oriental, light, lettering, antiquity, sword, gothic , west, door, large, wooden, lantern, case, all
Action: push rug
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: With a great effort, the rug is moved to one side of the room, revealing the dusty cover of a closed trap door.
Template probs: open OBJ: 0.582, push OBJ: 0.082, down: 0.074, take OBJ: 0.065, put down OBJ: 0.025, turn on OBJ: 0.025, west: 0.023, close OBJ: 0.021, throw OBJ at OBJ: 0.019, put OBJ in OBJ: 0.016
Object probs: window: 0.674, small: 0.326
Interactive objects: dusty, strange, trophy, cover, case, antiquity, lantern, lettering, sword, gothic, wooden , elvish, brass, west, rug, trap, door, light, all
Action: west
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door is nailed shut.
Template probs: open OBJ: 0.679, push OBJ: 0.073, down: 0.057, take OBJ: 0.046, put down OBJ: 0.022, turn on OBJ: 0.019, west: 0.017, close OBJ: 0.015, throw OBJ at OBJ: 0.015, put OBJ in OBJ: 0.015
Object probs: window: 0.672, small: 0.328
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: down
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The trap door is closed.
Template probs: open OBJ: 0.63, down: 0.087, take OBJ: 0.06, put down OBJ: 0.045, push OBJ: 0.04, west: 0.027, turn on OBJ: 0.02, close OBJ: 0.018, throw OBJ at OBJ: 0.018, put OBJ in OBJ: 0.015
Object probs: window: 0.657, small: 0.342
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, trap, door, wooden, lantern, light, all
Action: open sword
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: You must tell me how to do that to a sword.
Template probs: open OBJ: 0.625, down: 0.075, take OBJ: 0.053, push OBJ: 0.05, put down OBJ: 0.049, west: 0.028, turn on OBJ: 0.021, throw OBJ at OBJ: 0.02, close OBJ: 0.019, put OBJ in OBJ: 0.018
Object probs: window: 0.659, small: 0.34
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: open case
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: Opened.
Template probs: open OBJ: 0.61, down: 0.081, take OBJ: 0.056, push OBJ: 0.053, put down OBJ: 0.049, west: 0.029, turn on OBJ: 0.023, throw OBJ at OBJ: 0.02, put OBJ in OBJ: 0.019, close OBJ: 0.019
Object probs: window: 0.659, small: 0.341
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: open door
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: Which door do you mean, the wooden door or the trap door?
Template probs: open OBJ: 0.552, down: 0.085, take OBJ: 0.062, put down OBJ: 0.06, push OBJ: 0.055, west: 0.04, turn on OBJ: 0.026, throw OBJ at OBJ: 0.026, put OBJ in OBJ: 0.024, close OBJ: 0.021
Object probs: window: 0.66, small: 0.33
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, trap, door, wooden, lantern, light, all
Action: open all
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: You cant use multiple direct objects with "open".
Template probs: open OBJ: 0.529, down: 0.086, put down OBJ: 0.065, take OBJ: 0.063, push OBJ: 0.059, west: 0.044, throw OBJ at OBJ: 0.028, turn on OBJ: 0.028, put OBJ in OBJ: 0.028, close OBJ: 0.021
Object probs: window: 0.661, small: 0.339
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all</p>
<p>Action: down
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The trap door is closed.
Template probs: open OBJ: 0.569, down: 0.089, take OBJ: 0.063, put down OBJ: 0.059, push OBJ: 0.048, west: 0.036, turn on OBJ: 0.024, throw OBJ at OBJ: 0.024, put OBJ in OBJ: 0.021, close OBJ: 0.021
Object probs: window: 0.658, small: 0.341
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, trap, door, wooden, lantern, light, all
Action: shake gothic
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: You dont have the wooden door.
Template probs: open OBJ: 0.62, push OBJ: 0.085, take OBJ: 0.055, down: 0.053, west: 0.031, put down OBJ: 0.026, turn on OBJ: 0.025, throw OBJ at OBJ: 0.02, put OBJ in OBJ: 0.019, close OBJ: 0.014
Object probs: window: 0.668, small: 0.332
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: open west
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door cannot be opened.
Template probs: open OBJ: 0.648, push OBJ: 0.089, down: 0.053, take OBJ: 0.042, west: 0.025, turn on OBJ: 0.025, put down OBJ: 0.024, throw OBJ at OBJ: 0.021, put OBJ in OBJ: 0.02, close OBJ: 0.013
Object probs: window: 0.665, small: 0.335
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: open wooden
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door cannot be opened.
Template probs: open OBJ: 0.637, push OBJ: 0.081, down: 0.058, take OBJ: 0.05, put down OBJ: 0.024, west: 0.024, turn on OBJ: 0.024, close OBJ: 0.019, throw OBJ at OBJ: 0.017, put OBJ in OBJ: 0.016
Object probs: window: 0.671, small: 0.329
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: push sword
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: Pushing the sword doesnt seem to work.
Template probs: open OBJ: 0.591, push OBJ: 0.085, down: 0.073, take OBJ: 0.061, turn on OBJ: 0.025, put down OBJ: 0.024, west: 0.024, close OBJ: 0.02, throw OBJ at OBJ: 0.019, put OBJ in OBJ: 0.017
Object probs: window: 0.674, small: 0.326
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: open strang
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door cannot be opened.
Template probs: open OBJ: 0.614, push OBJ: 0.085, down: 0.065, take OBJ: 0.059, west: 0.024, turn on OBJ: 0.024, put down OBJ: 0.021, close OBJ: 0.017, throw OBJ at OBJ: 0.017, put OBJ in OBJ: 0.016
Object probs: window: 0.676, small: 0.323
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, door, trap, wooden, lantern, light, all
Action: down
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a closed trap door at your feet. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The trap door is closed.
Template probs: open OBJ: 0.665, down: 0.068, push OBJ: 0.052, take OBJ: 0.044, put down OBJ: 0.036, west: 0.026, turn on OBJ: 0.02, throw OBJ at OBJ: 0.018, put OBJ in OBJ: 0.017, close OBJ: 0.015
Object probs: window: 0.661, small: 0.339
Interactive objects: elvish, strange, trophy, brass, case, lettering, antiquity, sword, gothic, west, trap, door, wooden, lantern, light, all
Action: open trap
Score: 15
Obs: Desc: Living Room You are in the living room. There is a doorway to the east, a wooden door with strange gothic lettering to the west, which appears to be nailed shut, a trophy case, and a rug lying beside an open trap door. Above the trophy case hangs an elvish sword of great antiquity. Inv: You are carrying A brass lantern (providing light) Feedback: The door reluctantly opens to reveal a rickety staircase descending into darkness.</p>
<p>Template probs: down: 0.076, open OBJ: 0.046, take OBJ: 0.018, east: 0.013, close OBJ: 0.009, put down OBJ: 0.007, north: 0.006
Object probs: window: 0.604, small: 0.387, kitche: 0.006, trap: 0.003
Interactive objects: elvish, strange, trophy, brass, rug, staircase, case, lettering, antiquity, sword, gothic , west, door, trap, wooden, lantern, light, all
Action: down
Score: 15
Obs: Desc: It is pitch black. You are likely to be eaten by a grue. Inv: You are carrying A brass lantern Feedback: You have moved into a dark place. It is pitch black. You are likely to be eaten by a grue.
Template probs: take OBJ: 0.141, turn on OBJ: 0.14, open OBJ: 0.122, down: 0.117, close OBJ: 0.073, put down OBJ: 0.069, west: 0.065, push OBJ: 0.056, throw OBJ at OBJ: 0.054, south: 0.02
Object probs: lanter: 0.076, letter: 0.071, window: 0.061, door: 0.059, small: 0.052, gothic: 0.049, sword: 0.049, rug: 0.037, trophy: 0.035, west: 0.031</p>
<p>Interactive objects: brass, dark, lantern, black, all, grue
Action: down
Score: 40
Obs: Desc: It is pitch black. You are likely to be eaten by a grue. Inv: You are carrying A brass lantern Feedback: The chasm probably leads straight to the infernal regions.
Template probs: turn on OBJ: 0.167, take OBJ: 0.132, open OBJ: 0.125, down: 0.124, close OBJ: 0.076, push OBJ: 0.067, put down OBJ: 0.066, throw OBJ at OBJ: 0.056, west: 0.05, south: 0.024
Object probs: lanter: 0.077, letter: 0.071, window: 0.06, door: 0.059, small: 0.051, gothic: 0.05, sword: 0.049, rug: 0.037, trophy: 0.035, west: 0.031</p>
<p>Interactive objects: brass, chasm, lantern, black, all, grue
Action: turn on lanter
Score: 40
Obs: Desc: Cellar You are in a dark and damp cellar with a narrow passageway leading north, and a crawlway to the south. On the west is the bottom of a steep metal ramp which is unclimbable. There is a suspiciouslooking individual, holding a large bag, leaning against one wall. He is armed with a deadly stiletto. Inv: You are carrying A brass lantern (providing light) Feedback: You try to ascend the ramp, but it is impossible, and you slide back down.
Template probs: down: 0.246, open OBJ: 0.209, take OBJ: 0.122, close OBJ: 0.1, push OBJ: 0.082, turn on OBJ: 0.068, put down OBJ: 0.033, south: 0.029, west: 0.019, throw OBJ at OBJ: 0.016</p>
<p>Object probs: west: 0.08, small: 0.08, window: 0.073, door: 0.067, rug: 0.057, letter: 0.047, wooden: 0.045, gothic: 0.041, strang: 0.035, lanter: 0.034
Interactive objects: light, ramp, large, brass, stiletto, crawlway, dark, narrow, lantern, bag, suspicious, metal, all, wall, passageway
Action: take dark
Score: 40
Obs: Desc: Cellar You are in a dark and damp cellar with a narrow passageway leading north, and a crawlway to the south. On the west is the bottom of a steep metal ramp which is unclimbable. There is a suspiciouslooking individual, holding a large bag, leaning against one wall. He is armed with a deadly stiletto. Inv: You are carrying A brass lantern (providing light) Feedback: You cant be serious.
Template probs: down: 0.289, open OBJ: 0.201, take OBJ: 0.103, close OBJ: 0.091, turn on OBJ: 0.066, push OBJ: 0.065, put down OBJ: 0.043, throw OBJ at OBJ: 0.022, south: 0.021, west: 0.018
Object probs: west: 0.081, small: 0.076, window: 0.069, door: 0.068, rug: 0.057, letter: 0.048, wooden: 0.045, gothic: 0.042, strang: 0.036, lanter: 0.035
Interactive objects: light, ramp, large, brass, stiletto, crawlway, dark, narrow, lantern, bag, suspicious, metal, all, wall, passageway
Action: put out passag
Score: 40
Obs: Desc: Cellar You are in a dark and damp cellar with a narrow passageway leading north, and a crawlway to the south. On the west is the bottom of a steep metal ramp which is unclimbable. There is a suspiciouslooking individual, holding a large bag, leaning against one wall. He is armed with a deadly stiletto. The thief, finding nothing of value, left disgusted. Inv: You are carrying A brass lantern ( providing light) The thief, finding nothing of value, left disgusted. Feedback: Pushing the chute isnt notably helpful. Someone carrying a large bag is casually leaning against one of the walls here. He does not speak, but it is clear from his aspect that the bag will be taken only over his dead body.
Template probs: open OBJ: 0.211, take OBJ: 0.205, push OBJ: 0.188, south: 0.132, west: 0.105, close OBJ: 0.057, turn on OBJ: 0.026, go around OBJ: 0.02, east: 0.017, down: 0.016</p>
<p>Object probs: small: 0.112, window: 0.103, west: 0.075, door: 0.063, rug: 0.054, wooden: 0.044, letter: 0.04, gothic: 0.037, strang: 0.032, kitche: 0.031
Interactive objects: light, ramp, large, brass, stiletto, crawlway, walls, dark, narrow, thief, lantern, chute , bag, suspicious, metal, all, wall, passageway
Action: west
Score: 40
Obs: Desc: Cellar You are in a dark and damp cellar with a narrow passageway leading north, and a crawlway to the south. On the west is the bottom of a steep metal ramp which is unclimbable. There is a suspiciouslooking individual, holding a large bag, leaning against one wall. He is armed with a deadly stiletto. A quick thrust pinks your left arm, and blood starts to trickle down. Inv: You are carrying A brass lantern (providing light) The thief, finding nothing of value, left disgusted. Feedback: You dont have the way.
Template probs: take OBJ: 0.246, open OBJ: 0.211, push OBJ: 0.19, south: 0.091, west: 0.082, close OBJ: 0.059, turn on OBJ: 0.041, down: 0.026, go around OBJ: 0.017, east: 0.012
Object probs: small: 0.097, window: 0.087, west: 0.078, door: 0.065, rug: 0.056, wooden: 0.045, latter: 0.043, gothic: 0.038, strang: 0.034, lanter: 0.032
Interactive objects: light, ramp, large, brass, stiletto, crawlway, dark, narrow, lantern, bag, suspicious, metal, all, wall, passageway
Action: south
Score: 40
Obs: Desc: East of Chasm You are on the east edge of a chasm, the bottom of which cannot be seen. A narrow passage goes north, and the path you are on continues to the east. Inv: You are carrying A brass lantern (providing light) Feedback: The brass lantern is now on. East of Chasm You are on the east edge of a chasm, the bottom of which cannot be seen. A narrow passage goes north, and the path you are on continues to the east.</p>
<p>Template probs: put down OBJ: 0.132, take OBJ: 0.116, east: 0.1, open OBJ: 0.093, close OBJ: 0.09, turn on OBJ : 0.07 , throw OBJ at OBJ: 0.061 , west: 0.059 , push OBJ: 0.057 , down: 0.042
Object probs: window: 0.074, small: 0.057, lanter: 0.046, sword: 0.041, gothic: 0.034, wooden: 0.031, letter: 0.03 , bottle: 0.03 , door: 0.028 , large: 0.028</p>
<p>Interactive objects: light, brass, chasm, path, narrow, lantern, passage, all
Action: east
Score: 40
Obs: Desc: Gallery This is an art gallery. Most of the paintings have been stolen by vandals with exceptional taste. The vandals left through either the north or west exits. Fortunately, there is still one chance for you to be a vandal, for on the far wall is a painting of unparalleled beauty. Inv: You are emptyhanded. Feedback: Gallery This is an art gallery. Most of the paintings have been stolen by vandals with exceptional taste. The vandals left through either the north or west exits. Fortunately, there is still one chance for you to be a vandal, for on the far wall is a painting of unparalleled beauty. Template probs: open OBJ: 0.42 , west: 0.377 , take OBJ: 0.043 , blow out OBJ: 0.039 , east: 0.026 , push OBJ: 0.02 , down: 0.016 , go around OBJ: 0.01 , north: 0.008 , turn on OBJ: 0.006</p>
<p>Object probs: window: 0.701, small: 0.299
Interactive objects: art, painting, wall, all, paintings
Action: open painti
Score: 40
Obs: Desc: Gallery This is an art gallery. Most of the paintings have been stolen by vandals with exceptional taste. The vandals left through either the north or west exits. Fortunately, there is still one chance for you to be a vandal, for on the far wall is a painting of unparalleled beauty. Inv: You are emptyhanded. Feedback: You must tell me how to do that to a painting.
Template probs: open OBJ: 0.41 , west: 0.33 , take OBJ: 0.106 , push OBJ: 0.033 , blow out OBJ: 0.032 , down: 0.023 , turn on OBJ: 0.015 , east: 0.014 , go around OBJ: 0.01 , south: 0.006</p>
<p>Object probs: window: 0.701, small: 0.299
Interactive objects: art, painting, wall, all, paintings
Action: take painti
Score: 40
Obs: Desc: Gallery This is an art gallery. Most of the paintings have been stolen by vandals with exceptional taste. The vandals left through either the north or west exits. Inv: You are carrying A painting Feedback: Taken.
Template probs: open OBJ: 0.492, push OBJ: 0.296, take OBJ: 0.036 , west: 0.033 , turn on OBJ: 0.032 , throw OBJ at OBJ: 0.021 , down: 0.015 , close OBJ: 0.013 , put down OBJ: 0.011 , put OBJ in OBJ: 0.01</p>
<p>Object probs: window: 0.698, small: 0.302
Interactive objects: art, painting, all, paintings
Action: open art
Score: 44</p>
<h1>D. 1 Pentari Transcript</h1>
<p>TmplPred: examine OBJ 0.157, put OBJ down 0.129, take OBJ 0.072, sit on top of OBJ 0.067, listen to OBJ 0.063 ObjtPred: dirty 0.339, dagger 0.280 , sword 0.144 , chest 0.092 , all 0.071
Act: put dagger down, Rew 0, Score 0, Done False, Value 0.339
Obs: A beautiful day in Bostwin! You are weakened by a ray of sunlight peeking through a window shade and rise refreshed after a restful night's sleep. You've given your Company a weekend pass to get some R\&amp;R after your last grueling mission. Wasting precious little time your entire company took off for the city proper to pack in as much drinking, carousing, brawling, wenching and other relaxing pursuits as possible in 48 hours. In the fields of battle your men are an elite unit of trained professionals. Off duty they're pretty much like every other bunch of soldiers you've ever served with. A weekend off and what to do? After the challenges of the past year when you were first promoted and assumed command of Charlie Company you've nearly forgotten what free time is and what you're supposed to do with it. Pentari An Interactive Prequel To First Light Copyright 1998 (C) Howard A. Sherman. All Rights Reserved. Type "Info" For Information About This Game or "Help" for Instructions. Release 6 / Serial number 030206 / Inform v6.21 Library 6/10 Your Quarters Rank certainly does have its privileges. When you were a lowly lieutenant you had to share cramped quarters with a fellow lieutenant at your previous assignment. Commanding a company of your own affords you the luxury of private, spacious quarters just outside the barracks themselves. As a further abuse of your power your chest and bunk are not standard issue items from the Pentari millitary supply center. You can see a postcard here.
TmplPred: north 0.746, put OBJ down 0.127, take OBJ 0.126, examine OBJ 0.001, south 0.000
ObjtPred: postcard 0.817, sword 0.180, dagger 0.001, wall 0.001, wif 0.000
Act: put postcard down, Rew 0, Score 0, Done False, Value 0.634
Obs: The postcard is already here.
TmplPred: north 0.785, put OBJ down 0.108, take OBJ 0.105, examine OBJ 0.002, south 0.000
ObjtPred: postcard 0.620, sword 0.361, dagger 0.006, all 0.003, emerald 0.003
Act: north, Rew 0, Score 0, Done False, Value 0.633
Obs: Charlie Company Compound Your company compound consists of three large buildings bordering a large, open area where company formations precede the orders of the day. To the west the Company's supply building can be seen while directly ahead of you lies your company's barracks which seem quieter than a crypt. Off to the east you hear the distant shouts of another Company drilling. Poor souls.
TmplPred: north 0.915, put OBJ down 0.043, south 0.020, take OBJ 0.010, examine OBJ 0.005
ObjtPred: sword 0.982, postcard 0.014, dagger 0.002, all 0.001, enemy 0.000
Act: north, Rew 0, Score 0, Done False, Value 1.284
Obs: Charlie Company Barracks If the Army of Bostwin were to publish a new edition of the soldier's handbook, a picture of this barracks should be included as the example other companies should follow. The floors are polished to an almost blinding shine while each of the bunks lining both sides of this building are perfectly made. Every locker next to each bunk is closed and locked. Not a single scrap of paper, not one article of clothing, nay not even a dust particle looks out of place. The powerful smell of high quantities of pine cleaner nearly burns your nostrils. Damn, you run a good company. You can see a Pentarian Transporter here.
TmplPred: enter 0.974, get in OBJ 0.022, south 0.004, put OBJ down 0.001, get up 0.000
ObjtPred: transport 0.989, sword 0.011, legends 0.001, postcard 0.000, tapestrie 0.000
Act: enter, Rew 0, Score 0, Done False, Value 2.722
Obs: The Charlie Company Barracks (in the Pentarian Transporter)
TmplPred: city 0.974, get up 0.023, put OBJ down 0.003, take OBJ 0.000, south 0.000
ObjtPred: sword 0.996, postcard 0.002, transport 0.001, blade 0.000, dirty 0.000</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ http://www.allthingsjacq.com/interactive_fiction.html#clubfloyd&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>