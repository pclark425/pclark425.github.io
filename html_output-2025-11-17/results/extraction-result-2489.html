<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2489 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2489</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2489</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-cab294fe9d6a33f9876baf557f57b5aa65727b1f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/cab294fe9d6a33f9876baf557f57b5aa65727b1f" target="_blank">Autonomous discovery in the chemical sciences part I: Progress</a></p>
                <p><strong>Paper Venue:</strong> Angewandte Chemie</p>
                <p><strong>Paper TL;DR:</strong> This two-part review examines how automation has contributed to different aspects of discovery in the chemical sciences and describes many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science.</p>
                <p><strong>Paper Abstract:</strong> This two-part review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modelling. Part two reflects on these case studies and identifies a set of open challenges for the field.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2489.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2489.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active learning strategies (general)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Iterative experimental-design strategies that select new experiments to maximally improve predictive models while minimizing the number of experiments required; widely cited as enabling efficient navigation of high-dimensional design spaces in chemistry and materials discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Active learning strategies</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A class of iterative methods that use a current predictive model (e.g., a QSAR/QSPR or surrogate) to select the next experiments whose outcomes are expected to most improve model performance. The review frames these as methods to 'maximize the accuracy of predictive models while minimizing the required training data' and positions them as part of closed-loop discovery workflows that reduce experimental burden.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Drug discovery, materials discovery, chemical process optimization, general empirical-model-driven experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select experiments based on their expected value for improving the predictive model (e.g., sampling where uncertainty or expected model improvement is high), thereby allocating limited experimental budget to points that will most reduce model error; tradeoffs with throughput and experimental cost are noted qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Described qualitatively as improving model accuracy and reducing required training data; specific metrics (e.g., mutual information or expected reduction in predictive variance) are not specified in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Implicit balancing via acquisition criteria that prioritize uncertain or informative points (promoting exploration) versus points expected to provide high objective value (exploitation); the review notes exploration-promoting active learning can reduce the number of experiments (example claim: may require only ~20% of experiments compared to exhaustive search).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not specified in algorithmic detail in the review; exploration-focused acquisition is discussed as a way to cover diverse regions of design space.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed/limited experimental budget (number of experiments), time and resource limits for experiments</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by selecting only the most informative experiments under a constrained budget; review describes these methods as minimizing required training data/experiments but does not give an explicit optimization formulation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified; review frames benefit as improved model accuracy and locating promising candidates with fewer experiments rather than an explicit 'breakthrough' scoring function.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Qualitative claims only; review states that exploration-promoting active learning might require as little as ~20% of experiments compared to exhaustive strategies in some contexts (no units beyond fraction of experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implied comparisons to brute-force/high-throughput screening and random selection; the review contrasts active learning with brute-force screens.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative: active learning can substantially reduce experiments vs brute-force; the only quantitative example in the review is the ~20% figure mentioned above, with no detailed experimental numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Qualitative and context-dependent; review cites potential large reductions in experimental burden (e.g., the ~80% reduction implied by the 20% figure) but no systematic values.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review discusses tradeoffs conceptually: lower-cost/cheaper experiments enable more automation and less human intervention, but constrained experimental spaces simplify allocation decisions. It notes that exploration-focused strategies reduce data requirements but does not provide quantitative tradeoff curves between cost, information gain, diversity, and discovery probability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>No concrete optimal-allocation formulas are given; the review's key insight is that active learning principles (targeting information-rich experiments) are crucial for efficient discovery under budget constraints and that constraints (experimental, computational) strongly influence feasible allocation strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2489.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian optimization (BO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A goal-directed sequential optimization framework that uses a surrogate probabilistic model and an acquisition function to select experiments expected to improve an objective (e.g., maximize yield), often used to optimize continuous or expensive-to-evaluate experimental variables.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An iterative optimization approach in which a probabilistic surrogate model (e.g., Gaussian process or other regressor) predicts performance and uncertainty; an acquisition function (e.g., to trade off exploitation and exploration) is optimized to choose the next experimental conditions to evaluate. The review cites BO as a 'goal-directed strategy' to reduce experimental burden in discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Optimization of reaction/process conditions, materials parameter tuning, any experimental campaign with expensive evaluations</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate experiments by optimizing an acquisition function that balances expected improvement (or utility) against model uncertainty; experiments are selected sequentially to maximize expected gain per costly evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not specified in detail in the review; standard BO uses acquisition functions such as expected improvement, probability of improvement, or information-theoretic criteriaâ€”review refers to BO qualitatively and does not enumerate exact metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Handled by the acquisition function that embodies a tradeoff between exploiting currently promising regions and exploring uncertain regions; the review references BO's role in goal-directed search but does not detail a particular acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not detailed; diversity can arise indirectly through exploration-driven acquisition functions but no explicit diversity promotion described in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Costly/limited evaluations (experimental budget or time), implicitly fixed-number sequential budgets</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>BO inherently optimizes acquisition per iteration under the assumption of costly evaluations; the review does not provide explicit budget-optimization algorithms beyond generic BO framing.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified; BO typically seeks objective maximization (e.g., highest yield) rather than an explicit novelty/breakthrough score; review does not add a breakthrough-specific metric.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implicit comparisons to random or grid search and brute-force screening; review positions BO as more efficient for expensive evaluations but gives no numerical comparisons in the text provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Conceptual only: BO reduces number of costly experiments by prioritizing high-utility evaluations, but the review does not analyze quantitative tradeoffs among computational cost, information gain, and diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>No specific allocation rules beyond recommending BO as an effective framework for sequential allocation under expensive evaluation costs; the review emphasizes that choice of acquisition and model shape the resource allocation behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2489.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MCTS (CASP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Monte Carlo Tree Search with neural policies for computer-aided synthesis planning (CASP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A search framework combining learned action policies and value functions with Monte Carlo Tree Search to generate and evaluate retrosynthetic pathways efficiently in a vast combinatorial search space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Monte Carlo Tree Search + neural network policies (CASP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Retrosynthetic search guided by two complementary components: (1) action policies (neural classifiers or nearest-neighbor rules) that propose plausible disconnections, and (2) a Monte Carlo Tree Search (MCTS) planner that expands and evaluates pathway branches. Learned value functions estimate synthetic complexity or proximity to purchasable starting materials, helping prioritize branches.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Synthetic route planning / retrosynthesis in organic chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate search/simulation budget to most promising retrosynthetic branches as determined by the combination of policy priors and value estimates in MCTS; the tree-search allocates computational effort adaptively to expand promising nodes while sampling others to preserve exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>MCTS intrinsically balances exploration and exploitation by expanding nodes with high estimated value and sampling less-explored nodes; the review notes that MCTS combined with learned policies produced recommendations chemists found plausible, but algorithmic details (e.g., UCB) are not specified in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity of pathways arises from stochastic rollouts/sampling in MCTS and from multiple candidate actions provided by the policy; the review does not describe an explicit diversity-penalization term.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational/search budget and practical constraints on pathway depth/branching; implicit experimental budget since planned routes require experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by limiting tree search depth, using value functions to prune unlikely pathways, and prioritizing routes likely to reach purchasable precursors; review emphasizes heuristics and learned scores to keep search tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified; plausibility to expert chemists and ability to rediscover literature routes serve as qualitative measures in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Qualitative: reviewer notes that MCTS+neural approaches yielded pathways judged equally plausible to literature routes in a double-blind study (no numerical success rates reported in the excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to nearest-neighbor rule-based retrosynthesis, brute-force expansion, and value-function-guided searches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Reported qualitatively as competitive with literature pathways and more scalable than naive expansion; no quantitative performance numbers are provided in the review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review highlights the need to guide the combinatorial expansion (value functions, policies) to keep search tractable; no formal tradeoff analysis between computational cost and exploration breadth is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key practical insight: combining learned policies with tree search and value estimates is an effective strategy for allocating computational effort in retrosynthetic search; constraining search via value heuristics improves tractability without severely harming route plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2489.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep generative models (GANs, VAEs) for molecular generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural generative models (GANs, VAEs and related architectures) used to propose large libraries of candidate molecules or materials, enabling exploration of vast chemical space and supplying diverse hypotheses for downstream screening.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep generative models (GANs, VAEs, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Neural-network-based generative frameworks that learn a continuous latent representation of molecules from data and can sample novel candidates; used to create diverse molecular libraries without exhaustive enumeration and often integrated into pipelines that score/guided-by property predictors or optimization loops.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Molecular design, materials discovery, drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Generate large and diverse candidate sets cheaply in silico, then allocate expensive experimental/DFT validation budget to highest-scoring or most informative candidates according to downstream models; generative sampling reduces upfront enumeration costs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration promoted via stochastic sampling from latent space and diversity-encouraging priors; exploitation achieved by coupling generation to property predictors or optimization objectives (e.g., Bayesian optimization in latent space).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: generative models are highlighted for facilitating creation of diverse molecular libraries; diversity arises from sampling variance in latent space and training objectives that can be tuned for novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Downstream experimental/validation budget (number of compounds that can be synthesized/tested) and computational screening budget</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handle budget constraints by pre-screening and filtering generated libraries with fast predictors to triage candidates, reserving costly validation for a smaller selected subset; review notes this is a common integration pattern but does not give explicit algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified in the review; novelty/diversity of generated molecules is implied as relevant to breakthrough potential but not formalized.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to brute-force enumeration or library-based screening; generative models allow exploration beyond pre-enumerated libraries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review discusses that generative models reduce up-front enumeration costs and enable diverse hypothesis generation, but experimental validation remains a bottleneck; no quantitative tradeoff analysis is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Review suggests the practical principle of using cheap generative/surrogate screening to expand hypothesis sets, followed by targeted allocation of expensive validation resources to top candidates; no formal optimal-allocation prescription is offered.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2489.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Value functions / action policies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Value functions and action policies in retrosynthetic search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two complementary approaches to guide retrosynthetic expansion: value functions estimate synthetic complexity or distance-to-goal for candidate intermediates, while action policies predict which disconnection/transformation to apply next.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Value functions and action policies (CASP guidance)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Value functions provide a scalar estimate of how promising candidate reactants/intermediates are (e.g., synthetic accessibility or distance to purchasable precursors). Action policies (learned classifiers or nearest-neighbor lookups) directly suggest which transformation rules to apply during retrosynthetic expansion. Both are used to prioritize branches in search frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Computer-aided synthesis planning (retrosynthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate search and experimental validation effort by prioritizing disconnections that lead to lower estimated synthetic complexity (value) or those recommended by high-confidence action policies; policies can be used greedily or inside planners like MCTS to distribute computational effort.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Action policies can be used greedily (exploitation) or stochastically (to explore alternate disconnections); value functions provide a scalar guide to bias search toward promising regions, implicitly trading exploration and exploitation when combined with search.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not specified as an explicit diversity-promoting mechanism; stochastic policy sampling and breadth-limited search can produce diverse candidate pathways.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Search/computational budget and downstream experimental validation budget</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by using value functions to prune high-cost or unlikely branches and by using policies to reduce branching factor; review emphasizes their utility for keeping searches tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not defined; success assessed qualitatively by found pathways' plausibility and synthetic tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to rule-based heuristics and naive search expansion; learned value functions/policies can find shorter or more tractable routes than simple heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Review notes potential advantages (shorter pathways, tailored cost functions) but provides no numeric comparisons in the excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Conceptual: learned value functions/policies trade off search breadth for depth and tractability; no formal analysis of cost vs information gain is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Practical recommendation: use value functions and action policies to constrain retrosynthetic search and focus computational/experimental resources on the most promising branches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2489.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reaction enumeration/search</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mechanistic enumeration and reaction-network generation (MECHEM, RMG, MD nanoreactor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Algorithmic approaches that enumerate or discover elementary reaction steps and networks via heuristics, templates, transition-state searches, or reactive molecular dynamics to propose mechanistic hypotheses and reaction channels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Mechanistic enumeration/search frameworks (MECHEM, RMG, ab initio MD nanoreactor, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Includes programs that (a) enumerate elementary steps using reaction templates/heuristics and prune by estimated energetics (MECHEM, RMG), (b) perform transition-state searches via string or single-ended methods (FSM, GSM, AFIR), and (c) discover reaction pathways by direct reactive MD simulations with enhanced sampling (ab initio nanoreactor). These frameworks generate candidate mechanisms for further kinetic/thermodynamic evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Reaction mechanism discovery, catalysis, combustion/pyrolysis modeling, fundamental reaction-pathway discovery</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate computational effort by enumerating candidate steps and pruning by estimated kinetic/thermodynamic plausibility (e.g., estimated barrier energies), or by steering MD simulations to enhance rare-event sampling; pruning reduces the number of expensive quantum calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via systematic enumeration or stochastic MD sampling; exploitation via pruning using energetics or heuristic likelihood to focus detailed calculations on promising pathways.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity arises from combinatorial enumeration and from MD-driven sampling of many possible reaction channels; explicit diversity-promoting objectives are not described in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational resources (number of DFT/transition-state searches, MD simulation time) and time-to-solution</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by using heuristics, group-additivity estimates, lower-level potentials (ReaxFF) to focus expensive calculations, and by pruning reaction networks based on estimated rates or energetics.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not specified; successful identification of plausible, kinetically-relevant pathways or previously-unknown reaction channels is treated as impact.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared implicitly to manual mechanistic proposal and brute-force unconstrained enumeration (which is intractable); review highlights scalability challenges without pruning heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review emphasizes the computational-combinatorial tradeoff: naive enumeration produces millions of candidates, so heuristics and energetics-based pruning are necessary to allocate computational effort efficiently; no quantitative tradeoff curves are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: use cheaper heuristic/empirical estimates to triage and prune large candidate sets before committing expensive high-level electronic-structure calculations; MD-based nanoreactor approaches can discover unexpected pathways by biasing sampling toward collisions/events.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2489.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BACON / symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BACON and symbolic regression frameworks (e.g., Schmidt & Lipson)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Rule-based and symbolic-regression programs that search combinatorial spaces of functional forms to rediscover empirical or physical laws from data, generating analytic expressions as mechanistic hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Symbolic regression and rule-based induction (BACON, related frameworks)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Programs that generate candidate analytical relationships from input variables (using heuristics, operators, or grammar-based expression trees) and score them against data; extensions handle noise and irrelevant variables. These are search-in-hypothesis-space approaches rather than experimental-design allocators, but can guide which follow-up experiments would be most informative to discriminate candidate laws.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Model discovery, mechanistic law induction from experimental data, discovery of conservation laws or governing equations</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Implicit allocation: generate and score many candidate symbolic relationships and prioritize those with high explanatory power; when used iteratively, experiments could be chosen to disambiguate top candidate models (not detailed in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Search heuristics guide balance between exploring new functional forms and refining promising expressions; specific mechanisms differ across implementations and are not detailed in this review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity of candidate models arises from grammar/operators used for expression generation and from mutation/crossover operators in symbolic regression frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for evaluating many candidate expressions; experimental validation budget if iteratively applied.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by constraining the search space (operators, variable sets) and scoring/pruning low-scoring candidates; the review highlights that excluding irrelevant variables simplifies search.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Model intelligibility, explanatory power, and ability to recapitulate known natural laws are treated as success criteria; no numeric breakthrough metric provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared historically to manual model induction and to other automated-induction programs (e.g., STAHL, KEKADA).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review notes tradeoffs where heavy prior knowledge (rules) can both accelerate discovery and restrict novelty; restricting the hypothesis/search space simplifies computation but may limit radical discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: constraining the hypothesis space (removing irrelevant variables, restricting operators) makes symbolic discovery tractable, but care should be taken to avoid overly strong priors that preclude novel hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2489.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2489.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Directed evolution (automated)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Directed evolution and automated selection workflows</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Iterative laboratory selection campaigns (e.g., directed evolution, phage display, continuous evolution) that generate and screen variant libraries and select for functional improvements, often integrated into automated/closed-loop workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Automated directed evolution / selection workflows</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Experimental paradigms that iterate cycles of library generation, selection/screening, and amplification/variation. When coupled to automation and computational analysis, these workflows can close the loop to optimize functions (e.g., enzymatic activity) while choosing which variants to test next based on observed outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Protein engineering, enzyme evolution, molecular engineering</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate wet-lab screening capacity to variants predicted or observed to be promising; sequence/variant diversity and selection stringency are tuned to trade off exploration of sequence space versus exploitation of high-fitness lineages.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Experimental selection stringency and library design control exploration/exploitation: broader libraries and lower stringency promote diversity/exploration, higher stringency focuses on exploitation of top variants.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Library design (e.g., split-and-pool combinatorial chemistry, mutational strategies) explicitly promotes diversity; review calls out methodologies like split-and-pool and diversity-oriented synthesis as amenable to autonomous discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Screening throughput, reagent/time cost, and laboratory automation throughput limits</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handled by designing library sizes to match screening capacity, using selection to enrich promising sequences, and by automating stages to increase throughput; review highlights experimental constraints as a determinant of autonomy.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Functional improvement (activity/selectivity/fitness) over baseline; novelty of sequence/function can indicate high-impact discoveries but no formal metric is given in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to manual iterative engineering and to brute-force library screening; automation increases throughput and reduces human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Review discusses conceptual tradeoffs: increasing automation and throughput enables larger library exploration (diversity) but experimental cost and validation bottlenecks remain; no formal quantitative analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: match library design and selection stringency to available screening resources and desired exploration-exploitation balance; automating experimental steps reduces human overhead but does not eliminate the need to manage budget and diversity choices.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Autonomous discovery in the chemical sciences part I: Progress', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Distilling Free-Form Natural Laws from Experimental Data <em>(Rating: 2)</em></li>
                <li>Planning chemical syntheses with deep neural networks and symbolic AI <em>(Rating: 2)</em></li>
                <li>Discovering chemistry with an ab initio nanoreactor <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2489",
    "paper_id": "paper-cab294fe9d6a33f9876baf557f57b5aa65727b1f",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "Active learning",
            "name_full": "Active learning strategies (general)",
            "brief_description": "Iterative experimental-design strategies that select new experiments to maximally improve predictive models while minimizing the number of experiments required; widely cited as enabling efficient navigation of high-dimensional design spaces in chemistry and materials discovery.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Active learning strategies",
            "system_description": "A class of iterative methods that use a current predictive model (e.g., a QSAR/QSPR or surrogate) to select the next experiments whose outcomes are expected to most improve model performance. The review frames these as methods to 'maximize the accuracy of predictive models while minimizing the required training data' and positions them as part of closed-loop discovery workflows that reduce experimental burden.",
            "application_domain": "Drug discovery, materials discovery, chemical process optimization, general empirical-model-driven experimental design",
            "resource_allocation_strategy": "Select experiments based on their expected value for improving the predictive model (e.g., sampling where uncertainty or expected model improvement is high), thereby allocating limited experimental budget to points that will most reduce model error; tradeoffs with throughput and experimental cost are noted qualitatively.",
            "computational_cost_metric": null,
            "information_gain_metric": "Described qualitatively as improving model accuracy and reducing required training data; specific metrics (e.g., mutual information or expected reduction in predictive variance) are not specified in the review.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Implicit balancing via acquisition criteria that prioritize uncertain or informative points (promoting exploration) versus points expected to provide high objective value (exploitation); the review notes exploration-promoting active learning can reduce the number of experiments (example claim: may require only ~20% of experiments compared to exhaustive search).",
            "diversity_mechanism": "Not specified in algorithmic detail in the review; exploration-focused acquisition is discussed as a way to cover diverse regions of design space.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed/limited experimental budget (number of experiments), time and resource limits for experiments",
            "budget_constraint_handling": "Handled by selecting only the most informative experiments under a constrained budget; review describes these methods as minimizing required training data/experiments but does not give an explicit optimization formulation.",
            "breakthrough_discovery_metric": "Not specified; review frames benefit as improved model accuracy and locating promising candidates with fewer experiments rather than an explicit 'breakthrough' scoring function.",
            "performance_metrics": "Qualitative claims only; review states that exploration-promoting active learning might require as little as ~20% of experiments compared to exhaustive strategies in some contexts (no units beyond fraction of experiments).",
            "comparison_baseline": "Implied comparisons to brute-force/high-throughput screening and random selection; the review contrasts active learning with brute-force screens.",
            "performance_vs_baseline": "Qualitative: active learning can substantially reduce experiments vs brute-force; the only quantitative example in the review is the ~20% figure mentioned above, with no detailed experimental numbers.",
            "efficiency_gain": "Qualitative and context-dependent; review cites potential large reductions in experimental burden (e.g., the ~80% reduction implied by the 20% figure) but no systematic values.",
            "tradeoff_analysis": "Review discusses tradeoffs conceptually: lower-cost/cheaper experiments enable more automation and less human intervention, but constrained experimental spaces simplify allocation decisions. It notes that exploration-focused strategies reduce data requirements but does not provide quantitative tradeoff curves between cost, information gain, diversity, and discovery probability.",
            "optimal_allocation_findings": "No concrete optimal-allocation formulas are given; the review's key insight is that active learning principles (targeting information-rich experiments) are crucial for efficient discovery under budget constraints and that constraints (experimental, computational) strongly influence feasible allocation strategies.",
            "uuid": "e2489.0",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Bayesian optimization",
            "name_full": "Bayesian optimization (BO)",
            "brief_description": "A goal-directed sequential optimization framework that uses a surrogate probabilistic model and an acquisition function to select experiments expected to improve an objective (e.g., maximize yield), often used to optimize continuous or expensive-to-evaluate experimental variables.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Bayesian optimization",
            "system_description": "An iterative optimization approach in which a probabilistic surrogate model (e.g., Gaussian process or other regressor) predicts performance and uncertainty; an acquisition function (e.g., to trade off exploitation and exploration) is optimized to choose the next experimental conditions to evaluate. The review cites BO as a 'goal-directed strategy' to reduce experimental burden in discovery.",
            "application_domain": "Optimization of reaction/process conditions, materials parameter tuning, any experimental campaign with expensive evaluations",
            "resource_allocation_strategy": "Allocate experiments by optimizing an acquisition function that balances expected improvement (or utility) against model uncertainty; experiments are selected sequentially to maximize expected gain per costly evaluation.",
            "computational_cost_metric": null,
            "information_gain_metric": "Not specified in detail in the review; standard BO uses acquisition functions such as expected improvement, probability of improvement, or information-theoretic criteriaâ€”review refers to BO qualitatively and does not enumerate exact metrics.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Handled by the acquisition function that embodies a tradeoff between exploiting currently promising regions and exploring uncertain regions; the review references BO's role in goal-directed search but does not detail a particular acquisition.",
            "diversity_mechanism": "Not detailed; diversity can arise indirectly through exploration-driven acquisition functions but no explicit diversity promotion described in the review.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Costly/limited evaluations (experimental budget or time), implicitly fixed-number sequential budgets",
            "budget_constraint_handling": "BO inherently optimizes acquisition per iteration under the assumption of costly evaluations; the review does not provide explicit budget-optimization algorithms beyond generic BO framing.",
            "breakthrough_discovery_metric": "Not specified; BO typically seeks objective maximization (e.g., highest yield) rather than an explicit novelty/breakthrough score; review does not add a breakthrough-specific metric.",
            "performance_metrics": null,
            "comparison_baseline": "Implicit comparisons to random or grid search and brute-force screening; review positions BO as more efficient for expensive evaluations but gives no numerical comparisons in the text provided.",
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Conceptual only: BO reduces number of costly experiments by prioritizing high-utility evaluations, but the review does not analyze quantitative tradeoffs among computational cost, information gain, and diversity.",
            "optimal_allocation_findings": "No specific allocation rules beyond recommending BO as an effective framework for sequential allocation under expensive evaluation costs; the review emphasizes that choice of acquisition and model shape the resource allocation behavior.",
            "uuid": "e2489.1",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "MCTS (CASP)",
            "name_full": "Monte Carlo Tree Search with neural policies for computer-aided synthesis planning (CASP)",
            "brief_description": "A search framework combining learned action policies and value functions with Monte Carlo Tree Search to generate and evaluate retrosynthetic pathways efficiently in a vast combinatorial search space.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Monte Carlo Tree Search + neural network policies (CASP)",
            "system_description": "Retrosynthetic search guided by two complementary components: (1) action policies (neural classifiers or nearest-neighbor rules) that propose plausible disconnections, and (2) a Monte Carlo Tree Search (MCTS) planner that expands and evaluates pathway branches. Learned value functions estimate synthetic complexity or proximity to purchasable starting materials, helping prioritize branches.",
            "application_domain": "Synthetic route planning / retrosynthesis in organic chemistry",
            "resource_allocation_strategy": "Allocate search/simulation budget to most promising retrosynthetic branches as determined by the combination of policy priors and value estimates in MCTS; the tree-search allocates computational effort adaptively to expand promising nodes while sampling others to preserve exploration.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "MCTS intrinsically balances exploration and exploitation by expanding nodes with high estimated value and sampling less-explored nodes; the review notes that MCTS combined with learned policies produced recommendations chemists found plausible, but algorithmic details (e.g., UCB) are not specified in the text.",
            "diversity_mechanism": "Diversity of pathways arises from stochastic rollouts/sampling in MCTS and from multiple candidate actions provided by the policy; the review does not describe an explicit diversity-penalization term.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational/search budget and practical constraints on pathway depth/branching; implicit experimental budget since planned routes require experimental validation.",
            "budget_constraint_handling": "Handled by limiting tree search depth, using value functions to prune unlikely pathways, and prioritizing routes likely to reach purchasable precursors; review emphasizes heuristics and learned scores to keep search tractable.",
            "breakthrough_discovery_metric": "Not specified; plausibility to expert chemists and ability to rediscover literature routes serve as qualitative measures in the review.",
            "performance_metrics": "Qualitative: reviewer notes that MCTS+neural approaches yielded pathways judged equally plausible to literature routes in a double-blind study (no numerical success rates reported in the excerpt).",
            "comparison_baseline": "Compared conceptually to nearest-neighbor rule-based retrosynthesis, brute-force expansion, and value-function-guided searches.",
            "performance_vs_baseline": "Reported qualitatively as competitive with literature pathways and more scalable than naive expansion; no quantitative performance numbers are provided in the review excerpt.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Review highlights the need to guide the combinatorial expansion (value functions, policies) to keep search tractable; no formal tradeoff analysis between computational cost and exploration breadth is provided.",
            "optimal_allocation_findings": "Key practical insight: combining learned policies with tree search and value estimates is an effective strategy for allocating computational effort in retrosynthetic search; constraining search via value heuristics improves tractability without severely harming route plausibility.",
            "uuid": "e2489.2",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Generative models",
            "name_full": "Deep generative models (GANs, VAEs) for molecular generation",
            "brief_description": "Neural generative models (GANs, VAEs and related architectures) used to propose large libraries of candidate molecules or materials, enabling exploration of vast chemical space and supplying diverse hypotheses for downstream screening.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Deep generative models (GANs, VAEs, etc.)",
            "system_description": "Neural-network-based generative frameworks that learn a continuous latent representation of molecules from data and can sample novel candidates; used to create diverse molecular libraries without exhaustive enumeration and often integrated into pipelines that score/guided-by property predictors or optimization loops.",
            "application_domain": "Molecular design, materials discovery, drug discovery",
            "resource_allocation_strategy": "Generate large and diverse candidate sets cheaply in silico, then allocate expensive experimental/DFT validation budget to highest-scoring or most informative candidates according to downstream models; generative sampling reduces upfront enumeration costs.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Exploration promoted via stochastic sampling from latent space and diversity-encouraging priors; exploitation achieved by coupling generation to property predictors or optimization objectives (e.g., Bayesian optimization in latent space).",
            "diversity_mechanism": "Explicit: generative models are highlighted for facilitating creation of diverse molecular libraries; diversity arises from sampling variance in latent space and training objectives that can be tuned for novelty.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Downstream experimental/validation budget (number of compounds that can be synthesized/tested) and computational screening budget",
            "budget_constraint_handling": "Handle budget constraints by pre-screening and filtering generated libraries with fast predictors to triage candidates, reserving costly validation for a smaller selected subset; review notes this is a common integration pattern but does not give explicit algorithms.",
            "breakthrough_discovery_metric": "Not specified in the review; novelty/diversity of generated molecules is implied as relevant to breakthrough potential but not formalized.",
            "performance_metrics": null,
            "comparison_baseline": "Compared conceptually to brute-force enumeration or library-based screening; generative models allow exploration beyond pre-enumerated libraries.",
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Review discusses that generative models reduce up-front enumeration costs and enable diverse hypothesis generation, but experimental validation remains a bottleneck; no quantitative tradeoff analysis is provided.",
            "optimal_allocation_findings": "Review suggests the practical principle of using cheap generative/surrogate screening to expand hypothesis sets, followed by targeted allocation of expensive validation resources to top candidates; no formal optimal-allocation prescription is offered.",
            "uuid": "e2489.3",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Value functions / action policies",
            "name_full": "Value functions and action policies in retrosynthetic search",
            "brief_description": "Two complementary approaches to guide retrosynthetic expansion: value functions estimate synthetic complexity or distance-to-goal for candidate intermediates, while action policies predict which disconnection/transformation to apply next.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Value functions and action policies (CASP guidance)",
            "system_description": "Value functions provide a scalar estimate of how promising candidate reactants/intermediates are (e.g., synthetic accessibility or distance to purchasable precursors). Action policies (learned classifiers or nearest-neighbor lookups) directly suggest which transformation rules to apply during retrosynthetic expansion. Both are used to prioritize branches in search frameworks.",
            "application_domain": "Computer-aided synthesis planning (retrosynthesis)",
            "resource_allocation_strategy": "Allocate search and experimental validation effort by prioritizing disconnections that lead to lower estimated synthetic complexity (value) or those recommended by high-confidence action policies; policies can be used greedily or inside planners like MCTS to distribute computational effort.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Action policies can be used greedily (exploitation) or stochastically (to explore alternate disconnections); value functions provide a scalar guide to bias search toward promising regions, implicitly trading exploration and exploitation when combined with search.",
            "diversity_mechanism": "Not specified as an explicit diversity-promoting mechanism; stochastic policy sampling and breadth-limited search can produce diverse candidate pathways.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Search/computational budget and downstream experimental validation budget",
            "budget_constraint_handling": "Handled by using value functions to prune high-cost or unlikely branches and by using policies to reduce branching factor; review emphasizes their utility for keeping searches tractable.",
            "breakthrough_discovery_metric": "Not defined; success assessed qualitatively by found pathways' plausibility and synthetic tractability.",
            "performance_metrics": null,
            "comparison_baseline": "Compared to rule-based heuristics and naive search expansion; learned value functions/policies can find shorter or more tractable routes than simple heuristics.",
            "performance_vs_baseline": "Review notes potential advantages (shorter pathways, tailored cost functions) but provides no numeric comparisons in the excerpt.",
            "efficiency_gain": null,
            "tradeoff_analysis": "Conceptual: learned value functions/policies trade off search breadth for depth and tractability; no formal analysis of cost vs information gain is provided.",
            "optimal_allocation_findings": "Practical recommendation: use value functions and action policies to constrain retrosynthetic search and focus computational/experimental resources on the most promising branches.",
            "uuid": "e2489.4",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Reaction enumeration/search",
            "name_full": "Mechanistic enumeration and reaction-network generation (MECHEM, RMG, MD nanoreactor)",
            "brief_description": "Algorithmic approaches that enumerate or discover elementary reaction steps and networks via heuristics, templates, transition-state searches, or reactive molecular dynamics to propose mechanistic hypotheses and reaction channels.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Mechanistic enumeration/search frameworks (MECHEM, RMG, ab initio MD nanoreactor, etc.)",
            "system_description": "Includes programs that (a) enumerate elementary steps using reaction templates/heuristics and prune by estimated energetics (MECHEM, RMG), (b) perform transition-state searches via string or single-ended methods (FSM, GSM, AFIR), and (c) discover reaction pathways by direct reactive MD simulations with enhanced sampling (ab initio nanoreactor). These frameworks generate candidate mechanisms for further kinetic/thermodynamic evaluation.",
            "application_domain": "Reaction mechanism discovery, catalysis, combustion/pyrolysis modeling, fundamental reaction-pathway discovery",
            "resource_allocation_strategy": "Allocate computational effort by enumerating candidate steps and pruning by estimated kinetic/thermodynamic plausibility (e.g., estimated barrier energies), or by steering MD simulations to enhance rare-event sampling; pruning reduces the number of expensive quantum calculations.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Exploration via systematic enumeration or stochastic MD sampling; exploitation via pruning using energetics or heuristic likelihood to focus detailed calculations on promising pathways.",
            "diversity_mechanism": "Diversity arises from combinatorial enumeration and from MD-driven sampling of many possible reaction channels; explicit diversity-promoting objectives are not described in the review.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Computational resources (number of DFT/transition-state searches, MD simulation time) and time-to-solution",
            "budget_constraint_handling": "Handled by using heuristics, group-additivity estimates, lower-level potentials (ReaxFF) to focus expensive calculations, and by pruning reaction networks based on estimated rates or energetics.",
            "breakthrough_discovery_metric": "Not specified; successful identification of plausible, kinetically-relevant pathways or previously-unknown reaction channels is treated as impact.",
            "performance_metrics": null,
            "comparison_baseline": "Compared implicitly to manual mechanistic proposal and brute-force unconstrained enumeration (which is intractable); review highlights scalability challenges without pruning heuristics.",
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Review emphasizes the computational-combinatorial tradeoff: naive enumeration produces millions of candidates, so heuristics and energetics-based pruning are necessary to allocate computational effort efficiently; no quantitative tradeoff curves are provided.",
            "optimal_allocation_findings": "Principle: use cheaper heuristic/empirical estimates to triage and prune large candidate sets before committing expensive high-level electronic-structure calculations; MD-based nanoreactor approaches can discover unexpected pathways by biasing sampling toward collisions/events.",
            "uuid": "e2489.5",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "BACON / symbolic regression",
            "name_full": "BACON and symbolic regression frameworks (e.g., Schmidt & Lipson)",
            "brief_description": "Rule-based and symbolic-regression programs that search combinatorial spaces of functional forms to rediscover empirical or physical laws from data, generating analytic expressions as mechanistic hypotheses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Symbolic regression and rule-based induction (BACON, related frameworks)",
            "system_description": "Programs that generate candidate analytical relationships from input variables (using heuristics, operators, or grammar-based expression trees) and score them against data; extensions handle noise and irrelevant variables. These are search-in-hypothesis-space approaches rather than experimental-design allocators, but can guide which follow-up experiments would be most informative to discriminate candidate laws.",
            "application_domain": "Model discovery, mechanistic law induction from experimental data, discovery of conservation laws or governing equations",
            "resource_allocation_strategy": "Implicit allocation: generate and score many candidate symbolic relationships and prioritize those with high explanatory power; when used iteratively, experiments could be chosen to disambiguate top candidate models (not detailed in the review).",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Search heuristics guide balance between exploring new functional forms and refining promising expressions; specific mechanisms differ across implementations and are not detailed in this review excerpt.",
            "diversity_mechanism": "Diversity of candidate models arises from grammar/operators used for expression generation and from mutation/crossover operators in symbolic regression frameworks.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Computational budget for evaluating many candidate expressions; experimental validation budget if iteratively applied.",
            "budget_constraint_handling": "Handled by constraining the search space (operators, variable sets) and scoring/pruning low-scoring candidates; the review highlights that excluding irrelevant variables simplifies search.",
            "breakthrough_discovery_metric": "Model intelligibility, explanatory power, and ability to recapitulate known natural laws are treated as success criteria; no numeric breakthrough metric provided.",
            "performance_metrics": null,
            "comparison_baseline": "Compared historically to manual model induction and to other automated-induction programs (e.g., STAHL, KEKADA).",
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Review notes tradeoffs where heavy prior knowledge (rules) can both accelerate discovery and restrict novelty; restricting the hypothesis/search space simplifies computation but may limit radical discoveries.",
            "optimal_allocation_findings": "Principle: constraining the hypothesis space (removing irrelevant variables, restricting operators) makes symbolic discovery tractable, but care should be taken to avoid overly strong priors that preclude novel hypotheses.",
            "uuid": "e2489.6",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Directed evolution (automated)",
            "name_full": "Directed evolution and automated selection workflows",
            "brief_description": "Iterative laboratory selection campaigns (e.g., directed evolution, phage display, continuous evolution) that generate and screen variant libraries and select for functional improvements, often integrated into automated/closed-loop workflows.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Automated directed evolution / selection workflows",
            "system_description": "Experimental paradigms that iterate cycles of library generation, selection/screening, and amplification/variation. When coupled to automation and computational analysis, these workflows can close the loop to optimize functions (e.g., enzymatic activity) while choosing which variants to test next based on observed outcomes.",
            "application_domain": "Protein engineering, enzyme evolution, molecular engineering",
            "resource_allocation_strategy": "Allocate wet-lab screening capacity to variants predicted or observed to be promising; sequence/variant diversity and selection stringency are tuned to trade off exploration of sequence space versus exploitation of high-fitness lineages.",
            "computational_cost_metric": null,
            "information_gain_metric": null,
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Experimental selection stringency and library design control exploration/exploitation: broader libraries and lower stringency promote diversity/exploration, higher stringency focuses on exploitation of top variants.",
            "diversity_mechanism": "Library design (e.g., split-and-pool combinatorial chemistry, mutational strategies) explicitly promotes diversity; review calls out methodologies like split-and-pool and diversity-oriented synthesis as amenable to autonomous discovery.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Screening throughput, reagent/time cost, and laboratory automation throughput limits",
            "budget_constraint_handling": "Handled by designing library sizes to match screening capacity, using selection to enrich promising sequences, and by automating stages to increase throughput; review highlights experimental constraints as a determinant of autonomy.",
            "breakthrough_discovery_metric": "Functional improvement (activity/selectivity/fitness) over baseline; novelty of sequence/function can indicate high-impact discoveries but no formal metric is given in the review.",
            "performance_metrics": null,
            "comparison_baseline": "Compared conceptually to manual iterative engineering and to brute-force library screening; automation increases throughput and reduces human intervention.",
            "performance_vs_baseline": null,
            "efficiency_gain": null,
            "tradeoff_analysis": "Review discusses conceptual tradeoffs: increasing automation and throughput enables larger library exploration (diversity) but experimental cost and validation bottlenecks remain; no formal quantitative analysis.",
            "optimal_allocation_findings": "Principle: match library design and selection stringency to available screening resources and desired exploration-exploitation balance; automating experimental steps reduces human overhead but does not eliminate the need to manage budget and diversity choices.",
            "uuid": "e2489.7",
            "source_info": {
                "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Distilling Free-Form Natural Laws from Experimental Data",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "Planning chemical syntheses with deep neural networks and symbolic AI",
            "rating": 2,
            "sanitized_title": "planning_chemical_syntheses_with_deep_neural_networks_and_symbolic_ai"
        },
        {
            "paper_title": "Discovering chemistry with an ab initio nanoreactor",
            "rating": 2,
            "sanitized_title": "discovering_chemistry_with_an_ab_initio_nanoreactor"
        }
    ],
    "cost": 0.018925749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Autonomous discovery in the chemical sciences part I: Progress</h1>
<p>Connor W. Coley<em>! Natalie S. Eyke, Klavs F. Jensen</em>Â§</p>
<p>Keywords: automation, chemoinformatics, drug discovery, machine learning, materials science</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>Contents</h1>
<p>1 Abstract ..... 3
2 Introduction ..... 3
3 Defining discovery ..... 4
3.1 Classifications of discoveries ..... 4
3.2 Discovery as a search ..... 6
3.3 The role of validation and feedback ..... 7
4 Elements of autonomous discovery ..... 9
4.1 Assessing autonomy in discovery ..... 9
4.2 Enabling factors ..... 12
5 Examples of (partially) autonomous discovery ..... 15
5.1 Foundational computational reasoning frameworks ..... 15
5.2 Discovery of mechanistic models ..... 17
5.2.1 Discovery of detailed kinetic mechanisms ..... 17
5.3 Noniterative discovery of chemical processes ..... 19
5.3.1 Discovery of new synthetic pathways ..... 19
5.3.2 Discovering models of chemical reactivity ..... 21
5.3.3 Discovery of new chemical reactions from experimental screening ..... 25
5.4 Iterative discovery of chemical processes ..... 25
5.4.1 Discovery of optimal synthesis conditions ..... 25
5.4.2 Discovery of new chemical reactions through an active search ..... 28
5.5 Noniterative discovery of structure-property models ..... 29
5.5.1 Discovery of important molecular features ..... 30
5.5.2 Discovery of models for spectral analysis ..... 31
5.5.3 Discovery of potential energy surfaces and functionals ..... 32
5.5.4 Discovery of models for phase behavior ..... 33
5.6 Noniterative discovery of new physical matter ..... 33
5.6.1 Discovery through brute-force experimentation ..... 34
5.6.2 Discovery through computational screening ..... 36
5.6.3 Discovery through molecular generation ..... 39
5.7 Iterative discovery of new physical matter ..... 42
5.7.1 Discovery for pharmaceutical applications ..... 42
5.7.2 Discovery for materials applications ..... 45
5.8 Brief summary of discovery in other domains ..... 50
6 Conclusion ..... 51
7 Acknowledgements ..... 51</p>
<h1>1 Abstract</h1>
<p>This two-part review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modelling.</p>
<p>Part two reflects on these case studies and identifies a set of open challenges for the field.</p>
<h2>2 Introduction</h2>
<p>The prospect of a robotic scientist has long been an object of curiosity, optimism, skepticism, and job-loss fear, depending on who is asked. As computing was becoming mainstream, excitement grew around the potential for logic and reasoning-the underpinnings of the scientific process-to be codified into computer programs; as hardware automation became more robust and cost effective, excitement grew around the potential for a universal synthesis platform to enhance the work of human chemists in the lab; and as data availability and statistical analysis/inference techniques improved, excitement grew around the potential for statistical models (machine learning included) to draw new insights from vast quantities of chemical information $[1-7]$.</p>
<p>The confluence of these factors makes that prospect increasingly realistic. In organic chemistry, we have already seen proof-of-concept examples of the "robo-chemist" [8] able to intelligently select and conduct experiments [9-11]; there have even been strides made toward a universal synthesis platform [12-15], theoretically capable of executing most chemical processes but highly constrained in practice. While there have been fewer success stories in automating drug discovery holistically [16], the excitement around machine learning in this application space is especially apparent, with dozens of start-up companies promising to revolutionize the development of new medicines through artificial intelligence [17].</p>
<p>A more pessimistic view of automated discovery is that machines will never be able to make real "revolutions" in science because they necessarily operate within a specific set of instructions [18]. This attitude is exemplified by Lady Lovelace's objection: "The Analytical Engine has no pretensions to originate anything. It can do whatever we know how to order it to perform. It can follow analysis; but it has no power of</p>
<p>anticipating any analytical relations or truths" [1]. Some have expressed a milder sentiment, perhaps in light of advances in computing, cautioning that an increasing reliance on robotic tools might reduce the odds of a serendipitous discovery [6]. Muggleton is more declarative, stating that "science is an essentially human activity that requires clarity both in the statement of hypotheses and their clear and undeniable refutation through experimentation" [19]. However, there is little disagreement that automation and computation in science has improved productivity through efficiency, reduction of error, and the ability to address large-scale problems [20].</p>
<p>In the remainder of Part 1, we will discuss the different types of discovery typically reported in the chemical sciences and how they can be unified as searches in a high-dimensional design space. Along with this definition comes a recommended set of questions to ask when evaluating the extent to which a discovery can be attributed to automation or autonomy. We will then discuss a number of case studies arranged in terms of the type of discovery being pursued and the nature of the approach used to do so. Part 2 will reflect on these case studies and make explicit what we believe to be the primary obstacles to autonomous discovery.</p>
<h1>3 Defining discovery</h1>
<h3>3.1 Classifications of discoveries</h3>
<p>There is no single definition of what constitutes a scientific discovery. ValdÃ©s-PÃ©rez defines discovery as "the generation of novel, interesting, plausible, and intelligible knowledge" [5]. Data-driven knowledge discovery, specifically, has been defined as the "nontrivial extraction of implicit, previously unknown, and potential useful information" [21]. Each of these criteria, however, is inherently subjective. "Novel" is simultaneously ambiguous and considered distinct from "new"; it is generally meant to indicate some level of nonobviousness or, by one definition, a lack of predictability [22]. However, if we artificially limit what we consider to be known and demonstrate a successful extrapolation to a conclusion that really was known, it would be reasonable to argue that this does not constitute a discovery. This connects to the question of what it might mean for a discovery to be "interesting" or "useful", for which we avoid providing a precise definition.</p>
<p>For the purposes of this review, we instead define three broad types of discoveries in the chemical sciences (Figure 1) and provide examples of each.</p>
<p>Physical matter. Often, the ultimate result of a discovery campaign is the identification of a molecule (not discounting macromolecules), material, or device that achieves a desired function. This category encompasses most drug discovery efforts, where the output may be new chemical matter that could later become</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The three broad categories of discovery described in this review: physical matter, processes, and models.
part of a therapeutic, as well as materials discovery for a wide array of applications.
Processes. Discoveries may also take the form of processes. These may be abstract, like the HaberBosch process, pasteurization, and directed evolution. They are more often concrete, like synthetic routes to organic molecules or a specific set of reaction conditions to achieve a chemical transformation.</p>
<p>Models. Our definition of a model includes empirical models (such as those obtained through regression of experimental data), structure-function relationships, symbolic regressions, natural laws, and even conceptual models that provide mechanistic understanding. It is common for models to be part of the discovery of the other two types as surrogates for experiments, as will be seen in many examples below.</p>
<p>The most famous examples of scientific discoveries in chemistry tend to be natural laws or theories that are able to rationalize observed phenomena that previous theories could not. Mendeleev's periodic table of the elements, Thomson's discovery of the electron, Rutherford's discovery of atomic nuclei, the Schrodinger equation, KekulÃ©'s structure of benzene, et cetera. In their time, these represented radical departures from previous frameworks. Though we do consider these to be models, identifying them through computational or algorithmic approaches would require substantially more open-ended hypothesis generation than what is currently possible.</p>
<h1>3.2 Discovery as a search</h1>
<p>We argue that the process of scientific discovery can always be thought of as a search problem, regardless of the nature of that discovery $[7,23,24]$.</p>
<p>Molecular discovery is a search within "chemical space" [25-28]-an enormous combinatorial design space of theoretically-possible molecules. A common estimate of its size, considering only molecules of a limited size made up of CHONS atoms, is $10^{60}$ [29], although for any one application or with reasonable restrictions (e.g., on drug-likeness or synthetic accessibility), the size of the relevant chemical space will be significantly smaller [30, 31]. Biological compounds exist in an even larger space if one considers that there are, e.g., $20^{100}$ theoretically-possible 100 -peptide proteins using only canonical amino acids, although again the number that are foldable and biologically relevant will be significantly smaller. Materials discovery is another combinatorial design space, where structural composition must be defined by both discrete variables (e.g., elemental identities) and continuous variables (e.g., stoichometric ratios) and processing conditions. The design space for a device is even larger, as it compounds the complexity of its constituent components with additional considerations about its geometry.</p>
<p>Discovering a chemical or physical process is the result of searching a design space defined by process variables and/or sequences of operations. For example, optimizing a chemical reaction for its yield might involve changing species' concentrations, the reaction temperature, and the residence time [32]. It may also include selecting the identity of a catalyst as a discrete variable [33], or changing the order of addition [34]. A new research workflow can be thought of as the identification of actions to be taken and their timing, such as the development of split-and-pool combinatorial chemistry for diversity-oriented synthesis [35] or a screening and selection strategy for directed evolution [36].</p>
<p>The majority of models that are "discovered", under our broad definition, are empirical relationships that come from data fitting. In these cases, the search space is well-defined once an input representation (e.g., a set of descriptors or parameters) and a model family (e.g., a linear model, a deep neural network) are selected. While this can present a massive search space when considering all possible values of all learned parameters (e.g., for deep learning regression techniques), the final model is often the result of a simplified, local search from a random initialization (e.g., using stochastic gradient descent). Symbolic regressions are searches in a combinatorial space of input variables and mathematical operations [37]. More abstract models, like mechanistic explanations of natural phenomena, exist in a high-dimensional hypothesis space that is difficult to formalize; automated discovery tools that are able to generate causal explanations do so using simplified terminology and well-defined ontologies [38].</p>
<p>In virtually every case of computer-assisted discovery, the actual search space is significantly larger than</p>
<p>what the program or platform is allowed to explore. We might decide to focus our attention on a specific set of compounds (e.g., a fixed scaffold), a specific class of materials (e.g., perovskites), a specific step in a catalyst synthesis process with a finite number of tunable process variables (e.g., the temperature and time of an annealing step), or a specific hypothesis structure (e.g., categorizing a ligand's effect on a protein as an agonist, antagonist, promoter, etc.). Constraining the search space is one way of integrating domain expertise/intuition into the discovery process. Moreover, it can greatly simplify the search process and mitigate the practical challenges of automated validation and feedback.</p>
<h1>3.3 The role of validation and feedback</h1>
<p>The way that we navigate the search space in a discovery effort is often iterative. Classically, the discovery of physical matter, such as in lead optimization for drug discovery, is divided into stages of design, make, test. An analogous cycle for searching hypothesis space could be described as hypothesize, validate, revise beliefs.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Simplified schematic of a hypothesis-driven (or model-driven) discovery process. When not proceeding iteratively, new information is not used to revise our belief (current knowledge). Lowercase roman numerals (red) correspond to the questions for assessing autonomy in discovery.</p>
<p>This third step-test or revise beliefs-helps to explain the role of validation and feedback in discovery: experiments, physical or computational, serve to support or refute hypotheses. When information is imperfect or insufficient to lead to a confident prediction, it is important to collect new information to improve our understanding of the problem. This might mean taking an empirical regression fit to a small number of data points, evaluating our uncertainty, and performing follow-up experiments to reduce our uncertainty in regions where we would like to have a more confident prediction (Figure 2). Purely virtual screening is not sufficient for drug discovery [39], where experimental validation continues to be essential [40]; Schneider and Clark describe experimental testing of drugs designed using de novo workflows as a "non-negotiable" criterion [41]. In the materials space as well, Halls and Tasaki propose a materials discovery scheme in which synthesis,</p>
<p>characterization, and testing are critical components [42]. The scope of hypotheses that lend themselves to automated validation has limited the scope of discovery tasks that are able to be automated.</p>
<p>Consider a scenario where we have a large data set of molecular structures and a property of interest, like their in vitro binding affinity for a particular protein target. We can perform a statistical regression to correlate the two and represent our understanding of the structure-function landscape. Based on that model, we may propose a new structure-a compound not yet tested-that is predicted to have high activity. Whether that constitutes discovery of the compound is ambiguous. Using scientific publication as the bar, it is reasonable to expect a high degree of confidence, regardless of whether that confidence arises from a statistical analysis of existing data or from confirmation through acquisition of new data. Even with a highly accurate model, performing a large virtual screen could lead to thousands of false positive results [31]. For a philosophical discussion about the nature of knowledge and need for confidence, correctness, and justification, see the description of the Gettier problem in ref. 43.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: One way to visualize the discovery process. The goal definition will implicitly or explicitly define the search space within which we operate. Available structured information can be used to generate or refine a hypothesis within that search space. Often, when we are doing more than pure data analysis, there will be an iterative process of information gathering prior to the final output, or interpretation.</p>
<p>We note here that this hypothesis-first approach to discovery (Figure 3) is more consistent with the philosophy of Popper [44]. This is in contrast to an observation- or experiment-first approach, which is more consistent with the philosophy of Bacon [45]; data mining studies tend to be Baconian [46]. In practice, when discovery proceeds iteratively, the distinction between the two is simply where one enters the cycle. Both are types of model-guided discovery, which is distinct from brute-force screening or approaches relying solely on serendipity that we discuss later.</p>
<h1>4 Elements of autonomous discovery</h1>
<p>It is impossible to imagine conducting research without some degree of machine assistance, defining "machine" broadly. We rely on computers to organize, analyze, and visualize data; analytical instruments to queue samples, perform complex measurements, and convert them into structured data. However, it is important to consider precisely what is facilitated by automation or computer-assistance in terms of the broader discovery process. Many technologies (e.g., NMR sample changers) add a tremendous amount of convenience and reduce the manual burden of experimentation, but provide only a modest acceleration of discovery rather than a fundamental shift in the way we approach these problems. Considering the cognitive burden of experimental design and analysis connects to the distinction between autonomy and automation. A toy slot car that sets its own speed as it proceeds through a fixed track is qualitatively different from a self-driving car in the city, yet each successfully operates within its defined environment. Though there is no precise threshold between automation and autonomy, autonomy generally implies some degree of decision-making and adaptability in response to unexpected outcomes.</p>
<h3>4.1 Assessing autonomy in discovery</h3>
<p>Here, we propose a set of questions to ask when evaluating the extent to which a discovery process or workflow is autonomous: (i) How broadly is the goal defined? (ii) How constrained is the search/design space? (iii) How are experiments for validation/feedback selected? (iv) How superior to a brute force search is navigation of the design space? (v) How are experiments for validation/feedback performed? (vi) How are results organized and interpreted? (vii) Does the discovery outcome contribute to broader scientific knowledge? These questions are mapped onto the schematic for hypothesis-driven discovery in Figure 2.
(i) How broadly is the goal defined? While algorithms can be made to exhibit creativity (e.g., coming up with a unique strategy in Go or Chess [47, 48]), at some level, they do so for the sake of maximizing a human-defined objective. Is the goal defined at the highest level possible (e.g., find an effective therapeutic)? Or is it narrow (e.g., find a molecule that maximizes this black-box property for which we have an assay and preliminary data)? The higher the level at which the mission can be defined, the more compelling the discovery becomes. That requires platforms to understand what experiments can be performed and how they are useful for the task at hand.
(ii) How constrained is the search/design space? An unconstrained search space is one that we operate in as human researchers. There are many ways in which humans can artificially constrain the search space available to an autonomous platform. A maximally constrained search space in the discovery</p>
<p>of physical matter could be a (small) fixed list of candidates over which to screen. Limitations in the experimental and computational capabilities of an autonomous platform have the effect of constraining the search space as well; the scientific process itself has been described by some as a dual search in a hypothesis space and experimental space [24, 49]. How these constraints are defined influences the difficulty of the search process, the likelihood of success, and the significance of the discovery. The fewer the constraints placed on a platform, the greater the degree to which it can be said to be operating autonomously.
(iii) How are experiments for validation/feedback selected? Unconstrained experimental design is a complex process requiring evaluation of local decisions as well as a global strategy for the overall timeframe, coherency, and scientific merit of a proposed experiment [50]. When operating within a restricted experimental space, design can be simplified to local decisions of specific implementation details without these high-level decisions. Cummings and Bruni define a taxonomy for human-automation collaboration in terms of the three primary roles played by a human or computer: moderator (of the overall decision-making process), generator (of feasible solutions), and decision-maker (of which action to take) [51]. Their levels of automation include ones where humans must take all decisions/actions, where the computer narrows down the selection, where the computer executes one if the human approves, and where the computer executes automatically and informs the human if necessary. The second level is typical for the discovery of new physical matter, where computational design algorithms may propose compounds that must be subjected to a manual assessment of synthesizability before being manually synthesized. The smaller the search space and the cheaper the experiments-including considerations of time and risk of failure-the less human intervention is required in selecting experiments.
(iv) How superior to a brute force search is navigation of the design space? This question seeks to identify the extent to which there is "intelligence" in the search strategy. Langley et al.'s notion of discovery as a heuristic search emphasizes this criterion [23]. Whether or not the strategy is more effective than a brute force search depends on the size of the space and how experiments are selected. For example, a high throughput screen of compounds from a fixed library is equivalent to a brute-force search. An active learning strategy designed to promote exploration might require only $20 \%$ of the experiments to find an optimal solution. When dealing with continuous (e.g., process variables) or virtually infinite (e.g., molecular structure) design spaces, it is not possible to quantify meaningfully the number of experiments in a brute-force search.
(v) How are experiments for validation/feedback performed? Being able to automatically gather new information to support/refute a hypothesis is an important aspect of an automated discovery</p>
<p>workflow. At one extreme, experiments are performed entirely by humans (regardless of how they are proposed); in the middle, experiments might be performed semi-automatically but require significant human set-up between experiments; at the other extreme, experiments can be performed entirely without human intervention. This question is tightly coupled to that of who chooses the experiments and the size of the search space. The narrower the experimental design space, the more likely it is that validation/feedback can be automated. In computational studies, it is relatively straightforward to automate simulations if we are willing to discard failures without manual inspection (e.g., DFT simulations that fail to converge).
(vi) How are results organized and interpreted? In an iterative workflow, the results of information gathering (experiments, simulations) are organized as structured information and used to update our prior knowledge and revise our beliefs before the next round of experimental design. Provided that the experiments/simulations can be designed to produce information that is already in a compatible format (e.g., quantifying a reaction yield to build a model of yield as a function of process variables), this is simply a practical step toward closing the loop. In a few specialized workflows, experimental results naturally drive the selection of subsequent experiments, as in directed evolution and phase-assisted continuous evolution [52].
(vii) (optional) Does the outcome contribute to broader scientific knowledge? Though not necessarily related to the concept of autonomy, this question speaks to impact and intelligibility. Does it require extensive interpretation after the fact to evaluate how or what it has learned, or is it selfexplanatory? Intelligibility is one of the criteria for discovery put forward by ValdÃ©s-PÃ©rez [5], among others. Describing physical phenomena requires far less domain knowledge than does explaining those phenomena [53]. Especially in empirical modeling, there is often a dichotomy between models built for accurate predictions and models built for explanatory predictions [54, 55]. Turing made note of this at least as early as 1950, saying that "an important feature of a learning machine is that its teacher will often be very largely ignorant of quite what is going on inside, although he may still be able to some extent to predict his pupil's behavior" [1]. The past few years have seen an interest in the transparency, interpretability, and explainability of machine learning models, not just the accuracy [56].</p>
<p>Several of these questions probe the extent to which discovery is "closed loop", which implicitly assumes an iterative process of multiple hypothesize-test-revise beliefs cycles. Iterative refinement is crucial when operating inside poorly-explored design spaces (e.g., using an uncommon scaffold) or with new objective functions (e.g., maximizing binding to a new protein target in vitro). Most of the case studies described in the following sections are better described as "open loop" and involve only certain aspects of the work-</p>
<p>flow in Figure 2. For example, a common paradigm of computer-aided discovery is to define an objective function, perform a large-scale data mining study, propose a solution of new molecule, material, and/or model, and manually validate a small number of those predictions. Waltz and Buchanan describe many early computational discovery programs as merely running calculations, rather than trying to close the loop $[20]$.</p>
<h1>4.2 Enabling factors</h1>
<p>A confluence of improved data availability, computing abilities, and experimental capabilities have brought us substantially closer to autonomous discovery (Figure 4). These improvements contribute to two categories of methodological progress: (1) techniques for navigating the search space more effectively, and (2) techniques for accelerating validation/feedback. Many machine learning techniques, for example, have been used to build empirical models within the search space to enable or accelerate the search; mapping the design space for a molecule, material, device, or process to relevant performance metrics is a prerequisite for any "rational design".
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The factors that have enabled autonomous discovery fall into one of three main categories.</p>
<p>As Claus and Underwood point out, effective discovery requires assimilation of knowledge contained in large quantities of data of diverse types [57]. The quantity of chemical property and process data available in journals, the patent literature, and online databases makes it challenging to analyze by hand. Digitization of organic reaction information into computer-readable databases like Reaxys, SPRESI, CASREACT, and Lowe's USPTO dataset has not just facilitated searching that information, but has enabled new analyses thereof [58]. Millions of bioactivity measurements are found in databases like ChEMBL and PubChem, not to mention the dozens of genomic, metabolomic, and proteomic databases that have emerged in the last decade $[59,60]$. There are also many repositories for experimental and computational properties of materials, which</p>
<p>have facilitated the construction of empirical models to predict new material performance [61, 62]. Gil et al. [63] discusses the utility of AI techniques in searching and synthesizing large amounts of information as part of "discovery informatics" [57, 64, 65]. Even now, an enormous amount of untapped information remains housed in laboratory notebooks and journal articles. For such information to be directly usable, someone must undertake the challenge of compiling the data into an accessible, user-friendly format and overcome any intellectual property restrictions. Image and natural language processing techniques can make this task less burdensome; there is increasing interest in adapting such information extraction algorithms for use in chemistry $[66-71]$.</p>
<p>Autonomous discovery systems rely on a variety of computational tools to generate hypotheses from data without human intervention. This includes both the software that makes the recommendations (e.g., proposes correlations, regresses models, selects experiments) as well as the underlying hardware that makes using the software tractable. Our discussion of the advances in this area focuses on software developments with an emphasis on machine learning algorithms, which has elicited cross-disciplinary excitement [72-75].</p>
<p>Typically, search domains that are of interest for discovery are characterized by high dimensionality (e.g., chemical space). In such domains, the patterns within the available data may be beyond the capacity of humans to infer a priori without years of intuition-building practice. Machine learning and pattern recognition algorithms can be used to discover these regularities automatically, e.g., by using the available data to parameterize a neural network model [76]. Varnek and Baskin and Mitchell provide overviews of machine learning techniques as applicable to common cheminformatics problems [77, 78] and brief tutorials can be found in a number of reviews [79-82]. It is becoming increasingly common to use machine learning to develop empirical quantitative structure-activity/property relationships (QSARs/QSPRs) to score molecules and guide virtual screening as part of broader discovery frameworks [83]. These models can be used to distinguish promising compounds from unpromising ones and prioritize molecules for synthesis and testing (validation), thus facilitating the extrapolation of information about existing molecules to novel molecules that exist only in silico [31].</p>
<p>Algorithms that enable efficient navigation of design spaces represent an important set of computing advances. Even with a model representing our belief about a physical structure-property relationship, an algorithmic framework is needed to apply that belief to experimental design. These frameworks include active learning strategies [84] that aim to maximize the accuracy of predictive models while minimizing the required training data, as well as goal-directed strategies such as Bayesian optimization [85] and genetic algorithms [86]. These iterative techniques can reduce the experimental burden associated with discovery in domains or search spaces where exhaustive testing is not practical.</p>
<p>Algorithms that are capable of directly proposing candidate molecules or materials (physical matter)</p>
<p>as a form of experiment selection are worth special emphasis. Recently, deep generative models [87] such as generative adversarial networks (GANs) [88] and variational autoencoders (VAEs) [89] have attracted a great deal of interest, as they facilitate the creation of diverse molecular libraries without the impossible task of systematically enumerating all potential functional compounds [90-92]. Many case studies that leverage these and related frameworks for the discovery of physical matter are described later.</p>
<p>Experimental advances toward autonomous discovery include automation of well-established laboratory workflows (along with parallelization and miniaturization) as well as entirely novel synthetic and analytical methodologies. Aspects of experimental validation (Figure 5) have existed in an automated format for decades (e.g., addition to and sampling from chemical reactors [93, 94]), and many of the requisite hardware units have been commercialized (e.g., liquid handling platforms and plate readers available through companies such as Beckman, Hamilton, BioTek, and Tecan). However, moving beyond piecemeal automation to the entire experimental burden of discovery workflows is challenging. Each process step, which may include synthesis, purification, assay preparation, and analysis, must be seamlessly integrated for the platform to operate without manual intervention; each interface presents new potential points of failure [95].
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Generic workflow for experimental validation.</p>
<p>The complexity of software required for hardware automation ranges from sequencing commands from a fixed schedule [15], to real-time control and optimization [10], to higher-level scheduling and orchestration [96]; user interface driven software such as LabVIEW [97] can aid the creation of fit-for-purpose control systems with minimal programming experience. Although end-to-end automation of an experimental discovery workflow is uncommon, there are numerous benefits to be gained even from partial automation, chief among these being standardization and increased throughput [98].</p>
<p>In addition to automation, novel experimental methodologies have been developed that lend themselves particularly well to autonomous discovery workflows by facilitating the exploration of broad design spaces, a helpful feature that increases the likelihood of discovery [99]. These include synthesis-focused methodologies, such as DNA-encoded libraries [100] and diversity-oriented synthesis [35, 101], as well as analysis-focused methodologies, such as ambient mass spectrometry [102] and MISER for accelerating liquid chromatographic analysis $[103]$.</p>
<p>The three categories of enabling factors described herein facilitate discovery in different ways: data is leveraged to create models that inform and predict, computational tools are used to create models from data and reason about which experiments to perform next, and physical (or computational) experiments validate hypotheses and facilitate refinement thereof. These factors can be strategically combined to give rise to different types of studies. For example, the experimental capabilities described here, in isolation, can be used for high-throughput, brute-force screening; computational tools can be used for data generation (through, e.g., DFT simulations); virtual screening is achieved through the combination of data and algorithms; and integration of all three is needed for fully autonomous discovery.</p>
<h1>5 Examples of (partially) autonomous discovery</h1>
<p>In this section, we summarize a series of case studies that demonstrate how automation and machine autonomy influence discovery in various research domains. The extent to which techniques in automation and computation have enabled each case varies. Some only benefit from automated laboratory hardware, others learn underlying trends from large or complex data, and still others use computational techniques to efficiently explore high dimensional design spaces.</p>
<p>Specifically, subsection 5.1 describes early computational reasoning frameworks; 5.2 describes the discovery of mechanistic models; 5.3 and 5.4 describe the noniterative and iterative discovery of chemical processes; 5.5 describes the noniterative discovery of property models; 5.6 and 5.7 describe the noniterative and iterative discovery of physical matter; finally, 5.8 provides a brief summary of a few tangentially-related domains.</p>
<h3>5.1 Foundational computational reasoning frameworks</h3>
<p>There has been a long-standing fascination with the philosophical question of whether or not it is possible to codify and automate the process of discovery [104]. In the 1980s and 1990s, several programs were developed to mimic a codifiable approach to discovery and to reproduce specific quintessential discoveries of models, led by Langley and Zytkow [6]. These programs deal with questions of model induction and hypothesis generation (as a form of data analysis) rather than experimental selection and automated validation/feedback.</p>
<p>BACON is a rule-based framework introduced in 1978 to formalize the Baconian method of inductive reasoning to discover empirical laws, supplemented with data-driven heuristics [105]. BACON.4, a later iteration specifically designed for chemical problems, searched for arithmetic combinations of input variables to identify regularities in data (e.g., noting that pressure times volume is invariant for constant temperature in a closed gas system) [7]. This approach was able to recapitulate Ohm's law, Archimedes' law of displacement, Snell's law, conservation of momentum, gravitation, and Black's specific heat law [106]. The search for an</p>
<p>empirical relationship was greatly simplified by excluding any irrelevant variables (i.e., all input variables were known to be important) and eliminating all measurement noise. Extensions of this approach included describing piecewise functions (FARENHEIT [107]) and coping with irrelevant observations and noise (ABACUS [108]). More recently, Schmidt and Lipson demonstrated that using a symbolic regression framework similar to BACON, it is possible to rediscover Hamiltonians, Lagrangians, and geometric conservation laws from empirical motion tracking data [37]. Much like its predecessors, their program uses a two-part process of generating and scoring hypothesized analytical laws.</p>
<p>The STAHL program developed by Zytkow and Simon in the mid-1980s sought to automate the construction of compositional models to, e.g., rediscover Lavoisier's theory of oxygen [109]. It operates on a list of chemical reactions to produce a list of proposed chemical elements and the compounds they make up by making inferences like " $\mathrm{A}+\mathrm{B}+\mathrm{C} \longrightarrow \mathrm{B}+\mathrm{D} " \Longrightarrow$ " D is composed of A and C ". While the program was arguably successful in formalizing a specific form of scientific reasoning, the lack of any consideration for stoichometry, phase changes, and ability to consider uncertainty, competing hypotheses, and request information makes such a logic framework highly limited in utility. The KEKADA program [110] was designed with those abilities in order to replicate the discovery of the Krebs cycle. Using seven heuristic operators (hypothesis proposers, problem generators, problem choosers, expectation setters, hypothesis generators, hypothesis modifiers, and confidence modifiers) and simulated experiments of metabolic reactions, KEKADA was able to rediscover the Krebs cycle from the same empirical data that would have been obtainable at the time.</p>
<p>The knowledge bases for these early programs were comprised of expert-defined relationships, rules, and heuristics designed to reflect prior knowledge and bring the programs up to the level of domain experts. Programs based entirely on user-defined axioms have proved successful in automatic theorem generation in graph theory [111]. However, these rules bring at least two drawbacks in the context of inductive reasoning. The first is that it is more difficult for experts to recapitulate their knowledge through rules than by providing examples from which an algorithm can generalize [112]. The second is that too stringent priors may restrict the model from deviating far enough from existing theory to make a substantial discovery and merely "fill in the gaps" of what is known. Kulkarni and Simon argue that a lack of prior knowledge about allowed/disallowed reactions actually served to benefit Krebs, as a formally trained chemist might not have pursued a hypothesis that was-at the time-believed to be highly unlikely [110].</p>
<h1>5.2 Discovery of mechanistic models</h1>
<h3>5.2.1 Discovery of detailed kinetic mechanisms</h3>
<p>Computer assistance has proved useful in the exploration and simulation of reaction pathways [113-116]. The vast number of possible elementary reactions creates a combinatorial space of hypothesized pathways that is difficult to explore manually in an unbiased manner, making it a prime candidate for algorithmic approaches. One such approach, MECHEM, enumerates elementary reactions in catalytic reaction systems to identify series of mechanistic steps able to rationalize an observed global reaction [117-119]. Ismail et al. have demonstrated a similar approach to identifying multi-step reaction mechanisms for catalytic reactions using a ReaxFF potential energy surface [121] to guide the search toward kinetically-likely pathways [120]. In the absence of heuristics or calculations to drive the search, millions of possible elementary reactions can be generated even with species of just a few atoms [122].</p>
<p>The Reaction Mechanism Generator (RMG) fills a similar role in developing detailed kinetic mechanisms for combustion and pyrolysis processes [123]. Expert-defined reaction templates enumerate potential elementary reactions between a set of user-defined input molecules; rate constants for the forward and reverse reactions are estimated from a combination of first principles calculations (e.g., DFT) and group additivity rules regressed to experimental data. The ability to estimate kinetic and thermodynamic parameters enables the identification of new elementary reactions and pathways and, e.g., exploration of untested fuel additives' effects on ignition delay [124]. An earlier study by Broadbelt et al. used a similar approach to develop detailed kinetic models for pyrolysis reactions [125].</p>
<p>Mechanistic enumerations/searches have been applied extensively to the discovery of transition states and reaction channels [126-128]. These methods represent a search in the $(3 N-6)$-dimensional potential energy surface landscape implicitly defined by an $N$-atom pool of reacting species. Approaches like Berny optimization [129] are used to identify transition state (TS) geometries for the purposes of estimating energetic barrier heights. Double-ended search methods like the freezing string method (FSM [130]) or growing string method (GSM [131]) require knowledge of the product structure and run iterative electronic structure calculations to identify a plausible reaction pathway; these can be applied to the discovery of new elementary reactions by systematically enumerating potential product species [132-134] (Figure 7). Single-ended search methods operate on reactant species only and perturb the geometry along reactive coordinates, including, e.g., the artificial force induced reaction method (AFIR [135]). An alternate approach to reaction discovery is by direct simulation of reactive mixtures using molecular dynamics (MD) [136-138]. Wang et al. describe the use of an " $a b$ initio nanoreactor" to find unexpected products from similar starting materials to the Urey-Miller experiment on the origin of life [136]. Importantly, their approach does not require the use of</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Discovery of detailed kinetic models through iterative selection of important elementary reaction steps. Figure reproduced from Broadbelt et al. [125].
heuristics to define reaction coordinates or enumeration rules to define possible products. Instead, molecules in an MD simulation are periodically pushed toward the center to impart kinetic energy and encourage collisions at a rate that enables the observation of rare events over tractable simulation timescales. In principle, these can be to applied to the prospective prediction of novel reaction types and, ultimately, the development of new synthetic methodologies.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Workflow for identification of reaction networks between known reactants R and known products P through combinatorial enumeration of possible mechanistic steps pruned by calculated transition state energies. Figure reproduced from Kim et al. [134].</p>
<h1>5.3 Noniterative discovery of chemical processes</h1>
<h3>5.3.1 Discovery of new synthetic pathways</h3>
<p>Synthetic pathways are a prerequisite for physically producing a molecule of interest, whether for experimental validation of a predicted property or for production at scale. Retrospective analyses of known single-step chemical reactions can yield hypothesized synthetic pathways as combinations thereof. Gothard et al. describe an analysis of a "Network of Organic Chemistry"-a copy of the Beilstein database with seven million reactions-for the discovery of one-pot reactions; their search space comprised any consecutive sequence of known reactions where the product of one is a reactant of another [139]. Candidate sequences were evaluated using eight filters, including a $322 \times 322$ table of functional groups and their cross-reactivity and a $322 \times 97$ table of their compatibility under 97 categories of reaction conditions. Through application of these expert heuristics to millions of candidate sequences, the authors identified multi-step chemistries that could potentially be run without an intermediate purification, choosing a handful of such pathways for experimental validation. While their filters were all hand-encoded, data mining techniques can also be used to estimate functional group reactivity [140, 141]. Selecting pathways within a search space defined by combinations of known single-step reactions has taken on other forms as well, including the identification of cyclic pathways [142], the optimization of process cost [143], and the optimization of estimated process mass intensity [144].</p>
<p>Generating yet-unseen chemical reactions for a synthesis plan-a necessity for the synthesis of novel molecules-is a harder search problem than when searching within a fixed reaction network [145]. Because the number of states in a naive retrosynthetic expansion will scale as $b^{d}$ for branching factor $b$ and depth $d$, guiding the search is an essential aspect of computer-aided synthesis planning (CASP) programs. The breadth of the search depends on the coverage of the rule sets: abstracted enzymatic reactions tend to number in the hundreds [146], expert transformation rules often number in dozens or hundreds [147, 148] but can extend into the tens of thousands in contemporary programs [149], and algorithmically-extracted templates generally number in the thousands to hundreds of thousands [150-153]. To the extent that reaction rules and synthetic strategies can be codified, synthesis planning is highly conducive to computational assistance [58, 154-158] (Figure 8). CASP approaches that generate retrosynthetic suggestions without the use of pre-extracted template libraries $[159,160]$ still result in a large search space of possible disconnections.</p>
<p>Even the earliest CASP programs emphasized the importance of navigating the search space of possible disconnections [154, 161]. The search in OCSS was guided by five subgoals for structural simplification: reduce internal connectivity, reduce molecular size, minimize functional groups, remove reactive or unstable functional groups, and simplify stereochemistry [161]. Starting material oriented retrosynthesis introduces additional constraints in the search, as the goal state is a specific starting material, rather than one of many</p>
<p>from a database of available compounds [162]. It is only fairly recently that CASP tools have started to be used more widely for discovery of synthetic routes. Development is stymied by the complexities of validation and feedback, which can only occur by experimental implementation [163] or review by expert chemists [164].
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Workflow used by the WODCA program for computer-aided synthesis planning. Figure reproduced from Ihlenfeldt and Gasteiger [154].</p>
<p>There are two main approaches to navigating the search space during retrosynthetic expansion to determine which disconnections are most promising: value functions and action policies. Value functions estimate the synthetic complexity of reactant molecules as a proxy for how close they are to being purchasable [165169]. Despite their limitations, these are widely used in virtual screening libraries as a rapid means of prioritizing compounds that appear more synthetically tractable. While even simple user-defined heuristics that attempt to break a molecule into the smallest possible fragments can be successful in planning full synthetic routes, learned value functions can offer some advantages in finding shorter pathways or being tailored to a user-defined cost function [170]. Action policies directly predict which transformation rule to apply based on literature precedents in a knowledge base; this can be accomplished through a simple nearest-neighbor strategy [171] or through a trained neural network model for classification [153]. The latter approach has been integrated into a Monte Carlo tree search framework to rapidly generate and explore the space of candidate pathways, resulting in recommendations that chemists considered equally plausible to literature pathways in a double-blind study [164]. Less common approaches to navigating the search space include proof-number search [172].</p>
<p>Reaction pathway discovery is relevant in synthetic biology and metabolic engineering contexts as well.</p>
<p>For example, one study by Rangarajan et al. describes the application of Rule Input Network Generator (RING, [174]) to identify plausible production biosynthetic pathways through a heuristic-driven network generation and analysis [173]. Kim et al. review algorithms and heuristics used to explore metabolic networks and find optimal pathways [146]. A broader review of machine learning for biological networks can be found in ref. 175 .</p>
<h1>5.3.2 Discovering models of chemical reactivity</h1>
<p>Identifying synthetic pathways is but one step toward fully automated synthesis. For any theoretical robochemist capable of synthesizing any molecule on demand $[8,14]$, these ideas must be able to be acted upon and executed in the laboratory. Even without automated synthesis, hypothesized synthetic pathways are of little use without experimental validation. This requires additional models of chemical reactivity that can, among other things, propose suitable reaction conditions, estimate the confidence in the reactions it proposes, and have some notion of why one set of substrates might achieve a higher yield than others. Models for these tasks can be trained directly on experimental data using a variety of statistical techniques.</p>
<p>Given a set of combination of successful and unsuccessful reaction examples (i.e., high and low yielding), one can train a binary classifier model to predict whether a proposed set of reaction conditions will be successful [176]. The same task can also be treated as a regression of reaction yields, rather than as a classification, as a function of substrate descriptors; a virtual screen of known conditions as a fixed search space can then propose substrate-dependent optimal conditions [177]. When only successful reaction examples are present, one can treat the selection of reaction conditions as a recommendation problem comprising a classification subproblem (for reagent, catalyst, solvent identity) and a regression subproblem (temperature) under the assumption that the "true" published conditions are adequate. This was Gao et al.'s approach using the Reaxys database to produce a model that is able to propose conditions at the level of species identity and temperature based on reactant and product structures [178]. In the process of learning the relationship between reactants/products and suitable reaction conditions, the model learns a continuous embedding for chemicals that reflects their function in organic synthesis, similar to how semantic meaning is captured by word2vec models [179]. Formulating condition selection as a data-driven classification problem has also been used in a more focused manner as an alternative to expert recommender systems [180], e.g., to choose phosphine ligands for Buchwald-Hartwig aminations [144] or catalysts for deprotections [141].</p>
<p>In some cases, computational prediction of solvation free energies can meaningfully assist in the selection of reaction solvents [181]. To a first approximation, solvation energy can be estimated by a linear model describing potential solute-solvent interactions [182, 183]. When those interaction parameters can be predicted via DFT, one can estimate the performance of a large virtual set of solvents, e.g., to optimize the rate</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Department of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA 02139
${ }^{\dagger}$ ccoley@mit.edu
${ }^{\ddagger}$ kfjensen@mit.edu&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>