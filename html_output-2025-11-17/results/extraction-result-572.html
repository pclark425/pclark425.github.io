<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-572 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-572</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-572</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-1d5972b32a9b5a455a6eef389de5b7fca25771ad</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1d5972b32a9b5a455a6eef389de5b7fca25771ad" target="_blank">Domain-Adversarial Training of Neural Networks</a></p>
                <p><strong>Paper Venue:</strong> Journal of machine learning research</p>
                <p><strong>Paper TL;DR:</strong> A new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions, which can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer.</p>
                <p><strong>Paper Abstract:</strong> We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. 
 
The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. 
 
We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e572.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e572.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DANN / GRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain-Adversarial Neural Network with Gradient Reversal Layer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A training procedure that enforces domain-invariant feature learning by adversarially training a feature extractor to fool a domain classifier; implemented via a gradient reversal layer that multiplies backpropagated gradients by a negative scalar.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Domain-adversarial training (Gradient Reversal Layer)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Joint training of (i) a feature extractor, (ii) a task label predictor, and (iii) a domain classifier so that the feature extractor minimizes task loss while maximizing domain-classifier loss; implemented by inserting a gradient reversal layer (GRL) between the feature extractor and the domain classifier which acts as identity in forward pass but multiplies gradients by -1 during backpropagation, thereby converting a minimization w.r.t. feature parameters into a saddle-point optimization that produces features indistinguishable across source and target domains.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / training procedure</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>adversarial training techniques from generative/discriminative modeling (machine learning)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>unsupervised domain adaptation / representation learning for cross-domain classification (machine learning applications: NLP, vision, descriptor learning)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Recast adversarial idea from generative modeling to domain-discrimination: (1) replaced generator/discriminator game with feature-extractor vs domain-classifier game; (2) introduced a parameter-free gradient reversal layer that negates gradients from domain loss to feature parameters so standard SGD finds the saddle point; (3) used a weighted domain loss (hyperparameter λ) with a schedule for gradually increasing domain-adversarial strength; (4) integrated into arbitrary feed-forward architectures (shallow MLPs, convolutional nets, pre-trained networks) and trained with standard backprop/SGD.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - demonstrated consistent empirical improvements: on the Amazon reviews sentiment tasks DANN outperformed a same-architecture NN and linear SVM (Table 1), with pairwise Poisson-binomial test probabilities showing DANN significantly better than NN (0.87) and SVM (0.83); when combined with mSDA representations the probabilities increase (0.92 vs NN, 0.88 vs SVM). DANN also reduced Proxy A-distance (PAD) between source and target feature distributions (Figure 3) and produced state-of-the-art-like improvements on multiple image-domain adaptation benchmarks (MNIST, SVHN, Office) and improved cross-dataset person re-identification (quantitative improvements reported in paper sections beyond this excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>training instability and early-stage issues when domain signals are strong (e.g., saturating sigmoids), need to tune/adapt λ schedule to prevent noisy adversarial signal early in training; computational cost for deep architectures; requirement for sufficient unlabeled target data.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>clear theoretical grounding in H-divergence/domain-adaptation theory; compatibility with existing backprop/SGD frameworks; only a small architectural change (GRL) required; availability of pre-trained networks and deep-learning toolkits (authors released GRL implementation for Caffe).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>requires labeled source data and unlabeled target data; implement GRL in training framework; choose/anneal λ schedule and learning-rate schedule; sufficient compute (GPUs) for deep models; for theoretical guarantees, domain-classifier hypothesis class should subsume label-classifier class ideally.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>high within machine-learning contexts: authors claim DANN (via GRL) can be applied to almost any feed-forward neural architecture and demonstrate it across multiple modalities (text sentiment, small-image benchmarks, real-image Office dataset, descriptor learning for re-identification); approach is broadly applicable to other domain-shift problems where unlabeled target data are available.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>combination of theoretical principles (H-divergence/domain adaptation theory) and explicit procedural/technical steps (GRL implementation, SGD updates, λ scheduling)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain-Adversarial Training of Neural Networks', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e572.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e572.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>mSDA → DANN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Marginalized Stacked Denoising Autoencoder representations combined with Domain-Adversarial Training</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid transfer where unsupervised mSDA representation learning is used to produce high-dimensional robust features, and the DANN domain-adversarial training is applied on top of those representations to further reduce domain discrepancy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>mSDA representations combined with domain-adversarial training</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>First compute marginalized stacked denoising autoencoder (mSDA) features from unlabeled source+target (concatenate several layers' outputs plus original input to form a high-dimensional feature vector), then train a DANN on these mSDA features: label predictor trained on labeled source mSDA features; domain classifier trained on both source and target mSDA features through a GRL; optimization via SGD with adapted learning rates.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / representational preprocessing combined with training procedure</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>unsupervised representation learning / denoising autoencoders (machine learning)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>unsupervised domain adaptation (machine learning applications such as sentiment analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>hybrid approach combining with existing methods</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Used concatenation of outputs from 5 mSDA layers plus original input to form 30,000-d representations; adjusted DANN hyperparameters for high-dimensional input (lower learning rate µ = 1e-4); applied DANN on top of these representations rather than raw inputs; used reverse validation to select hyperparameters unsupervisedly.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful / complementary - combining mSDA and DANN improved performance on Amazon reviews tasks relative to NN and SVM on the same mSDA features: Poisson-binomial test probabilities indicate DANN significantly better than NN (0.92) and SVM (0.88) when using mSDA features. Additionally, applying DANN on mSDA reduced PAD substantially compared to mSDA alone (Figure 3c), explaining the performance gains.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>mSDA alone sometimes increased PAD (i.e., made domains more separable) despite improving adaptation accuracy in prior work, indicating conflicting objectives; high dimensionality (30k) required careful learning-rate setting and more computation.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>complementary objectives (mSDA for robust features, DANN for domain invariance); availability of large unlabeled sets to train mSDA; ability to apply DANN on arbitrary input representations.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>unlabeled data from both domains to train mSDA; computational resources for high-dimensional representations; hyperparameter selection method (reverse validation) when no labeled target data exist.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>likely generalizable to other learned representations (any precomputed feature embedding) where domain discrepancy remains; authors suggest DANN can operate on top of arbitrary features so the combination pattern is broadly applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (how to build representations and apply DANN), and instrumental/technical know-how (hyperparameters, learning-rate adjustments)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain-Adversarial Training of Neural Networks', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e572.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e572.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DANN for descriptor learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain-adversarial descriptor learning for person re-identification (Siamese-like loss)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptation of domain-adversarial training where the task loss is a descriptor/similarity (Siamese-like) loss instead of a classification loss, used to produce descriptors that are invariant across datasets for person re-identification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Domain-adversarial descriptor learning (Siamese-loss + GRL)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Replace the label-prediction branch of DANN with a descriptor-learning objective (Siamese-like verification loss) so the network learns embeddings useful for re-identification; concurrently train a domain-classifier branch (with GRL) that attempts to discriminate dataset origin, so the learned descriptors are made domain-invariant by adversarial training.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / task adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>metric / descriptor learning (computer vision: person re-identification research)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>cross-dataset person re-identification under domain shift</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Swapped classification loss for a Siamese-like loss in the task branch; retained the domain-classifier+GRL structure to adversarially remove dataset-specific cues from learned descriptors; trained using same saddle-point/SGD procedure.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - authors report that domain-adversarial learning 'considerably improve[s] cross-data-set re-identification'. (Exact quantitative results are presented elsewhere in the paper; the text indicates clear improvements over non-adapted descriptors.)</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>no explicit new barriers listed in the excerpt; general challenges include need for suitable pair/triplet labeling in the source dataset and potential sensitivity to loss formulation and sampling strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>flexibility of DANN framework to accept arbitrary task losses; presence of labeled source pairs/triplets and unlabeled target images; architectural compatibility with descriptor learning networks.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>labeled source pairs/triplets for descriptor loss, unlabeled target images for adversarial regularization, computational resources for training embedding networks.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>likely generalizable to other embedding/metric-learning tasks suffering domain shift (e.g., face recognition, fine-grained retrieval) because method only requires replacing the task loss while keeping adversarial domain regularizer.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (loss replacement, GRL integration) and instrumental/technical skills (training embeddings with adversarial regularizer)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain-Adversarial Training of Neural Networks', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e572.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e572.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN + GRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Augmenting convolutional neural networks with Gradient Reversal Layer for unsupervised domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The procedure of attaching a domain-classifier branch with a GRL to existing convolutional neural networks (pre-trained or trained from scratch) to obtain domain-invariant deep visual features for cross-domain image tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Augmented CNNs with domain-classifier + GRL</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Take a convolutional feature extractor (e.g., LeNet-like, SVHN architecture, AlexNet), attach a multi-layer domain-classifier that receives features through a GRL, and jointly train the network so the feature extractor minimizes the label loss on labeled source data and maximizes domain loss through GRL; use specific domain-classifier architectures (e.g., x→1024→1024→2) and schedules for λ and learning rate appropriate for deep nets.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / architectural adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>standard supervised convolutional network training for image recognition (computer vision)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>unsupervised domain adaptation for image classification and object recognition across datasets</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Added a domain-classifier branch (three fully connected layers) attached at a chosen bottleneck (e.g., fc7), inserted GRL between feature extractor and domain classifier, used learning-rate annealing schedule (μ_p = μ0/(1+αp)^β) and λ schedule (λ_p = 2/(1+exp(-γ p)) - 1) to stabilize training, used dropout/ℓ2 constraints and adjusted domain-classifier size depending on dataset (simpler for MNIST).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - experiments reported improved adaptation performance on MNIST, SVHN, GTSRB, and Office datasets compared to source-only and some prior domain-adaptation baselines (authors report considerable improvements, retrain last layer with SVM for fair comparison; exact numeric results across datasets are reported in paper sections beyond this excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>computational cost for deep CNNs and hyperparameter tuning; potential sensitivity to choice of attachment point and domain-classifier architecture; need for careful scheduling of λ and learning rates to avoid noisy adversarial signals early in training.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>availability of pre-trained CNNs (e.g., AlexNet) and deep-learning frameworks (Caffe); compatibility of GRL with standard backpropagation allowing easy integration; use of established regularization (dropout, ℓ2) and momentum provides stable optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>labeled source images and unlabeled target images; sufficient compute (GPUs); implementation of GRL in chosen DL framework; selection of appropriate bottleneck layer to attach domain-classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>the authors claim the augmentation is generic and can be applied to 'almost any feed-forward model' trained by backprop, so it is broadly applicable to other visual architectures and tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical know-how (architecture augmentation, hyperparameter schedules) and explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Domain-Adversarial Training of Neural Networks', 'publication_date_yy_mm': '2015-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative Adversarial Nets <em>(Rating: 2)</em></li>
                <li>Marginalized Stacked Denoising Autoencoders for Domain Adaptation <em>(Rating: 2)</em></li>
                <li>Unsupervised Visual Domain Adaptation using Subspace Alignment <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-572",
    "paper_id": "paper-1d5972b32a9b5a455a6eef389de5b7fca25771ad",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "DANN / GRL",
            "name_full": "Domain-Adversarial Neural Network with Gradient Reversal Layer",
            "brief_description": "A training procedure that enforces domain-invariant feature learning by adversarially training a feature extractor to fool a domain classifier; implemented via a gradient reversal layer that multiplies backpropagated gradients by a negative scalar.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Domain-adversarial training (Gradient Reversal Layer)",
            "procedure_description": "Joint training of (i) a feature extractor, (ii) a task label predictor, and (iii) a domain classifier so that the feature extractor minimizes task loss while maximizing domain-classifier loss; implemented by inserting a gradient reversal layer (GRL) between the feature extractor and the domain classifier which acts as identity in forward pass but multiplies gradients by -1 during backpropagation, thereby converting a minimization w.r.t. feature parameters into a saddle-point optimization that produces features indistinguishable across source and target domains.",
            "procedure_type": "computational method / training procedure",
            "source_domain": "adversarial training techniques from generative/discriminative modeling (machine learning)",
            "target_domain": "unsupervised domain adaptation / representation learning for cross-domain classification (machine learning applications: NLP, vision, descriptor learning)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Recast adversarial idea from generative modeling to domain-discrimination: (1) replaced generator/discriminator game with feature-extractor vs domain-classifier game; (2) introduced a parameter-free gradient reversal layer that negates gradients from domain loss to feature parameters so standard SGD finds the saddle point; (3) used a weighted domain loss (hyperparameter λ) with a schedule for gradually increasing domain-adversarial strength; (4) integrated into arbitrary feed-forward architectures (shallow MLPs, convolutional nets, pre-trained networks) and trained with standard backprop/SGD.",
            "transfer_success": "successful - demonstrated consistent empirical improvements: on the Amazon reviews sentiment tasks DANN outperformed a same-architecture NN and linear SVM (Table 1), with pairwise Poisson-binomial test probabilities showing DANN significantly better than NN (0.87) and SVM (0.83); when combined with mSDA representations the probabilities increase (0.92 vs NN, 0.88 vs SVM). DANN also reduced Proxy A-distance (PAD) between source and target feature distributions (Figure 3) and produced state-of-the-art-like improvements on multiple image-domain adaptation benchmarks (MNIST, SVHN, Office) and improved cross-dataset person re-identification (quantitative improvements reported in paper sections beyond this excerpt).",
            "barriers_encountered": "training instability and early-stage issues when domain signals are strong (e.g., saturating sigmoids), need to tune/adapt λ schedule to prevent noisy adversarial signal early in training; computational cost for deep architectures; requirement for sufficient unlabeled target data.",
            "facilitating_factors": "clear theoretical grounding in H-divergence/domain-adaptation theory; compatibility with existing backprop/SGD frameworks; only a small architectural change (GRL) required; availability of pre-trained networks and deep-learning toolkits (authors released GRL implementation for Caffe).",
            "contextual_requirements": "requires labeled source data and unlabeled target data; implement GRL in training framework; choose/anneal λ schedule and learning-rate schedule; sufficient compute (GPUs) for deep models; for theoretical guarantees, domain-classifier hypothesis class should subsume label-classifier class ideally.",
            "generalizability": "high within machine-learning contexts: authors claim DANN (via GRL) can be applied to almost any feed-forward neural architecture and demonstrate it across multiple modalities (text sentiment, small-image benchmarks, real-image Office dataset, descriptor learning for re-identification); approach is broadly applicable to other domain-shift problems where unlabeled target data are available.",
            "knowledge_type": "combination of theoretical principles (H-divergence/domain adaptation theory) and explicit procedural/technical steps (GRL implementation, SGD updates, λ scheduling)",
            "uuid": "e572.0",
            "source_info": {
                "paper_title": "Domain-Adversarial Training of Neural Networks",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "mSDA → DANN",
            "name_full": "Marginalized Stacked Denoising Autoencoder representations combined with Domain-Adversarial Training",
            "brief_description": "A hybrid transfer where unsupervised mSDA representation learning is used to produce high-dimensional robust features, and the DANN domain-adversarial training is applied on top of those representations to further reduce domain discrepancy.",
            "citation_title": "",
            "mention_or_use": "use",
            "procedure_name": "mSDA representations combined with domain-adversarial training",
            "procedure_description": "First compute marginalized stacked denoising autoencoder (mSDA) features from unlabeled source+target (concatenate several layers' outputs plus original input to form a high-dimensional feature vector), then train a DANN on these mSDA features: label predictor trained on labeled source mSDA features; domain classifier trained on both source and target mSDA features through a GRL; optimization via SGD with adapted learning rates.",
            "procedure_type": "computational method / representational preprocessing combined with training procedure",
            "source_domain": "unsupervised representation learning / denoising autoencoders (machine learning)",
            "target_domain": "unsupervised domain adaptation (machine learning applications such as sentiment analysis)",
            "transfer_type": "hybrid approach combining with existing methods",
            "modifications_made": "Used concatenation of outputs from 5 mSDA layers plus original input to form 30,000-d representations; adjusted DANN hyperparameters for high-dimensional input (lower learning rate µ = 1e-4); applied DANN on top of these representations rather than raw inputs; used reverse validation to select hyperparameters unsupervisedly.",
            "transfer_success": "successful / complementary - combining mSDA and DANN improved performance on Amazon reviews tasks relative to NN and SVM on the same mSDA features: Poisson-binomial test probabilities indicate DANN significantly better than NN (0.92) and SVM (0.88) when using mSDA features. Additionally, applying DANN on mSDA reduced PAD substantially compared to mSDA alone (Figure 3c), explaining the performance gains.",
            "barriers_encountered": "mSDA alone sometimes increased PAD (i.e., made domains more separable) despite improving adaptation accuracy in prior work, indicating conflicting objectives; high dimensionality (30k) required careful learning-rate setting and more computation.",
            "facilitating_factors": "complementary objectives (mSDA for robust features, DANN for domain invariance); availability of large unlabeled sets to train mSDA; ability to apply DANN on arbitrary input representations.",
            "contextual_requirements": "unlabeled data from both domains to train mSDA; computational resources for high-dimensional representations; hyperparameter selection method (reverse validation) when no labeled target data exist.",
            "generalizability": "likely generalizable to other learned representations (any precomputed feature embedding) where domain discrepancy remains; authors suggest DANN can operate on top of arbitrary features so the combination pattern is broadly applicable.",
            "knowledge_type": "explicit procedural steps (how to build representations and apply DANN), and instrumental/technical know-how (hyperparameters, learning-rate adjustments)",
            "uuid": "e572.1",
            "source_info": {
                "paper_title": "Domain-Adversarial Training of Neural Networks",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "DANN for descriptor learning",
            "name_full": "Domain-adversarial descriptor learning for person re-identification (Siamese-like loss)",
            "brief_description": "An adaptation of domain-adversarial training where the task loss is a descriptor/similarity (Siamese-like) loss instead of a classification loss, used to produce descriptors that are invariant across datasets for person re-identification.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Domain-adversarial descriptor learning (Siamese-loss + GRL)",
            "procedure_description": "Replace the label-prediction branch of DANN with a descriptor-learning objective (Siamese-like verification loss) so the network learns embeddings useful for re-identification; concurrently train a domain-classifier branch (with GRL) that attempts to discriminate dataset origin, so the learned descriptors are made domain-invariant by adversarial training.",
            "procedure_type": "computational method / task adaptation",
            "source_domain": "metric / descriptor learning (computer vision: person re-identification research)",
            "target_domain": "cross-dataset person re-identification under domain shift",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Swapped classification loss for a Siamese-like loss in the task branch; retained the domain-classifier+GRL structure to adversarially remove dataset-specific cues from learned descriptors; trained using same saddle-point/SGD procedure.",
            "transfer_success": "successful - authors report that domain-adversarial learning 'considerably improve[s] cross-data-set re-identification'. (Exact quantitative results are presented elsewhere in the paper; the text indicates clear improvements over non-adapted descriptors.)",
            "barriers_encountered": "no explicit new barriers listed in the excerpt; general challenges include need for suitable pair/triplet labeling in the source dataset and potential sensitivity to loss formulation and sampling strategies.",
            "facilitating_factors": "flexibility of DANN framework to accept arbitrary task losses; presence of labeled source pairs/triplets and unlabeled target images; architectural compatibility with descriptor learning networks.",
            "contextual_requirements": "labeled source pairs/triplets for descriptor loss, unlabeled target images for adversarial regularization, computational resources for training embedding networks.",
            "generalizability": "likely generalizable to other embedding/metric-learning tasks suffering domain shift (e.g., face recognition, fine-grained retrieval) because method only requires replacing the task loss while keeping adversarial domain regularizer.",
            "knowledge_type": "explicit procedural steps (loss replacement, GRL integration) and instrumental/technical skills (training embeddings with adversarial regularizer)",
            "uuid": "e572.2",
            "source_info": {
                "paper_title": "Domain-Adversarial Training of Neural Networks",
                "publication_date_yy_mm": "2015-05"
            }
        },
        {
            "name_short": "CNN + GRL",
            "name_full": "Augmenting convolutional neural networks with Gradient Reversal Layer for unsupervised domain adaptation",
            "brief_description": "The procedure of attaching a domain-classifier branch with a GRL to existing convolutional neural networks (pre-trained or trained from scratch) to obtain domain-invariant deep visual features for cross-domain image tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Augmented CNNs with domain-classifier + GRL",
            "procedure_description": "Take a convolutional feature extractor (e.g., LeNet-like, SVHN architecture, AlexNet), attach a multi-layer domain-classifier that receives features through a GRL, and jointly train the network so the feature extractor minimizes the label loss on labeled source data and maximizes domain loss through GRL; use specific domain-classifier architectures (e.g., x→1024→1024→2) and schedules for λ and learning rate appropriate for deep nets.",
            "procedure_type": "computational method / architectural adaptation",
            "source_domain": "standard supervised convolutional network training for image recognition (computer vision)",
            "target_domain": "unsupervised domain adaptation for image classification and object recognition across datasets",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Added a domain-classifier branch (three fully connected layers) attached at a chosen bottleneck (e.g., fc7), inserted GRL between feature extractor and domain classifier, used learning-rate annealing schedule (μ_p = μ0/(1+αp)^β) and λ schedule (λ_p = 2/(1+exp(-γ p)) - 1) to stabilize training, used dropout/ℓ2 constraints and adjusted domain-classifier size depending on dataset (simpler for MNIST).",
            "transfer_success": "successful - experiments reported improved adaptation performance on MNIST, SVHN, GTSRB, and Office datasets compared to source-only and some prior domain-adaptation baselines (authors report considerable improvements, retrain last layer with SVM for fair comparison; exact numeric results across datasets are reported in paper sections beyond this excerpt).",
            "barriers_encountered": "computational cost for deep CNNs and hyperparameter tuning; potential sensitivity to choice of attachment point and domain-classifier architecture; need for careful scheduling of λ and learning rates to avoid noisy adversarial signals early in training.",
            "facilitating_factors": "availability of pre-trained CNNs (e.g., AlexNet) and deep-learning frameworks (Caffe); compatibility of GRL with standard backpropagation allowing easy integration; use of established regularization (dropout, ℓ2) and momentum provides stable optimization.",
            "contextual_requirements": "labeled source images and unlabeled target images; sufficient compute (GPUs); implementation of GRL in chosen DL framework; selection of appropriate bottleneck layer to attach domain-classifier.",
            "generalizability": "the authors claim the augmentation is generic and can be applied to 'almost any feed-forward model' trained by backprop, so it is broadly applicable to other visual architectures and tasks.",
            "knowledge_type": "instrumental/technical know-how (architecture augmentation, hyperparameter schedules) and explicit procedural steps",
            "uuid": "e572.3",
            "source_info": {
                "paper_title": "Domain-Adversarial Training of Neural Networks",
                "publication_date_yy_mm": "2015-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative Adversarial Nets",
            "rating": 2
        },
        {
            "paper_title": "Marginalized Stacked Denoising Autoencoders for Domain Adaptation",
            "rating": 2
        },
        {
            "paper_title": "Unsupervised Visual Domain Adaptation using Subspace Alignment",
            "rating": 2
        }
    ],
    "cost": 0.0176295,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Domain-Adversarial Training of Neural Networks</h1>
<p>Yaroslav Ganin<br>Evgeniya Ustinova<br>Skolkovo Institute of Science and Technology (Skoltech)<br>Skolkovo, Moscow Region, Russia<br>Hana Ajakan<br>PAScal Germain<br>Département d'informatique et de génie logiciel, Université Laval<br>Québec, Canada, G1V 0A6<br>Hugo Larochelle<br>Département d'informatique, Université de Sherbrooke<br>Québec, Canada, J1K 2R1<br>François Laviolette<br>Mario Marchand<br>Département d'informatique et de génie logiciel, Université Laval<br>Québec, Canada, G1V 0A6<br>Victor Lempitsky<br>Skolkovo Institute of Science and Technology (Skoltech)<br>Skolkovo, Moscow Region, Russia</p>
<p>GANIN@SKOLTECH.RU
EVGENIYA.USTINOVA@SKOLTECH.RU</p>
<h2>Hana.AJAKAN.1@ULAVAL.CA</h2>
<p>PAScal.Germain@ift.ulaval.ca</p>
<p>HUGO.LAROCHELLE@USHERBROOKE.CA</p>
<p>FRANCOIS.LAVOLEtTE@IFT.ULAVAL.CA
Mario.MARCHAND@IFT.ULAVAL.CA</p>
<p>Editor: Urun Dogan, Marius Kloft, Francesco Orabona, and Tatiana Tommasi</p>
<h4>Abstract</h4>
<p>We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains.</p>
<p>The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages.</p>
<p>We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.</p>
<p>Keywords: domain adaptation, neural network, representation learning, deep learning, synthetic data, image classification, sentiment analysis, person re-identification</p>
<h1>1. Introduction</h1>
<p>The cost of generating labeled data for a new machine learning task is often an obstacle for applying machine learning methods. In particular, this is a limiting factor for the further progress of deep neural network architectures, that have already brought impressive advances to the state-of-the-art across a wide variety of machine-learning tasks and applications. For problems lacking labeled data, it may be still possible to obtain training sets that are big enough for training large-scale deep models, but that suffer from the shift in data distribution from the actual data encountered at "test time". One important example is training an image classifier on synthetic or semi-synthetic images, which may come in abundance and be fully labeled, but which inevitably have a distribution that is different from real images (Liebelt and Schmid, 2010; Stark et al., 2010; Vázquez et al., 2014; Sun and Saenko, 2014). Another example is in the context of sentiment analysis in written reviews, where one might have labeled data for reviews of one type of product (e.g., movies), while having the need to classify reviews of other products (e.g., books).</p>
<p>Learning a discriminative classifier or other predictor in the presence of a shift between training and test distributions is known as domain adaptation (DA). The proposed approaches build mappings between the source (training-time) and the target (test-time) domains, so that the classifier learned for the source domain can also be applied to the target domain, when composed with the learned mapping between domains. The appeal of the domain adaptation approaches is the ability to learn a mapping between domains in the situation when the target domain data are either fully unlabeled (unsupervised domain annotation) or have few labeled samples (semi-supervised domain adaptation). Below, we focus on the harder unsupervised case, although the proposed approach (domain-adversarial learning) can be generalized to the semi-supervised case rather straightforwardly.</p>
<p>Unlike many previous papers on domain adaptation that worked with fixed feature representations, we focus on combining domain adaptation and deep feature learning within one training process. Our goal is to embed domain adaptation into the process of learning representation, so that the final classification decisions are made based on features that are both discriminative and invariant to the change of domains, i.e., have the same or very similar distributions in the source and the target domains. In this way, the obtained feed-forward network can be applicable to the target domain without being hindered by the shift between the two domains. Our approach is motivated by the theory on domain adaptation (Ben-David et al., 2006, 2010), that suggests that a good representation for cross-domain transfer is one for which an algorithm cannot learn to identify the domain of origin of the input observation.</p>
<p>We thus focus on learning features that combine (i) discriminativeness and (ii) domaininvariance. This is achieved by jointly optimizing the underlying features as well as two discriminative classifiers operating on these features: (i) the label predictor that predicts class labels and is used both during training and at test time and (ii) the domain classifier that discriminates between the source and the target domains during training. While the parameters of the classifiers are optimized in order to minimize their error on the training set, the parameters of the underlying deep feature mapping are optimized in order to minimize the loss of the label classifier and to maximize the loss of the domain classifier. The latter</p>
<p>update thus works adversarially to the domain classifier, and it encourages domain-invariant features to emerge in the course of the optimization.</p>
<p>Crucially, we show that all three training processes can be embedded into an appropriately composed deep feed-forward network, called domain-adversarial neural network (DANN) (illustrated by Figure 1, page 12) that uses standard layers and loss functions, and can be trained using standard backpropagation algorithms based on stochastic gradient descent or its modifications (e.g., SGD with momentum). The approach is generic as a DANN version can be created for almost any existing feed-forward architecture that is trainable by backpropagation. In practice, the only non-standard component of the proposed architecture is a rather trivial gradient reversal layer that leaves the input unchanged during forward propagation and reverses the gradient by multiplying it by a negative scalar during the backpropagation.</p>
<p>We provide an experimental evaluation of the proposed domain-adversarial learning idea over a range of deep architectures and applications. We first consider the simplest DANN architecture where the three parts (label predictor, domain classifier and feature extractor) are linear, and demonstrate the success of domain-adversarial learning for such architecture. The evaluation is performed for synthetic data as well as for the sentiment analysis problem in natural language processing, where DANN improves the state-of-the-art marginalized Stacked Autoencoders (mSDA) of Chen et al. (2012) on the common Amazon reviews benchmark.</p>
<p>We further evaluate the approach extensively for an image classification task, and present results on traditional deep learning image data sets - such as MNIST (LeCun et al., 1998) and SVHN (Netzer et al., 2011)—as well as on Office benchmarks (Saenko et al., 2010), where domain-adversarial learning allows obtaining a deep architecture that considerably improves over previous state-of-the-art accuracy.</p>
<p>Finally, we evaluate domain-adversarial descriptor learning in the context of person re-identification application (Gong et al., 2014), where the task is to obtain good pedestrian image descriptors that are suitable for retrieval and verification. We apply domainadversarial learning, as we consider a descriptor predictor trained with a Siamese-like loss instead of the label predictor trained with a classification loss. In a series of experiments, we demonstrate that domain-adversarial learning can improve cross-data-set re-identification considerably.</p>
<h1>2. Related work</h1>
<p>The general approach of achieving domain adaptation explored under many facets. Over the years, a large part of the literature has focused mainly on linear hypothesis (see for instance Blitzer et al., 2006; Bruzzone and Marconcini, 2010; Germain et al., 2013; Baktashmotlagh et al., 2013; Cortes and Mohri, 2014). More recently, non-linear representations have become increasingly studied, including neural network representations (Glorot et al., 2011; Li et al., 2014) and most notably the state-of-the-art mSDA (Chen et al., 2012). That literature has mostly focused on exploiting the principle of robust representations, based on the denoising autoencoder paradigm (Vincent et al., 2008).</p>
<p>Concurrently, multiple methods of matching the feature distributions in the source and the target domains have been proposed for unsupervised domain adaptation. Some ap-</p>
<p>proaches perform this by reweighing or selecting samples from the source domain (Borgwardt et al., 2006; Huang et al., 2006; Gong et al., 2013), while others seek an explicit feature space transformation that would map source distribution into the target one (Pan et al., 2011; Gopalan et al., 2011; Baktashmotlagh et al., 2013). An important aspect of the distribution matching approach is the way the (dis)similarity between distributions is measured. Here, one popular choice is matching the distribution means in the kernelreproducing Hilbert space (Borgwardt et al., 2006; Huang et al., 2006), whereas Gong et al. (2012) and Fernando et al. (2013) map the principal axes associated with each of the distributions.</p>
<p>Our approach also attempts to match feature space distributions, however this is accomplished by modifying the feature representation itself rather than by reweighing or geometric transformation. Also, our method uses a rather different way to measure the disparity between distributions based on their separability by a deep discriminatively-trained classifier. Note also that several approaches perform transition from the source to the target domain (Gopalan et al., 2011; Gong et al., 2012) by changing gradually the training distribution. Among these methods, Chopra et al. (2013) does this in a "deep" way by the layerwise training of a sequence of deep autoencoders, while gradually replacing source-domain samples with target-domain samples. This improves over a similar approach of Glorot et al. (2011) that simply trains a single deep autoencoder for both domains. In both approaches, the actual classifier/predictor is learned in a separate step using the feature representation learned by autoencoder(s). In contrast to Glorot et al. (2011); Chopra et al. (2013), our approach performs feature learning, domain adaptation and classifier learning jointly, in a unified architecture, and using a single learning algorithm (backpropagation). We therefore argue that our approach is simpler (both conceptually and in terms of its implementation). Our method also achieves considerably better results on the popular OFFICE benchmark.</p>
<p>While the above approaches perform unsupervised domain adaptation, there are approaches that perform supervised domain adaptation by exploiting labeled data from the target domain. In the context of deep feed-forward architectures, such data can be used to "fine-tune" the network trained on the source domain (Zeiler and Fergus, 2013; Oquab et al., 2014; Babenko et al., 2014). Our approach does not require labeled target-domain data. At the same time, it can easily incorporate such data when they are available.</p>
<p>An idea related to ours is described in Goodfellow et al. (2014). While their goal is quite different (building generative deep networks that can synthesize samples), the way they measure and minimize the discrepancy between the distribution of the training data and the distribution of the synthesized data is very similar to the way our architecture measures and minimizes the discrepancy between feature distributions for the two domains. Moreover, the authors mention the problem of saturating sigmoids which may arise at the early stages of training due to the significant dissimilarity of the domains. The technique they use to circumvent this issue (the "adversarial" part of the gradient is replaced by a gradient computed with respect to a suitable cost) is directly applicable to our method.</p>
<p>Also, recent and concurrent reports by Tzeng et al. (2014); Long and Wang (2015) focus on domain adaptation in feed-forward networks. Their set of techniques measures and minimizes the distance between the data distribution means across domains (potentially, after embedding distributions into RKHS). Their approach is thus different from our idea of matching distributions by making them indistinguishable for a discriminative classifier.</p>
<p>Below, we compare our approach to Tzeng et al. (2014); Long and Wang (2015) on the Office benchmark. Another approach to deep domain adaptation, which is arguably more different from ours, has been developed in parallel by Chen et al. (2015).</p>
<p>From a theoretical standpoint, our approach is directly derived from the seminal theoretical works of Ben-David et al. $(2006,2010)$. Indeed, DANN directly optimizes the notion of $\mathcal{H}$-divergence. We do note the work of Huang and Yates (2012), in which HMM representations are learned for word tagging using a posterior regularizer that is also inspired by Ben-David et al.'s work. In addition to the tasks being different-Huang and Yates (2012) focus on word tagging problems-, we would argue that DANN learning objective more closely optimizes the $\mathcal{H}$-divergence, with Huang and Yates (2012) relying on cruder approximations for efficiency reasons.</p>
<p>A part of this paper has been published as a conference paper (Ganin and Lempitsky, 2015). This version extends Ganin and Lempitsky (2015) very considerably by incorporating the report Ajakan et al. (2014) (presented as part of the Second Workshop on Transfer and Multi-Task Learning), which brings in new terminology, in-depth theoretical analysis and justification of the approach, extensive experiments with the shallow DANN case on synthetic data as well as on a natural language processing task (sentiment analysis). Furthermore, in this version we go beyond classification and evaluate domain-adversarial learning for descriptor learning setting within the person re-identification application.</p>
<h1>3. Domain Adaptation</h1>
<p>We consider classification tasks where $X$ is the input space and $Y={0,1, \ldots, L-1}$ is the set of $L$ possible labels. Moreover, we have two different distributions over $X \times Y$, called the source domain $\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}$ and the target domain $\mathcal{D}</em>}}$. An unsupervised domain adaptation learning algorithm is then provided with a labeled source sample $S$ drawn i.i.d. from $\mathcal{D<em _mathrm_T="\mathrm{T">{\mathrm{S}}$, and an unlabeled target sample $T$ drawn i.i.d. from $\mathcal{D}</em>}}^{ \pm}$, where $\mathcal{D<em _mathrm_T="\mathrm{T">{\mathrm{T}}^{ \pm}$is the marginal distribution of $\mathcal{D}</em>$ over $X$.}</p>
<p>$$
S=\left{\left(\mathbf{x}<em i="i">{i}, y</em>\right)\right}<em _mathrm_S="\mathrm{S">{i=1}^{n} \sim\left(\mathcal{D}</em>}}\right)^{n} ; \quad T=\left{\mathbf{x<em i="n+1">{i}\right}</em>
$$}^{N} \sim\left(\mathcal{D}_{\mathrm{T}}^{ \pm}\right)^{n^{\prime}</p>
<p>with $N=n+n^{\prime}$ being the total number of samples. The goal of the learning algorithm is to build a classifier $\eta: X \rightarrow Y$ with a low target risk</p>
<p>$$
R_{\mathcal{D}<em _mathbf_x="(\mathbf{x">{\mathrm{T}}}(\eta)=\operatorname{Pr}</em>) \neq y)
$$}, y) \sim \mathcal{D}_{\mathrm{T}}}(\eta(\mathbf{x</p>
<p>while having no information about the labels of $\mathcal{D}_{\mathrm{T}}$.</p>
<h3>3.1 Domain Divergence</h3>
<p>To tackle the challenging domain adaptation task, many approaches bound the target error by the sum of the source error and a notion of distance between the source and the target distributions. These methods are intuitively justified by a simple assumption: the source risk is expected to be a good indicator of the target risk when both distributions are similar. Several notions of distance have been proposed for domain adaptation (Ben-David et al., 2006, 2010; Mansour et al., 2009a,b; Germain et al., 2013). In this paper, we focus on the $\mathcal{H}$-divergence used by Ben-David et al. $(2006,2010)$, and based on the earlier work of Kifer</p>
<p>et al. (2004). Note that we assume in definition 1 below that the hypothesis class $\mathcal{H}$ is a (discrete or continuous) set of binary classifiers $\eta: X \rightarrow{0,1}$.</p>
<p>Definition 1 (Ben-David et al., 2006, 2010; Kifer et al., 2004) Given two domain distributions $\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}$ and $\mathcal{D}</em>}}^{X}$ over $X$, and a hypothesis class $\mathcal{H}$, the $\mathcal{H}$-divergence between $\mathcal{D<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}$ and $\mathcal{D}</em>$ is}}^{X</p>
<p>$$
d_{\mathcal{H}}\left(\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}, \mathcal{D}</em>\right)=\left.2 \sup }}^{X<em _mathbf_x="\mathbf{x">{\eta \in \mathcal{H}} \mid \operatorname{Pr}</em>} \sim \mathcal{D<em _mathbf_x="\mathbf{x">{\mathrm{S}}^{X}}[\eta(\mathbf{x})=1]-\operatorname{Pr}</em>)=1]\right|
$$} \sim \mathcal{D}_{\mathrm{T}}^{X}}[\eta(\mathbf{x</p>
<p>That is, the $\mathcal{H}$-divergence relies on the capacity of the hypothesis class $\mathcal{H}$ to distinguish between examples generated by $\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}$ from examples generated by $\mathcal{D}</em>}}^{X}$. Ben-David et al. $(2006,2010)$ proved that, for a symmetric hypothesis class $\mathcal{H}$, one can compute the empirical $\mathcal{H}$-divergence between two samples $S \sim\left(\mathcal{D<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{S}\right)^{n}$ and $T \sim\left(\mathcal{D}</em>$ by computing}}^{S}\right)^{n^{\prime}</p>
<p>$$
\hat{d}<em _eta="\eta" _in="\in" _mathcal_H="\mathcal{H">{\mathcal{H}}(S, T)=2\left(1-\min </em>}}\left[\frac{1}{n} \sum_{i=1}^{n} I\left[\eta\left(\mathbf{x<em i="n+1">{i}\right)=0\right]+\frac{1}{n^{\prime}} \sum</em>\right)=1\right]\right]\right)
$$}^{N} I\left[\eta\left(\mathbf{x}_{i</p>
<p>where $I[a]$ is the indicator function which is 1 if predicate $a$ is true, and 0 otherwise.</p>
<h1>3.2 Proxy Distance</h1>
<p>Ben-David et al. (2006) suggested that, even if it is generally hard to compute $\hat{d}_{\mathcal{H}}(S, T)$ exactly (e.g., when $\mathcal{H}$ is the space of linear classifiers on $X$ ), we can easily approximate it by running a learning algorithm on the problem of discriminating between source and target examples. To do so, we construct a new data set</p>
<p>$$
U=\left{\left(\mathbf{x}<em i="1">{i}, 0\right)\right}</em>}^{n} \cup\left{\left(\mathbf{x<em i="n+1">{i}, 1\right)\right}</em>
$$}^{N</p>
<p>where the examples of the source sample are labeled 0 and the examples of the target sample are labeled 1. Then, the risk of the classifier trained on the new data set $U$ approximates the "min" part of Equation (1). Given a generalization error $\epsilon$ on the problem of discriminating between source and target examples, the $\mathcal{H}$-divergence is then approximated by</p>
<p>$$
\hat{d}_{\mathcal{A}}=2(1-2 \epsilon)
$$</p>
<p>In Ben-David et al. (2006), the value $\hat{d}<em _mathcal_A="\mathcal{A">{\mathcal{A}}$ is called the Proxy $\mathcal{A}$-distance (PAD). The $\mathcal{A}$ distance being defined as $d</em>}}\left(\mathcal{D<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}, \mathcal{D}</em>\right)=2 \sup }}^{X<em _mathcal_D="\mathcal{D">{A \in \mathcal{A}}\left|\operatorname{Pr}</em><em _mathcal_D="\mathcal{D">{\mathrm{S}}^{X}}(A)-\operatorname{Pr}</em><em _eta="\eta">{\mathrm{T}}^{X}}(A)\right|$, where $\mathcal{A}$ is a subset of $X$. Note that, by choosing $\mathcal{A}=\left{A</em>$-divergence of Definition 1 are identical.} \mid \eta \in \mathcal{H}\right}$, with $A_{\eta}$ the set represented by the characteristic function $\eta$, the $\mathcal{A}$-distance and the $\mathcal{H</p>
<p>In the experiments section of this paper, we compute the PAD value following the approach of Glorot et al. (2011); Chen et al. (2012), i.e., we train either a linear SVM or a deeper MLP classifier on a subset of $U$ (Equation 2), and we use the obtained classifier error on the other subset as the value of $\epsilon$ in Equation (3). More details and illustrations of the linear SVM case are provided in Section 5.1.5.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>3.3 Generalization Bound on the Target Risk</h1>
<p>The work of Ben-David et al. $(2006,2010)$ also showed that the $\mathcal{H}$-divergence $d_{\mathcal{H}}\left(\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{\mathrm{x}}, \mathcal{D}</em>$ and the size of samples $S$ and $T$. By combining this result with a similar bound on the source risk, the following theorem is obtained.}}^{\mathrm{x}}\right)$ is upper bounded by its empirical estimate $\hat{d}_{\mathcal{H}}(S, T)$ plus a constant complexity term that depends on the $V C$ dimension of $\mathcal{H</p>
<p>Theorem 2 (Ben-David et al., 2006) Let $\mathcal{H}$ be a hypothesis class of VC dimension d. With probability $1-\delta$ over the choice of samples $S \sim\left(\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}\right)^{n}$ and $T \sim\left(\mathcal{D}</em>$ :}}^{\mathrm{x}}\right)^{n}$, for every $\eta \in \mathcal{H</p>
<p>$$
R_{\mathcal{D}<em S="S">{\mathrm{T}}}(\eta) \leq R</em>+\beta
$$}(\eta)+\sqrt{\frac{4}{n}\left(d \log \frac{2 \mathrm{c} n}{d}+\log \frac{4}{\delta}\right)}+\hat{d}_{\mathcal{H}}(S, T)+4 \sqrt{\frac{1}{n}\left(d \log \frac{2 \eta}{d}+\log \frac{4}{\delta}\right)</p>
<p>with $\beta \geq \inf <em _mathcal_D="\mathcal{D">{\eta^{<em>} \in \mathcal{H}}\left[R_{\mathcal{D}_{\mathrm{S}}}\left(\eta^{</em>}\right)+R</em>\right)\right]$, and}_{\mathrm{T}}}\left(\eta^{*</p>
<p>$$
R_{S}(\eta)=\frac{1}{n} \sum_{i=1}^{m} I\left[\eta\left(\mathbf{x}<em i="i">{i}\right) \neq y</em>\right]
$$</p>
<p>is the empirical source risk.
The previous result tells us that $R_{\mathcal{D}<em _mathcal_D="\mathcal{D">{\mathrm{T}}}(\eta)$ can be low only when the $\beta$ term is low, i.e., only when there exists a classifier that can achieve a low risk on both distributions. It also tells us that, to find a classifier with a small $R</em><em S="S">{\mathrm{T}}}(\eta)$ in a given class of fixed VC dimension, the learning algorithm should minimize (in that class) a trade-off between the source risk $R</em>$-divergence is to find a representation of the examples where both the source and the target domain are as indistinguishable as possible. Under such a representation, a hypothesis with a low source risk will, according to Theorem 2, perform well on the target data. In this paper, we present an algorithm that directly exploits this idea.}(\eta)$ and the empirical $\mathcal{H}$-divergence $\hat{d}_{\mathcal{H}}(S, T)$. As pointed-out by Ben-David et al. (2006), a strategy to control the $\mathcal{H</p>
<h2>4. Domain-Adversarial Neural Networks (DANN)</h2>
<p>An original aspect of our approach is to explicitly implement the idea exhibited by Theorem 2 into a neural network classifier. That is, to learn a model that can generalize well from one domain to another, we ensure that the internal representation of the neural network contains no discriminative information about the origin of the input (source or target), while preserving a low risk on the source (labeled) examples.</p>
<p>In this section, we detail the proposed approach for incorporating a "domain adaptation component" to neural networks. In Subsection 4.1, we start by developing the idea for the simplest possible case, i.e., a single hidden layer, fully connected neural network. We then describe how to generalize the approach to arbitrary (deep) network architectures.</p>
<h3>4.1 Example Case with a Shallow Neural Network</h3>
<p>Let us first consider a standard neural network (NN) architecture with a single hidden layer. For simplicity, we suppose that the input space is formed by $m$-dimensional real</p>
<p>vectors. Thus, $X=\mathbb{R}^{m}$. The hidden layer $G_{f}$ learns a function $G_{f}: X \rightarrow \mathbb{R}^{D}$ that maps an example into a new $D$-dimensional representation ${ }^{2}$, and is parameterized by a matrix-vector pair $(\mathbf{W}, \mathbf{b}) \in \mathbb{R}^{D \times m} \times \mathbb{R}^{D}$ :</p>
<p>$$
G_{f}(\mathbf{x} ; \mathbf{W}, \mathbf{b})=\operatorname{sigm}(\mathbf{W} \mathbf{x}+\mathbf{b})
$$</p>
<p>with $\operatorname{sigm}(\mathbf{a})=\left[\frac{1}{1+\exp \left(-a_{i}\right)}\right]<em y="y">{i=1}^{|\mathbf{a}|}$.
Similarly, the prediction layer $G</em>$ :}$ learns a function $G_{y}: \mathbb{R}^{D} \rightarrow[0,1]^{L}$ that is parameterized by a pair $(\mathbf{V}, \mathbf{c}) \in \mathbb{R}^{L \times D} \times \mathbb{R}^{L</p>
<p>$$
G_{y}\left(G_{f}(\mathbf{x}) ; \mathbf{V}, \mathbf{c}\right)=\operatorname{softmax}\left(\mathbf{V} G_{f}(\mathbf{x})+\mathbf{c}\right)
$$</p>
<p>with $\operatorname{softmax}(\mathbf{a})=\left[\frac{\exp \left(a_{i}\right)}{\sum_{j=1}^{|\mathbf{a}|} \exp \left(a_{j}\right)}\right]<em y="y">{i=1}^{|\mathbf{a}|}$.
Here we have $L=|Y|$. By using the softmax function, each component of vector $G</em>}\left(G_{f}(\mathbf{x})\right)$ denotes the conditional probability that the neural network assigns $\mathbf{x}$ to the class in $Y$ represented by that component. Given a source example $\left(\mathbf{x<em i="i">{i}, y</em>\right)$, the natural classification loss to use is the negative log-probability of the correct label:</p>
<p>$$
\mathcal{L}<em y="y">{y}\left(G</em>}\left(G_{f}\left(\mathbf{x<em i="i">{i}\right)\right), y</em>)\right)}\right)=\log \frac{1}{G_{y}\left(G_{f}(\mathbf{x<em i="i">{y</em>
$$}}</p>
<p>Training the neural network then leads to the following optimization problem on the source domain:</p>
<p>$$
\min <em i="1">{\mathbf{W}, \mathbf{b}, \mathbf{V}, \mathbf{c}}\left[\frac{1}{n} \sum</em>)\right]
$$}^{n} \mathcal{L}_{y}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{V}, \mathbf{c})+\lambda \cdot R(\mathbf{W}, \mathbf{b</p>
<p>where $\mathcal{L}<em y="y">{y}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{V}, \mathbf{c})=\mathcal{L}</em>}\left(G_{y}\left(G_{f}\left(\mathbf{x<em i="i">{i} ; \mathbf{W}, \mathbf{b}\right) ; \mathbf{V}, \mathbf{c}\right), y</em>)$ is an optional regularizer that is weighted by hyper-parameter $\lambda$.}\right)$ is a shorthand notation for the prediction loss on the $i$-th example, and $R(\mathbf{W}, \mathbf{b</p>
<p>The heart of our approach is to design a domain regularizer directly derived from the $\mathcal{H}$-divergence of Definition 1. To this end, we view the output of the hidden layer $G_{f}(\cdot)$ (Equation 4) as the internal representation of the neural network. Thus, we denote the source sample representations as</p>
<p>$$
S\left(G_{f}\right)=\left{G_{f}(\mathbf{x}) \mid \mathbf{x} \in S\right}
$$</p>
<p>Similarly, given an unlabeled sample from the target domain we denote the corresponding representations</p>
<p>$$
T\left(G_{f}\right)=\left{G_{f}(\mathbf{x}) \mid \mathbf{x} \in T\right}
$$</p>
<p>Based on Equation (1), the empirical $\mathcal{H}$-divergence of a symmetric hypothesis class $\mathcal{H}$ between samples $S\left(G_{f}\right)$ and $T\left(G_{f}\right)$ is given by</p>
<p>$$
\hat{d}<em f="f">{\mathcal{H}}\left(S\left(G</em>\right)\right)=2\left(1-\min }\right), T\left(G_{f<em i="1">{\eta \in \mathcal{H}}\left[\frac{1}{n} \sum</em>}^{n} I\left[\eta\left(G_{f}\left(\mathbf{x<em i="n+1">{i}\right)\right)=0\right]+\frac{1}{n^{\prime}} \sum</em>\right)\right)=1\right]\right]\right)
$$}^{N} I\left[\eta\left(G_{f}\left(\mathbf{x}_{i</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Let us consider $\mathcal{H}$ as the class of hyperplanes in the representation space. Inspired by the Proxy $\mathcal{A}$-distance (see Section 3.2), we suggest estimating the "min" part of Equation (6) by a domain classification layer $G_{d}$ that learns a logistic regressor $G_{d}: \mathbb{R}^{D} \rightarrow[0,1]$, parameterized by a vector-scalar pair $(\mathbf{u}, z) \in \mathbb{R}^{D} \times \mathbb{R}$, that models the probability that a given input is from the source domain $\mathcal{D}<em _mathrm_T="\mathrm{T">{\mathrm{S}}^{X}$ or the target domain $\mathcal{D}</em>$. Thus,}}^{X</p>
<p>$$
G_{d}\left(G_{f}(\mathbf{x}) ; \mathbf{u}, z\right)=\operatorname{sigm}\left(\mathbf{u}^{\top} G_{f}(\mathbf{x})+z\right)
$$</p>
<p>Hence, the function $G_{d}(\cdot)$ is a domain regressor. We define its loss by</p>
<p>$$
\mathcal{L}<em d="d">{d}\left(G</em>}\left(G_{f}\left(\mathbf{x<em i="i">{i}\right)\right), d</em>}\right)=d_{i} \log \frac{1}{G_{d}\left(G_{f}\left(\mathbf{x<em i="i">{i}\right)\right)}+\left(1-d</em>
$$}\right) \log \frac{1}{1-G_{d}\left(G_{f}\left(\mathbf{x}_{i}\right)\right)</p>
<p>where $d_{i}$ denotes the binary variable (domain label) for the $i$-th example, which indicates whether $\mathbf{x}<em i="i">{i}$ come from the source distribution $\left(\mathbf{x}</em>} \sim \mathcal{D<em i="i">{\mathrm{S}}^{X}\right.$ if $\left.d</em>}=0\right)$ or from the target distribution $\left(\mathbf{x<em _mathrm_T="\mathrm{T">{i} \sim \mathcal{D}</em>=1\right)$.}}^{\mathrm{X}}\right.$ if $\left.d_{i</p>
<p>Recall that for the examples from the source distribution $\left(d_{i}=0\right)$, the corresponding labels $y_{i} \in Y$ are known at training time. For the examples from the target domains, we do not know the labels at training time, and we want to predict such labels at test time. This enables us to add a domain adaptation term to the objective of Equation (5), giving the following regularizer:</p>
<p>$$
R(\mathbf{W}, \mathbf{b})=\max <em i="1">{\mathbf{u}, z}\left[-\frac{1}{n} \sum</em>}^{n} \mathcal{L<em i="n+1">{d}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{u}, z)-\frac{1}{n^{\prime}} \sum</em>, z)\right]
$$}^{N} \mathcal{L}_{d}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{u</p>
<p>where $\mathcal{L}<em d="d">{d}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{u}, z)=\mathcal{L}</em>}\left(G_{d}\left(G_{f}\left(\mathbf{x<em i="i">{i} ; \mathbf{W}, \mathbf{b}\right) ; \mathbf{u}, z\right), d</em>}\right)$. This regularizer seeks to approximate the $\mathcal{H}$-divergence of Equation (6), as $2(1-R(\mathbf{W}, \mathbf{b}))$ is a surrogate for $\hat{d<em f="f">{\mathcal{H}}\left(S\left(G</em>(\cdot, \cdot)$. The hyper-parameter $\lambda$ is then used to tune the trade-off between these two quantities during the learning process.}\right), T\left(G_{f}\right)\right)$. In line with Theorem 2, the optimization problem given by Equations (5) and (8) implements a trade-off between the minimization of the source risk $R_{S}(\cdot)$ and the divergence $\hat{d}_{\mathcal{H}</p>
<p>For learning, we first note that we can rewrite the complete optimization objective of Equation (5) as follows:</p>
<p>$$
\begin{aligned}
&amp; E(\mathbf{W}, \mathbf{V}, \mathbf{b}, \mathbf{c}, \mathbf{u}, z) \
&amp; \quad=\frac{1}{n} \sum_{i=1}^{n} \mathcal{L}<em i="1">{y}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{V}, \mathbf{c})-\lambda\left(\frac{1}{n} \sum</em>}^{n} \mathcal{L<em i="n+1">{d}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{u}, z)+\frac{1}{n^{\prime}} \sum</em>, z)\right)
\end{aligned}
$$}^{N} \mathcal{L}_{d}^{i}(\mathbf{W}, \mathbf{b}, \mathbf{u</p>
<p>where we are seeking the parameters $\hat{\mathbf{W}}, \hat{\mathbf{V}}, \hat{\mathbf{b}}, \hat{\mathbf{c}}, \hat{\mathbf{u}}, \hat{z}$ that deliver a saddle point given by</p>
<p>$$
\begin{aligned}
(\hat{\mathbf{W}}, \hat{\mathbf{V}}, \hat{\mathbf{b}}, \hat{\mathbf{c}}) &amp; =\underset{\mathbf{W}, \mathbf{V}, \mathbf{b}, \mathbf{c}}{\operatorname{argmin}} E(\mathbf{W}, \mathbf{V}, \mathbf{b}, \mathbf{c}, \hat{\mathbf{u}}, \hat{z}) \
(\hat{\mathbf{u}}, \hat{z}) &amp; =\underset{\mathbf{u}, z}{\operatorname{argmax}} E(\hat{\mathbf{W}}, \hat{\mathbf{V}}, \hat{\mathbf{b}}, \hat{\mathbf{c}}, \mathbf{u}, z)
\end{aligned}
$$</p>
<p>Thus, the optimization problem involves a minimization with respect to some parameters, as well as a maximization with respect to the others.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mh">1</span><span class="w"> </span><span class="n">Shallow</span><span class="w"> </span><span class="n">DANN</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Stochastic</span><span class="w"> </span><span class="n">training</span><span class="w"> </span><span class="n">update</span>
<span class="w">    </span><span class="nl">Input:</span>
<span class="w">    </span><span class="o">-</span><span class="w"> </span><span class="n">samples</span><span class="w"> </span><span class="n">\(S=\left\{\left(\mathbf{x}_{i},</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">i</span><span class="p">}</span><span class="n">\right)\right\}_{i=1}^{n}\)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">\(T=\left\{\mathbf{x}_{i}\right\}_{i=1}^{n^{\prime}}\)</span>
<span class="w">    </span><span class="o">-</span><span class="w"> </span><span class="n">hidden</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="n">\(D\)</span>
<span class="w">    </span><span class="o">-</span><span class="w"> </span><span class="n">adaptation</span><span class="w"> </span><span class="k">parameter</span><span class="w"> </span><span class="n">\(\lambda\)</span>
<span class="w">    </span><span class="o">-</span><span class="w"> </span><span class="n">learning</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="n">\(\mu\),</span>
<span class="mh">2</span><span class="o">:</span><span class="w"> </span><span class="nl">Output:</span><span class="w"> </span><span class="n">neural</span><span class="w"> </span><span class="n">network</span><span class="w"> </span><span class="n">\(\{\mathbf{W},</span><span class="w"> </span><span class="n">\mathbf{V},</span><span class="w"> </span><span class="n">\mathbf{b},</span><span class="w"> </span><span class="n">\mathbf{c}\}\)</span>
<span class="mh">3</span><span class="o">:</span><span class="w"> </span><span class="n">\(\mathbf{W},</span><span class="w"> </span><span class="n">\mathbf{V}</span><span class="w"> </span><span class="n">\leftarrow\)</span><span class="w"> </span><span class="n">random_init</span><span class="w"> </span><span class="n">\((D)\)</span>
<span class="mh">4</span><span class="o">:</span><span class="w"> </span><span class="n">\(\mathbf{b},</span><span class="w"> </span><span class="n">\mathbf{c},</span><span class="w"> </span><span class="n">\mathbf{u},</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="mh">0</span><span class="n">\)</span>
<span class="mh">5</span><span class="o">:</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="n">stopping</span><span class="w"> </span><span class="n">criterion</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">met</span><span class="w"> </span><span class="k">do</span>
<span class="mh">6</span><span class="o">:</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">\(i\)</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="mh">1</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">\(n\)</span><span class="w"> </span><span class="k">do</span>
<span class="mh">7</span><span class="o">:</span><span class="w"> </span><span class="n">\#</span><span class="w"> </span><span class="n">Forward</span><span class="w"> </span><span class="n">propagation</span>
<span class="mh">8</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\operatorname{sigm}\left(\mathbf{b}+\mathbf{W}</span><span class="w"> </span><span class="n">\mathbf{x}_{i}\right)\)</span>
<span class="mh">9</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">y</span><span class="p">}</span><span class="n">\left(G_{f}\left(\mathbf{x}_{i}\right)\right)</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\operatorname{softmax}\left(\mathbf{c}+\mathbf{V}</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)\right)\)</span>
<span class="mh">10</span><span class="o">:</span><span class="w"> </span><span class="n">\#</span><span class="w"> </span><span class="n">Backpropagation</span>
<span class="mh">11</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{\mathbf{c}}</span><span class="w"> </span><span class="n">\leftarrow-\left(\mathbf{e}\left(y_{i}\right)-G_{y}\left(G_{f}\left(\mathbf{x}_{i}\right)\right)\right)\)</span>
<span class="mh">12</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{\mathbf{V}}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\Delta_{\mathbf{c}}</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)^{\top}\)</span>
<span class="mh">13</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{\mathbf{b}}</span><span class="w"> </span><span class="n">\leftarrow\left(\mathbf{V}^{\top}</span><span class="w"> </span><span class="n">\Delta_{\mathbf{c}}\right)</span><span class="w"> </span><span class="n">\odot</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)</span><span class="w"> </span><span class="n">\odot\left(1-G_{f}\left(\mathbf{x}_{i}\right)\right)\)</span>
<span class="mh">14</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{\mathbf{W}}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\Delta_{\mathbf{b}}</span><span class="w"> </span><span class="n">\cdot\left(\mathbf{x}_{i}\right)^{\top}\)</span>
<span class="mh">15</span><span class="o">:</span><span class="w"> </span><span class="n">\#</span><span class="w"> </span><span class="n">Domain</span><span class="w"> </span><span class="n">adaptation</span><span class="w"> </span><span class="n">regularizer</span><span class="p">...</span>
<span class="mh">16</span><span class="o">:</span><span class="w"> </span><span class="n">\#</span><span class="w"> </span><span class="p">...</span><span class="n">from</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="n">domain</span>
<span class="mh">17</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">d</span><span class="p">}</span><span class="n">\left(G_{f}\left(\mathbf{x}_{i}\right)\right)</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\operatorname{sigm}\left(d+\mathbf{u}^{\top}</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)\right)\)</span>
<span class="mh">18</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{d}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\lambda\left(1-G_{d}\left(G_{f}\left(\mathbf{x}_{i}\right)\right)\right)\)</span>
<span class="mh">19</span><span class="o">:</span><span class="w"> </span><span class="n">\(\quad</span><span class="w"> </span><span class="n">\Delta_{\mathbf{u}}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\lambda\left(1-G_{d}\left(G_{f}\left(\mathbf{x}_{i}\right)\right)\right)</span><span class="w"> </span><span class="n">G_</span><span class="p">{</span><span class="n">f</span><span class="p">}</span><span class="n">\left(\mathbf{x}_{i}\right)\)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>    \(\operatorname{tmp} \leftarrow \lambda\left(1-G_{d}\left(G_{f}\left(\mathbf{x}_{i}\right)\right)\right)\)
        \(\times \mathbf{u} \odot G_{f}\left(\mathbf{x}_{i}\right) \odot\left(1-G_{f}\left(\mathbf{x}_{i}\right)\right)\)
    \(\Delta_{\mathbf{b}} \leftarrow \Delta_{\mathbf{b}}+\operatorname{tmp}\)
    \(\Delta_{\mathbf{W}} \leftarrow \Delta_{\mathbf{W}}+\operatorname{tmp} \cdot\left(\mathbf{x}_{i}\right)^{\top}\)
    \# ...from other domain
    \(j \leftarrow\) uniform_integer \(\left(1, \ldots, n^{\prime}\right)\)
    \(G_{f}\left(\mathbf{x}_{j}\right) \leftarrow \operatorname{sigm}\left(\mathbf{b}+\mathbf{W} \mathbf{x}_{j}\right)\)
    \(G_{d}\left(G_{f}\left(\mathbf{x}_{j}\right)\right) \leftarrow \operatorname{sigm}\left(d+\mathbf{u}^{\top} G_{f}\left(\mathbf{x}_{j}\right)\right)\)
    \(\Delta_{d} \leftarrow \Delta_{d}-\lambda G_{d}\left(G_{f}\left(\mathbf{x}_{j}\right)\right)\)
    \(\Delta_{\mathbf{u}} \leftarrow \Delta_{\mathbf{u}}-\lambda G_{d}\left(G_{f}\left(\mathbf{x}_{j}\right)\right) G_{f}\left(\mathbf{x}_{j}\right)\)
\(\operatorname{tmp} \leftarrow-\lambda G_{d}\left(G_{f}\left(\mathbf{x}_{j}\right)\right)\)
            \(\times \mathbf{u} \odot G_{f}\left(\mathbf{x}_{j}\right) \odot\left(1-G_{f}\left(\mathbf{x}_{j}\right)\right)\)
    \(\Delta_{\mathbf{b}} \leftarrow \Delta_{\mathbf{b}}+\operatorname{tmp}\)
    \(\Delta_{\mathbf{W}} \leftarrow \Delta_{\mathbf{W}}+\operatorname{tmp} \cdot\left(\mathbf{x}_{j}\right)^{\top}\)
    \# Update neural network parameters
    \(\mathbf{W} \leftarrow \mathbf{W}-\mu \Delta_{\mathbf{W}}\)
    \(\mathbf{V} \leftarrow \mathbf{V}-\mu \Delta_{\mathbf{V}}\)
    \(\mathbf{b} \leftarrow \mathbf{b}-\mu \Delta_{\mathbf{b}}\)
    \(\mathbf{c} \leftarrow \mathbf{c}-\mu \Delta_{\mathbf{c}}\)
    \# Update domain classifier
    \(\mathbf{u} \leftarrow \mathbf{u}+\mu \Delta_{\mathbf{u}}\)
    \(d \leftarrow d+\mu \Delta_{d}\)
end for
end while
</code></pre></div>

<p>Note: In this pseudo-code, $\mathbf{e}(y)$ refers to a "one-hot" vector, consisting of all 0 s except for a 1 at position $y$, and $\odot$ is the element-wise product.</p>
<p>We propose to tackle this problem with a simple stochastic gradient procedure, in which updates are made in the opposite direction of the gradient of Equation (9) for the minimizing parameters, and in the direction of the gradient for the maximizing parameters. Stochastic estimates of the gradient are made, using a subset of the training samples to compute the averages. Algorithm 1 provides the complete pseudo-code of this learning procedure. ${ }^{3}$ In words, during training, the neural network (parameterized by $\mathbf{W}, \mathbf{b}, \mathbf{V}, \mathbf{c}$ ) and the domain regressor (parameterized by $\mathbf{u}, z$ ) are competing against each other, in an adversarial way, over the objective of Equation (9). For this reason, we refer to networks trained according to this objective as Domain-Adversarial Neural Networks (DANN). DANN will effectively attempt to learn a hidden layer $G_{f}(\cdot)$ that maps an example (either source or target) into a representation allowing the output layer $G_{y}(\cdot)$ to accurately classify source samples, but crippling the ability of the domain regressor $G_{d}(\cdot)$ to detect whether each example belongs to the source or target domains.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>4.2 Generalization to Arbitrary Architectures</h1>
<p>For illustration purposes, we've so far focused on the case of a single hidden layer DANN. However, it is straightforward to generalize to other sophisticated architectures, which might be more appropriate for the data at hand. For example, deep convolutional neural networks are well known for being state-of-the-art models for learning discriminative features of images (Krizhevsky et al., 2012).</p>
<p>Let us now use a more general notation for the different components of DANN. Namely, let $G_{f}\left(\cdot ; \theta_{f}\right)$ be the $D$-dimensional neural network feature extractor, with parameters $\theta_{f}$. Also, let $G_{y}\left(\cdot ; \theta_{y}\right)$ be the part of DANN that computes the network's label prediction output layer, with parameters $\theta_{y}$, while $G_{d}\left(\cdot ; \theta_{d}\right)$ now corresponds to the computation of the domain prediction output of the network, with parameters $\theta_{d}$. Note that for preserving the theoretical guarantees of Theorem 2, the hypothesis class $\mathcal{H}<em d="d">{d}$ generated by the domain prediction component $G</em>}$ should include the hypothesis class $\mathcal{H<em y="y">{y}$ generated by the label prediction component $G</em>}$. Thus, $\mathcal{H<em d="d">{y} \subseteq \mathcal{H}</em>$.</p>
<p>We will note the prediction loss and the domain loss respectively by</p>
<p>$$
\begin{aligned}
\mathcal{L}<em f="f">{y}^{i}\left(\theta</em>}, \theta_{y}\right) &amp; =\mathcal{L<em y="y">{y}\left(G</em>}\left(G_{f}\left(\mathbf{x<em f="f">{i} ; \theta</em>\right) \
\mathcal{L}}\right) ; \theta_{y}\right), y_{i<em f="f">{d}^{i}\left(\theta</em>}, \theta_{d}\right) &amp; =\mathcal{L<em d="d">{d}\left(G</em>}\left(G_{f}\left(\mathbf{x<em f="f">{i} ; \theta</em>\right)
\end{aligned}
$$}\right) ; \theta_{d}\right), d_{i</p>
<p>Training DANN then parallels the single layer case and consists in optimizing</p>
<p>$$
E\left(\theta_{f}, \theta_{y}, \theta_{d}\right)=\frac{1}{n} \sum_{i=1}^{n} \mathcal{L}<em f="f">{y}^{i}\left(\theta</em>}, \theta_{y}\right)-\lambda\left(\frac{1}{n} \sum_{i=1}^{n} \mathcal{L<em f="f">{d}^{i}\left(\theta</em>}, \theta_{d}\right)+\frac{1}{n^{\prime}} \sum_{i=n+1}^{N} \mathcal{L<em f="f">{d}^{i}\left(\theta</em>\right)\right)
$$}, \theta_{d</p>
<p>by finding the saddle point $\hat{\theta}<em y="y">{f}, \hat{\theta}</em>$ such that}, \hat{\theta}_{d</p>
<p>$$
\begin{aligned}
\left(\hat{\theta}<em y="y">{f}, \hat{\theta}</em>}\right) &amp; =\underset{\theta_{f}, \theta_{y}}{\operatorname{argmin}} E\left(\theta_{f}, \theta_{y}, \hat{\theta<em d="d">{d}\right) \
\hat{\theta}</em>} &amp; =\underset{\theta_{d}}{\operatorname{argmax}} E\left(\hat{\theta<em y="y">{f}, \hat{\theta}</em>\right)
\end{aligned}
$$}, \theta_{d</p>
<p>As suggested previously, a saddle point defined by Equations (11-12) can be found as a stationary point of the following gradient updates:</p>
<p>$$
\begin{aligned}
&amp; \theta_{f} \leftarrow \theta_{f}-\mu\left(\frac{\partial \mathcal{L}<em f="f">{y}^{i}}{\partial \theta</em>}}-\lambda \frac{\partial \mathcal{L<em f="f">{d}^{i}}{\partial \theta</em>\right) \
&amp; \theta_{y} \leftarrow \quad \theta_{y}-\mu \frac{\partial \mathcal{L}}<em y="y">{y}^{i}}{\partial \theta</em> \
&amp; \theta_{d} \leftarrow \quad \theta_{d}-\mu \lambda \frac{\partial \mathcal{L}}<em d="d">{d}^{i}}{\partial \theta</em>
\end{aligned}
$$}</p>
<p>where $\mu$ is the learning rate. We use stochastic estimates of these gradients, by sampling examples from the data set.</p>
<p>The updates of Equations (13-15) are very similar to stochastic gradient descent (SGD) updates for a feed-forward deep model that comprises feature extractor fed into the label</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The proposed architecture includes a deep feature extractor (green) and a deep label predictor (blue), which together form a standard feed-forward architecture. Unsupervised domain adaptation is achieved by adding a domain classifier (red) connected to the feature extractor via a gradient reversal layer that multiplies the gradient by a certain negative constant during the backpropagation-based training. Otherwise, the training proceeds standardly and minimizes the label prediction loss (for source examples) and the domain classification loss (for all samples). Gradient reversal ensures that the feature distributions over the two domains are made similar (as indistinguishable as possible for the domain classifier), thus resulting in the domain-invariant features.
predictor and into the domain classifier (with loss weighted by $\lambda$ ). The only difference is that in (13), the gradients from the class and domain predictors are subtracted, instead of being summed (the difference is important, as otherwise SGD would try to make features dissimilar across domains in order to minimize the domain classification loss). Since SGDand its many variants, such as ADAGRAD (Duchi et al., 2010) or ADADELTA (Zeiler, 2012)—is the main learning algorithm implemented in most libraries for deep learning, it would be convenient to frame an implementation of our stochastic saddle point procedure as SGD.</p>
<p>Fortunately, such a reduction can be accomplished by introducing a special gradient reversal layer (GRL), defined as follows. The gradient reversal layer has no parameters associated with it. During the forward propagation, the GRL acts as an identity transformation. During the backpropagation however, the GRL takes the gradient from the subsequent level and changes its sign, i.e., multiplies it by -1 , before passing it to the preceding layer. Implementing such a layer using existing object-oriented packages for deep learning is simple, requiring only to define procedures for the forward propagation (identity transformation), and backpropagation (multiplying by -1 ). The layer requires no parameter update.</p>
<p>The GRL as defined above is inserted between the feature extractor $G_{f}$ and the domain classifier $G_{d}$, resulting in the architecture depicted in Figure 1. As the backpropagation process passes through the GRL, the partial derivatives of the loss that is downstream</p>
<p>the GRL (i.e., $\mathcal{L}<em f="f">{d}$ ) w.r.t. the layer parameters that are upstream the GRL (i.e., $\theta</em>}$ ) get multiplied by -1 , i.e., $\frac{\partial \mathcal{L<em f="f">{d}}{\partial \theta</em>}}$ is effectively replaced with $-\frac{\partial \mathcal{L<em f="f">{d}}{\partial \theta</em>$. Therefore, running SGD in the resulting model implements the updates of Equations (13-15) and converges to a saddle point of Equation (10).}</p>
<p>Mathematically, we can formally treat the gradient reversal layer as a "pseudo-function" $\mathcal{R}(\mathbf{x})$ defined by two (incompatible) equations describing its forward and backpropagation behaviour:</p>
<p>$$
\begin{aligned}
&amp; \mathcal{R}(\mathbf{x})=\mathbf{x} \
&amp; \frac{d \mathcal{R}}{d \mathbf{x}}=-\mathbf{I}
\end{aligned}
$$</p>
<p>where $\mathbf{I}$ is an identity matrix. We can then define the objective "pseudo-function" of $\left(\theta_{f}, \theta_{y}, \theta_{d}\right)$ that is being optimized by the stochastic gradient descent within our method:</p>
<p>$$
\begin{aligned}
&amp; \tilde{E}\left(\theta_{f}, \theta_{y}, \theta_{d}\right)=\frac{1}{n} \sum_{i=1}^{n} \mathcal{L}<em y="y">{y}\left(G</em>}\left(G_{f}\left(\mathbf{x<em f="f">{i} ; \theta</em>\right) \
&amp; \quad-\lambda\left(\frac{1}{n} \sum_{i=1}^{n} \mathcal{L}}\right) ; \theta_{y}\right), y_{i<em d="d">{d}\left(G</em>}\left(\mathcal{R}\left(G_{f}\left(\mathbf{x<em f="f">{i} ; \theta</em>}\right)\right) ; \theta_{d}\right), d_{i}\right)+\frac{1}{n^{\prime}} \sum_{i=n+1}^{N} \mathcal{L<em d="d">{d}\left(G</em>}\left(\mathcal{R}\left(G_{f}\left(\mathbf{x<em f="f">{i} ; \theta</em>\right)\right)
\end{aligned}
$$}\right)\right) ; \theta_{d}\right), d_{i</p>
<p>Running updates (13-15) can then be implemented as doing SGD for (18) and leads to the emergence of features that are domain-invariant and discriminative at the same time. After the learning, the label predictor $G_{y}\left(G_{f}\left(\mathbf{x} ; \theta_{f}\right) ; \theta_{y}\right)$ can be used to predict labels for samples from the target domain (as well as from the source domain). Note that we release the source code for the Gradient Reversal layer along with the usage examples as an extension to Caffe (Jia et al., 2014). ${ }^{4}$</p>
<h1>5. Experiments</h1>
<p>In this section, we present a variety of empirical results for both shallow domain adversarial neural networks (Subsection 5.1) and deep ones (Subsections 5.2 and 5.3).</p>
<h3>5.1 Experiments with Shallow Neural Networks</h3>
<p>In this first experiment section, we evaluate the behavior of the simple version of DANN described by Subsection 4.1. Note that the results reported in the present subsection are obtained using Algorithm 1. Thus, the stochastic gradient descent approach here consists of sampling a pair of source and target examples and performing a gradient step update of all parameters of DANN. Crucially, while the update of the regular parameters follows as usual the opposite direction of the gradient, for the adversarial parameters the step must follow the gradient's direction (since we maximize with respect to them, instead of minimizing).</p>
<h3>5.1.1 Experiments on a Toy Problem</h3>
<p>As a first experiment, we study the behavior of the proposed algorithm on a variant of the inter-twinning moons 2 D problem, where the target distribution is a rotation of the source</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" />
(a) Standard NN. For the "domain classification", we use a non adversarial domain regressor on the hidden neurons learned by the Standard NN. (This is equivalent to run Algorithm 1, without Lines 22 and 31)
<img alt="img-2.jpeg" src="img-2.jpeg" />
(b) DANN (Algorithm 1)</p>
<p>Figure 2: The inter-twinning moons toy problem. Examples from the source sample are represented as a " + "(label 1) and a " - "(label 0 ), while examples from the unlabeled target sample are represented as black dots. See text for the figure discussion.
one. As the source sample $S$, we generate a lower moon and an upper moon labeled 0 and 1 respectively, each of which containing 150 examples. The target sample $T$ is obtained by the following procedure: (1) we generate a sample $S^{\prime}$ the same way $S$ has been generated; (2) we rotate each example by $35^{\circ}$; and (3) we remove all the labels. Thus, $T$ contains 300 unlabeled examples. We have represented those examples in Figure 2.</p>
<p>We study the adaptation capability of DANN by comparing it to the standard neural network (NN). In these toy experiments, both algorithms share the same network architecture, with a hidden layer size of 15 neurons. We train the NN using the same procedure as the DANN. That is, we keep updating the domain regressor component using target sample $T$ (with a hyper-parameter $\lambda=6$; the same value is used for DANN), but we disable the adversarial back-propagation into the hidden layer. To do so, we execute Algorithm 1 by omitting the lines numbered 22 and 31 . This allows recovering the NN learning algorithm - based on the source risk minimization of Equation (5) without any regularizer-and simultaneously train the domain regressor of Equation (7) to discriminate between source and target domains. With this toy experience, we will first illustrate how DANN adapts its decision boundary when compared to NN. Moreover, we will also illustrate how the representation given by the hidden layer is less adapted to the source domain task with DANN than with NN (this is why we need a domain regressor in the NN experiment). We recall that this is the founding idea behind our proposed algorithm. The analysis of the experiment appears in Figure 2, where upper graphs relate to standard NN, and lower graphs relate to DANN. By looking at the lower and upper graphs pairwise, we compare NN and DANN from four different perspectives, described in details below.</p>
<p>The column "Label Classification" of Figure 2 shows the decision boundaries of DANN and NN on the problem of predicting the labels of both source and the target examples. As expected, NN accurately classifies the two classes of the source sample $S$, but is not fully adapted to the target sample $T$. On the contrary, the decision boundary of DANN perfectly classifies examples from both source and target samples. In the studied task, DANN clearly adapts to the target distribution.</p>
<p>The column "Representation PCA" studies how the domain adaptation regularizer affects the representation $G_{f}(\cdot)$ provided by the network hidden layer. The graphs are obtained by applying a Principal component analysis (PCA) on the set of all representation of source and target data points, i.e., $S\left(G_{f}\right) \cup T\left(G_{f}\right)$. Thus, given the trained network (NN or DANN), every point from $S$ and $T$ is mapped into a 15 -dimensional feature space through the hidden layer, and projected back into a two-dimensional plane by the PCA transformation. In the DANN-PCA representation, we observe that target points are homogeneously spread out among source points; In the NN-PCA representation, a number of target points belong to clusters containing no source points. Hence, labeling the target points seems an easier task given the DANN-PCA representation.
To push the analysis further, the PCA graphs tag four crucial data points by the letters A, B, C and D, that correspond to the moon extremities in the original space (note that the original point locations are tagged in the first column graphs). We observe that points A and B are very close to each other in the NN-PCA representation, while they clearly belong to different classes. The same happens to points C and D. Conversely, these four points are at the opposite four corners in the DANN-PCA representation. Note also that the target point A (resp. D) - that is difficult to classify in the original space-is located in the " + "cluster (resp. "-" cluster) in the DANN-PCA representation. Therefore, the representation promoted by DANN is better suited to the adaptation problem.</p>
<p>The column "Domain Classification" shows the decision boundary on the domain classification problem, which is given by the domain regressor $G_{d}$ of Equation (7). More precisely, an example $\mathbf{x}$ is classified as a source example when $G_{d}\left(G_{f}(\mathbf{x})\right) \geq 0.5$, and is classified as a domain example otherwise. Remember that, during the learning process of DANN, the $G_{d}$ regressor struggles to discriminate between source and target domains, while the hidden representation $G_{f}(\cdot)$ is adversarially updated to prevent it to succeed. As explained above, we trained a domain regressor during the learning process of NN, but without allowing it to influence the learned representation $G_{f}(\cdot)$.
On one hand, the DANN domain regressor clearly fails to generalize source and target distribution topologies. On the other hand, the NN domain regressor shows a better (although imperfect) generalization capability. Inter alia, it seems to roughly capture the rotation angle of the target distribution. This again corroborates that the DANN representation does not allow discriminating between domains.</p>
<p>The column "Hidden Neurons" shows the configuration of hidden layer neurons (by Equation 4, we have that each neuron is indeed a linear regressor). In other words, each of the fifteen plot line corresponds to the coordinates $\mathbf{x} \in \mathbb{R}^{2}$ for which the $i$-th component of $G_{f}(\mathbf{x})$ equals $\frac{1}{2}$, for $i \in{1, \ldots, 15}$. We observe that the standard NN neurons are grouped in three clusters, each one allowing to generate a straight line of the zigzag decision boundary for the label classification problem. However, most of these neurons are also able</p>
<p>to (roughly) capture the rotation angle of the domain classification problem. Hence, we observe that the adaptation regularizer of DANN prevents these kinds of neurons to be produced. It is indeed striking to see that the two predominant patterns in the NN neurons (i.e., the two parallel lines crossing the plane from lower left to upper right) are vanishing in the DANN neurons.</p>
<h1>5.1.2 Unsupervised Hyper-Parameter Selection</h1>
<p>To perform unsupervised domain adaption, one should provide ways to set hyper-parameters (such as the domain regularization parameter $\lambda$, the learning rate, the network architecture for our method) in an unsupervised way, i.e., without referring to labeled data in the target domain. In the following experiments of Sections 5.1.3 and 5.1.4, we select the hyper-parameters of each algorithm by using a variant of reverse cross-validation approach proposed by Zhong et al. (2010), that we call reverse validation.</p>
<p>To evaluate the reverse validation risk associated to a tuple of hyper-parameters, we proceed as follows. Given the labeled source sample $S$ and the unlabeled target sample $T$, we split each set into training sets ( $S^{\prime}$ and $T^{\prime}$ respectively, containing $90 \%$ of the original examples) and the validation sets ( $S_{V}$ and $T_{V}$ respectively). We use the labeled set $S^{\prime}$ and the unlabeled target set $T^{\prime}$ to learn a classifier $\eta$. Then, using the same algorithm, we learn a reverse classifier $\eta_{r}$ using the self-labeled set ${(\mathbf{x}, \eta(\mathbf{x}))}<em r="r">{\mathbf{x} \in T^{\prime}}$ and the unlabeled part of $S^{\prime}$ as target sample. Finally, the reverse classifier $\eta</em>\right)$. The process is repeated with multiple values of hyper-parameters and the selected parameters are those corresponding to the classifier with the lowest reverse validation risk.}$ is evaluated on the validation set $S_{V}$ of source sample. We then say that the classifier $\eta$ has a reverse validation risk of $R_{S_{V}}\left(\eta_{r</p>
<p>Note that when we train neural network architectures, the validation set $S_{V}$ is also used as an early stopping criterion during the learning of $\eta$, and self-labeled validation set ${(\mathbf{x}, \eta(\mathbf{x}))}<em V="V">{\mathbf{x} \in T</em>$ with the configuration learned by the network $\eta$.}}$ is used as an early stopping criterion during the learning of $\eta_{r}$. We also observed better accuracies when we initialized the learning of the reverse classifier $\eta_{r</p>
<h3>5.1.3 Experiments on Sentiment Analysis Data Sets</h3>
<p>We now compare the performance of our proposed DANN algorithm to a standard neural network with one hidden layer (NN) described by Equation (5), and a Support Vector Machine (SVM) with a linear kernel. We compare the algorithms on the Amazon reviews data set, as pre-processed by Chen et al. (2012). This data set includes four domains, each one composed of reviews of a specific kind of product (books, dvd disks, electronics, and kitchen appliances). Reviews are encoded in 5000 dimensional feature vectors of unigrams and bigrams, and labels are binary: " 0 " if the product is ranked up to 3 stars, and " 1 " if the product is ranked 4 or 5 stars.</p>
<p>We perform twelve domain adaptation tasks. All learning algorithms are given 2000 labeled source examples and 2000 unlabeled target examples. Then, we evaluate them on separate target test sets (between 3000 and 6000 examples). Note that NN and SVM do not use the unlabeled target sample for learning.</p>
<p>Here are more details about the procedure used for each learning algorithms leading to the empirical results of Table 1.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: center;">Original data</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">mSDA representation</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Source</td>
<td style="text-align: left;">Target</td>
<td style="text-align: center;">DANN</td>
<td style="text-align: center;">NN</td>
<td style="text-align: center;">SVM</td>
<td style="text-align: center;">DANN</td>
<td style="text-align: center;">NN</td>
<td style="text-align: center;">SVM</td>
</tr>
<tr>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: left;">DVD</td>
<td style="text-align: center;">.784</td>
<td style="text-align: center;">.790</td>
<td style="text-align: center;">$\mathbf{. 7 9 9}$</td>
<td style="text-align: center;">.829</td>
<td style="text-align: center;">.824</td>
<td style="text-align: center;">$\mathbf{. 8 3 0}$</td>
</tr>
<tr>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: center;">.733</td>
<td style="text-align: center;">.747</td>
<td style="text-align: center;">$\mathbf{. 7 4 8}$</td>
<td style="text-align: center;">$\mathbf{. 8 0 4}$</td>
<td style="text-align: center;">.770</td>
<td style="text-align: center;">.766</td>
</tr>
<tr>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: center;">$\mathbf{. 7 7 9}$</td>
<td style="text-align: center;">.778</td>
<td style="text-align: center;">.769</td>
<td style="text-align: center;">$\mathbf{. 8 4 3}$</td>
<td style="text-align: center;">.842</td>
<td style="text-align: center;">.821</td>
</tr>
<tr>
<td style="text-align: left;">DVD</td>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: center;">.723</td>
<td style="text-align: center;">.720</td>
<td style="text-align: center;">$\mathbf{. 7 4 3}$</td>
<td style="text-align: center;">.825</td>
<td style="text-align: center;">.823</td>
<td style="text-align: center;">$\mathbf{. 8 2 6}$</td>
</tr>
<tr>
<td style="text-align: left;">DVD</td>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: center;">$\mathbf{. 7 5 4}$</td>
<td style="text-align: center;">.732</td>
<td style="text-align: center;">.748</td>
<td style="text-align: center;">$\mathbf{. 8 0 9}$</td>
<td style="text-align: center;">.768</td>
<td style="text-align: center;">.739</td>
</tr>
<tr>
<td style="text-align: left;">DVD</td>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: center;">$\mathbf{. 7 8 3}$</td>
<td style="text-align: center;">.778</td>
<td style="text-align: center;">.746</td>
<td style="text-align: center;">.849</td>
<td style="text-align: center;">$\mathbf{. 8 5 3}$</td>
<td style="text-align: center;">.842</td>
</tr>
<tr>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: center;">$\mathbf{. 7 1 3}$</td>
<td style="text-align: center;">.709</td>
<td style="text-align: center;">.705</td>
<td style="text-align: center;">$\mathbf{. 7 7 4}$</td>
<td style="text-align: center;">.770</td>
<td style="text-align: center;">.762</td>
</tr>
<tr>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: left;">DVD</td>
<td style="text-align: center;">$\mathbf{. 7 3 8}$</td>
<td style="text-align: center;">.733</td>
<td style="text-align: center;">.726</td>
<td style="text-align: center;">$\mathbf{. 7 8 1}$</td>
<td style="text-align: center;">.759</td>
<td style="text-align: center;">.770</td>
</tr>
<tr>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: center;">$\mathbf{. 8 5 4}$</td>
<td style="text-align: center;">$\mathbf{. 8 5 4}$</td>
<td style="text-align: center;">.847</td>
<td style="text-align: center;">.881</td>
<td style="text-align: center;">$\mathbf{. 8 6 3}$</td>
<td style="text-align: center;">.847</td>
</tr>
<tr>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: left;">BOOKS</td>
<td style="text-align: center;">$\mathbf{. 7 0 9}$</td>
<td style="text-align: center;">.708</td>
<td style="text-align: center;">.707</td>
<td style="text-align: center;">.718</td>
<td style="text-align: center;">.721</td>
<td style="text-align: center;">$\mathbf{. 7 6 9}$</td>
</tr>
<tr>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: left;">DVD</td>
<td style="text-align: center;">$\mathbf{. 7 4 0}$</td>
<td style="text-align: center;">.739</td>
<td style="text-align: center;">.736</td>
<td style="text-align: center;">$\mathbf{. 7 8 9}$</td>
<td style="text-align: center;">$\mathbf{. 7 8 9}$</td>
<td style="text-align: center;">.788</td>
</tr>
<tr>
<td style="text-align: left;">KITCHEN</td>
<td style="text-align: left;">ELECTRONICS</td>
<td style="text-align: center;">$\mathbf{. 8 4 3}$</td>
<td style="text-align: center;">.841</td>
<td style="text-align: center;">.842</td>
<td style="text-align: center;">.856</td>
<td style="text-align: center;">.850</td>
<td style="text-align: center;">$\mathbf{. 8 6 1}$</td>
</tr>
</tbody>
</table>
<p>(a) Classification accuracy on the Amazon reviews data set</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Original data</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">DANN</td>
<td style="text-align: center;">NN</td>
<td style="text-align: center;">SVM</td>
</tr>
<tr>
<td style="text-align: left;">DANN</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">$\mathbf{. 8 7}$</td>
<td style="text-align: center;">$\mathbf{. 8 3}$</td>
</tr>
<tr>
<td style="text-align: left;">NN</td>
<td style="text-align: center;">.13</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">.63</td>
</tr>
<tr>
<td style="text-align: left;">SVM</td>
<td style="text-align: center;">.17</td>
<td style="text-align: center;">.37</td>
<td style="text-align: center;">.50</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;">mSDA representations</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">DANN</td>
<td style="text-align: center;">NN</td>
<td style="text-align: center;">SVM</td>
</tr>
<tr>
<td style="text-align: left;">DANN</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">$\mathbf{. 9 2}$</td>
<td style="text-align: center;">$\mathbf{. 8 8}$</td>
</tr>
<tr>
<td style="text-align: left;">NN</td>
<td style="text-align: center;">.08</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">.62</td>
</tr>
<tr>
<td style="text-align: left;">SVM</td>
<td style="text-align: center;">.12</td>
<td style="text-align: center;">.38</td>
<td style="text-align: center;">.50</td>
</tr>
</tbody>
</table>
<p>(b) Pairwise Poisson binomial test</p>
<p>Table 1: Classification accuracy on the Amazon reviews data set, and Pairwise Poisson binomial test.</p>
<ul>
<li>For the DANN algorithm, the adaptation parameter $\lambda$ is chosen among 9 values between $10^{-2}$ and 1 on a logarithmic scale. The hidden layer size $l$ is either 50 or 100 . Finally, the learning rate $\mu$ is fixed at $10^{-3}$.</li>
<li>For the NN algorithm, we use exactly the same hyper-parameters grid and training procedure as DANN above, except that we do not need an adaptation parameter. Note that one can train NN by using the DANN implementation (Algorithm 1) with $\lambda=0$.</li>
<li>For the SVM algorithm, the hyper-parameter $C$ is chosen among 10 values between $10^{-5}$ and 1 on a logarithmic scale. This range of values is the same as used by Chen et al. (2012) in their experiments.</li>
</ul>
<p>As presented at Section 5.1.2, we used reverse cross validation selecting the hyper-parameters for all three learning algorithms, with early stopping as the stopping criterion for DANN and NN .</p>
<p>The "Original data" part of Table 1a shows the target test accuracy of all algorithms, and Table 1b reports the probability that one algorithm is significantly better than the others according to the Poisson binomial test (Lacoste et al., 2012). We note that DANN has a significantly better performance than NN and SVM, with respective probabilities $\mathbf{0 . 8 7}$ and $\mathbf{0 . 8 3}$. As the only difference between DANN and NN is the domain adaptation regularizer, we conclude that our approach successfully helps to find a representation suitable for the target domain.</p>
<h1>5.1.4 Combining DANN with Denoising Autoencoders</h1>
<p>We now investigate on whether the DANN algorithm can improve on the representation learned by the state-of-the-art Marginalized Stacked Denoising Autoencoders (mSDA) proposed by Chen et al. (2012). In brief, mSDA is an unsupervised algorithm that learns a new robust feature representation of the training samples. It takes the unlabeled parts of both source and target samples to learn a feature map from input space $X$ to a new representation space. As a denoising autoencoders algorithm, it finds a feature representation from which one can (approximately) reconstruct the original features of an example from its noisy counterpart. Chen et al. (2012) showed that using mSDA with a linear SVM classifier reaches state-of-the-art performance on the Amazon reviews data sets. As an alternative to the SVM, we propose to apply our Shallow DANN algorithm on the same representations generated by mSDA (using representations of both source and target samples). Note that, even if mSDA and DANN are two representation learning approaches, they optimize different objectives, which can be complementary.</p>
<p>We perform this experiment on the same Amazon reviews data set described in the previous subsection. For each source-target domain pair, we generate the mSDA representations using a corruption probability of $50 \%$ and a number of layers of 5 . We then execute the three learning algorithms (DANN, NN, and SVM) on these representations. More precisely, following the experimental procedure of Chen et al. (2012), we use the concatenation of the output of the 5 layers and the original input as the new representation. Thus, each example is now encoded in a vector of 30000 dimensions. Note that we use the same grid search as in the previous Subsection 5.1.3, but use a learning rate $\mu$ of $10^{-4}$ for both DANN and the NN. The results of "mSDA representation" columns in Table 1a confirm that combining mSDA and DANN is a sound approach. Indeed, the Poisson binomial test shows that DANN has a better performance than the NN and the SVM, with probabilities $\mathbf{0 . 9 2}$ and $\mathbf{0 . 8 8}$ respectively, as reported in Table 1b. We note however that the standard NN and the SVM find the best solution on respectively the second and the fourth tasks. This suggests that DANN and mSDA adaptation strategies are not fully complementary.</p>
<h3>5.1.5 Proxy Distance</h3>
<p>The theoretical foundation of the DANN algorithm is the domain adaptation theory of BenDavid et al. $(2006,2010)$. We claimed that DANN finds a representation in which the source and the target example are hardly distinguishable. Our toy experiment of Section 5.1.1 already points out some evidence for that and here we provide analysis on real data. To do so, we compare the Proxy $\mathcal{A}$-distance (PAD) on various representations of the Amazon Reviews data set; these representations are obtained by running either NN, DANN, mSDA,</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: Proxy $\mathcal{A}$-distances (PAD). Note that the PAD values of mSDA representations are symmetric when swapping source and target samples.
or mSDA and DANN combined. Recall that PAD, as described in Section 3.2, is a metric estimating the similarity of the source and the target representations. More precisely, to obtain a PAD value, we use the following procedure: (1) we construct the data set $U$ of Equation (2) using both source and target representations of the training samples; (2) we randomly split $U$ in two subsets of equal size; (3) we train linear SVMs on the first subset of $U$ using a large range of $C$ values; (4) we compute the error of all obtained classifiers on the second subset of $U$; and (5) we use the lowest error to compute the PAD value of Equation (3).</p>
<p>Firstly, Figure 3a compares the PAD of DANN representations obtained in the experiments of Section 5.1.3 (using the hyper-parameters values leading to the results of Table 1) to the PAD computed on raw data. As expected, the PAD values are driven down by the DANN representations.</p>
<p>Secondly, Figure 3b compares the PAD of DANN representations to the PAD of standard NN representations. As the PAD is influenced by the hidden layer size (the discriminating power tends to increase with the representation length), we fix here the size to 100 neurons for both algorithms. We also fix the adaptation parameter of DANN to $\lambda \simeq 0.31$; it was the value that has been selected most of the time during our preceding experiments on the Amazon Reviews data set. Again, DANN is clearly leading to the lowest PAD values.</p>
<p>Lastly, Figure 3c presents two sets of results related to Section 5.1.4 experiments. On one hand, we reproduce the results of Chen et al. (2012), which noticed that the mSDA representations have greater PAD values than original (raw) data. Although the mSDA approach clearly helps to adapt to the target task, it seems to contradict the theory of BenDavid et al.. On the other hand, we observe that, when running DANN on top of mSDA (using the hyper-parameters values leading to the results of Table 1), the obtained representations have much lower PAD values. These observations might explain the improvements provided by DANN when combined with the mSDA procedure.</p>
<h1>5.2 Experiments with Deep Networks on Image Classification</h1>
<p>We now perform extensive evaluation of a deep version of DANN (see Subsection 4.2) on a number of popular image data sets and their modifications. These include large-scale data sets of small images popular with deep learning methods, and the Office data sets (Saenko et al., 2010), which are a de facto standard for domain adaptation in computer vision, but have much fewer images.</p>
<h3>5.2.1 BASELINES</h3>
<p>The following baselines are evaluated in the experiments of this subsection. The source-only model is trained without consideration for target-domain data (no domain classifier branch included into the network). The train-on-target model is trained on the target domain with class labels revealed. This model serves as an upper bound on DA methods, assuming that target data are abundant and the shift between the domains is considerable.</p>
<p>In addition, we compare our approach against the recently proposed unsupervised DA method based on subspace alignment (SA) (Fernando et al., 2013), which is simple to setup and test on new data sets, but has also been shown to perform very well in experimental comparisons with other "shallow" DA methods. To boost the performance of this baseline, we pick its most important free parameter (the number of principal components) from the range ${2, \ldots, 60}$, so that the test performance on the target domain is maximized. To apply SA in our setting, we train a source-only model and then consider the activations of the last hidden layer in the label predictor (before the final linear classifier) as descriptors/features, and learn the mapping between the source and the target domains (Fernando et al., 2013).</p>
<p>Since the SA baseline requires training a new classifier after adapting the features, and in order to put all the compared settings on an equal footing, we retrain the last layer of the label predictor using a standard linear SVM (Fan et al., 2008) for all four considered methods (including ours; the performance on the target domain remains approximately the same after the retraining).</p>
<p>For the Office data set (Saenko et al., 2010), we directly compare the performance of our full network (feature extractor and label predictor) against recent DA approaches using previously published results.</p>
<h3>5.2.2 CNN architectures and Training Procedure</h3>
<p>In general, we compose feature extractor from two or three convolutional layers, picking their exact configurations from previous works. More precisely, four different architectures were used in our experiments. The first three are shown in Figure 4. For the Office domains, we use pre-trained AlexNet from the Caffe-package (Jia et al., 2014). The adaptation architecture is identical to Tzeng et al. (2014). ${ }^{5}$</p>
<p>For the domain adaption component, we use three $(x \rightarrow 1024 \rightarrow 1024 \rightarrow 2)$ fully connected layers, except for MNIST where we used a simpler $(x \rightarrow 100 \rightarrow 2)$ architecture to speed up the experiments. Admittedly these choices for domain classifier are arbitrary, and better adaptation performance might be attained if this part of the architecture is tuned.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" />
(a) MNIST architecture; inspired by the classical LeNet-5 (LeCun et al., 1998).
<img alt="img-5.jpeg" src="img-5.jpeg" />
(b) SVHN architecture; adopted from Srivastava et al. (2014).
<img alt="img-6.jpeg" src="img-6.jpeg" />
(c) GTSRB architecture; we used the single-CNN baseline from Cireşan et al. (2012) as our starting point.</p>
<p>Figure 4: CNN architectures used in the experiments. Boxes correspond to transformations applied to the data. Color-coding is the same as in Figure 1.</p>
<p>For the loss functions, we set $\mathcal{L}<em d="d">{y}$ and $\mathcal{L}</em>$-norm restriction when we train the SVHN architecture.}$ to be the logistic regression loss and the binomial cross-entropy respectively. Following Srivastava et al. (2014) we also use dropout and $\ell_{2</p>
<p>The other hyper-parameters are not selected through a grid search as in the small scale experiments of Section 5.1, which would be computationally costly. Instead, the learning rate is adjusted during the stochastic gradient descent using the following formula:</p>
<p>$$
\mu_{p}=\frac{\mu_{0}}{(1+\alpha \cdot p)^{\beta}}
$$</p>
<p>where $p$ is the training progress linearly changing from 0 to $1, \mu_{0}=0.01, \alpha=10$ and $\beta=0.75$ (the schedule was optimized to promote convergence and low error on the source domain). A momentum term of 0.9 is also used.</p>
<p>The domain adaptation parameter $\lambda$ is initiated at 0 and is gradually changed to 1 using the following schedule:</p>
<p>$$
\lambda_{p}=\frac{2}{1+\exp (-\gamma \cdot p)}-1
$$</p>
<p>where $\gamma$ was set to 10 in all experiments (the schedule was not optimized/tweaked). This strategy allows the domain classifier to be less sensitive to noisy signal at the early stages of the training procedure. Note however that these $\lambda_{p}$ were used only for updating the feature</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ol>
<li>A 2-layer domain classifier $(x \rightarrow 1024 \rightarrow 1024 \rightarrow 2)$ is attached to the 256 -dimensional bottleneck of fc 7 .</li>
</ol>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>