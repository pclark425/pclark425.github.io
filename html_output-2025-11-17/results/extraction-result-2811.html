<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2811 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2811</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2811</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-71.html">extraction-schema-71</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-268445573</p>
                <p><strong>Paper Title:</strong> LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot</p>
                <p><strong>Paper Abstract:</strong> This paper presents LaSofa, an avant-garde interactive sofa that revolutionizes the concept of human-furniture interaction by integrating fantasy storytelling with conventional furniture design. LaSofa is equipped with pressure sensors that recognize user interactions, which in turn trigger character dialogues and adventure narratives set in an embedded fantasy world. These narratives are dynamically generated by advanced large language models (LLMs) and are delivered through state-of-the-art audio technology to create an enveloping auditory experience. This integration not only embodies the convergence of technology and storytelling within the realm of furniture but also marks a pioneering venture into augmenting human experiences through interactive design. The paper elaborates on the genesis, architecture, and prospective influence of LaSofa in the domains of interactive storytelling and innovative furniture design.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2811.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2811.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LIGHT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LIGHT (text-based fantasy adventure game)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A text-based fantasy adventure environment cited in the paper where LLMs are used to train goal-driven agents that speak and act within the game world.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>goal-driven agents in LIGHT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Described as agents trained with LLMs using pre-training and reinforcement learning to behave and communicate in the LIGHT fantasy environment; the paper only references their use for goal-driven speaking and acting, without implementation details.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td>LIGHT</td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td>Text-based fantasy adventure game; supports goal-driven agents that must act and communicate in a fantasy world (environment for dialogue and behavior learning).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>The paper notes that LLM-trained, RL-refined agents in LIGHT demonstrated enhanced behavior and communication in the environment, but provides no quantitative metrics or memory-specific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2811.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2811.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive Simulacra</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach where LLM-based agents record experiences in natural language, synthesize memories into higher-level reflections over time, and dynamically retrieve those memories to plan future behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative Agents: Interactive Simulacra</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>generative agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>LLM-based agents that log their experiences in natural language, periodically synthesize those logs into higher-level reflective summaries, and dynamically retrieve relevant memories to inform planning and future actions.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>experience logs / episodic memory with synthesized higher-level (reflective) summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Described at a conceptual level: agents store natural-language records of experiences, synthesize those records into higher-level reflections over time, and perform dynamic retrieval of these stored/synthesized memories to plan future behavior; implementation details (e.g., storage backend or vectorization) are not provided in this paper's mention.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dynamic retrieval of synthesized memories for planning (method unspecified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Memories are recorded continuously as experiences occur and are periodically synthesized into higher-level reflections (i.e., updated over time after experiences); exact scheduling/mechanism not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>Memory enables agents to record past experiences, form higher-level reflections, and retrieve these to plan future behaviors—implying improved coherence and planning ability, though no numerical evaluations are reported in this paper's mention.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2811.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2811.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory systems to play text games, including details about the memory architecture, the text games played, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LaSofa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prototype interactive sofa that uses GPT-4 to generate character-driven narratives; it maintains brief dialogue outlines in a Planning module that are reused to preserve story coherence across interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>sofa agents (e.g., Jack, Amy, Agent C, Agent E, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Architecture composed of Planning, Dialogue, and Plot Progression modules: sensor inputs (RFID and pressure sensor values) select which character agents to activate; the Planning module (GPT-4) generates settings, characters, and coded story outlines; the Dialogue module uses those planning outputs to prompt GPT-4 to produce spoken dialogues; after each dialogue GPT-4 writes a brief outline of key points which is integrated into the Planning module for future prompt generation; Plot Progression advances or ends plots after repeated activations to avoid repetition.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>outline-based episodic/dialogue memory (short-term narrative outlines stored in the Planning module)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Memory is implemented as an Outline section within the Planning module: after each generated dialogue GPT-4 produces a concise outline of key points which is stored in the Planning module's Outline and reused in subsequent prompt construction to maintain coherence and reduce token usage; Plot Progression uses stored interaction counts/outlines to trigger narrative advancement when an agent is activated repeatedly.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Explicit reuse/inclusion of the stored Outline from the Planning module into future prompts (i.e., direct re-prompting of stored outline content); no vector retrieval backend or similarity search is described.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_strategy</strong></td>
                            <td>Outlines are written and integrated after each dialogue interaction; Plot Progression triggers further updates when the same agent is activated more than three times to advance the plot and avoid repetition.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_benchmark</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>game_characteristics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory_effectiveness</strong></td>
                            <td>The paper reports that integrating brief outlines into the Planning module improves narrative continuity and reduces token calls, and that the Plot Progression mechanism prevents repetitive content; these claims are qualitative and based on design rationale and a small pilot study rather than quantitative benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds <em>(Rating: 2)</em></li>
                <li>Generative Agents: Interactive Simulacra <em>(Rating: 2)</em></li>
                <li>Language Models for Communication Games: An Empirical Study on Werewolf <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2811",
    "paper_id": "paper-268445573",
    "extraction_schema_id": "extraction-schema-71",
    "extracted_data": [
        {
            "name_short": "LIGHT",
            "name_full": "LIGHT (text-based fantasy adventure game)",
            "brief_description": "A text-based fantasy adventure environment cited in the paper where LLMs are used to train goal-driven agents that speak and act within the game world.",
            "citation_title": "How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds",
            "mention_or_use": "mention",
            "agent_name": "goal-driven agents in LIGHT",
            "agent_description": "Described as agents trained with LLMs using pre-training and reinforcement learning to behave and communicate in the LIGHT fantasy environment; the paper only references their use for goal-driven speaking and acting, without implementation details.",
            "base_llm": null,
            "uses_memory": null,
            "memory_type": null,
            "memory_architecture": null,
            "memory_capacity": null,
            "memory_retrieval_method": null,
            "memory_update_strategy": null,
            "text_game_benchmark": "LIGHT",
            "game_characteristics": "Text-based fantasy adventure game; supports goal-driven agents that must act and communicate in a fantasy world (environment for dialogue and behavior learning).",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "The paper notes that LLM-trained, RL-refined agents in LIGHT demonstrated enhanced behavior and communication in the environment, but provides no quantitative metrics or memory-specific claims.",
            "uuid": "e2811.0",
            "source_info": {
                "paper_title": "LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive Simulacra",
            "brief_description": "An approach where LLM-based agents record experiences in natural language, synthesize memories into higher-level reflections over time, and dynamically retrieve those memories to plan future behavior.",
            "citation_title": "Generative Agents: Interactive Simulacra",
            "mention_or_use": "mention",
            "agent_name": "generative agents",
            "agent_description": "LLM-based agents that log their experiences in natural language, periodically synthesize those logs into higher-level reflective summaries, and dynamically retrieve relevant memories to inform planning and future actions.",
            "base_llm": null,
            "uses_memory": true,
            "memory_type": "experience logs / episodic memory with synthesized higher-level (reflective) summaries",
            "memory_architecture": "Described at a conceptual level: agents store natural-language records of experiences, synthesize those records into higher-level reflections over time, and perform dynamic retrieval of these stored/synthesized memories to plan future behavior; implementation details (e.g., storage backend or vectorization) are not provided in this paper's mention.",
            "memory_capacity": null,
            "memory_retrieval_method": "Dynamic retrieval of synthesized memories for planning (method unspecified in this paper)",
            "memory_update_strategy": "Memories are recorded continuously as experiences occur and are periodically synthesized into higher-level reflections (i.e., updated over time after experiences); exact scheduling/mechanism not specified here.",
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "Memory enables agents to record past experiences, form higher-level reflections, and retrieve these to plan future behaviors—implying improved coherence and planning ability, though no numerical evaluations are reported in this paper's mention.",
            "uuid": "e2811.1",
            "source_info": {
                "paper_title": "LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "LaSofa",
            "name_full": "LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot",
            "brief_description": "A prototype interactive sofa that uses GPT-4 to generate character-driven narratives; it maintains brief dialogue outlines in a Planning module that are reused to preserve story coherence across interactions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "sofa agents (e.g., Jack, Amy, Agent C, Agent E, etc.)",
            "agent_description": "Architecture composed of Planning, Dialogue, and Plot Progression modules: sensor inputs (RFID and pressure sensor values) select which character agents to activate; the Planning module (GPT-4) generates settings, characters, and coded story outlines; the Dialogue module uses those planning outputs to prompt GPT-4 to produce spoken dialogues; after each dialogue GPT-4 writes a brief outline of key points which is integrated into the Planning module for future prompt generation; Plot Progression advances or ends plots after repeated activations to avoid repetition.",
            "base_llm": "GPT-4",
            "uses_memory": true,
            "memory_type": "outline-based episodic/dialogue memory (short-term narrative outlines stored in the Planning module)",
            "memory_architecture": "Memory is implemented as an Outline section within the Planning module: after each generated dialogue GPT-4 produces a concise outline of key points which is stored in the Planning module's Outline and reused in subsequent prompt construction to maintain coherence and reduce token usage; Plot Progression uses stored interaction counts/outlines to trigger narrative advancement when an agent is activated repeatedly.",
            "memory_capacity": null,
            "memory_retrieval_method": "Explicit reuse/inclusion of the stored Outline from the Planning module into future prompts (i.e., direct re-prompting of stored outline content); no vector retrieval backend or similarity search is described.",
            "memory_update_strategy": "Outlines are written and integrated after each dialogue interaction; Plot Progression triggers further updates when the same agent is activated more than three times to advance the plot and avoid repetition.",
            "text_game_benchmark": null,
            "game_characteristics": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": false,
            "memory_ablation_results": null,
            "comparison_with_other_memory_types": null,
            "key_findings_about_memory_effectiveness": "The paper reports that integrating brief outlines into the Planning module improves narrative continuity and reduces token calls, and that the Plot Progression mechanism prevents repetitive content; these claims are qualitative and based on design rationale and a small pilot study rather than quantitative benchmarks.",
            "uuid": "e2811.2",
            "source_info": {
                "paper_title": "LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds",
            "rating": 2,
            "sanitized_title": "how_to_motivate_your_dragon_teaching_goaldriven_agents_to_speak_and_act_in_fantasy_worlds"
        },
        {
            "paper_title": "Generative Agents: Interactive Simulacra",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra"
        },
        {
            "paper_title": "Language Models for Communication Games: An Empirical Study on Werewolf",
            "rating": 1,
            "sanitized_title": "language_models_for_communication_games_an_empirical_study_on_werewolf"
        }
    ],
    "cost": 0.010623249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot</p>
<p>Yu Meizhu Tongge 
Ya Chen 
Li 
Deehsiao Lew 
Kejin Yu </p>
<p>Tsinghua University</p>
<p>Tsinghua University Tsinghua University Haidian Qu
BeijingChina</p>
<p>Haidian Qu
BeijingChina</p>
<p>Haidian Qu
BeijingChina</p>
<p>Tsinghua University Tsinghua University Haidian Qu
BeijingChina</p>
<p>Haidian Qu
BeijingChina</p>
<p>LaSofa: Integrating Fantasy Storytelling in Human-Robot Interaction through an Interactive Sofa Robot
8A20690D107FBD51C7868CB0861F663710.1145/3610978.3640672Human-Robot InteractionStorytelling TechnologySensory ExperienceLarge Language ModelsFurniture Innovation
This paper presents LaSofa, an avant-garde interactive sofa that revolutionizes the concept of human-furniture interaction by integrating fantasy storytelling with conventional furniture design.LaSofa is equipped with pressure sensors that recognize user interactions, which in turn trigger character dialogues and adventure narratives set in an embedded fantasy world.These narratives are dynamically generated by advanced large language models (LLMs) and are delivered through state-of-the-art audio technology to create an enveloping auditory experience.This integration not only embodies the convergence of technology and storytelling within the realm of furniture but also marks a pioneering venture into augmenting human experiences through interactive design.The paper elaborates on the genesis, architecture, and prospective infuence of LaSofa in the domains of interactive storytelling and innovative furniture design.CCS CONCEPTS• Human-centered computing → Human computer interaction (HCI); • Computer systems organization → Robotics; • Computing methodologies → Natural language processing.</p>
<p>INTRODUCTION</p>
<p>People inherently possess a fondness for fantasy worlds, driven by their innate curiosity and desire to explore [4].Fantasy worlds can provide resistance to reality and spiritual regeneration, proving to be particularly valuable in today's high-stress context [14].Sofas, a primary furniture piece for relaxation in everyday life, are often seen in current home design as functional items meant to enhance physical comfort and visual aesthetics [6,9].However, people's daily use of sofas for sleeping, dreaming, watching TV, reading, and chatting transforms them into a space for fantasy and social interaction.Our goal is to integrate the concept of the fantasy world with traditional sofas, thereby altering the experience humans interact with sofas.This approach aims to meet not only physical but also psychological needs, ofering a novel form of human-robot interaction, where sofas are not merely passive objects but active participants in creating immersive, interactive experiences.Addressing this need, our paper introduces LaSofa, a pioneering robotic sofa that seamlessly integrates fantasy storytelling into its functionality.LaSofa is equipped with pressure sensors and is powered by LLMs, enabling it to initiate interactive narratives and dialogues.This integration transforms the user experience, ofering an immersive auditory environment and redefning the sofa from a mere piece of furniture to an interactive storytelling platform.This research contributes to the feld of human-robot interaction by demonstrating how the incorporation of fantasy and storytelling can enhance the functionality and user experience of robotic furniture.</p>
<p>RELATED WORKS</p>
<p>The integration of fantasy elements into interactive technology spans various domains, including narratives, the latest LLMs technology, and robotics.This section provides a concise overview of the relevant literature and technological advancements that underpin the development of LaSofa.</p>
<p>Fantasy Narratives and Interactive Games</p>
<p>A substantial body of research has explored the role of fantasy in novels, comics, movies, and games [5].These studies emphasize how fantasy worlds immerse individuals, sparking curiosity and a desire for exploration.The allure of these worlds lies in their capacity to ofer an escape from reality and to inspire imaginative thought.</p>
<p>Role-playing games (RPGs) are a prime example of how interactive storytelling can engage users.Research [10] notes that RPGs cater to individuals seeking escapism and adventure, ofering an alternative to mundane experiences.These games create intricate worlds where players can explore diferent facets of their personalities and decision-making skills.</p>
<p>Large Language Models in Storytelling and Gaming</p>
<p>Signifcant past research has revealed that Large Language Models (LLMs), a form of deep learning algorithm, possess the potential to create immersive fantasy experiences, like in storytelling[13].</p>
<p>In the text-based fantasy adventure game LIGHT, LLMs are employed to train goal-driven agents.These agents, through a combination of pre-training and reinforcement learning, have demonstrated enhanced behavior and communication within the game environment [1].In the context of Generative Agents, LLMs utilize natural language to comprehensively record an agent's experiences, synthesize these memories into higher-level refections over time, and dynamically retrieve them to plan future behaviors [8].LLMs have also shown impressive performance in communication games like Werewolf[12].</p>
<p>Robotics and Interactive Furniture</p>
<p>While the integration of fantasy in games is well-documented, its application in the feld of robotics, particularly in terms of physical engagement, remains less explored.There are discussions on how robot interactions, involving physical and tactile elements, difer signifcantly from virtual interactions [3].The development of robotic furniture, such as the Lift-Bit sofa, has shown functional advancements but lacks in providing comprehensive interactive experiences [2].Other interactive furniture pieces in the market are exploring various ways to engage users.The "Sparkle Bench" by NunoErin, for example, features LEDs and sensors that change color upon touch, creating an interactive visual experience [7].These designs showcase a trend in furniture towards interactivity and emotional engagement, beyond just functionality.</p>
<p>LASOFA SYSTEM BREAKDOWN</p>
<p>Bridging these gaps, this paper introduces LaSofa, a novel approach to integrating fantasy storytelling with functional furniture.LaSofa is equipped with pressure sensors and is powered by LLMs, enabling it to initiate interactive narratives and dialogues.</p>
<p>Interaction Design</p>
<p>Our interaction consists of two parts: When the "Tail " is picked up and brought close to other agent modules on the sofa, the robot begins to vibrate slightly.This vibration, with a "buzzing" sound, is as if the robot is being awakened.When touching robots of diferent personalities on the backrest, LaSofa provides varied auditory feedback according to the diferent personality identities of the pillow robots.LaSofa integrates RFID 1 technology within its robot modules, strategically concealed in the sofa's "Tail."This sophisticated use of RFID, which enables triggering from a distance, allows users to seamlessly initiate dialogues between the sofa and other agent modules [11].This feature enhances user interaction, making the experience more intuitive and engaging.</p>
<p>When users lie on LaSofa and embrace the "Tail", the sofa back's most pressured module triggers a conversation with the Tail's agent, recounting their adventure stories.If a user's posture presses on multiple modules, LaSofa selects for activation those at the edges of the pressure range, typically under hands and feet in a stretched posture, with up to two modules engaging in separate dialogues with the "Tail".As a result, the agents activated on LaSofa vary with each user's unique lying position.With distinct personalities and professions, these agents are activated at diferent frequencies based on posture-driven interactions, leading to a unique narrative journey for every LaSofa.This design ofers users a range of interactive experiences, forging an immersive adventure.3.2 System Architecture Design 3.2.1 Worldview Revealed.We aim to immerse users in a fantastical, adventure-flled world through our Sofa Robots.In this narrative, the sofa transforms into a continent, with its small robot modules embodying diverse characters, each with unique stories.The Sofa Tail, acting as a protagonist, is central to most narratives, engaging with other characters that have rich social dynamics, including friendships, family ties, and feuds.This interactive storytelling is shaped by user interactions, leading to varied storylines.For instance, when a user interacts with diferent characters like Jack the Soldier 2 and Amy the Farmer 3 , the Large Language Model crafts unique stories, such as their joint quest at an Enchanted Forest.Users can explore diferent plot lines by maintaining positions or shifting interactions, like engaging with Joe the Merchant, ensuring a personalized and immersive experience with each session.</p>
<p>System Design.</p>
<p>We propose an interactive storytelling and dialogue generation system, consisting of Planning, Dialogue, and Plot Progression modules. 2 The main character, whose name, occupation, and personality are generated by GPT-4 3 Agent C, whose name, occupation, and personality are also generated by  The Planning module includes Settings, Characters, and Outline.Settings detail the fantasy world's layout, created using GPT-4 to generate weather, terrain, beliefs, and history.Key locations such as squares, bars, and homes are established as default dialogue orientations.The Characters section uses GPT-4 to develop 8 virtual characters, specifying their names, professions, and personalities, which shape their dialogue topics and tones.The Outline section employs GPT-4 to formulate concise, coded story outlines for the whole fantasy world and each character, laying the framework for dialogue trends.Upon user interaction, LaSofa activates when a user sits and picks up LaSofa's tail, signaled by an RFID sensor module, with the system picks up the value on each pressure sensor and decide which character should be activated.The Planning module is continuously reused to generate dialogue prompts in the Dialogue module.</p>
<p>The Dialogue module consists of Input, Dialogue, and Outline.When a user embraces LaSofa's tail and leans against a specifc module on the sofa's backrest, it activates dialogues between the represented agent and the protagonist, Jack.For instance, Amy could be triggered when the user lies in the middle.The Dialogue module then utilizes the Planning module for prompt input, generating dialogues that align with the story context, as well as the characters' personalities and tones, which are then played for the user.After the dialogue, GPT-4 formulates a brief outline of the key points, integrating them into the Planning module's Outline section for future reference and re-prompting.If the user shifts their position, activating a diferent agent, the module dynamically produces their dialogue.The Outline Section ensures coherence in each interaction, enhancing the narrative arc of each character within the broader story.</p>
<p>The fnal component, the Plot Progression module, activates when users trigger the same agent more than three times.This module prompts GPT-4 to advance plots and write the ending of the current events in the dialogue.The purpose of this module is to avoid repetitive content and user fatigue when the same agent is activated in short succession.</p>
<p>Our robot presents stories in a conversational format.Therefore, compared to similar storytelling algorithms[13], our research places a stronger emphasis on the quality of the generated dialogue.Our system framework provides a more optimized solution.In terms of efciency, it ensures both the continuity of content in each interaction and minimizes the need for token calls.Regarding the entertainment value of the stories, we delve deeper into character personalities and backgrounds to better portray each character's unique traits.Additionally, our Plot Progression module is a crucial design element aimed at enhancing the user experience.It helps prevent content repetition and ensures a fresh experience for users while listening to the story.</p>
<p>Through these three modules, along with the sofa's sensors and auditory system, the system crafts an immersive experience.This experience parallels a Lilliput-like world within the confnes of the sofa, thereby introducing an innovative and captivating interaction form of human-sofa interaction.</p>
<p>Characters</p>
<p>Portrait of Jack and others</p>
<p>Outline</p>
<p>Outline the main plot points.</p>
<p>Plot Progression</p>
<p>Lasofa turns off</p>
<p>Progress the storyline discussed in the current conversation and write the results of the current storyline.</p>
<p>Input</p>
<p>Plan module of Jack and agent C, relevant context</p>
<p>Dialogue</p>
<p>Speaker plays the generated dialogue.</p>
<p>Outline</p>
<p>Outline the main plot points of the dialogues.</p>
<p>Input</p>
<p>Plan module of Jack and agent E, relevant context</p>
<p>Dialogue</p>
<p>Speaker plays the generated dialogue.</p>
<p>Outline</p>
<p>Outline the main plot points of the dialogues.</p>
<p>…</p>
<p>Figure 4: System Design</p>
<p>FIELD STUDY</p>
<p>After developing the LaSofa prototype, we executed a pilot study and recruited fve participants to interact with LaSofa.Their reclining postures were recorded, and their experiences were subsequently interviewed.Observations on reclining postures indicated a natural preference among participants to embrace the "Tail", signifying this as a comfortable and accepted posture.Regarding module activation, the central agents-Agent E and Agent F-were most frequently activated in single-module scenarios, while the peripheral agents-Agent A, Agent C, Agent F, and Agent G-had higher activation in multimodule scenarios.These activation patterns provide insights for future enhancement of agent interrelationships.</p>
<p>Regarding user experience, the majority expressed fascination with the sofa's human-like conversation abilities.A minority desired ambient sounds alongside human voices.In response, we plan to integrate specifc sound efects into dialogues to enrich the immersive experience.Furthermore, we would like to introduce directional sound feld technology to create a spatial dimension in the audio experience, where the volume of voices changes with perceived distance, thus enhancing the sofa's ability to create a more spatially dynamic conversational environment.Looking ahead, we aim to expand LaSofa's human-machine interaction capabilities.Our focus will be on integrating multimodal interaction features, such as visual elements and gesture recognition, to enhance the immersive experience.Inspired by Interactive Drama Games, we also plan to introduce choice-based narrative elements, allowing users to infuence the story through an interactive tablet interface, further personalizing their experience.</p>
<p>We recognize the importance of understanding user experiences with LaSofa.Future studies will delve deeper into what aspects users fnd most appealing, whether it's the conversational abilities or other unique features of LaSofa.These insights will guide our ongoing development and refnement of the technology.</p>
<p>Additionally, we plan to integrate LaSofa into smart homes, enhancing its role as both an interactive storytelling device and an immersive audio platform, utilizing innovative sound feld localization technology for a richer auditory experience.</p>
<p>Figure 1 :
1
Figure 1: LaSofa robot prototype</p>
<p>Figure 2 :
2
Figure 2: Trigger mode When you lie down holding the pillow in the position shown in the left image, it simultaneously triggers "Tail" and agents C and F. The interaction among these three creates a story.If you change your posture to the one shown in the right image, it simultaneously triggers "Tail" and agents A and F, resulting in a diferent story through their mutual interaction.</p>
<p>Figure 3 :
3
Figure 3: Storytelling Example</p>
<p>Figure 5 :
5
Figure 5: Participants' Postures</p>
<p>Dialogue Jack and Joe talk around Plan Lasofa activated
User picking up the TailUser leaning on Agent C moduleUser leaning on Agent E module…User trigged the same agent×3DialogueSettingsWorld setting, weather, etc.Jack and Amy talk around
Radio Frequency Identifcation (RFID) refers to a wireless system comprised of two components: tags and readers.
Amy the FarmerAmyJack: "Amy, are you ready for this?The Enchanted Forest isn't for the faint of heart."Amy: "I know, Jack.After all, it's where we first met."Jack: "Understandable.But remember, the forest is full of mysteries and dangers.We need to stay alert.
Tim Rocktäschel, and Jason Weston. Prithviraj Ammanabrolu, Jakub Urbanek, Maithra Li, Arthur Szlam, arXiv:2010.00685How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds. 2020. 2020arXiv preprint</p>
<p>. Carlo Ratti, Associati , n.d.. Lift-Bit</p>
<p>Communication in Human-Robot Interaction. A Bonarini, 10.1007/s43154-020-00026-1Curr Robot Rep. 12020. 2020</p>
<p>Why imaginary worlds? The psychological foundations and cultural evolution of fctions with imaginary worlds. Edgar Dubourg, Nicolas Baumard, Behavioral and Brain Sciences. 45e2762022. 2022</p>
<p>Exploratory preferences explain the human fascination for imaginary worlds in fctional stories. E Dubourg, V Thouzeau, C De Dampierre, 10.1038/s41598-023-35151-2Sci Rep. 1386572023. 2023</p>
<p>Examining the Efects of the Industrial Revolution on Furniture. Şerif Tolga, Erdem , A+ Arch Design International Journal of Architecture and Design. 52019. 2019</p>
<p>Nunoerin, Sparkle Bench. </p>
<p>An introduction to RFID technology. Ji-Sung Park, John O' Brien, Chengyuan , Julian Cai, Meredith Ringel Morris, ; R Percy, Want, Michael S Liang, Bernstein, 10.1109/MPRV.2006.2Generative Agents: Interactive Simulacra. 5112006. 2023. 2006IEEE Pervasive Computing</p>
<p>Exploring Large Interface Software and Technology. 1-22. ; Y Of Human Behavior, S Xu, P Wang, F Li, X Luo, W Wang, Y Liu, Liu, Proceedings of the 36th Annual ACM Symposium on User. the 36th Annual ACM Symposium on User2023Language Models for Communication Games: An Empirical Study on Werewolf</p>
<p>Furniture design. Jerzy Smardzewski, arXiv:2309.046582015. 2023Springer6arXiv preprint</p>
<p>Re3: Generon their players: a discourse-based look at the evidence. A L Wadum, J Trier-Knudsen ; Kevin, Yuandong Yang, Nanyun Tian, Dan Peng, Klein, arXiv:2210.06774The Role-Playing ating longer stories with recursive reprompting and revision. arXiv preprint Society: Essays on the Popular Infuence of Role-Playing Games. 2015. 2022. 202213Psychological efects of fantasy games</p>
<p>. F Crocco, McFarland.in press</p>
<p>Why fantasy matters too much. Jack Zipes, The Journal of Aesthetic Education. 432009. 2009</p>            </div>
        </div>

    </div>
</body>
</html>