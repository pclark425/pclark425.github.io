<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1316 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1316</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1316</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-248377012</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2204.11138v1.pdf" target="_blank">Use of Multifidelity Training Data and Transfer Learning for Efficient Construction of Subsurface Flow Surrogate Models</a></p>
                <p><strong>Paper Abstract:</strong> Data assimilation presents computational challenges because many high-fidelity models must be simulated. Various deep-learning-based surrogate modeling techniques have been developed to reduce the simulation costs associated with these applications. However, to construct data-driven surrogate models, several thousand high-fidelity simulation runs may be required to provide training samples, and these computations can make training prohibitively expensive. To address this issue, in this work we present a framework where most of the training simulations are performed on coarsened geomodels. These models are constructed using a flow-based upscaling method. The framework entails the use of a transfer-learning procedure, incorporated within an existing recurrent residual U-Net architecture, in which network training is accomplished in three steps. In the first step. where the bulk of the training is performed, only low-fidelity simulation results are used. The second and third steps, in which the output layer is trained and the overall network is fine-tuned, require a relatively small number of high-fidelity simulations. Here we use 2500 low-fidelity runs and 200 high-fidelity runs, which leads to about a 90% reduction in training simulation costs. The method is applied for two-phase subsurface flow in 3D channelized systems, with flow driven by wells. The surrogate model trained with multifidelity data is shown to be nearly as accurate as a reference surrogate trained with only high-fidelity data in predicting dynamic pressure and saturation fields in new geomodels. Importantly, the network provides results that are significantly more accurate than the low-fidelity simulations used for most of the training. The multifidelity surrogate is also applied for history matching using an ensemble-based procedure, where accuracy relative to reference results is again demonstrated.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1316.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1316.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ADGPRS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Stanford Automatic Differentiation General Purpose Research Simulator (ADGPRS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose reservoir simulator used in this work to run both high-fidelity (fine-scale) and low-fidelity (coarse-scale) two-phase flow simulations (finite-volume discretization, Newton nonlinear solver, linear solvers, multisegment-well support).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallel General-purpose Reservoir Simulation with Coupled Reservoir Models and Multisegment Wells.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>ADGPRS</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Finite-volume reservoir simulator that solves two-phase immiscible subsurface flow (Darcy velocities, mass conservation) with Newton's method and linear solvers; supports well models (well index, BHP), used to generate training data for surrogate models at both fine and coarse scales.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>subsurface flow / reservoir simulation / fluid dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity (fine-scale) numerical simulator when applied to full-resolution geomodel (80×80×20 grid, 128,000 cells); also used to run low-fidelity simulations on upscaled coarse geomodels (20×20×10) but with the same solver.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-fidelity runs: solves full two-phase PDEs (mass conservation + Darcy flux), includes detailed permeability/porosity fields, relative-permeability curves, realistic well formulations, ~30–35 time steps, ~6 Newton iterations/time step, ~200 linear solves per run; low-fidelity runs: same numerical solver on upscaled transmissibility/well-index fields but coarse grid and missing relative-permeability upscaling effects.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>recurrent R-U-Net surrogate (pressure and saturation predictors)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A 3D recurrent residual U-Net (encoder–decoder residual CNN) combined with 3D convLSTM recurrent module; separate output layers for HF and LF outputs; trained via transfer learning with multifidelity simulation data.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict time-dependent pressure and saturation fields and compute well rates for two-phase oil–water subsurface flow; used within history matching/data assimilation (ESMDA).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Reference HF-only surrogate (trained with 2500 HF ADGPRS runs): median errors over 400 test cases — pressure 1.18%, saturation 3.70%. Multifidelity-trained surrogate (2500 LF ADGPRS runs + 200 HF ADGPRS runs): median errors — pressure 1.5%, saturation 5.5%.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Transfer from pretraining on low-fidelity simulator outputs (ADGPRS on upscaled geomodels) to high-fidelity predictions (ADGPRS fine-scale outputs) and to data-assimilation tasks (ESMDA posterior predictions).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>With 2500 LF + 200 HF runs: surrogate predictions nearly match HF-only surrogate (1.5% vs 1.1% pressure median error; 5.5% vs 3.5% saturation). Well-rate P10/P50/P90 posterior predictions from multifidelity surrogate closely match reference surrogate and HF simulations. Computational cost reduced ≈90% in HF-equivalent simulation units (C_ref=2500 → C_multi≈284) and GPU training time reduced ≈42% in accelerated regimen.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>LF-only ADGPRS simulations (on upscaled models) produce median errors of pressure 2.7% and saturation 19.4% (large saturation front smearing). HF-only surrogate (trained on 2500 HF runs) yields best accuracy (pressure ≈1.1%, saturation ≈3.5%). Multifidelity approach (2500 LF pretrain + 100–400 HF fine-tune; chosen 200 HF) yields accuracy close to HF-only while using far fewer HF runs; increasing HF samples beyond ≈100 produces only minor improvements, with 200 used as reasonable tradeoff.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper shows LF simulations must capture single-phase pressure/flow responses (via transmissibility upscaling) but explicitly lack upscaling of relative permeability; therefore LF data by itself is insufficient for sharp two-phase fronts and must be complemented by a modest number of HF simulations (≈100–400, recommended ≈200 here) to achieve HF-level surrogate accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>LF-only training produced high saturation errors and smeared fronts (median saturation error 19.4%). Using too few HF samples (<<100) gives worse transfer performance; no catastrophic failure modes reported beyond degraded accuracy when HF fine-tuning is insufficient. Specific missing physics in LF (no relative-permeability upscaling) is identified as the cause of two-phase inaccuracies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1316.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1316.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Global transmissibility upscaling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Flow-based global single-phase transmissibility upscaling (Crain implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A procedure that derives coarse-scale transmissibilities and well-indices from fine-scale single-phase steady-state pressure/flow solves to produce low-fidelity geomodels for cheaper simulation runs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extended Framework for Multifidelity Uncertainty Quantification in Subsurface Flow Systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>global transmissibility upscaling (procedure to produce LF geomodels)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Algorithm: solve global single-phase steady-state pressure on HF grid, compute fine-scale block-to-block flows, aggregate flows and volume-averaged pressures to define coarse transmissibilities T* and upscaled well-indices WI* for each LF interface/coarse block; implemented following Crain.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>subsurface flow / reservoir simulation / model reduction</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>low-fidelity (coarse-scale) geomodel generator — captures single-phase pressure and volumetric flow rates accurately at coarse scale; approximate for two-phase physics.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Upscaled LF geomodels include coarse porosity and directional transmissibilities (x,y,z) and upscaled well-indices; upscaling is based on single-phase pressure solves and aggregation of fine-scale flows; does NOT include upscaling of relative permeability (two-phase effects), leading to smoothed fronts and two-phase errors.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>LF geomodels (coarse-scale models) used for LF ADGPRS simulations</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Coarse-grid representations (here 20×20×10) derived from HF geomodels (80×80×20) used as inputs to ADGPRS to cheaply generate LF training outputs for surrogate pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Provide computationally cheap surrogate training data that approximate HF flow responses so the surrogate can learn spatial/temporal correlations before HF fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>2500 LF ADGPRS runs used for pretraining; LF runs are ≈1/32 cost of HF runs so 2500 LF ≈ 78 HF-equivalent runs. LF-only performance vs HF: median pressure error 2.7%, median saturation error 19.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Pretraining data source for transfer learning to HF surrogate outputs (fine-tuning on small HF dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>When used to pretrain encoder/convLSTM/decoder, followed by HF output-layer training and HF fine-tuning (200 HF runs), the resulting surrogate attains median errors near HF-only surrogate (pressure 1.5%, saturation 5.5%) and large overall simulation cost savings (~90%).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Upscaled-LF models are adequate to learn representations of spatial/temporal structure but insufficient to capture two-phase nonlinearities (relative-permeability effects); combining LF pretraining with a modest HF dataset (≈200 runs) provides best cost/accuracy tradeoff in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors conclude LF models must reliably capture single-phase pressure and flow characteristics; explicit statement that LF models omit relative-permeability upscaling and therefore require HF fine-tuning. They find ≈200 HF runs (in this 3D channelized example) are sufficient for high-quality transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>LF models lacking relative-permeability upscaling produce smeared saturation fronts and large saturation errors (≈19.4% median); using only LF data to train the surrogate yields noticeably worse predictions than when HF fine-tuning is included.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Multi-fidelity generative deep learning turbulent flows. <em>(Rating: 2)</em></li>
                <li>A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems. <em>(Rating: 2)</em></li>
                <li>On transfer learning of neural networks using bi-fidelity data for uncertainty propagation. <em>(Rating: 2)</em></li>
                <li>Transfer learning on multi-fidelity data. <em>(Rating: 2)</em></li>
                <li>Towards a predictor for CO2 plume migration using deep neural networks. <em>(Rating: 1)</em></li>
                <li>Deep-learning-based surrogate flow modeling and geological parameterization for data assimilation in 3D subsurface flow. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1316",
    "paper_id": "paper-248377012",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "ADGPRS",
            "name_full": "Stanford Automatic Differentiation General Purpose Research Simulator (ADGPRS)",
            "brief_description": "A general-purpose reservoir simulator used in this work to run both high-fidelity (fine-scale) and low-fidelity (coarse-scale) two-phase flow simulations (finite-volume discretization, Newton nonlinear solver, linear solvers, multisegment-well support).",
            "citation_title": "Parallel General-purpose Reservoir Simulation with Coupled Reservoir Models and Multisegment Wells.",
            "mention_or_use": "use",
            "simulator_name": "ADGPRS",
            "simulator_description": "Finite-volume reservoir simulator that solves two-phase immiscible subsurface flow (Darcy velocities, mass conservation) with Newton's method and linear solvers; supports well models (well index, BHP), used to generate training data for surrogate models at both fine and coarse scales.",
            "scientific_domain": "subsurface flow / reservoir simulation / fluid dynamics",
            "fidelity_level": "high-fidelity (fine-scale) numerical simulator when applied to full-resolution geomodel (80×80×20 grid, 128,000 cells); also used to run low-fidelity simulations on upscaled coarse geomodels (20×20×10) but with the same solver.",
            "fidelity_characteristics": "High-fidelity runs: solves full two-phase PDEs (mass conservation + Darcy flux), includes detailed permeability/porosity fields, relative-permeability curves, realistic well formulations, ~30–35 time steps, ~6 Newton iterations/time step, ~200 linear solves per run; low-fidelity runs: same numerical solver on upscaled transmissibility/well-index fields but coarse grid and missing relative-permeability upscaling effects.",
            "model_or_agent_name": "recurrent R-U-Net surrogate (pressure and saturation predictors)",
            "model_description": "A 3D recurrent residual U-Net (encoder–decoder residual CNN) combined with 3D convLSTM recurrent module; separate output layers for HF and LF outputs; trained via transfer learning with multifidelity simulation data.",
            "reasoning_task": "Predict time-dependent pressure and saturation fields and compute well rates for two-phase oil–water subsurface flow; used within history matching/data assimilation (ESMDA).",
            "training_performance": "Reference HF-only surrogate (trained with 2500 HF ADGPRS runs): median errors over 400 test cases — pressure 1.18%, saturation 3.70%. Multifidelity-trained surrogate (2500 LF ADGPRS runs + 200 HF ADGPRS runs): median errors — pressure 1.5%, saturation 5.5%.",
            "transfer_target": "Transfer from pretraining on low-fidelity simulator outputs (ADGPRS on upscaled geomodels) to high-fidelity predictions (ADGPRS fine-scale outputs) and to data-assimilation tasks (ESMDA posterior predictions).",
            "transfer_performance": "With 2500 LF + 200 HF runs: surrogate predictions nearly match HF-only surrogate (1.5% vs 1.1% pressure median error; 5.5% vs 3.5% saturation). Well-rate P10/P50/P90 posterior predictions from multifidelity surrogate closely match reference surrogate and HF simulations. Computational cost reduced ≈90% in HF-equivalent simulation units (C_ref=2500 → C_multi≈284) and GPU training time reduced ≈42% in accelerated regimen.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "LF-only ADGPRS simulations (on upscaled models) produce median errors of pressure 2.7% and saturation 19.4% (large saturation front smearing). HF-only surrogate (trained on 2500 HF runs) yields best accuracy (pressure ≈1.1%, saturation ≈3.5%). Multifidelity approach (2500 LF pretrain + 100–400 HF fine-tune; chosen 200 HF) yields accuracy close to HF-only while using far fewer HF runs; increasing HF samples beyond ≈100 produces only minor improvements, with 200 used as reasonable tradeoff.",
            "minimal_fidelity_discussion": "Paper shows LF simulations must capture single-phase pressure/flow responses (via transmissibility upscaling) but explicitly lack upscaling of relative permeability; therefore LF data by itself is insufficient for sharp two-phase fronts and must be complemented by a modest number of HF simulations (≈100–400, recommended ≈200 here) to achieve HF-level surrogate accuracy.",
            "failure_cases": "LF-only training produced high saturation errors and smeared fronts (median saturation error 19.4%). Using too few HF samples (&lt;&lt;100) gives worse transfer performance; no catastrophic failure modes reported beyond degraded accuracy when HF fine-tuning is insufficient. Specific missing physics in LF (no relative-permeability upscaling) is identified as the cause of two-phase inaccuracies.",
            "uuid": "e1316.0"
        },
        {
            "name_short": "Global transmissibility upscaling",
            "name_full": "Flow-based global single-phase transmissibility upscaling (Crain implementation)",
            "brief_description": "A procedure that derives coarse-scale transmissibilities and well-indices from fine-scale single-phase steady-state pressure/flow solves to produce low-fidelity geomodels for cheaper simulation runs.",
            "citation_title": "Extended Framework for Multifidelity Uncertainty Quantification in Subsurface Flow Systems",
            "mention_or_use": "use",
            "simulator_name": "global transmissibility upscaling (procedure to produce LF geomodels)",
            "simulator_description": "Algorithm: solve global single-phase steady-state pressure on HF grid, compute fine-scale block-to-block flows, aggregate flows and volume-averaged pressures to define coarse transmissibilities T* and upscaled well-indices WI* for each LF interface/coarse block; implemented following Crain.",
            "scientific_domain": "subsurface flow / reservoir simulation / model reduction",
            "fidelity_level": "low-fidelity (coarse-scale) geomodel generator — captures single-phase pressure and volumetric flow rates accurately at coarse scale; approximate for two-phase physics.",
            "fidelity_characteristics": "Upscaled LF geomodels include coarse porosity and directional transmissibilities (x,y,z) and upscaled well-indices; upscaling is based on single-phase pressure solves and aggregation of fine-scale flows; does NOT include upscaling of relative permeability (two-phase effects), leading to smoothed fronts and two-phase errors.",
            "model_or_agent_name": "LF geomodels (coarse-scale models) used for LF ADGPRS simulations",
            "model_description": "Coarse-grid representations (here 20×20×10) derived from HF geomodels (80×80×20) used as inputs to ADGPRS to cheaply generate LF training outputs for surrogate pretraining.",
            "reasoning_task": "Provide computationally cheap surrogate training data that approximate HF flow responses so the surrogate can learn spatial/temporal correlations before HF fine-tuning.",
            "training_performance": "2500 LF ADGPRS runs used for pretraining; LF runs are ≈1/32 cost of HF runs so 2500 LF ≈ 78 HF-equivalent runs. LF-only performance vs HF: median pressure error 2.7%, median saturation error 19.4%.",
            "transfer_target": "Pretraining data source for transfer learning to HF surrogate outputs (fine-tuning on small HF dataset).",
            "transfer_performance": "When used to pretrain encoder/convLSTM/decoder, followed by HF output-layer training and HF fine-tuning (200 HF runs), the resulting surrogate attains median errors near HF-only surrogate (pressure 1.5%, saturation 5.5%) and large overall simulation cost savings (~90%).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Upscaled-LF models are adequate to learn representations of spatial/temporal structure but insufficient to capture two-phase nonlinearities (relative-permeability effects); combining LF pretraining with a modest HF dataset (≈200 runs) provides best cost/accuracy tradeoff in this study.",
            "minimal_fidelity_discussion": "Authors conclude LF models must reliably capture single-phase pressure and flow characteristics; explicit statement that LF models omit relative-permeability upscaling and therefore require HF fine-tuning. They find ≈200 HF runs (in this 3D channelized example) are sufficient for high-quality transfer.",
            "failure_cases": "LF models lacking relative-permeability upscaling produce smeared saturation fronts and large saturation errors (≈19.4% median); using only LF data to train the surrogate yields noticeably worse predictions than when HF fine-tuning is included.",
            "uuid": "e1316.1"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Multi-fidelity generative deep learning turbulent flows.",
            "rating": 2,
            "sanitized_title": "multifidelity_generative_deep_learning_turbulent_flows"
        },
        {
            "paper_title": "A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems.",
            "rating": 2,
            "sanitized_title": "a_composite_neural_network_that_learns_from_multifidelity_data_application_to_function_approximation_and_inverse_pde_problems"
        },
        {
            "paper_title": "On transfer learning of neural networks using bi-fidelity data for uncertainty propagation.",
            "rating": 2,
            "sanitized_title": "on_transfer_learning_of_neural_networks_using_bifidelity_data_for_uncertainty_propagation"
        },
        {
            "paper_title": "Transfer learning on multi-fidelity data.",
            "rating": 2,
            "sanitized_title": "transfer_learning_on_multifidelity_data"
        },
        {
            "paper_title": "Towards a predictor for CO2 plume migration using deep neural networks.",
            "rating": 1,
            "sanitized_title": "towards_a_predictor_for_co2_plume_migration_using_deep_neural_networks"
        },
        {
            "paper_title": "Deep-learning-based surrogate flow modeling and geological parameterization for data assimilation in 3D subsurface flow.",
            "rating": 2,
            "sanitized_title": "deeplearningbased_surrogate_flow_modeling_and_geological_parameterization_for_data_assimilation_in_3d_subsurface_flow"
        }
    ],
    "cost": 0.0149685,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Use of Multifidelity Training Data and Transfer Learning for Efficient Construction of Subsurface Flow Surrogate Models</p>
<p>Su Jiang 
Department of Energy Resources Engineering
Stanford University
94305StanfordCAUSA</p>
<p>Louis J Durlofsky 
Department of Energy Resources Engineering
Stanford University
94305StanfordCAUSA</p>
<p>Use of Multifidelity Training Data and Transfer Learning for Efficient Construction of Subsurface Flow Surrogate Models
Surrogate modelTransfer learningMultifidelity dataReservoir simulationHistory matchingData assimilation
In subsurface flow settings, data assimilation/history matching presents computational challenges because many high-fidelity models must be simulated. Various deep-learning-based surrogate modeling techniques have been developed to reduce the simulation costs associated with these applications. However, to construct data-driven surrogate models, several thousand high-fidelity simulation runs may be required to provide training samples, and these computations can make training prohibitively expensive. To address this issue, in this work we present a framework where most of the training simulations are performed on coarsened (low-fidelity) geomodels. These models are constructed using a flow-based upscaling method. The framework entails the use of a transfer-learning procedure, incorporated within an existing recurrent residual U-Net architecture, in which network training is accomplished in three steps. In the first step. where the bulk of the training is performed, only low-fidelity simulation results are used. The second and third steps, in which the output layer is trained and the overall network is fine-tuned, require a relatively small number of high-fidelity simulations. Here we use 2500 low-fidelity runs and 200 high-fidelity runs, which leads to about a 90% reduction in training simulation costs. The method is applied for two-phase subsurface flow in 3D channelized systems, with flow driven by wells. The surrogate model trained with multifidelity data is shown to be nearly as accurate as a reference surrogate trained with only high-fidelity data in predicting dynamic pressure and saturation fields in new geomodels. Importantly, the network provides results that are significantly more accurate than the low-fidelity simulations used for most of the training. The multifidelity surrogate is also applied for history matching using an ensemble-based procedure, where accuracy relative to reference results is again demonstrated. problems with flow driven by wells. A residual U-Net and a convolutional long short-term memory (convLSTM) recurrent network were integrated to capture pressure and saturation fields at a number of discrete time steps. Tang et al.[2,3]extended the method to treat 3D oil-water systems with channelized geomodels. This procedure was later modified to model 3D CO 2 storage problems involving coupled flow and geomechanics (multiphysics) problems[4]. Wen et al.[16]introduced a residual U-Net surrogate model for predicting plume migration in CO 2 storage settings. This model, which was developed to be predictive over a wide range of flow and engineering parameters, was trained using 20,000 simulation runs. Transfer learning, with a few hundred additional training samples, was applied to fine-tune the model when new injection settings were considered.From the above discussion we see that, with sufficient training, data-driven surrogate models can predict complicated subsurface flow behavior, but the large number of highfidelity simulation runs required for training may limit their overall applicability. The use of multifidelity data (from high-fidelity and low-fidelity simulation output) for surrogate model construction can mitigate this problem. Geneva and Zabaras [17] developed a conditional invertible neural network to generate the probability distribution for high-fidelity turbulent flows conditioned to low-fidelity data. Physically accurate turbulent flows and statistics were constructed with a generative method trained with a reduced data set. Meng and Karniadakis[18]utilized multifidelity data to train a composite physics-informed neural network for unsaturated flow and reactive transport. Three networks were coupled to capture the linear and nonlinear correlations between the high and low-fidelity data. High accuracy was achieved through use of a small set of high-fidelity training data.Multifidelity data can be combined with transfer learning to construct surrogate models that provide high-fidelity predictions. This entails first training the surrogate model with low-fidelity simulation results and then using transfer learning to fine-tune the model with a small number of high-fidelity samples. De et al. [19]  applied transfer learning and developed a bi-fidelity-weighted learning for uncertainty propagation in engineering problems. For the process of bi-fidelity-weighted learning, a Gaussian process model was trained with a few high-fidelity samples. This provided synthetic data samples that were used to update the surrogate model trained with low-fidelity data. The use of a Gaussian process model may affect prediction accuracy for more complicated processes. Song and Tartakovsky [20] applied transfer learning to build a CNN-based surrogate model to solve two-phase flow problems in 2D Gaussian geomodels. The high-fidelity models had four times as many grid blocks as the low-fidelity models. The optimal ratio of low-fidelity to high-fidelity training runs was found to be around five.In this work, we develop a transfer-learning-based surrogate model that builds on the existing recurrent R-U-Net framework. The target application here is two-phase (well-driven) subsurface flow in 3D channelized systems. A global single-phase transmissibility upscaling procedure is applied to generate coarse-scale models from high-fidelity geomodels. Two-phase flow simulations performed on these models provide the low-fidelity training samples. In our approach, which differs from previous treatments, the high-fidelity geomodel is always used as network input, and the decoder output is also always at high-fidelity. In the first training step, 2500 low-fidelity simulation results are used, and the high-fidelity decoder output is fed to a separate low-fidelity output layer. In subsequent training steps, a small number (∼200) of high-fidelity simulation results are used to train a high-fidelity output layer, which enables the</p>
<p>Introduction</p>
<p>Accurate subsurface flow modeling is required to manage the production of energy resources and the storage of CO 2 . The key input in these frameworks is the geological model. Before the geomodel can be used for predictions or optimization, it must be calibrated such that simulation predictions match historical observations. The computations required in this history matching step (also referred to as data assimilation) can be very demanding, however, because thousands to millions of high-fidelity forward simulations must be performed. Surrogate modeling techniques can be very useful in this setting. Data-driven surrogate models represent an effective family of approaches for treating complex geological systems, though existing procedures require several thousand high-fidelity simulations to provide training samples. The computation associated with these training runs is one of the most expensive components of these procedures and may limit their application.</p>
<p>In recent work, a data-driven surrogate model for subsurface flow that employs residual U-Nets within a recurrent neural network (the overall model is referred to as recurrent R-U-Net) was developed and applied for history matching problems in oil production and CO 2 storage applications [1,2,3,4]. In the examples considered, which included up to 128,000 finite volume cells (with two unknowns per cell), 2000-3000 high-fidelity simulations were required as training samples to achieve accurate surrogate model predictions. Our goal in this work is to use high and low fidelity (referred to as multifidelity) simulation data in combination with transfer learning to accelerate surrogate model construction. This strategy enables us to perform ∼90% of the training simulations using low-fidelity models. The low-fidelity geomodels required for these simulations are constructed from high-fidelity geomodels using a flow-based upscaling procedure. A relatively small number of computationally demanding fine-scale simulations are required to fine-tune the surrogate model.</p>
<p>Many approaches have been developed for the construction of surrogate flow models using deep neural networks. We classify these approaches into two general (though overlapping) categories -physics-informed neural networks (PINNs) and data-driven deep-learning-based surrogate models. The training process for PINNs is conducted by minimizing the (physical) loss from the residual of the governing partial differential equations along with losses associated with boundary and initial conditions. The minimization process can be accomplished, in theory, without running any forward simulations, though simulation data are also commonly used. Raissi et al. [5] first proposed the idea of PINNs to approximate multiple different governing equations. Theory-guided neural networks (TgNNs), which are also physics-informed treatments, were developed by Wang et al. [6,7,8] and have been used to approximate 2D single-phase flow and other problems. PINN methods incorporating physical loss and simulation data mismatch have been successfully applied by He et al. [9] and Tartakovsky et al. [10,11] for single-phase flow and transport problems. Extending these methods to realistic 3D multiphase flow problems, or to multiphysics settings, will require additional development.</p>
<p>Data-driven deep-learning-based surrogate models are trained with labeled data. After training, these models provide a mapping from simulation input to output. These procedures may require a substantial amount of training data, though they have been applied in complicated flow settings. The spatial correlations are generally captured through use of convolutional neural networks (CNNs), and time evolution is modeled using approaches for the treatment of time series. Zhu and Zabaras [12] introduced a convolutional encoder-decoder framework to predict single-phase flow solutions. Mo et al. [13,14,15] further developed the framework through application of autoregressive strategies to predict temporal evolution and simulation output over long time frames. Applications of this framework include 2D CO 2 storage and 2D and 3D contaminant transport in channelized systems.</p>
<p>Tang et al. [1] developed a recurrent residual U-Net (R-U-Net) model for 2D oil-water overall network to provide high-fidelity pressure and saturation fields at a specified set of time steps. The surrogate model is then applied for history matching with an ESMDA (ensemble smoother with multiple data assimilation) procedure to generate posterior geomodels. The surrogate model predictions are compared to reference fine-scale simulations to assess the performance of the overall procedure. This paper proceeds as follows. In Section 2, we present the governing equations for the two-phase flow problem and describe the upscaling procedure, which enables the generation of multifidelity data. Then, in Section 3, we discuss the recurrent R-U-Net surrogate model and the use of transfer learning with multifidelity data for training. Surrogate model results for oil-water flow in 3D channelized systems are presented in Section 4. Comparisons between a surrogate model trained with multifidelity data, a surrogate model trained with only highfidelity data, and reference numerical simulation results are provided. In Section 5, the transfer-learning-based recurrent R-U-Net is combined with ESMDA to generate posterior models and predictions. Conclusions and suggestions for future work in this area appear in Section 6.</p>
<p>Governing Equations and Upscaling Procedure</p>
<p>In this section, we present the governing equations for two-phase subsurface flow problems and describe the upscaling procedure used to provide low-fidelity geomodels.</p>
<p>Governing Equations</p>
<p>The two-phase immiscible subsurface flow equations considered in this work are applicable for oil reservoir simulation (e.g., oil production via water injection) and to environmental remediation modeling involving water and a nonaqueous-phase liquid (NAPL) contaminant. The governing equations are
∇ · (ρ j u j ) + q j + ∂ ∂t (φρ j S j ) = 0, j = o, w,(1)
where j denotes phase, with o indicating oil phase and w water phase, ρ j is the density of phase j, u j is the Darcy velocity of phase j, q j denotes the source/sink term, φ is porosity and S j is the phase saturation (volume fraction). Darcy velocity u j is given by
u j = − kk rj (S j ) µ j (p j ) (∇p j − ρ j g∇z), j = o, w,(2)
where k represents the absolute permeability tensor, k rj is the relative permeability of phase j, µ j is the viscosity of phase j, p j is the pressure of phase j, g is gravitational acceleration, and z is depth. The relative permeability k rj and viscosity µ j are nonlinear functions of saturation and pressure, respectively. As is common in reservoir-scale simulations, we neglect capillary pressure in this work, so we have p = p w = p o . In the context of oil reservoir simulation, which is the setting considered here, the governing equations 1 and 2 are usually discretized using finite volume methods. Newton's method is applied to solve the discrete nonlinear equations. In this work, we use Stanford's Automatic Differentiation General Purpose Research Simulator ADGPRS [21] for both high-fidelity (HF) and low-fidelity (LF) simulation.</p>
<p>High-fidelity geomodels are denoted by m h ∈ R n h ×1 , where n h = n h x × n h y × n h z is the number of grid blocks in the HF model, with n h x , n h y and n h z the number of blocks in each coordinate direction (superscripts h and l indicate HF and LF). Note that here the geological parameters are represented in terms of a single quantity in each block, which defines (isotropic) permeability and porosity. The governing equations are solved, with m h as input, to provide HF solutions for the state variables. In oil-water problems these are pressure P h ∈ R n h ×nts and saturation S h ∈ R n h ×nts in every grid block at n ts simulation time steps. The simulation process can be represented as
x h = [P h , S h ] = g(m h ),(3)
where g represents the forward numerical simulation process and x h is the simulation output.</p>
<p>Well injection/production rates are primary quantities of interest in subsurface flow problems. These rates are computed through application of
(q w j ) i = W I i k rj ρ j µ j i (p i − p w i ),(4)
where (q w j ) i denotes the source/sink mass flow rate for phase j in well block i, p i denotes the well-block pressure, p w i denotes the wellbore pressure evaluated at the center of well block i, and W I i is the well index, computed as [22] 
W I i = 2πk i ∆z ln r 0 rw ,(5)
where k i is the well block permeability, ∆z is the thickness of the well block, r 0 = 0.2∆x for isotropic permeability and ∆x = ∆y, where ∆x and ∆y denote the dimensions of the well block. Eq. 5 is for a vertical well that fully penetrates the grid block. The wellbore pressure p w i , which varies with depth, is given by
p w i+1 = p w i + (ρ i,i+1 g)∆z i,i+1 .(6)
Here ρ i,i+1 is the average fluid density between well blocks i and i + 1 and ∆z i,i+1 denotes the difference in depth. Bottom-hole pressure (BHP), which will be specified in our simulations, corresponds to the wellbore pressure at the uppermost perforation.</p>
<p>Upscaling Procedure</p>
<p>A flow-based, single-phase global transmissibility upscaling procedure [23,24,25] is applied to generate coarse-scale (LF) models from fine-scale (HF) geomodels. The specific implementation used in this work is that of Crain [25]. This discussion follows [26], where upscaled models of the type used here were applied with error models for history matching in data space.</p>
<p>The first step in the upscaling process is the solution of the global single-phase steadystate pressure equation over the HF geomodel, i.e.,
∇ · (k∇p) = q,(7)
where the source term q, which corresponds to flow driven by wells, is expressed using the single-phase-flow analog of Eq. 4. From the HF pressure solution, the block-to-block volumetric flow rate f h α is computed via
f h α = T α (p h α + − p h α − ),(8)
where T α is the transmissibility, α denotes the interface of two fine-scale grid cells, and p h α ± denotes the pressures of the grid blocks on either side of interface α. Transmissibility, which is essentially the numerical analog of permeability, is given by T α = k α ∆y∆z/∆x, for cells connected in the x-direction, where k α is the harmonic average of the permeabilities of the blocks on either side of interface α. Analogous expressions define transmissibilities for cells connected in the y and z-directions. Given the HF pressure solution and flow rates through all HF block-to-block interfaces (Eq. 8), the coarse-scale (LF) transmissibilities and well indices can be constructed. Let β denote the interface between two LF grid blocks. The LF block pressures p l β ± for block β + and β − are estimated as the volume average ( p β ± ) of the fine-scale pressures p h that lie within the range of coarse blocks β + and β − . The flow rate f l β through LF interface β is estimated to be the sum of the fine-scale flow rates f h α over the range of interface β. In analogy to Eq. 8, the upscaled transmissibility T * β , over the LF interface β, is then given by
T * β = f l β p l β − − p l β + ≈ α∈β f h α p β − − p β + .(9)
The above estimate of LF transmissibility, which can be viewed as a volume average of the HF flow result, has been shown to provide accurate LF transmissibilities. It can be improved by iterating on the LF model to force very close agreement between α∈β f h α and f l β [24]. Treatments for handling anomalous T * β , which can occur when f l β and/or (p l β − − p l β + ) are very small, are discussed by Crain [25].</p>
<p>The upscaled well index W I * provides a transmissibility relating well injection/production rate to the difference in pressure between the wellbore and the well block. In analogy to Eq. 9, this is given by
W I * i = f w,l i p l i − p w i ≈ k∈i f w,h k p i − p w i ,(10)
where f w,l i denotes the flow rate between the well and LF well block i. This is simply the sum of the HF flow rates f w,h k in the range of coarse well-block i. The LF block pressure p l i is again the volume average of the corresponding HF block pressures.</p>
<p>The upscaling procedure is applied to generate LF geomodels m l ∈ R n l ×4 from highfidelity models m h ∈ R n h ×1 , where n l = n l x × n l y × n l z is the number of LF grid blocks. Here n l × 4 appears in the LF model dimension because this geomodel is characterized, in general, by LF porosity and different transmissibilities in the x, y and z-directions (even when the HF permeability field is isotropic). The two-phase flow simulation of the LF model can be expressed as
x l = [P l , S l ] = g(m l ),(11)
where P l ∈ R n l ×nts , S l ∈ R n l ×nts denote the pressure and saturation from LF simulation and x l represents LF simulation output. It is important to note that, because the LF model is constructed to capture single-phase pressures and flow rates, it is only approximate in twophase-flow settings (i.e., for the solution of Eqs. 1 and 2). In particular, the LF model used here does not include any upscaling of relative permeability effects, which can be important in coarse-scale models for two-phase flow. Thus we expect this representation to lead to some error relative to HF simulation results.</p>
<p>Network Training with Transfer Learning and Multifidelity Data</p>
<p>In this section we first provide a brief description of the recurrent R-U-Net surrogate model [1,2]. The use of transfer learning with multifidelity data to train the surrogate model is then described.</p>
<p>3D Recurrent Residual U-Net</p>
<p>With the existing deep-neural-network surrogate [2], the forward model can be expressed
asx h = [P h ,Ŝ h ] =g(m h , θ h ),(12)
wherex h represents the HF surrogate model output,P h ∈ R n h ×nt andŜ h ∈ R n h ×nt are the surrogate model pressure and saturation output,g denotes the surrogate model, and θ indicates the tunable network parameters. Here n t is the number of time steps at which surrogate model output is constructed. This is generally somewhat less than the number of simulation time steps n ts , e.g., in this work n ts ∼ 30-35, and n t = 10. The 3D recurrent R-U-Net architecture is used as the framework in this study. The residual U-Net, illustrated in Fig. 1, includes encoding and decoding networks to capture the spatial correlation in simulation input and output. The encoding network maps the input geomodel m h to low-dimensional latent features F 1 , . . . , F 5 . These feature maps are concatenated with the upsampled features in the decoding net, which facilitates the representation of multiscale effects in the solution.</p>
<p>The recurrent network is introduced to capture the temporal evolution of the simulation output. Figure 2 displays the recurrent component of the recurrent R-U-Net. The overall surrogate model includes the residual U-Net and a long short-term memory convolutional (convLSTM) recurrent network. The most compressed (and most global) feature F 5 is mapped to a time series of latent features, F 1 5 , F 2 5 , . . . , F nt 5 , by the convLSTM module. The feature F t 5 from the convLSTM (for t = 1, . . . , n t ), along with extracted features F 1 , . . . , F 4 from the encoding net, are combined as they move through the decoding net. The decoding net then generates a predictionx h,t for each of the n t time steps. Please see [1,2] for more details on the recurrent R-U-Net architecture.</p>
<p>The recurrent R-U-Net is trained by minimizing the loss between the simulated pressure and saturation fields and the corresponding surrogate model predictions. A set of forward simulations is performed with specified well locations and settings (BHPs in our case). The pressure and saturation data from n t time steps are collected. The minimization problem is </p>
<p>Encoding Net</p>
<p>Decoding Net 3D ConvLSTM Net given by
θ * = argmin θ 1 n smp 1 n t nsmp i=1 nt t=1 ||x h,t i − x h,t i || 2 2 + λ w 1 n smp 1 n t 1 n w nsmp i=1 nt t=1 nw w=1 ||x h,t,w i − x h,t,w i || 2 2 ,(13)
where n smp is the number of training samples, n w is the number of well blocks, and λ w represents the weighting for well-block data. The second term in Eq. 13 enables additional weighting at well blocks, which acts to improve the accuracy of pressure and saturation at well locations. This in turn improves the accuracy of well rate predictions (see Eq. 4), which are often the key observations used in data assimilation problems. Note that, following [2], separate networks are trained for pressure and saturation predictions.</p>
<p>Transfer Learning with Multifidelity Data</p>
<p>The training of the existing recurrent R-U-Net requires a large number of high-fidelity simulation runs as training samples. For example, in Tang et al. [3], 2500 runs were used to train the network to predict pressure and saturation in 3D channelized models containing 128,000 grid blocks. Each high-fidelity simulation for the 3D models considered in this work (which also contain 128,000 blocks) requires 20 minutes using ADGPRS on a single CPU. Practical 3D models, which may contain millions of grid blocks, may entail hours of computation for a single forward simulation. Thus there is a practical need to reduce the computational demands associated with network training.</p>
<p>The idea of transfer learning is to apply a neural network trained for one task to a different but related task. With the knowledge embodied in the neural network trained for the first task, the training cost for the second task may be substantially reduced. In the approach used here, the model is first trained with 2500 LF (coarse-scale) simulation runs. The coarsescale flow physics (i.e., simulation operator g) is the same as that on the fine scale, and the coarse-scale flow responses approximate (with some error) the HF simulation results. A relatively small number of HF simulations (100-400 are considered here) are then applied to fine-tune the neural networks and thus complete the HF surrogate model.</p>
<p>The transfer learning process involves three steps, which are shown in Fig. 3. First, we predict LF model outputx l from the input high-fidelity geomodel m h ∈ R n h ×1 ,
x l = [P l ,Ŝ l ] =g(m h , θ l ).(14)
Here θ l denotes the parameters for the LF neural networks. We train the surrogate model with n l smp = 2500 LF samples. The model parameters θ l = [θ l enc , θ l convLST M , θ l dec , θ l output ] include parameters for the encoder (θ l enc ), 3D convLSTM network (θ l convLST M ), decoder (θ l dec ), and output layers (θ l output ). Note that the LF geomodel m l is not input to the network (here or in subsequent steps). Rather, the network always works with m h , even when it is trained using x l .</p>
<p>In the Step 1 training process, the surrogate model is trained to capture spatial distributions and temporal evolution with parameters θ l enc , θ l convLST M , θ l dec . These parameters are associated with major portions of the recurrent R-U-Net.</p>
<p>Step 1 training also provides θ l output . In Step 2, parameters θ l enc , θ l convLST M and θ l dec are not updated, though the outputlayer parameters are modified. Specifically, in this step we map the geomodel input m h to HF simulation outputx h ∈ R n h ×nt througĥ
x h = [P h ,Ŝ h ] =g(m h , θ h ).(15)
The parameter set is now defined as θ h = [θ l enc , θ l convLST M , θ l dec , θ h output ]. The output layers with parameters θ h output are trained with n h smp HF samples. In this work, we evaluate network performance over the range n h smp = 100-400. Step 3 (c) Step 3: fine-tuning of full network with HF data Figure 3: Workflow for surrogate model training with multifidelity data and transfer learning.</p>
<p>The last step of the transfer learning procedure is the fine-tuning of all parameters using the n h smp HF samples. The parameter set is now denoted by
θ h = [θ h enc , θ h convLST M , θ h dec , θ h output ].
The parameters θ h enc , θ h convLST M and θ h dec are well-approximated by θ l enc , θ l convLST M and θ l dec , and an initial estimate for θ h output is already available, so this training step is relatively fast. Table 1 presents the detailed architecture of the 3D recurrent R-U-Net with HF and LF data. The input model is of dimensions n h x × n h y × n h z × 1. The HF and LF models share the same encoder, 3D convLSTM and decoder networks (though these are updated in Step 3). Different output layers are applied to map the decoder output to LF data (of dimensions n l x × n l y × n l z × 1 × n t ) and to HF data (dimension of n h x × n h y × n h z × 1 × n t ). The encoder is composed of four 'conv' blocks and two residual blocks. Each conv block includes one 3D convolutional layer, a batch normalization layer and ReLU nonlinear activation. The residual block includes one conv block with 64 filters of size 3 × 3 × 3 with stride (1, 1, 1), followed by one 3D convolutional layer and a batch normalization layer. The output of the residual block is the sum of the input of the residual block and the output of the second convolutional layer. The output of the encoder is fed to the 3D convLSTM net, which uses 64 filters of size 3 × 3 × 3 with stride (1, 1, 1) in all LSTM blocks. The output size of the 3D convLSTM net is ( n h x 4 , n h y 4 , n h z 4 , 64) for n t time steps. The decoder includes two residual blocks and four 'deconv' blocks. The deconv block is a stack of a 3D deconvolutional (upsampling) layer, a batch normalization layer and ReLU nonlinear activation. The decoder output is of dimensions (n h x , n h y , n h z , 16, n t ). 
n h z 4 , 64, n t ) residual block, 64 filters of size 3 × 3 × 3, stride 1 ( n h x 4 , n h y 4 , n h z 4 , 64, n t ) deconv, 64 filters of size 3 × 3 × 3, stride 1 ( n h x 4 , n h y 4 , n h z 4 , 64, n t ) deconv, 32 filters of size 3 × 3 × 3, stride 2 ( n h x 4 , n h y 4 , n h z 4 , 32, n t ) deconv, 32 filters of size 3 × 3 × 3, stride 1 ( n h x 2 , n h y 2 , n h z 2 , 32, n t ) deconv, 16 filters of size 3 × 3 × 3, stride 2 (n h x , n h y , n h z , 16, n t ) Output Layers (LF, θ l output ) multi conv, 1 filters of size 3 × 3 × 3, stride 2 (n l x , n l y , n l z , 1, n t ) Output Layers (HF, θ h output ) conv, 1 filters of size 3 × 3 × 3, stride 1 (n h x , n h y , n h z , 1, n t )
In the system considered in this work, the fine-scale (HF) geomodel is defined on a grid of dimensions 80 × 80 × 20, and it is upscaled to a 20 × 20 × 10 LF grid. For the LF surrogate model in Step 1, the output layers include two 3D convolutional layers to map the decoder output to LF output of dimensions (n l x , n l y , n l z , 1, n t ). The HF output layer in Steps 2 and 3 is a 3D convolutional layer that generates output of dimensions (n h x , n h y , n h z , 1, n t ).</p>
<p>Data preprocessing is essential, and the detailed treatments impact the performance of the overall procedure. In this study the network is applied to predict pressure and saturation for binary geomodels with wells operating under BHP control. The geomodels m h are defined in terms of ones (indicating the cell contains sand) and zeros (indicating shale/mud), so no preprocessing of m h is required. Saturation values are in range of 0 to 1, so these can also be used directly. For pressure normalization, the BHPs of the injectors and producers are taken as the maximum and minimum values, respectively. Min-max normalization is applied for both the LF and HF pressure output.</p>
<p>The minimization applied in Step 1 training, involving LF data and predictions, is expressed as
(θ l ) * = argmin θ l 1 n l smp 1 n t n l smp i=1 nt t=1 ||x l,t i − x l,t i || 2 2 + λ l w 1 n l smp 1 n t 1 n l w n l smp i=1 nt t=1 n l w w=1 ||x l,t,w i − x l,t,w i || 2 2 ,(16)
where λ l w represents the additional weight for the n l w well blocks in the LF model. For</p>
<p>Step 2 and Step 3 training (HF data and predictions) the minimization problem is
(θ h ) * = argmin θ h 1 n h smp 1 n t n h smp i=1 nt t=1 ||x h,t i − x h,t i || 2 2 + λ h w 1 n h smp 1 n t 1 n h w n h smp i=1 nt t=1 n h w w=1 ||x h,t,w i − x h,t,w i || 2 2 ,(17)
where λ h w is the well-block weighting for the n h w well blocks in the HF model. Pressure quantities in Eqs. 16 and 17 are normalized as described earlier. Following training, the surrogate model provides flow predictions for a new geomodel in about 0.05 seconds on a single GPU.</p>
<p>Surrogate Model Evaluation</p>
<p>In this section, we describe the problem setup and then present detailed results using the transfer-learning-based surrogate model. Comparisons with flow results from HF simulation, LF simulation, and a reference deep-learning surrogate procedure are provided.</p>
<p>Problem Setup</p>
<p>The 3D channelized system considered in this work corresponds to that used in [3], though the specific realizations here are all newly generated. The well types and completion intervals are also different from those in [3]. The models are binary and include channel sand and background mud/shale. The realizations are randomly generated through application of a convolutional neural network -principal component analysis (CNN-PCA) parameterization procedure [27]. The CNN-PCA representation itself is trained using reference realizations generated through application of geostatistical software (see [27] for details on the parameterization procedure).</p>
<p>The 3D CNN-PCA model in [3] is applied to generate the geological realizations used for training and testing. The fine-scale (HF) geomodels are defined on an 80 × 80 × 20 grid, with blocks of size 20 m × 20 m × 2 m. Figure 4 presents three geomodel realizations. Well locations are shown in Fig. 4(a). Porosity is set to 0.25 in sand facies and 0.1 in mud/shale facies. Permeability is prescribed as 2000 md for sand and 20 md for mud/shale. The realization in Fig. 4(c) is used for some of the results shown later in this section, and it also represents the 'true' model applied for history matching in Section 5.</p>
<p>The geological realizations are conditioned to facies type at well locations. In contrast to the setup in [3], here there are three injection wells (denoted I1 to I3) and five production wells (denoted P1 to P5), as shown in Fig. 4(a). The initial reservoir pressure is 325 bar.  The flow problem involves two immiscible fluids (oil and water). Figure 5 shows the oil-water relative permeability curves used for both the HF and LF flow simulations. The initial water and oil saturations are 0.1 and 0.9. Water viscosity is constant at 0.31 cp; oil viscosity varies with pressure and is 1.14 cp at 325 bar. All flow simulations are performed using ADGPRS [21]. The simulation time frame is 1000 days. The global transmissibility upscaling procedure described in Section 2.2 is applied to generate the LF models. These models are defined on grids of dimensions 20 × 20 × 10, which corresponds to an upscaling factor of 32.</p>
<p>Surrogate Model Training and Overall Performance</p>
<p>The process for generating the multifidelity data used for training is as follows. We generate 2500 HF binary geomodel realizations with CNN-PCA. These realizations are upscaled to LF models using the procedure described in Section 2.2. A total of n l smp = 2500 LF simulation runs are performed with ADGPRS. These represent the samples used in Step 1 of the training procedure. The pressure and saturation fields for these LF simulations are collected at n t = 10 time steps (specifically at 50, 100, 150, 300, 400, 500, 600, 700, 850 and 1000 days). Separate surrogate models are trained for pressure and saturation with these 2500 LF simulation results. The hyperparameters affecting performance include the learning rate, the weight on data at well blocks, the number of epochs, and the batch size. For</p>
<p>Step 1 of the training, we set λ l w = 20 and the batch size to 4. The networks are trained for 150 epochs using the ADAM optimizer [28] with an initial learning rate of 0.003.</p>
<p>The number of HF samples used for transfer learning affects the computational cost and performance of the surrogate model. It is useful to conduct numerical experiments to determine an optimal number of HF samples. We consider n h smp = 100, 200, 300 and 400 (representative) realizations selected from the full set of 2500 HF geomodels. These HF models are then simulated, and Steps 2 and 3 of the training framework are applied. It is important to note that even 400 HF training samples is not nearly enough to train the recurrent R-U-Net surrogate model (O(2500) samples are required).</p>
<p>The HF models to be simulated are selected through use of the clustering strategy suggested in [29]. Specifically, a K-means procedure is first applied on the normalized flow response data constructed from the full set of LF simulation results. A total of n h smp clusters are generated, and a k-medoids method is then used to select the 'centers' of the n h smp clusters. These (cluster center) realizations comprise the representative set. HF simulation is then performed on all n h smp realizations to provide the HF training data. The HF simulation results are used in Steps 2 and 3 of the training. Here λ h w is set to 1000. This increased weighting (λ l w = 20 in Step 1) is applied because we now have a much lower fraction of well blocks with pressure and saturation data (64/128, 000 = 0.0005 for HF in contrast to 32/4000 = 0.008 for LF), and because HF well data are especially important to capture. The initial learning rates are set to 0.003 (Step 2) and 0.001 (Step 3). We train the output layers for 200 epochs in Step 2 and fine-tune the model for 100 epochs in Step 3. Because a small number of HF samples are used in Steps 2 and 3, the training times for these steps are much smaller than that for Step 1. The detailed training times for the framework will be provided later.</p>
<p>For comparison purposes, we also train a reference recurrent R-U-Net surrogate model using only high-fidelity samples. The same original set of 2500 HF geomodels is used for this training. The HF networks (one for pressure and one for saturation) are trained for 150 epochs with an initial learning rate of 0.003.</p>
<p>A new set of n e = 400 HF geological realizations is then generated and simulated. These represent the test samples used to evaluate the performance of the transfer-learning-based surrogate model. The performance of the surrogate model is compared to HF simulation results. The relative error for pressure for test sample i, denoted δ i p , for i = 1, . . . , n e , is given by
δ i p = 1 n h n t n h j=1 nt t=1 |p t i,j − p t i,j | p max − p min .(18)
Here p t i,j is the HF pressure from simulation output in grid block j at time t for test sample i,p t i,j is the corresponding pressure output for the surrogate model, and p max and p min are the injector and producer BHPs (330 bar and 310 bar). The relative error for saturation is given by
δ i S = 1 n h n t n h j=1 nt t=1 |Ŝ t i,j − S t i,j | S t i,j ,(19)
for i = 1, . . . , n e , where S t i,j andŜ t i,j represent saturation from HF simulation and the surrogate model. The initial (and minimum) water saturation is 0.1, so the denominator in Eq. 19 does not approach zero.</p>
<p>Relative errors for pressure and saturation for the 400 test samples, computed using Eqs. 18 and 19, are shown in Figs. 6 and 7. These errors are presented as box plots. The top and bottom of each box show the P 75 and P 25 (75th and 25th percentile) relative errors, and the solid red line provides the P 50 result. The maximum and minimum relative errors are indicated by the lines extending beyond the boxes. In the figures, the blue boxes display the relative errors associated with LF (coarse-scale) simulation results. The yellow boxes indicate the relative errors for the reference surrogate model (average errors of 1.18% for pressure and 3.70% for saturation) -these represent the best performance that could be expected from the transfer-learning-based surrogate. The white boxes show the relative errors for the transferlearning-based surrogate model trained with different numbers of HF samples.  The relative errors for the LF simulation results (blue boxes) are computed by projecting the LF pressure or saturation solution to the 80 × 80 × 20 grid, which gives pressure or saturation fields that are constant over 4 × 4 × 2 regions. Equations analogous to Eqs. 18 and 19 are then applied to compute δ i p and δ i S , for i = 1, . . . , n e . Particularly in the case of saturation, the LF error is large. This is mainly due to errors around fluid fronts in the LF simulations.</p>
<p>A key observation from Figs. 6 and 7 is that the errors from the transfer-learning-based surrogate are considerably less than those from LF simulation. This accuracy is achieved even though the significant majority of the training is accomplished using LF models. Though there is a slight trend of decreasing relative error with increasing n h smp , the use of more than 100 HF samples has only a minor impact on results. For both pressure and saturation, the errors for the reference surrogate (yellow boxes) are less than those with the transfer-learningbased surrogate, as would be expected. The differences are relatively small, however.</p>
<p>In many subsurface flow problems, the flow rates associated with wells represent key quantities of interest. Here we calculate an aggregate relative well rate error δ i r as
δ i r = 1 N inj N inj j=1 T 0 |q w,inj j,i (t) − q w,inj j,i (t)|dt T 0 |(q w,inj j,i (t)|dt + 1 N prod N prod j=1 T 0 |q w,prod j,i (t) − q w,prod j,i (t)|dt T 0 |(q w,prod j,i (t)|dt + 1 N prod N prod j=1 T 0 |q o,prod j,i (t) − q o,prod j,i (t)|dt T 0 |(q o,prod j,i (t)|dt ,(20)
for i = 1, . . . , n e , where N inj and N prod are the number of injectors and producers and T is the total simulation time. Here q w,inj j,i (t) denotes the injection rate of injector j at time t for test sample i from HF simulation, andq w,inj j,i (t) is the corresponding injection rate for the surrogate model. Analogously, the quantities q w,prod j,i (t) and q o,prod j,i (t) are the HF water and oil production rates, andq w,prod j,i (t) andq o,prod j,i (t) are the corresponding production rates for the surrogate model. Figure 8 displays the aggregate relative well rate errors. These errors are larger than the pressure and saturation errors in Figs. 6 and 7, likely because well rates depend nonlinearly on predicted pressure and saturation values in just a few particular grid blocks (see Eq. 4). There is again a slight decrease in relative error with increasing n h smp . The maximum relative error, for example, decreases from 0.18 with n h smp = 100 to 0.15 for n h smp = 200, and then stays nearly constant with increasing n h smp . We thus conclude that 200 HF samples is a reasonable choice for this case. In future work, it may be worthwhile to investigate the detailed selection strategy and approaches for determining the optimal value of n h smp . In the remainder of this paper, we use n h smp = 200 in all transfer-learning-based surrogate results. </p>
<p>Computational Costs of Surrogate Model Construction</p>
<p>The computational cost of the transfer learning workflow includes the generation of LF and HF simulation data and the time for surrogate model training. Flow simulations and the upscaling computations are conducted with ADGPRS. As noted earlier, each HF simulation takes around 20 minutes on a single CPU. The overall cost for simulating 2500 HF samples is thus around 833 hours. In our assessment here, we evaluate simulation requirements in units of HF simulation runs. Thus, for the reference surrogate model, where all 2500 training runs are performed with HF simulation, the computational cost is C ref = 2500.</p>
<p>Linear solutions dominate the computational cost of the two-phase flow simulations performed in this work. Linear solvers ideally require O(N ) computation, where N is the number of equations/unknowns in the linear system (super-linear scaling occurs in many cases). In HF simulations, N = 2n h = 256, 000, while in LF simulations, N = 2n l = 8000. Both HF and LF simulations require ∼30-35 time steps with an average of ∼6 Newton iterations per time step (this relatively large number of Newton iterations results from taking large time steps). Thus ∼200 linear solutions are required for each (HF or LF) two-phase flow simulation run. The cost of simulating 2500 LF models is therefore about C LF = 2500 × 1 32 ≈ 78. Upscaling computations involve HF models, but only one linear solution with one equation/unknown is required. Thus the cost of upscaling 2500 models is about C upscale = 2500 × 1 200 × 1 2 ≈ 6.</p>
<p>The total simulation cost of generating multifidelity data, with n l smp = 2500 and n h smp = 200, can be estimated as C multi = 6 + 78 + 200 = 284. Compared to C ref = 2500, this represents a computational savings of nearly 90%. The estimated computational time for generating the multifidelity data is about 95 hours, compared to 833 hours with HF data. Note that super-linear scaling in the linear solver will lead to larger savings, while significant amounts of simulation overhead/startup time will lead to smaller savings.</p>
<p>The training time depends on the complexity of the surrogate model, the number of training samples, and the number of epochs required for convergence. We train two separate surrogate models for pressure and saturation in parallel on two Nvidia Tesla V100 GPUs. The training for the transfer learning framework includes training with LF samples, transfer learning training, and fine-tuning with HF samples. To achieve convergence, the Step 1 training requires 150 epochs. This can be reduced, however, by stopping this training early. Table 2 presents cost and accuracy results for HF training and two multifidelity training strategies. The training process for the reference HF surrogate model converges in 15 hours (150 epochs, 360 seconds per epoch). For the surrogate model trained with multifidelity data with Step 1 iterated until convergence (MF training), the Step 1 training cost is about the same as the full HF training cost. This is because these trainings involve networks of similar complexity and the same number of training samples and epochs. As indicated in the table, the total training time for Steps 2 and 3 is 1.66 hours, which gives an overall training time of 16.66 hours. This is slightly larger than the reference HF training time.</p>
<p>It is not necessary, however, to continue Step 1 training until convergence (150 epochs) since additional training with HF data will be performed. Accelerated training (right-most column of Table 2) entails stopping Step 1 training at 70 epochs, at which point training loss is acceptable, although the training has not fully converged. Overall training time is now reduced to 8.66 hours. Relative errors with this approach are incrementally greater, but the computational savings are substantial. In subsequent results, in all cases the surrogate model is trained using this accelerated process.</p>
<p>In summary, we see that the use of multifidelity data and transfer learning can lead to a nearly 90% reduction in the computations associated with the training simulations, and a savings of about 42% in training time. It is possible these speedups could be further improved with additional tuning, though this was not attempted here. </p>
<p>Pressure and Saturation Predictions</p>
<p>To assess the performance of the transfer-learning-based surrogate model trained with multifidelity data, we now compare pressure and saturation predictions to results from HF simulation and the reference surrogate model (trained with 2500 HF simulation runs). The three realizations in Fig. 4, which correspond to test-case realizations with relative pressure and saturation errors slightly larger than the median, are considered. Figure 9 shows the pressure fields for these three test cases at 400 days. The upper row displays the HF simulation results, the middle row shows results from the reference surrogate model, and the bottom row shows results from the transfer-learning-based surrogate model. There are noticeable differences in the pressure distributions between the three realizations, indicating a reasonable degree of variability over the test set. The reference surrogate model gives results that are visually close to the simulation results. The transfer-learning-based surrogate model also provides results that are in close visual agreement. Some discrepancies are evident, e.g., in the blue feature in the back right corner of the models in Fig. 9(i) and (c), though these are relatively minor.</p>
<p>Water saturation results for the same three realizations, at 1000 days (the end of the simulation), are presented in Fig. 10. We again observe variability between realizations and high accuracy in both the reference surrogate model and the transfer-learning-based surrogate model. The latter model is seen to provide sharp water saturation fronts, even though most of its training involves LF simulation results where fronts are diffused.</p>
<p>We next show pressure and saturation maps at 1000 days for one particular layer (layer 8) in the realization in Fig. 4(c). Figure 11(a) and (b) display the pressure fields from HF and LF simulation. In Fig. 11(b), the 20 × 20 LF result is mapped onto an 80 × 80 grid. Figure 11(c) and (d) show the pressure predictions from the two surrogate models. The reference surrogate results are in close agreement with the HF simulation result. Some differences are evident in the transfer-learning-based surrogate, though it is evident that some features that are not resolved in the LF simulation result in Fig. 11(b) are captured in the result in Fig. 11(d). Such details include the large yellow feature (midway in x, middle to bottom in y) and the light blue feature along the left edge (around the middle in y).</p>
<p>Analogous results for saturation appear in Fig. 12. The LF simulation result for this quantity, in Fig. 12(b), shows a high degree of smearing. The transfer-learning-based surrogate result in Fig. 12(d) is in close visual agreement with the HF simulation result, and it shows much better front resolution than the LF simulation result. This illustrates the ability of the multifidelity procedure to provide high-quality HF surrogate predictions with training that is largely based on LF simulation data.</p>
<p>We now present relative pressure and saturation error results for the 400 test samples. Figure 13 displays histograms of these errors, for pressure and saturation, for LF simulation and both surrogate model results. Errors are all relative to HF simulation results. The orange histograms show errors for the reference surrogate model predictions. These results are the most accurate, as expected, and display median pressure and saturation errors of 1.1% and 3.5%. The green histograms show relative errors for the LF simulation results. The median errors here are 2.7% and 19.4%. The errors for the surrogate model trained with multifidelity data (blue histograms) fall between the reference surrogate model errors and the LF simulation errors. Importantly, these errors (with medians 1.5% and 5.5%) are much closer to those of the reference surrogate model than to those from LF simulation. This again highlights the capabilities of the transfer-learning procedure.</p>
<p>Well Rate Statistics</p>
<p>Water injection rates and water and oil production rates are calculated from well-block pressure and saturation values and the specified BHP using Eqs. 4 and 5. We now present flow rate statistics evaluated over the 400 test samples. Figure 14 presents flow statistics for oil and water production rates (OPR and WPR) of producers P1 and P4. Results for the P 10 , P 50 and P 90 (10th, 50th and 90th percentile) rates are presented at n t = 10 time steps. The red dashed lines in all subplots in Fig. 14 represent the P 10 , P 50 , P 90 HF simulation results. The blue curves in the left column subplots show LF simulation results, while the black dash-dotted curves in the middle column present the reference surrogate results. The black solid lines in the right column display results for the transfer-learning-based surrogate trained with multifidelity data. From the left-column subplots, it is clear that the LF simulation results display some error relative to the HF results. Water production rates are systematically under-predicted in Fig. 14(d) and (j), and oil rates show discrepancies in Fig. 14(a) and (g). The reference surrogate model (trained with HF simulation data) provides accurate flow statistics for all quantities considered. The results for the surrogate trained with multifidelity data (right column) are quite close to the reference surrogate results shown in the middle column. This demonstrates the ability of the transfer learning framework to provide high-quality predictions for key well rate quantities.</p>
<p>Data Assimilation with Surrogate Model</p>
<p>In this section, we first describe the history matching framework, which involves the use of an ensemble smoother with multiple data assimilation (ESMDA) [30], with geomodels parameterized using CNN-PCA and flow responses determined using the transfer-learning- based surrogate model. We then present history matching results using this framework for a synthetic example.</p>
<p>ESMDA Procedure</p>
<p>The ESMDA-based history matching procedure in this work is the same as in [2,3], except here we use the transfer-learning-based surrogate instead of the (reference) recurrent R-U-Net model. CNN-PCA enables us to generate HF geological realizations m cnnpca ∈ R n h from lowdimensional latent variables ξ ∈ R N l , where N l denotes the dimension of the latent variables. For the case consider in this work, N l = 400, which is much less than the total number of HF grid blocks (n h = 128, 000). A geological realization in the history matching process is represented as m cnnpca (ξ). The resulting flow predictions d ∈ R N hm for the historical period, generated using the surrogate model, are denoted by d =f (m cnnpca (ξ)). Here N hm denotes the number of observations in the history matching period.</p>
<p>In the data assimilation procedure, we first sample latent variables from their prior distribution N (µ ξ , C ξ ), where µ ξ and C ξ denote the prior mean and covariance of ξ. ESMDA generates posterior distributions by assimilating data and updating the model parameters 
ξ k+1 i = ξ k i + C k ξ,d (C k d + α k C D ) −1 (d obs + √ α k e k i − d k i ),(21)
for i = 1, . . . , N r and k = 1, . . . , N a , where N r is the number of realizations considered and N a is the number of data assimilation steps. Here α k , k = 1, . . . , N a , are the inflation coefficients, subject to Na k=1 α −1 k = 1. The choice of N a and α k can affect the performance of the method. In this work, we specify N a = 10 and use α k values of 57.017, 35.0, 25.0, 20.0, 18.0, 15.0, 12.0, 8.0, 5.0, 3.0, as suggested in [31].</p>
<p>At each iteration k, we perturb the observation data d obs ∈ R N hm with d obs + √ α k e k i . The vector e represents random noise sampled from N (0, C D ), where C D is the covariance of the measurement error. The data in the historical period are generated through application of d k i =f (m cnnpca (ξ k i )). The covariance matrix C k ξ,d and auto-covariance  </p>
<p>History Matching Results</p>
<p>We now present history matching results using the recurrent R-U-Net surrogate model trained with transfer learning and multifidelity data. These predictions are compared to results using the reference surrogate model for the determination of d k i =f (m cnnpca (ξ k i )). The geomodel shown in Fig. 4(c) is taken to be the 'true' model. The observed data d obs are generated by performing high-fidelity simulation of this model, with noise added to represent measurement error. This noise is sampled from N (0, C D ), with the standard deviation specified to be 5% of the simulated value. The observed data include the water and oil production rates for all five production wells at 150 and 300 days. We thus have N hm = 20. We set N r = 400. Figure 15 presents statistical results (over the 400 posterior samples) for water and oil production rates of wells P1, P4, and P5. These wells are representative of the overall system (the P2 flow rates resemble those of P1, and the P3 rates resemble those of P4). The prior P 10 -P 90 range for the reference high-fidelity simulation results is shown in each subplot as the gray-shaded region. The red dashed lines show the simulated flow rates of the 'true' model. The red circles present the observed data (which deviate from the red lines due to measurement error). The black dash-dotted lines indicate the P 10 , P 50 , P 90 posterior results generated from the reference surrogate model and ESMDA. The black solid lines show the P 10 , P 50 , P 90 posterior predictions from the surrogate model trained with multifidelity data. In Fig. 15, we observe substantial uncertainty reduction in posterior flow rate predictions for some quantities (such as P1 water rate) and very little uncertainty reduction in other quantities (P4 water rate). The true-model well rates (red curves) are essentially within the posterior P 10 -P 90 ranges, as would be expected. Most importantly for current purposes, the posterior P 10 , P 50 , P 90 results from the surrogate model trained with multifidelity data agree closely with the reference surrogate model predictions. There are some minor discrepancies between these two sets of results (e.g., at early time in the P 10 prediction in Fig. 15(a)), but the differences in general are small, especially compared to the amount of uncertainty reduction achieved. Flow simulation is now performed on the 400 posterior models found using ESMDA with the transfer-learning-based surrogate model. These simulation results are compared to surrogate model predictions, in terms of P 10 , P 50 , P 90 flow responses, in Fig. 16. Note that prior results are not shown here, and the y-axis ranges differ from those in Fig. 15. There is slightly more error here than in Fig. 15, though the overall agreement is still quite satisfactory.</p>
<p>Finally, in Fig. 17, we show relative errors for pressure and saturation predictions for prior and posterior transfer-learning-based surrogate results. These results are of interest because they quantify global accuracy, in contrast to accuracy in (local) well rate quantities, as shown in Fig. 16. The blue boxes in Fig. 17 display the relative errors (compared to HF simulation) for pressure and saturation predictions for 400 prior samples, while the yellow boxes show these errors for the posterior results (box quantities are as described for Fig. 6). The errors in the prior models correspond to the histogram results in Fig. 13. The consistency between the prior and posterior errors indicates that the surrogate model retains accuracy during the data assimilation process.    </p>
<p>Concluding Remarks</p>
<p>In this work, a transfer-learning-based surrogate model that uses multifidelity training data was developed to approximate state variables and well rates in two-phase subsurface flow. The underlying network for this implementation is an existing 3D recurrent residual U-Net, which has been used previously for oil-water and CO 2 storage problems. The surrogate model is trained with both high and low-fidelity numerical simulation data. Most of the network parameters are first estimated from LF data, while output-layer training and network finetuning are accomplished with HF data. In the examples, we used 2500 LF simulations and 200 HF simulations. The network input in all cases is the high-fidelity (fine-scale) geomodel. The LF simulations are themselves performed using coarsened geomodels constructed from the original fine-scale geological description using a global flow-based transmissibility upscaling procedure. The multifidelity approach provided about a 90% savings in training computations and a 40% savings in (GPU) training time compared to using only HF simulation data.</p>
<p>The transfer-learning-based surrogate model was applied for two-phase oil-water flow in 3D channelized systems, with eight wells operating under bottom-hole pressure control. The surrogate model was evaluated over a test set of 400 HF models. A reference surrogate model, in which all training runs were performed at high fidelity (the same 2500 data samples were used), was also constructed. The transfer-learning-based surrogate model was shown to provide accurate predictions for dynamic pressure and saturation fields, with errors very near those obtained by the reference surrogate model. Specifically, the median relative errors for pressure and saturation with the transfer-learning-based surrogate were 1.5% and 5.5%, compared to 1.1% and 3.5% for the reference surrogate. This represents much greater accuracy than that achieved in the LF numerical simulations, where the median saturation error was 19.4%. Close agreement in P 10 , P 50 and P 90 well rates between the transfer-learning-based surrogate predictions and HF simulations was also demonstrated.</p>
<p>The surrogate model was then combined with ESMDA for use in history matching. The geological models were parameterized using the 3D CNN-PCA representation, and flow predictions were generated using the transfer-learning-based surrogate model. The overall procedure provided clear uncertainty reduction, and comparisons of flow predictions for posterior models demonstrated reasonable agreement between surrogate and numerical simulation results for P 10 , P 50 and P 90 well rate quantities.</p>
<p>There are a number of topics for future research in this area. In this work, we used simulation data from only two fidelity levels. It may be possible to improve the performance of the surrogate model, and/or reduce computational demands, through use of data at several fidelity levels. The transfer-learning-based framework can be extended to treat larger and more complicated models. This includes coupled flow and geomechanics, which is important in CO 2 storage settings. It will also be of interest to incorporate physical loss in the training process. This could act to further reduce the number of high-fidelity training simulations required. Finally, the general framework could be extended to treat problems involving variable well controls and well locations, which would enable its use for a wide range of optimization problems.</p>
<p>Figure 1 :
13D residual U-Net architecture.</p>
<p>Figure 2 :
2Recurrent R-U-Net architecture[2].</p>
<p>The injectors and producers operate at fixed bottom-hole pressures (BHPs) of 330 bar and 310 bar, respectively. Wells I2, I3, P3, P4 and P5 are completed (open to flow) in the top eight layers of the model (layers 1-8), while wells I1, P1 and P2 are completed in layers 13-20.</p>
<p>Figure 4 :
4CNN-PCA geomodel realizations conditioned to hard data at eight well locations. Well locations are shown in (a). Realization in (c) corresponds to 'true' model used for history matching. Cutaway view used for better 3D visualization.</p>
<p>Figure 5 :
5Oil-water relative permeability curves.</p>
<p>Figure 6 :
6Relative pressure errors for 400 test samples (compared to HF simulation results) for LF (coarse) simulation, surrogate model trained with 100, 200, 300 and 400 HF samples, and reference surrogate model trained with 2500 HF simulations.</p>
<p>Figure 7 :
7Relative saturation errors for 400 test samples (compared to HF simulation results) for LF (coarse) simulation, surrogate model trained with 100, 200, 300 and 400 HF samples, and reference surrogate model trained with 2500 HF simulations.</p>
<p>Figure 8 :
8Aggregate relative well rate errors for 400 test samples (compared to HF simulation results) for LF (coarse) simulation, surrogate model trained with 100, 200, 300 and 400 HF samples, and reference surrogate model trained with 2500 HF simulations.</p>
<p>Figure 9 :
9Pressure fields from HF simulation (top row), surrogate model trained with HF data (middle row), and transfer-learning-based surrogate model trained with multifidelity data (bottom row). All results are at 400 days. Cutaway views highlight 3D effects.</p>
<p>Figure 10 :
10Water saturation fields from HF simulation (top row), surrogate model trained with HF data (middle row), and transfer-learning-based surrogate model trained with multifidelity data (bottom row). All results are at 1000 days.</p>
<p>Figure 11 :
11Pressure maps from HF and LF simulation, reference surrogate, and transfer-learning-based surrogate trained with multifidelity data. Results are for layer 8 from realization inFig. 4(c) at 1000 days.</p>
<p>Figure 12 :
12Saturation maps from HF and LF simulation, reference surrogate, and transfer-learning-based surrogate trained with multifidelity data. Results are for layer 8 from realization inFig. 4(c) at 1000 days. multiple times. The ESMDA update equation is</p>
<p>C k d are constructed from the data ensemble d k i and model parameter ensemble ξ k i . After N a iterations are completed, the posterior predictions d post are constructed via d post =ĝ(m cnnpca (ξ post )).</p>
<p>Figure 13 :
13Histograms of relative errors for pressure and saturation for the 400 test samples.</p>
<p>Figure 15 :
15Posterior results from reference surrogate model (black dash-dotted curves) and surrogate model trained with multifidelity data (black solid curves). Lower, middle and upper curves are P 10 , P 50 and P 90 responses. Gray regions show the prior P 10 -P 90 range, and red circles and curves present observed and true data. Legend in (a) applies to all subplots.</p>
<p>Figure 16 :
16Posterior results from surrogate model trained with multifidelity data (black solid curves) and corresponding fine-scale simulations (blue dash-dotted curves). Lower, middle and upper curves are P 10 , P 50 and P 90 responses. Legend in (a) applies to all subplots.</p>
<p>Figure 17 :
17Relative errors for prior and posterior pressure and saturation predictions for surrogate model trained with multifidelity data. Errors are for 400 realizations and are relative to HF simulation results.</p>
<p>Table 1 :
1Architecture of 3D recurrent R-U-Net with multifidelity data residual block, 64 filters of size 3 × 3 × 3, stride 1 ( residual block, 64 filters of size 3 × 3 × 3, stride 1 ( 3D ConvLSTM (θ convLST M ) convLSTM3D, 64 filters 3 × 3 × 3, stride 1 (Network 
Layer </p>
<p>Table 2 :
2Computational costs of training reference and transfer-learning-based surrogate with multifidelity (MF) data (Step 1: training with LF data, Step 2: transfer learning with HF data, Step 3: fine-tuning with HF data). The relative errors are averages over 400 test samplesHF training 
MF training 
Accl MF training 
Step 1 
N/A 
150 ep×360 s/ep = 15 h 70 ep×360 s/ep = 7 h 
Step 2 
N/A 
200 ep×15 s/ep = 0.83 h 200 ep×15 s/ep = 0.83 h 
Step 3 
150 ep×360 s/ep = 15 h 100 ep×30 s/ep = 0.83 h 100 ep×30 s/ep = 0.83 h 
Time 
15 h 
16.66 h 
8.66 h 
p error (δ p ) 
1.18% 
1.52% 
1.58% 
S error (δ S ) 
3.70% 
5.38% 
5.57% </p>
<p>Figure 14: Flow rate statistics for HF and LF simulation (left column), reference surrogate model (middle column), and surrogate model trained with multifidelity data (right column) for P1 and P4 oil and water production rates. Results correspond to P 10 , P 50 and P 90 responses over 400 test cases.250 500 750 1000 
Days </p>
<p>200 </p>
<p>400 </p>
<p>600 </p>
<p>800 </p>
<p>1000 </p>
<p>1200 </p>
<p>P1 oil rate (m 3 </p>
<p>/Day) </p>
<p>sim (LF) 
sim (HF) </p>
<p>(a) P1 OPR -HF and LF </p>
<p>200 
400 
600 
800 
1000 </p>
<p>Days </p>
<p>200 </p>
<p>400 </p>
<p>600 </p>
<p>800 </p>
<p>1000 </p>
<p>1200 </p>
<p>P1 oil rate (m 3 </p>
<p>/Day) </p>
<p>surr (ref) 
sim (HF) </p>
<p>(b) P1 OPR -HF and surr (ref) </p>
<p>250 500 750 1000 
Days </p>
<p>200 </p>
<p>400 </p>
<p>600 </p>
<p>800 </p>
<p>1000 </p>
<p>1200 </p>
<p>P1 oil rate (m 3 </p>
<p>/Day) </p>
<p>surr (multi) 
sim (HF) </p>
<p>(c) P1 OPR -HF and surr (multi) </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P1 water rate (m 3 </p>
<p>/Day) </p>
<p>sim (LF) 
sim (HF) </p>
<p>(d) P1 WPR -HF and LF </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P1 water rate (m 3 </p>
<p>/Day) </p>
<p>surr (ref) 
sim (HF) </p>
<p>(e) P1 WPR -HF and surr (ref) </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P1 water rate (m 3 </p>
<p>/Day) </p>
<p>surr (multi) 
sim (HF) </p>
<p>(f) P1 WPR -HF and surr (multi) </p>
<p>250 500 750 1000 
Days </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P4 oil rate (m 3 </p>
<p>/Day) </p>
<p>sim (LF) 
sim (HF) </p>
<p>(g) P4 OPR -HF and LF </p>
<p>250 500 750 1000 
Days </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P4 oil rate (m 3 </p>
<p>/Day) </p>
<p>surr (ref) 
sim (HF) </p>
<p>(h) P4 OPR -HF and surr (ref) </p>
<p>250 500 750 1000 
Days </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>P4 oil rate (m 3 </p>
<p>/Day) </p>
<p>surr (multi) 
sim (HF) </p>
<p>(i) P4 OPR -HF and surr (multi) </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>2000 </p>
<p>2500 </p>
<p>P4 water rate (m 3 </p>
<p>/Day) </p>
<p>sim (LF) 
sim (HF) </p>
<p>(j) P4 WPR -HF and LF </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>1000 </p>
<p>2000 </p>
<p>P4 water rate (m 3 </p>
<p>/Day) </p>
<p>surr (ref) 
sim (HF) </p>
<p>(k) P4 WPR -HF and surr (ref) </p>
<p>250 500 750 1000 
Days </p>
<p>0 </p>
<p>500 </p>
<p>1000 </p>
<p>1500 </p>
<p>2000 </p>
<p>2500 </p>
<p>P4 water rate (m 3 </p>
<p>/Day) </p>
<p>surr (multi) 
sim (HF) </p>
<p>(l) P4 WPR -HF and surr (multi) </p>
<p>AcknowledgementsWe are grateful to the Stanford Smart Fields Consortium for partial funding of this work. We thank Meng Tang for providing geological models, parameterization code and recurrent R-U-Net code, and Dylan Crain for providing the upscaling code used in this study.
A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems. M Tang, Y Liu, L J Durlofsky, Journal of Computational Physics. 413109456M. Tang, Y. Liu, L. J. Durlofsky, A deep-learning-based surrogate model for data assimilation in dynamic subsurface flow problems, Journal of Computational Physics 413 (2020) 109456.</p>
<p>Deep-learning-based surrogate flow modeling and geological parameterization for data assimilation in 3D subsurface flow. M Tang, Y Liu, L J Durlofsky, Computer Methods in Applied Mechanics and Engineering. 376113636M. Tang, Y. Liu, L. J. Durlofsky, Deep-learning-based surrogate flow modeling and geo- logical parameterization for data assimilation in 3D subsurface flow, Computer Methods in Applied Mechanics and Engineering 376 (2021) 113636.</p>
<p>History matching complex 3D systems using deeplearning-based surrogate flow modeling and CNN-PCA geological parameterization. M Tang, Y Liu, L J Durlofsky, SPE Reservoir Simulation Conference. 2021M. Tang, Y. Liu, L. J. Durlofsky, History matching complex 3D systems using deep- learning-based surrogate flow modeling and CNN-PCA geological parameterization, in: SPE Reservoir Simulation Conference, OnePetro, 2021.</p>
<p>Deep-learning-based coupled flow-geomechanics surrogate model for CO 2 sequestration. M Tang, X Ju, L J Durlofsky, arXiv:2105.01334arXiv preprintM. Tang, X. Ju, L. J. Durlofsky, Deep-learning-based coupled flow-geomechanics surro- gate model for CO 2 sequestration, arXiv preprint arXiv:2105.01334 (2021).</p>
<p>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G E Karniadakis, Journal of Computational Physics. 378M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations, Journal of Computational Physics 378 (2019) 686-707.</p>
<p>Deep learning of subsurface flow via theory-guided neural network. N Wang, D Zhang, H Chang, H Li, Journal of Hydrology. 584124700N. Wang, D. Zhang, H. Chang, H. Li, Deep learning of subsurface flow via theory-guided neural network, Journal of Hydrology 584 (2020) 124700.</p>
<p>Efficient uncertainty quantification for dynamic subsurface flow with surrogate by theory-guided neural network. N Wang, H Chang, D Zhang, Computer Methods in Applied Mechanics and Engineering. 373113492N. Wang, H. Chang, D. Zhang, Efficient uncertainty quantification for dynamic sub- surface flow with surrogate by theory-guided neural network, Computer Methods in Applied Mechanics and Engineering 373 (2021) 113492.</p>
<p>Theory-guided auto-encoder for surrogate construction and inverse modeling. N Wang, H Chang, D Zhang, Computer Methods in Applied Mechanics and Engineering. 385114037N. Wang, H. Chang, D. Zhang, Theory-guided auto-encoder for surrogate construction and inverse modeling, Computer Methods in Applied Mechanics and Engineering 385 (2021) 114037.</p>
<p>Physics-informed neural networks for multiphysics data assimilation with application to subsurface transport. Q He, D Barajas-Solano, G Tartakovsky, A M Tartakovsky, Advances in Water Resources. 141103610Q. He, D. Barajas-Solano, G. Tartakovsky, A. M. Tartakovsky, Physics-informed neural networks for multiphysics data assimilation with application to subsurface transport, Advances in Water Resources 141 (2020) 103610.</p>
<p>Physics-informed deep neural networks for learning parameters and constitutive relationships in subsurface flow problems. A M Tartakovsky, C O Marrero, P Perdikaris, G D Tartakovsky, D Barajas-Solano, Water Resources Research. 56A. M. Tartakovsky, C. O. Marrero, P. Perdikaris, G. D. Tartakovsky, D. Barajas-Solano, Physics-informed deep neural networks for learning parameters and constitutive relation- ships in subsurface flow problems, Water Resources Research 56 (2020) e2019WR026731.</p>
<p>Physics-informed machine learning with conditional Karhunen-Loeve expansions. A M Tartakovsky, D A Barajas-Solano, Q He, Journal of Computational Physics. 426109904A. M. Tartakovsky, D. A. Barajas-Solano, Q. He, Physics-informed machine learning with conditional Karhunen-Loeve expansions, Journal of Computational Physics 426 (2021) 109904.</p>
<p>Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification. Y Zhu, N Zabaras, Journal of Computational Physics. 366Y. Zhu, N. Zabaras, Bayesian deep convolutional encoder-decoder networks for surrogate modeling and uncertainty quantification, Journal of Computational Physics 366 (2018) 415-447.</p>
<p>Deep convolutional encoder-decoder networks for uncertainty quantification of dynamic multiphase flow in heterogeneous media. S Mo, Y Zhu, N Zabaras, X Shi, J Wu, Water Resources Research. 55S. Mo, Y. Zhu, N. Zabaras, X. Shi, J. Wu, Deep convolutional encoder-decoder networks for uncertainty quantification of dynamic multiphase flow in heterogeneous media, Water Resources Research 55 (2019) 703-728.</p>
<p>Deep autoregressive neural networks for highdimensional inverse problems in groundwater contaminant source identification. S Mo, N Zabaras, X Shi, J Wu, Water Resources Research. 55S. Mo, N. Zabaras, X. Shi, J. Wu, Deep autoregressive neural networks for high- dimensional inverse problems in groundwater contaminant source identification, Water Resources Research 55 (2019) 3856-3881.</p>
<p>Integration of adversarial autoencoders with residual dense convolutional networks for estimation of non-Gaussian hydraulic conductivities. S Mo, N Zabaras, X Shi, J Wu, Water Resources Research. 56S. Mo, N. Zabaras, X. Shi, J. Wu, Integration of adversarial autoencoders with residual dense convolutional networks for estimation of non-Gaussian hydraulic conductivities, Water Resources Research 56 (2020) e2019WR026082.</p>
<p>Towards a predictor for CO 2 plume migration using deep neural networks. G Wen, M Tang, S M Benson, International Journal of Greenhouse Gas Control. 105103223G. Wen, M. Tang, S. M. Benson, Towards a predictor for CO 2 plume migration using deep neural networks, International Journal of Greenhouse Gas Control 105 (2021) 103223.</p>
<p>N Geneva, N Zabaras, arXiv:2006.04731Multi-fidelity generative deep learning turbulent flows. arXiv preprintN. Geneva, N. Zabaras, Multi-fidelity generative deep learning turbulent flows, arXiv preprint arXiv:2006.04731 (2020).</p>
<p>A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems. X Meng, G E Karniadakis, Journal of Computational Physics. 401109020X. Meng, G. E. Karniadakis, A composite neural network that learns from multi-fidelity data: Application to function approximation and inverse PDE problems, Journal of Computational Physics 401 (2020) 109020.</p>
<p>On transfer learning of neural networks using bi-fidelity data for uncertainty propagation. S De, J Britton, M Reynolds, R Skinner, K Jansen, A Doostan, International Journal for Uncertainty Quantification. 10S. De, J. Britton, M. Reynolds, R. Skinner, K. Jansen, A. Doostan, On transfer learn- ing of neural networks using bi-fidelity data for uncertainty propagation, International Journal for Uncertainty Quantification 10 (2020) 543-573.</p>
<p>Transfer learning on multi-fidelity data. D H Song, D M Tartakovsky, Journal of Machine Learning for Modeling and Computing. 2D. H. Song, D. M. Tartakovsky, Transfer learning on multi-fidelity data, Journal of Machine Learning for Modeling and Computing 2 (2022) 31-47.</p>
<p>Parallel General-purpose Reservoir Simulation with Coupled Reservoir Models and Multisegment Wells. Y Zhou, Stanford UniversityPh.D. thesisY. Zhou, Parallel General-purpose Reservoir Simulation with Coupled Reservoir Models and Multisegment Wells, Ph.D. thesis, Stanford University, 2012.</p>
<p>Interpretation of well-block pressures in numerical reservoir simulation with nonsquare grid blocks and anisotropic permeability. D W Peaceman, SPE Journal. 23D. W. Peaceman, Interpretation of well-block pressures in numerical reservoir simulation with nonsquare grid blocks and anisotropic permeability, SPE Journal 23 (1983) 531- 543.</p>
<p>A new practical method for upscaling in highly heterogeneous reservoir models. P Zhang, G E Pickup, M A Christie, SPE Journal. 13P. Zhang, G. E. Pickup, M. A. Christie, A new practical method for upscaling in highly heterogeneous reservoir models, SPE Journal 13 (2008) 68-76.</p>
<p>Nonlinear two-point flux approximation for modeling full-tensor effects in subsurface flow simulations. Y Chen, B T Mallison, L J Durlofsky, Computational Geosciences. 12Y. Chen, B. T. Mallison, L. J. Durlofsky, Nonlinear two-point flux approximation for modeling full-tensor effects in subsurface flow simulations, Computational Geosciences 12 (2008) 317-335.</p>
<p>Extended Framework for Multifidelity Uncertainty Quantification in Subsurface Flow Systems. D Crain, Master's thesis. Stanford UniversityD. Crain, Extended Framework for Multifidelity Uncertainty Quantification in Subsur- face Flow Systems, Master's thesis, Stanford University, 2020.</p>
<p>Treatment of model error in subsurface flow history matching using a data-space method. S Jiang, L J Durlofsky, Journal of Hydrology. 603127063S. Jiang, L. J. Durlofsky, Treatment of model error in subsurface flow history matching using a data-space method, Journal of Hydrology 603 (2021) 127063.</p>
<p>3D CNN-PCA: A deep-learning-based parameterization for complex geomodels. Y Liu, L J Durlofsky, Computers &amp; Geosciences. 148104676Y. Liu, L. J. Durlofsky, 3D CNN-PCA: A deep-learning-based parameterization for complex geomodels, Computers &amp; Geosciences 148 (2021) 104676.</p>
<p>D P Kingma, J Ba, arXiv:1412.6980Adam: A method for stochastic optimization. arXiv preprintD. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980 (2014).</p>
<p>A general method to select representative models for decision making and optimization under uncertainty. M G Shirangi, L J Durlofsky, Computers &amp; Geosciences. 96M. G. Shirangi, L. J. Durlofsky, A general method to select representative models for decision making and optimization under uncertainty, Computers &amp; Geosciences 96 (2016) 109-123.</p>
<p>Ensemble smoother with multiple data assimilation. A A Emerick, A C Reynolds, Computers &amp; Geosciences. 55A. A. Emerick, A. C. Reynolds, Ensemble smoother with multiple data assimilation, Computers &amp; Geosciences 55 (2013) 3-15.</p>
<p>Investigation of the sampling performance of ensemblebased methods with a simple reservoir model. A A Emerick, A C Reynolds, Computational Geosciences. 17A. A. Emerick, A. C. Reynolds, Investigation of the sampling performance of ensemble- based methods with a simple reservoir model, Computational Geosciences 17 (2013) 325-350.</p>            </div>
        </div>

    </div>
</body>
</html>