<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-707 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-707</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-707</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-18.html">extraction-schema-18</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</div>
                <p><strong>Paper ID:</strong> paper-269df328eec08b56b7b1f38a7555797fe2b999b6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/269df328eec08b56b7b1f38a7555797fe2b999b6" target="_blank">ReCode: Robustness Evaluation of Code Generation Models</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This paper customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format to provide multifaceted assessments of a model’s robustness performance, and defines robustness metrics for code generation models considering the worst-case behavior under each type of perturbation.</p>
                <p><strong>Paper Abstract:</strong> Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model’s robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e707.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e707.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Docstring-NL vs Code Generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discrepancies between docstring natural-language descriptions and generated code completions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Changes in natural-language docstrings (paraphrase, typos, case, whitespace) that preserve semantics can nevertheless cause large, often worst-case, changes in code-generation outputs; these discrepancies are identified via execution-based tests and quantified with new robustness metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReCode robustness evaluation (docstring perturbations)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A robustness evaluation pipeline that perturbs docstrings with natural-language transformations (e.g., BackTranslation, ButterFingers, CharCaseChange, SynonymSubstitution) and measures model correctness by executing unit tests over generated code.</td>
                        </tr>
                        <tr>
                            <td><strong>nl_description_type</strong></td>
                            <td>docstring / natural-language function description</td>
                        </tr>
                        <tr>
                            <td><strong>code_implementation_type</strong></td>
                            <td>Python function implementation (generated completions)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_type</strong></td>
                            <td>semantic-preserving NL perturbation sensitivity (ambiguous mapping / brittle model behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_description</strong></td>
                            <td>Natural-language variations in docstrings that preserve the original semantics (paraphrases, typos, casing, tense) sometimes produce drastically different generated code. Although the perturbed docstrings are intended to describe the same functionality, models often fail under these perturbations: i.e., the mapping from docstring text to intended code is non-robust, producing incorrect completions despite semantic equivalence of the descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_location</strong></td>
                            <td>model input interpretation / prompt-to-code mapping (prompt parsing & conditional generation)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>execution-based correctness checks (unit tests) over model-generated code combined with human annotation and automatic similarity metrics (sentence-transformer cosine similarity, CodeBLEU, human naturalness/semantic judgments).</td>
                        </tr>
                        <tr>
                            <td><strong>measurement_method</strong></td>
                            <td>Worst-case robustness metrics RP_s@k (Robust Pass), RD_s@k (Robust Drop), RR_s@k (Robust Relative); sentence-embedding cosine similarity (all-mpnet-base-v2) between original and perturbed docstrings; human naturalness/semantic ratings; CodeBLEU for code comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_results</strong></td>
                            <td>Substantial drops in measured correctness under perturbation. Example figures from the paper: average sentence similarity for docstrings ≈ 0.93; human validation shows >90% of perturbed prompts judged to preserve semantics, yet Robust Pass (RP_5@1) values drop (examples: docstring category RP_5@1 averages ~0.078 on HumanEval, ~0.071 on MBPP across models) and Robust Drop (RD_5@1) often in the tens of percent (e.g., RD_5@1 ≈ 60.67% for HumanEval docstring average, ≈75.31% for MBPP docstring average). Specific transformations (e.g., ButterFingers) produce per-model RD values in the 20–60% range depending on model and dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>frequency_or_prevalence</strong></td>
                            <td>High: human evaluation shows the majority of perturbations (≈90% by majority vote) preserved semantics; naturalness score drops from ≈0.92 (nominal) to ≈0.75–0.80 (perturbed) on average (≈14% drop). Sentence-similarity averages ≈0.93 for docstrings; many (majority) perturbation types produce measurable model failures.</td>
                        </tr>
                        <tr>
                            <td><strong>root_cause</strong></td>
                            <td>Models are brittle to surface-form variations in NL prompts and can rely on spurious correlations; NL-augmentation tools applied naively may change tokens important for code mapping; prompt-aware constraints are needed.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_approach</strong></td>
                            <td>Constrain perturbations with code-aware parsing (tree-sitter blacklist of program keywords/types/identifiers), validate perturbed prompts with semantic-similarity checks (sentence embeddings) and human review, and measure worst-case behavior with RP/RD/RR metrics; recommend s=5 random perturbations as a balance between cost and coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Quantified indirectly: after applying filters (tree-sitter blacklist) and validation, >90% of perturbed prompts preserve semantics by human vote; sentence-similarity and CodeBLEU scores confirm high preservation (docstring similarity ≈0.93). Using RP/RD/RR exposes failures and gives a reproducible way to evaluate mitigations. The paper recommends s=5 as a practical choice (empirically shows convergence of measured drops beyond that).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>machine learning / code generation (software engineering prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_impact</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ReCode: Robustness Evaluation of Code Generation Models', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e707.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e707.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FunctionName-NL vs Code</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discrepancies between natural-language mentions of function names and code behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Perturbations to function names (naming convention changes, typos, inflection, synonyms) that preserve intended semantics can change model completions, revealing a mismatch between NL references (function signature text) and how models condition on identifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReCode robustness evaluation (function-name perturbations)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A testbed that modifies function names consistently across prompt (including docstrings) using transformations such as CamelCase↔snake_case, ButterFingers typos, SwapCharacters, ChangeCharCase, InflectionalVariation, SynonymSubstitution, then measures generated-code correctness via unit tests.</td>
                        </tr>
                        <tr>
                            <td><strong>nl_description_type</strong></td>
                            <td>function name in signature and in-text occurrences (docstring references)</td>
                        </tr>
                        <tr>
                            <td><strong>code_implementation_type</strong></td>
                            <td>Python function signature and generated implementation</td>
                        </tr>
                        <tr>
                            <td><strong>gap_type</strong></td>
                            <td>identifier mismatch / naming-sensitivity (ambiguous description vs code token mapping)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_description</strong></td>
                            <td>Changing the surface form of the target function name (even when the docstring is updated consistently) can cause different code generation results, indicating that models are sensitive to identifier formatting and even small typos when mapping prompts to code. Some perturbations that are semantically equivalent (e.g., camelCase vs snake_case) still alter model outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_location</strong></td>
                            <td>prompt signature & identifier handling (token-level conditioning inside model)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Execution-based correctness across perturbed prompts; sentence-transformer cosine similarity on split function-name tokens; human annotation of naturalness/semantic preservation.</td>
                        </tr>
                        <tr>
                            <td><strong>measurement_method</strong></td>
                            <td>RP_s@k, RD_s@k, RR_s@k aggregated per transformation type; function-name cosine similarity (after splitting into words) reported (average ≈0.80–0.81 across datasets); human naturalness scores.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_results</strong></td>
                            <td>Function-name perturbations reduce worst-case correctness (RP_5@1) and cause non-negligible RD_5@1 and RR_5@1; examples: average RP_5@1 across models for function perturbations ≈0.113 (HumanEval) vs nominal higher pass@k; RD_5@1 for function category ≈41.61% (HumanEval average) and ≈46.59% (MBPP average). Certain perturbations (typos) produce larger relative drops depending on model.</td>
                        </tr>
                        <tr>
                            <td><strong>frequency_or_prevalence</strong></td>
                            <td>Common: function-name cosine similarity averages ≈0.80; some perturbation types (e.g., CamelCase) preserve similarity perfectly (1.0), while small typos produce low measured similarity for short names. Perturbations produce measurable failures across many models.</td>
                        </tr>
                        <tr>
                            <td><strong>root_cause</strong></td>
                            <td>Models rely on identifier surface forms for conditioning; short identifier strings lack context so small changes have outsized effect; training data biases and tokenization/idiosyncrasies amplify sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_approach</strong></td>
                            <td>Make identifier perturbations code-aware and validate similarity; include identifier variants during training/augmentation; use CodeBERT-based variable renaming to propose plausible renames when generating perturbations; measure robustness with RP/RD/RR.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>CodeBERT-based renaming yields more natural variable/function-name candidates (measured qualitatively); function-name similarity metrics and human ratings indicate that constrained perturbations preserve meaning. The paper reports that some deterministic naming transformations (e.g., CamelCase) have minimal negative effect, while random/typo renamings produce larger drops—indicating effectiveness of constrained, context-aware approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>machine learning / code generation</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_impact</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ReCode: Robustness Evaluation of Code Generation Models', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e707.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e707.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CodeSyntax/Format Gap</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Misalignment between natural-language descriptions and partial code prompts (syntax/format perturbations) causing generation failures</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Syntactic and formatting changes to partial code in prompts (dead-code insertion, for↔while switches, operand swaps, variable renamings, tab/space indent changes, newline insertions, docstring↔comment conversion) preserve semantics but can severely change model completions and evaluation outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReCode robustness evaluation (code syntax & format perturbations)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A framework that constructs function-completion prompts by inserting partial canonical solutions and then applying a variety of semantically-preserving code transformations, evaluating model robustness via execution-based tests and worst-case metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>nl_description_type</strong></td>
                            <td>partial-code prompt accompanied by natural-language docstring (mixed NL & code prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>code_implementation_type</strong></td>
                            <td>partial Python code in prompt and completed Python implementation</td>
                        </tr>
                        <tr>
                            <td><strong>gap_type</strong></td>
                            <td>syntactic/format mismatch (formatting or innocuous syntactic edits change model behaviour)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_description</strong></td>
                            <td>Syntactically valid but semantically invariant changes to the partial code (formatting or refactorings) produce large differences in generated completions. For example, insertion of dead code or simply adding an empty newline before the completion site can cause model outputs to become incorrect. This shows a misalignment between the intent expressed in the prompt (NL + partial code) and the model's conditioning on code contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_location</strong></td>
                            <td>partial-code context & prompt structure (pre-completion context provided to generator)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Execution of generated code against unit tests after applying randomized syntax/format transformations; human and CodeBLEU checks for preservation of semantics/syntax; targeted failure-case analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>measurement_method</strong></td>
                            <td>RP_s@k, RD_s@k, RR_s@k per perturbation; CodeBLEU syntax and dataflow similarity between original and perturbed partial code (average syntax/dataflow scores ~0.96–0.97 for many transformations); qualitative failure-case examples.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_results</strong></td>
                            <td>Very large: syntax perturbations often cause the largest performance drops of all categories. Examples from the paper: on HumanEval DeadCodeInserter caused RD_5@1 ≈ 71.21% (CodeGen 2B example: RP drop from 0.402 nominal to 0.116); on MBPP syntax-category RD values reach ≈94–97% for multiple models (extremely large relative drops). Format perturbations (newlines, tab indent) also produce significant RP reductions in some cases; dead-code insertion and newline-before-code are specifically highlighted as effective at causing failures.</td>
                        </tr>
                        <tr>
                            <td><strong>frequency_or_prevalence</strong></td>
                            <td>High in effect when applied: many syntax/format transformations preserve CodeBLEU (≈0.9+) for syntax/dataflow — the paper reports that ≈77% (syntax) and ≈89% (dataflow) of transformations have CodeBLEU > 0.9 — yet they still produce frequent model failures. Thus, semantic invariance does not prevent high failure rates.</td>
                        </tr>
                        <tr>
                            <td><strong>root_cause</strong></td>
                            <td>Models are overly sensitive to local syntactic/structural cues in the prompt; they may attend to spurious local patterns (e.g., an immediately preceding for loop) when deciding completion tokens rather than robust program semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_approach</strong></td>
                            <td>Evaluate using worst-case metrics across multiple random perturbations (RP/RD/RR) and incorporate such perturbations into training/augmentation; use code-aware transformations (NatGen-style) and CodeBLEU/dataflow checks to ensure perturbations preserve semantics; analyze failure cases to design targeted defenses.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Mitigation evaluated mainly as diagnostic: CodeBLEU/dataflow confirms semantic preservation of perturbations (so failures are model brittleness rather than perturbation invalidity). The paper finds that larger models and more diverse pretraining improve RP in many cases (but can increase RR), indicating partial effectiveness of model-scale and corpus diversity as mitigations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>machine learning / program synthesis / code generation</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_impact</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ReCode: Robustness Evaluation of Code Generation Models', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e707.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e707.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of discrepancies, gaps, or misalignments between natural language descriptions (such as paper descriptions, documentation, or specifications) and their corresponding code implementations in automated experimentation systems, including how these gaps are identified, measured, and their impacts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NL-Augmenter vs Code Keywords</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mismatch between general NL-augmentation tools and code-sensitive prompts (keyword corruption)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying off-the-shelf natural-language augmentation (NL-Augmenter) to code-related text can produce invalid or unnatural perturbations because code tokens (identifiers, types, syntax) are treated as regular words; this must be mitigated with code-aware constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ReCode augmentation pipeline (NL-Augmenter with tree-sitter constraints)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Docstring perturbation pipeline using NL-Augmenter transformations adapted for code prompts; combined with tree-sitter parsing to blacklist program keywords and identifiers from being altered.</td>
                        </tr>
                        <tr>
                            <td><strong>nl_description_type</strong></td>
                            <td>docstring augmentation using NL-augmentation toolkit</td>
                        </tr>
                        <tr>
                            <td><strong>code_implementation_type</strong></td>
                            <td>augmentation script applied to prompts (preprocessing step)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_type</strong></td>
                            <td>augmentation-tool mismatch / missing code-aware constraints (ambiguous/incomplete specification of allowed perturbations)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_description</strong></td>
                            <td>Direct application of general NL-augmentation methods to docstrings can inadvertently alter or corrupt program keywords, identifiers, or code-like tokens (e.g., producing syntactically invalid or unnatural code references). The paper gives an example where naive perturbation could change "Create a list a[][]" into an unnatural/bracket-mismatched form.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_location</strong></td>
                            <td>data preprocessing / prompt augmentation pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Manual inspection and rule-based detection; use of tree-sitter parsing to identify code tokens that must be excluded from NL perturbations; human evaluation of perturbed outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>measurement_method</strong></td>
                            <td>Human naturalness scoring (0/0.5/1), semantic-preservation voting; quantitative checks via sentence similarity and CodeBLEU to ensure perturbations don't alter code semantics. The paper reports a 14% average drop in naturalness score for perturbed data (from ≈0.92 to ≈0.75–0.80) and uses tree-sitter to prevent perturbations of code tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_results</strong></td>
                            <td>If unmitigated, augmentation can produce low-quality perturbed prompts that either change semantics or make prompts unnatural/invalid, leading to misleading robustness measurements or invalid model inputs. Mitigation (tree-sitter blacklist) was applied to avoid these issues; after mitigation >90% of perturbed prompts are judged to preserve semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>frequency_or_prevalence</strong></td>
                            <td>Common risk when applying vanilla NL-augmentation to code-related text; many transformations required customization (paper customized 10 docstring transformations and used tree-sitter to filter keywords).</td>
                        </tr>
                        <tr>
                            <td><strong>root_cause</strong></td>
                            <td>NL-augmentation tools are developed for natural-language text and do not account for code tokens; lack of explicit specification about which tokens to protect leads to corruption.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_approach</strong></td>
                            <td>Use code-aware parsing (tree-sitter) to extract and blacklist identifiers/types/keywords before applying NL augmentations; post-perturbation validation via human checks and automatic similarity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Effective in practice as reported: after applying code-aware constraints and validation, the paper reports that majority (>90%) of perturbed prompts preserve semantics by human vote; sentence similarity and CodeBLEU support high-quality perturbations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_field</strong></td>
                            <td>machine learning / data augmentation for code generation</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_impact</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ReCode: Robustness Evaluation of Code Generation Models', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>NL-Augmenter: A Framework for Task-Sensitive Natural Language Augmentation <em>(Rating: 2)</em></li>
                <li>Natgen: Generative pre-training by "naturalizing" source code <em>(Rating: 2)</em></li>
                <li>CodeAttack: Code-based adversarial attacks for pre-trained programming language models <em>(Rating: 2)</em></li>
                <li>Adversarial Robustness for Code <em>(Rating: 2)</em></li>
                <li>CodeBLEU: a machine learning benchmark dataset for code understanding and generation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-707",
    "paper_id": "paper-269df328eec08b56b7b1f38a7555797fe2b999b6",
    "extraction_schema_id": "extraction-schema-18",
    "extracted_data": [
        {
            "name_short": "Docstring-NL vs Code Generation",
            "name_full": "Discrepancies between docstring natural-language descriptions and generated code completions",
            "brief_description": "Changes in natural-language docstrings (paraphrase, typos, case, whitespace) that preserve semantics can nevertheless cause large, often worst-case, changes in code-generation outputs; these discrepancies are identified via execution-based tests and quantified with new robustness metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ReCode robustness evaluation (docstring perturbations)",
            "system_description": "A robustness evaluation pipeline that perturbs docstrings with natural-language transformations (e.g., BackTranslation, ButterFingers, CharCaseChange, SynonymSubstitution) and measures model correctness by executing unit tests over generated code.",
            "nl_description_type": "docstring / natural-language function description",
            "code_implementation_type": "Python function implementation (generated completions)",
            "gap_type": "semantic-preserving NL perturbation sensitivity (ambiguous mapping / brittle model behavior)",
            "gap_description": "Natural-language variations in docstrings that preserve the original semantics (paraphrases, typos, casing, tense) sometimes produce drastically different generated code. Although the perturbed docstrings are intended to describe the same functionality, models often fail under these perturbations: i.e., the mapping from docstring text to intended code is non-robust, producing incorrect completions despite semantic equivalence of the descriptions.",
            "gap_location": "model input interpretation / prompt-to-code mapping (prompt parsing & conditional generation)",
            "detection_method": "execution-based correctness checks (unit tests) over model-generated code combined with human annotation and automatic similarity metrics (sentence-transformer cosine similarity, CodeBLEU, human naturalness/semantic judgments).",
            "measurement_method": "Worst-case robustness metrics RP_s@k (Robust Pass), RD_s@k (Robust Drop), RR_s@k (Robust Relative); sentence-embedding cosine similarity (all-mpnet-base-v2) between original and perturbed docstrings; human naturalness/semantic ratings; CodeBLEU for code comparisons.",
            "impact_on_results": "Substantial drops in measured correctness under perturbation. Example figures from the paper: average sentence similarity for docstrings ≈ 0.93; human validation shows &gt;90% of perturbed prompts judged to preserve semantics, yet Robust Pass (RP_5@1) values drop (examples: docstring category RP_5@1 averages ~0.078 on HumanEval, ~0.071 on MBPP across models) and Robust Drop (RD_5@1) often in the tens of percent (e.g., RD_5@1 ≈ 60.67% for HumanEval docstring average, ≈75.31% for MBPP docstring average). Specific transformations (e.g., ButterFingers) produce per-model RD values in the 20–60% range depending on model and dataset.",
            "frequency_or_prevalence": "High: human evaluation shows the majority of perturbations (≈90% by majority vote) preserved semantics; naturalness score drops from ≈0.92 (nominal) to ≈0.75–0.80 (perturbed) on average (≈14% drop). Sentence-similarity averages ≈0.93 for docstrings; many (majority) perturbation types produce measurable model failures.",
            "root_cause": "Models are brittle to surface-form variations in NL prompts and can rely on spurious correlations; NL-augmentation tools applied naively may change tokens important for code mapping; prompt-aware constraints are needed.",
            "mitigation_approach": "Constrain perturbations with code-aware parsing (tree-sitter blacklist of program keywords/types/identifiers), validate perturbed prompts with semantic-similarity checks (sentence embeddings) and human review, and measure worst-case behavior with RP/RD/RR metrics; recommend s=5 random perturbations as a balance between cost and coverage.",
            "mitigation_effectiveness": "Quantified indirectly: after applying filters (tree-sitter blacklist) and validation, &gt;90% of perturbed prompts preserve semantics by human vote; sentence-similarity and CodeBLEU scores confirm high preservation (docstring similarity ≈0.93). Using RP/RD/RR exposes failures and gives a reproducible way to evaluate mitigations. The paper recommends s=5 as a practical choice (empirically shows convergence of measured drops beyond that).",
            "domain_or_field": "machine learning / code generation (software engineering prompts)",
            "reproducibility_impact": true,
            "uuid": "e707.0",
            "source_info": {
                "paper_title": "ReCode: Robustness Evaluation of Code Generation Models",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "FunctionName-NL vs Code",
            "name_full": "Discrepancies between natural-language mentions of function names and code behavior",
            "brief_description": "Perturbations to function names (naming convention changes, typos, inflection, synonyms) that preserve intended semantics can change model completions, revealing a mismatch between NL references (function signature text) and how models condition on identifiers.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ReCode robustness evaluation (function-name perturbations)",
            "system_description": "A testbed that modifies function names consistently across prompt (including docstrings) using transformations such as CamelCase↔snake_case, ButterFingers typos, SwapCharacters, ChangeCharCase, InflectionalVariation, SynonymSubstitution, then measures generated-code correctness via unit tests.",
            "nl_description_type": "function name in signature and in-text occurrences (docstring references)",
            "code_implementation_type": "Python function signature and generated implementation",
            "gap_type": "identifier mismatch / naming-sensitivity (ambiguous description vs code token mapping)",
            "gap_description": "Changing the surface form of the target function name (even when the docstring is updated consistently) can cause different code generation results, indicating that models are sensitive to identifier formatting and even small typos when mapping prompts to code. Some perturbations that are semantically equivalent (e.g., camelCase vs snake_case) still alter model outputs.",
            "gap_location": "prompt signature & identifier handling (token-level conditioning inside model)",
            "detection_method": "Execution-based correctness across perturbed prompts; sentence-transformer cosine similarity on split function-name tokens; human annotation of naturalness/semantic preservation.",
            "measurement_method": "RP_s@k, RD_s@k, RR_s@k aggregated per transformation type; function-name cosine similarity (after splitting into words) reported (average ≈0.80–0.81 across datasets); human naturalness scores.",
            "impact_on_results": "Function-name perturbations reduce worst-case correctness (RP_5@1) and cause non-negligible RD_5@1 and RR_5@1; examples: average RP_5@1 across models for function perturbations ≈0.113 (HumanEval) vs nominal higher pass@k; RD_5@1 for function category ≈41.61% (HumanEval average) and ≈46.59% (MBPP average). Certain perturbations (typos) produce larger relative drops depending on model.",
            "frequency_or_prevalence": "Common: function-name cosine similarity averages ≈0.80; some perturbation types (e.g., CamelCase) preserve similarity perfectly (1.0), while small typos produce low measured similarity for short names. Perturbations produce measurable failures across many models.",
            "root_cause": "Models rely on identifier surface forms for conditioning; short identifier strings lack context so small changes have outsized effect; training data biases and tokenization/idiosyncrasies amplify sensitivity.",
            "mitigation_approach": "Make identifier perturbations code-aware and validate similarity; include identifier variants during training/augmentation; use CodeBERT-based variable renaming to propose plausible renames when generating perturbations; measure robustness with RP/RD/RR.",
            "mitigation_effectiveness": "CodeBERT-based renaming yields more natural variable/function-name candidates (measured qualitatively); function-name similarity metrics and human ratings indicate that constrained perturbations preserve meaning. The paper reports that some deterministic naming transformations (e.g., CamelCase) have minimal negative effect, while random/typo renamings produce larger drops—indicating effectiveness of constrained, context-aware approaches.",
            "domain_or_field": "machine learning / code generation",
            "reproducibility_impact": true,
            "uuid": "e707.1",
            "source_info": {
                "paper_title": "ReCode: Robustness Evaluation of Code Generation Models",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "CodeSyntax/Format Gap",
            "name_full": "Misalignment between natural-language descriptions and partial code prompts (syntax/format perturbations) causing generation failures",
            "brief_description": "Syntactic and formatting changes to partial code in prompts (dead-code insertion, for↔while switches, operand swaps, variable renamings, tab/space indent changes, newline insertions, docstring↔comment conversion) preserve semantics but can severely change model completions and evaluation outcomes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ReCode robustness evaluation (code syntax & format perturbations)",
            "system_description": "A framework that constructs function-completion prompts by inserting partial canonical solutions and then applying a variety of semantically-preserving code transformations, evaluating model robustness via execution-based tests and worst-case metrics.",
            "nl_description_type": "partial-code prompt accompanied by natural-language docstring (mixed NL & code prompt)",
            "code_implementation_type": "partial Python code in prompt and completed Python implementation",
            "gap_type": "syntactic/format mismatch (formatting or innocuous syntactic edits change model behaviour)",
            "gap_description": "Syntactically valid but semantically invariant changes to the partial code (formatting or refactorings) produce large differences in generated completions. For example, insertion of dead code or simply adding an empty newline before the completion site can cause model outputs to become incorrect. This shows a misalignment between the intent expressed in the prompt (NL + partial code) and the model's conditioning on code contexts.",
            "gap_location": "partial-code context & prompt structure (pre-completion context provided to generator)",
            "detection_method": "Execution of generated code against unit tests after applying randomized syntax/format transformations; human and CodeBLEU checks for preservation of semantics/syntax; targeted failure-case analysis.",
            "measurement_method": "RP_s@k, RD_s@k, RR_s@k per perturbation; CodeBLEU syntax and dataflow similarity between original and perturbed partial code (average syntax/dataflow scores ~0.96–0.97 for many transformations); qualitative failure-case examples.",
            "impact_on_results": "Very large: syntax perturbations often cause the largest performance drops of all categories. Examples from the paper: on HumanEval DeadCodeInserter caused RD_5@1 ≈ 71.21% (CodeGen 2B example: RP drop from 0.402 nominal to 0.116); on MBPP syntax-category RD values reach ≈94–97% for multiple models (extremely large relative drops). Format perturbations (newlines, tab indent) also produce significant RP reductions in some cases; dead-code insertion and newline-before-code are specifically highlighted as effective at causing failures.",
            "frequency_or_prevalence": "High in effect when applied: many syntax/format transformations preserve CodeBLEU (≈0.9+) for syntax/dataflow — the paper reports that ≈77% (syntax) and ≈89% (dataflow) of transformations have CodeBLEU &gt; 0.9 — yet they still produce frequent model failures. Thus, semantic invariance does not prevent high failure rates.",
            "root_cause": "Models are overly sensitive to local syntactic/structural cues in the prompt; they may attend to spurious local patterns (e.g., an immediately preceding for loop) when deciding completion tokens rather than robust program semantics.",
            "mitigation_approach": "Evaluate using worst-case metrics across multiple random perturbations (RP/RD/RR) and incorporate such perturbations into training/augmentation; use code-aware transformations (NatGen-style) and CodeBLEU/dataflow checks to ensure perturbations preserve semantics; analyze failure cases to design targeted defenses.",
            "mitigation_effectiveness": "Mitigation evaluated mainly as diagnostic: CodeBLEU/dataflow confirms semantic preservation of perturbations (so failures are model brittleness rather than perturbation invalidity). The paper finds that larger models and more diverse pretraining improve RP in many cases (but can increase RR), indicating partial effectiveness of model-scale and corpus diversity as mitigations.",
            "domain_or_field": "machine learning / program synthesis / code generation",
            "reproducibility_impact": true,
            "uuid": "e707.2",
            "source_info": {
                "paper_title": "ReCode: Robustness Evaluation of Code Generation Models",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "NL-Augmenter vs Code Keywords",
            "name_full": "Mismatch between general NL-augmentation tools and code-sensitive prompts (keyword corruption)",
            "brief_description": "Applying off-the-shelf natural-language augmentation (NL-Augmenter) to code-related text can produce invalid or unnatural perturbations because code tokens (identifiers, types, syntax) are treated as regular words; this must be mitigated with code-aware constraints.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ReCode augmentation pipeline (NL-Augmenter with tree-sitter constraints)",
            "system_description": "Docstring perturbation pipeline using NL-Augmenter transformations adapted for code prompts; combined with tree-sitter parsing to blacklist program keywords and identifiers from being altered.",
            "nl_description_type": "docstring augmentation using NL-augmentation toolkit",
            "code_implementation_type": "augmentation script applied to prompts (preprocessing step)",
            "gap_type": "augmentation-tool mismatch / missing code-aware constraints (ambiguous/incomplete specification of allowed perturbations)",
            "gap_description": "Direct application of general NL-augmentation methods to docstrings can inadvertently alter or corrupt program keywords, identifiers, or code-like tokens (e.g., producing syntactically invalid or unnatural code references). The paper gives an example where naive perturbation could change \"Create a list a[][]\" into an unnatural/bracket-mismatched form.",
            "gap_location": "data preprocessing / prompt augmentation pipeline",
            "detection_method": "Manual inspection and rule-based detection; use of tree-sitter parsing to identify code tokens that must be excluded from NL perturbations; human evaluation of perturbed outputs.",
            "measurement_method": "Human naturalness scoring (0/0.5/1), semantic-preservation voting; quantitative checks via sentence similarity and CodeBLEU to ensure perturbations don't alter code semantics. The paper reports a 14% average drop in naturalness score for perturbed data (from ≈0.92 to ≈0.75–0.80) and uses tree-sitter to prevent perturbations of code tokens.",
            "impact_on_results": "If unmitigated, augmentation can produce low-quality perturbed prompts that either change semantics or make prompts unnatural/invalid, leading to misleading robustness measurements or invalid model inputs. Mitigation (tree-sitter blacklist) was applied to avoid these issues; after mitigation &gt;90% of perturbed prompts are judged to preserve semantics.",
            "frequency_or_prevalence": "Common risk when applying vanilla NL-augmentation to code-related text; many transformations required customization (paper customized 10 docstring transformations and used tree-sitter to filter keywords).",
            "root_cause": "NL-augmentation tools are developed for natural-language text and do not account for code tokens; lack of explicit specification about which tokens to protect leads to corruption.",
            "mitigation_approach": "Use code-aware parsing (tree-sitter) to extract and blacklist identifiers/types/keywords before applying NL augmentations; post-perturbation validation via human checks and automatic similarity metrics.",
            "mitigation_effectiveness": "Effective in practice as reported: after applying code-aware constraints and validation, the paper reports that majority (&gt;90%) of perturbed prompts preserve semantics by human vote; sentence similarity and CodeBLEU support high-quality perturbations.",
            "domain_or_field": "machine learning / data augmentation for code generation",
            "reproducibility_impact": true,
            "uuid": "e707.3",
            "source_info": {
                "paper_title": "ReCode: Robustness Evaluation of Code Generation Models",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "NL-Augmenter: A Framework for Task-Sensitive Natural Language Augmentation",
            "rating": 2
        },
        {
            "paper_title": "Natgen: Generative pre-training by \"naturalizing\" source code",
            "rating": 2
        },
        {
            "paper_title": "CodeAttack: Code-based adversarial attacks for pre-trained programming language models",
            "rating": 2
        },
        {
            "paper_title": "Adversarial Robustness for Code",
            "rating": 2
        },
        {
            "paper_title": "CodeBLEU: a machine learning benchmark dataset for code understanding and generation",
            "rating": 1
        }
    ],
    "cost": 0.019831750000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ReCode: Robustness Evaluation of Code Generation Models</h1>
<p>Shiqi Wang ${ }^{1,<em>, \ddagger}$ Zheng $\mathbf{L i}^{2,</em>, \dagger}$ Haifeng Qian ${ }^{1}$ Chenghao Yang ${ }^{3, \dagger}$ Zijian Wang ${ }^{1}$<br>Mingyue Shang ${ }^{1}$ Varun Kumar ${ }^{3}$ Samson Tan ${ }^{4}$ Baishakhi Ray ${ }^{1}$ Parminder Bhatia ${ }^{1}$<br>Ramesh Nallapati ${ }^{1}$ Murali Krishna Ramanathan ${ }^{1}$ Dan Roth ${ }^{1}$ Bing Xiang ${ }^{1}$<br>${ }^{1}$ AWS AI Labs ${ }^{2}$ Cornell University ${ }^{3}$ University of Chicago ${ }^{4}$ AWS AI Research \&amp; Education<br>{wshiqi, qianhf,zijwan,bxiang}@amazon.com zl634@cornell.edu</p>
<h4>Abstract</h4>
<p>Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over $90 \%$ of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.</p>
<h2>1 Introduction</h2>
<p>Code generation has emerged as an important AI application. Multiple models (Nijkamp et al., 2022;</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Fried et al., 2022; Wang and Komatsuzaki, 2021) have been proposed and achieved impressive performance on generating code using a natural-language description, on completing partial lines and functions, and even on solving complex coding-contest problems. They can offer real-life help to software engineers and enhance their productivity, and multiple commercial offerings exist today for AIpowered code generation (Chen et al., 2021).</p>
<p>However, one important aspect, robustness of the code generation models, is commonly overlooked. Anecdotally, people know that these models are sensitive to perturbations over prompts: sometimes just an extra space in a line or a slight change to a function name would lead to completely different generations, with potentially negative impacts to usability. In Fig. 1 and Fig. 2, we show two failure cases on InCoder-6B (Fried et al., 2022) and CodeGen-16B-mono (Nijkamp et al., 2022) where they perform correctly on regular prompts but fail on our perturbed ones after docstring paraphrasing and function camel case renaming in our ReCode benchmark. The perturbed prompts are natural and retain the original meaning, indicating weakness of these models if deployed in real-life applications.</p>
<p>There exists no comprehensive and quantitative robustness benchmark for code generation models. Li et al. (2022) includes a brief study on robustness but it has limited perturbation types and is in a setting with massive numbers of samples, unrealistic in practice. Other existing works on robustness in text or code tasks have focused on classification and are not directly applicable to code generation (Zhang et al., 2020; Jha and Reddy, 2022).</p>
<p>In this paper, we present ReCode, a Robustness Evaluation framework for Code, aiming to provide comprehensive assessment for robustness of code generation models. ReCode includes only transformations that (1) appear naturally in practice and (2) preserve the semantic meaning of the original inputs. We carefully collect and customize a com-</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: InCoder-6B predicts correctly on nominal prompt (left) but fails on the prompt where docstrings are paraphrasing with BackTranslation (right). We underline the perturbed positions and wrong model completions.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: CodeGen-16B-mono is correct on nominal prompt (left) but fails when function name is perturbed (right).
prehensive list of natural transformations on docstrings, function and variable names, code syntax, and code format, providing multifaceted assessments of a model's robustness performance. We verify the quality of the perturbed data using both human evaluation and objective similarity scores. We take advantage of the fact that executing the generated code can serve as objective evaluation and define three robustness evaluation metrics that aggregate a model's correctness across randomized transformations and transformation types. These metrics quantify a model's accuracy on perturbed prompts, its relative accuracy drop from original prompts, as well as its general instability.</p>
<p>We summarize our contributions below:</p>
<ul>
<li>We present the first robustness evaluation benchmark ReCode for code generation tasks. Our evaluation framework is general and can be easily extended to any code generation datasets and models. ${ }^{1}$</li>
<li>We collect and customize over 30 natural transformations from the aspects of docstrings, function and variable names, code syntax, and code format. Human evaluation shows that most of the perturbed prompts do not alter the semantic meaning and that their level of naturalness is close to the originals. Quantitative</li>
</ul>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>similarity metrics confirm the same.</p>
<ul>
<li>We propose robustness evaluation metrics for code-generation tasks: Robust Pass ${ }<em x="x">{x} @ \mathrm{k}$, Robust Drop ${ }</em>$.} @ \mathrm{k}$, and Robust Relative ${ }_{x} @ \mathrm{k</li>
<li>We demonstrate the ReCode benchmark on HumanEval and MBPP datasets and present extensive empirical robustness comparisons on state-of-the-art models including CodeGen, InCoder, and GPT-J across different sizes. We find that 1) diverse pretraining corpus and larger model size can help improve the model worst-case robustness, but models may learn to generalize in a non-robust way; 2) code generation models are most sensitive to syntax perturbations; 3) due to diversity, MBPP poses greater changes than HumanEval.</li>
</ul>
<h2>2 Related Work</h2>
<p>Robustness for NLP. Recent research have identified the severe robustness problem in Large Language Models (LLMs) using adversarial examples. For example, LLMs can be easily fooled by synonym replacement (Jin et al., 2020; Zang et al., 2020). To better illustrate the severity of adversarial robustness problems for NLP models, existing works (Nie et al., 2020; Gardner et al., 2020; Kiela et al., 2021; Wang et al., 2021a) build robustness benchmarks, which encourage people to further build robust and trustworthy models. Zhang</p>
<p>et al. (2020) presents a comprehensive overview of works in this field. Most existing works in this field focus on classification tasks rather than generation tasks. The main challenge for benchmarking robustness over generation tasks is that the evaluation of text generation is highly subjective and is usually hard to quantify. However, code generation provides a special opportunity because we can do objective and quantitative evaluation on generated codes, and code generation models use similar model architecture as NLP models.</p>
<p>Robustness for code. There are a series of previous work on different aspects of robustness problems for code. Specifically, Bielik and Vechev (2020) studies the adversarial robustness problem for type inference in programming languages. Yang et al. (2022) focuses on improving the naturalness of adversarial examples in code vulnerability prediction, clone detection and authorship attribution. Zhou et al. (2022) focuses on the adversarial robustness problems of source code comment generation and (Jha and Reddy, 2022) focuses on code translation, repair and summarization. These papers mainly focus on proposing attack and defense methods for different tasks in code domain, but there is no previous work on a comprehensive robustness benchmark for code generation domain.</p>
<p>Code generation. Code generation, also known as program synthesis, is a task of generating code based on natural language statements or code from context. Researchers have adapted transformerbased large language models to the code generation field. Various architectures have been explored: For example, CodeBERT (Feng et al., 2020), PLBART (Ahmad et al., 2021), CodeGPT (Lu et al., 2021) explore BERT, BART and GPT architectures for language models pretrained on code corpus. There are also works that propose to incorporate code structures for models to better understand the semantic information, including GraphCodeBERT (Guo et al., 2021) and CodeT5 (Wang et al., 2021b). Most recently, models with much larger size (i.e., billion-scale parameter numbers) are shown to significantly improve the performance on code generation benchmarks. Codex-12B (Chen et al., 2021) and CodeGen-16B (Nijkamp et al., 2022) are two representative very large pretrained code generation models and have established new state of the arts. However, few works have systematically explored robustness in code generation.</p>
<h2>3 Methodology</h2>
<p>In this section, we introduce the transformations to perturb prompts on both text (docstring) and code. We then propose new robust evaluation metrics.</p>
<h3>3.1 Problem Formulation</h3>
<p>We consider the end-to-end model-based code generation task. The input prompt can include natural language statements that describe the functionality, signature of the function to generate, helper functions, and possibly a half-written function. The goal is left-to-right generation that creates or completes the function. This setting is agnostic to model architectures and is applicable to encoderdecoder or decoder-only models.</p>
<p>We perturb the input prompt with transformations. We focus on natural transformations that preserve the semantic meaning of the original prompt and that are likely to appear in practice, e.g., frequent typos in docstrings, tab to four spaces, function name style changes, and many more. We do not consider adversarial attacks that require model feedbacks in this paper because it is non-trivial to control the naturalness of adversarial attacks and they often require higher computational cost. Instead, we randomly generate perturbed prompts based on the restrictions for each type of perturbations and propose new metrics to evaluate model robustness based on these prompts. We leave adversarial attacks for future work.</p>
<h3>3.2 Natural Transformations on Docstrings</h3>
<p>Docstring describes the target function to generate. Since docstrings can vary greatly when written by different users, robustness against changes in docstrings is critical for usability in applications.</p>
<p>For docstrings, we use the NLAugmenter (Dhole et al., 2021) library which is designed for data augmentation and robustness evaluation on text. ${ }^{2}$ We carefully select ten transformations, including character-level, wordlevel and sentence-level ones, that are likely to preserve semantic similarity. The selected perturbations include CharCaseChange, where random characters are replaced with their upper cases, SynonymSubstitution, where random words are substituted with their WordNet synonyms (Miller, 1992), BackTranslation, where sentences are translated to a different language (e.g., German by default) then back to English for paraphrasing the</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Perturbations</th>
<th style="text-align: center;">MBPP Docstrings</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">Write a function to find all words which are at least 4 characters long in a string by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">BackTranslation</td>
<td style="text-align: center;">Write a function to find all words in a string at least 4 characters long using regex.</td>
</tr>
<tr>
<td style="text-align: center;">ButterFingers</td>
<td style="text-align: center;">Wrile a function to find all words which are ar leas 4 characters long in a string by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">WriTe a fUnctiOn to find All woRds whicH are at leAst 4 ChsRacterS LonG in a string by uMng reGex.</td>
</tr>
<tr>
<td style="text-align: center;">EnglishInflectionalVariation</td>
<td style="text-align: center;">Writes a functions to found all word which was at least 4 character long in a string by use regex.</td>
</tr>
<tr>
<td style="text-align: center;">SwapCharacters</td>
<td style="text-align: center;">rWite a function to find all words which are at elast 4 chraacters long in a string by suing regex.</td>
</tr>
<tr>
<td style="text-align: center;">SynonymInsertion</td>
<td style="text-align: center;">Write a function to find discover all words which are at least 4 characters long in a string by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">SynonymSubstition</td>
<td style="text-align: center;">Write a function to find all words which equal at least 4 character long in a chain by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformationPust</td>
<td style="text-align: center;">Write a function to find all words which was at least 4 characters long in a string by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformationFuture</td>
<td style="text-align: center;">Write a function to find all words which was at least 4 characters long in a string by using regex.</td>
</tr>
<tr>
<td style="text-align: center;">Whitespace</td>
<td style="text-align: center;">Write a function to find all words w hichare at least 4 characters long in a string by using regex.</td>
</tr>
</tbody>
</table>
<p>Table 1: Illustrations for docstring perturbations on a MBPP sample.
whole sentence (Li and Specia, 2019; Sugiyama and Yoshinaga, 2019), and more. To perform perturbations, we extract docstring sentences from the input prompt and then put the perturbed version back to the prompt. See Appendix A for details.</p>
<p>We observe that directly applying NLAugmenter to docstrings without constraints can potentially lead to low quality due to keywords in the programming languages. For example, "Create a list a[][]" could be perturbed by "Create a list [a]]]" by character case swap, which is not natural. Therefore, to guarantee naturalness of perturbations, we use tree-sitter to parse the whole code snippet (the prompt \&amp; the canonical solution) to extract any existing function names, variable names ("a"), and type names ("list"). We then exclude them from being perturbed by the transformations. In Tab. 1, we list all ten transformations that are customized from NL-Augmenter and are included in our robustness benchmark along with sample illustrations.</p>
<h3>3.3 Natural Transformations on Function Names</h3>
<p>Perturbing function names also results in performance drops for code generation models. We summarize our perturbations in Tab. 2.</p>
<p>Some perturbations switch function names between naming conventions. For example, the perturbation called CamelCase transform function names between camel-case (e.g., "findCharLong") and snake-case ("find_char_long").</p>
<p>Other perturbations apply character-level or word-level natural text transformations on component words in a function name, including ChangeCharCase, InflectionalVariation, and SynonymSubstition as discussed in Sect. 3.2.</p>
<h3>3.4 Natural Transformations on Code Syntax</h3>
<p>Code generation models are often used on function completion task where the prompt includes a partial</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">~~</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">        </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">        </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">~~</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">            </span><span class="k">break</span>
<span class="w">        </span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="n">Baseline</span><span class="w"> </span><span class="k">Partial</span><span class="w"> </span><span class="n">Code</span>
<span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="o">[</span><span class="n">same doc string</span><span class="o">]</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">            </span><span class="k">break</span>
<span class="w">        </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">For</span><span class="o">-</span><span class="k">While</span><span class="w"> </span><span class="n">Switch</span>
<span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="o">[</span><span class="n">same doc string</span><span class="o">]</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">lines</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">lines</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">lines</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lines</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">lines</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>(c) Variable Renaming with CodeBERT</p>
<p>Figure 3: An original prompt with partial code (a) and its perturbed versions (b, c).</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Perturbations on Function Names</th>
<th style="text-align: center;">MBPP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nominal</td>
<td style="text-align: center;">find_char_long</td>
</tr>
<tr>
<td style="text-align: left;">CamelCase</td>
<td style="text-align: center;">findCharLong</td>
</tr>
<tr>
<td style="text-align: left;">ButterFingers</td>
<td style="text-align: center;">finf_char_long</td>
</tr>
<tr>
<td style="text-align: left;">SwapCharacters</td>
<td style="text-align: center;">find_cahr_long</td>
</tr>
<tr>
<td style="text-align: left;">ChangeCharCase</td>
<td style="text-align: center;">finD_chark_long</td>
</tr>
<tr>
<td style="text-align: left;">InflectionalVariation</td>
<td style="text-align: center;">found_chars_long</td>
</tr>
<tr>
<td style="text-align: left;">SynonymSubstition</td>
<td style="text-align: center;">discover_char_long</td>
</tr>
</tbody>
</table>
<p>Table 2: Illustrations for function name perturbations on a MBPP sample.
implementation of the target function and the goal is to complete it. In such scenarios, the partial</p>
<p>code in prompt is work in progress and can be subject to frequent editing, and ideally a model should be robust with respect to perturbations in the partial code. For this evaluation, we derive new customized datasets from HumanEval and MBPP by adding half ${ }^{3}$ of the canonical solutions to the prompts (Fig. 3a). Then we perturb such partial code inside prompts. Details and examples for each perturbations can be found in Appendix A.</p>
<p>Transformations on partial code must be syntactically correct and must not alter semantic meaning. The next section will address code format, and let us first focus on code refactoring: these are syntactic changes that are semantically invariant.</p>
<p>We adopt three transformations from NatGen (Chakraborty et al., 2022): (1) Deadcode Insertion where dummy loops ( 0 iterations) or if conditions are randomly inserted; (2) Operand Swap where we randomly swap one operation (e.g., $a<b$ to $b>a$ ); (3) For-While Switch where we randomly transform one for-loop structure in code to equivalent while-loop structure and vice versa.</p>
<p>Additionally, we implement three different schemes of variable renaming. We select the most frequent variable in the partial code and replace it using: (1) using CodeBERT (Feng et al., 2020) predictions with highest aggregated scores according to the context around all its appearance, a method inspired by (Jha and Reddy, 2022; Li et al., 2020), (2) using NatGen style renaming as "VAR_0", and (3) random name generation with half alphabetic and half numeric characters. The first strategy tends to provide more natural variable names, yet names from the other two strategies are also plausible.</p>
<h3>3.5 Natural Transformations on Code Format</h3>
<p>A natural way to perturb partial code is by code format transformations as they preserve the original semantic meaning. We implement following code format transformations in ReCode.</p>
<p>Newline Insertion: We consider three methods of new line insertions: (1) empty lines at randomly selected positions, (2) an empty line inserted between docstring and partial code, and (3) an empty line inserted after partial code.</p>
<p>Tab-Indent: We randomly replace any space indent with tab or replace tab with 4 spaces for indent-sensitive languages like Python.</p>
<p>Line Split: We select the longest line of code and split it into two lines in the middle.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Docstrings to Comments: We convert docstrings to comments (e.g., """ docstring """ to # docstring for Python).</p>
<h3>3.6 Evaluation Metrics</h3>
<p>Many proposed transformations are randomized operations. Hence, we need to measure model robustness over multiple samples to reduce variance. Specifically, for each transformation and each prompt, we create $s$ randomly perturbed prompts. The model under evaluation generates outputs for each of them. We measure the worst-case performance across each group of $s$ perturbed prompts: the model is considered robust on a prompt if and only if it generates a correct solution for all $s$ perturbed prompts, where correctness is measured by executing associated unit tests.</p>
<p>Based on such worst-case measurements, we propose three new metrics for robustness evaluation.</p>
<p>Robust Pass ${ }<em s="s">{s} @ \mathbf{k}\left(\mathbf{R P}</em>} @ \mathbf{k}\right)$ : Pass@k is a widely used metric for measuring the performance of code generation tasks (Chen et al., 2021). We extend its definition to Robust Pass ${ <em s="s">{s} @ \mathrm{k}\left(\mathrm{RP}</em>$ metric as Eq. (1).} @ \mathrm{k}\right)$ with $s$ random perturbations. For an original prompt $x$ and for each transformation, let the perturbed prompts be $x_{1}, \cdots, x_{s}$. We sample $n$ generations by the model for each prompt, and in total there are $n \cdot s$ generations $f_{i}\left(x_{j}\right)$, where $1 \leq i \leq n$ and $1 \leq j \leq$ $s$. Instead of regular pass@k, we first consider the worst-case correctness across $f_{i}\left(x_{1}\right), \ldots, f_{i}\left(x_{s}\right)$ for $1 \leq i \leq n$ : Let $c_{i, s}(x)=1$ if $f_{i}\left(x_{1}\right), \ldots, f_{i}\left(x_{s}\right)$ are all correct and $c_{i, s}(x)=0$ otherwise. Let $r c_{s}(x)=$ $\sum_{i=1}^{n} c_{i, s}(x)$. Following definition of pass@k, we define the $\mathrm{RP}_{s} @ \mathrm{k</p>
<p>$$
\mathrm{RP}<em x="x">{s} @ k:=\mathbb{E}</em>\right]
$$}\left[1-\frac{\binom{n-r c_{s}(x)}{k}}{\binom{n}{k}</p>
<p>Robust Drop $<em s="s">{s} @ \mathbf{k}\left(\mathbf{R D}</em>} @ \mathbf{k}\right)$ : $\mathrm{RP<em s="s">{s} @ k$ directly measure worst-case robustness in absolute values. It provides a worst-case estimation for models under certain perturbation. But in some applications, users may care more about relative performance change to compare worst-case performance and average-case performance. We propose Robust Drop $</em>$ defined in Eq. (2) as another important robustness metric to quantify relative changes.} @ \mathrm{k</p>
<p>$$
\mathrm{RD}<em s="s">{s} @ k:=\frac{\text { Pass@k }- \text { Robust Pass }</em>
$$} @ k}{\text { Pass@k }</p>
<p>Robust Relative ${ }<em s="s">{s} @ \mathbf{k}\left(\mathbf{R R}</em>\right)$ : Lastly, there are cases where models generate incorrect code on} @ \mathbf{k</p>
<p>original prompts yet predict correctly on perturbed ones. This can (arguably) be considered as nonrobust behavior that we should include when reporting model robustness. Let's first consider the case of greedy decoding with $n=k=1$. Let $R C_{s}^{[-]}$ denote the number of correct-to-incorrect changes under the worst-case measurement as discussed. Symmetrically, let $R C_{s}^{[+]}$ denote the number of incorrect-to-correct changes under best-case measurement: if the prediction with the original prompt is incorrect yet is correct for any of the $s$ perturbed prompts. We define the Robust Relative ${ }_{s} @ 1$ metric as the fraction of changes in both directions out of the size of the dataset $(N)$ :</p>
<p>$$
\mathrm{RR}<em s="s">{s} @ 1:=\frac{R C</em>
$$}^{[+]}+R C_{s}^{[-]}}{N</p>
<p>This definition can be generalized to sampling. Let $r c_{s}^{[-]}(x)$ and $r c_{s}^{[+]}(x)$ be similarly defined as $R C_{s}^{[-]}$and $R C_{s}^{[+]}$ except that they are the number of changes within $n$ samples for a prompt $x$ instead of counting across the dataset. We define</p>
<p>$$
\mathrm{RR}<em x="x">{s} @ k:=\mathbb{E}</em>\right]
$$}\left[2-\frac{\binom{n-r c_{s}^{[-]}(x)}{k}}{\binom{n}{k}}-\frac{\binom{n-r c_{s}^{[+]}(x)}{k}}{\binom{n}{k}</p>
<p>Eq. (4) falls back to Eq. (3) when $n=k=1$.
Discussion. $\mathrm{RP}<em s="s">{s} @ k, \mathrm{RD}</em>} @ k$ and $\mathrm{RR<em s="s">{s} @ k$ focus on different robustness requirements in practice. High $\mathrm{RP}</em>} @ k$ does not necessarily mean low $\mathrm{RD<em s="s">{s} @ k$ or $\mathrm{RR}</em> @ k$, because the model may learn to utilize spurious correlation in the datasets to demonstrate better Pass@ $k$ or RP@ $k$, which is not robust. We advocate to report all of them to provide a comprehensive estimation of model robustness.</p>
<h2>4 Evaluation</h2>
<p>Evaluation setup. In this work, we use execution-based code generation benchmarks HumanEval (Chen et al., 2021) and MBPP (Austin et al., 2021) to demonstrate our ReCode robustness evaluation framework. We perform a comprehensive study of robustness evaluation on popular public models including CodeGen (Nijkamp et al., 2022), InCoder (Fried et al., 2022), and GPTJ (Wang and Komatsuzaki, 2021) to show the robustness comparisons across different model architectures and sizes. The perturbations and metrics implemented in ReCode are general and applicable to any code generation datasets and models.</p>
<h3>4.1 Code Generation Robustness Evaluation</h3>
<p>Tab. 3 and Tab. 4 show the general perturbation performances on all the models in terms of the four general perturbation categories including transformations on docstrings, function names, code syntax, and code format. The nominal baselines for docstrings and function name perturbations are the pass@k on nonperturbed datasets. For perturbations on code syntax and format, the nominal baseline is the pass@k on nonperturbed customized datasets with partial code (see Sect. 3.4). We use greedy sampling for all the models to eliminate randomness effect and enable fair comparisons as the default setting. We consider $s=5$, i.e., we generate five different datasets with different random seeds for each type of perturbations and evaluate worst-case robustness performance according to the robustness evaluation metric defined in Sect. 3.6. To evaluate and compare model robustness in a unified fashion, we aggregate the worst performance across different perturbations under each category. Taking the docstring perturbation category as an example, we say the model is robust only when the model predicts correctly on all the $s$ perturbed datasets for each transformation listed in Tab. 1. We present detailed numbers for each perturbation type in Appendix D, Tab. 11-18. In Appendix B, we showcase and analyze failure cases on CodeGen-16B-mono under three top perturbations, causing significant performance drops.
(1) Diverse pretraining corpus helps with both generalization and worst-case robustness. Comparing all code generation models with the same size 6B, CodeGen models have much better nominal performance, and have better robustness on $\mathrm{RP}<em 5="5">{5} @ 1$, a very strict worst-case robustness metric. That is possibly because CodeGen models are pretrained over a more diverse corpus than InCoder and GPT-J and thus have more capacity to deal with unseen instances and perturbations. However, CodeGen models have worse performance on $\mathrm{RD}</em>$
(2) Larger model size brings improvement in} @ 1$ and $\mathrm{RR}_{5} @ 1$, two robustness metrics relative to nominal performance, indicating that CodeGen models cannot generalize in a robust way (e.g., may learn to use spurious features in data). ${ }^{4</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Docstring</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.232 \ &amp; 0.122 \ &amp; 47.37 \ &amp; 20.73 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.140 \ &amp; 0.049 \ &amp; 65.28 \ &amp; 14.63 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.262 \ &amp; 0.104 \ &amp; 60.47 \ &amp; 27.44 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.195 \ &amp; 0.073 \ &amp; 62.50 \ &amp; 18.90 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.305 \ &amp; 0.128 \ &amp; 58.00 \ &amp; 35.37 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.195 \ &amp; 0.098 \ &amp; 50.00 \ &amp; 18.90 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.104 \ &amp; 0.024 \ &amp; 76.47 \ &amp; 14.63 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.152 \ &amp; 0.067 \ &amp; 56.00 \ &amp; 15.85 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.122 \ &amp; 0.037 \ &amp; 70.00 \ &amp; 10.98 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Function</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.232 \ &amp; 0.140 \ &amp; 39.47 \ &amp; 14.02 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.140 \ &amp; 0.061 \ &amp; 56.52 \ &amp; 10.37 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.262 \ &amp; 0.146 \ &amp; 44.19 \ &amp; 18.90 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.195 \ &amp; 0.116 \ &amp; 40.63 \ &amp; 12.20 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.305 \ &amp; 0.116 \ &amp; 30.00 \ &amp; 19.51 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.195 \ &amp; 0.116 \ &amp; 40.63 \ &amp; 9.146 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.104 \ &amp; 0.055 \ &amp; 47.06 \ &amp; 8.537 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.152 \ &amp; 0.098 \ &amp; 36.00 \ &amp; 9.756 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.122 \ &amp; 0.073 \ &amp; 40.00 \ &amp; 6.098 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Syntax</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.402 \ &amp; 0.110 \ &amp; 72.73 \ &amp; 23.17 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.293 \ &amp; 0.067 \ &amp; 77.08 \ &amp; 16.46 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.518 \ &amp; 0.152 \ &amp; 70.59 \ &amp; 32.93 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.366 \ &amp; 0.110 \ &amp; 47.06 \ &amp; 23.78 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.549 \ &amp; 0.159 \ &amp; 46.67 \ &amp; 23.78 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.390 \ &amp; 0.091 \ &amp; 71.11 \ &amp; 25.00 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.189 \ &amp; 0.091 \ &amp; 77.42 \ &amp; 22.56 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.323 \ &amp; 0.079 \ &amp; 77.42 \ &amp; 14.63 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.250 \ &amp; 0.079 \ &amp; 75.47 \ &amp; 21.95 \end{aligned}$</td>
</tr>
</tbody>
</table>
<p>Table 3: ReCode benchmark robustness evaluation on popular code generation models for HumanEval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">MBPP</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Docstring</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.317 \ &amp; 0.137 \ &amp; 56.96 \ &amp; 36.86 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.191 \ &amp; 0.050 \ &amp; 73.66 \ &amp; 34.39 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.361 \ &amp; 0.147 \ &amp; 59.38 \ &amp; 41.89 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.221 \ &amp; 0.042 \ &amp; 80.93 \ &amp; 36.76 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.407 \ &amp; 0.163 \ &amp; 99.85 \ &amp; 46.72 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.241 \ &amp; 0.045 \ &amp; 81.28 \ &amp; 44.66 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.128 \ &amp; 0.011 \ &amp; 91.20 \ &amp; 25.57 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.199 \ &amp; 0.031 \ &amp; 84.54 \ &amp; 35.32 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.133 \ &amp; 0.013 \ &amp; 90.00 \ &amp; 30.08 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Function</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.317 \ &amp; 0.221 \ &amp; 30.42 \ &amp; 19.51 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.191 \ &amp; 0.101 \ &amp; 47.31 \ &amp; 20.43 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.361 \ &amp; 0.252 \ &amp; 30.40 \ &amp; 24.13 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.221 \ &amp; 0.110 \ &amp; 50.23 \ &amp; 22.79 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.407 \ &amp; 0.279 \ &amp; 31.31 \ &amp; 24.95 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.241 \ &amp; 0.139 \ &amp; 62.55 \ &amp; 23.51 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.128 \ &amp; 0.047 \ &amp; 63.20 \ &amp; 16.22 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.199 \ &amp; 0.087 \ &amp; 56.19 \ &amp; 20.02 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.133 \ &amp; 0.043 \ &amp; 67.69 \ &amp; 17.56 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Syntax</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.450 \ &amp; 0.027 \ &amp; 94.06 \ &amp; 59.03 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.285 \ &amp; 0.008 \ &amp; 97.12 \ &amp; 45.07 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.535 \ &amp; 0.027 \ &amp; 95.01 \ &amp; 64.17 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.331 \ &amp; 0.008 \ &amp; 97.52 \ &amp; 47.74 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.571 \ &amp; 0.038 \ &amp; 93.34 \ &amp; 67.04 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.379 \ &amp; 0.017 \ &amp; 95.39 \ &amp; 54.21 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.219 \ &amp; 0.008 \ &amp; 96.24 \ &amp; 54.21 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.292 \ &amp; 0.064 \ &amp; 97.89 \ &amp; 50.60 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.176 \ &amp; 0.004 \ &amp; 97.66 \ &amp; 30.60 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">Format</td>
<td style="text-align: center;">$\begin{gathered} \text { Nominal } \uparrow \ \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1 \% \downarrow \ \mathrm{RR}_{5} @ 1 \% \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.450 \ &amp; 0.333 \ &amp; 26.03 \ &amp; 19.82 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.285 \ &amp; 0.146 \ &amp; 48.92 \ &amp; 25.15 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.535 \ &amp; 0.289 \ &amp; 46.07 \ &amp; 31.11 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.331 \ &amp; 0.166 \ &amp; 49.69 \ &amp; 27.00 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.571 \ &amp; 0.403 \ &amp; 29.32 \ &amp; 25.26 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.379 \ &amp; 0.017 \ &amp; 95.39 \ &amp; 26.59 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.219 \ &amp; 0.008 \ &amp; 96.24 \ &amp; 54.21 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.292 \ &amp; 0.064 \ &amp; 97.89 \ &amp; 50.60 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.176 \ &amp; 0.004 \ &amp; 97.66 \ &amp; 30.60 \end{aligned}$</td>
</tr>
</tbody>
</table>
<p>Table 4: ReCode benchmark robustness evaluation on popular code generation models for MBPP.
worst-case robustness, but may risk overfitting. In general, we observe higher $\mathrm{RP}<em 5="5">{5} @ 1$ for larger models within the same model family (e.g., improved from 0.174 to 0.217 for CodeGen-mono 2B to 16 B on average across all perturbations), indicating larger model helps improve worst-case robustness. Similarly, we observe that larger models usually have larger $\mathrm{RR}</em> @ 1$ (e.g., increased from $27.90 \%$ to $35.91 \%$ for CodeGen-mono 2B to 16B on average), indicating that larger models may risk overfitting as the relative performance drops under perturbations are significant.
(3) Code generation models are most sensitive to syntax perturbation. Among all perturbation types and across MBPP and HumanEval, we observe that syntax perturbations often result in the most performance drops. That reveals a significant limitation of syntax understanding ability of the state-of-the-art code generation models.
(4) Datasets having more variances in code
style poses more challenges on model robustness. In Tab. 5, we can see that models show better robustness on HumanEval over MBPP on average. MBPP has more variances in code style (e.g., indent with 1 space), closer to natural code distribution hence more challenging for model robustness.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Category</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">MBPP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Docstring</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.078</td>
<td style="text-align: center;">0.071</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">60.67</td>
<td style="text-align: center;">75.31</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">19.72</td>
<td style="text-align: center;">36.92</td>
</tr>
<tr>
<td style="text-align: center;">Function</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.113</td>
<td style="text-align: center;">0.142</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">41.61</td>
<td style="text-align: center;">46.59</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">12.06</td>
<td style="text-align: center;">21.01</td>
</tr>
<tr>
<td style="text-align: center;">Syntax</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">0.025</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">72.58</td>
<td style="text-align: center;">93.40</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">33.88</td>
<td style="text-align: center;">47.86</td>
</tr>
<tr>
<td style="text-align: center;">Format</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">0.206</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">43.30</td>
<td style="text-align: center;">45.73</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">22.70</td>
<td style="text-align: center;">24.60</td>
</tr>
</tbody>
</table>
<p>Table 5: Average robustness numbers across all models. MBPP is more challenging for robustness evaluation.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Robust Drop $<em s="s">{s} @ 1$ and Robust Relative $</em> @ 1$ under different $s$. Larger $s$ indicates stronger perturbations evaluated and larger performance drops.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Robust Drop $<em 1="1">{1} @ \mathrm{k}$ and Robust Relative $</em>$ under different $k$ using sampling $n=100$. Robust Drop remains stable while Robust Relative increases with k .} @ \mathrm{k</p>
<h3>4.2 Ablation Study</h3>
<p>Robustness with $s$ perturbed datasets. As described in Sect. 3.6, our robustness metrics consider worst-case performance across $s$ perturbed datasets for each perturbation. Larger $s$ leads to stronger perturbations evaluated, larger performance drops, and more extensive coverage to practical failures. The performance drops will start converging when large enough $s$ evaluated. We can clearly see such trends in Fig. 4 where we evaluate CodeGen-16Bmono $\mathrm{RD}<em s="s">{s} @ 1$ and $\mathrm{RR}</em> @ 1$ under greedy sampling with $s=1, \ldots, 10$. Perturbation categories like docstring and syntax that involve larger searching space and more randomness tend to benefit more with larger $s$ (see Appendix A for details). As a trade-off, evaluation cost linearly increase with $s$. Thus, we recommend $s=5$ as a good balance between cost and evaluation strength. We summarize the ablation study in terms of larger sampling $n$ in Appendix D. 3 which can also benefit our proposed robustness estimation with additional sampling cost.
Stable RD@k and increasing RR@k under different $k$. Pass@k allows the model to have k trials and model performance is often reported with different k . With the sampling setting of $n=100$, we plot the $\mathrm{RD}<em 1="1">{1} @ \mathrm{k}$ and $\mathrm{RR}</em>$ in Fig. 5. Interestingly, we observe that RD@k stays stable across different k while RR@k increases with k . This is because larger k leads to higher nominal pass@k and RP@k but their relative ratio stays similar leading to stable RD. On the other hand, larger k involves more samples potentially changing results on perturbed datasets causing larger RR. Similar} @ \mathrm{k</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">MBPP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Naturalness (Nominal) $\uparrow$</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.92</td>
</tr>
<tr>
<td style="text-align: left;">Naturalness (Perturbed) $\uparrow$</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.80</td>
</tr>
<tr>
<td style="text-align: left;">Semantics Similarity $\uparrow$</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.92</td>
</tr>
</tbody>
</table>
<p>Table 6: Human evaluation for practical naturalness and semantic similarity by 5 annotators. Either $0,0.5$, or 1 is assigned to each data point indicating quality level.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">MBPP</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Syntax Format</td>
<td style="text-align: center;">Syntax</td>
<td style="text-align: center;">Format</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">CodeBLEU (syntax) $\uparrow$</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.96</td>
</tr>
<tr>
<td style="text-align: left;">CodeBLEU (dataflow) $\uparrow$</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">1.00</td>
</tr>
</tbody>
</table>
<p>Table 7: Average CodeBLEU syntax and format scores between non-perturbed codes and perturbed ones with our syntax and format transformations.
trends on CodeGen-2B and 6B in Appendix D. 2 further confirm the observations.</p>
<h3>4.3 Perturbation Sample Quality</h3>
<p>Human evaluation. To verify the naturalness of the perturbations in ReCode, we randomly sample and shuffle 100 and 50 perturbed and nonperturbed MBPP and HumanEval data points and create a shuffle mix of 300 samples. Each sample is shown to 5 human annotators who are familiar with Python and who are asked to rate naturalness out of 0 : not natural, 0.5 : possible to appear in practice but rare, and 1: natural. The scores for naturalness drop $14 \%$ on average for our perturbed data where drops mainly come from typos by Butterfingers, CharCaseChanges, SwapCharacter, etc.</p>
<p>In addition, we randomly sample 100 and 50 pairs perturbed and non-perturbed MBPP and HumanEval data points. Each pair is shown to 5 human annotators who are asked to rate semantics out of 0 : totally changed, 0.5 : slightly changed, and 1 : exactly preserved. We summarize the main results in Tab. 6, and we present statistic details and setup in Appendix C.1. Notably, the majority vote (at least three out of five) is 1 for $90 \%$ of data points. We further provide automatic evaluation below to support the quality of our perturbed datasets, but human evaluation is in general more reliable.</p>
<p>Docstring/function names similarity. We measure the sentence cosine similarity between perturbed and non-perturbed docstrings and function names. We obtain the embeddings by sentence transformers using model all-mpnet-base-v2 ${ }^{5}$ (Song et al., 2020). Note that we split each function name into words to get</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>sentence embeddings. On average, we have 0.93 and 0.81 for docstring and function name perturbations, showing that they well preserve the semantics. Scores for some function name perturbations are sensitive to typos due to the lack of sentence context (e.g., 0.21 for interperse and intErpErse). Appendix C. 2 summarizes detailed numbers for each perturbation.
Code syntax/format similarity. In Tab. 7, we also measure the code similarity using CodeBLEU scores (Lu et al., 2021) for perturbed and nonperturbed data involving code syntax/format transformations. Here we consider the CodeBLEU score with syntax and dataflow separately as the evaluation metrics. On average, we have score 0.96 and 0.97 for CodeBLEU syntax and dataflow, showing good quality of perturbed datasets. Note that a few perturbations should expect low CodeBLEU scores: doc2comments transforms docstrings into comments causing changes of syntax; Deadcode insertion and for-while switch involve new if-conditions, loops, and new variables causing changes of code syntax and dataflow. Please refer to Appendix C. 3 for details.</p>
<h2>5 Conclusion</h2>
<p>In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We collect and customize over 30 natural transformations under categories of docstrings, function names, code syntax, and code format perturbations. These transformations are carefully selected and designed to be natural in practice and preserve the semantic meaning after perturbations. We further propose general worst-case robustness metrics to give a unified overview of the model robustness performance. We empirically demonstrate our ReCode benchmark on popular models including CodeGen, InCoder, and GPT-J using HumanEval and MBPP datasets and function completion tasks derived from them. With human evaluation, over $90 \%$ of our perturbed data are confirmed to preserve the original semantic meaning; sentence similarity and CodeBLEU scores additionally support the quality of perturbations in ReCode.</p>
<h2>Limitations</h2>
<p>ReCode benchmark has several limitations: (1) It contains perturbed datasets based on HumanEval and MBPP which focuses on Python function completion use cases. Therefore, we only perform
evaluation on Python language and not be able to capture robustness in a wide variety of code completion use cases. However, our transformations are generalizable and could be easily extended to other languages and also other coderelated datasets (Athiwaratkun et al., 2023). We encourage researchers to apply and extend ReCode benchmark to additional languages and other coderelated tasks; (2) ReCode benchmark is designed for robustness evaluation and cannot mitigate the lack of robustness. Given that our benchmark can be used to generate comprehensive collection of perturbed data, we believe that it can be used for training data augmentation to enhance model robustness. We will consider corresponding robust training strategy design and evaluation in the future work.</p>
<h2>Ethics Statement</h2>
<p>Our ReCode robustness benchmark aims to provide a comprehensive robustness evaluation framework for any code-generation models, which we believe is critical towards building robust and user-friendly language models for code. With the new robustness evaluation metrics, users can rely on ReCode and assess model predictions with more confidence. The model trainers, on the other hand, will be aware of the potential vulnerabilities that might cause mispredictions in practice and mitigate them before deployments. Therefore, we believe our ReCode benchmark is beneficial in terms of broader impact.</p>
<h2>References</h2>
<p>Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2655-2668, Online. Association for Computational Linguistics.</p>
<p>Ben Athiwaratkun, Sanjay Krishna Gouda, Zijian Wang, Xiaopeng Li, Yuchen Tian, Ming Tan, Wasi Uddin Ahmad, Shiqi Wang, Qing Sun, Mingyue Shang, Sujan Kumar Gonugondla, Hantian Ding, Varun Kumar, Nathan Fulton, Arash Farahani, Siddhartha Jain, Robert Giaquinto, Haifeng Qian, Murali Krishna Ramanathan, Ramesh Nallapati, Baishakhi Ray, Parminder Bhatia, Sudipta Sengupta, Dan Roth, and Bing Xiang. 2023. Multi-lingual evaluation of code generation models. In The 11th International Conference on Learning Representations (ICLR).</p>
<p>Jacob Austin, Augustus Odena, Maxwell I. Nye, Maarten Bosma, Henryk Michalewski, David Dohan,</p>
<p>Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. 2021. Program synthesis with large language models. ArXiv preprint, abs/2108.07732.</p>
<p>Pavol Bielik and Martin T. Vechev. 2020. Adversarial robustness for code. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 896-907. PMLR.</p>
<p>Saikat Chakraborty, Toufique Ahmed, Yangruibo Ding, Premkumar Devanbu, and Baishakhi Ray. 2022. Natgen: Generative pre-training by" naturalizing" source code. ArXiv preprint, abs/2206.07585.</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. ArXiv preprint, abs/2107.03374.</p>
<p>Kaustubh D Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh Gupta, Zhenhao Li, Saad Mahamood, Abinaya Mahendiran, Simon Mille, Ashish Srivastava, Samson Tan, et al. 2021. Nl-augmenter: A framework for task-sensitive natural language augmentation. ArXiv preprint, abs/2112.02721.</p>
<p>Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A pre-trained model for programming and natural languages. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1536-1547, Online. Association for Computational Linguistics.</p>
<p>Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, and Mike Lewis. 2022. Incoder: A generative model for code infilling and synthesis. ArXiv preprint, abs/2204.05999.</p>
<p>Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin, Jiangming Liu, Nelson F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh, Noah A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou. 2020. Evaluating models' local decision boundaries via contrast sets. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1307-1323, Online. Association for Computational Linguistics.</p>
<p>Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin B. Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and Ming Zhou. 2021.</p>
<p>Graphcodebert: Pre-training code representations with data flow. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.</p>
<p>Kilem L Gwet. 2014. Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters. Advanced Analytics, LLC.</p>
<p>Akshita Jha and Chandan K Reddy. 2022. Codeattack: Code-based adversarial attacks for pre-trained programming language models. ArXiv preprint, abs/2206.00052.</p>
<p>Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2020. Is BERT really robust? A strong baseline for natural language attack on text classification and entailment. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 8018-8025. AAAI Press.</p>
<p>Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and Adina Williams. 2021. Dynabench: Rethinking benchmarking in NLP. In North American Association for Computational Linguistics (NAACL), pages 4110-4124.</p>
<p>Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. 2020. BERT-ATTACK: Adversarial attack against BERT using BERT. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6193-6202, Online. Association for Computational Linguistics.</p>
<p>Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, PoSen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022. Competition-level code generation with alphacode. ArXiv preprint, abs/2203.07814.</p>
<p>Zhenhao Li and Lucia Specia. 2019. Improving neural machine translation robustness via data augmentation: Beyond back-translation. In Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019), pages 328-336, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian</p>
<p>Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. Holistic evaluation of language models. ArXiv preprint, abs/2211.09110.</p>
<p>Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. In Thirtyfifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1).</p>
<p>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313-330.</p>
<p>Simon Mille, Kaustubh Dhole, Saad Mahamood, Laura Perez-Beltrachini, Varun Gangal, Mihir Kale, Emiel van Miltenburg, and Sebastian Gehrmann. 2021. Automatic construction of evaluation suites for natural language generation datasets. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1).</p>
<p>George A. Miller. 1992. WordNet: A lexical database for English. In Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992.</p>
<p>Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, J. Weston, and Douwe Kiela. 2020. Adversarial nli: A new benchmark for natural language understanding. In Association for Computational Linguistics (ACL).</p>
<p>Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. 2022. A conversational paradigm for program synthesis. ArXiv preprint, abs/2203.13474.</p>
<p>Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. Mpnet: Masked and permuted pretraining for language understanding. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. ArXiv preprint, abs/2206.04615.</p>
<p>Amane Sugiyama and Naoki Yoshinaga. 2019. Data augmentation using back-translation for contextaware neural machine translation. In Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019), pages 35-44, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Ben Wang and Aran Komatsuzaki. 2021. GPT-J6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/ mesh-transformer-jax.</p>
<p>Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, and Bo Li. 2021a. Adversarial glue: A multitask benchmark for robustness evaluation of language models. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).</p>
<p>Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. 2021b. CodeT5: Identifier-aware unified pretrained encoder-decoder models for code understanding and generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8696-8708, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Zhou Yang, Jieke Shi, Junda He, and David Lo. 2022. Natural attack for pre-trained models of code. ArXiv preprint, abs/2201.08698.</p>
<p>Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, and Maosong Sun. 2020. Word-level textual adversarial attacking as combinatorial optimization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6066-6080, Online. Association for Computational Linguistics.</p>
<p>Wei Emma Zhang, Quan Z Sheng, Ahoud Alhazmi, and Chenliang Li. 2020. Adversarial attacks on deeplearning models in natural language processing: A survey. TIST, 11(3):1-41.</p>
<p>Yu Zhou, Xiaoqing Zhang, Juanjuan Shen, Tingting Han, Taolue Chen, and Harald Gall. 2022. Adversarial robustness of deep code comment generation. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(4):1-30.</p>
<h2>A Transformation Details and Qualitative Examples</h2>
<p>In this section, we give detailed descriptions and settings for each type of perturbations that are included in our ReCode benchmark with qualitative examples for illustrations.</p>
<h2>A. 1 Natural Transformations on Docstrings</h2>
<p>For natural transformations on docstrings, we aim to perturb the docstrings to their variances that preserve the semantics and also appear natural in practice. Specifically, we will first extract and perturb the docstrings with the following natural transformations in each prompt, and then attach their perturbed versions to the prompt. To preserve semantics for the code generation task prompts, we extract a blacklist of program keywords using treesitter as discussed in Sect. 3.2 that are excluded from perturbations. We extend most transformations from NL-Augmenter (Dhole et al., 2021), a standard library designed for data augmentation and robustness evaluation on text. We list some qualitative examples in Tab. 1.</p>
<p>BackTranslation. BackTranslation paraphrases the docstrings by translating them to another language (in this case, German) and then back to English. It is a common method for data augmentation in generating sentence variances with the same semantics (Li and Specia, 2019; Sugiyama and Yoshinaga, 2019). Overall, it can reliably generate high quality perturbed docstrings. We use the default implementation in NL-Augmenter (Dhole et al., 2021). BackTranslation contains no randomness in transformations.</p>
<p>ButterFingers. ButterFingers transformation randomly selects characters of the docstrings and perturbs each of them to a random subset of similar characters, it is from (Dhole et al., 2021) and is also used in (Mille et al., 2021). Since this transformation tends to introduce character-level typos, we set randomness for perturbing each character to be low as 0.05 for naturalness consideration.</p>
<p>ChangeCharCase. ChangeCharCase transformation randomly changes the selected characters to upper case in the docstrings. We use the default probability 0.35 where majority annotators vote 0.5 for naturalness in the setting of Sect. 4.3.</p>
<p>EnglishInflectionalVariation. This transformation randomly selects words in the docstring and change them to a random inflection variance. This can be from plural to singular (or vice versa) for nouns and tense changes for verbs. To maintain naturalness, the perturbation is constrained to be the same Part of Speech (POS) tag in the Penn Treebank (Marcus et al., 1993).</p>
<p>SwapCharacters. This transformation randomly selects pairs of adjacent characters in the docstring and swap them. This represents a common type of typos by humans. To ensure naturalness, we set the probability as 0.05 for making the swap.</p>
<p>SynonymInsertion. This transformation randomly select words in the docstrings and inserts their synonyms in WordNet (Miller, 1992). Punctuations and stopwords are excluded. We set the probability to be 0.35 considering low success rate after keywords filtering.</p>
<p>SynonymSubstitution. This transformation randomly selects words in the docstring and replaces each one with a synonym from WordNet (Miller, 1992). Similar to SynonymInsertion, we set the probability as 0.35 to balance naturalness and perturbation success rates.</p>
<p>TenseTransformationPast. This is a deterministic transformation that converts sentences in the docstring to past tense.</p>
<p>TenseTransformationFuture. This is a deterministic transformation that converts sentences in the docstring to future tense.</p>
<p>Whitespace. This transformation inserts or deletes a single white space at randomly selected locations in the docstring. This represents a common type of typos by humans. Folowing NL-Augmenter, we use probability 0.1 for adding whitespaces and 0.05 for removing whitespaces.</p>
<h2>A. 2 Natural Transformations on Function Names</h2>
<p>These transformations modify the name of the target function to generate. Any references to the function name in the prompt, e.g., in docstring, are also modified to maintain consistency. Qualitative examples can be found in Tab. 2.</p>
<p>CamelCase. A function name is often composed of multiple words. If the original function name concatenates the words in camel-case style, this</p>
<p>transformation changes it to snake-case, and vice versa. This transformation is deterministic.</p>
<p>ButterFingers. ButterFingers transformation randomly selects characters of the docstrings and perturbs each of them to a random subset of similar characters, it is from (Dhole et al., 2021) and is also used in (Mille et al., 2021). Since this transformation tends to introduce character-level typos, we set randomness for perturbing each character to be low as 0.05 for naturalness consideration.</p>
<p>SwapCharacters. This transformation randomly selects pairs of adjacent characters in the function name and swap each pair. This represents a common type of typos by humans. To control naturalness, we set the probability to be 0.05 , same setting as the docstring perturbations.</p>
<p>ChangeCharCase. ChangeCharCase transformation randomly changes the selected characters to upper case in the docstrings. We use the default probability 0.35 where majority annotators vote 0.5 for naturalness in the setting of Sect. 4.3.</p>
<p>InflectionalVariation. This transformation randomly selects words in the function name and applies a random inflection on them. This can be from plural to singular (or vice versa) for nouns and tense change for verbs. To control naturalness, the perturbation is constrained to be the same Part of Speech (POS) tag in the Penn Treebank (Marcus et al., 1993).</p>
<p>SynonymSubstitution. This transformation randomly selects words in the docstring and replaces each one with a synonym from WordNet (Miller, 1992). Similar to SynonymInsertion, we set the probability as 0.35 to balance naturalness and perturbation success rates.</p>
<h2>A. 3 Natural Transformations on Code Syntax</h2>
<p>These transformations modify the code content in the prompt. We derived function completion tasks with half the code from the canonical solutions such that the following code transformations and robustness evaluation can be performed. To guarantee fair comparisons to the nominal baseline, we make sure that we have the same block of code before and after code perturbations. In the following part we show qualitative examples on the same MBPP sample baseline ( Fig. 6).</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 6: An baseline example of the prompt with partial code derived from original MBPP prompt for robustness evaluation on code.</p>
<p>DeadCodeInserter. This transformation inserts a block of useless code at a random location. The added block can be a loop of zero iteration or an if condition that is always false. The code content inside the dummy loop or if condition is randomly selected from the adjacent code statements with limited tree-sitter node sizes.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="k">false</span><span class="err">:</span>
<span class="w">        </span><span class="k">break</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">                </span><span class="k">break</span>
</code></pre></div>

<p>Figure 7: An example of the DeadCodeInserter perturbation.</p>
<p>For-While Switch. This transformation randomly selects a for-loop or while-loop in the prompt and transforms it to its equivalent counterpart.</p>
<p>OperandSwap. This transformation randomly selects a binary logical operation, swaps the two operands, and modifies the operator if necessary to maintain semantic equivalence.</p>
<p>VarRenamerCB. This transformation selects the most frequently referenced variable name in the partial code and replaces it throughout the prompt with a new name obtained by CodeBERT (Feng</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 8: An example of the For-While Switch perturbation.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">        </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">        </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="k">while</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">iist</span><span class="p">(</span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 9: An example of the OperandSwap perturbation.
et al., 2020). Specifically, we replace all occurrence of the variable name with a mask token, and then run CodeBERT inference to obtain candidate names at each location, where each candidate name comes with a probability score. We pick the candidate name with the highest aggregated score across locations. This transformation is inspired by (Jha and Reddy, 2022; Li et al., 2020).</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">Lines</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Lines</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">lines</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">Lines</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Lines</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Lines</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">                </span><span class="k">break</span>
</code></pre></div>

<p>Figure 10: An example of the VarRenamerCB perturbation.</p>
<p>VarRenamerNaive. This transformation selects the most frequently referenced variable name in the partial code and replaces it with "VAR_0". This is the original implementation in the NatGen package. This transformation is deterministic.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">VAR_0</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">        </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">        </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">        </span><span class="ss">&quot;heo&quot;</span>
<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">        </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">        </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">        </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">VAR_0</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">VAR_0</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">VAR_0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">VAR_0</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">VAR_0</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">                </span><span class="k">break</span>
</code></pre></div>

<p>Figure 11: An example of the VarRenamerNaive perturbation.</p>
<p>VarRenamerRN. This transformation selects the most frequently referenced variable name in the partial code and replaces it with a random string with half alphabetic and half numeric characters.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">r5</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">        </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">        </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">r5</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">r5</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">ch</span><span class="p">:</span>
<span class="w">            </span><span class="n">r5</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">r5</span><span class="o">[</span><span class="n">0:i</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">r5</span><span class="o">[</span><span class="n">i + 1 :</span><span class="o">]</span>
<span class="w">                </span><span class="k">break</span>
</code></pre></div>

<p>Figure 12: An example of the VarRenamerRN perturbation.</p>
<h2>A. 4 Natural Transformations on Code Format</h2>
<p>Tab-Indent. This transformation replaces any space indents with tabs or replaces tabs with 4 spaces for indent-sensitive languages like Python. This transformation is deterministic.</p>
<p>Line Split. This transformation splits the longest line in the partial code into two lines. This transformation is deterministic.</p>
<p>Doc2Comments. This transformation changes the style of the documentation in the prompt. For Python, it converts docstring (e.g., """ docstring " " ") to commented lines (e.g., # docstring) and vice versa. For Java, it converts comments in the</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 13: An example of the Tab-Indent perturbation.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">0: \mathrm{i}</span><span class="o">]+</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">\mathrm{i}+1:</span><span class="o">]</span><span class="err">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 14: An example of the Line Split perturbation.
format of / * docstring $* /$ to // docstring and vice versa. This transformation is deterministic.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">*</span><span class="w"> </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="o">*</span><span class="w"> </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">0: \mathrm{i}</span><span class="o">]+</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">\mathrm{i}+1:</span><span class="o">]</span><span class="err">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 15: An example of the Doc2Comments perturbation.</p>
<p>NewlineRandom. This transformation inserts empty lines at randomly selected positions.</p>
<p>NewlineAfterCode. This transformation inserts an empty line at the end of the prompt. This transformation is deterministic.</p>
<p>NewlineAfterDoc. This transformation inserts an empty line between the docstring and the partial code. This transformation is deterministic.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 16: An example of the NewlineRandom perturbation.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">0: \mathrm{i}</span><span class="o">]+</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">\mathrm{i}+1:</span><span class="o">]</span><span class="err">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 17: An example of the NewlineAfterCode perturbation.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">Write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">python</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">remove</span>
<span class="w">    </span><span class="k">first</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">occurrence</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span>
<span class="w">    </span><span class="n">given</span><span class="w"> </span><span class="k">character</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">string</span><span class="p">.</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;hello&quot;</span><span class="p">,</span><span class="ss">&quot;l&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;heo&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;abcda&quot;</span><span class="p">,</span><span class="ss">&quot;a&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;bcd&quot;</span>
<span class="w">    </span><span class="o">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">remove_Occ</span><span class="p">(</span><span class="ss">&quot;PHP&quot;</span><span class="p">,</span><span class="ss">&quot;P&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="ss">&quot;H&quot;</span>
<span class="w">    </span><span class="o">***</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">ch</span><span class="p">)</span><span class="err">:</span>
<span class="w">            </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">0: \mathrm{i}</span><span class="o">]+</span><span class="err">\</span><span class="n">mathrm</span><span class="err">{</span><span class="n">s</span><span class="err">}</span><span class="o">[</span><span class="n">\mathrm{i}+1:</span><span class="o">]</span><span class="err">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">break</span>
</code></pre></div>

<p>Figure 18: An example of the NewlineAfterDoc perturbation.</p>
<h2>B Failure Case Study under Perturbations</h2>
<p>In this section, we showcase and analyze some failure cases on CodeGen-16B-mono and perturbed HumanEval datasets under three top perturbations that will cause significant performance drops.</p>
<p>DeadCode insertion is one of the most effective</p>
<p>perturbations. It can commonly mislead the model predictions with the inserted dead code, especially when the completions are required right after the inserted dead code. Fig. 19 shows an failure example where CodeGen-mono-16B only predicts a newline after inserted meaningless for loop, which might be mislead by the inserted return statement.</p>
<div class="codehilite"><pre><span></span><code>def change_base(x: int, base: int):
    &quot;&quot;&quot;Change numerical base of input number
    x to base. return string representation
    after the conversion.
    base numbers are less than 10.
    &gt;&gt;&gt; change_base(8, 3)
    &#39;22&#39;
    &gt;&gt;&gt; change_base(8, 2)
    &#39;1000&#39;
    &gt;&gt;&gt; change_base(7, 2)
    &#39;111&#39;
    &quot;&quot;&quot;
    ret = &quot;&quot;
    while x &gt; 0:
        ret = str(x % base) + ret
        x = x // base
    return ret
</code></pre></div>

<p>(a) Correct completion without perturbation.
def change_base(x: int, base: int):
""Change numerical base of input number
$x$ to base. return string representation
after the conversion.
base numbers are less than 10 .</p>
<blockquote>
<blockquote>
<blockquote>
<p>change_base(8, 3)
'22'
change_base(8, 2)
'1000'
change_base(7, 2)
'111'
$<em> * </em>$
ret $=$ ""
while $x&gt;0$ :
for i 3 in range(0):
return ret
[empty line]
<img alt="img-7.jpeg" src="img-7.jpeg" />
(b) Wrong completion perturbed by deadcode insertion.</p>
</blockquote>
</blockquote>
</blockquote>
<p>Figure 19: HumanEval showcase 1 illustrating failure case under deadcode insertion.</p>
<p>Fig. 20 shows a failure example of CodeGen-16B-mono on a prompt where an empty newline is inserted right before completion. Such simple perturbation causes wrong predictions for the following if-else conditions. It is especially effective when the required completion code is complicated.</p>
<p>ButterFingers perturbation on docstring causes large performance drops as well. Fig. 21 shows another falure example on CodeGen-16B-mono. The typos introduced in the perturbation might cause the model to misunderstand the targeted docstrings, leading to wrong model completions.</p>
<div class="codehilite"><pre><span></span><code><span class="n">def</span><span class="w"> </span><span class="n">sum_squares</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="ss">&quot; &quot;</span><span class="w"> </span><span class="ss">&quot;</span>
<span class="ss">    This function will take a list of integers.</span>
<span class="ss">    For all entries in the list, the function</span>
<span class="ss">    shall square the integer entry if its index</span>
<span class="ss">    is a multiple of 3 and will cube the integer</span>
<span class="ss">    entry if its index is a multiple of 4 and</span>
<span class="ss">    not a multiple of 3. The function will not</span>
<span class="ss">    change the entries in the list whose indexes</span>
<span class="ss">    are not a multiple of 3 or 4. The function</span>
<span class="ss">    shall then return the sum of all entries.</span>
<span class="ss">    Examples:</span>
<span class="ss">    For lst = [1,2,3] the output should be 6</span>
<span class="ss">    For lst = [] the output should be 0</span>
<span class="ss">    For lst = [-1,-5,2,-1,-5] the output should</span>
<span class="ss">    be -126</span>
<span class="ss">    &quot;</span><span class="w"> </span><span class="ss">&quot; &quot;</span>
<span class="w">    </span><span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[]</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">lst</span><span class="p">))</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="mi">3</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="err">:</span>
<span class="w">            </span><span class="k">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">lst</span><span class="o">[</span><span class="n">i</span><span class="o">]**</span><span class="mi">2</span><span class="p">)</span>
<span class="w">        </span><span class="n">elif</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="mi">4</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="mi">3</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="err">:</span>
<span class="w">            </span><span class="k">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">lst</span><span class="o">[</span><span class="n">i</span><span class="o">]**</span><span class="mi">3</span><span class="p">)</span>
<span class="w">            </span><span class="k">else</span><span class="err">:</span>
<span class="w">                </span><span class="k">result</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">lst</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="k">result</span><span class="p">)</span>
</code></pre></div>

<p>(a) Correct completion without perturbation.
def sum_squares(lst):
" " "
This function will take a list of integers. For all entries in the list, the function shall square the integer entry if its index is a multiple of 3 and will cube the integer entry if its index is a multiple of 4 and not a multiple of 3. The function will not change the entries in the list whose indexes are not a multiple of 3 or 4 . The function shall then return the sum of all entries.</p>
<p>Examples:
For lst $=[1,2,3]$ the output should be 6
For lst $=[]$ the output should be 0
For lst $=[-1,-5,2,-1,-5]$ the output should
be -126
" " "
result $=$ []
for i in range(len(lst)):
if i $\% 3==0$ :
result.append(lst[i]<strong>2)
(new line)
elif i $\% 4==0$ and i $\% 3$ != 0: result.append(lst[i]</strong>3)
return sum(result)
<img alt="img-8.jpeg" src="img-8.jpeg" />
(b) Wrong completion perturbed by NewlineAfterCode insertion.
Figure 20: HumanEval showcase 2 illustrating failure case under NewlineAfterCode insertion.</p>
<h2>C Perturbation Sample Quality</h2>
<h2>C. 1 Details for Human Evaluation</h2>
<p>The annotators are all recruited from software engineers online who have good experience in Python via strict coding interview. To guarantee the reliability of the human evaluation results, we first conducted annotation trials with our annotators. We gave them clear definitions for each level of naturalness and semantic similarity.</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" />
(a) Correct completion without perturbation.
def truncate_number(number: float) -&gt; float:
""" Givfn a positive floating point number,
it can be decimposey into and integer part
(largest integer smeller than given number)
and decimals (leftover part always smaller
that 1).
Return the decimal part of the number.</p>
<blockquote>
<blockquote>
<blockquote>
<p>truncate_number(3.5)
0.5
"""
return number - int(number)
Original
completion
(a) Correct completion without perturbation.
def truncate_number(number: float) -&gt; float:
""" Givfn a positive floating point number,
it can be decimposey into and integer part
(largest integer smeller than given number)
and decimals (leftover part always smaller
that 1).
Return the decimal part of the number.
truncate_number(3.5)
0.5
"""
return int(number) + (number - int(number))
New
completion
(b) Wrong completion perturbed by ButterFingers.</p>
</blockquote>
</blockquote>
</blockquote>
<p>Figure 21: HumanEval showcase 3 illustrating failure case under ButterFingers perturbations on docstrings.</p>
<p>We measure the inter-annotator agreement rate Fless Kappa in Tab. 8. The overall average Fleiss Kappa for the annotations is $0.52,0.36$ for semantic and naturalness measurements on perturbed samples. The confidence interval ( $95 \%$ ) with bootstrap sampling ( 10 K samples) is $[0.515,0.528]$ and $[0.358,0.364]$, indicating that our annotation reaches "moderate agreement" and thus our annotations are reliable (Gwet, 2014). The scores from annotators are not perfectly consistent especially for naturalness since people have different preferences for code.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Fleiss Kappa</th>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">MBPP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Naturalness (Nominal) $\uparrow$</td>
<td style="text-align: center;">0.362</td>
<td style="text-align: center;">0.301</td>
</tr>
<tr>
<td style="text-align: left;">Naturalness (Perturbed) $\uparrow$</td>
<td style="text-align: center;">0.435</td>
<td style="text-align: center;">0.326</td>
</tr>
<tr>
<td style="text-align: left;">Semantics Similarity $\uparrow$</td>
<td style="text-align: center;">0.658</td>
<td style="text-align: center;">0.461</td>
</tr>
</tbody>
</table>
<p>Table 8: Fleiss Kappa of human evaluation.</p>
<h2>C. 2 Sentence Transformers for Docstring/Function Names Similarity</h2>
<p>In this subsection, we give experimental details for measuring the sentence similarity of perturbed and unperturbed data points using sentence transformers.</p>
<p>To measure the similarity scores for the docstring perturbations, we first extract docstrings from each pair of perturbed and unperturbed data points, and we use sentence transformer all-mpnet-base-v2 (Song et al., 2020) to predict
an embedding vector for each docstring. Then cosine similarity is calculated and reported for each pair of perturbed and unperturbed datapoints.</p>
<p>Same process cannot be directly applied to function name perturbations since function names are concatenations of words instead of common sentences, barely seen by the sentence transformer training data. In order get more accurate sentence embeddings for function names, we first split each name into words (e.g., has_close_elements to has close elements) and then calculate the corresponding cosine similarities.</p>
<p>In Table 9, we present the detailed results for each type of perturbations for sentence similarity. On average, we can have 0.93 and 0.92 similarity scores for docstring perturbations and 0.80 and 0.81 for function name perturbations on the Hu manEval and MBPP datasets. The overall high similarity numbers provide support that our perturbations have good quality in naturalness and semantic preservation from the unperturbed inputs.</p>
<p>Some function name perturbations including ButterFinger, SynonymSubstitution, and CharCaseChange have relatively low sentence similarity. This is mainly because the function names only include keywords without complete sentence context and thus minor changes to each words could potentially cause large change in measured cosine similarity. For instance, character case changes on function name intersperse to intErspErse which lacks of context only has 0.21 similarity. On the other hand, the function names with more context has much higher scores, e.g., 1.0 similarity score for has_close_elements and has_ClosE_Elements.</p>
<h2>C. 3 CodeBLEU Scores for Code Similarity</h2>
<p>Here we present the experimental details for the CodeBLEU syntax and dataflow scores to quantitatively measure the quality of our code syntax and format transformations.</p>
<p>The measurement is straightforward. The unperturbed baseline is each data point from our customized partial code datasets derived from HumanEval and MBPP. The perturbed one is the same data point transformed by each type of our perturbations. The CodeBLEU syntax and dataflow scores are then directly measured using the CodeXGLUE (Lu et al., 2021) implementation. ${ }^{6}$</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Categories</th>
<th style="text-align: center;">Perturbations</th>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">MBPP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Docstring</td>
<td style="text-align: center;">BackTranslation</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.95</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ButterFingers</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.89</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">EnglishInflectionalVariation</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.93</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SwapCharacters</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.87</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SynonymInsertion</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.88</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SynonymSubstitution</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TenseTransformationPast</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">TenseTransformationFuture</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.97</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Whitespace</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.86</td>
</tr>
<tr>
<td style="text-align: center;">Function</td>
<td style="text-align: center;">CamelCase</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ButterFingers</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.57</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SwapCharacters</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.75</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.96</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">InflectionalVariation</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.93</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SynonymSubstition</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.64</td>
</tr>
</tbody>
</table>
<p>Table 9: Cosine similarity for each type of perturbations where perturbed and unperturbed docstrings/function names are embedded by the SOTA sentence transformer.</p>
<p>In Table 10, we present the detailed CodeBLEU results for each type of perturbations. The average numbers are summarized in Table 7. Overall, $77 \%$ and $89 \%$ of our transformations have over 0.9 CodeBLEU syntax and dataflow scores, showing good quality in preserving semantics from the unperturbed code.</p>
<p>However, CodeBLEU syntax and dataflow are not perfect in quantitatively measuring naturalness and semantic preservation for the perturbations and thus some perturbations have expected relatively low scores: Doc2Comments transforms docstrings into comments causing changes of syntax; Deadcode insertion and for-while switch involve new if-conditions, loops, and new variables causing changes of code syntax and dataflow.</p>
<h2>D Additional Results</h2>
<h2>D. 1 Fine-grained Robustness Evaluation</h2>
<p>We present the robustness evaluation for each type of perturbations from Table 11 to 18, . The evaluation setting is the same as Table 3 and 4 where we evaluate various sizes of CodeGen (Nijkamp et al., 2022), InCoder (Fried et al., 2022), and GPTJ (Wang and Komatsuzaki, 2021) with greedy sampling. For each type of perturbations, we randomly generate $s=5$ different perturbed datasets derived from HumanEval and MBPP. For perturbations without randomness, only one single version of perturbed dataset is evaluated. The list of indeterministic perturbations can be found in Appendix A.</p>
<h2>D. 2 Additional Results for Different $k$</h2>
<p>As discussed in Sect. 4.2, we observe that Robust Drop stays stable across different k while Robust Relative increases linearly with k . We present additional results on CodeGen-2B-mono, CodeGen-6Bmono along with CodeGen-16B-mono in Fig. 22. We evaluate each model with large $n(n=100)$ using top-p sampling strategy with probability 0.95 and temperature 0.2 .</p>
<h2>D. 3 Additional Results for Large Sampling $\mathbf{n}$</h2>
<p>Larger sampling $n$ is commonly used for preventing model generation variances and providing accurate estimations. The evaluation cost increases linearly to $n$. Here we show that larger $n$ can also benefit our proposed three robustness metrics but not causing significant differences. In specific, we measure Robust Pass ${ }<em 1="1">{1} @ 1$, Robust Drop ${ }</em> @ 1$ on CodeGen-16B-mono and HumanEval dataset. The model is run with $n=100$ using top-p sampling strategy with probability 0.95 and temperature 0.2 . We present detailed results in Tab. 19.} @ 1$, and Robust Relative ${ }_{1</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Categories</th>
<th style="text-align: center;">Perturbations</th>
<th style="text-align: center;">HumanEval CodeBLEU (syntax)</th>
<th style="text-align: center;">CodeBLEU (dataflow)</th>
<th style="text-align: center;">MBPP <br> CodeBLEU (syntax)</th>
<th style="text-align: center;">CodeBLEU (dataflow)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Syntax</td>
<td style="text-align: center;">DeadCodeInserter</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.67</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">For-While Switch</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.86</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OperandSwap</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">VarRenamerCB</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">VarRenamerNaive</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">VarRenamerRN</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;">Format</td>
<td style="text-align: center;">Tab-Indent</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Line Split</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Doc2Comments</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NewlineRandom</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NewlineAfterCode</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NewlineAfterDoc</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
</tbody>
</table>
<p>Table 10: CodeBLEU syntax and format similarity scores between unperturbed codes and perturbed ones with each type of our syntax and format transformations.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen 2B mono</th>
<th style="text-align: center;">CodeGen 2B multi</th>
<th style="text-align: center;">CodeGen 6B mono</th>
<th style="text-align: center;">CodeGen 6B multi</th>
<th style="text-align: center;">CodeGen 16B mono</th>
<th style="text-align: center;">CodeGen 16B multi</th>
<th style="text-align: center;">InCoder 1B</th>
<th style="text-align: center;">InCoder 6B</th>
<th style="text-align: center;">GPT-J 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.122</td>
</tr>
<tr>
<td style="text-align: center;">BackTranslation</td>
<td style="text-align: center;">$\begin{gathered} \mathrm{RP}<em 5="5">{5} @ 1 \uparrow \ \mathrm{RD}</em>$} @ 1(\%) \downarrow \end{gathered</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.213 \ &amp; 7.89 \ &amp; 4.27 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.116 \ &amp; 17.39 \ &amp; 6.10 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.238 \ &amp; 9.30 \ &amp; 8.54 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.159 \ &amp; 18.75 \ &amp; 6.10 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.244 \ &amp; 20.00 \ &amp; 10.98 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.152 \ &amp; 21.88 \ &amp; 5.49 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.098 \ &amp; 5.88 \ &amp; 3.05 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.134 \ &amp; 12.00 \ &amp; 3.05 \end{aligned}$</td>
<td style="text-align: center;">$\begin{aligned} &amp; 0.098 \ &amp; 20.00 \ &amp; 3.66 \end{aligned}$</td>
</tr>
<tr>
<td style="text-align: center;">ButterFingers</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.165</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.067</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.067</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">28.95</td>
<td style="text-align: center;">30.43</td>
<td style="text-align: center;">34.88</td>
<td style="text-align: center;">37.50</td>
<td style="text-align: center;">38.00</td>
<td style="text-align: center;">40.62</td>
<td style="text-align: center;">35.29</td>
<td style="text-align: center;">36.00</td>
<td style="text-align: center;">45.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">15.85</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">20.12</td>
<td style="text-align: center;">12.20</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">6.71</td>
</tr>
<tr>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.037</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.049</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">34.21</td>
<td style="text-align: center;">43.48</td>
<td style="text-align: center;">41.86</td>
<td style="text-align: center;">46.88</td>
<td style="text-align: center;">42.00</td>
<td style="text-align: center;">37.50</td>
<td style="text-align: center;">64.71</td>
<td style="text-align: center;">36.00</td>
<td style="text-align: center;">60.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">12.80</td>
<td style="text-align: center;">10.98</td>
<td style="text-align: center;">15.85</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">17.68</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">7.93</td>
</tr>
<tr>
<td style="text-align: center;">EnglishInflectional Variation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.268</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.104</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">10.53</td>
<td style="text-align: center;">4.35</td>
<td style="text-align: center;">13.95</td>
<td style="text-align: center;">12.50</td>
<td style="text-align: center;">12.00</td>
<td style="text-align: center;">9.38</td>
<td style="text-align: center;">11.76</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">15.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">1.22</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">3.05</td>
</tr>
<tr>
<td style="text-align: center;">SwapCharacters <br> Perturbation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.183</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.067</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">31.58</td>
<td style="text-align: center;">30.43</td>
<td style="text-align: center;">30.23</td>
<td style="text-align: center;">34.38</td>
<td style="text-align: center;">32.00</td>
<td style="text-align: center;">31.25</td>
<td style="text-align: center;">17.65</td>
<td style="text-align: center;">32.00</td>
<td style="text-align: center;">45.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">12.20</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">12.80</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">17.07</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">6.10</td>
</tr>
<tr>
<td style="text-align: center;">Synonym Insertion</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.183</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.067</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.079</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">21.05</td>
<td style="text-align: center;">26.09</td>
<td style="text-align: center;">39.53</td>
<td style="text-align: center;">34.38</td>
<td style="text-align: center;">26.00</td>
<td style="text-align: center;">34.38</td>
<td style="text-align: center;">35.29</td>
<td style="text-align: center;">32.00</td>
<td style="text-align: center;">35.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">14.63</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">15.85</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">5.49</td>
</tr>
<tr>
<td style="text-align: center;">Synonym <br> Substitution</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.201</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.073</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.061</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">36.84</td>
<td style="text-align: center;">34.78</td>
<td style="text-align: center;">39.53</td>
<td style="text-align: center;">46.88</td>
<td style="text-align: center;">34.00</td>
<td style="text-align: center;">28.12</td>
<td style="text-align: center;">29.41</td>
<td style="text-align: center;">48.00</td>
<td style="text-align: center;">50.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">17.07</td>
<td style="text-align: center;">10.98</td>
<td style="text-align: center;">15.24</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">6.71</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformation <br> Past</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.250</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.110</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-7.89$</td>
<td style="text-align: center;">$-4.35$</td>
<td style="text-align: center;">9.30</td>
<td style="text-align: center;">3.13</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">12.50</td>
<td style="text-align: center;">$-5.88$</td>
<td style="text-align: center;">12.00</td>
<td style="text-align: center;">10.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.22</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformation Future</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.250</td>
<td style="text-align: center;">0.183</td>
<td style="text-align: center;">0.311</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.110</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-2.63$</td>
<td style="text-align: center;">13.04</td>
<td style="text-align: center;">4.65</td>
<td style="text-align: center;">6.25</td>
<td style="text-align: center;">$-2.00$</td>
<td style="text-align: center;">12.50</td>
<td style="text-align: center;">17.65</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">10.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.22</td>
</tr>
<tr>
<td style="text-align: center;">Whitespace <br> Perturbation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.073</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.049</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">36.84</td>
<td style="text-align: center;">39.13</td>
<td style="text-align: center;">44.19</td>
<td style="text-align: center;">37.50</td>
<td style="text-align: center;">42.00</td>
<td style="text-align: center;">37.50</td>
<td style="text-align: center;">29.41</td>
<td style="text-align: center;">40.00</td>
<td style="text-align: center;">60.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">14.02</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">15.85</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">22.56</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">10.98</td>
<td style="text-align: center;">7.32</td>
</tr>
</tbody>
</table>
<p>Table 11: Robustness evaluation for each type of docstring perturbations on HumanEval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">MBPP</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.317</td>
<td style="text-align: center;">0.191</td>
<td style="text-align: center;">0.361</td>
<td style="text-align: center;">0.221</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">0.241</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.199</td>
<td style="text-align: center;">0.133</td>
</tr>
<tr>
<td style="text-align: center;">BackTranslation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.304</td>
<td style="text-align: center;">0.186</td>
<td style="text-align: center;">0.360</td>
<td style="text-align: center;">0.222</td>
<td style="text-align: center;">0.387</td>
<td style="text-align: center;">0.230</td>
<td style="text-align: center;">0.119</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.128</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.21</td>
<td style="text-align: center;">2.69</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">-0.47</td>
<td style="text-align: center;">4.80</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">7.20</td>
<td style="text-align: center;">11.34</td>
<td style="text-align: center;">3.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">6.26</td>
<td style="text-align: center;">6.06</td>
<td style="text-align: center;">7.91</td>
<td style="text-align: center;">6.06</td>
<td style="text-align: center;">6.26</td>
<td style="text-align: center;">7.08</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">5.95</td>
<td style="text-align: center;">5.44</td>
</tr>
<tr>
<td style="text-align: center;">ButterFingers <br> Perturbation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.210</td>
<td style="text-align: center;">0.092</td>
<td style="text-align: center;">0.240</td>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.126</td>
<td style="text-align: center;">0.044</td>
<td style="text-align: center;">0.082</td>
<td style="text-align: center;">0.057</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">33.66</td>
<td style="text-align: center;">51.61</td>
<td style="text-align: center;">33.52</td>
<td style="text-align: center;">54.88</td>
<td style="text-align: center;">31.06</td>
<td style="text-align: center;">47.66</td>
<td style="text-align: center;">65.60</td>
<td style="text-align: center;">58.76</td>
<td style="text-align: center;">56.92</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">20.43</td>
<td style="text-align: center;">21.66</td>
<td style="text-align: center;">23.72</td>
<td style="text-align: center;">22.07</td>
<td style="text-align: center;">25.26</td>
<td style="text-align: center;">23.31</td>
<td style="text-align: center;">14.48</td>
<td style="text-align: center;">20.12</td>
<td style="text-align: center;">16.32</td>
</tr>
<tr>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.187</td>
<td style="text-align: center;">0.087</td>
<td style="text-align: center;">0.220</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.266</td>
<td style="text-align: center;">0.124</td>
<td style="text-align: center;">0.053</td>
<td style="text-align: center;">0.074</td>
<td style="text-align: center;">0.055</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">41.10</td>
<td style="text-align: center;">54.30</td>
<td style="text-align: center;">39.20</td>
<td style="text-align: center;">52.56</td>
<td style="text-align: center;">34.60</td>
<td style="text-align: center;">48.51</td>
<td style="text-align: center;">58.40</td>
<td style="text-align: center;">62.89</td>
<td style="text-align: center;">58.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">22.07</td>
<td style="text-align: center;">20.74</td>
<td style="text-align: center;">27.21</td>
<td style="text-align: center;">20.84</td>
<td style="text-align: center;">26.28</td>
<td style="text-align: center;">25.87</td>
<td style="text-align: center;">13.24</td>
<td style="text-align: center;">21.46</td>
<td style="text-align: center;">17.45</td>
</tr>
<tr>
<td style="text-align: center;">EnglishInflectional <br> Variation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.306</td>
<td style="text-align: center;">0.161</td>
<td style="text-align: center;">0.334</td>
<td style="text-align: center;">0.198</td>
<td style="text-align: center;">0.399</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">0.103</td>
<td style="text-align: center;">0.179</td>
<td style="text-align: center;">0.113</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.56</td>
<td style="text-align: center;">15.59</td>
<td style="text-align: center;">7.67</td>
<td style="text-align: center;">10.23</td>
<td style="text-align: center;">1.77</td>
<td style="text-align: center;">11.49</td>
<td style="text-align: center;">20.00</td>
<td style="text-align: center;">10.31</td>
<td style="text-align: center;">15.38</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">8.93</td>
<td style="text-align: center;">10.78</td>
<td style="text-align: center;">11.40</td>
<td style="text-align: center;">9.65</td>
<td style="text-align: center;">10.68</td>
<td style="text-align: center;">12.53</td>
<td style="text-align: center;">7.08</td>
<td style="text-align: center;">9.45</td>
<td style="text-align: center;">6.78</td>
</tr>
<tr>
<td style="text-align: center;">SwapCharacters <br> Perturbation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.115</td>
<td style="text-align: center;">0.266</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.304</td>
<td style="text-align: center;">0.149</td>
<td style="text-align: center;">0.059</td>
<td style="text-align: center;">0.108</td>
<td style="text-align: center;">0.063</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">26.86</td>
<td style="text-align: center;">39.78</td>
<td style="text-align: center;">26.42</td>
<td style="text-align: center;">44.19</td>
<td style="text-align: center;">25.25</td>
<td style="text-align: center;">38.30</td>
<td style="text-align: center;">54.40</td>
<td style="text-align: center;">45.88</td>
<td style="text-align: center;">53.08</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">16.53</td>
<td style="text-align: center;">15.81</td>
<td style="text-align: center;">19.61</td>
<td style="text-align: center;">18.99</td>
<td style="text-align: center;">20.84</td>
<td style="text-align: center;">20.43</td>
<td style="text-align: center;">12.42</td>
<td style="text-align: center;">14.99</td>
<td style="text-align: center;">15.30</td>
</tr>
<tr>
<td style="text-align: center;">Synonym <br> Insertion</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.111</td>
<td style="text-align: center;">0.263</td>
<td style="text-align: center;">0.103</td>
<td style="text-align: center;">0.290</td>
<td style="text-align: center;">0.121</td>
<td style="text-align: center;">0.052</td>
<td style="text-align: center;">0.101</td>
<td style="text-align: center;">0.055</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">24.92</td>
<td style="text-align: center;">41.94</td>
<td style="text-align: center;">27.27</td>
<td style="text-align: center;">53.49</td>
<td style="text-align: center;">28.79</td>
<td style="text-align: center;">49.79</td>
<td style="text-align: center;">59.20</td>
<td style="text-align: center;">49.48</td>
<td style="text-align: center;">58.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">16.63</td>
<td style="text-align: center;">18.99</td>
<td style="text-align: center;">21.25</td>
<td style="text-align: center;">20.53</td>
<td style="text-align: center;">24.44</td>
<td style="text-align: center;">24.85</td>
<td style="text-align: center;">13.14</td>
<td style="text-align: center;">17.56</td>
<td style="text-align: center;">14.99</td>
</tr>
<tr>
<td style="text-align: center;">Synonym <br> Substitution</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.193</td>
<td style="text-align: center;">0.099</td>
<td style="text-align: center;">0.213</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">0.092</td>
<td style="text-align: center;">0.027</td>
<td style="text-align: center;">0.064</td>
<td style="text-align: center;">0.031</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">39.16</td>
<td style="text-align: center;">48.39</td>
<td style="text-align: center;">41.19</td>
<td style="text-align: center;">64.19</td>
<td style="text-align: center;">42.68</td>
<td style="text-align: center;">61.70</td>
<td style="text-align: center;">79.20</td>
<td style="text-align: center;">68.04</td>
<td style="text-align: center;">76.92</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">22.79</td>
<td style="text-align: center;">18.17</td>
<td style="text-align: center;">27.31</td>
<td style="text-align: center;">23.61</td>
<td style="text-align: center;">30.18</td>
<td style="text-align: center;">26.90</td>
<td style="text-align: center;">16.22</td>
<td style="text-align: center;">22.38</td>
<td style="text-align: center;">17.45</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformation <br> Past</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.318</td>
<td style="text-align: center;">0.190</td>
<td style="text-align: center;">0.362</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">0.402</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.120</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.141</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-0.32$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">$-0.28$</td>
<td style="text-align: center;">3.26</td>
<td style="text-align: center;">1.01</td>
<td style="text-align: center;">1.28</td>
<td style="text-align: center;">6.40</td>
<td style="text-align: center;">1.03</td>
<td style="text-align: center;">$-5.38$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">2.16</td>
<td style="text-align: center;">2.36</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">3.18</td>
<td style="text-align: center;">3.29</td>
<td style="text-align: center;">2.16</td>
<td style="text-align: center;">1.64</td>
<td style="text-align: center;">2.26</td>
<td style="text-align: center;">1.54</td>
</tr>
<tr>
<td style="text-align: center;">TenseTransformation <br> Future</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.314</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.369</td>
<td style="text-align: center;">0.218</td>
<td style="text-align: center;">0.400</td>
<td style="text-align: center;">0.242</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.185</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">$-3.23$</td>
<td style="text-align: center;">$-1.99$</td>
<td style="text-align: center;">1.40</td>
<td style="text-align: center;">1.52</td>
<td style="text-align: center;">$-0.43$</td>
<td style="text-align: center;">4.80</td>
<td style="text-align: center;">7.22</td>
<td style="text-align: center;">6.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.18</td>
<td style="text-align: center;">3.29</td>
<td style="text-align: center;">5.65</td>
<td style="text-align: center;">4.21</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">2.46</td>
<td style="text-align: center;">3.49</td>
<td style="text-align: center;">2.26</td>
</tr>
<tr>
<td style="text-align: center;">Whitespace <br> Perturbation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">0.107</td>
<td style="text-align: center;">0.252</td>
<td style="text-align: center;">0.106</td>
<td style="text-align: center;">0.287</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.057</td>
<td style="text-align: center;">0.094</td>
<td style="text-align: center;">0.054</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">32.69</td>
<td style="text-align: center;">44.09</td>
<td style="text-align: center;">30.40</td>
<td style="text-align: center;">52.09</td>
<td style="text-align: center;">29.29</td>
<td style="text-align: center;">44.26</td>
<td style="text-align: center;">55.20</td>
<td style="text-align: center;">52.58</td>
<td style="text-align: center;">59.23</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">20.64</td>
<td style="text-align: center;">17.66</td>
<td style="text-align: center;">21.56</td>
<td style="text-align: center;">20.64</td>
<td style="text-align: center;">25.46</td>
<td style="text-align: center;">23.31</td>
<td style="text-align: center;">12.42</td>
<td style="text-align: center;">17.86</td>
<td style="text-align: center;">16.02</td>
</tr>
</tbody>
</table>
<p>Table 12: Robustness evaluation for each type of docstring perturbations on MBPP.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.122</td>
</tr>
<tr>
<td style="text-align: center;">CamelCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.256</td>
<td style="text-align: center;">0.201</td>
<td style="text-align: center;">0.293</td>
<td style="text-align: center;">0.165</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.116</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-2.63$</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">2.33</td>
<td style="text-align: center;">$-3.13$</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">15.62</td>
<td style="text-align: center;">5.88</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">5.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">1.22</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">1.22</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: center;">ButterFinger</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.104</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.274</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.091</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">15.79</td>
<td style="text-align: center;">26.09</td>
<td style="text-align: center;">11.63</td>
<td style="text-align: center;">9.38</td>
<td style="text-align: center;">10.00</td>
<td style="text-align: center;">18.75</td>
<td style="text-align: center;">5.88</td>
<td style="text-align: center;">8.00</td>
<td style="text-align: center;">25.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">3.05</td>
</tr>
<tr>
<td style="text-align: center;">SwapChar</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.299</td>
<td style="text-align: center;">0.183</td>
<td style="text-align: center;">0.073</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.116</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">2.63</td>
<td style="text-align: center;">17.39</td>
<td style="text-align: center;">13.95</td>
<td style="text-align: center;">9.38</td>
<td style="text-align: center;">2.00</td>
<td style="text-align: center;">6.25</td>
<td style="text-align: center;">29.41</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">5.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.213</td>
<td style="text-align: center;">0.140</td>
<td style="text-align: center;">0.256</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.091</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">10.53</td>
<td style="text-align: center;">13.04</td>
<td style="text-align: center;">18.60</td>
<td style="text-align: center;">28.12</td>
<td style="text-align: center;">16.00</td>
<td style="text-align: center;">25.00</td>
<td style="text-align: center;">5.88</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">25.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">10.98</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">5.49</td>
</tr>
<tr>
<td style="text-align: center;">Inflectional <br> Variation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.201</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.110</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">4.35</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">$-3.13$</td>
<td style="text-align: center;">$-5.88$</td>
<td style="text-align: center;">16.00</td>
<td style="text-align: center;">10.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">1.83</td>
<td style="text-align: center;">2.44</td>
<td style="text-align: center;">1.22</td>
</tr>
<tr>
<td style="text-align: center;">Synonym <br> Substitution</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.195</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.098</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">15.79</td>
<td style="text-align: center;">30.43</td>
<td style="text-align: center;">11.63</td>
<td style="text-align: center;">18.75</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">18.75</td>
<td style="text-align: center;">17.65</td>
<td style="text-align: center;">16.00</td>
<td style="text-align: center;">20.00</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">3.66</td>
<td style="text-align: center;">3.05</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">2.44</td>
</tr>
</tbody>
</table>
<p>Table 13: Robustness evaluation for each type of function name perturbations on HumanEval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">MBPP</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.317</td>
<td style="text-align: center;">0.191</td>
<td style="text-align: center;">0.361</td>
<td style="text-align: center;">0.221</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">0.241</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.199</td>
<td style="text-align: center;">0.133</td>
</tr>
<tr>
<td style="text-align: center;">CamelCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.316</td>
<td style="text-align: center;">0.196</td>
<td style="text-align: center;">0.367</td>
<td style="text-align: center;">0.219</td>
<td style="text-align: center;">0.408</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.194</td>
<td style="text-align: center;">0.134</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">$-2.69$</td>
<td style="text-align: center;">$-1.42$</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">$-0.25$</td>
<td style="text-align: center;">$-1.70$</td>
<td style="text-align: center;">9.60</td>
<td style="text-align: center;">2.58</td>
<td style="text-align: center;">$-0.77$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">5.44</td>
<td style="text-align: center;">5.44</td>
<td style="text-align: center;">7.29</td>
<td style="text-align: center;">5.34</td>
<td style="text-align: center;">7.08</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">5.75</td>
<td style="text-align: center;">5.03</td>
<td style="text-align: center;">3.18</td>
</tr>
<tr>
<td style="text-align: center;">ButterFinger</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.312</td>
<td style="text-align: center;">0.185</td>
<td style="text-align: center;">0.370</td>
<td style="text-align: center;">0.203</td>
<td style="text-align: center;">0.412</td>
<td style="text-align: center;">0.231</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.175</td>
<td style="text-align: center;">0.117</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">1.62</td>
<td style="text-align: center;">3.23</td>
<td style="text-align: center;">$-2.27$</td>
<td style="text-align: center;">7.91</td>
<td style="text-align: center;">$-1.26$</td>
<td style="text-align: center;">4.26</td>
<td style="text-align: center;">14.40</td>
<td style="text-align: center;">12.37</td>
<td style="text-align: center;">12.31</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">7.19</td>
<td style="text-align: center;">8.62</td>
<td style="text-align: center;">9.65</td>
<td style="text-align: center;">10.99</td>
<td style="text-align: center;">8.73</td>
<td style="text-align: center;">9.86</td>
<td style="text-align: center;">6.67</td>
<td style="text-align: center;">8.11</td>
<td style="text-align: center;">6.98</td>
</tr>
<tr>
<td style="text-align: center;">SwapChar</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.309</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.342</td>
<td style="text-align: center;">0.202</td>
<td style="text-align: center;">0.399</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.113</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">2.59</td>
<td style="text-align: center;">1.08</td>
<td style="text-align: center;">5.40</td>
<td style="text-align: center;">8.37</td>
<td style="text-align: center;">1.77</td>
<td style="text-align: center;">1.70</td>
<td style="text-align: center;">9.60</td>
<td style="text-align: center;">13.92</td>
<td style="text-align: center;">15.38</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.41</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">7.29</td>
<td style="text-align: center;">6.88</td>
<td style="text-align: center;">6.06</td>
<td style="text-align: center;">4.52</td>
<td style="text-align: center;">3.18</td>
<td style="text-align: center;">5.24</td>
<td style="text-align: center;">4.21</td>
</tr>
<tr>
<td style="text-align: center;">ChangeCharCase</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.295</td>
<td style="text-align: center;">0.179</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.192</td>
<td style="text-align: center;">0.400</td>
<td style="text-align: center;">0.244</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.111</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">7.12</td>
<td style="text-align: center;">6.45</td>
<td style="text-align: center;">4.26</td>
<td style="text-align: center;">13.02</td>
<td style="text-align: center;">1.52</td>
<td style="text-align: center;">$-1.28$</td>
<td style="text-align: center;">27.20</td>
<td style="text-align: center;">13.92</td>
<td style="text-align: center;">16.92</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">9.55</td>
<td style="text-align: center;">10.88</td>
<td style="text-align: center;">11.91</td>
<td style="text-align: center;">12.22</td>
<td style="text-align: center;">12.73</td>
<td style="text-align: center;">9.75</td>
<td style="text-align: center;">8.32</td>
<td style="text-align: center;">10.57</td>
<td style="text-align: center;">9.45</td>
</tr>
<tr>
<td style="text-align: center;">Inflectional Variation</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.318</td>
<td style="text-align: center;">0.187</td>
<td style="text-align: center;">0.343</td>
<td style="text-align: center;">0.202</td>
<td style="text-align: center;">0.402</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.188</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-0.32$</td>
<td style="text-align: center;">2.15</td>
<td style="text-align: center;">5.11</td>
<td style="text-align: center;">8.37</td>
<td style="text-align: center;">1.01</td>
<td style="text-align: center;">$-0.85$</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">5.67</td>
<td style="text-align: center;">6.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">3.08</td>
<td style="text-align: center;">4.31</td>
<td style="text-align: center;">6.88</td>
<td style="text-align: center;">5.75</td>
<td style="text-align: center;">5.95</td>
<td style="text-align: center;">4.31</td>
<td style="text-align: center;">2.46</td>
<td style="text-align: center;">2.98</td>
<td style="text-align: center;">3.49</td>
</tr>
<tr>
<td style="text-align: center;">Synonym Substitution</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.316</td>
<td style="text-align: center;">0.186</td>
<td style="text-align: center;">0.346</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.384</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.164</td>
<td style="text-align: center;">0.117</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">2.69</td>
<td style="text-align: center;">4.26</td>
<td style="text-align: center;">10.70</td>
<td style="text-align: center;">5.56</td>
<td style="text-align: center;">$-0.85$</td>
<td style="text-align: center;">18.40</td>
<td style="text-align: center;">17.53</td>
<td style="text-align: center;">12.31</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">6.88</td>
<td style="text-align: center;">7.49</td>
<td style="text-align: center;">10.88</td>
<td style="text-align: center;">10.47</td>
<td style="text-align: center;">9.96</td>
<td style="text-align: center;">9.86</td>
<td style="text-align: center;">7.70</td>
<td style="text-align: center;">8.52</td>
<td style="text-align: center;">6.88</td>
</tr>
</tbody>
</table>
<p>Table 14: Robustness evaluation for each type of function name perturbations on MBPP.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">HumanEval</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">CodeGen <br> 2B mono</th>
<th style="text-align: center;">CodeGen <br> 2B multi</th>
<th style="text-align: center;">CodeGen <br> 6B mono</th>
<th style="text-align: center;">CodeGen <br> 6B multi</th>
<th style="text-align: center;">CodeGen <br> 16B mono</th>
<th style="text-align: center;">CodeGen <br> 16B multi</th>
<th style="text-align: center;">InCoder <br> 1B</th>
<th style="text-align: center;">InCoder <br> 6B</th>
<th style="text-align: center;">GPT-J <br> 6B</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Nominal</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.402</td>
<td style="text-align: center;">0.293</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">0.366</td>
<td style="text-align: center;">0.549</td>
<td style="text-align: center;">0.390</td>
<td style="text-align: center;">0.189</td>
<td style="text-align: center;">0.323</td>
<td style="text-align: center;">0.250</td>
</tr>
<tr>
<td style="text-align: center;">DeadCodeInserter</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.116</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.055</td>
<td style="text-align: center;">0.079</td>
<td style="text-align: center;">0.079</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">71.21</td>
<td style="text-align: center;">72.92</td>
<td style="text-align: center;">70.59</td>
<td style="text-align: center;">70.00</td>
<td style="text-align: center;">71.11</td>
<td style="text-align: center;">76.56</td>
<td style="text-align: center;">70.97</td>
<td style="text-align: center;">75.47</td>
<td style="text-align: center;">68.29</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">37.80</td>
<td style="text-align: center;">30.49</td>
<td style="text-align: center;">41.46</td>
<td style="text-align: center;">32.93</td>
<td style="text-align: center;">45.12</td>
<td style="text-align: center;">37.20</td>
<td style="text-align: center;">17.07</td>
<td style="text-align: center;">30.49</td>
<td style="text-align: center;">27.44</td>
</tr>
<tr>
<td style="text-align: center;">ForWhile <br> TransformerFirst</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.384</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.500</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.537</td>
<td style="text-align: center;">0.384</td>
<td style="text-align: center;">0.159</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.213</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.55</td>
<td style="text-align: center;">22.92</td>
<td style="text-align: center;">3.53</td>
<td style="text-align: center;">16.67</td>
<td style="text-align: center;">2.22</td>
<td style="text-align: center;">1.56</td>
<td style="text-align: center;">16.13</td>
<td style="text-align: center;">13.21</td>
<td style="text-align: center;">14.63</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">9.76</td>
</tr>
<tr>
<td style="text-align: center;">OperandSwap</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.402</td>
<td style="text-align: center;">0.274</td>
<td style="text-align: center;">0.500</td>
<td style="text-align: center;">0.348</td>
<td style="text-align: center;">0.512</td>
<td style="text-align: center;">0.354</td>
<td style="text-align: center;">0.171</td>
<td style="text-align: center;">0.311</td>
<td style="text-align: center;">0.220</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">6.25</td>
<td style="text-align: center;">3.53</td>
<td style="text-align: center;">5.00</td>
<td style="text-align: center;">6.67</td>
<td style="text-align: center;">9.38</td>
<td style="text-align: center;">9.68</td>
<td style="text-align: center;">3.77</td>
<td style="text-align: center;">12.20</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">7.32</td>
</tr>
<tr>
<td style="text-align: center;">VarRenamerCB</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.415</td>
<td style="text-align: center;">0.268</td>
<td style="text-align: center;">0.476</td>
<td style="text-align: center;">0.329</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">0.354</td>
<td style="text-align: center;">0.146</td>
<td style="text-align: center;">0.287</td>
<td style="text-align: center;">0.238</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">$-3.03$</td>
<td style="text-align: center;">8.33</td>
<td style="text-align: center;">8.24</td>
<td style="text-align: center;">10.00</td>
<td style="text-align: center;">5.56</td>
<td style="text-align: center;">9.38</td>
<td style="text-align: center;">22.58</td>
<td style="text-align: center;">11.32</td>
<td style="text-align: center;">4.88</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.88</td>
<td style="text-align: center;">6.10</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">7.93</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">4.88</td>
</tr>
<tr>
<td style="text-align: center;">VarRenamerNaive</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.396</td>
<td style="text-align: center;">0.244</td>
<td style="text-align: center;">0.482</td>
<td style="text-align: center;">0.348</td>
<td style="text-align: center;">0.494</td>
<td style="text-align: center;">0.341</td>
<td style="text-align: center;">0.177</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.220</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">1.52</td>
<td style="text-align: center;">16.67</td>
<td style="text-align: center;">7.06</td>
<td style="text-align: center;">5.00</td>
<td style="text-align: center;">10.00</td>
<td style="text-align: center;">12.50</td>
<td style="text-align: center;">6.45</td>
<td style="text-align: center;">13.21</td>
<td style="text-align: center;">12.20</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">4.27</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">7.32</td>
<td style="text-align: center;">9.15</td>
<td style="text-align: center;">6.71</td>
<td style="text-align: center;">8.54</td>
<td style="text-align: center;">9.76</td>
<td style="text-align: center;">10.37</td>
<td style="text-align: center;">5.49</td>
</tr>
<tr>
<td style="text-align: center;">VarRenamerRN</td>
<td style="text-align: center;">$\mathrm{RP}_{5} @ 1 \uparrow$</td>
<td style="text-align: center;">0.366</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">0.421</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.470</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.152</td>
<td style="text-align: center;">0.177</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RD}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">9.09</td>
<td style="text-align: center;">29.17</td>
<td style="text-align: center;">18.82</td>
<td style="text-align: center;">23.33</td>
<td style="text-align: center;">14.44</td>
<td style="text-align: center;">28.12</td>
<td style="text-align: center;">54.84</td>
<td style="text-align: center;">52.83</td>
<td style="text-align: center;">29.27</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathrm{RR}_{5} @ 1(\%) \downarrow$</td>
<td style="text-align: center;">12.20</td>
<td style="text-align: center;">14.63</td>
<td style="text-align: center;">14.02</td>
<td style="text-align: center;">12.80</td>
<td style="text-align: center;">11.59</td>
<td style="text-align: center;">17.07</td>
<td style="text-align: center;">16.46</td>
<td style="text-align: center;">24.39</td>
<td style="text-align: center;">12.20</td>
</tr>
</tbody>
</table>
<p>Table 15: Robustness evaluation for each type of code syntax perturbations on HumanEval.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ https://github.com/microsoft/CodeXGLUE&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>