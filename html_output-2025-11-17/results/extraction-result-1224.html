<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1224 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1224</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1224</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-803078355d5db058ffc8fe99d60e4210bd90de59</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/803078355d5db058ffc8fe99d60e4210bd90de59" target="_blank">Artificial Scientific Discovery</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This thesis spans from AlphaGo to ChatGPT to empirically examine the fundamental concepts needed to realize the vision of an artificial scientist: a machine with the capacity to autonomously generate original research and contribute to the expansion of human knowledge.</p>
                <p><strong>Paper Abstract:</strong> Rooted in the explosion of deep learning over the past decade, this thesis spans from AlphaGo to ChatGPT to empirically examine the fundamental concepts needed to realize the vision of an artificial scientist: a machine with the capacity to autonomously generate original research and contribute to the expansion of human knowledge. The investigation begins with Olivaw, an AlphaGo Zero-like agent that discovers Othello knowledge from scratch but is unable to communicate it. This realization leads to the development of the Explanatory Learning (EL) framework, a formalization of the problem faced by a scientist when trying to explain a new phenomenon to their peers. The effective EL prescriptions allow us to crack Zendo, a popular board game simulating the scientific endeavor. This success comes with a fundamental insight: an artificial scientist must develop its own interpretation of the language used to explain its findings, and not rely on a rigid existing interpreter. Questioning the very process of learning an interpreter, we turn our attention to the inner functioning of modern multimodal models. This culminates in a simple idea to build CLIP-like models where interpretation and perception are explicitly disentangled: a cost-effective approach that couples two unimodal models using little multimodal data and no further training. Finally, we discuss what ChatGPT and its siblings are still missing to become artificial scientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark about interpreting Zendo-like explanations that sees LLMs going no further than random chance while being instead fully solved by humans.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1224.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1224.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Olivaw</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Olivaw: AlphaGo Zero-like Othello agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AlphaGo Zero-inspired self-play agent that learns Othello strategy from scratch using Monte Carlo Tree Search coupled with a neural network; trained with cost-saving modifications to reach world-class play on commodity hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>OLIVAW: Mastering Othello without Human Knowledge, nor a Penny</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Olivaw</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AlphaGo Zero paradigm: a neural network guiding Monte Carlo Tree Search trained via self-play. Modifications include doubling collected positions per game (including heavily explored but unplayed positions) and other low-cost training accelerations to enable learning on commodity/cloud resources.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Game strategy / computational game-playing (Othello)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Olivaw autonomously discovers Othello knowledge/strategies from self-play (i.e., learned evaluation and policy for positions) without human domain knowledge or large computational budgets. It attains performance described as 'world-class' and is tested against strong engines and top human players.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>discover knowledge from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The thesis repeatedly frames Olivaw's result as the agent 'discover[ing] Othello knowledge from scratch'—i.e., generating gameplay knowledge via self-play rather than inheriting human-crafted heuristics. The work emphasizes autonomous emergence of strategy rather than incremental refinement of human-coded rules.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Empirical match-play evaluation: (1) tournaments and matches against a strong open-source engine (Edax), (2) anonymous online play on OthelloQuest, and (3) in-person matches versus top human players including a national champion and a former world champion. Training-curve monitoring, position-collection statistics and generation-level performance visualizations are used to measure learning progress.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation by direct comparison to established baselines: head-to-head matches vs Edax (engine), win/loss/tournament standings on OthelloQuest, and contested physical matches vs human experts. The chapter provides reproducibility details (training process, resources) so results can be replicated.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed qualitatively in two dimensions: (1) achieving world-class Othello play without human knowledge or large compute/cost, and (2) methodological novelty in low-cost training modifications (e.g., doubling positions collected per game). The thesis highlights these as the contributions distinguishing Olivaw from prior AlphaGo-style systems.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Impact is measured via match outcomes and leaderboard rankings (tournament standings vs Edax and match records vs human champions) and by demonstrating feasibility of achieving high performance with limited resources. Specific numeric results are reported in chapter tables/figures (referenced) but are not reproduced in full in the provided excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Direct empirical comparisons to humans and to a state-of-the-art engine (Edax) are performed: Olivaw plays anonymous online matches, competes in a tournament vs Edax, and plays in-person matches against top human players. The thesis also philosophically contrasts machine-acquired knowledge with human-communicable explanations, noting that although Olivaw attains strong play, it cannot automatically communicate its discovered knowledge in human-understandable explanatory form.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Qualitative: the system attained 'world-class' level play and succeeded in beating/competing with strong software and human opponents in the reported experiments; success is demonstrated via match records and tournament placements (exact win percentages are reported in the thesis figures/tables but not quoted here).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key limitations identified include inability to produce human-understandable explanations of discovered strategies (communication bottleneck), dependence on self-play/data collection design, and limitations related to interpretability; these limitations complicate assessing whether the agent's knowledge constitutes transmissible scientific insight versus closed-form skill.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Scientific Discovery', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1224.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1224.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Explanatory Learning / CRNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Explanatory Learning (EL) framework and Critical Rationalist Networks (CRNs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed formal framework (Explanatory Learning) for machines to autonomously produce explanations of observed phenomena and a modeling approach (CRNs, implemented with Transformer architectures) that generates conjectures/explanations and is evaluated on Odeen, a Zendo-like scientific game.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Explanatory learning: Beyond empiricism in neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Explanatory Learning agent (implemented as Critical Rationalist Networks / Transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Explanatory Learning is a problem formalization: given sparse symbolic sequences paired with observations, learn both an interpreter (mapping symbols to meanings) and produce explanations/conjectures. CRNs instantiate the idea: networks that generate and critically evaluate conjectures (multiple hypotheses) and select/adjust them—implemented and evaluated with Transformer architectures on the Odeen environment.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Symbolic rule discovery / scientific explanation in synthetic domains (Odeen/Zendo-like tasks); more broadly, conceptual scientific reasoning and hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>The system discovers underlying symbolic rules that generate observed examples in Odeen, producing explicit symbolic explanations (conjectures) that generalize to held-out examples. It 'cracks' the Zendo-like tasks by autonomously building an interpretation/language mapping and using it to explain phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>artificial scientist / original research (as framed by the authors)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The thesis frames success on Odeen/Zendo as an instance of 'when a ML system becomes an artificial scientist' because the agent not only fits observations but produces interpretable explanations (conjectures) and learns its own interpreter rather than relying on a fixed human-coded language. This is presented as a conceptual step beyond purely empirical prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Controlled synthetic benchmark (Odeen) with generated datasets; quantitative metrics defined for the task (the thesis references specific metrics sections and tables, e.g., T-Acc and NRS), generalization tests to held-out structures/rules, experiments assessing data-scaling laws, handling of ambiguity and contradiction, explainability analyses, measuring prediction confidence, and tests with variable 'thinking time' (generating more conjectures).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation via held-out test sets and metrics specific to the explanatory task; ablation and comparison to baseline 'empiricist' models; experiments measure generalization capability, robustness to ambiguous/contradictory data, and interpretability of produced explanations. The thesis reports empirical superiority of CRNs over empiricist baselines in these validation regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty rests on two claims: (1) formalizing Explanatory Learning as distinct from standard supervised/program-synthesis formulations by requiring the agent to learn an interpreter, and (2) demonstrating that CRNs can learn interpretable explanations and generalize in Zendo-like tasks with greater data efficiency than purely empiricist models. The thesis positions this as moving 'beyond empiricism' in ML.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Reported impact metrics include task-specific evaluation scores (e.g., accuracy-like metrics T-Acc, NRS—referenced in appendix/table headings), empirical scaling laws demonstrating data-efficiency advantages, and qualitative improvements in explainability. Exact numeric metrics are reported in the thesis tables (not reproduced verbatim here).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The Odeen/Zendo tasks are chosen for human solvability; the thesis notes that CRNs 'crack Zendo' and that humans can solve these tasks. Additionally, the work contrasts CRNs with LLMs which fail a related Symbol Interpretation Task (SIT). CRNs outperform empiricist models in data efficiency and generalization in the synthetic explanatory environment.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Qualitative: CRNs successfully solve the Odeen explanatory tasks in the reported experiments and demonstrate higher data efficiency and robustness compared to empiricist baselines. Exact success rates and metric values are given in the thesis experiment tables/figures.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include the synthetic nature of Odeen (transfer to real scientific domains is non-trivial), remaining ambiguity/contradiction handling challenges (though addressed experimentally), dependency on dataset generation choices, and the broader difficulty of evaluating whether produced explanations correspond to genuinely novel scientific insight versus artefacts of the synthetic environment.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Scientific Discovery', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1224.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1224.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Large Language Models (LLMs) / SIT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models evaluated on the Symbol Interpretation Task (SIT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transformer-based large language models (e.g., GPT-family) are examined as candidate 'sparks' of artificial scientists and empirically evaluated on the Big-Bench Symbol Interpretation Task, where they fail (performing at or near chance) while humans succeed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Large Language Models (LLMs) such as GPT-3/GPT-4 and similar next-token-prediction transformers</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pretrained transformer LMs optimized for next-token prediction exhibiting strong linguistic and reasoning capabilities on many tasks. The thesis analyzes their limitations for scientific-style discovery—particularly their inability to learn new interpreters for novel symbolic systems and to reliably assess their own knowledge gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Natural language-based reasoning and symbolic interpretation; assessed for potential to perform scientific-style discoveries (symbol interpretation/explanation).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>LLMs are tested on their ability to interpret arbitrary symbol systems and produce correct explanations or rule inferences (the SIT derived from Odeen/Zendo). The reported result is that LLMs perform no better than random chance on SIT subtasks and thus do not demonstrate the capacity to autonomously produce interpretable scientific discoveries in this setting.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>not demonstrated (LLMs fail to function as artificial scientists on SIT)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The thesis frames LLMs as candidates for artificial scientists ('sparks of Artificial Scientists?') but justifies their rejection based on empirical results: LLMs fail the Symbol Interpretation Task, demonstrating they cannot reliably build interpreters for new symbolic languages nor produce verifiable explanatory conjectures in the tested setting.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Benchmark evaluation using the Big-Bench Symbol Interpretation Task (SIT) and its subtasks; performance metrics comparing model outputs to ground-truth rule interpretations; comparisons to human participants (human baselines). The thesis refers to aggregated and subtask-specific performance figures (e.g., Figure 22, Figure 23, Table 6) showing the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation by measured performance on SIT subtasks against ground truth and against human baselines; analysis of failure modes (e.g., accepting input uncritically, inability to assess unknowns). The benchmark is part of the Big-Bench collection, enabling cross-model comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessment focuses on inability rather than achievement: the established novelty is negative—the identification of a failure mode (symbol-interpretation / interpreter-learning) that LLMs cannot overcome with current architectures/training. The SIT is noted as the Big-Bench task with the largest gap between humans and models.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Impact assessed via the size of the human–machine performance gap on SIT (noted as 'the largest performance gap' in Big-Bench) and by per-subtask and aggregate model accuracies (figures/tables referenced in the thesis). Numerical values are presented in the thesis but not quoted here.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Direct comparison: humans fully solve SIT while LLMs perform at near-chance levels. The thesis emphasizes this stark quantitative gap (largest in Big-Bench) as evidence that current LLMs do not attain the required capabilities for interpreter-based discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Low: on SIT subtasks LLMs perform at or near random-chance levels according to the thesis; humans perform near perfect. Exact percentages are reported in the thesis Big-Bench results tables/figures.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Identified limitations include LLMs' tendency to uncritically accept inputs, inability to assess unknowns or produce calibrated uncertainty, failure to learn new interpreters from sparse symbol–observation pairings, and an overall tension between next-token predictive training and the epistemic requirements of scientific explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Scientific Discovery', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1224.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1224.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Metahumans (conceptual)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Metahumans (hypothetical superior automated scientific entities)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conceptual discussion in the prologue describing hypothetical superior automated scientists ('metahumans') that dominate experimental research and communicate findings in an inaccessible digital neural transfer (DNT) medium.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Metahumans (conceptual automated scientists)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A speculative class of non-human research entities posited in the prologue: extremely capable automated systems that perform original research and communicate internally via an inaccessible medium (DNT), leading to a human interpretability crisis.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>General scientific research (speculative / philosophical discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Used as a narrative device: metahumans are said to make original research discoveries accessible only via DNT, creating a situation where human scientists can no longer directly comprehend or produce original research.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>transformational / paradigm-shifting (framed as a potential future scenario)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The thesis uses the metahuman scenario to illustrate a transformational possibility in which automated entities monopolize discovery and produce results beyond human comprehension—this is discussed as a dramatic (paradigm-shifting) outcome rather than an observed empirical finding.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>This is a conceptual / speculative discussion; no empirical evaluation methods are applied in the thesis for metahumans.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not applicable (speculative/philosophical argument).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is rhetorical/philosophical: the scenario underscores challenges of interpretability and communication if discoveries occur in a non-human-interpretable medium.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>None empirical; the text uses qualitative argumentation rather than metric-based impact assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The discussion contrasts human scientific practice (explanation in human language) with a future where metahumans produce discoveries in an inaccessible format, leading to a shift in what counts as 'science' for humans.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Not applicable (speculative).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The main point is the communicative barrier: discoveries inaccessible to humans create epistemic and cultural issues; the thesis argues that science is fundamentally about human-understandable explanations, so purely non-communicative metahuman discoveries are problematic.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Scientific Discovery', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1224.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1224.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGo Zero</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaGo Zero</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-play reinforcement learning system that mastered the game of Go from scratch using MCTS and a neural network, cited in this thesis as inspiration for Olivaw.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaGo Zero</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Monte Carlo Tree Search guided by a neural network trained entirely by self-play reinforcement learning; referenced as a canonical example of machine discovery of game-playing knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Game-playing (Go)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>AlphaGo Zero discovered high-level Go strategies and achieved superhuman play via self-play learning without human game data; used as an inspirational precedent for Olivaw.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>original research / paradigm-shifting (historical example in AI literature)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>AlphaGo Zero is invoked as an influential example where an automated system produced domain mastery autonomously, motivating inquiry into whether similar mechanisms can lead to scientific discovery in other domains.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Historical evaluation: head-to-head matches against top human players and prior engines (as discussed in the literature).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Empirical matches and community validation in the original AlphaGo Zero literature (not validated within this thesis beyond citation).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty in its domain historically recognized (self-play, no human data), used to motivate the thesis work.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Historical records of match victories and community recognition (not enumerated here).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Serves as inspiration/comparison point for Olivaw; the thesis notes that while AlphaGo Zero discovered Go strategies, such systems cannot necessarily communicate discoveries in human-understandable explanatory form.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Used to illustrate that high-performance discovery/skill does not equal communicable scientific explanation; motivates need for interpreter-learning.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Scientific Discovery', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>OLIVAW: Mastering Othello without Human Knowledge, nor a Penny <em>(Rating: 2)</em></li>
                <li>Explanatory learning: Beyond empiricism in neural networks <em>(Rating: 2)</em></li>
                <li>ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training <em>(Rating: 1)</em></li>
                <li>Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models <em>(Rating: 2)</em></li>
                <li>AlphaGo Zero <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1224",
    "paper_id": "paper-803078355d5db058ffc8fe99d60e4210bd90de59",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "Olivaw",
            "name_full": "Olivaw: AlphaGo Zero-like Othello agent",
            "brief_description": "An AlphaGo Zero-inspired self-play agent that learns Othello strategy from scratch using Monte Carlo Tree Search coupled with a neural network; trained with cost-saving modifications to reach world-class play on commodity hardware.",
            "citation_title": "OLIVAW: Mastering Othello without Human Knowledge, nor a Penny",
            "mention_or_use": "use",
            "system_name": "Olivaw",
            "system_description": "AlphaGo Zero paradigm: a neural network guiding Monte Carlo Tree Search trained via self-play. Modifications include doubling collected positions per game (including heavily explored but unplayed positions) and other low-cost training accelerations to enable learning on commodity/cloud resources.",
            "discovery_domain": "Game strategy / computational game-playing (Othello)",
            "discovery_description": "Olivaw autonomously discovers Othello knowledge/strategies from self-play (i.e., learned evaluation and policy for positions) without human domain knowledge or large computational budgets. It attains performance described as 'world-class' and is tested against strong engines and top human players.",
            "discovery_type": "discover knowledge from scratch",
            "discovery_type_justification": "The thesis repeatedly frames Olivaw's result as the agent 'discover[ing] Othello knowledge from scratch'—i.e., generating gameplay knowledge via self-play rather than inheriting human-crafted heuristics. The work emphasizes autonomous emergence of strategy rather than incremental refinement of human-coded rules.",
            "evaluation_methods": "Empirical match-play evaluation: (1) tournaments and matches against a strong open-source engine (Edax), (2) anonymous online play on OthelloQuest, and (3) in-person matches versus top human players including a national champion and a former world champion. Training-curve monitoring, position-collection statistics and generation-level performance visualizations are used to measure learning progress.",
            "validation_approaches": "Validation by direct comparison to established baselines: head-to-head matches vs Edax (engine), win/loss/tournament standings on OthelloQuest, and contested physical matches vs human experts. The chapter provides reproducibility details (training process, resources) so results can be replicated.",
            "novelty_assessment": "Novelty is assessed qualitatively in two dimensions: (1) achieving world-class Othello play without human knowledge or large compute/cost, and (2) methodological novelty in low-cost training modifications (e.g., doubling positions collected per game). The thesis highlights these as the contributions distinguishing Olivaw from prior AlphaGo-style systems.",
            "impact_metrics": "Impact is measured via match outcomes and leaderboard rankings (tournament standings vs Edax and match records vs human champions) and by demonstrating feasibility of achieving high performance with limited resources. Specific numeric results are reported in chapter tables/figures (referenced) but are not reproduced in full in the provided excerpt.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Direct empirical comparisons to humans and to a state-of-the-art engine (Edax) are performed: Olivaw plays anonymous online matches, competes in a tournament vs Edax, and plays in-person matches against top human players. The thesis also philosophically contrasts machine-acquired knowledge with human-communicable explanations, noting that although Olivaw attains strong play, it cannot automatically communicate its discovered knowledge in human-understandable explanatory form.",
            "success_rate": "Qualitative: the system attained 'world-class' level play and succeeded in beating/competing with strong software and human opponents in the reported experiments; success is demonstrated via match records and tournament placements (exact win percentages are reported in the thesis figures/tables but not quoted here).",
            "challenges_limitations": "Key limitations identified include inability to produce human-understandable explanations of discovered strategies (communication bottleneck), dependence on self-play/data collection design, and limitations related to interpretability; these limitations complicate assessing whether the agent's knowledge constitutes transmissible scientific insight versus closed-form skill.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1224.0",
            "source_info": {
                "paper_title": "Artificial Scientific Discovery",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Explanatory Learning / CRNs",
            "name_full": "Explanatory Learning (EL) framework and Critical Rationalist Networks (CRNs)",
            "brief_description": "A proposed formal framework (Explanatory Learning) for machines to autonomously produce explanations of observed phenomena and a modeling approach (CRNs, implemented with Transformer architectures) that generates conjectures/explanations and is evaluated on Odeen, a Zendo-like scientific game.",
            "citation_title": "Explanatory learning: Beyond empiricism in neural networks",
            "mention_or_use": "use",
            "system_name": "Explanatory Learning agent (implemented as Critical Rationalist Networks / Transformers)",
            "system_description": "Explanatory Learning is a problem formalization: given sparse symbolic sequences paired with observations, learn both an interpreter (mapping symbols to meanings) and produce explanations/conjectures. CRNs instantiate the idea: networks that generate and critically evaluate conjectures (multiple hypotheses) and select/adjust them—implemented and evaluated with Transformer architectures on the Odeen environment.",
            "discovery_domain": "Symbolic rule discovery / scientific explanation in synthetic domains (Odeen/Zendo-like tasks); more broadly, conceptual scientific reasoning and hypothesis generation.",
            "discovery_description": "The system discovers underlying symbolic rules that generate observed examples in Odeen, producing explicit symbolic explanations (conjectures) that generalize to held-out examples. It 'cracks' the Zendo-like tasks by autonomously building an interpretation/language mapping and using it to explain phenomena.",
            "discovery_type": "artificial scientist / original research (as framed by the authors)",
            "discovery_type_justification": "The thesis frames success on Odeen/Zendo as an instance of 'when a ML system becomes an artificial scientist' because the agent not only fits observations but produces interpretable explanations (conjectures) and learns its own interpreter rather than relying on a fixed human-coded language. This is presented as a conceptual step beyond purely empirical prediction.",
            "evaluation_methods": "Controlled synthetic benchmark (Odeen) with generated datasets; quantitative metrics defined for the task (the thesis references specific metrics sections and tables, e.g., T-Acc and NRS), generalization tests to held-out structures/rules, experiments assessing data-scaling laws, handling of ambiguity and contradiction, explainability analyses, measuring prediction confidence, and tests with variable 'thinking time' (generating more conjectures).",
            "validation_approaches": "Validation via held-out test sets and metrics specific to the explanatory task; ablation and comparison to baseline 'empiricist' models; experiments measure generalization capability, robustness to ambiguous/contradictory data, and interpretability of produced explanations. The thesis reports empirical superiority of CRNs over empiricist baselines in these validation regimes.",
            "novelty_assessment": "Novelty rests on two claims: (1) formalizing Explanatory Learning as distinct from standard supervised/program-synthesis formulations by requiring the agent to learn an interpreter, and (2) demonstrating that CRNs can learn interpretable explanations and generalize in Zendo-like tasks with greater data efficiency than purely empiricist models. The thesis positions this as moving 'beyond empiricism' in ML.",
            "impact_metrics": "Reported impact metrics include task-specific evaluation scores (e.g., accuracy-like metrics T-Acc, NRS—referenced in appendix/table headings), empirical scaling laws demonstrating data-efficiency advantages, and qualitative improvements in explainability. Exact numeric metrics are reported in the thesis tables (not reproduced verbatim here).",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The Odeen/Zendo tasks are chosen for human solvability; the thesis notes that CRNs 'crack Zendo' and that humans can solve these tasks. Additionally, the work contrasts CRNs with LLMs which fail a related Symbol Interpretation Task (SIT). CRNs outperform empiricist models in data efficiency and generalization in the synthetic explanatory environment.",
            "success_rate": "Qualitative: CRNs successfully solve the Odeen explanatory tasks in the reported experiments and demonstrate higher data efficiency and robustness compared to empiricist baselines. Exact success rates and metric values are given in the thesis experiment tables/figures.",
            "challenges_limitations": "Limitations include the synthetic nature of Odeen (transfer to real scientific domains is non-trivial), remaining ambiguity/contradiction handling challenges (though addressed experimentally), dependency on dataset generation choices, and the broader difficulty of evaluating whether produced explanations correspond to genuinely novel scientific insight versus artefacts of the synthetic environment.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1224.1",
            "source_info": {
                "paper_title": "Artificial Scientific Discovery",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Large Language Models (LLMs) / SIT",
            "name_full": "Large Language Models evaluated on the Symbol Interpretation Task (SIT)",
            "brief_description": "Transformer-based large language models (e.g., GPT-family) are examined as candidate 'sparks' of artificial scientists and empirically evaluated on the Big-Bench Symbol Interpretation Task, where they fail (performing at or near chance) while humans succeed.",
            "citation_title": "Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models",
            "mention_or_use": "use",
            "system_name": "Large Language Models (LLMs) such as GPT-3/GPT-4 and similar next-token-prediction transformers",
            "system_description": "Pretrained transformer LMs optimized for next-token prediction exhibiting strong linguistic and reasoning capabilities on many tasks. The thesis analyzes their limitations for scientific-style discovery—particularly their inability to learn new interpreters for novel symbolic systems and to reliably assess their own knowledge gaps.",
            "discovery_domain": "Natural language-based reasoning and symbolic interpretation; assessed for potential to perform scientific-style discoveries (symbol interpretation/explanation).",
            "discovery_description": "LLMs are tested on their ability to interpret arbitrary symbol systems and produce correct explanations or rule inferences (the SIT derived from Odeen/Zendo). The reported result is that LLMs perform no better than random chance on SIT subtasks and thus do not demonstrate the capacity to autonomously produce interpretable scientific discoveries in this setting.",
            "discovery_type": "not demonstrated (LLMs fail to function as artificial scientists on SIT)",
            "discovery_type_justification": "The thesis frames LLMs as candidates for artificial scientists ('sparks of Artificial Scientists?') but justifies their rejection based on empirical results: LLMs fail the Symbol Interpretation Task, demonstrating they cannot reliably build interpreters for new symbolic languages nor produce verifiable explanatory conjectures in the tested setting.",
            "evaluation_methods": "Benchmark evaluation using the Big-Bench Symbol Interpretation Task (SIT) and its subtasks; performance metrics comparing model outputs to ground-truth rule interpretations; comparisons to human participants (human baselines). The thesis refers to aggregated and subtask-specific performance figures (e.g., Figure 22, Figure 23, Table 6) showing the gap.",
            "validation_approaches": "Validation by measured performance on SIT subtasks against ground truth and against human baselines; analysis of failure modes (e.g., accepting input uncritically, inability to assess unknowns). The benchmark is part of the Big-Bench collection, enabling cross-model comparisons.",
            "novelty_assessment": "Novelty assessment focuses on inability rather than achievement: the established novelty is negative—the identification of a failure mode (symbol-interpretation / interpreter-learning) that LLMs cannot overcome with current architectures/training. The SIT is noted as the Big-Bench task with the largest gap between humans and models.",
            "impact_metrics": "Impact assessed via the size of the human–machine performance gap on SIT (noted as 'the largest performance gap' in Big-Bench) and by per-subtask and aggregate model accuracies (figures/tables referenced in the thesis). Numerical values are presented in the thesis but not quoted here.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "Direct comparison: humans fully solve SIT while LLMs perform at near-chance levels. The thesis emphasizes this stark quantitative gap (largest in Big-Bench) as evidence that current LLMs do not attain the required capabilities for interpreter-based discovery.",
            "success_rate": "Low: on SIT subtasks LLMs perform at or near random-chance levels according to the thesis; humans perform near perfect. Exact percentages are reported in the thesis Big-Bench results tables/figures.",
            "challenges_limitations": "Identified limitations include LLMs' tendency to uncritically accept inputs, inability to assess unknowns or produce calibrated uncertainty, failure to learn new interpreters from sparse symbol–observation pairings, and an overall tension between next-token predictive training and the epistemic requirements of scientific explanation.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1224.2",
            "source_info": {
                "paper_title": "Artificial Scientific Discovery",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Metahumans (conceptual)",
            "name_full": "Metahumans (hypothetical superior automated scientific entities)",
            "brief_description": "A conceptual discussion in the prologue describing hypothetical superior automated scientists ('metahumans') that dominate experimental research and communicate findings in an inaccessible digital neural transfer (DNT) medium.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Metahumans (conceptual automated scientists)",
            "system_description": "A speculative class of non-human research entities posited in the prologue: extremely capable automated systems that perform original research and communicate internally via an inaccessible medium (DNT), leading to a human interpretability crisis.",
            "discovery_domain": "General scientific research (speculative / philosophical discussion)",
            "discovery_description": "Used as a narrative device: metahumans are said to make original research discoveries accessible only via DNT, creating a situation where human scientists can no longer directly comprehend or produce original research.",
            "discovery_type": "transformational / paradigm-shifting (framed as a potential future scenario)",
            "discovery_type_justification": "The thesis uses the metahuman scenario to illustrate a transformational possibility in which automated entities monopolize discovery and produce results beyond human comprehension—this is discussed as a dramatic (paradigm-shifting) outcome rather than an observed empirical finding.",
            "evaluation_methods": "This is a conceptual / speculative discussion; no empirical evaluation methods are applied in the thesis for metahumans.",
            "validation_approaches": "Not applicable (speculative/philosophical argument).",
            "novelty_assessment": "Novelty is rhetorical/philosophical: the scenario underscores challenges of interpretability and communication if discoveries occur in a non-human-interpretable medium.",
            "impact_metrics": "None empirical; the text uses qualitative argumentation rather than metric-based impact assessment.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The discussion contrasts human scientific practice (explanation in human language) with a future where metahumans produce discoveries in an inaccessible format, leading to a shift in what counts as 'science' for humans.",
            "success_rate": "Not applicable (speculative).",
            "challenges_limitations": "The main point is the communicative barrier: discoveries inaccessible to humans create epistemic and cultural issues; the thesis argues that science is fundamentally about human-understandable explanations, so purely non-communicative metahuman discoveries are problematic.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1224.3",
            "source_info": {
                "paper_title": "Artificial Scientific Discovery",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "AlphaGo Zero",
            "name_full": "AlphaGo Zero",
            "brief_description": "A self-play reinforcement learning system that mastered the game of Go from scratch using MCTS and a neural network, cited in this thesis as inspiration for Olivaw.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AlphaGo Zero",
            "system_description": "Monte Carlo Tree Search guided by a neural network trained entirely by self-play reinforcement learning; referenced as a canonical example of machine discovery of game-playing knowledge.",
            "discovery_domain": "Game-playing (Go)",
            "discovery_description": "AlphaGo Zero discovered high-level Go strategies and achieved superhuman play via self-play learning without human game data; used as an inspirational precedent for Olivaw.",
            "discovery_type": "original research / paradigm-shifting (historical example in AI literature)",
            "discovery_type_justification": "AlphaGo Zero is invoked as an influential example where an automated system produced domain mastery autonomously, motivating inquiry into whether similar mechanisms can lead to scientific discovery in other domains.",
            "evaluation_methods": "Historical evaluation: head-to-head matches against top human players and prior engines (as discussed in the literature).",
            "validation_approaches": "Empirical matches and community validation in the original AlphaGo Zero literature (not validated within this thesis beyond citation).",
            "novelty_assessment": "Novelty in its domain historically recognized (self-play, no human data), used to motivate the thesis work.",
            "impact_metrics": "Historical records of match victories and community recognition (not enumerated here).",
            "comparison_to_human_discoveries": null,
            "comparison_details": "Serves as inspiration/comparison point for Olivaw; the thesis notes that while AlphaGo Zero discovered Go strategies, such systems cannot necessarily communicate discoveries in human-understandable explanatory form.",
            "success_rate": null,
            "challenges_limitations": "Used to illustrate that high-performance discovery/skill does not equal communicable scientific explanation; motivates need for interpreter-learning.",
            "has_incremental_transformational_comparison": null,
            "uuid": "e1224.4",
            "source_info": {
                "paper_title": "Artificial Scientific Discovery",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "OLIVAW: Mastering Othello without Human Knowledge, nor a Penny",
            "rating": 2,
            "sanitized_title": "olivaw_mastering_othello_without_human_knowledge_nor_a_penny"
        },
        {
            "paper_title": "Explanatory learning: Beyond empiricism in neural networks",
            "rating": 2,
            "sanitized_title": "explanatory_learning_beyond_empiricism_in_neural_networks"
        },
        {
            "paper_title": "ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training",
            "rating": 1,
            "sanitized_title": "asif_coupled_data_turns_unimodal_models_to_multimodal_without_training"
        },
        {
            "paper_title": "Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models",
            "rating": 2,
            "sanitized_title": "beyond_the_imitation_game_quantifying_and_extrapolating_the_capabilities_of_language_models"
        },
        {
            "paper_title": "AlphaGo Zero",
            "rating": 1,
            "sanitized_title": "alphago_zero"
        }
    ],
    "cost": 0.017912749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ARTIFICIAL SCIENTIFIC DISCOVERY</h1>
<p>ANTONIO NORELLI</p>
<p>PhD thesis in Computer Science
Dipartimento di Informatica
Università degli Studi di Roma "La Sapienza"
October 2023</p>
<p>Antonio Norelli: Artificial Scientific Discovery, PhD thesis in Computer Science, (C) October 2023</p>
<p>PHD SUPERVISOR:
Prof. Emanuele Rodolà, Università degli Studi di Roma "La Sapienza"
REVIEWERS:
Dr. Andrew Lampinen, Senior Research Scientist at Google DeepMind
Prof. Alex Bronstein, Technion - Israel Institute of Technology
thesis Defended on JANUARY 26, 2024,
BEFORE THE EXTERNAL COMMITTEE:
Prof. Lamberto Ballan, Università degli Studi di Padova
Prof. Giovanni Petri, Northeastern University London and CENTAI
Prof. Alessandro Raganato, Università degli Studi di Milano-Bicocca
PhD degree conferred cum laude.
A video of the defense can be found here.</p>
<p>A mamma, che insegna latino e greco ma vuole sempre che le spieghi la mia ricerca. Finché non capisce, e allora ho capito meglio anch'io.</p>
<p>E ho capito meglio cos'è la ricerca.</p>
<p>To my mother, who teaches Latin and Greek but always wants me to explain my research. Until she understands, and then I've understood it better myself.</p>
<p>And I've understood better what research truly is.</p>
<p>.</p>
<p>Rooted in the explosion of deep learning over the past decade, this thesis spans from AlphaGo to ChatGPT to empirically examine the fundamental concepts needed to realize the vision of an artificial scientist: a machine with the capacity to autonomously generate original research and contribute to the expansion of human knowledge.</p>
<p>The investigation begins with OlivaW, an AlphaGo Zero-like agent that discovers Othello knowledge from scratch but is unable to communicate it. This realization leads to the development of the Explanatory Learning (EL) framework, a formalization of the problem faced by a scientist when trying to explain a new phenomenon to their peers. The effective EL prescriptions allow us to crack Zendo, a popular board game simulating the scientific endeavor. This success comes with a fundamental insight: an artificial scientist must develop its own interpretation of the language used to explain its findings, and not rely on a rigid existing interpreter. Questioning the very process of learning an interpreter, we turn our attention to the inner functioning of modern multimodal models. This culminates in a simple idea to build CLIP-like models where interpretation and perception are explicitly disentangled: a cost-effective approach that couples two unimodal models using little multimodal data and no further training. Finally, we discuss what ChatGPT and its siblings are still missing to become artificial scientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark about interpreting Zendo-like explanations that sees LLMs going no further than random chance while being instead fully solved by humans.</p>
<p>.</p>
<p>The content of this thesis is largely based on the following articles. In each, I was the main author, leading the research, curating the writing, and conducting most of the experiments. In Big-Bench I was leading our task proposal.</p>
<ol>
<li>OLIVAW: Mastering Othello without Human Knowledge, nor a Penny
Antonio Norelli and Alessandro Panconesi
IEEE Transactions on Games, 2022
AlphaGo Zero for Othello. With two ideas to speed up the learning, and tested in a live match against a former world champion. (Norelli and Panconesi 2022)</li>
<li>Explanatory learning: Beyond empiricism in neural networks Antonio Norelli, Giorgio Mariani, Luca Moschella, Andrea Santilli, Giambattista Parascandolo, Simone Melzi, and Emanuele Rodolà
ICML 2023 Workshop: Knowledge and Logical Reasoning in the Era of Data-driven Learning
When a ML system becomes an artificial scientist: mastering the game of Zendo with Transformers.
(Norelli et al. 2022)</li>
<li>ASIF: Coupled Data Turns Unimodal Models to Multimodal Without Training
Antonio Norelli, Marco Fumero, Valentino Maiorca, Luca Moschella, Emanuele Rodolà, and Francesco Locatello
NeurIPS 2023: Conference on Neural Information Processing Systems The meaning was already there: connecting text and images without training a neural network to do so.
(Norelli et al. 2023)</li>
<li>Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models
450 authors including Antonio Norelli, Giorgio Mariani, Luca Moschella, Andrea Santilli, Giambattista Parascandolo, Simone Melzi, and Emanuele Rodolà
Transactions on Machine Learning Research, 2023
The task with the widest gap between human and machine performance in BIG-bench, a collaborative effort to test Language Models.
(Srivastava et al. 2023)</li>
</ol>
<p>I also collaborated in the following publications as part of my PhD research, but they are not covered in this thesis.
5. Relative Representations Enable Zero-shot Latent Space Communication
Luca Moschella, Valentino Maiorca, Marco Fumero, Antonio Norelli, Francesco Locatello, and Emanuele Rodolà
ICLR 2023: International Conference on Learning Representations
It happens that different neural networks trained on the same stuff learn intrinsically equivalent latent spaces.
(Moschella et al. 2022)
6. LIMP: Learning Latent Shape Representations with Metric Preservation Priors
Luca Cosmo, Antonio Norelli, Oshri Halimi, Ron Kimmel, and Emanuele Rodolà
ECCV 2020: European Conference on Computer Vision
With the right geometric prior, 11 samples are enough to train a generative model for 3 D shapes of humans or animals.
(Cosmo et al. 2020)
7. Latent Space Translation via Semantic Alignment</p>
<p>Valentino Maiorca, Luca Moschella, Antonio Norelli, Marco Fumero, Francesco Locatello, and Emanuele Rodolà
NeurIPS 2023: Conference on Neural Information Processing Systems Translating between pre-trained networks with simple algebraic transformations enables zero-shot stitching of text and vision models.
(Maiorca et al. 2023)
8. Learning Rotation-Agnostic Representations via Group Equivariant VAEs
Ahmedeo Shokry and Antonio Norelli
Tiny paper at ICLR 2023
Group-equivariant Variational Autoencoders may be useful to produce representations that are invariant to rotations.
(Shokry and Norelli 2023)
9. Bootstrapping Parallel Anchors for Relative Representations Irene Cannistraci, Luca Moschella, Valentino Maiorca, Marco Fumero, Antonio Norelli, and Emanuele Rodolà Tiny paper at ICLR 2023
New parallel anchors to use with relative representations can be discovered from a smaller set through optimization.
(Cannistraci et al. 2023)
10. Errare Humanum Est? A Pilot Study to Evaluate the Humanlikeness of an AI Othello Playing Agent
Enrico Lauletta, Beatrice Biancardi, Antonio Norelli, Maurizio</p>
<p>Mancini, and Alessandro Panconesi
Proceedings of the 22nd ACM International Conference on Intelligent Virtual, 2022
Investigating the human-like behaviors and characteristics of Olivaw.
(Lauletta et al. 2022)</p>
<p>.</p>
<p>It has been 25 years since a report of original research was last submitted to our editors for publication, making this an appropriate time to revisit the question that was so widely debated then: what is the role of human scientists in an age when the frontiers of scientific inquiry have moved beyond the comprehensibility of humans?</p>
<p>No doubt many of our subscribers remember reading papers whose authors were the first individuals ever to obtain the results they described. But as metahumans began to dominate experimental research, they increasingly made their findings available only via DNT (digital neural transfer), leaving journals to publish second-hand accounts translated into human language.</p>
<p>Without DNT, humans could not fully grasp earlier developments nor effectively utilize the new tools needed to conduct research, while metahumans continued to improve DNT and rely on it even more. Journals for human audiences were reduced to vehicles of popularization, and poor ones at that, as even the most brilliant humans found themselves puzzled by translations of the latest findings.</p>
<p>No one denies the many benefits of metahuman science, but one of its costs to human researchers was the realization that they would probably never make an original contribution to science again. Some left the field altogether, but those who stayed shifted their attentions away from original research and toward hermeneutics: interpreting the scientific work of metahumans.</p>
<p>In the year 2000, on the pages of Nature, the esteemed sciencefiction author Ted Chiang depicts a world that appears to offer no more room for human scientists. Superior entities has taken the lead in research, and communicate their findings only within themselves through an inaccessible medium (Chiang 2000).</p>
<p>This scenario seems the one we will be condemned to with the advent of artificial scientists: in the future, machines alone will be responsible for making the discoveries necessary to refine our tools and therapies. They are faster, with greater memory, capable of making associations beyond our reach. Most importantly, they will not be hampered by the bottleneck of our language, free to surpass our reasoning limits.</p>
<p>Are we condemned to not understand future breakthroughs, to give up on the once glorious practice of science as a species?</p>
<p>Se non ci divertiamo a risolvere questo problema perché dovremmo studiarlo? ${ }^{1}$</p>
<ul>
<li>Nicola Cabibbo (Wiki)</li>
</ul>
<p>Not at all. And not because we will not have those formidable machines. This fear comes from a fundamental misrepresentation of what science truly is: a playful pursuit of our curiosity.</p>
<p>That stands as a vital part of the human culture-as Ted Chiang reminds us in the latter half of his story-rooted in creativity, experience, and, ultimately, communication.</p>
<p>Science is the art of explaining nature to humans, there is no science beyond our language. ${ }^{2}$</p>
<p>Nevertheless, machines can partake in this infinite quest alongside us. Indeed, this is the perspective we will adopt in the following pages: How can we devise a machine capable of making its own discoveries and then effectively explain them to us?</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>1 INTRODUCTION AND OVERVIEW ..... 1
1.1 Devising an artificial scientist ..... 1
2 OLIVAW: MASTERING OTHELLO WITHOUT HUMAN KNOWL- EDGE, NOR A FORTUNE ..... 3
2.1 Introduction ..... 4
2.2 Related work ..... 5
2.3 Othello ..... 6
2.4 Olivaw: the algorithm ..... 7
2.4.1 The basic design ..... 8
2.4.2 Low-cost faster training ..... 9
2.5 Resources ..... 11
2.6 The training process ..... 12
2.6.1 Details to replicate training conditions: ..... 13
2.7 Attaining world-class level in Othello ..... 15
2.7.1 Matches on the web platform OthelloQuest ..... 15
2.7.2 Matches against Edax ..... 16
2.7.3 Matches against top-notch human players ..... 17
2.8 Conclusion ..... 19
3 EXPLANATORY LEARNING: BEYOND EMPIRICISM IN NEU- RAL NETWORKS ..... 21
3.1 Introduction ..... 22
3.2 Explanatory Learning ..... 23
3.2.1 Problem setup ..... 24
3.2.2 Relationship with other ML problems. ..... 25
3.3 Odeen: a puzzle game as Explanatory Learning envi- ronment ..... 26
3.3.1 Odeen challenge ..... 26
3.3.2 Problem formulation ..... 28
3.3.3 Why not explicitly ask for the rule? ..... 28
3.3.4 Dataset generation ..... 29
3.3.5 Metrics ..... 29
3.4 Critical Rationalist Networks ..... 30
3.4.1 Learning model ..... 31
3.5 Experiments ..... 32
3.5.1 Generalization power and data scaling laws ..... 33
3.5.2 Handling ambiguity and contradiction ..... 34
3.5.3 Explainability ..... 35
3.5.4 Adjustable thinking time. ..... 36
3.5.5 Prediction confidence ..... 36
3.6 Related Work ..... 37</p>
<p>3.7 Conclusions ..... 38
4 ASIF: COUPLED DATA TURNS UNIMODAL MODELS TO MUL- TIMODAL WITHOUT TRAINING ..... 41
4.1 Introduction ..... 42
4.2 Aligning Pre-Trained Models with ASIF ..... 44
4.2.1 Contrastive training to build a common space. ..... 46
4.2.2 Relative representations. ..... 46
4.2.3 Relation with Kernel methods. ..... 46
4.2.4 ASIF: relative representations inducing a mean-ingful common space. ..... 47
4.2.5 Properties of ASIF models. ..... 48
4.2.6 Relation to k-Nearest Neighbors. ..... 49
4.2.7 Implementation that scales. ..... 49
4.2.8 Design choices and implementation of ASIF mod- els. ..... 50
4.3 Related Works ..... 51
4.4 Empirical Evidence ..... 52
4.4.1 Pretrained encoders and multimodal dataset used. ..... 52
4.4.2 Zero-shot performance. ..... 53
4.4.3 ASIF scaling laws. ..... 53
4.4.4 Adjusting an ASIF model in seconds. ..... 54
4.4.5 Deep dive into a classification. ..... 55
4.5 Discussion ..... 56
4.5.1 Perception and interpretation disentangled. ..... 57
4.5.2 Learning or retrieval? ..... 57
4.5.3 Generalization to new distributions. ..... 57
4.5.4 Limitations. ..... 58
4.6 Conclusions. ..... 58
5 ARE LARGE LANGUAGE MODELS SPARKS OF ARTIFICIAL SCIENTISTS? ..... 61
5.1 The tension between truth and LLMs functioning ..... 62
5.1.1 Do LLMs just need more training data? ..... 62
5.1.2 Reality check ..... 63
5.1.3 LLMs uncritically accept every input sample ..... 64
5.1.4 LLMs are not able to assess what they do not know ..... 65
5.2 An experiment: LLMs tested on Odeen ..... 65
5.2.1 Big-Bench ..... 66
5.2.2 The Symbol Interpretation Task (SIT) ..... 66
5.2.3 What is SIT trying to measure? ..... 68
5.2.4 SIT subtasks ..... 69
5.2.5 SIT subtasks results ..... 70
6 CONCLUSIONS ..... 73</p>
<p>6.1 Recap ..... 73
6.2 Beyond Intelligence ..... 74
A APPENDIX EXPLANATORY LEARNING ..... 77
A. 1 Further details on the Odeen dataset ..... 77
A.1.1 The Odeen binary semantic representations. ..... 77
A. 2 Implementation Details ..... 79
A. 3 Efficiency ..... 82
A. 4 Odeen example games ..... 84
B APPENDIX ASIF ..... 87
B. 1 Additional details on the scaling laws experiment ..... 87
B. 2 Additional details on the EuroSAT experiment. ..... 88
B. 3 ASIF sensibility to its hyperparameters ..... 91
BIBLIOGRAPHY ..... 93</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Figure 1</th>
<th style="text-align: center;">Rules of Othello 7</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Figure 2</td>
<td style="text-align: center;">Olivaw's Training process. 10</td>
</tr>
<tr>
<td style="text-align: center;">Figure 3</td>
<td style="text-align: center;">Olivaw's performance on OthelloQuest 12</td>
</tr>
<tr>
<td style="text-align: center;">Figure 4</td>
<td style="text-align: center;">Location of crucial moves by generation 13</td>
</tr>
<tr>
<td style="text-align: center;">Figure 5</td>
<td style="text-align: center;">Olivaw vs Edax 15</td>
</tr>
<tr>
<td style="text-align: center;">Figure 6</td>
<td style="text-align: center;">Olivaw vs Edax: the tournament 18</td>
</tr>
<tr>
<td style="text-align: center;">Figure 7</td>
<td style="text-align: center;">Match between Olivaw generation 20 and the former World champion Michele Borassi, final game 20</td>
</tr>
<tr>
<td style="text-align: center;">Figure 8</td>
<td style="text-align: center;">The Odeen universe 22</td>
</tr>
<tr>
<td style="text-align: center;">Figure 9</td>
<td style="text-align: center;">A game of Odeen 26</td>
</tr>
<tr>
<td style="text-align: center;">Figure 10</td>
<td style="text-align: center;">Odeen science book 27</td>
</tr>
<tr>
<td style="text-align: center;">Figure 11</td>
<td style="text-align: center;">Odeen Explanatory Learning problem 29</td>
</tr>
<tr>
<td style="text-align: center;">Figure 12</td>
<td style="text-align: center;">Format of a solution for the Odeen task 30</td>
</tr>
<tr>
<td style="text-align: center;">Figure 13</td>
<td style="text-align: center;">Test-time algorithm of CRNs and Transformer architectures used 32</td>
</tr>
<tr>
<td style="text-align: center;">Figure 14</td>
<td style="text-align: center;">The rationalist model is more data efficient than the empiricist model 34</td>
</tr>
<tr>
<td style="text-align: center;">Figure 15</td>
<td style="text-align: center;">How generating more conjectures improves the performance of a CRN 36</td>
</tr>
<tr>
<td style="text-align: center;">Figure 16</td>
<td style="text-align: center;">ASIF is a simple recipe to align the representations of two frozen pre-trained encoders 42</td>
</tr>
<tr>
<td style="text-align: center;">Figure 17</td>
<td style="text-align: center;">The ASIF construction 43</td>
</tr>
<tr>
<td style="text-align: center;">Figure 18</td>
<td style="text-align: center;">Captions of similar images are themselves similar 44</td>
</tr>
<tr>
<td style="text-align: center;">Figure 19</td>
<td style="text-align: center;">Zero shot classification with ASIF 45</td>
</tr>
<tr>
<td style="text-align: center;">Figure 20</td>
<td style="text-align: center;">ASIF is a learning algorithm 54</td>
</tr>
<tr>
<td style="text-align: center;">Figure 21</td>
<td style="text-align: center;">ASIF representations are interpretable and amend- <br> able 55</td>
</tr>
<tr>
<td style="text-align: center;">Figure 22</td>
<td style="text-align: center;">LLMs performance on our Symbol Interpretation Task 67</td>
</tr>
<tr>
<td style="text-align: center;">Figure 23</td>
<td style="text-align: center;">LLMs performance on the SIT subtasks 72</td>
</tr>
<tr>
<td style="text-align: center;">Figure 24</td>
<td style="text-align: center;">Grammar productions for the Odeen Language. 78</td>
</tr>
<tr>
<td style="text-align: center;">Figure 25</td>
<td style="text-align: center;">Hamming weight of structures and rules representations in Odeen 79</td>
</tr>
<tr>
<td style="text-align: center;">Figure 26</td>
<td style="text-align: center;">PCA on the structures representations 80</td>
</tr>
<tr>
<td style="text-align: center;">Figure 27</td>
<td style="text-align: center;">Interpretability of EuroSAT classifications through ASIF 88</td>
</tr>
<tr>
<td style="text-align: center;">Figure 28</td>
<td style="text-align: center;">ASIF performance does not saturate earlier with smaller encoders 89</td>
</tr>
<tr>
<td style="text-align: center;">Figure 29</td>
<td style="text-align: center;">ASIF Hyperparameters search 91</td>
</tr>
</tbody>
</table>
<p>Figure 30 Captions of similar images are themselves similar 92</p>
<p>LIST OF TABLES</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Table 1</th>
<th style="text-align: center;">Leaderboard of the tournament between Oli- <br> vaw and Edax 18</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Table 2</td>
<td style="text-align: center;">Olivaw games versus top Othello players 19</td>
</tr>
<tr>
<td style="text-align: center;">Table 3</td>
<td style="text-align: center;">Rationalist vs Empiricist models 33</td>
</tr>
<tr>
<td style="text-align: center;">Table 4</td>
<td style="text-align: center;">Explanatory Learning vs Program Synthesis paradigm</td>
</tr>
<tr>
<td style="text-align: center;">Table 5</td>
<td style="text-align: center;">Zero shot classification accuracy of different <br> multimodal designs 52</td>
</tr>
<tr>
<td style="text-align: center;">Table 6</td>
<td style="text-align: center;">The Symbol Interpretation Task shows the largest <br> performance gap between human participants <br> and LLMs. 71</td>
</tr>
<tr>
<td style="text-align: center;">Table 7</td>
<td style="text-align: center;">Number of training epochs for each training <br> regimen in Odeen. 81</td>
</tr>
<tr>
<td style="text-align: center;">Table 8</td>
<td style="text-align: center;">T-Acc and NRS for different training regimens. 82</td>
</tr>
<tr>
<td style="text-align: center;">Table 9</td>
<td style="text-align: center;">CRNs computational cost analysis on structures 83</td>
</tr>
<tr>
<td style="text-align: center;">Table 10</td>
<td style="text-align: center;">CRNs computational cost analysis on rules 84</td>
</tr>
<tr>
<td style="text-align: center;">Table 11</td>
<td style="text-align: center;">Zero shot classification accuracy of ASIF mod- <br> els with different backbones 90</td>
</tr>
<tr>
<td style="text-align: center;">Table 12</td>
<td style="text-align: center;">ASIF Hyperparams search 91</td>
</tr>
</tbody>
</table>
<p>.</p>
<h1>1.1 DEVISING AN ARTIFICIAL SCIENTIST</h1>
<p>Explanations are the fuel of progress, the fundamental tool through which humans have increased their agency, earning more and more control over their future throughout history. So far, the production of these extraordinary symbolic sequences has been a unique prerogative of human scientists, but the formidable breakthroughs in AI that followed the advent of deep learning (LeCun, Bengio, and Hinton 2015) evoke the idea of machines capable of assisting us in this endeavour. Not mere tools empowering scientists, but rather peers capable of producing original research and pushing forward knowledge autonomously.</p>
<p>In this thesis I seriously entertain this idea, and seek to understand what it means to build an artificial scientist.</p>
<p>We will relive my research route, that initiated with an in-depth study of AlphaGo Zero. This AI system was able to master Go starting from scratch and defeated the best players in the world, a very promising starting point to investigate the possibility of knowledge creation by machines. Our discussion will begin with Olivaw, an AlphaGo Zero-like agent that I brought to retrace the journey of its illustrious predecessor on the game of Othello, to the point of challenging a former World champion. Narrated with a blend of rigor and humor, this adventure culminates in a pivotal realization: knowledge is such if it can be transmitted to us, and AlphaGo cannot write a book on Go that could help human players improve.</p>
<p>A fundamental characteristic of a scientist is the ability to communicate their own discoveries. This will lead us to realize the tension between language and the effective representation of new natural phenomena: language must be adapted to the new communicative need, but at the same time it should remain understandable; its vocabulary and rules slowly but inevitably change over time. Therefore, we will attempt to model an agent capable of explaining its observations without strictly defining its language. As a result, we will introduce Explanatory Learning and place the keystone of this thesis: a true artificial scientist can only emerge when a machine can autonomously interpret symbols.</p>
<p>This realization will drive us beyond traditional AI methodologies, such as Inductive Logic Programming and Program Synthesis, which approach the challenge of creating intelligent agents by presupposing the existence of a rigid, human-coded language interpreter. In-</p>
<p>Chapter 2
Olivaw: Mastering Othello with neither Human Knowledge nor a Penny</p>
<p>Chapter 3
Explanatory
Learning: Beyond
Empiricism in
Neural Networks</p>
<p>Chapter 4
ASIF: Coupled Data
Turns Unimodal
Models to
Multimodal without
Training</p>
<p>Chapter 5
Are Large Language
Models Sparks of
Artificial Scientists?
stead, Explanatory Learning ditches this assumption, leaving us with a sparse assortment of symbolic sequences associated to observations of various phenomena as the sole resource to build an interpreter. It calls for an autonomous accomplishment of the mastering of a language through learning. An autonomous construction of the map between signs and meanings, that stays adjustable as it had to be during its creation, not a given rigid one carved in stone.</p>
<p>Having reached this peak, and realized that the interpreter is a fundamental piece of an artificial scientist, we will narrow our focus on it, analyzing how this map between signs and their meanings can be created and adjusted. Deep learning has provided us with glorious examples of the creation of this map, like the contrastive learning of CLIP (Radford et al. 2021), resulting in an unprecedented ability to connect text with images. Still, CLIP's creation process is very opaque: countless and repeated weight updates under the direction of a gradient with cascades of non-linear dependencies; it seems almost the technology of the metahumans mentioned in the prologue. We will give it back to humans, downgrading neural networks to mere sensors and building a map between signs and meanings comparable in performance to CLIP (Radford et al. 2021) but in broad daylight, with a transparent and simple algorithm, based on a formalization of the word "as" in the context of representation learning. That is, taking the vector representing an image, and considering it as if it were the vector representing its ideal caption.</p>
<p>Finally, after having recognized the centrality of language in scientific discovery, we will not ignore what is arguably the most impressive product of deep learning as of today-based on a trivial but incredibly effective model of language as just a matter of being good in predicting the next word-Large Language Models. They took the scene of AI research only in 2020 with GPT-3 (Brown et al. 2020), and three years later GPT-4 is already hailed as a spark of Artificial General Intelligence (Bubeck et al. 2023), i.e. a machine that could learn to accomplish any intellectual task that human beings or animals can perform. And therefore also science. The path has now been taken, and are we a step away from the artificial scientist able to autonomously push forward human knowledge, as we imagined a few lines above? In the last chapter of this thesis, we will discuss the impressive capabilities of Large Language Models, but also examine the tension between how they function and the principles of scientific practice. This culminates in the resounding failure of LLMs on the Symbol Interpretation Task, a benchmark based on Odeen designed to test the ability to reason and interpret symbols. Fully solved by humans, it turned out to be the task with the largest gap between human and machine performance in the Big-Bench collection (Srivastava et al. 2023).</p>
<h1>OLIVAW: MASTERING OTHELLO WITHOUT HUMAN KNOWLEDGE, NOR A FORTUNE</h1>
<h2>CHAPTER ABSTRACT</h2>
<p>We introduce Olivaw, an AI Othello player adopting the design principles of the famous AlphaGo programs. The main motivation behind Olivaw was to discover knowledge from scratch in a non-trivial board game at a tiny fraction of the cost of its illustrious predecessors. In this chapter, we show how the AlphaGo Zero's paradigm can be successfully applied to the popular game of Othello using only commodity hardware and free cloud services. While being simpler than Chess or Go, Othello maintains a considerable search space and difficulty in evaluating board positions. To achieve this result, Olivaw implements some improvements inspired by recent works to accelerate the standard AlphaGo Zero learning process. The main modification implies doubling the positions collected per game during the training phase, by including also positions not played but largely explored by the agent. We tested the strength of Olivaw in three different ways: by pitting it against Edax, considered by many the strongest open-source Othello engine, by playing anonymous games on the web platform OthelloQuest, and finally in two in-person matches against top-notch human players: a national champion and a former world champion.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>This chapter is based on the paper "Olivaw: Mastering Othello without Human Knowledge, nor a Fortune", by Antonio Norelli and Alessandro Panconesi.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>