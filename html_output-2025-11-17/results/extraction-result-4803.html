<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4803 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4803</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4803</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-103.html">extraction-schema-103</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <p><strong>Paper ID:</strong> paper-081edae651e709e448bdd8a1f1b5760c7c7e1f53</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53" target="_blank">Long Time No See! Open-Domain Conversation with Long-Term Persona Memory</a></p>
                <p><strong>Paper Venue:</strong> Findings</p>
                <p><strong>Paper TL;DR:</strong> This is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot, using a dialogue generation framework with Long-Term Memory (LTM) mechanism (called PLATO-LTM).</p>
                <p><strong>Paper Abstract:</strong> Most of the open-domain dialogue models tend to perform poorly in the setting of long-term human-bot conversations. The possible reason is that they lack the capability of understanding and memorizing long-term dialogue history information. To address this issue, we present a novel task of Long-term Memory Conversation (LeMon) and then build a new dialogue dataset DuLeMon and a dialogue generation framework with Long-Term Memory (LTM) mechanism (called PLATO-LTM). This LTM mechanism enables our system to accurately extract and continuously update long-term persona memory without requiring multiple-session dialogue datasets for model training. To our knowledge, this is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot. Results on DuLeMon indicate that PLATO-LTM can significantly outperform baselines in terms of long-term dialogue consistency, leading to better dialogue engagingness.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4803.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4803.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-LTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO with Long-Term Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plug-in long-term persona memory module (LTM) integrated with the PLATO-2 generative dialogue model that extracts, stores, updates and retrieves explicit persona sentences for both user and chatbot to improve long-term conversational consistency and engagingness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-LTM</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Based on PLATO-2 (transformer-based generative dialog model). Adds a dual explicit long-term memory (user memory and chatbot memory), a Persona Extractor (PE) to identify persona sentences, and a Context-Persona Matching (CPM) retriever; retrieved persona sentences are concatenated to context for generation. Uses role embeddings and role tokens to separate persona sources.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external explicit long-term persona memory (retrieval-augmented vector store / episodic-persona memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Memory stores explicit persona sentences with precomputed embeddings {persona_text, E_rho(persona)} in two separate stores (user and chatbot). Write proceeds by PE detection and duplicate replacement if cosine similarity > s_dup (0.95). Read retrieves top-K candidates by dense vector similarity (cosine) between context encoding E_c(c) and persona encodings, filters by similarity threshold s_c (0.7), and returns top-k (K=5) user and chatbot persona sentences that are concatenated to context for generation. The CPM scoring model is trained with triplet loss (margin 0.2).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term Memory Conversation (LeMon) / open-domain long-term persona chat</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate conversational responses that maintain and utilize long-term persona information (mutual persona) across sessions; system must extract, store, update, retrieve persona facts about both user and bot and use them to produce consistent, engaging dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>DuLeMon (new dataset introduced in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Human eval (self-chat) — Coherence: 1.67 (score/2); Consistency: 0.87; Engagingness: 1.54. Retrieval metrics: CPM AUC=0.76, recall@5=0.83. Persona extractor (used for writing) pc-stage2 F1=0.91 (ACC=0.92, Precision=0.95, Recall=0.87).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Baseline PLATO-FT (no LTM, but fine-tuned) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40. Baseline PLATO-2 (pretrained, no finetune/no LTM) — Coherence: 1.70; Consistency: 0.13; Engagingness: 1.46.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Adding LTM (with persona extractor) substantially improves persona consistency (0.40 -> 0.87 relative improvement ~118% versus PLATO-FT) and improves engagingness (1.40 -> 1.54); LTM without PE still improves consistency over PLATO-FT (to 0.49) showing memory itself helps, but the PE notably increases gains. Retrieval model achieves AUC 0.76 and recall@5 0.83, and persona extractor attains F1 ~0.91 supporting effective memory population.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Fine-tuning PLATO on the (relatively small) DuLeMon dataset slightly degrades coherence relative to pretrained PLATO-2 (1.59 vs 1.70). The approach depends on accurate persona extraction and retrieval thresholds (PE and CPM errors can cause wrong or missing persona use). Memory design uses similarity thresholds and duplicate replacement heuristics (s_dup=0.95, s_c=0.7) which may require tuning; authors note persona sparsity and do not limit memory capacity, which could affect long-term scaling but is not empirically explored.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Explicit read-write long-term persona memory that stores sentence-level persona facts for both user and bot, combined with a persona extractor and a learned context-persona matching retriever, enables large-scale generative dialogue models to leverage long-term persona without training on long-session data; persona extraction quality and retrieval accuracy are critical, and concatenating retrieved persona to context with role signals is an effective generation strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4803.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-LTM w/o PE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO-LTM without Persona Extractor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Variant of PLATO-LTM that writes all historical utterances into memory (separately for user and bot) without first filtering by a persona extractor; used to evaluate importance of PE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-LTM w/o PE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same PLATO-2 generation backbone and LTM read/retrieval pipeline as PLATO-LTM but skips persona extraction at write-time; all history utterances are stored in memory (subject to duplicate replacement) and then retrieved by CPM for generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external explicit long-term memory (unfiltered: stores all historical utterances)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Writes unfiltered historical utterances to memory and retrieves top-K by the same CPM retriever; no persona-sentence-level filtering before storage (relies on CPM at read-time to select relevant items).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term Memory Conversation (LeMon) / persona-aware long-term chat (ablation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same as PLATO-LTM — produce long-term persona-coherent and engaging responses; this variant tests memory effectiveness without an upstream persona extractor.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>DuLeMon</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Human eval (self-chat) — Coherence: 1.57; Consistency: 0.49; Engagingness: 1.43.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>PLATO-FT (no LTM) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Using LTM without persona extraction still improves persona consistency over PLATO-FT (0.40 -> 0.49), but is substantially worse than PLATO-LTM with PE (0.49 vs 0.87), indicating that filtering (PE) is important to avoid storing noisy or irrelevant memory entries and to maximize utility of retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Storing all historical utterances without filtering increases memory noise and yields lower gains; reliance on CPM alone to select relevant items is insufficient to match performance obtained when upstream persona extraction is applied.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Memory alone helps, but upstream filtering (persona extraction) that stores focused, high-quality persona facts is necessary to substantially increase persona consistency and engagingness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4803.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-FT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO-2 Fine-Tuned on DuLeMon</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PLATO-2 generative dialogue model fine-tuned on DuLeMon dataset (role_embed and role_token used in best variants) used as a non-memory baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-FT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>PLATO-2 model fine-tuned on the DuLeMon dataset (with role embedding and role token). Does not include the long-term memory module; used as a baseline to compare effects of adding LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>none</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>No long-term memory; only uses context and persona present in the current session (if provided) during fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term persona dialogue (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same DuLeMon LeMon task; used to evaluate whether fine-tuning alone confers long-term persona ability.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>DuLeMon</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Human eval (self-chat) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40. Automatic generative metrics (best generative config reported): PPL (32L + role_embed + role_token) = 9.380, BLEU-1/2 ~ 0.194/0.087, DISTINCT-1/2 = 0.068/0.296, F1=22.61 (see Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Serves as the primary no-LTM baseline: adding LTM increases consistency drastically (0.40 -> 0.87 with PE) and modestly increases engagingness; fine-tuning without explicit memory can decrease coherence relative to the pretrained PLATO-2.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Fine-tuning on relatively small DuLeMon can reduce open-domain coherence compared to the pretrained PLATO-2; lacks mechanisms to accumulate and reuse persona facts across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Fine-tuning alone is insufficient to achieve robust long-term persona consistency; explicit memory mechanisms are required to store and recall persona across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4803.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Example-based personalized agent (Bang et al., 2015)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Example-based chat-oriented dialogue system with personalized long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior rule/example-based dialogue system that memorizes user-related information for personalized response rewriting and long-term interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Example-based chatoriented dialogue system with personalized longterm memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Bang et al. (2015) personalized chat agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Rule/example-based dialogue system that stores user-related information in a long-term memory and uses it to personalize response generation or rewriting.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic / long-term personalized memory (rule-based storage)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Memorizes user-related facts from prior interactions and uses them to rewrite or select personalized responses in future dialogues (not a neural retrieval store).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Personalized long-term dialogue / response rewriting</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Maintain and use long-term user information to personalize chat responses over extended interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Mentioned as prior work demonstrating long-term memory use in chat systems; these systems were mainly rule-based and did not leverage large-scale pretrained generative models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Prior systems are rule-based with difficulties scaling to large pretraining and learning-based retrieval; authors of current paper cite them to motivate neural LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Historical example-based memory systems show value in maintaining user-specific facts, motivating neural LTM components for modern generative models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4803.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conversational memory agent (Campos et al., 2018)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent that revisits shared conversational history to maintain coherent social relationships</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent architecture that leverages conversational memory to revisit shared user-agent histories to maintain coherent social relationships over time; identifies difficulties exploiting shared history at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Challenges in exploiting conversational memory in human-agent interaction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Campos et al. (2018) conversational memory agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Framework/agent that stores and revisits shared conversational history to sustain long-term social interaction and coherence, discussing architectural and practical challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>conversational memory / episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Maintains and revisits shared history with users to provide coherent long-term interactions; highlights representational and utilization challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term human-agent conversational coherence</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Use conversational history to maintain consistent, socially coherent interactions across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Cited to highlight difficulties in leveraging shared history; motivates the need for robust memory architectures in neural dialogue systems.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Authors report challenges in exploiting shared history with individuals and accommodating expected conversational coordination patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Practical challenges in conversational memory motivate careful memory design (filtering, retrieval relevance) as implemented in PLATO-LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4803.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Episodic conversational memory (Elvir et al., 2017)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Remembering a conversation - a conversational memory architecture for embodied conversational agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A unified episodic memory architecture for embodied conversational agents that determines prevalent contexts from interactions and stores them for later use.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Remembering a conversation - a conversational memory architecture for embodied conversational agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Elvir et al. (2017) episodic memory agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Proposes a unified episodic memory architecture for conversational agents to identify prevalent contexts in dialogues and store them for future retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory architecture</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Extracts and stores salient context/facts from interactions to support later dialogue behavior and revisiting shared history.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Conversational memory support for embodied agents</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Maintain and reuse salient context from interactions to support coherent future dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Referenced as antecedent work on episodic memory in dialogue; influences design choice to store explicit persona facts in PLATO-LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Prior work highlights engineering challenges in detecting and managing relevant episodic items.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Episodic memory concepts (detect/store/retrieve salient items) are applicable to persona LTM design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4803.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4803.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MSC / Xu et al. (2021)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Session Chat (MSC) dataset and retrieval-augmented dialogue approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An English multi-session extension of PersonaChat (MSC) that annotates session summaries and uses summarized prior conversations as memory documents for retrieval-augmented generation; shows pretrained generative models struggle on long-term conversation without such data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond goldfish memory: Long-term open-domain conversation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MSC / Xu et al. (2021) retrieval-augmented models</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Dataset and retrieval-augmented generative approach that summarizes and recalls previous conversations as retrieval documents for future generation; highlights that storing ever-growing documents without dynamic modification may be problematic.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented memory (document-level summaries)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Stores summaries/documents of prior sessions and retrieves them during generation; stored documents are not dynamically modified and may grow unbounded with sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term open-domain conversation (multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-session conversational setting requiring summarization and retrieval of past interactions to inform future dialogue turns.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>MSC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>Cited as a recent approach to long-term memory in dialogue; authors contrast PLATO-LTM design (real-time extraction and dynamic update of persona memory) with MSC's static summary documents that grow over time and require long-session data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>MSC stored documents expand indefinitely and are not dynamically modified; retrieval-augmented methods may rely on long-session datasets for training, which are costly.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Dynamic, real-time persona extraction and memory updating (as in PLATO-LTM) can mitigate needs for long-session annotated data and unbounded document growth.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Beyond goldfish memory: Long-term open-domain conversation <em>(Rating: 2)</em></li>
                <li>Challenges in exploiting conversational memory in human-agent interaction <em>(Rating: 2)</em></li>
                <li>Example-based chatoriented dialogue system with personalized longterm memory <em>(Rating: 2)</em></li>
                <li>Remembering a conversation - a conversational memory architecture for embodied conversational agents <em>(Rating: 2)</em></li>
                <li>Acquisition and use of long-term memory for personalized dialog systems <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4803",
    "paper_id": "paper-081edae651e709e448bdd8a1f1b5760c7c7e1f53",
    "extraction_schema_id": "extraction-schema-103",
    "extracted_data": [
        {
            "name_short": "PLATO-LTM",
            "name_full": "PLATO with Long-Term Memory",
            "brief_description": "A plug-in long-term persona memory module (LTM) integrated with the PLATO-2 generative dialogue model that extracts, stores, updates and retrieves explicit persona sentences for both user and chatbot to improve long-term conversational consistency and engagingness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-LTM",
            "agent_description": "Based on PLATO-2 (transformer-based generative dialog model). Adds a dual explicit long-term memory (user memory and chatbot memory), a Persona Extractor (PE) to identify persona sentences, and a Context-Persona Matching (CPM) retriever; retrieved persona sentences are concatenated to context for generation. Uses role embeddings and role tokens to separate persona sources.",
            "memory_type": "external explicit long-term persona memory (retrieval-augmented vector store / episodic-persona memory)",
            "memory_description": "Memory stores explicit persona sentences with precomputed embeddings {persona_text, E_rho(persona)} in two separate stores (user and chatbot). Write proceeds by PE detection and duplicate replacement if cosine similarity &gt; s_dup (0.95). Read retrieves top-K candidates by dense vector similarity (cosine) between context encoding E_c(c) and persona encodings, filters by similarity threshold s_c (0.7), and returns top-k (K=5) user and chatbot persona sentences that are concatenated to context for generation. The CPM scoring model is trained with triplet loss (margin 0.2).",
            "task_name": "Long-term Memory Conversation (LeMon) / open-domain long-term persona chat",
            "task_description": "Generate conversational responses that maintain and utilize long-term persona information (mutual persona) across sessions; system must extract, store, update, retrieve persona facts about both user and bot and use them to produce consistent, engaging dialogue.",
            "benchmark_name": "DuLeMon (new dataset introduced in paper)",
            "performance_with_memory": "Human eval (self-chat) — Coherence: 1.67 (score/2); Consistency: 0.87; Engagingness: 1.54. Retrieval metrics: CPM AUC=0.76, recall@5=0.83. Persona extractor (used for writing) pc-stage2 F1=0.91 (ACC=0.92, Precision=0.95, Recall=0.87).",
            "performance_without_memory": "Baseline PLATO-FT (no LTM, but fine-tuned) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40. Baseline PLATO-2 (pretrained, no finetune/no LTM) — Coherence: 1.70; Consistency: 0.13; Engagingness: 1.46.",
            "has_performance_with_without_memory": true,
            "memory_comparison_summary": "Adding LTM (with persona extractor) substantially improves persona consistency (0.40 -&gt; 0.87 relative improvement ~118% versus PLATO-FT) and improves engagingness (1.40 -&gt; 1.54); LTM without PE still improves consistency over PLATO-FT (to 0.49) showing memory itself helps, but the PE notably increases gains. Retrieval model achieves AUC 0.76 and recall@5 0.83, and persona extractor attains F1 ~0.91 supporting effective memory population.",
            "limitations_or_challenges": "Fine-tuning PLATO on the (relatively small) DuLeMon dataset slightly degrades coherence relative to pretrained PLATO-2 (1.59 vs 1.70). The approach depends on accurate persona extraction and retrieval thresholds (PE and CPM errors can cause wrong or missing persona use). Memory design uses similarity thresholds and duplicate replacement heuristics (s_dup=0.95, s_c=0.7) which may require tuning; authors note persona sparsity and do not limit memory capacity, which could affect long-term scaling but is not empirically explored.",
            "key_insights": "Explicit read-write long-term persona memory that stores sentence-level persona facts for both user and bot, combined with a persona extractor and a learned context-persona matching retriever, enables large-scale generative dialogue models to leverage long-term persona without training on long-session data; persona extraction quality and retrieval accuracy are critical, and concatenating retrieved persona to context with role signals is an effective generation strategy.",
            "uuid": "e4803.0",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "PLATO-LTM w/o PE",
            "name_full": "PLATO-LTM without Persona Extractor",
            "brief_description": "Variant of PLATO-LTM that writes all historical utterances into memory (separately for user and bot) without first filtering by a persona extractor; used to evaluate importance of PE.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-LTM w/o PE",
            "agent_description": "Same PLATO-2 generation backbone and LTM read/retrieval pipeline as PLATO-LTM but skips persona extraction at write-time; all history utterances are stored in memory (subject to duplicate replacement) and then retrieved by CPM for generation.",
            "memory_type": "external explicit long-term memory (unfiltered: stores all historical utterances)",
            "memory_description": "Writes unfiltered historical utterances to memory and retrieves top-K by the same CPM retriever; no persona-sentence-level filtering before storage (relies on CPM at read-time to select relevant items).",
            "task_name": "Long-term Memory Conversation (LeMon) / persona-aware long-term chat (ablation)",
            "task_description": "Same as PLATO-LTM — produce long-term persona-coherent and engaging responses; this variant tests memory effectiveness without an upstream persona extractor.",
            "benchmark_name": "DuLeMon",
            "performance_with_memory": "Human eval (self-chat) — Coherence: 1.57; Consistency: 0.49; Engagingness: 1.43.",
            "performance_without_memory": "PLATO-FT (no LTM) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40.",
            "has_performance_with_without_memory": true,
            "memory_comparison_summary": "Using LTM without persona extraction still improves persona consistency over PLATO-FT (0.40 -&gt; 0.49), but is substantially worse than PLATO-LTM with PE (0.49 vs 0.87), indicating that filtering (PE) is important to avoid storing noisy or irrelevant memory entries and to maximize utility of retrieval.",
            "limitations_or_challenges": "Storing all historical utterances without filtering increases memory noise and yields lower gains; reliance on CPM alone to select relevant items is insufficient to match performance obtained when upstream persona extraction is applied.",
            "key_insights": "Memory alone helps, but upstream filtering (persona extraction) that stores focused, high-quality persona facts is necessary to substantially increase persona consistency and engagingness.",
            "uuid": "e4803.1",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "PLATO-FT",
            "name_full": "PLATO-2 Fine-Tuned on DuLeMon",
            "brief_description": "PLATO-2 generative dialogue model fine-tuned on DuLeMon dataset (role_embed and role_token used in best variants) used as a non-memory baseline.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-FT",
            "agent_description": "PLATO-2 model fine-tuned on the DuLeMon dataset (with role embedding and role token). Does not include the long-term memory module; used as a baseline to compare effects of adding LTM.",
            "memory_type": "none",
            "memory_description": "No long-term memory; only uses context and persona present in the current session (if provided) during fine-tuning.",
            "task_name": "Long-term persona dialogue (baseline)",
            "task_description": "Same DuLeMon LeMon task; used to evaluate whether fine-tuning alone confers long-term persona ability.",
            "benchmark_name": "DuLeMon",
            "performance_with_memory": null,
            "performance_without_memory": "Human eval (self-chat) — Coherence: 1.59; Consistency: 0.40; Engagingness: 1.40. Automatic generative metrics (best generative config reported): PPL (32L + role_embed + role_token) = 9.380, BLEU-1/2 ~ 0.194/0.087, DISTINCT-1/2 = 0.068/0.296, F1=22.61 (see Table 4).",
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "Serves as the primary no-LTM baseline: adding LTM increases consistency drastically (0.40 -&gt; 0.87 with PE) and modestly increases engagingness; fine-tuning without explicit memory can decrease coherence relative to the pretrained PLATO-2.",
            "limitations_or_challenges": "Fine-tuning on relatively small DuLeMon can reduce open-domain coherence compared to the pretrained PLATO-2; lacks mechanisms to accumulate and reuse persona facts across sessions.",
            "key_insights": "Fine-tuning alone is insufficient to achieve robust long-term persona consistency; explicit memory mechanisms are required to store and recall persona across sessions.",
            "uuid": "e4803.2",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Example-based personalized agent (Bang et al., 2015)",
            "name_full": "Example-based chat-oriented dialogue system with personalized long-term memory",
            "brief_description": "Prior rule/example-based dialogue system that memorizes user-related information for personalized response rewriting and long-term interactions.",
            "citation_title": "Example-based chatoriented dialogue system with personalized longterm memory",
            "mention_or_use": "mention",
            "agent_name": "Bang et al. (2015) personalized chat agent",
            "agent_description": "Rule/example-based dialogue system that stores user-related information in a long-term memory and uses it to personalize response generation or rewriting.",
            "memory_type": "episodic / long-term personalized memory (rule-based storage)",
            "memory_description": "Memorizes user-related facts from prior interactions and uses them to rewrite or select personalized responses in future dialogues (not a neural retrieval store).",
            "task_name": "Personalized long-term dialogue / response rewriting",
            "task_description": "Maintain and use long-term user information to personalize chat responses over extended interactions.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "memory_comparison_summary": "Mentioned as prior work demonstrating long-term memory use in chat systems; these systems were mainly rule-based and did not leverage large-scale pretrained generative models.",
            "limitations_or_challenges": "Prior systems are rule-based with difficulties scaling to large pretraining and learning-based retrieval; authors of current paper cite them to motivate neural LTM.",
            "key_insights": "Historical example-based memory systems show value in maintaining user-specific facts, motivating neural LTM components for modern generative models.",
            "uuid": "e4803.3",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Conversational memory agent (Campos et al., 2018)",
            "name_full": "Agent that revisits shared conversational history to maintain coherent social relationships",
            "brief_description": "An agent architecture that leverages conversational memory to revisit shared user-agent histories to maintain coherent social relationships over time; identifies difficulties exploiting shared history at scale.",
            "citation_title": "Challenges in exploiting conversational memory in human-agent interaction",
            "mention_or_use": "mention",
            "agent_name": "Campos et al. (2018) conversational memory agent",
            "agent_description": "Framework/agent that stores and revisits shared conversational history to sustain long-term social interaction and coherence, discussing architectural and practical challenges.",
            "memory_type": "conversational memory / episodic memory",
            "memory_description": "Maintains and revisits shared history with users to provide coherent long-term interactions; highlights representational and utilization challenges.",
            "task_name": "Long-term human-agent conversational coherence",
            "task_description": "Use conversational history to maintain consistent, socially coherent interactions across sessions.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "memory_comparison_summary": "Cited to highlight difficulties in leveraging shared history; motivates the need for robust memory architectures in neural dialogue systems.",
            "limitations_or_challenges": "Authors report challenges in exploiting shared history with individuals and accommodating expected conversational coordination patterns.",
            "key_insights": "Practical challenges in conversational memory motivate careful memory design (filtering, retrieval relevance) as implemented in PLATO-LTM.",
            "uuid": "e4803.4",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Episodic conversational memory (Elvir et al., 2017)",
            "name_full": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "brief_description": "A unified episodic memory architecture for embodied conversational agents that determines prevalent contexts from interactions and stores them for later use.",
            "citation_title": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "mention_or_use": "mention",
            "agent_name": "Elvir et al. (2017) episodic memory agent",
            "agent_description": "Proposes a unified episodic memory architecture for conversational agents to identify prevalent contexts in dialogues and store them for future retrieval.",
            "memory_type": "episodic memory architecture",
            "memory_description": "Extracts and stores salient context/facts from interactions to support later dialogue behavior and revisiting shared history.",
            "task_name": "Conversational memory support for embodied agents",
            "task_description": "Maintain and reuse salient context from interactions to support coherent future dialogues.",
            "benchmark_name": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "memory_comparison_summary": "Referenced as antecedent work on episodic memory in dialogue; influences design choice to store explicit persona facts in PLATO-LTM.",
            "limitations_or_challenges": "Prior work highlights engineering challenges in detecting and managing relevant episodic items.",
            "key_insights": "Episodic memory concepts (detect/store/retrieve salient items) are applicable to persona LTM design.",
            "uuid": "e4803.5",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "MSC / Xu et al. (2021)",
            "name_full": "Multi-Session Chat (MSC) dataset and retrieval-augmented dialogue approach",
            "brief_description": "An English multi-session extension of PersonaChat (MSC) that annotates session summaries and uses summarized prior conversations as memory documents for retrieval-augmented generation; shows pretrained generative models struggle on long-term conversation without such data.",
            "citation_title": "Beyond goldfish memory: Long-term open-domain conversation",
            "mention_or_use": "mention",
            "agent_name": "MSC / Xu et al. (2021) retrieval-augmented models",
            "agent_description": "Dataset and retrieval-augmented generative approach that summarizes and recalls previous conversations as retrieval documents for future generation; highlights that storing ever-growing documents without dynamic modification may be problematic.",
            "memory_type": "retrieval-augmented memory (document-level summaries)",
            "memory_description": "Stores summaries/documents of prior sessions and retrieves them during generation; stored documents are not dynamically modified and may grow unbounded with sessions.",
            "task_name": "Long-term open-domain conversation (multi-session)",
            "task_description": "Multi-session conversational setting requiring summarization and retrieval of past interactions to inform future dialogue turns.",
            "benchmark_name": "MSC",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "memory_comparison_summary": "Cited as a recent approach to long-term memory in dialogue; authors contrast PLATO-LTM design (real-time extraction and dynamic update of persona memory) with MSC's static summary documents that grow over time and require long-session data.",
            "limitations_or_challenges": "MSC stored documents expand indefinitely and are not dynamically modified; retrieval-augmented methods may rely on long-session datasets for training, which are costly.",
            "key_insights": "Dynamic, real-time persona extraction and memory updating (as in PLATO-LTM) can mitigate needs for long-session annotated data and unbounded document growth.",
            "uuid": "e4803.6",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Beyond goldfish memory: Long-term open-domain conversation",
            "rating": 2
        },
        {
            "paper_title": "Challenges in exploiting conversational memory in human-agent interaction",
            "rating": 2
        },
        {
            "paper_title": "Example-based chatoriented dialogue system with personalized longterm memory",
            "rating": 2
        },
        {
            "paper_title": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "rating": 2
        },
        {
            "paper_title": "Acquisition and use of long-term memory for personalized dialog systems",
            "rating": 2
        }
    ],
    "cost": 0.01449825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Long Time No See! Open-Domain Conversation with Long-Term Persona Memory</h1>
<p>Xinchao $\mathbf{X u}^{1 <em>}$, Zhibin Gou ${ }^{1,2 </em>}$, Wenquan $\mathbf{W u}^{1}$, Zheng-Yu Niu ${ }^{1}$, Hua Wu ${ }^{1}$, Haifeng Wang ${ }^{1}$ and Shihang Wang ${ }^{3}$<br>${ }^{1}$ Baidu Inc., China<br>${ }^{2}$ School of Computer Science, Beijing University of Posts and Telecommunications<br>${ }^{3}$ Columbia University<br>{xinchaoxu, wuwenquan01,niuzhengyu, wu_hua,wanghaifeng}@baidu.com zebgou@gmail.com, sw3275@columbia.edu</p>
<h4>Abstract</h4>
<p>Most of the open-domain dialogue models tend to perform poorly in the setting of long-term human-bot conversations. The possible reason is that they lack the capability of understanding and memorizing long-term dialogue history information. To address this issue, we present a novel task of Long-term Memory Conversation (LeMon) and then build a new dialogue dataset DuLeMon and a dialogue generation framework PLATO-LTM with a Long-Term Memory (LTM) mechanism. This LTM mechanism enables our system to accurately extract and continuously update long-term persona memory without requiring multiple-session dialogue datasets for model training. To our knowledge, this is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot. Results on DuLeMon indicate that PLATO-LTM can significantly outperform baselines in terms of long-term dialogue consistency, leading to better dialogue engagingness ${ }^{1}$.</p>
<h2>1 Introduction</h2>
<p>Persona is crucial for open-domain dialogue systems to establish long-term intimacy with users (Huang et al., 2020). Existing persona dialogue datasets such as PersonaChat (Zhang et al., 2018; Dinan et al., 2019) and models (Li et al., 2016a; Zhang et al., 2017; Qian et al., 2018) have greatly facilitated the chatbot with configurable and persistent personalities.</p>
<p>Nevertheless, current open-domain dialogue systems still cannot build a long-term connection with humans. The possible reason is that they lack the capability of understanding and memorizing longterm dialogue history information, which we called</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A sample of long-term conversation with memory. At first, the chat partner is not familiar with each other, so the goal is to get to know each other; Then, after multiple sessions, the chatbot already has a certain understanding and memory of the user's persona and its own persona, making the deep chat possible.
long-term persona ability. Remembering and actively utilizing the user's persona increases engagingness and contributes to long-term friendships between chatbot and user (Campos et al., 2018). Without this ability, the current state-of-the-art models, such as Meena (Adiwardana et al., 2020), Blender (Roller et al., 2021), and PLATO (Bao et al., 2020), tend to talk to people like strangers in long-term conversations.</p>
<p>Despite the importance and challenge of utilizing long-term persona in open-domain dialogue, as far as we know, the long-term persona ability of large-scale models is less studied due to a lack of both task design and corresponding dataset. Previous long-term persona dialogue systems (Kim et al., 2014; Bang et al., 2015) are mainly rule-based systems without large-scale pre-training models, in which researchers proposed various episodic memory architectures to extract, store and manage rel-</p>
<p>evant facts in prior interactions for use in future dialogs (Campos et al., 2018).</p>
<p>In addition, existing persona conversation datasets (Zhang et al., 2018; Dinan et al., 2019; Zheng et al., 2019) focus only on the consistency of the chatbot's own persona and ignore the memory and utilization of the user's persona. And they all set fixed persona that cannot be updated during the chat. Recently, Xu et al. (2021) proposed MSC dataset as a multi-session extension of PersonaChat, and its sessions are additionally annotated with summaries of important personal points. Similar to the previous episodic memory architecture, Xu et al. (2021) summarize and recall previous conversations for future dialogue generation. The stored documents in MSC will not be dynamically modified and will increase infinitely as the conversation progresses. Furthermore, the retrieval-augmented generative models rely on a long-session conversation dataset for training, which is expensive and difficult to annotate.</p>
<p>To address the limitations of existing models and the above issues, we defines the LeMon (Longterm Memory Conversation) task and propose a new dataset named DuLeMon, which focuses not only on the consistency of the bot's own persona but also on the active construction and utilization of the user's persona in a long-term interaction (ie. mutual persona). We demonstrate an example dialogue in DuLeMon in Figure 1. In DuLeMon, we assume that the two speakers have previously interacted with each other and that the chatbot remembers part of the user's persona. Besides, both the user and chatbot grounding persona are annotated in each utterance.</p>
<p>Based on our collected dataset, we carefully design a novel PLATO-LTM framework for the longterm persona dialogue setting by adding a plug-andplay long-term memory (LTM) to the state-of-theart open-domain dialogue model (Bao et al., 2020). It enables us to study long-term persona conversations without relying on the long-session dataset. PLATO-LTM can extract both parties' persona information from the conversation in real time, write it to persona memory respectively, and retrieve both parties' persona information from memory to generate responses. The PLATO-LTM framework consists of three modules: (1) Persona Extractor (PE): The memory is updated by filtering irrelevant information and extracting persona sentences through a classifier. (2) Long-Term Memory (LTM): Two
separated long-term memories store the explicit persona information of interlocutors. (3) Generation Module: We use the large-scale model and the retrieved persona sentences of the user and chatbot are directly concatenated with dialogue context as model input.</p>
<p>Our major contributions are as follows:
(1) We firstly propose the long-term persona chat task LeMon for Chinese long-term conversations. Our proposed DuLeMon dataset is also the largest multi-turn Chinese mutual persona chat dataset currently available.
(2) We proposed a PLATO-LTM framework that extracts and remembers both user's and the chatbot's persona in real time, enabling the chatbot to have long-term persona dialogue without training on long-session data.
(3) Automatic and human evaluation show that our method significantly improves the consistency of the state-of-the-art in long conversations, making the response more engaging while ensuring coherency.</p>
<h2>2 Related Work</h2>
<p>Persona Dialogue: As described in Huang et al. (2020), there is much work related to persona dialogue. Generally speaking, these works can be divided into implicit persona models and explicit persona models. In the implicit model, the persona is represented in the form of the semantic persona vector. Kim et al. (2014) proposed a retrieval-based method to integrate persona and user interests into the dialogue system. Because these models are implicit methods, they are not easy to interpret and control in target response generation. In Qian et al. (2018), an explicit persona model is proposed to generate consistent responses for given persona information. The persona information of the machine includes name, gender, hobbies, and so on. In this way, the given persona information can be better used for model generation. There are also many persona chat datasets that have been constructed to develop models, as shown in Table 1. In particular, the introduction of the PersonaChat (Zhang et al., 2018; Dinan et al., 2019) dataset has extensively promoted the development of this field where the crowd-workers are simply asked to "chat with the other person naturally and try to get to know each other." However, the user's persona was unknown</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">Persona</th>
<th style="text-align: left;">Mutual</th>
<th style="text-align: left;"># Dialogues</th>
<th style="text-align: left;">Language</th>
<th style="text-align: left;">Multi-turn</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PersonaChat (Zhang et al., 2018)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">10,907</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PersonaIDialog (Zheng et al., 2019)</td>
<td style="text-align: left;">Structure</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">$20,830,000$</td>
<td style="text-align: left;">Chinese</td>
<td style="text-align: left;">part</td>
</tr>
<tr>
<td style="text-align: left;">XPersona (Lin et al., 2020)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">16,878</td>
<td style="text-align: left;">Multilingual</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PEC (Zhong et al., 2020)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">355,000</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PCR (Mazaré et al., 2018)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">$700,000,000$</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">MSC (Xu et al., 2021)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">5,001</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">DuLeMon (Ours)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">27,501</td>
<td style="text-align: left;">Chinese</td>
<td style="text-align: left;">Yes</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of our dataset DuLeMon with other datasets.
to the bot, so the dialogue was like strangers exchanging information. In contrast, our proposed DuLeMon dataset requires the chatbot to actively remember and use the user's persona to improve conversational engagements and increase the intimacy between interlocutors in long-term interactions.
Dialogue Model with External Memory: As described in Lim (2012), there are various memory models used by the rule-based dialogue systems. In Bang et al. (2015), user-related information is memorized and used to rewrite the response. In Elvir et al. (2017), a unified episodic memory architecture for Embodied Conversational Agents (ECAs) is proposed. They describe a process that determines the prevalent contexts in the conversations obtained from the interactions. In Campos et al. (2018), the authors introduce an agent that uses its conversational memory to revisit shared history with users to maintain a coherent social relationship over time. However, they find it challenging to leverage the shared history with individual users and hard to accommodate expected conversational coordination patterns. Apart from studies in rulebased dialogue systems mentioned above, Xu et al. (2021) shows how large-scale pre-training generative dialogue models trained on existing datasets perform poorly in the long-term conversation setting and proposes a new extended English conversation dataset, entitled Multi-Session Chat (MSC). Different from them, our novel dataset DuLeMon does not rely on long sessions with high collection costs to study long-term memory problems in the persona chat, with significant differences in task design and data collection.</p>
<h2>3 Data Collection</h2>
<p>Task Definition. Given dialogue context $c=$ $\left{u_{1}, s_{1}, u_{2}, s_{2}, \ldots, u_{t-1}, s_{t-1}, u_{t}\right}$, where $u$ and $s$ represent the user and the chatbot respectively. Each speaker has its corresponding persona descrip-
tion that consists of a set of sentences, we define the user persona as $\rho^{u}=\left{\rho_{1}^{u}, \rho_{2}^{u}, \ldots, \rho_{m}^{u}\right}$, and the chatbot persona as $\rho^{s}=\left{\rho_{1}^{s}, \rho_{2}^{s}, \ldots, \rho_{n}^{s}\right}$. Given the dialogue context $c$, user persona $\rho^{u}$ and chatbot persona $\rho^{s}$, we are interested in finding the corresponding persona and predicting the chatbot response $s_{t}$.</p>
<p>To support our task, we collect and release a new dataset, entitled DuLeMon. In DuLeMon, the chatbot actively remembers and reasonably uses what the user has said about their persona while maintaining consistency in its persona, allowing the conversation to proceed more deeply. In a nutshell, our DuLeMon dataset has two essential features: During the conversation, the chatbot can see the persona of both parties; the other is that the persona associated with the response is explicitly annotated in our dataset. Unlike the PersonaChat dataset, the setting in DuLeMon is that one speaker plays the role of a chatbot, and the other plays the user's role. We elaborate on the construction process of the dataset as the following.
(1) Persona collection: The persona is mainly from the translation and rewriting of persona in PersonaChat. The chatbot's persona is only visible to itself, and the chatbot can use its persona information to chat with the user, as shown in Figure 2. The user's persona contains two parts: persona that the chatbot already knows and persona that the chatbot does not know. The first part is the user's persona that the chatbot has learned through historical conversations. This part is randomly selected from multiple personas of each user. The chatbot needs to use this information to guide the conversation during the chat process. It should be noted that in order to simulate the situation at the beginning of the chat, this part may be empty.
(2) Dialogue collection: For each dialogue, two crowd-workers (one plays the chatbot, the other plays the user) are randomly paired and given random persona. They are required to organize a di-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Example of our proposed DuLeMon dataset with both chatbot's and user's persona. It has two important features: one is that during the conversation, the chatbot can see the persona of both parties; the other is that the persona information associated with the response is explicitly labeled in our dataset which is shown as the $\rho^{a}$ and $\rho^{a}$ in the figure.
alogue based on the given persona. The chatbot should think more about chatting to make it go on. It should utilize the known user's persona to conduct the in-depth chat. The user will act as an ordinary user to cooperate with the conversation. The content of the chat can be selected from the given persona. It must not be irrelevant for the given information, nor can it conflict with the given persona.
(3) Persona Grounding Labeling: This part annotates whether the current response uses the given persona information and whether the current sentence is a persona sentence. For each utterance, we first let the annotators label whether it uses persona or not. Furthermore, the annotator should label the grounding persona (from chatbot or user) being used in the response. Therefore, through this process, the direct relationship between the response and the persona can be given. Then, for sentences that use the persona, we further annotate whether the utterance is a persona sentence or not.</p>
<p>To scale the amount of data, we also collected conversations where the user's persona was not visible to the bot, following the PersonaChat (Zhang et al., 2018). Finally, our DuLeMon dataset consists of two parts. In DeLeMon-SELF, the bot only knows its own persona, while in DuLeMonBOTH, it also knows part of the user's persona (as described above). The overall statistics of the DuLeMon are shown in Table 2.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Category</th>
<th style="text-align: left;">SELF</th>
<th style="text-align: left;">BOTH</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># Dialogues</td>
<td style="text-align: left;">24500</td>
<td style="text-align: left;">3001</td>
</tr>
<tr>
<td style="text-align: left;"># Utterances</td>
<td style="text-align: left;">400472</td>
<td style="text-align: left;">48522</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # turns</td>
<td style="text-align: left;">16.3</td>
<td style="text-align: left;">16.2</td>
</tr>
<tr>
<td style="text-align: left;">Avg. length of utterances</td>
<td style="text-align: left;">19.7</td>
<td style="text-align: left;">21.2</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # bot persona</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">4.0</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # user persona (seen)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">4.4</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # user persona (unseen)</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">1.3</td>
</tr>
</tbody>
</table>
<p>Table 2: Statistics of DuLeMon.</p>
<h2>4 Model Architecture</h2>
<p>In this work, we propose a long-term memory dialogue system based on an explicit memory readwrite mechanism. It includes three parts: persona extractor, long-term persona memory, and generation module. Through the read and write operations of the long-term memory module, the user's and chatbot's persona can be stored, updated, and read. The overall framework is shown in Figure3.</p>
<h3>4.1 Persona Extractor</h3>
<p>Given an utterance or text span as input, our persona extractor can assign each input a label to indicate if it contains persona information. Here we train an ERNIE-CNN network architecture in a supervised way on an annotated persona-utterance dataset as this persona extractor. Specifically, the ERNIE-CNN network employs a pre-trained ERNIE $^{2}$ (Sun et al., 2019) network for sentence representation, and another CNN model (Kim, 2014)</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Illustration of our system PLATO-LTM. (a) shows the dialogue flow. (b) describes the modules and pipeline of our system. It consists of a persona extractor (PE), a long-term persona memory, a retriever, and a generator. (1) The long-term memory contains both user persona and chatbot persona extracted from the dialogue history by PE. (2) The retriever uses context as query to retrieve related personas in memory (3) concatenates the retrieved text to the context and use the generator to produce the generated response. (c) details our generator PLATO-2 and ranker CPM (Context Persona Matching).
for classification.
Training procedure. First, we collect the firstversion training dataset, in which there are 6 k utterances (from the DuLeMon corpus and Chinese social forum corpus) being human-annotated with positive or negative class labels. Second, using the aforementioned dataset, we train five ERNIE-CNN network (with different pre-training parameter versions) based models (called pc-stage1). Third, we employ these five models to automatically annotate 1.4 million utterances with labels, where these utterances are collected from the DuLeMon and the online Chinese social forum. We then refine this augmented dataset as the final-version dataset with the following steps: (a) Given an utterance, if there are at least two of the above five models identifying it as a positive sample, then it is attached with a positive label, (b) otherwise it is attached with a negative label. Finally, we train the five models on the final-version dataset and select the one with the best performance as our persona extractor (named pc-stage2).</p>
<p>Inference procedure. First, given an utterance, we segment it into clauses with the use of punctuation marks. Second, we use the persona extractor
mentioned above to classify each clause with a label and then collect the clause with a positive label as persona sentences.</p>
<h3>4.2 Long-Term Memory</h3>
<p>The long-term memory (LTM) module maintains memories to store the historical persona information from the user and the chatbot, respectively. The most critical operations are reading and writing based on the context persona matching (CPM) model. We use context encoder $E_{c}(\cdot)$ to encode the current context $c$, and use persona encoder $E_{\rho}(\cdot)$ to encode the persona $\rho_{i} . E(\cdot)$ is the encoder's output on the first input token ([CLS]), corresponding to the input's pooled representation.</p>
<p>The encoder $E_{c}$ and $E_{\rho}$ is initialized with the ERNIE model and then trained on our DuLeMon corpus. For each training sample, we define the positive persona as the persona used in the current user's utterance and the bot's response (including bot persona and user persona seen by bot), and the negative persona as the remaining persona of the current session. Given context $c$, a positive persona $\rho^{+}$, and a negative persona $\rho^{-}$, we use triplet loss</p>
<p>to tune the network as:</p>
<p>$$
\max \left(\operatorname{sim}\left(c, \rho^{+}\right)-\operatorname{sim}\left(c, \rho^{-}\right)+\alpha, 0\right)
$$</p>
<p>We set the margin $\alpha=0.2$ in our experiments. Below we describe the specific read and write process of the long-term memory module.</p>
<p>Write: We use the PE module to identify the persona in the dialogue history as the candidate information to be written. It needs to eliminate duplicates before writing. Specifically, calculate the cosine similarity with the persona in memory to get the most approximate persona $\rho_{j}$. When the similarity between $\rho_{i}$ and $\rho_{j}$ exceeds the given duplication threshold $s_{\text {dup }}$, replace $\rho_{j}$ in memory with $\rho_{i}$; otherwise, write $\rho_{i}$ directly into the memory. When writing to memory, save $\left{\rho_{i}, E_{\rho}\left(\rho_{i}\right)\right}$ pair for the subsequent reading. We measure the distance with the cosine similarity as:</p>
<p>$$
\operatorname{sim}\left(\rho_{i}, \rho_{j}\right)=\cos \left(E_{\rho}\left(\rho_{i}\right), E_{\rho}\left(\rho_{j}\right)\right)
$$</p>
<p>Read: The reading process can be regarded as the retrieval process from memory. First, we use the efficient similarity search of dense vectors to select candidates. Then a matching model is utilized to score the relevance of the candidates to the current context. The similarity between the context and the persona using cosine similarity:</p>
<p>$$
\operatorname{sim}\left(c, \rho_{i}\right)=\cos \left(E_{c}(c), E_{\rho}\left(\rho_{i}\right)\right)
$$</p>
<p>The top $k$ persona candidates $\rho^{u}$ in the user memory and top $k$ candidates $\rho^{s}$ in the chatbot memory are used for response generation. To model persona sparsity in dialogue, we filter out the persona, whose similarity score is lower than the similarity threshold $s_{c}$.</p>
<h3>4.3 Generation Module</h3>
<p>We trained our model on the basis of the PLATO2 (Bao et al., 2020) architecture which adopts the generic transformer language model (Vaswani et al., 2017) and leverages a stack of masked multi-head self-attention layers to train on massive dialogue data ${ }^{3}$.</p>
<p>Given the conversation context $c=$ $\left{u_{1}, s_{1}, u_{2}, s_{2}, \ldots, u_{t-1}, s_{t-1}, u_{t}\right}$, the corresponding user persona $\rho^{u}$ and chatbot persona $\rho^{s}$, the ground truth response as</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>$r=\left{x_{m+1}, x_{m+2}, \ldots, x_{N}\right}$, the conditional probability of $p\left(r \mid c, \rho^{u}, \rho^{s}\right)$ can be written as the product of a series of conditional probabilities:</p>
<p>$$
p\left(r \mid c, \rho^{u}, \rho^{s}\right)=\prod_{t}^{N} p\left(r_{t} \mid c, \rho^{u}, \rho^{s}, r_{&lt;t}\right)
$$</p>
<p>Therefore, we need to minimize the following negative log-likelihood (NLL) loss:</p>
<p>$$
\begin{aligned}
\mathcal{L}<em t="1">{N L L} &amp; =-\mathbb{E} \log p\left(r \mid c, \rho^{u}, \rho^{s}\right) \
&amp; =-\mathbb{E} \sum</em>\right)
\end{aligned}
$$}^{T} \log p\left(r_{t} \mid c, \rho^{u}, \rho^{s}, r_{&lt;t</p>
<p>where $T$ is the length of the target response $r$ and $r_{&lt;t}$ denotes previously generated words. Since the response generation is a uni-directional decoding process, each token in the response only attends to those before it. As for the context, bi-directional attention is enabled for better natural language understanding.</p>
<p>We added two strategies to distinguish different roles in the dialogue and prevent the confusing use of persona information.</p>
<ul>
<li>Role Embedding (Bao et al., 2021): different role embedding is used to distinguish the persona of different chat parties, abbreviated role_embed.</li>
<li>Role Token: splicing "system persona" before the chatbot persona and "user persona" before the user persona, abbreviated role_token.</li>
</ul>
<h2>5 Experiments</h2>
<p>In this section, we present the baselines, experiment settings, model comparisons, and results of experiments.</p>
<h3>5.1 Compared Methods</h3>
<p>As baselines, we select state-of-the-art methods to compare with our method.</p>
<ul>
<li>PLATO-2 (Bao et al., 2020): The SOTA opendomain dialogue model.</li>
<li>PLATO-FT: The PLATO-2 model fine-tuned on our proposed DuLeMon dataset.</li>
<li>
<p>PLATO-LTM: The PLATO-FT model with our proposed long-term memory (LTM).</p>
</li>
<li>
<p>PLATO-LTM w/o PE: PLATO-LTM without the persona extractor (PE) module, which stores all history utterances (user and bot separately) into memory without persona extraction.</p>
</li>
</ul>
<h3>5.2 Experiment Settings</h3>
<p>Automatic Evaluation Metrics. We use Precision, Recall and F1 to evaluate the persona classification model. For the long-term memory module, we use the AUC and recall@k to evaluate the ranking model. We evaluate responses generated by the models using PPL, BLEU (Papineni et al., 2002), and F1 with reference to the human-annotated responses and DISTINCT-1/2 (Zhao et al., 2017). More recently, Adiwardana et al. (2020) has shown the correlation between perplexity and human judgment in open-domain chit-chat models.
Human Evaluation Metrics. In human evaluation, we employ three utterance-level metrics, including coherence, consistency, engagingness. Three crowd-sourcing workers are asked to score the response/dialogue quality on a scale of $[0,1,2]$. The higher score, the better. These criteria are discussed as follows:</p>
<ul>
<li>Coherence: an utterance-level metric, measuring whether the response is relevant and consistent with the context.</li>
<li>Consistency: an utterance-level metric, evaluating whether the response is consistent with the persona in the dialogue history.</li>
<li>Engagingness: an utterance-level metric, assessing whether the annotator would like to talk with the speaker for each response in the long-term conversation.</li>
</ul>
<h3>5.3 Results</h3>
<p>In this part, we first analyze the effects of each module and then analyze the results of the manual evaluation of our entire system, PLATO-LTM.</p>
<h3>5.3.1 Results of Persona Extractor</h3>
<p>We measure the performance of the persona extractor. To measure the performance of different models, we manually annotated the test set (the number of test sets is 200). We select the best of the first and second stages. The result is shown in Table 3. The pc-stage2 model is better than that of the pc-stage1 model. The F1 of the model exceeds</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">ACC</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">pc-stage1</td>
<td style="text-align: left;">0.91</td>
<td style="text-align: left;">0.96</td>
<td style="text-align: left;">0.84</td>
<td style="text-align: left;">0.90</td>
</tr>
<tr>
<td style="text-align: left;">pc-stage2</td>
<td style="text-align: left;">0.92</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;">0.87</td>
<td style="text-align: left;">0.91</td>
</tr>
</tbody>
</table>
<p>Table 3: Comparison of two-stage models of our persona classifier.
0.9 , which shows that our model can effectively recognize the persona information from the dialogue history and ensure that the persona information can be correctly stored in the long-term memory. Therefore, the pc-stage2 model is adopted in our system to recognize the persona in the dialogue history.</p>
<h3>5.3.2 Selection of Generative Models</h3>
<p>The generative model utilizes the current context and persona information retrieved from long-term memory to generate the response. We first evaluate the effect of the CPM model on retrieval persona information. The AUC on the automatic test set is 0.76 , recall@ 5 is 0.83 , which shows that our model can efficiently retrieve relevant persona from the long-term memory.</p>
<p>The effect of the generative model reflects the model's ability to use the content of long-term memory to generate the response. Therefore, we select the best generative model to utilize better the retrieved persona information to generate. The result is shown in Table 4. We use the 12L model to conduct experiments to compare different models. The experiment results show that PLATO-FT + role_embed + role_token is the best. Compared to PLATO-FT, the PPL can decrease to 13.377, showing that both strategies are effective. In order to further improve the model, we increased the model size and further trained with the 32L model. Experiment results have shown that the PPL of the 32L model is lower than the 12L model by 4.4 and F1 increased by 2.5 , which can further improve the generative model. Therefore, PLATO-FT 32L + role_embed + role_token model is adopted in our system.</p>
<h3>5.3.3 Human Evaluation</h3>
<p>Self-chat has been widely used in the evaluation of dialogue systems (Li et al., 2016b; Roller et al., 2021; Bao et al., 2020), where the model plays the roles of both parties in the dialogue. To better control variables, we use our proposed PLATOLTM as a user simulator in our experiments and ask all chatbots (including PLATO-LTM) to chat sepa-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">PPL</th>
<th style="text-align: center;">BLUE-1/2</th>
<th style="text-align: center;">DISTINT-1/2</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PLATO-FT 12L</td>
<td style="text-align: center;">13.641</td>
<td style="text-align: center;">$0.190 / 0.081$</td>
<td style="text-align: center;">$0.061 / 0.277$</td>
<td style="text-align: center;">21.02</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_embed</td>
<td style="text-align: center;">13.387</td>
<td style="text-align: center;">$0.180 / 0.080$</td>
<td style="text-align: center;">$0.062 / 0.274$</td>
<td style="text-align: center;">20.98</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_token</td>
<td style="text-align: center;">13.553</td>
<td style="text-align: center;">$0.193 / 0.081$</td>
<td style="text-align: center;">$0.060 / 0.272$</td>
<td style="text-align: center;">21.28</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_embed + role_token</td>
<td style="text-align: center;">$\mathbf{1 3 . 3 7 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 1 9 4 / 0 . 0 8 1}$</td>
<td style="text-align: center;">$0.060 / 0.267$</td>
<td style="text-align: center;">$\mathbf{2 1 . 5 9}$</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 32L + role_embed + role_token</td>
<td style="text-align: center;">9.380</td>
<td style="text-align: center;">$0.194 / 0.087$</td>
<td style="text-align: center;">$0.068 / 0.296$</td>
<td style="text-align: center;">22.61</td>
</tr>
</tbody>
</table>
<p>Table 4: Comparison of automatic evaluation metric results among different generative models.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Coherence</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Engagingness</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PLATO-2</td>
<td style="text-align: center;">$\mathbf{1 . 7 0}$</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">1.46</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">1.40</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-LTM</td>
<td style="text-align: center;">1.67</td>
<td style="text-align: center;">$\mathbf{0 . 8 7}$</td>
<td style="text-align: center;">$\mathbf{1 . 5 4}$</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-LTM w/o PE</td>
<td style="text-align: center;">1.57</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">1.43</td>
</tr>
</tbody>
</table>
<p>Table 5: Comparison of human evaluation metric results on self-chat dialogues among our model and baselines. All the above generation models are 32L. The PLATO-FT is with role embedding and role token strategies.
rately with the user simulator. After that, the crowdsourcing workers evaluate only the responses generated by the chatbots other than the simulator. The details are as follows.</p>
<p>Each chatbot chats with the user simulator for 10 episodes, each containing 4 long sessions, and each session contains 16 rounds. As in Bao et al. (2020), we do not impose any restrictions on the chats except for specifying session openings. We pre-select some session openings from the DuLeMon test set, start the interactive conversation with these openings, and ask the two bots to perform chats given the context.</p>
<p>The results are shown in Table 5, from which we can get the following key results:
(1) The long-Term Memory mechanism can significantly improve dialogue consistency. As shown in Table 5, in terms of dialogue consistency, our two models, PLATO-LTM and PLATO-FT, can achieve scores of 0.87 and 0.40 , respectively, which is significantly better than the baseline model PLATO-2. Furthermore, when we compare the performance of PLATO-LTM with PLATO-FT, it can be seen that the use of Long-Term Memory and persona extractor can boost the performance of PLATO-FT with a relative improvement of $118 \%$. Moreover, the model of PLATO-LTM w/o PE can achieve a score of 0.49 , which is still better than the PLATO-FT model. It indicates that long-term memory without a persona extractor is still effective in improving persona consistency.
(2) With the long-term memory mechanism, the use of persona extractor can significantly improve persona consistency and dialogue engagingness. As shown in Table 5, in terms of dia-
logue consistency, the two models, PLATO-LTM (using PE) and PLATO-LTM w/o PE, can achieve scores of 0.87 and 0.49 respectively, indicating that the use of persona extractor can significantly improve dialogue consistency. In terms of dialogue engagingness, PLATO-LTM can obtain a score of 1.54, outperforming the baseline model PLATO-2. In addition, when we remove PE from PLATOLTM, its performance drops from 1.54 (the score of PLATO-LTM) to 1.43 (that of PLATO-LTM w/o PE), indicating that the use of persona extractor can improve the performance of PLATO-FT.
(3) Fine-tuning on the small-scale dataset will slightly hurt the performance of pre-trained dialogue models in dialogue coherence. In terms of dialogue coherence, the PLATO-FT model (finetuned on our dataset) achieve a score of 1.59 , which is lower than that of the baseline model PLATO (not finetuned on our dataset). The possible reason is that during the self-play procedure for system evaluation, their dialogs usually cover a wide range of topics, and then it is challenging to generate appropriate or coherent responses when given these open-domain topics in contexts. The finetuning procedure might hurt the capability of the pre-trained dialogue model in terms of response appropriateness or dialogue coherence, leading to the inferior performance of PLATO-LTM and its variants.</p>
<h2>6 Conclusion</h2>
<p>In this paper, We present a novel LeMon (Longterm Memory Conversation) task and then build the corresponding dataset DuLeMon, introducing longterm persona modelling into large-scale generative</p>
<p>dialogue models. We further propose a Long-Term Memory (LTM) as a plug-in component of state-of-the-art large-scale generative dialogue models. LTM consists of user memory and chatbot memory, where the user memory is for understanding and memorizing persona information mentioned by the user, and the chatbot memory attempts to keep its persona information to be continuously updated over time. Experiment results show that our system PLATO-LTM can make effective use of both parties' persona information from dialogue history to enhance dialogue consistency and engagingness when conducting a long-term conversation. In the future, we will further study the possibility of using reinforcement learning with human feedback signals to help long-term conversation.</p>
<h2>7 Ethical Considerations</h2>
<p>We are sure that DuLeMon has been collected in a manner that is consistent with the terms of use of any sources and the intellectual property and privacy rights of the original authors of the texts. Meanwhile, our project is approved by an IRB. Finally, we also provide details on the characteristics of DuLeMon and steps taken to ensure the potential problems with the quality of the dataset do not create additional risks.</p>
<h2>References</h2>
<p>Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V. Le. 2020. Towards a human-like opendomain chatbot. CoRR, abs/2001.09977.</p>
<p>Jeesoo Bang, Hyungjong Noh, Yonghee Kim, and Gary Geunbae Lee. 2015. Example-based chatoriented dialogue system with personalized longterm memory. In 2015 International Conference on Big Data and Smart Computing (BIGCOMP), pages 238-243.</p>
<p>Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang, Wenquan Wu, Zhen Guo, Zhibin Liu, and Xinchao Xu. 2020. PLATO-2: towards building an open-domain chatbot via curriculum learning. CoRR, abs/2006.16779.</p>
<p>Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang, Wenquan Wu, Zhihua Wu, Zhen Guo, Hua Lu, Xinxian Huang, Xin Tian, Xinchao Xu, Yingzhan Lin, and Zhengyu Niu. 2021. Plato-xl: Exploring the large-scale pre-training of dialogue generation.</p>
<p>Joana Campos, James Kennedy, and Jill F. Lehman. 2018. Challenges in exploiting conversational memory in human-agent interaction. In Proceedings of
the 17th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS '18, page 1649-1657, Richland, SC. International Foundation for Autonomous Agents and Multiagent Systems.</p>
<p>Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander H. Miller, Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan Lowe, Shrimai Prabhumoye, Alan W. Black, Alexander I. Rudnicky, Jason Williams, Joelle Pineau, Mikhail S. Burtsev, and Jason Weston. 2019. The second conversational intelligence challenge (convai2). CoRR, abs/1902.00098.</p>
<p>Miguel Elvir, Avelino J. Gonzalez, Christopher Walls, and Bryan Wilder. 2017. Remembering a conversation - a conversational memory architecture for embodied conversational agents. Journal of Intelligent Systems, 26(1):1-21.</p>
<p>Minlie Huang, Xiaoyan Zhu, and Jianfeng Gao. 2020. Challenges in building intelligent open-domain dialog systems. ACM Trans. Inf. Syst., 38(3).</p>
<p>Yonghee Kim, Jeesoo Bang, Junhwi Choi, Seonghan Ryu, Sangjun Koo, and Gary Geunbae Lee. 2014. Acquisition and use of long-term memory for personalized dialog systems. In Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction - Second International Workshop, MA3HMI 2014, Held in Conjunction with INTERSPEECH 2014, Singapore, Singapore, September 14, 2014, Revised Selected Papers, volume 8757 of Lecture Notes in Computer Science, pages 78-87. Springer.</p>
<p>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1746-1751. ACL.</p>
<p>Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.</p>
<p>Jiwei Li, Michel Galley, Chris Brockett, Georgios P. Spithourakis, Jianfeng Gao, and William B. Dolan. 2016a. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. The Association for Computer Linguistics.</p>
<p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. 2016b. Deep reinforcement learning for dialogue generation.</p>
<p>Mei Yii Lim. 2012. Memory Models for Intelligent Social Companions, pages 241-262. Springer Berlin Heidelberg, Berlin, Heidelberg.</p>
<p>Zhaojiang Lin, Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya, Andrea Madotto, Yejin Bang, Etsuko Ishii, and Pascale Fung. 2020. Xpersona: Evaluating multilingual personalized chatbot. CoRR, abs/2003.07568.</p>
<p>Pierre-Emmanuel Mazaré, Samuel Humeau, Martin Raison, and Antoine Bordes. 2018. Training millions of personalized dialogue agents. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775-2779, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pages 311-318. ACL.</p>
<p>Qiao Qian, Minlie Huang, Haizhou Zhao, Jingfang Xu , and Xiaoyan Zhu. 2018. Assigning personality/profile to a chatting machine for coherent conversation generation. In Proceedings of the TwentySeventh International Joint Conference on Artificial Intelligence, IJCAI-18, pages 4279-4285. International Joint Conferences on Artificial Intelligence Organization.</p>
<p>Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. 2021. Recipes for building an open-domain chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, Online, April 19 - 23, 2021, pages 300-325. Association for Computational Linguistics.</p>
<p>Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, and Haifeng Wang. 2019. Ernie 2.0: A continual pre-training framework for language understanding.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.</p>
<p>Jing Xu, Arthur Szlam, and Jason Weston. 2021. Beyond goldfish memory: Long-term open-domain conversation.</p>
<p>Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2204-2213, Melbourne, Australia. Association for Computational Linguistics.</p>
<p>Weinan Zhang, Ting Liu, Yifa Wang, and Qingfu Zhu. 2017. Neural personalized response generation as domain adaptation. CoRR, abs/1701.02073.</p>
<p>Tiancheng Zhao, Ran Zhao, and Maxine Eskénazi. 2017. Learning discourse-level diversity for neural dialog models using conditional variational autoencoders. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 654-664. Association for Computational Linguistics.</p>
<p>Yinhe Zheng, Guanyi Chen, Minlie Huang, Song Liu, and Xuan Zhu. 2019. Personalized dialogue generation with diversified traits. CoRR, abs/1901.09672.</p>
<p>Peixiang Zhong, Chen Zhang, Hao Wang, Yong Liu, and Chunyan Miao. 2020. Towards persona-based empathetic conversational models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6556-6566, Online. Association for Computational Linguistics.</p>
<h2>A Details of Data Collection</h2>
<p>The collection processes of DuLeMon are as follows.</p>
<ul>
<li>The crowdworkers enter the chat interface in pairs, and role 1 initiates a conversation;</li>
<li>The chat content can include opening greetings, self-introduction, chatting content that conforms to the persona information, asking the other party's questions, answering the other's questions, and so on. The information used in the chat must be consistent with the given personal information;</li>
<li>The dialogue contains at least 8 turns (each person speaks at least 8 utterances);</li>
</ul>
<p>At the same time, we also let the crowdworkers pay attention to the follows: 1 . Use as many words as possible, and do not repeat them. The overall dialogue strives to be natural, smooth, and not embarrassing. 2. Do not simply copy and paste the sentences in the personal information and express them as richly as possible. If it is found that $50 \%$ of the fragments of any given sentence appear in the conversation, it is a non-compliant conversation. 3. When using persona information, do not copy it entirely, and talk about relevant content around the persona. For example, if the persona setting contains the sentence "I am a painter", the response can be that "I have painted many beautiful paintings and held several exhibitions"; 4. If the question raised by the other speaker is not covered in the given personal information, the reply can be freely used; if there is any reference or related information in the given personal information, reply according it.</p>
<h1>B Details of Models</h1>
<p>Generation Model For the Generation model, We follow PLATO-2 (Bao et al., 2020). The maximum length of context, user persona, and chatbot persona are set to 384,76 , and 52 , respectively. The vocabulary contains 30 K Chinese BPE tokens. We optimize all models using Adam (Kingma and Ba, 2015) with every batch of $B=16384$ tokens and learning rate of $l r=5 e-5$. We conduct all experiments on NVIDIA V100 32GB and A100 48GB GPUs.
Long-term Memory For both user memory and chatbot memory, we set duplication threshold $s_{\text {dup }}=0.95$, number of candidates $K=5$, and similarity threshold $s_{c}=0.7$. Due to the persona sparsity of dialogue and the efficiency of our persona storage, we do not limit the memory capacity.</p>
<h2>C Cases of PLATO-LTM</h2>
<p>To concretely demonstrate the long-term persona ability in a long-term conversation, we further provide a cherry-picked example of one episode conversation (between PLATO-LTM and PLATO-2) in Figure 4.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: A cherry-picked example of one episode conversation between PLATO-LTM and PLATO-2.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ There are two stages within the PLATO-2 model, the first stage conduct candidate responses generation and the second stage conduct responses selection. We only implement our work on the first stage of PLATO-2.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>