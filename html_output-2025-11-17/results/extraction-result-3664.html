<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3664 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3664</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3664</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-91.html">extraction-schema-91</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-266999123</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.07534v1.pdf" target="_blank">Exploring the Potential of Large Language Models in Self-adaptive Systems</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs), with their abilities in knowledge acquisition and reasoning, can potentially enhance the various aspects of Self-adaptive Systems (SAS). Yet, the potential of LLMs in SAS remains largely unexplored and ambiguous, due to the lack of literature from flagship conferences or journals in the field, such as SEAMS and TAAS. The interdisciplinary nature of SAS suggests that drawing and integrating ideas from related fields, such as software engineering and autonomous agents, could unveil innovative research directions for LLMs within SAS. To this end, this paper reports the results of a literature review of studies in relevant fields, summarizes and classifies the studies relevant to SAS, and outlines their potential to specific aspects of SAS.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3664.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3664.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DomainKnowledgeDistill (Tang et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An empirical study (cited in this survey) that, by its title, investigates distilling domain knowledge from large language models for the autonomous driving domain; the survey references it as an example of domain knowledge distillation using LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Domain Knowledge Distillation from LLM</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>Not described in detail in this survey; referenced as an empirical study on distilling domain knowledge from LLM(s) for autonomous driving. The survey does not provide method-level specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of Large Language Models in Self-adaptive Systems', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain <em>(Rating: 2)</em></li>
                <li>Large Language Models Based Automatic Synthesis of Software Specifications <em>(Rating: 1)</em></li>
                <li>Large Language Models for Software Engineering: Survey and Open Problems <em>(Rating: 1)</em></li>
                <li>A Survey of Large Language Models <em>(Rating: 1)</em></li>
                <li>A Survey of Large Language Models for Autonomous Driving <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3664",
    "paper_id": "paper-266999123",
    "extraction_schema_id": "extraction-schema-91",
    "extracted_data": [
        {
            "name_short": "DomainKnowledgeDistill (Tang et al.)",
            "name_full": "Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain",
            "brief_description": "An empirical study (cited in this survey) that, by its title, investigates distilling domain knowledge from large language models for the autonomous driving domain; the survey references it as an example of domain knowledge distillation using LLMs.",
            "citation_title": "Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain",
            "mention_or_use": "mention",
            "system_or_method_name": "Domain Knowledge Distillation from LLM",
            "system_or_method_description": "Not described in detail in this survey; referenced as an empirical study on distilling domain knowledge from LLM(s) for autonomous driving. The survey does not provide method-level specifics.",
            "input_corpus_description": null,
            "topic_or_query_specification": null,
            "distillation_method": null,
            "output_type_and_format": null,
            "evaluation_or_validation_method": null,
            "results_summary": null,
            "limitations_or_challenges": null,
            "comparison_to_baselines_or_humans": null,
            "uuid": "e3664.0",
            "source_info": {
                "paper_title": "Exploring the Potential of Large Language Models in Self-adaptive Systems",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain",
            "rating": 2,
            "sanitized_title": "domain_knowledge_distillation_from_large_language_model_an_empirical_study_in_the_autonomous_driving_domain"
        },
        {
            "paper_title": "Large Language Models Based Automatic Synthesis of Software Specifications",
            "rating": 1,
            "sanitized_title": "large_language_models_based_automatic_synthesis_of_software_specifications"
        },
        {
            "paper_title": "Large Language Models for Software Engineering: Survey and Open Problems",
            "rating": 1,
            "sanitized_title": "large_language_models_for_software_engineering_survey_and_open_problems"
        },
        {
            "paper_title": "A Survey of Large Language Models",
            "rating": 1,
            "sanitized_title": "a_survey_of_large_language_models"
        },
        {
            "paper_title": "A Survey of Large Language Models for Autonomous Driving",
            "rating": 1,
            "sanitized_title": "a_survey_of_large_language_models_for_autonomous_driving"
        }
    ],
    "cost": 0.008352,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Exploring the Potential of Large Language Models in Self-adaptive Systems
15 Jan 2024</p>
<p>Jialong Li lijialong@fuji.waseda.jp 
Mingyue Zhang myzhangswu@swu.edu.cn 
Nianyu Li li_nianyu@pku.edu.cn 
Danny Weyns danny.weyns@kuleuven.be 
Zhi Jin zhijin@pku.edu.cn 
Kenji Tei tei@c.titech.ac.jp </p>
<p>Waseda University Tokyo
Japan</p>
<p>Southwest University Chongqing
China</p>
<p>ZGC National Laboratory
BeijingChina</p>
<p>KU Leuven Leuven
Belgium</p>
<p>Peking University
BeijingChina</p>
<p>Tokyo Institute of Technology Tokyo
Japan</p>
<p>Exploring the Potential of Large Language Models in Self-adaptive Systems
15 Jan 20244D3ED905D94ADB7F2064AFEF3112F7D9arXiv:2401.07534v1[cs.SE]Large Language ModelSelf-adaptive SystemsSurvey
Large Language Models (LLMs), with their abilities in knowledge acquisition and reasoning, can potentially enhance the various aspects of Self-adaptive Systems (SAS).Yet, the potential of LLMs in SAS remains largely unexplored and ambiguous, due to the lack of literature from flagship conferences or journals in the field, such as SEAMS and TAAS.The interdisciplinary nature of SAS suggests that drawing and integrating ideas from related fields, such as software engineering and autonomous agents, could unveil innovative research directions for LLMs within SAS.To this end, this paper reports the results of a literature review of studies in relevant fields, summarizes and classifies the studies relevant to SAS, and outlines their potential to specific aspects of SAS.</p>
<p>INTRODUCTION</p>
<p>A language model is, in essence, a computational artifact that allows predicting the next word in a sentence based on the probability distribution over sequences of words [38].Empowered by modern AI techniques such as the Transformer [52], pre-trained language models (PLM) [11] have demonstrated increasing performance in specific tasks following the 'pre-train and fine-tune' paradigm.Furthermore, with the increasing scale of the model size and the amount of data used for pre-training and fine-tuning, PLMs show emergent and remarkable capabilities in various tasks [55].Such large-scale PLMs are commonly referred to as 'large language models (LLM)'.</p>
<p>As discussed in the fields of 'Cognitive Linguistics' and 'Philosophy of Language', language not only serves as an intermediary that enables the building of humans' complex systems of knowledge but also defines a deeper logical structure, reflecting the logic of human thought.Similarly, LLMs, trained on vast textual corpora, have shown their capabilities in knowledge acquisition as well as in logical reasoning and planning.Leveraging these abilities, LLMs have demonstrated strong capabilities in solving diverse problems, leading to a rapid expansion of research and applications.</p>
<p>Self-adaptive Systems (SAS) are engineered to autonomously adapt to their dynamics in their environment or internal changes without manual interventions, a capability essential for tackling real-world challenges [7,15,27,57,58].LLMs, as demonstrated in other studies, have significantly enhanced the system's capabilities, including context awareness and decision-making, which are essential for handling self-adaptation.However, there is a notable scarcity of literature on the use of LLM within the field of SAS, particularly from flagship conferences or journals in the field like SEAMS, ACSOS, and TAAS.This lack of research makes the potential of LLMs in SAS remain unexplored and ambiguous.As SAS is a cross-disciplinary research field that intersects with software engineering, autonomous agents, human-computer interaction, among others, we believe that a cross-pollination from these relevant fields, could lead to innovative insights, helping to identify potential research directions of LLMs in the context and perspective of SAS.</p>
<p>To this end, this paper aims to explore the potential of LLMs in SAS by targeting the following two research questions:</p>
<p>• RQ1: What are the key areas of research that explore the application of LLMs relevant to SAS? • RQ2: How do the existing studies on LLMs contribute to specific aspects of SAS, and what future research challenges do they suggest for the SAS research community?To answer RQ1, we review LLM studies from four different research fields relevant to SAS and summarize key research areas on LLM within these fields.To answer RQ2, we further filter and categorize the above studies, discussing LLMs' potential and challenges in various aspects of SAS.We start with a brief introduction of LLM (Section 2) and explain the study design (Section 3).Then, we present the results answering the research questions (Sections 4 and 5).Finally, we discuss threats to validity (Section 6), and draw conclusions (Section 7).</p>
<p>BACKGROUND: LARGE LANGUAGE MODEL</p>
<p>To lay the foundation for the subsequent discussions, we briefly introduce LLM focusing on core aspects.</p>
<p>Architectures of LLMs and Pre-training.LLMs refer to transformer-based, large-scale language models that contain billions of parameters and are pre-trained on massive text data [26].For instance, GPT-3 has 175 billion parameters and uses preprocessed 570GB of text data for training.The architecture of LLMs can be categorized into three main types: (i) encoder-only, in which the encoder encodes the input text into a hidden representation to capture the relationships between words and the overall text context; (ii) encoder-decoder, in which the encoder processes the input into a hidden space, and the decoder translates the abstract representation from hidden space into relevant text expression; and (iii) decoder-only, which is used in models like GPT, gradually generates the output text by sequentially predicting the subsequent tokens.LLMs are pre-trained using datasets that include web pages, books, conversational text, and program code.The data undergoes pre-processing, such as quality filtering, de-duplication, to improve data quality, and privacy data reduction to enhance privacy.</p>
<p>Fine-tuning of LLMs.After pre-training, fine-tuning is a technique that uses application-specific customized datasets to provide additional training of the model, thereby improving its performance on the specific task [23].A representative example is OpenAI's Codex [5] that is based on GPT-3 and specifically fine-tuned for code generation.In addition to traditional fine-tuning, LLMs require two new types of tuning: (i) Instruction tuning to enhance LLM ability to accurately comprehend and execute tasks as directed by (user-given) natural language instructions; and (ii) Alignment tuning to align LLM more closely with human values such as helpfulness and honesty.</p>
<p>Utilizing LLMs.After pre-training and optional fine-tuning, LLMs can be utilized to solve various tasks when given suitable prompts.The prompting strategies can be mainly classified into three categories: (i) In-Context Learning (ICL), which offers task description along with examples as demonstrations [3]; (ii) Chainof-Thought (CoT) that incorporates intermediate steps of reasoning into the prompts [56]; and (iii) Planning that decomposes complex tasks into smaller sub-tasks and creates a plan of actions to complete the overall task [72].Employing these strategies enhances LLM performance by aligning the model's processing with the nature of the specific task, thereby resulting in the generation of more coherent and contextually relevant responses.</p>
<p>Capabilities of LLMs.According to Zhao et al. [71], LLMs mainly have the following six abilities: (i) Language generation aims at creating text that meets certain requirements set by tasks like translation, summarization, question answering, as well as formal language (e.g., logical forms, code) synthesis; (ii) Knowledge utilization entails leveraging the extensive factual knowledge from the pre-training corpus or accessing external data to perform tasks that require significant knowledge, such as common-sense question answering and fact completion; (iii) Reasoning, encompassing knowledge, symbolic, and mathematical reasoning, pertains to the capability to comprehend and apply evidence or logic to reach conclusions or make decisions; (iv) Human alignment means that LLM can well conform to human values and needs, with criteria like truthfulness, honesty, and safety; (v) Interaction with the external environment refers to the ability to receive feedback from the external environment and perform actions according to behavioral instruction, e.g., generating detailed action plans in natural language or other formats; (vi) Tool manipulation refers to the ability to utilize external tools, such as search engines and calculators, to enhance performance on given tasks.It should be noted that these six capabilities are neither comprehensive nor orthogonal, i.e., a task may require a combination of multiple capabilities.</p>
<p>Shortcomings of LLMs.Although this paper does not delve into the technical details of LLMs, it is important to consider shortcomings when using them.We highlight key issues.First, hallucination refers to the phenomenon where a model generates misleading and factually incorrect information.This may challenge the system's reliability and trustworthiness.Second, the need for high-performance hardware: Due to the sheer model size and complex inference, LLMs generally require high-performance hardware.This leads to increased deployment and operational costs; Third, slow inference speed: Similarly, due to the large model size, LLMs take time to process input and generate output.This limits the application of LLMs in domains requiring real-time responses.Fourth, explainability issues: Due to LLMs' complex neural network architectures and massive parameter counts, they often operate as black boxes.This may make it difficult to apply them to critical applications.Fifth, privacy concerns: LLMs may use and sometimes share user data with third parties (e.g., when using external search engines).This may not align with users' data privacy expectations.These issues call for further research and regulation.</p>
<p>STUDY DESIGN</p>
<p>We used a study design comprising five steps.The first two steps focused on searching for literature on LLMs in fields relevant to SAS (targeting RQ1).The last three steps focused on filtering and classifying the literature in relation to the field of SAS (targeting RQ2).</p>
<p>Step 1: Due to the cross-disciplinary nature of the SAS area, we collected studies from fields relevant to SAS.Specifically, we selected two theoretical research fields (software engineering and autonomous agents) and two application-oriented domains (robotics and autonomous driving).The choice of these fields is motivated by their relevance to adaptation and the abundance of literature in these areas.To more effectively search for papers and avoid reinventing the wheel, we collected literature from well-known reviews in these fields.Specifically, we selected a total of seven survey papers: two for software engineering [14,22], two for autonomous agents [53,64], one for robotics [68], and one for autonomous driving [67].In addition, we also selected a review paper for LLM [71] to capture potential literature beyond the aforementioned fields.After de-duplication, this resulted in a total of 1,363 papers.</p>
<p>Step 2: Preliminary screening of the literature based on the following criteria: (i) Exclude papers published before 2017, as the Transformer model was introduced in that year; (ii) Exclude GitHub projects, news, X (Twitter), and blogs; and (iii) Exclude papers unrelated to PLM or LLM by checking the title and abstract of studies.This resulted in 880 papers after the preliminary screening.</p>
<p>Step 3: Establish first-level categories for classifying studies.The first-level categories followed the MAPE-K reference model (Monitor-Analysis-Plan-Execution over Knowledge), the classic conceptual model for engineering SAS [27].Additionally, we included the category of 'human-in-the-loop (HITL).'</p>
<p>Step 4: Confirm the relevance to SAS of each study.The relevance was determined by whether a study explicitly contributes to the first-level categories (from step 3), i.e., whether LLMs empower context awareness, decision-making, plan execution, and humancomputer interaction with the system.To enhance the validity of this step, two of the researchers involved in this study independently confirmed the title, abstract, and keywords of each study and decisions were made based on discussions between the two in case of disagreement.We mainly excluded theoretical studies of LLM (e.g., fine-tuning techniques), studies that improve the performance of LLM without direct relevance for SAS (e.g., prompt engineering), applications of the humanities, and dataset or benchmark studies.This step resulted in 179 papers.</p>
<p>Step 5: Refine categories and classify the selected studies.We thoroughly read the full text of all selected studies and categorized them into the first-level categories.We then refined each first-level category into subsequent-level categories and classified each study.This step involved at least three researchers of the study.</p>
<p>RQ1: LLM IN RELEVANT FIELDS</p>
<p>In this section, we investigate the application of LLMs in fields relevant to SAS.The results enable us to answer RQ1.</p>
<p>Software Engineering.LLMs are instrumental across various stages of Software Engineering (SE), offering tools and methods that enhance the efficiency and quality of SE activities [14,22].In requirements engineering, LLMs are used for classifying, analyzing requirements [19], and translating requirements in natural language to logic-based specifications [9].During the software design phase, LLMs facilitate the generation of software prototypes [60].In the development phase, their applications include code generation and completion, code comprehension and summarization [32], and recommending or utilizing APIs (Application Programming Interface) [40].LLMs are also explored for software quality assurance and maintenance.They are mainly applied to automated test generation [50] , program repair [65], and code review [51].</p>
<p>Autonomous Agents.LLMs have already been used to support various types of autonomous agents, including simulation agents, web agents, game agents, assistant agents, and more [53,64].Although there is no consensus on the architectural design of LLMbased autonomous agents, LLMs have been primarily used in the following five kinds of modules: (i) Profiling module, where LLMs are utilized to automatically define the appropriate agent's roles, such as coders or domain experts, for given tasks [6]; (ii) Perception module, where multi-modal LLMs enable the perception of various modalities (textual, visual, and auditory) [31] and formats (e.g., point cloud-based 3D maps) [17]; (iii) Memory module, in which LLMs are used to store, retrieve, or reflect past information, utilizing short-and/or long-term memory structures in various formats like natural languages, embedding vectors, and databases [73]; (iv) Decision-making module (planning and reasoning), with representative methods like Chain of Thought (CoT) and self-consistency.In addition, various reflection methods are also proposed, enabling LLMs to modify and refine agent plans based on feedback from humans or the environment [54]; (v) Action module, in which LLMs are used to decide actions based on the given decision, usually by calling external tools such as APIs, planners, and solvers [39,70] Robotics.Robotics can be viewed as embodied agents that solve their own domain-specific problems [68].For instance, [63] aligns LLMs with visual perception models, enabling the generation of executable plans based on the perceived objects in the scene.[41] allows LLMs to conduct efficient semantic search-based planning based on the specific input of 3D scene graphs.Additionally, there are specialized pre-trained Vision-Language-Action models (VLA) for robotics, such as Google's PaLM-E and Deepmind's RT-2 [2].</p>
<p>Autonomous Driving.LLMs are extensively studied in the domain of autonomous driving.In perception, LLMs are used to assist in tracking or detecting 2D or 3D objects in driving scenes [12].For decision-making, LLMs have been explored for tasks such as generating motion plans by transforming these tasks into sequence modeling problems [4].Additionally, another promising direction involves scene generation, where LLMs combined with diffusion multimodal models are utilized to generate realistic driving videos or intricate driving scenarios under specific environmental factors [24].This approach significantly lowers the cost of data collection and labeling, thereby providing an efficient and cost-effective solution for the verification and testing of autonomous driving systems.</p>
<p>Answer to RQ1</p>
<p>The key areas of research on using LLMs in Software Engineering (SE) lie in improving the efficiency and performance of SE activities.Hence, such improvements offer potential benefits to the engineering of SAS.Key areas of research on using LLMs in autonomous agents, robotics, and autonomous driving focus on the collection and representation of knowledge and decision-making.These areas offer potential for supporting the runtime activities of SAS, in particular analysis and planning.</p>
<p>RQ2: POTENTIAL OF LLM FOR SAS</p>
<p>We now zoom in on the analysis of the potential of LLM for SAS.The results enable answering RQ2.We begin with an overview of the classification of the literature.Then, we delve into the potential of LLM for SAS in the different categories.</p>
<p>Overview of Literature Classification</p>
<p>Following the procedure explained in Sec. 3, we classified the collected literature according to the functions of the MAPE-K reference model plus human-in-the-loop, as shown in Fig. 1.</p>
<p>For the classification, several points require special attention: (i) We combined analysis and planning into a single category, as their responsibilities often overlap and are difficult to clearly distinguish; (ii) Studies do not necessarily belong to one category; e.g., task assignment for human-computer collaboration could be considered in both planning and human-in-the-loop.We classified each study according to its main category; (iii) Due to page limitations, we only discuss representative studies for each classification.For studies with relatively close contributions or novelty, we select the one or two most relevant based on discussions among the authors.The complete literature classification 1 is available for interested readers.</p>
<p>The remainder of this section presents the potential of LLM in each category and provides an answer to RQ2 for each category.</p>
<p>Monitoring</p>
<p>As SASs operate in environments that are often dynamic and unpredictable, the monitoring function is crucial for collecting and filtering data, as well as understanding the context of the system and the environments in which it operates.</p>
<p>Understanding Context.In other research fields, language models for vision are a highly discussed topic, yet most SASs do not involve image processing.However, LLMs also offer interesting possibilities in understanding text or data.For instance, LLMs can detect semantic anomalies in data [37].A straightforward example is an autonomous driving system mistaking a truck's taillight for a moving traffic signal.This ability can not only identify sensing errors or data fusion errors but can also be used to timely and accurately trigger the system's adaptation or human intervention. 1Anonymous link for blind review: https://figshare.com/s/09ff1b1c1ed433d55a53</p>
<p>Predicting Context.In addition to understanding context, LLMs can also be used to reason about and predict future contexts.Seff et al. [43] utilizes LLMs to predict the motion of autonomous vehicles by representing continuous trajectories as sequences of discrete motion tokens and defining motion prediction as a language modeling task.Graule and Isler [17] uses a semantic map of the environment to infer probable sequences of human actions and activities.The capability of context prediction allows SAS to anticipate future states or changes, thereby laying a foundation for proactive adaptation.</p>
<p>Answer to RQ2: Monitoring</p>
<p>LLMs have demonstrated the ability to enable more accurate and richer contextual awareness, laying a solid basis for higherquality decision-making in SAS.However, the strategies leveraging these abilities into SAS require exploration, as massive sources of (indirect) data will lead to a large design space for monitoring.Furthermore, employing LLM for monitoring tasks in large-scale self-adaptive systems raises performance challenges when high-frequency monitoring is required during runtime.</p>
<p>Analysis &amp; Planning</p>
<p>The analysis and planning functions provide the mechanisms to analyze the options for adaptation and compose a plan for adaptation to achieve the system's goals.Here, we divide the literature in two categories: first, using LLM to empower existing approaches, leveraging the 'seven waves' in the textbook [57], 2 and second, emerging analysis and planning paradigms enabled by LLM.</p>
<p>Empowering Existing Methods.</p>
<p>Architecture-based Adaptation.The focus is on architectural models and modeling abstractions that enable the system to reason about adaptation decisions [15].As extensively discussed in the literature, LLMs can decompose given tasks (equivalent to the goal management layer in the three-layer model [46]).Based on the decomposed sub-goals, LLMs can select and use the appropriate tools, which can be considered system components, at runtime (equivalent to the change management layer and component control layer).For instance, Qin et al. [40] utilizes ChatGPT to generate a chain of API calls for the given instruction from pools of more than 16,000 real-world APIs.Zohar et al. [74] uses LLMs to choose appropriate AI models for given tasks, according to the function descriptions of each model, and connect them to complete the task.Hence, LLMs have the potential to support flexible and largescale architecture-based adaptations utilizing large-scale libraries of components.</p>
<p>Requirements-driven Adaptation.This approach considers requirements as first-class entities to manage requirement-driven adaptation.A recognized open challenge in this approach is how to support automatically changing goals at runtime [57] to handle the uncertainty and dynamics of requirements.First, as mentioned in RQ1, many LLM studies in SE have focused on the automated decomposition, analysis, and classification of 'static' requirements; thus, bridging them into runtime could be a possible direction.</p>
<p>Second, some studies on autonomous agents also provide insightful ideas for this approach.[1] applies LLM-based agents to negotiation games, which could be a solution for resolving requirement conflicts or enabling requirement relaxation.[44] proposes a self-refinement mechanism for automating the design of a reward function, where adjusting the reward function can be viewed as a modification to the requirements and their weights or priorities.</p>
<p>Guarantees under Uncertainty.This approach aims to provide evidence that the adaptation behavior guarantees the adaptation goals under uncertainty.It is noteworthy that we did not find work combining LLM with formal methods, such as probabilistic or statistical verification.However, there are studies based on game theory that offer potential, as game theory can be used to model the behavioral uncertainty of cooperative and adversarial entities and guarantee the system's performance under the worst possible scenarios.For instance, Alympics [35] employs an LLM-based agent to simulate multi-agent game simulations, where the LLM enables the construction of more realistic and dynamic models of human interactions.However, to our knowledge, existing studies have only demonstrated LLMs' ability to generate agent behaviors for defining and simulating more realistic and complex game processes.To our knowledge, the potential of LLMs in solving mathematically defined games has not yet been discussed.</p>
<p>Control-based Software Adaptation.This approach focuses on exploiting the mathematical basis of control theory for designing SASs and guaranteeing key properties of the system.As mentioned in [57], the key challenge of this approach is how to translate nonfunctional requirements (NFR) in the context of SE into control properties in the context of control theory (and vice versa).To our knowledge, although [10] involves using LLMs to interpret the behavior of the PID controller, there are currently no studies using LLMs to automate or assist in building controllers based on requirements.However, given LLMs' understanding of NFRs, as well as their capabilities in mathematical reasoning and translation, we believe that it is worth exploring the use of LLMs in bridging SE and control theory and apply this to the field of self-adaptation.</p>
<p>Learning from Experience.This approach is about exploiting machine learning techniques to support functions within managing systems, addressing the growing system scale and increasingly complex uncertainty.Here, LLM may have several potential applications.Firstly, LLMs themselves can be used for context-aware classification, such as failure mode classification [45], to reduce the decision-making space to only relevant adaptation options.Secondly, LLMs have also been applied in automated machine learning and data science to reduce manual design costs and improve performance.For example, [20] uses LLMs to iteratively generate semantically meaningful and domain-specific features to automate feature engineering in machine learning.Thirdly, LLMs have been effectively integrated with reinforcement learning (RL) in several ways.[44] proposes an LLM-based self-refinement mechanism for automated reward function design, demonstrating its effectiveness in dynamic environments and complex tasks in robotics.[66] proposes a combined decision-making method of RL and LLM for the Werewolf game.Specifically, LLMs are first used to generate possible action candidates (by applying deductive reasoning to analyze the hidden roles of other players), and RL is subsequently applied to select the optimal action.</p>
<p>New Paradigms.</p>
<p>Collective intelligence.Collective intelligence in the form of crowd-sourcing has emerged as a novel method to leverage the wisdom of crowds (where multiple agents often play different roles or are enabled by multiple fine-tuned LLMs) to achieve consensusdriven decision-making through discussion, debate, or voting.[13] proposes a method to arrive at a common final answer for reasoning problems through multiple rounds of debate, demonstrating the potential of crowd-sourcing in reducing fallacious answers and hallucinations.[6] explores automated expert recruitment (deciding what kind of domain expert is needed for the task and then generating their persona) and different forms of crowd-sourcing (democratic or hierarchical).[69] transplants the Actor-Critic framework from RL into LLM multi-agent crowd-sourcing, demonstrating its potential to reduce hallucinations and lower usage costs (in terms of token length).Due to its nature, this paradigm provides a new avenue for decision-making, particularly suitable for decentralized SAS [59].</p>
<p>Experience Accumulation.Experience accumulation, distinct from existing methods such as machine learning-based classification or reinforcement learning, refers to the ability of an agent to employ LLMs to accumulate experience and gradually learn to plan through continuous trial-and-error.For failed experiences, the reasons for failure, analyzed by an LLM or provided by a human, can be reflected upon and incorporated into the next round of planning [54].Similarly, for successful experiences, LLMs are used to store them in memory or skill pool, and then retrieve and reuse them when encountering similar situations in the future [73].The paradigm of experience accumulation aligns with the widely acknowledged yet not extensively explored concept of 'self-learning SAS' [36].This paradigm suggests that LLM provides a foundation that enables SAS to learn from collected experiences and autonomously evolve their own 'learning' to handle unexpected conditions.</p>
<p>Answer to RQ2: Analysis &amp; Planning (1) Existing analysis and planning methods may benefit from integrating LLM helping to improve runtime performance or reduce design costs.The integration of LLM with established disciplines like formal verification or control theory remains unexplored, despite the probabilistic nature of LLM that aligns well with many of the frameworks of these traditional methods.(2) Several new generalized analysis and planning paradigms, previously unexplored in the SAS community, have emerged.These paradigms hold great potential, particularly for decentralized SAS and self-learning SAS.</p>
<p>Execution</p>
<p>Execution refers to the enactment of actions of the adaptation plan in porder to adapt a SAS, but its scope varies depending on the concrete designs and division of responsibilities between the managed system (i.e., the system that is subject to adaptation) and the managing system (i.e., the MAPE loop that adapts the managed system).For instance, consider a plan 'moving to the destination.' Execution can vary: (i) the executor simply passes destination coordinates to the managed system that autonomously completes the movement, or (ii) the executor translates the given plan into a more detailed path or even control parameters for the managed system.</p>
<p>For cases such as the first scenario, execution is straightforward and LLMs offer little benefit.However, for more complex tasks like the second scenario, as demonstrated by the Vision-Language-Action model (VLA) or 'robotic transformer', LLMs have demonstrated to be beneficial in translating high-level instructions into specific control parameters [2].Although the literature in this category is quite limited, LLMs essentially have the ability to reason about and convert high-level activities into low-level configuration actions.Despite these capabilities, current SAS literature suggests that execution is often carried out with simple mappings or rule sets.This identifies a gap in understanding which scenarios can truly benefit from LLM-enabled complex conversions.</p>
<p>Answer to RQ2: Execution</p>
<p>LLMs have demonstrated the ability to convert higher-level activities into low-level control actions.SAS may benefit from these capabilities.However, the potential of LLM for the execution of adaptation plans remains an area for further exploration.</p>
<p>Runtime Models &amp; Knowledge</p>
<p>Knowledge or runtime models, extending the notion of development-time models to runtime, are elements that are associated with the four functions of MAPE, enabling runtime reasoning and decision-making.In some cases, these runtime models are defined with a specific focus, using meticulously designed Domain-Specific Modeling Languages (DSML) [57].We focus here on system models and environment models.</p>
<p>System Models.LLMs have been practically used to generate models describing different aspects of software, including but not limited to requirement models [19], and architecture models [21].In addition, LLMs have demonstrated their ability to generate or translate into domain-specific models.For instance, Mandal et al. [34] converts requirements from natural language to DSML, although the format and operators of/within the DSML need to be specified by the user in the prompt.Liu et al. [30] applies domain-adapted fine-tuning to enable a 5x reduction in LLM model size and better performance in tasks of industrial chip design.However, the models generated by these studies are often static at development time and do not consider reasoning during runtime.Therefore, utilizing LLMs to design DSML for runtime models (which aspects or information to capture and how to support decision-making) may still be a research direction that requires further exploration.</p>
<p>Environment Models.LLMs as world models [18] 3 , or more broadly, Artificial Intelligence Generated Content (AIGC), have demonstrated their capability in generating environmental data, thereby simulating environmental uncertainties for training or testing SAS.For instance, Hu et al. [24] uses video, text, and action inputs to generate realistic driving scenarios with fine-grained scene features.However, addressing the hallucinations of LLMs and aligning simulated environments with the real world remain as important future research directions.</p>
<p>Answer to RQ2: Runtime Models &amp; Knowledge</p>
<p>LLMs can automate or assist in the design or translation of models.Here, the generated objects include not only models describing the system (to support runtime decision-making) but also models of the operational environment (to enable simulation or testing).However, the challenges of creating system models that support reasoning and generating environment models that align with the real world continue to be crucial areas for future research.</p>
<p>Human-in-the-Loop</p>
<p>Human-in-the-Loop (HITL) ensures that human intelligence and judgment can assist or guide the system's adaptive behavior, particularly at critical moments, which is vital for enhancing the overall effectiveness and trustworthiness of the system [42].</p>
<p>Transparency.Transparency refers to the degree to which the system's operations and decision-making processes are understandable to the human user [28].Many studies have provided insights into improving system interpretability, including: (i) code summarization and comprehension, where LLMs can directly interpret code and document it, thereby explaining the system's operational logic [32]; (ii) model explanation, where LLMs can explain decisionmaking in models such as PID controller models [10]; (iii) data explanation, which involves explaining the system's operations through log/diagnostic information of systems [47].Additionally, the capabilities of Q&amp;A-style interaction [48] and data visualization [33] of LLMs can also provide directions for more user-friendly and intuitive explanations.With transparency empowered by LLMs, it becomes easier to establish user trust in SAS's behavior and enable informed decision-making by SAS in co-operation with the user.</p>
<p>Controllability.Controllability refers to the ability of the human user to intervene, guide, or alter the system's operations or decision-making process.Some literature explores manually correcting the composition of the Chain of Thought (CoT) and LLMgenerated workflows, or allowing humans to modify the intermediate outcomes produced by various steps in the workflow [62].Such features have the potential to enhance the safety and reliability of SAS, as they allow humans to intervene in situations where the system may not act normally or optimally.</p>
<p>Human-computer Collaboration.Human-computer collaboration refers to the cooperative interaction between humans and the system, thereby harnessing the respective strengths of humans and computers for optimal utility [8].Gong et al. [16] proposes MindAgent, a framework that uses LLMs to generate action patterns for non-player character (NPC) collaborators (in a game environment) based on the behavior (history) of human players.Kannan et al. [25] apply LLMs to convert high-level task instructions provided as input into a multi-agent task plan, including task decomposition, agent grouping formation, and task allocation.These approaches demonstrate the potential of LLMs for designing collaborations in SAS that are both user-centric and computer-mediated.</p>
<p>Preference Acquisition.Preference acquisition refers to the process of gathering and understanding the preferences and needs of users [29].Wu et al. [61] focuses on preferences for the placement of objects in robotic cleaning tasks, where LLMs are applied to summarize and infer generalized and broadly applicable user preferences from just a few interaction examples.Thomas et al. [49] uses feedback from real users to predict whether a search result is valuable to the searcher (as a relevance label), and the evaluation deployed on Bing demonstrated that the accuracy is comparable to human labelers.As another form of context understanding and prediction, LLMs have shown their potential to acquire human preferences, thereby facilitating personalized and user-centric adaptations for enhancing user satisfaction in SAS.</p>
<p>Answer to RQ2: Human-in-the-loop Although HITL is recognized as an important research direction in the field of SAS, the studies in this area are still limited.With the emergence of LLMs and their demonstrated capabilities and powerfull generalizability in HITL tasks, they could bring significant opportunities in this direction to SAS.</p>
<p>THREATS TO VALIDITY</p>
<p>Our study is exploratory in nature and subject to a number of threats to validity.First and foremost, we selected studies from a set of existing literature reviews.Evidently, we may have missed relevant papers.To limit this threat, we selected well-known and multiple reviews, but we acknowledge that a full systematic literature review would better mitigate this threat.Second, we established a number of rules to determine the relevance of the studies to SAS.This set of rules is inherently limited, and we acknowledge that we may have missed interesting opportunities reported in the literature.By leveraging the MAPE-K reference models, and established approaches documented in the literature [57], we have tried to minimize this validity threat.Thirdly, the interpretation of categories for classification may not have been fully objective.To mitigate this potential validity threat, the data was collected by multiple researchers and discussed in cases of disagreement.Furthermore, the results were cross-checked by the other researchers involved in this study.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>In this paper, we reviewed recent studies of LLM in the relevant fields of SAS, and categorized their contributions into specific aspects of SAS.The results primarily suggest that LLMs have the potential to augment existing methods and introduce new opportunities for functionalities.These potentials encompass all phases of the MAPE-K loop and human-in-the-loop.</p>
<p>In future research, we plan to expand this study.More specifically, due to the emphasis on the timeliness of research, we simplified the steps in our literature search.Similarly, because of space limitations, this paper remains necessarily brief regarding most of the literature.Therefore, we plan to conduct a systematic literature review and perform a comprehensive and finer-grained analysis and discussion.</p>
<p>Nevertheless, we hope that this paper provides a useful and comprehensive snapshot of the potential of LLM for the SAS community, thereby facilitating research on LLM applied in SAS.</p>
<p>Figure 1 :
1
Figure 1: Overview of Categorization.The numbers in brackets indicate the number of studies in the category.One study can be categorized into multiple categories.</p>
<p>We omit 'automating tasks', which refers mainly to MAPE-K as a whole, and 'runtime models', which we discuss as part of •runtime models &amp; knowledge'.
A concept in AI referring to a computational model that simulates the real-world environment, behaviors, and dynamics.</p>
<p>Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, Mario Fritz, arXiv:2309.17234[cs.CL]LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games. 2023</p>
<p>. Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, Pete Florence, Chuyuan Fu, Montse Gonzalez Arenas, Keerthana Gopalakrishnan, Kehang Han, Karol Hausman, Alexander Herzog, Jasmine Hsu, Brian Ichter, Alex Irpan, Nikhil Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Isabel Leal, Lisa Lee, Tsang-Wei Edward Lee, Sergey Levine, Yao Lu, Henryk Michalewski, Igor Mordatch, Karl Pertsch, Kanishka Rao, Krista Reymann, Michael Ryoo, Grecia Salazar, Pannag Sanketi, Pierre Sermanet, Jaspiar Singh, Anikait Singh, Radu Soricut, Huong Tran, Vincent Vanhoucke, Quan Vuong, Ayzaan Wahid, Stefan Welker, Paul Wohlhart, Jialin Wu, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, arXiv:2307.15818[cs.RO]Tianhe Yuand Brianna Zitkovich. 2023. RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control</p>
<p>Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, arXiv:2005.14165[cs.CL]Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</p>
<p>Long Chen, Oleg Sinavski, Jan Hünermann, Alice Karnsund, Andrew James Willmott, Danny Birch, Daniel Maund, Jamie Shotton, arXiv:2310.01957[cs.RO]Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving. 2023</p>
<p>. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet ; Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, arXiv:2107.03374[cs.LG]Felipe Petroski Such. Josh Achiam, Vedant Misra, Evan Morikawa, Alec RadfordJan LeikeIlya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou, arXiv:2308.10848[cs.CL]AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. 2023</p>
<p>Software Engineering for Self-Adaptive Systems: A Research Roadmap. H C Betty, Cheng, 2009Springer</p>
<p>Extending MAPE-K to Support Human-Machine Teaming. Jane Cleland-Huang, Ankit Agrawal, Michael Vierhauser, Michael Murphy, Mike Prieto, Proceedings of the 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems. the 17th Symposium on Software Engineering for Adaptive and Self-Managing SystemsPittsburgh, Pennsylvania; New York, NY, USAAssociation for Computing Machinery2022SEAMS '22)</p>
<p>nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models. Matthias Cosler, Christopher Hahn, Daniel Mendoza, Frederik Schmitt, Caroline Trippel, Computer Aided Verification. Nature SwitzerlandSpringer2023</p>
<p>LLM Adaptive PID Control for B5G Truck Platooning Systems. I De Zarzà, J De Curtò, Gemma Roig, Carlos T Calafate, Sensors. 23132023. 2023</p>
<p>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 2019</p>
<p>Xinpeng Ding, Jianhua Han, Hang Xu, Wei Zhang, Xiaomeng Li, arXiv:2309.05186[cs.CV]HiLM-D: Towards High-Resolution Understanding in Multimodal Large Language Models for Autonomous Driving. 2023</p>
<p>Improving Factuality and Reasoning in Language Models through Multiagent Debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.14325[cs.CL]2023</p>
<p>Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, Jie M Zhang, arXiv:2310.03533[cs.SE]Large Language Models for Software Engineering: Survey and Open Problems. 2023</p>
<p>Rainbow: architecture-based self-adaptation with reusable infrastructure. D Garlan, Computer. 37102004. 2004</p>
<p>Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, Jianfeng Gao, arXiv:2309.09971[cs.AI]MindAgent: Emergent Gaming Interaction. 2023</p>
<p>A Moritz, Volkan Graule, Isler, arXiv:2310.20034[cs.RO]GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning. 2023</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992[cs.CL]Reasoning with Language Model is Planning with World Model. 2023</p>
<p>MAPE-K Loop-based Goal Model Generation Using Generative AI. Shinichi Honiden, Hiroyuki Nakagawa, IEEE 31st International Requirements Engineering Conference Workshop. 2023</p>
<p>Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering. Noah Hollmann, Samuel Müller, Frank Hutter, arXiv:2305.03403[cs.AI]2023</p>
<p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, arXiv:2308.00352[cs.AI]Chenyu Ran, Lingfeng Xiao, and Chenglin Wu. 2023. MetaGPT: Meta Programming for Multi-Agent Collaborative Framework. </p>
<p>Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, Haoyu Wang, arXiv:2308.10620[cs.SE]Large Language Models for Software Engineering: A Systematic Literature Review. 2023</p>
<p>Universal Language Model Finetuning for Text Classification. Jeremy Howard, Sebastian Ruder, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. Iryna Gurevych, Yusuke Miyao, the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20181</p>
<p>Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev, Alex Kendall, Jamie Shotton, Gianluca Corrado, arXiv:2309.17080[cs.CV]GAIA-1: A Generative World Model for Autonomous Driving. 2023</p>
<p>Shyam Sundar Kannan, L N Vishnunandan, Byung-Cheol Venkatesh, Min, arXiv:2309.10062[cs.RO]SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models. 2023</p>
<p>Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, arXiv:2001.08361[cs.LG]Scaling Laws for Neural Language Models. 2020</p>
<p>The vision of autonomic computing. Jeff Kephart, Davidchess , Computer. 362003. Jan 2003</p>
<p>Explanations for Human-on-the-Loop: A Probabilistic Model Checking Approach. Nianyu Li, Sridhar Adepu, Eunsuk Kang, David Garlan, Proceedings of the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS '20). the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS '20)2020</p>
<p>Preference Adaptation: user satisfaction is all you need!. Nianyu Li, Mingyue Zhang, Jialong Li, Eunsuk Kang, Kenji Tei, 2023 IEEE/ACM 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS). 2023</p>
<p>Mingjie Liu, Teo Ene, Robert Kirby, Chris Cheng, Nathaniel Pinckney, Rongjian Liang, Jonah Alben, Himyanshu Anand, Sanmitra Banerjee, Ismet Bayraktaroglu, Bonita Bhaskaran, Bryan Catanzaro, Arjun Chaudhuri, Sharon Clay, Bill Dally, Laura Dang, Parikshit Deshpande, Siddhanth Dhodhi, Sameer Halepete, Eric Hill, Jiashang Hu, Sumit Jain, Brucek Khailany, Kishor Kunal, Xiaowei Li, Hao Liu, Stuart Oberman, Sujeet Omar, Sreedhar Pratty, Ambar Sarkar, Zhengjiang Shao, Hanfei Sun, P Pratik, Suthar, arXiv:2311.00176[cs.CL]Varun Tej, Kaizhe Xu, and Haoxing Ren. 2023. ChipNeMo: Domain-Adapted LLMs for Chip Design. </p>
<p>Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, Zhaopeng Tu, arXiv:2306.09093[cs.CL]Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration. 2023</p>
<p>Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, Yang Liu, arXiv:2305.12138[cs.SE]ChatGPT: Understanding Code Syntax and Semantics. 2023</p>
<p>Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. Paula Maddigan, Teo Susnjak, IEEE Access. 112023. 2023</p>
<p>Large Language Models Based Automatic Synthesis of Software Specifications. Shantanu Mandal, Adhrik Chethan, Vahid Janfaza, S M Farabi Mahmud, Todd A Anderson, Javier Turek, Jesmin Jahan Tithi, Abdullah Muzahid, arXiv:2304.09181[cs.SE]2023</p>
<p>Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, Furu Wei, arXiv:2311.03220[cs.CL]ALYMPICS: Language Agents Meet Game Theory. 2023</p>
<p>Survey of Machine Learning Enabled Software Self-adaptation. Jin Zhang Mingyue, Zhao Zhi, Luo Haiyan, Yixing, Journal of Software (in Chinese). 312020. 2020</p>
<p>A framework for anomaly detection using language modeling, and its applications to finance. Armineh Nourbakhsh, Grace Bang, arXiv:1908.09156[cs.CL]2019</p>
<p>Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, arXiv:2304.08354[cs.CL]Tool Learning with Foundation Models. Zhiyuan Liu, and Maosong Sun2023</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, Maosong Sun, arXiv:2307.16789[cs.AI]ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs. 2023</p>
<p>SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning. Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, Niko Suenderhauf, arXiv:2307.06135[cs.RO]2023</p>
<p>Gunar Schirner, Deniz Erdogmus, Kaushik Chowdhury, Taskin Padir, The Future of Human-in-the-Loop Cyber-Physical Systems. 2013. 201346</p>
<p>Ari Seff, Brian Cera, Dian Chen, Mason Ng, Aurick Zhou, Nigamaa Nayakanti, Khaled S Refaat, Rami Al-Rfou, Benjamin Sapp, arXiv:2309.16534[cs.CV]MotionLM: Multi-Agent Motion Forecasting as Language Modeling. 2023</p>
<p>Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics. Jiayang Song, Zhehua Zhou, Jiawei Liu, Chunrong Fang, Zhan Shu, Lei Ma, arXiv:2309.06687[cs.RO]2023</p>
<p>Michael Stewart, Melinda Hodkiewicz, Sirui Li, arXiv:2309.08181[cs.CL]Large Language Models for Failure Mode Classification: An Investigation. 2023</p>
<p>From Goals to Components: A Combined Approach to Self-Management. Daniel Sykes, William Heaven, Jeff Magee, Jeff Kramer, Proceedings of the 2008 International Workshop on Software Engineering for Adaptive and Self-Managing Systems (SEAMS '08). the 2008 International Workshop on Software Engineering for Adaptive and Self-Managing Systems (SEAMS '08)2008</p>
<p>REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots. Andrea Tagliabue, Kota Kondo, Tong Zhao, Mason Peterson, Claudius T Tewari, Jonathan P How, arXiv:2311.01403[cs.RO]2023</p>
<p>Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain. Yun Tang, Antonio A Bruto Da Costa, Jason Zhang, Irvine Patrick, Siddartha Khastgir, Paul Jennings, arXiv:2307.11769[cs.CL]2023</p>
<p>Large language models can accurately predict searcher preferences. Paul Thomas, Seth Spielman, Nick Craswell, Bhaskar Mitra, arXiv:2309.10621[cs.IR]2023</p>
<p>Variable Discovery with Large Language Models for Metamorphic Testing of Scientific Software. Christos Tsigkanos, Pooja Rani, Sebastian Müller, Timo Kehrer, Computational Science -ICCS 2023. ChamSpringer Nature Switzerland2023</p>
<p>Using Pre-Trained Models to Boost Code Review Automation. Rosalia Tufano, Simone Masiero, Antonio Mastropaolo, Luca Pascarella, Denys Poshyvanyk, Gabriele Bavota, Proceedings of the 44th International Conference on Software Engineering. the 44th International Conference on Software EngineeringPittsburgh, Pennsylvania; New York, NY, USAAssociation for Computing Machinery2022ICSE '22)</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, arXiv:1706.03762[cs.CL]Attention Is All You Need. 2023</p>
<p>Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen, arXiv:2308.11432[cs.AI]A Survey on Large Language Model based Autonomous Agents. 2023</p>
<p>Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, Yitao Liang, arXiv:2302.01560[cs.AI]Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. 2023</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, arXiv:2206.07682[cs.CL]Emergent Abilities of Large Language Models. 2022and William Fedus</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.11903[cs.CL]Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. 2023</p>
<p>An Introduction to Self-adaptive Systems : A Contemporary Software Engineering Perspective. Danny Weyns, 2020Wiley-IEEE Computer Society Pr</p>
<p>Self-Adaptation in Industry: A Survey. Danny Weyns, ACM Trans. Auton. Adapt. Syst. 182023. 202344 pages</p>
<p>On Patterns for Decentralized Control in Self-Adaptive Systems. Danny Weyns, Bradley Schmerl, Vincenzo Grassi, Sam Malek, Raffaela Mirandola, Christian Prehofer, Jochen Wuttke, Jesper Andersson, Holger Giese, Karl M Göschka, 10.1007/978-3-642-35813-5_42013SpringerBerlin Heidelberg; Berlin, Heidelberg</p>
<p>Jules White, Sam Hays, Quchen Fu, Jesse Spencer-Smith, Douglas C Schmidt, arXiv:2303.07839[cs.SE]ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design. 2023</p>
<p>TidyBot: personalized robot assistance with large language models. Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser, Autonomous Robots. 2023. 2023</p>
<p>AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts. Tongshuang Wu, Michael Terry, Carrie , Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22). the 2022 CHI Conference on Human Factors in Computing Systems (CHI '22)Jun Cai. 2022385</p>
<p>Embodied Task Planning with Large Language Models. Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, Haibin Yan, arXiv:2307.01848[cs.CV]2023</p>
<p>Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, arXiv:2309.07864[cs.AI]Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and Tao Gui. 2023. The Rise and Potential of Large Language Model Based Agents: A Survey. </p>
<p>Automated Program Repair in the Era of Large Pre-trained Language Models. Chunqiu Steven Xia, Yuxiang Wei, Lingming Zhang, 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE). 2023</p>
<p>Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game. Zelai Xu, Chao Yu, Fei Fang, Yu Wang, Yi Wu, arXiv:2310.18940[cs.AI]2023</p>
<p>A Survey of Large Language Models for Autonomous Driving. Zhenjie Yang, Xiaosong Jia, Hongyang Li, Junchi Yan, arXiv:2311.01043[cs.AI]2023</p>
<p>Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, Philip S Yu, arXiv:2311.07226[cs.RO]Large Language Models for Robotics: A Survey. 2023</p>
<p>Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, Lijuan Li, Guoliang Fan, arXiv:2311.13884[cs.AI]Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach. 2023</p>
<p>Kechi Zhang, Huangzhao Zhang, Ge Li, Jia Li, Zhuo Li, Zhi Jin, arXiv:2305.04032[cs.SE]ToolCoder: Teach Code Generation Models to use API search tools. 2023</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Yifan Dong, Chen Du, Yushuo Yang, Zhipeng Chen, Jinhao Chen, Jiang, arXiv:2303.18223[cs.CL]A Survey of Large Language Models. Peiyu Liu, Jian-Yun Liu, Ji-Rong Nie, Wen, Ruiyang Ren, Yifan Li, Xinyu Tang2023</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, arXiv:2205.10625[cs.AI]Quoc Le, and Ed Chi. 2023. Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. </p>
<p>Xizhou Zhu, Yuntao Chen, Chenxin Hao Tian, Weijie Tao, Chenyu Su, Gao Yang, Bin Huang, Lewei Li, Xiaogang Lu, Yu Wang, Zhaoxiang Qiao, Jifeng Zhang, Dai, arXiv:2305.17144[cs.AI]Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory. 2023</p>
<p>Shih-Cheng Orr Zohar, Kuan-Chieh Huang, Serena Wang, Yeung, arXiv:2306.08893[cs.CV]LOVM: Language-Only Vision Model Selection. 2023</p>            </div>
        </div>

    </div>
</body>
</html>