<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1110 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1110</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1110</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-245634512</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2112.14811v1.pdf" target="_blank">Active Learning-Based Optimization of Scientific Experimental Design</a></p>
                <p><strong>Paper Abstract:</strong> Active learning (AL) is a machine learning algorithm that can achieve greater accuracy with fewer labeled training instances, for having the ability to ask oracles to label the most valuable unlabeled data chosen iteratively and heuristically by query strategies. Scientific experiments nowadays, though becoming increasingly automated, are still suffering from human involvement in the designing process and the exhaustive search in the experimental space. This article performs a retrospective study on a drug response dataset using the proposed AL scheme comprised of the matrix factorization method of alternating least square (ALS) and deep neural networks (DNN). This article also proposes an AL query strategy based on expected loss minimization. As a result, the retrospective study demonstrates that scientific experimental design, instead of being manually set, can be optimized by AL, and the proposed query strategy ELM sampling shows better experimental performance than other ones such as random sampling and uncertainty sampling.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1110.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1110.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALSDL+ELM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Alternating Least Squares with Deep Learning (ALSDL) predictive model + Expected Loss Minimization (ELM) active-learning sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive experimental-design agent that combines matrix-factorization latent features (ALS), a fully-connected neural network head (DL) to predict continuous drug-response metrics, and an active-learning query strategy that selects next experiments by minimizing the model's expected test loss.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ALSDL + ELM active learning scheme</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Two-part architecture: (1) Alternating Least Squares (ALS) matrix factorization to produce latent embeddings for cells and molecules (embedding dim d=5, learning rate 0.01); (2) a Fully-Connected Neural Network (FCNN) head with three hidden layers (20, 10, 5 units, tanh activations, rmsprop optimizer) that takes aligned cell+molecule embeddings to predict continuous sensitivity (GR or IFD). The AL loop uses an Expected Loss Minimization (ELM) query strategy to select new samples to label and add to training.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Active learning (Expected Loss Minimization variant)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each AL iteration the agent trains the ALSDL model on the current labeled set D, then for each candidate unlabeled sample x+ it simulates the effect of adding x+ by using the current model's prediction ŷ+ as a proxy label, retraining (or estimating) the updated model M+ and computing the expected test loss on the unlabeled pool (using current-model predictions for the unlabeled pool). It selects samples x+ that minimize this expected test loss; for batch queries it sorts unlabeled samples by expected loss and takes the top-nper_query entries.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Breast Cancer Profiling Project, Drug Sensitivity 1 (redefined subset: 35 cell lines × 34 molecules × 4 concentrations = 4760 samples)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Finite discrete pool of candidate experiments; continuous noisy regression targets (GR and IFD); labels (true responses) are unknown until an experiment is performed (partially observable / label-costly); no explicit physical/chemical features for cells or molecules provided (unknown subject properties); retrospective evaluation on a fully labeled dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Reformulated pool size = 4760 samples (35 cells × 34 molecules × 4 concentrations); action space = selecting up to 40 samples per query; labeling is costly/time-consuming in real world (one physical experiment takes ~3 days serialized per paper); state is not episodic in standard RL sense (single-round pool-based AL with up to 8 query rounds in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>ELM + ALSDL reached the best accuracy and lowest RMSE among compared sampling strategies after 8 query rounds (total labeled = 360 samples). Reported predictive-model numbers in the paper: ALSDL test RMSE for GR converges to ~0.10 (text) and table reports GR ALSDL average test loss 0.160126785 with average test accuracy 0.872478992, improving over ALS baseline (GR ALS test loss 0.250860068 and accuracy 0.854432773). For IFD the paper reports ALSDL test RMSE around ~0.02 (text) although table entries appear inconsistent; qualitatively ELM sampling produced lower loss and higher accuracy than random, orderly, and uncertainty sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>In the experiments ELM reached superior model performance after 8 queries (ninit=40, nper_query=40, nmax_query=8) → 360 labeled samples (≈7.6% of the 4760-sample pool). The paper states ELM converges more rapidly and constructs better predictive models with fewer labeled examples compared to random, orderly, and uncertainty sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Implicitly managed by minimizing expected test loss: selected samples are those predicted to yield the greatest reduction in future test loss, which trades off exploration (samples that reduce uncertainty / expected loss across the pool) and exploitation (samples predicted to improve accuracy where the model is already uncertain/erroneous). This is different from explicit uncertainty-based selection — ELM uses model-predicted downstream benefit rather than only uncertainty near decision boundaries.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Orderly (row/column) sampling, Random sampling, Uncertainty sampling (select samples with predicted values nearest the classification boundary).</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) The ELM active-sampling strategy outperformed random, orderly, and uncertainty sampling in this retrospective drug-response dataset: it achieved faster convergence of RMSE and higher classification accuracy for the same labeling budget. 2) The ALSDL predictive model (ALS embeddings + FCNN) produced lower RMSEs and higher accuracies than ALS alone. 3) With 360 labeled examples (from 4760 total), ELM produced the best models among tested strategies, demonstrating improved sample efficiency. 4) ELM initially may lag when few labels are available but catches up as expected-test-loss estimates become reliable.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Reported limitations include: (a) results are from a retrospective study on a single redefined dataset (limited generality); (b) hyperparameters and FCNN architecture were not exhaustively tuned due to computational constraints; (c) ELM requires using current-model predictions as proxy labels to estimate expected loss, which can be misleading early in training and cause initial lag; (d) the method depends on the quality of ALS-derived embeddings (no explicit phys/chem features provided); (e) the paper notes that in some settings uncertainty sampling can be unstable because the classification boundary shifts during training.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1110.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1110.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALSDL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Alternating Least Squares with Deep Learning (ALSDL) predictive model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A predictive model that uses ALS matrix factorization to produce latent cell and molecule embeddings and feeds concatenated aligned embeddings into a small FCNN; includes a custom loss that penalizes RMSE together with a classification-penalty term (β-weighted).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ALSDL predictive model</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ALS produces latent features (d=5) for cells and molecules; aligned embeddings are input to a FCNN (layers sizes 20-10-5-1, tanh activations) trained with an RMSE loss optionally augmented by a penalty term that increases loss for incorrect sign/classification (β parameter, set to 0 in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>None by itself (predictive model used within an adaptive AL loop when combined with a query strategy)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Not an adaptive agent by itself; adapts only insofar as it is retrained iteratively during an active-learning loop driven by a separate query strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same drug-response dataset (redefined subset of Breast Cancer Profiling Project, Drug Sensitivity 1)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Predictive target: continuous GR and IFD with binary-sign classification boundary at 0; inputs are latent embeddings derived from cooperative filtering because explicit phys/chem features are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Same pool of 4760 samples used in experiments; trained with 10-fold CV and up to 200 epochs DL training in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>When used as the predictive model inside the AL scheme, ALSDL + ELM achieved the best performance; standalone ALSDL test numbers reported: GR ALSDL average test loss 0.160126785 and test accuracy 0.872478992 (table), improved relative to ALS baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>ALS baseline: reported GR test loss 0.250860068 and accuracy 0.854432773 (table). ALSDL reduced loss and increased accuracy for GR; qualitative improvements in training/test loss overlap (reduced overfitting).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>ALSDL converged to lower RMSE in ~200 epochs of DL training when fed ALS embeddings; when combined with AL sampling the combined scheme needed ~360 labeled samples to reach top performance in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Not applicable directly; exploration/exploitation handled at the AL query layer (e.g., ELM).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against ALS-only predictive model (matrix-factorization output without FCNN head) in predictive experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>ALSDL reduced test RMSE and improved test accuracy relative to ALS alone (reported GR RMSE decrease and improved accuracy), and reduced overfitting (training/test loss curves aligned more closely).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>β penalty parameter was set to 0 in experiments (the proposed classification-penalty loss was not used to influence training in reported runs), hyperparameters not exhaustively tuned, and generality untested beyond this dataset.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1110.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1110.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ELM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Loss Minimization query strategy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active-learning query policy for regression targets that selects unlabeled samples whose addition (using current-model predicted labels as proxies) yields the greatest expected reduction in test loss across the pool.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Expected Loss Minimization (ELM) sampler</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A pool-based AL query strategy that for each candidate sample uses the current model's predicted label as a pseudo-label, estimates the model M+ that would result from adding that sample, computes expected test loss of M+ (on the pool using current-model predictions), and selects samples minimizing this expected loss; supports batch selection by sorting expected losses and picking the top-k.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Active learning (expected loss minimization / value-of-information for sample selection)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Uses the model's current predictive distribution (point predictions in this paper) to approximate the post-labeling model and evaluates which candidate will most reduce future test loss; selection changes over time as the model improves and predictions become more accurate.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same drug-response experimental pool (Breast Cancer Profiling Project subset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Partially observable (labels unknown without running physical experiments), continuous regression targets, discrete finite candidate pool, label-costly environment.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Pool size 4760; batch query size 40; up to 8 query rounds performed in experiments (360 labeled examples total for top performance).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>ELM produced models with the lowest RMSE and highest accuracy among tested sampling strategies after 8 query rounds (360 labeled samples). According to the paper, ELM 'reaches the highest accuracy and the least loss for both GR and IFD' and converges faster than random, orderly, and uncertainty sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Achieved superior model quality with 360 labeled samples (initial ninit=40 plus 8 queries of 40 each) out of a 4760-sample pool; qualitatively more sample-efficient than baselines in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Balances exploration and exploitation implicitly by quantifying expected downstream test-loss reduction: a candidate sample is chosen if it is expected to most improve future predictive performance (captures both informative/uncertain samples and those that correct systematic errors).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against Orderly (manual row/column) sampling, Random sampling, and Uncertainty sampling baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>ELM outperforms naive and uncertainty-based samplers in this retrospective drug-response setting, especially as the model's expected-loss estimates become accurate; ELM can initially underperform (lag) when the model is poorly trained but surpasses others as training proceeds.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Relies on current-model predictions as proxy labels when estimating expected loss, which can mislead selection early in training; computational overhead to evaluate expected loss per candidate (the paper used an expedited evaluation by measuring RMSE after 200 ALS epochs to speed queries); demonstrated on a single dataset only.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Active learning literature survey <em>(Rating: 2)</em></li>
                <li>Collaborative filtering for implicit feedback datasets <em>(Rating: 2)</em></li>
                <li>Designing drug-response experiments and quantifying their results <em>(Rating: 1)</em></li>
                <li>Growth rate inhibition metrics correct for confounders in measuring sensitivity to cancer drugs <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1110",
    "paper_id": "paper-245634512",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "ALSDL+ELM",
            "name_full": "Alternating Least Squares with Deep Learning (ALSDL) predictive model + Expected Loss Minimization (ELM) active-learning sampling",
            "brief_description": "An adaptive experimental-design agent that combines matrix-factorization latent features (ALS), a fully-connected neural network head (DL) to predict continuous drug-response metrics, and an active-learning query strategy that selects next experiments by minimizing the model's expected test loss.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "ALSDL + ELM active learning scheme",
            "agent_description": "Two-part architecture: (1) Alternating Least Squares (ALS) matrix factorization to produce latent embeddings for cells and molecules (embedding dim d=5, learning rate 0.01); (2) a Fully-Connected Neural Network (FCNN) head with three hidden layers (20, 10, 5 units, tanh activations, rmsprop optimizer) that takes aligned cell+molecule embeddings to predict continuous sensitivity (GR or IFD). The AL loop uses an Expected Loss Minimization (ELM) query strategy to select new samples to label and add to training.",
            "adaptive_design_method": "Active learning (Expected Loss Minimization variant)",
            "adaptation_strategy_description": "At each AL iteration the agent trains the ALSDL model on the current labeled set D, then for each candidate unlabeled sample x+ it simulates the effect of adding x+ by using the current model's prediction ŷ+ as a proxy label, retraining (or estimating) the updated model M+ and computing the expected test loss on the unlabeled pool (using current-model predictions for the unlabeled pool). It selects samples x+ that minimize this expected test loss; for batch queries it sorts unlabeled samples by expected loss and takes the top-nper_query entries.",
            "environment_name": "Breast Cancer Profiling Project, Drug Sensitivity 1 (redefined subset: 35 cell lines × 34 molecules × 4 concentrations = 4760 samples)",
            "environment_characteristics": "Finite discrete pool of candidate experiments; continuous noisy regression targets (GR and IFD); labels (true responses) are unknown until an experiment is performed (partially observable / label-costly); no explicit physical/chemical features for cells or molecules provided (unknown subject properties); retrospective evaluation on a fully labeled dataset.",
            "environment_complexity": "Reformulated pool size = 4760 samples (35 cells × 34 molecules × 4 concentrations); action space = selecting up to 40 samples per query; labeling is costly/time-consuming in real world (one physical experiment takes ~3 days serialized per paper); state is not episodic in standard RL sense (single-round pool-based AL with up to 8 query rounds in experiments).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "ELM + ALSDL reached the best accuracy and lowest RMSE among compared sampling strategies after 8 query rounds (total labeled = 360 samples). Reported predictive-model numbers in the paper: ALSDL test RMSE for GR converges to ~0.10 (text) and table reports GR ALSDL average test loss 0.160126785 with average test accuracy 0.872478992, improving over ALS baseline (GR ALS test loss 0.250860068 and accuracy 0.854432773). For IFD the paper reports ALSDL test RMSE around ~0.02 (text) although table entries appear inconsistent; qualitatively ELM sampling produced lower loss and higher accuracy than random, orderly, and uncertainty sampling.",
            "performance_without_adaptation": null,
            "sample_efficiency": "In the experiments ELM reached superior model performance after 8 queries (ninit=40, nper_query=40, nmax_query=8) → 360 labeled samples (≈7.6% of the 4760-sample pool). The paper states ELM converges more rapidly and constructs better predictive models with fewer labeled examples compared to random, orderly, and uncertainty sampling.",
            "exploration_exploitation_tradeoff": "Implicitly managed by minimizing expected test loss: selected samples are those predicted to yield the greatest reduction in future test loss, which trades off exploration (samples that reduce uncertainty / expected loss across the pool) and exploitation (samples predicted to improve accuracy where the model is already uncertain/erroneous). This is different from explicit uncertainty-based selection — ELM uses model-predicted downstream benefit rather than only uncertainty near decision boundaries.",
            "comparison_methods": "Orderly (row/column) sampling, Random sampling, Uncertainty sampling (select samples with predicted values nearest the classification boundary).",
            "key_results": "1) The ELM active-sampling strategy outperformed random, orderly, and uncertainty sampling in this retrospective drug-response dataset: it achieved faster convergence of RMSE and higher classification accuracy for the same labeling budget. 2) The ALSDL predictive model (ALS embeddings + FCNN) produced lower RMSEs and higher accuracies than ALS alone. 3) With 360 labeled examples (from 4760 total), ELM produced the best models among tested strategies, demonstrating improved sample efficiency. 4) ELM initially may lag when few labels are available but catches up as expected-test-loss estimates become reliable.",
            "limitations_or_failures": "Reported limitations include: (a) results are from a retrospective study on a single redefined dataset (limited generality); (b) hyperparameters and FCNN architecture were not exhaustively tuned due to computational constraints; (c) ELM requires using current-model predictions as proxy labels to estimate expected loss, which can be misleading early in training and cause initial lag; (d) the method depends on the quality of ALS-derived embeddings (no explicit phys/chem features provided); (e) the paper notes that in some settings uncertainty sampling can be unstable because the classification boundary shifts during training.",
            "uuid": "e1110.0"
        },
        {
            "name_short": "ALSDL",
            "name_full": "Alternating Least Squares with Deep Learning (ALSDL) predictive model",
            "brief_description": "A predictive model that uses ALS matrix factorization to produce latent cell and molecule embeddings and feeds concatenated aligned embeddings into a small FCNN; includes a custom loss that penalizes RMSE together with a classification-penalty term (β-weighted).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "ALSDL predictive model",
            "agent_description": "ALS produces latent features (d=5) for cells and molecules; aligned embeddings are input to a FCNN (layers sizes 20-10-5-1, tanh activations) trained with an RMSE loss optionally augmented by a penalty term that increases loss for incorrect sign/classification (β parameter, set to 0 in experiments).",
            "adaptive_design_method": "None by itself (predictive model used within an adaptive AL loop when combined with a query strategy)",
            "adaptation_strategy_description": "Not an adaptive agent by itself; adapts only insofar as it is retrained iteratively during an active-learning loop driven by a separate query strategy.",
            "environment_name": "Same drug-response dataset (redefined subset of Breast Cancer Profiling Project, Drug Sensitivity 1)",
            "environment_characteristics": "Predictive target: continuous GR and IFD with binary-sign classification boundary at 0; inputs are latent embeddings derived from cooperative filtering because explicit phys/chem features are not provided.",
            "environment_complexity": "Same pool of 4760 samples used in experiments; trained with 10-fold CV and up to 200 epochs DL training in experiments.",
            "uses_adaptive_design": false,
            "performance_with_adaptation": "When used as the predictive model inside the AL scheme, ALSDL + ELM achieved the best performance; standalone ALSDL test numbers reported: GR ALSDL average test loss 0.160126785 and test accuracy 0.872478992 (table), improved relative to ALS baseline.",
            "performance_without_adaptation": "ALS baseline: reported GR test loss 0.250860068 and accuracy 0.854432773 (table). ALSDL reduced loss and increased accuracy for GR; qualitative improvements in training/test loss overlap (reduced overfitting).",
            "sample_efficiency": "ALSDL converged to lower RMSE in ~200 epochs of DL training when fed ALS embeddings; when combined with AL sampling the combined scheme needed ~360 labeled samples to reach top performance in the experiments.",
            "exploration_exploitation_tradeoff": "Not applicable directly; exploration/exploitation handled at the AL query layer (e.g., ELM).",
            "comparison_methods": "Compared against ALS-only predictive model (matrix-factorization output without FCNN head) in predictive experiments.",
            "key_results": "ALSDL reduced test RMSE and improved test accuracy relative to ALS alone (reported GR RMSE decrease and improved accuracy), and reduced overfitting (training/test loss curves aligned more closely).",
            "limitations_or_failures": "β penalty parameter was set to 0 in experiments (the proposed classification-penalty loss was not used to influence training in reported runs), hyperparameters not exhaustively tuned, and generality untested beyond this dataset.",
            "uuid": "e1110.1"
        },
        {
            "name_short": "ELM",
            "name_full": "Expected Loss Minimization query strategy",
            "brief_description": "An active-learning query policy for regression targets that selects unlabeled samples whose addition (using current-model predicted labels as proxies) yields the greatest expected reduction in test loss across the pool.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Expected Loss Minimization (ELM) sampler",
            "agent_description": "A pool-based AL query strategy that for each candidate sample uses the current model's predicted label as a pseudo-label, estimates the model M+ that would result from adding that sample, computes expected test loss of M+ (on the pool using current-model predictions), and selects samples minimizing this expected loss; supports batch selection by sorting expected losses and picking the top-k.",
            "adaptive_design_method": "Active learning (expected loss minimization / value-of-information for sample selection)",
            "adaptation_strategy_description": "Uses the model's current predictive distribution (point predictions in this paper) to approximate the post-labeling model and evaluates which candidate will most reduce future test loss; selection changes over time as the model improves and predictions become more accurate.",
            "environment_name": "Same drug-response experimental pool (Breast Cancer Profiling Project subset)",
            "environment_characteristics": "Partially observable (labels unknown without running physical experiments), continuous regression targets, discrete finite candidate pool, label-costly environment.",
            "environment_complexity": "Pool size 4760; batch query size 40; up to 8 query rounds performed in experiments (360 labeled examples total for top performance).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "ELM produced models with the lowest RMSE and highest accuracy among tested sampling strategies after 8 query rounds (360 labeled samples). According to the paper, ELM 'reaches the highest accuracy and the least loss for both GR and IFD' and converges faster than random, orderly, and uncertainty sampling.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Achieved superior model quality with 360 labeled samples (initial ninit=40 plus 8 queries of 40 each) out of a 4760-sample pool; qualitatively more sample-efficient than baselines in experiments.",
            "exploration_exploitation_tradeoff": "Balances exploration and exploitation implicitly by quantifying expected downstream test-loss reduction: a candidate sample is chosen if it is expected to most improve future predictive performance (captures both informative/uncertain samples and those that correct systematic errors).",
            "comparison_methods": "Compared against Orderly (manual row/column) sampling, Random sampling, and Uncertainty sampling baselines.",
            "key_results": "ELM outperforms naive and uncertainty-based samplers in this retrospective drug-response setting, especially as the model's expected-loss estimates become accurate; ELM can initially underperform (lag) when the model is poorly trained but surpasses others as training proceeds.",
            "limitations_or_failures": "Relies on current-model predictions as proxy labels when estimating expected loss, which can mislead selection early in training; computational overhead to evaluate expected loss per candidate (the paper used an expedited evaluation by measuring RMSE after 200 ALS epochs to speed queries); demonstrated on a single dataset only.",
            "uuid": "e1110.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Active learning literature survey",
            "rating": 2,
            "sanitized_title": "active_learning_literature_survey"
        },
        {
            "paper_title": "Collaborative filtering for implicit feedback datasets",
            "rating": 2,
            "sanitized_title": "collaborative_filtering_for_implicit_feedback_datasets"
        },
        {
            "paper_title": "Designing drug-response experiments and quantifying their results",
            "rating": 1,
            "sanitized_title": "designing_drugresponse_experiments_and_quantifying_their_results"
        },
        {
            "paper_title": "Growth rate inhibition metrics correct for confounders in measuring sensitivity to cancer drugs",
            "rating": 1,
            "sanitized_title": "growth_rate_inhibition_metrics_correct_for_confounders_in_measuring_sensitivity_to_cancer_drugs"
        }
    ],
    "cost": 0.0117315,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Active Learning-Based Optimization of Scientific Experimental Design</p>
<p>Ruoyu Wang lannywong2000@163.com 
School of Computer Science &amp; Engineering
South China University of Technology Guangzhou
510006GuangdongChina</p>
<p>Active Learning-Based Optimization of Scientific Experimental Design
Machine LearningActive LearningScientific Experiment DesignAlternating Least SquareDeep Neural Network
Active learning (AL) is a machine learning algorithm that can achieve greater accuracy with fewer labeled training instances, for having the ability to ask oracles to label the most valuable unlabeled data chosen iteratively and heuristically by query strategies. Scientific experiments nowadays, though becoming increasingly automated, are still suffering from human involvement in the designing process and the exhaustive search in the experimental space. This article performs a retrospective study on a drug response dataset using the proposed AL scheme comprised of the matrix factorization method of alternating least square (ALS) and deep neural networks (DNN). This article also proposes an AL query strategy based on expected loss minimization. As a result, the retrospective study demonstrates that scientific experimental design, instead of being manually set, can be optimized by AL, and the proposed query strategy ELM sampling shows better experimental performance than other ones such as random sampling and uncertainty sampling.</p>
<p>Introduction</p>
<p>Scientific experiments have become progressively reliant on automated machines overtime to cope with large datasets and high concurrency. For instance, Hafner et al. [1] propose a mostly automated pipeline for drug response experiments implementation and results quantification. However, the remained human involvement in the process of experimental design has a high tendency to generate errors that are difficult to tackle. The most conventional replacement for manual experimental design is an exhaustive one. But without heuristic sampling methods, the exhaustive exploration in the experiment space tends to lead to excessive consumption of experimental resources and manpower.</p>
<p>Some non-exhaustive methods were proposed to achieve experimental design automation, such as random sampling and orthogonal experimental design [2]. However, since the two methods are based on stochastic distribution and predetermined orthogonal table respectively, both of them fail to take the properties of the experimental subjects into consideration and therefore their performance varies in real-life experimental practices.</p>
<p>Accordingly, an active method is needed to implement automated experimental design adaptively based on the properties of the experimental subjects. And active learning (AL) is a machine learning algorithm that can achieve greater accuracy with fewer labeled training instances, for having the ability to ask oracles to label the most valuable unlabeled data chosen iteratively by query strategies [3].</p>
<p>In the regard of above, this article performs a retrospective study on a dataset produced by the mentioned pipeline and discusses the feasibility of adaptive design of scientific experiments using AL strategy. Insights and inspiration can be found in this article for scientists to harness the strength of AL to avoid human involvement in experimental design, heuristically achieve experimental design optimization and train satisfying predictive models with relatively fewer physical experiments.</p>
<p>Dataset</p>
<p>Dataset Description</p>
<p>The dataset used in this article is Breast Cancer Profiling Project, Drug Sensitivity 1 [4]. This dataset, produced from the mentioned drug response experiment pipeline[1] of Hafner's as shown in Figure 1, contains the exhausted experimental results of measuring the sensitivities of 35 breast cancer cell lines to 34 small molecule perturbagens. Every combination of cell and molecule is treated with 9 doses of different concentrations of small molecule perturbagens respectively. Therefore, the dataset contains 10710 instances in total.</p>
<p>Figure 1: Hafner's Pipeline for experimental design and analysis</p>
<p>The independent and dependent variables of the dataset are described as follows. The independents variables are Cell HMS LINCS ID, Cell Name, Small Molecule HMS LINCS ID, Small Molecule Name, Small Mol Concentration (uM), Primary Target and Pathway. The dependent variables are two measurements of sensitivity that are Mean Normalized Growth Rate Inhibition Value (GR) and Increased Fraction Dead (IFD).
GR = 2 log 2 x(c) x 0 log 2 x ctrl x 0 [5]
Where x(c), x0 and x ctrl is the mean of the measured live cell counts after a given treatment, from the day 0 untreated plate grown in parallel until the time of treatment, and of the control wells for all technical replicates respectively.
IF D = f d(c) − f d ctrl
Where f d(c) is the mean fraction of dead cells in the wells from a given treatment and f d ctrl is the mean fraction of dead cells in the control wells across all technical replicates.</p>
<p>Properties of Variables</p>
<p>High interdependencies exist among the independent variables. For example, Cell HMS LINCS ID and Cell Name have a one-to-one mapping relationship, and Primary Target and Pathway are both determined by each certain combination of cell and molecule. Thus, the independent variables of the dataset can be restated as Cell Type, Molecule Type and Molecule Concentration (uM).</p>
<p>Notably, the explicit physical or chemical properties of cells and molecules are not given in the dataset.</p>
<p>The independent variables measuring sensitivity are continuous. Thus, a regression model with regression metrics, such as rooted mean square error, is needed to perform prediction work.</p>
<p>Scientists are also interested in the classification accuracy that whether certain molecule accelerates or restrains the growth of certain cell. Obviously, a GR value greater than 1 or a negative IFD value indicates a positive effect of certain molecule on the growth of certain cell. On the contrary, a GR value less than 1 or a positive IFD value indicates a negative one. In the following experiments, the GR values are typically reduced by 1 so that both the independent variables have a binary classification boundary of 0.</p>
<p>Dataset Redefinition</p>
<p>As previously discussed, every combination of cell and molecule are treated with 9 different concentrations of molecule respectively. However, the 9 concentrations are not entirely the same as each other. For the convenience of doing retrospective AL experiments (i.e. to make sure that the sensitivity result is known for every possible combination of cell, molecule and concentration of molecule), the problem space will be restricted to a subset of all concentration values in which every concentration value has correspondent results of all combinations of cell and molecule. As it turns out, this subset of concentration values has a size of 4.</p>
<p>Therefore, the problem space will be redefined to one containing 4760 samples. Although the size of the dataset is halved, it is still worth studying since one single experiment takes three days to complete in the physical world in a serialized manner [4], and a better experimental design can avoid excessive consumption of resources and can also produce more accurate predictive models.</p>
<p>In the following experiments, all the proposed methods will be performed on the 4 subdatasets of different concentration values separately. Particularly, the training curves of the subdataset with a molecule concentration of 0.01uM are shown to illustrate the traits of the algorithms. And the arithmetic mean of all the 4 subdatasets' results is calculated when referring to average. </p>
<p>Predictive Models</p>
<p>The difficulty of building predictive models for the dataset lies in that the independent variables do not represent the explicit features of cells and molecules, therefore cannot be used to train predictive models directly. In this section, a matrix factorization method called Alternating Least Square (ALS) will be used to produce the latent features of cells and molecules, then an ALS improvement method with the combination of Deep Neural Network (DNN) will be proposed.</p>
<p>Metrics</p>
<p>The metrics for the predictive models are loss and accuracy. Rooted mean square error (RMSE) is used to measure the loss. And accuracy is calculated as the percentage of predicted sensitivity values that are on the same side of decision boundary (0 in this article) as the ground truth sensitivity values.
RM SE = 1 n n i=1 (ŷi − yi) 2
n is the number of samples,ŷi is the predicted value and yi is the ground truth for sample i.</p>
<p>Alternating Least Square</p>
<p>ALS Prerequisites</p>
<p>ALS [6] is a collaborative filtering algorithm in the field of recommender systems using matrix factorization. Specifically, given a sparse user-item real matrix recording user ratings on the items, the aim is to decompose the user-item matrix into a dot product of a user embedding matrix and an item embedding matrix such that the squared error between the dot product and the user-item matrix is minimized. The loss function is shown below where i, j, d, x, w, y and r is the i th of m users, j th of n items, number of dimensions of embedding vector, m × d user embedding matrix, d × n item embedding matrix, m × n user-item matrix and m × n 0-1 matrix recording rated positions respectively.
loss = 1 2 (i,j)∈r(i,j)=1 d l=1 x il w lj − yij 2
One can then deduce the partial derivatives of loss with respect to x and w.
∂loss ∂x ik = j∈r(i,j)=1 d l=1 x il w lj − yij w kj ∂loss ∂w kj = i∈r(i,j)=1 d l=1 x il w lj − yij x ik
Finally, the gradient decent method can be used to train the model with learning rate α.
x = x − α∆x = x − αr · (xw − y) w T w = w − α∆w = w − αx T [(xw − y) · r]
This method is called alternating because the user matrix and the item matrix are trained alternately while the other one is fixed.</p>
<p>ALS Experiment Settings</p>
<p>The number of dimensions of the embedding vector d is intuitively set to 5. The learning rate α is 0.01. An ALS model is trained for every cell-molecule matrix and a 10-fold cross-validation is performed with 400 epochs of training for every ALS model. The ALS training curves of GR and IFD with molecule concentration of 0.01 uM are shown in Figure  3 and Figure 4 and the average test loss and average test accuracy are shown in Table 1. From Figure 3 and Figure 4, it is revealed that:</p>
<p>ALS Results Analysis</p>
<p>The training loss, RMSE, converges at a relatively satisfying value of around 0.15 for GR and around 0.05 for IFD after 100 to 200 epochs of training.</p>
<p>The phenomenon of overfitting is quite obvious especially as shown in Figure 3, where the test loss only converges at around 0.2 and lacks behind the training loss by roughly 0.1.</p>
<p>The model reduces loss at the expense of accuracy. After 100 to 200 epochs of training, the test loss drops at an extremely slow rate while the test accuracy is stable or even reduced. This reduction of test accuracy can significantly impair the practical performance of the predictive model and thus should be addressed carefully.</p>
<p>Alternating Least Square with</p>
<p>Deep Learning (ALSDL)</p>
<p>ALS Improvement with DL</p>
<p>An ALS improvement using Deep Learning (DL) method is proposed to solve the problems above. After several training epochs of the ALS algorithm, the latent features of cell and molecule under certain concentration can be achieved by user (cell) and item (molecule) matrixes. Then the aligned features of cell and molecule are fed to a Fully Connected Neural Network (FCNN) to predict the sensitivity value.</p>
<p>A new loss function is proposed with RMSE reducing a penalty term for incorrect classification, where β is a weight parameter and n is the size of the training set, so that the model has the tendency to correctly classify the sensitivity value. Specifically when the RMSE is fixed, the loss increases as more sensitivity values are incorrectly classified thus producing a negative product of prediction and ground truth, vice versa.
loss = RM SE − β 1 n n i=1 sign (ŷi, yi) sign(x) =      1, x &gt; 0 0, x = 0 −1, x &lt; 0
A more general form of the proposed loss function is shown below, where the predictive model is tackling a k-class classification problem with classification boundaries c1, c2, ......, c k . As a brief explanation, only a prediction falls in the same interval between two adjacent classification boundaries as the ground truth will produce a positive penalty term, otherwise, negative.
loss = RM SE−β 1 n n i=1 sign k j=1 sign ((ŷi − cj) (yi − cj) − k + 1)</p>
<p>ALSDL Experiment Settings</p>
<p>The parameters of ALS in ALSDL are the same as in the former experiment. The FCNN has three hidden layers containing 20, 10, 5 neural cells respectively and an output layer of 1 neural cell. The activation functions between hidden layers are all tanh and the optimizer for back propagation is rmsprop. The weight parameter β of the loss function is 0.</p>
<ol>
<li>An ALSDL model is trained for every cell-molecule matrix and a 10-fold cross-validation is performed with 200 epochs of ALS training and another 200 epochs for FCNN training for every ALSDL model. With the restriction of the penalty term for incorrect classification, the accuracy does not decrease as loss reduces at the DL training stage. Instead, for both GR and IFD, the test accuracy is not significantly worse if not better than the training accuracy.  Table 1 shows that, for both GR and IFD, the average test loss is reduced and the average test accuracy is increased by ALSDL compared with ALS.</li>
</ol>
<p>ALSDL Result Analysis</p>
<p>Active Learning Implementation</p>
<p>With the predictive model ALSDL proposed and its effectiveness examined, the AL algorithm is to be implemented on the model to form the AL scheme as a whole. However, incompatibility occurs when common classification-based query strategies, such as the uncertainty sampling, are performed on the regression problem. In this section, a query strategy based on expected loss minimization and suitable for regression problem will be proposed followed by comparative experiment and result analysis.</p>
<p>Active Learning Prerequisites</p>
<p>Active learning (AL) is a machine learning algorithm that can train models to achieve greater accuracy or less error with relatively fewer labeled training instances. Figure 7 illustrates the procedure of poolbased AL where all the unlabeled data are maintained as a pool and are queried by query strategies till the pool is empty. Carefully designed query strategies will actively choose the most valuable unlabeled data for oracles to label, thus a more representative training set and a better-trained model can be obtained. The most common query strategies include uncertainty sampling, least confident and margin sampling [7]. </p>
<p>Query Strategy based on Expected Loss Minimization</p>
<p>To implement an AL algorithm on the predictive model, a query strategy based on the minimization of the expected loss (ELM) of the model is proposed. The core idea of ELM query strategy is to choose the unlabeled sample x + , y + from the unlabeled dataset U such that when x + , y + is removed from </p>
<p>Proposed</p>
<p>Active Learning Scheme and Experiment Settings</p>
<p>The procedures of the proposed AL scheme are as follows.</p>
<p>Initialization: Randomly choose ninit samples to be labeled as the training set D. nquery = 0.</p>
<p>Training: Train a new ALSDL predictive model on D.</p>
<p>Query: If nquery &gt; nmax q uery , terminate the scheme. Otherwise, select nper q uery samples to be added to D from the unlabeled dataset using ELM query strategy, nquery = nquery + 1, then return to procedure Training.</p>
<p>Both ninit and nper q uery are set to 40 and nmax q uery is 8. The ALSDL model has the same settings as in the former experiment. The RMSE loss and accuracy of the ALSDL model evaluated on the full dataset are recorded after every training procedure. The RMSE loss is used for new model evaluation in the ELM query strategy and is evaluated after 200 epochs of ALS training to speed up the query procedure.</p>
<p>In comparison, three other sampling methods (query strategies) are implemented to substitute ELM query strategy in the scheme. Orderly sampling resembles a manual experimental design that queries useritem matrix in a row or column order. Random sampling queries the unlabeled pool stochastically. Uncertainty sampling chooses the unseen samples with sensitivity values closest to the classification boundary.</p>
<p>Active Learning Result Analysis</p>
<p>The proposed AL scheme training curves of GR and IFD with molecule concentration of 0.01uM are shown respectively as Figure 8 and Figure 9. After 8 times of queries, with a total of 360 examples learned, the proposed ELM sampling method reaches the highest accuracy and the least loss for both GR and IFD. Compared with other query strategies, the proposed expected loss minimization query strategy constructs better predictive models more efficiently for the following aspects. The rate of convergence of ELM sampling is more rapid. With little percent of total experiment space covered, the performance of ELM sampling falls behind other sampling methods in the beginning. Then ELM soon catches up and outperforms other sampling methods as the expected test loss becoming more and more accurate. ELM sampling, whose loss function always encourages the training of a more accurate model, is more heuristically designed than orderly and random sampling. It also prevails over uncertainty sampling because the latter depends on the classification boundary that is constantly shifting with the result of the ALS model's training. With the same amount of examples queried, ELM sampling results in a predictive model of less loss and higher accuracy be-cause the queried samples are among the most valuable ones. Therefore, the optimized design of the experiment of cells' sensitivity to molecules can be achieved by the proposed AL scheme with the query strategy of expected loss minimization.</p>
<p>Conclusion</p>
<p>This article proposed an AL scheme that combines ALS, DNN and a query strategy variant for conducting scientific experiments design without prior knowledge of the properties of experimental subjects. After performing a retrospective study on a dataset of scientific experiment results, it was demonstrated that the optimization of experimental design that builds better predictive models more efficiently can be automatically reached by the AL scheme and the proposed ELM query strategy outperforms several others.</p>
<p>Due to the constraint of computational power, all the hyperparameters in this article are not heuristically tuned but manually set based on the optima of several trials. Similarly, the FCNN setting used in this article is not necessarily optimal and it requires further investigation. However, the performance should not vary significantly as the hyperparameters shift since the whole scheme is built on mature and robust algorithms.</p>
<p>The work in this article can be an inspiration for optimizing the design of automated scientific experiments, especially whose consumption of physical experimental resources is tremendous and the knowledge of experimental subjects' properties is limited, such as drug response experiments in the field of biomedicine. In the future, more datasets would be tested and more experiments would be conducted on the proposed AL scheme to further improve its generality.</p>
<p>Figure 2 :
2Heatmap visualization of the redefined dataset</p>
<p>Figure 3 :Figure 4 :
34ALS training curve of GR with molecule concentration of 0.01uM ALS training curve of IFD with molecule concentration of 0.01uM</p>
<p>Figure 5 : 01uM Figure 6 :
501uM6ALSDL training curve of GR with molecule concentration of 0.ALSDL training curve of IFD with molecule concentration of 0.01uM The ALSDL training curves of GR and IFD with molecule concentration of 0.01 uM are shown in Figure 5 and Figure 6 and the results are promising in three aspects comparing with ALS. The loss, RMSE, continues to converge at a lower value of around 0.1 for GR and around 0.02 for IFD with a significant improvement compared with ALS convergence value at 200 epochs of training. The phenomenon of overfitting is less intense as the curves of training loss and test loss almost overlap during the 200 training epochs of DL.</p>
<p>Figure 7 :
7Pool-Based Active Learning</p>
<p>U and added to the current model M 's training set D to train a new model M + , the new model produces the least test loss. The test loss is measured with the combination of D and U , i.e. the whole dataset. xELM = arg min x + ∈U loss M + , D ∪ U However, since the ground truth of y + and U 's label values are unknown, the expected new modelM + is trained with the current model M 's prediction of x + ,ŷ + and training set D, then the expected test loss ofM + is evaluated with M 's predictions of unlabeled dataÛ in substitution of U . xELM = arg min x + ∈U loss M + , D ∪ÛMultiple samples can also be obtained in one query by sorting the unlabeled samples in ascending order according to their expected loss then selecting the top ones.</p>
<p>Figure 8 : 01uM Figure 9 :
801uM9Active learning training curve of GR with molecule concentration of 0.Active learning training curve of IFD with molecule concentration of 0.01uM</p>
<p>Table 1: ALS and ALSDL average test loss and average test accuracyAverage Test Loss 
Average Test Accuracy 
ALS 
ALSDL 
ALS 
ALSDL 
GR 
0.250860068 
0.160126785 0.854432773 0.872478992 
IFD 0.0097235223 0.054959413 0.748781513 0.818277311 </p>
<p>AcknowledgementThis article would not have been finished without the valuable reference materials and lectures that I received from the professor, Dr. Robert F. Murphy of Carnegie Mellon University, whose insightful guidance and enthusiastic encouragement gave me much help in the course when I was shaping this article hence I want to show my deepest gratitude to him.I would also avail myself of this opportunity to extend my sincere thanks to the teachers from whose teaching and instruction I obtained during my undergraduate education in the School of Computer Science &amp; Engineering, South China University of Technology.Last but not least, I am much indebted to my family, without whose unconditional affection and consistent support this article could not have appeared in its final form.
Designing drug-response experiments and quantifying their results. Current protocols in chemical biology. Marc Hafner, Mario Niepel, Kartik Subramanian, Peter K Sorger, 9Marc Hafner, Mario Niepel, Kartik Subramanian, and Peter K Sorger. Designing drug-response ex- periments and quantifying their results. Current protocols in chemical biology, 9(2):96-116, 2017.</p>
<p>Study on the design and analysis methods of orthogonal experiment. Liu Ruijiang, Zhang Yewang, Wen Chongwei, Tang Jian, Experimental Technology and Management. 9Liu Ruijiang, Zhang Yewang, Wen Chongwei, and Tang Jian. Study on the design and analysis meth- ods of orthogonal experiment. Experimental Tech- nology and Management, 9:52-55, 2010.</p>
<p>Active learning literature survey. Burr Settles, Burr Settles. Active learning literature survey. 2009.</p>
<p>Breast cancer profiling project, drug sensitivity 1: Fixed-cell gr measures of 35 breast cell lines to 34 small molecule perturbagens. dataset 1 of 2: Normalized growth rate inhibition values. K Peter, Sorger, Peter K. Sorger. Breast cancer profiling project, drug sensitivity 1: Fixed-cell gr measures of 35 breast cell lines to 34 small molecule perturbagens. dataset 1 of 2: Normalized growth rate inhibition values., 2018.</p>
<p>Growth rate inhibition metrics correct for confounders in measuring sensitivity to cancer drugs. Marc Hafner, Mario Niepel, Mirra Chung, Peter K Sorger, Nature methods. 136Marc Hafner, Mario Niepel, Mirra Chung, and Peter K Sorger. Growth rate inhibition metrics correct for confounders in measuring sensitivity to cancer drugs. Nature methods, 13(6):521-527, 2016.</p>
<p>Collaborative filtering for implicit feedback datasets. Yifan Hu, Yehuda Koren, Chris Volinsky, Eighth IEEE International Conference on Data Mining. IeeeYifan Hu, Yehuda Koren, and Chris Volinsky. Col- laborative filtering for implicit feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining, pages 263-272. Ieee, 2008.</p>
<p>Active learning. morgan claypool. Burr Settles, J Ronald, Brachman, Synthesis Lectures on AI and ML. Burr Settles and Ronald J Brachman. Active learn- ing. morgan claypool. Synthesis Lectures on AI and ML, 2012.</p>            </div>
        </div>

    </div>
</body>
</html>