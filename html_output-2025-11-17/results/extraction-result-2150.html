<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2150 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2150</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2150</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-57.html">extraction-schema-57</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <p><strong>Paper ID:</strong> paper-280676831</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2508.11957v1.pdf" target="_blank">A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond</a></p>
                <p><strong>Paper Abstract:</strong> Artificial Intelligence (AI) agents have rapidly evolved from specialized, rule-based programs to versatile, learning-driven autonomous systems capable of perception, reasoning, and action in complex environments. The explosion of data, advances in deep learning, reinforcement learning, and multi-agent coordination have accelerated this transformation. Yet, designing and deploying unified AI agents that seamlessly integrate cognition, planning, and interaction remains a grand challenge. In this review, we systematically examine the architectural principles, foundational components, and emergent paradigms that define the landscape of contemporary AI agents. We synthesize insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and large language model-based reasoning. Moreover, we discuss the pressing ethical, safety, and interpretability concerns associated with deploying these agents in real-world scenarios. By highlighting major breakthroughs, persistent challenges, and promising research directions, this review aims to guide the next generation of AI agent systems toward more robust, adaptable, and trustworthy autonomous intelligence.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2150.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2150.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Automated Lab Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated laboratories and scientific discovery agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Autonomous agent-driven laboratory systems that design, execute, and analyze experiments (often combining robotics, planning, and ML) to accelerate hypothesis generation and scientific discovery in biology, chemistry, and materials science. The review describes them as systems that can propose experiments, run robotic protocols, analyze results, and suggest follow-up hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Automated laboratory / scientific discovery agents</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>multi-agent robotic + ML pipeline (LLM/ML-driven planning + robotics)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>biology, chemistry, materials science, general scientific research</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>experimental protocols, hypotheses, candidate materials/compounds, experimental conditions, data analyses and proposed follow-up experiments</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>primarily experimental testing in physical laboratories (robotic execution of experiments), analysis of measured outcomes, comparison to prior known results, and human expert review; simulation and in-silico screening used as preliminary validation in some workflows</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>qualitative (novelty assessed by proposing experiments or hypotheses not present in prior datasets, expert judgement, and whether results diverge from established literature); the review notes lack of standardized quantitative novelty-distance metrics</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Reported qualitatively: such systems can accelerate lab throughput and surface plausible novel hypotheses; review cites demonstrations of automation improving speed and throughput but does not provide numeric success rates; performance is said to be strong for routine or well-characterized assay spaces and degrades for novel experimental regimes</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation relies on actual experiments and expert adjudication; review does not report numeric accuracy metrics, but emphasizes that experimental validation is resource-intensive and that many candidate outputs fail when tested—especially those that are more novel</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Validation reliability declines for higher-novelty outputs: novel hypotheses/protocols more frequently fail experimental validation or require extensive human review; the review explicitly notes difficulties validating out-of-distribution discoveries</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Yes — the review highlights an asymmetry where generation (hypothesis/idea production) outpaces reliable validation (experimental confirmation); generation can propose many plausible-seeming outputs while validation is slow, expensive, and often rejects novel proposals</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Degraded: agents trained in existing assay/chemical/material spaces transfer poorly to out-of-distribution experimental conditions, often requiring re-training or additional human-guided refinement</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Poorly characterized and typically weak; agents often lack calibrated uncertainty estimates for novel experimental proposals, and confidence tends to be unreliable on OOD outputs</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>High (experimental resources, robotics, reagents, lab time) compared to relatively low computational cost for generating proposals; cost ratio increases with novelty because novel proposals need bespoke validation and troubleshooting</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>robot-in-the-loop experimental pipelines, human-in-the-loop review, integrated simulation/surrogate models for pre-screening, multi-agent coordination to triage experiments, and callouts to need for standardized benchmarks and evaluation protocols</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Automated lab agents can generate hypotheses and experimental protocols rapidly, but experimental validation is resource-intensive and less reliable for novel outputs; the review identifies a generation-validation gap where many generated discoveries require expensive human/experimental confirmation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2150.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A project referenced in the review that attempts end-to-end automation of scientific research — from idea generation to experiment and publication — using agentic systems. The review cites it as an ambitious example of an automated research agent that faces challenges like hallucinations and explainability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Scientist</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based multi-component research agent (planning + experiment orchestration + analysis) integrated with lab automation</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>general scientific research (emphasis on automated open-ended discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>research ideas, experimental designs, protocols, analyses, and paper-style outputs (results and discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>physical experiment execution (where applicable), result analysis, and human-in-the-loop review; the review notes ongoing difficulties with ensuring generated claims are experimentally validated and reproducible</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>not standardized in the referenced project per the review; novelty generally judged by proposing ideas beyond training corpus and by experimental confirmation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Reported qualitatively: capable of producing end-to-end research artifacts in demonstrations, but suffers from hallucinations and reproducibility issues; the review does not include quantitative success rates</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Limited and variable — many generated claims require human validation; the system struggles to consistently validate high-novelty claims without human oversight</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Strong negative effect: the more novel the generated research claim, the less reliable automated validation is, according to the review</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Yes — the review uses AI Scientist to illustrate that autonomous generation is feasible but that automatic, trustworthy validation lags behind</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Poor: performance and reliability drop on tasks/discoveries that lie outside prior training or demonstration domains</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Noted as weak; confidence or claimed certainty from such agents is not well-calibrated for novel claims</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>High when experiments are required; textual/analytic validation is cheaper but insufficient for novel empirical claims</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>improved interpretability, rigorous experimental automation, human-in-the-loop verification, and better uncertainty estimation; the review points to these but notes they are still research problems</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>AI Scientist-type systems demonstrate end-to-end generation potential but face substantial validation and explainability challenges; automated validation is resource-intensive and less reliable for novel discoveries.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2150.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that augments LLM agents with self-reflection: agents receive linguistic feedback and heuristic functions enabling learning from trial-and-error without extensive fine-tuning, improving reasoning and task performance across diverse tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: Language agents with verbal reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based agent with reinforcement-learning-like self-reflection loop (verbal feedback loop)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>general reasoning and multi-task agent performance (language tasks, planning)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>improved stepwise reasoning, refined textual outputs, iterative plan generation and correction</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>intrinsic self-evaluation via heuristic feedback, task success metrics, and downstream task evaluation; reported experiments evaluate improvements on reasoning and other benchmarks rather than external experimental validation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>not explicitly formalized in the review; evaluated by task performance improvements on held-out tasks and benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Qualitative claim in review: Reflexion improves agent outputs across diverse tasks without heavy fine-tuning; no numeric success rates provided in the review</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation is primarily task-based (benchmark improvements); the review does not provide precision/recall but notes Reflexion offers better alignment and fewer failures compared to baseline prompting methods</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Not explicitly quantified in the review; Reflexion is presented as improving adaptation, but the review cautions that out-of-distribution (novel) tasks remain challenging</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Mixed — Reflexion narrows the gap by improving iterative self-correction, but full experimental validation for scientific claims remains outside its scope</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Improved relative to vanilla prompting for many tasks, but still degrades on truly novel, OOD tasks per the review's general statements about generalization limits</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported; review does not provide calibration metrics for Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>Low-to-moderate computational overhead for self-reflection loops compared to full RL fine-tuning; validation still uses task evaluation which is cheaper than physical experiments</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>self-reflection loop, linguistic feedback, iterative correction — mechanisms intended to reduce hallucinations and improve alignment without heavy fine-tuning</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Reflexion offers an approach to improve LLM-agent generation via verbal self-reflection and iterative correction, improving on baselines in benchmarks; however, it does not eliminate the need for experimental/human validation for empirical scientific claims.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2150.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain of Hindsight (CoH)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain of Hindsight aligns language models with feedback</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A training framework that incorporates past model outputs paired with feedback into sequence modeling, using masking to avoid training on feedback tokens directly; reported to align LLMs with human feedback more effectively than SFT or RLHF on tasks like summarization and dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of hindsight aligns language models with feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Chain of Hindsight (CoH)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM training/alignment method (sequence modeling with feedback masking)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>language tasks (summarization, dialogue) and LLM alignment</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>produces model outputs aligned with human feedback, improved summaries and dialog responses</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>benchmark comparisons to RLHF and SFT on summarization and dialogue datasets, human preference evaluations</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>measured by improvement over baseline alignment (human preference/metric gains); not framed as scientific novelty</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Reported in the review as significantly surpassing RLHF and baseline methods on summarization and dialogue datasets (no numeric values provided in review)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validated via dataset-based metrics and human evaluations demonstrating better alignment; the review does not report detailed numeric validation rates</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Not applicable in the scientific-discovery sense within the review; CoH improves alignment for in-domain tasks but OOD behavior not quantified</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>CoH focuses on improving generation alignment rather than independent validation mechanisms; thus it narrows generation-validation mismatch for language outputs but does not address empirical experimental validation</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not detailed in the review; generalization beyond datasets is unreported</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported in the review</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>Training with feedback sequences has additional data-processing complexity, but review does not quantify cost</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>training on historical outputs with feedback and masking to prevent learning feedback tokens directly; aligns generation more closely with human preferences</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CoH is an effective alignment technique for LLM outputs in language tasks, outperforming RLHF in cited experiments, but its role is limited to improving generation alignment rather than providing independent empirical validation for scientific discoveries.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2150.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MLR-Copilot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced system that uses LLM-based agents to autonomously conduct aspects of machine learning research (e.g., experiment setup, code generation, analysis), demonstrating automated support for research workflows in ML.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MLR-Copilot</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based agentic research assistant (code+experiment orchestration)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>machine learning research and experiment automation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>research scaffolding: experiment design, code generation, hyperparameter suggestions, result summaries and draft writeups</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>benchmarking experiments, unit tests, automated evaluation metrics (e.g., held-out performance), and developer/human review; the review notes such systems can maintain codebases and run tests</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>measured by ability to propose novel experiments or configurations not in training data and by improvements in automated ML workflow efficiency; not standardized in review</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Qualitative: capable of automating many routine ML-research tasks and producing working code/experiments, though the review warns about hallucinations and reproducibility issues</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation primarily via automated tests and ML evaluation metrics; review implies this is effective for routine tasks but insufficient for high-novelty research claims</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Automated validation is adequate for familiar/routine research tasks but degrades for novel experiments that require interpretive judgement or new evaluation protocols</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Present: MLR-Copilot can generate runnable experiments readily, but validating whether novel experiments constitute genuine scientific advancement requires human oversight</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Degrades on novel research directions not represented in its training or tested pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported; review cautions about overconfidence/hallucination risks</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>Moderate computational cost for running ML experiments; validation cost scales with experiment complexity but is generally lower than wet-lab experimental validation</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>automated testing, unit tests, CI pipelines, human-in-the-loop code review, and ensemble/reproducibility checks</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MLR-Copilot-like agents can automate many ML-research tasks and produce executable experiments, but automated validation is reliable mainly for familiar tasks and insufficient for judging novel scientific contributions without human review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2150.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LAB-Bench</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LAB-Bench: Measuring Capabilities of Language Models for Biology Research</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark and evaluation suite (referenced in the review) that measures LLM capabilities applied to biology research tasks; intended to quantify what LLMs can and cannot do in practical biology research contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LAB-Bench: Measuring Capabilities of Language Models for Biology Research</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LAB-Bench</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>benchmark / evaluation framework for LLMs in biology</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>biology research (biological data interpretation, experiment design assistance, literature synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>N/A (benchmark evaluates LLM generation of biology research artifacts such as experimental plans, literature summaries, and analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>benchmark tasks with ground-truth answers or expert-annotated evaluations, comparison to known results, and human expert scoring</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>benchmarks typically measure in-distribution task accuracy and some OOD probes; review notes need for metrics that capture novelty and scientific usefulness</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Benchmark-based: LLMs show strengths on literature synthesis and routine tasks but struggle on tasks requiring domain-specific reasoning or experimental design that is novel; paper does not include numeric metrics in review</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Benchmark validations use expert scoring and comparison to curated ground truth; review states these reveal gaps especially for novel, high-impact tasks</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Benchmarks expose reduced validation/accuracy for novel or OOD tasks; review emphasizes need for better OOD evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Benchmarks reveal that generation quality can appear high on in-distribution tasks while validation/expert acceptance for novel outputs is lower</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Typically degrades on OOD biology tasks according to reported benchmark analyses referenced in the review</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Benchmarks highlight calibration issues but review provides no numeric calibration metrics</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>Benchmark evaluation is computationally modest but human expert scoring increases cost and is required for nuanced assessment</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>benchmark-driven evaluation, task-specific human annotation, creation of OOD testbeds and standardized biological evaluation protocols</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>supports</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LAB-Bench-style evaluations show LLMs can help with routine biology tasks but are unreliable for novel experimental design; benchmarks reveal a generation-validation gap that widens for OOD tasks and novel research questions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2150.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2150.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate scientific discoveries, hypotheses, predictions, or novel outputs, and how these systems validate or assess the correctness of their generations, particularly comparing performance on novel versus familiar tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scalable Multi-Agent Lab Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scalable multi-agent lab framework for lab optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced framework that uses multiple coordinating agents to optimize laboratory experiments and workflows, leveraging multi-agent coordination to increase throughput and explore parameter spaces more effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scalable multi-agent lab framework for lab optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Scalable multi-agent lab framework</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>multi-agent coordination system integrating planning, experiment scheduling, and robotic execution</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>laboratory automation, materials/chemistry/biology experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_capability</strong></td>
                            <td>generates experiment schedules, parameter sweeps, and coordinated experimental campaigns to optimize objectives</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>iterative experimental evaluation (closed-loop lab runs), simulation-based pre-screening, and comparison of optimization outcomes to baseline lab protocols</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_measure</strong></td>
                            <td>measured by improvement in optimization metrics (throughput, objective function values) and capacity to discover previously unexplored parameter regions; explicit novelty-distance measures not described in review</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Qualitatively reported to improve lab optimization and throughput; review does not provide numeric success rates but notes enhanced exploration efficiency relative to single-agent or manual workflows</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validated via closed-loop experimental runs showing improved optimization results; robustness on novel target spaces is limited and depends on surrogate model quality</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_effect_on_validation</strong></td>
                            <td>Performance and validation reliability depend on whether surrogate models and prior data cover the target space; more novel regions yield less reliable automated validation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_asymmetry</strong></td>
                            <td>Present: coordination enables aggressive generation/exploration but experimental validation remains the bottleneck, especially in novel parameter regimes</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Degrades when optimization targets fall outside prior data distributions or the surrogate model's domain</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not characterized in review; surrogate model uncertainty estimation is implied to be important but not standardized</td>
                        </tr>
                        <tr>
                            <td><strong>validation_computational_cost</strong></td>
                            <td>Generation and planning costs are modest; experimental validation cost remains high and increases with exploratory novelty</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>gap_closing_mechanisms</strong></td>
                            <td>multi-agent orchestration to triage experiments, surrogate-model pre-screening, uncertainty-aware acquisition functions, human oversight for high-risk or novel experiments</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_type</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Multi-agent lab frameworks accelerate exploration and optimization but still face validation bottlenecks when moving into novel experimental regions; surrogate models and coordination help but do not remove need for experimental confirmation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery <em>(Rating: 2)</em></li>
                <li>LAB-Bench: Measuring Capabilities of Language Models for Biology Research <em>(Rating: 2)</em></li>
                <li>Reflexion: Language agents with verbal reinforcement learning <em>(Rating: 2)</em></li>
                <li>Chain of hindsight aligns language models with feedback <em>(Rating: 2)</em></li>
                <li>MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents <em>(Rating: 2)</em></li>
                <li>Scalable multi-agent lab framework for lab optimization <em>(Rating: 2)</em></li>
                <li>Empowering biomedical discovery with AI agents <em>(Rating: 1)</em></li>
                <li>A multi-agent-driven robotic AI chemist enabling autonomous chemical research on demand <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2150",
    "paper_id": "paper-280676831",
    "extraction_schema_id": "extraction-schema-57",
    "extracted_data": [
        {
            "name_short": "Automated Lab Agents",
            "name_full": "Automated laboratories and scientific discovery agents",
            "brief_description": "Autonomous agent-driven laboratory systems that design, execute, and analyze experiments (often combining robotics, planning, and ML) to accelerate hypothesis generation and scientific discovery in biology, chemistry, and materials science. The review describes them as systems that can propose experiments, run robotic protocols, analyze results, and suggest follow-up hypotheses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Automated laboratory / scientific discovery agents",
            "system_type": "multi-agent robotic + ML pipeline (LLM/ML-driven planning + robotics)",
            "domain": "biology, chemistry, materials science, general scientific research",
            "generation_capability": "experimental protocols, hypotheses, candidate materials/compounds, experimental conditions, data analyses and proposed follow-up experiments",
            "validation_method": "primarily experimental testing in physical laboratories (robotic execution of experiments), analysis of measured outcomes, comparison to prior known results, and human expert review; simulation and in-silico screening used as preliminary validation in some workflows",
            "novelty_measure": "qualitative (novelty assessed by proposing experiments or hypotheses not present in prior datasets, expert judgement, and whether results diverge from established literature); the review notes lack of standardized quantitative novelty-distance metrics",
            "generation_performance": "Reported qualitatively: such systems can accelerate lab throughput and surface plausible novel hypotheses; review cites demonstrations of automation improving speed and throughput but does not provide numeric success rates; performance is said to be strong for routine or well-characterized assay spaces and degrades for novel experimental regimes",
            "validation_performance": "Validation relies on actual experiments and expert adjudication; review does not report numeric accuracy metrics, but emphasizes that experimental validation is resource-intensive and that many candidate outputs fail when tested—especially those that are more novel",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Validation reliability declines for higher-novelty outputs: novel hypotheses/protocols more frequently fail experimental validation or require extensive human review; the review explicitly notes difficulties validating out-of-distribution discoveries",
            "generation_validation_asymmetry": "Yes — the review highlights an asymmetry where generation (hypothesis/idea production) outpaces reliable validation (experimental confirmation); generation can propose many plausible-seeming outputs while validation is slow, expensive, and often rejects novel proposals",
            "out_of_distribution_performance": "Degraded: agents trained in existing assay/chemical/material spaces transfer poorly to out-of-distribution experimental conditions, often requiring re-training or additional human-guided refinement",
            "calibration_quality": "Poorly characterized and typically weak; agents often lack calibrated uncertainty estimates for novel experimental proposals, and confidence tends to be unreliable on OOD outputs",
            "validation_computational_cost": "High (experimental resources, robotics, reagents, lab time) compared to relatively low computational cost for generating proposals; cost ratio increases with novelty because novel proposals need bespoke validation and troubleshooting",
            "human_validation_required": true,
            "gap_closing_mechanisms": "robot-in-the-loop experimental pipelines, human-in-the-loop review, integrated simulation/surrogate models for pre-screening, multi-agent coordination to triage experiments, and callouts to need for standardized benchmarks and evaluation protocols",
            "evidence_type": "supports",
            "key_findings": "Automated lab agents can generate hypotheses and experimental protocols rapidly, but experimental validation is resource-intensive and less reliable for novel outputs; the review identifies a generation-validation gap where many generated discoveries require expensive human/experimental confirmation.",
            "uuid": "e2150.0"
        },
        {
            "name_short": "AI Scientist",
            "name_full": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
            "brief_description": "A project referenced in the review that attempts end-to-end automation of scientific research — from idea generation to experiment and publication — using agentic systems. The review cites it as an ambitious example of an automated research agent that faces challenges like hallucinations and explainability.",
            "citation_title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
            "mention_or_use": "mention",
            "system_name": "AI Scientist",
            "system_type": "LLM-based multi-component research agent (planning + experiment orchestration + analysis) integrated with lab automation",
            "domain": "general scientific research (emphasis on automated open-ended discovery)",
            "generation_capability": "research ideas, experimental designs, protocols, analyses, and paper-style outputs (results and discussion)",
            "validation_method": "physical experiment execution (where applicable), result analysis, and human-in-the-loop review; the review notes ongoing difficulties with ensuring generated claims are experimentally validated and reproducible",
            "novelty_measure": "not standardized in the referenced project per the review; novelty generally judged by proposing ideas beyond training corpus and by experimental confirmation",
            "generation_performance": "Reported qualitatively: capable of producing end-to-end research artifacts in demonstrations, but suffers from hallucinations and reproducibility issues; the review does not include quantitative success rates",
            "validation_performance": "Limited and variable — many generated claims require human validation; the system struggles to consistently validate high-novelty claims without human oversight",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Strong negative effect: the more novel the generated research claim, the less reliable automated validation is, according to the review",
            "generation_validation_asymmetry": "Yes — the review uses AI Scientist to illustrate that autonomous generation is feasible but that automatic, trustworthy validation lags behind",
            "out_of_distribution_performance": "Poor: performance and reliability drop on tasks/discoveries that lie outside prior training or demonstration domains",
            "calibration_quality": "Noted as weak; confidence or claimed certainty from such agents is not well-calibrated for novel claims",
            "validation_computational_cost": "High when experiments are required; textual/analytic validation is cheaper but insufficient for novel empirical claims",
            "human_validation_required": true,
            "gap_closing_mechanisms": "improved interpretability, rigorous experimental automation, human-in-the-loop verification, and better uncertainty estimation; the review points to these but notes they are still research problems",
            "evidence_type": "supports",
            "key_findings": "AI Scientist-type systems demonstrate end-to-end generation potential but face substantial validation and explainability challenges; automated validation is resource-intensive and less reliable for novel discoveries.",
            "uuid": "e2150.1"
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion: Language agents with verbal reinforcement learning",
            "brief_description": "A framework that augments LLM agents with self-reflection: agents receive linguistic feedback and heuristic functions enabling learning from trial-and-error without extensive fine-tuning, improving reasoning and task performance across diverse tasks.",
            "citation_title": "Reflexion: Language agents with verbal reinforcement learning",
            "mention_or_use": "mention",
            "system_name": "Reflexion",
            "system_type": "LLM-based agent with reinforcement-learning-like self-reflection loop (verbal feedback loop)",
            "domain": "general reasoning and multi-task agent performance (language tasks, planning)",
            "generation_capability": "improved stepwise reasoning, refined textual outputs, iterative plan generation and correction",
            "validation_method": "intrinsic self-evaluation via heuristic feedback, task success metrics, and downstream task evaluation; reported experiments evaluate improvements on reasoning and other benchmarks rather than external experimental validation",
            "novelty_measure": "not explicitly formalized in the review; evaluated by task performance improvements on held-out tasks and benchmarks",
            "generation_performance": "Qualitative claim in review: Reflexion improves agent outputs across diverse tasks without heavy fine-tuning; no numeric success rates provided in the review",
            "validation_performance": "Validation is primarily task-based (benchmark improvements); the review does not provide precision/recall but notes Reflexion offers better alignment and fewer failures compared to baseline prompting methods",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Not explicitly quantified in the review; Reflexion is presented as improving adaptation, but the review cautions that out-of-distribution (novel) tasks remain challenging",
            "generation_validation_asymmetry": "Mixed — Reflexion narrows the gap by improving iterative self-correction, but full experimental validation for scientific claims remains outside its scope",
            "out_of_distribution_performance": "Improved relative to vanilla prompting for many tasks, but still degrades on truly novel, OOD tasks per the review's general statements about generalization limits",
            "calibration_quality": "Not reported; review does not provide calibration metrics for Reflexion",
            "validation_computational_cost": "Low-to-moderate computational overhead for self-reflection loops compared to full RL fine-tuning; validation still uses task evaluation which is cheaper than physical experiments",
            "human_validation_required": null,
            "gap_closing_mechanisms": "self-reflection loop, linguistic feedback, iterative correction — mechanisms intended to reduce hallucinations and improve alignment without heavy fine-tuning",
            "evidence_type": "mixed",
            "key_findings": "Reflexion offers an approach to improve LLM-agent generation via verbal self-reflection and iterative correction, improving on baselines in benchmarks; however, it does not eliminate the need for experimental/human validation for empirical scientific claims.",
            "uuid": "e2150.2"
        },
        {
            "name_short": "Chain of Hindsight (CoH)",
            "name_full": "Chain of Hindsight aligns language models with feedback",
            "brief_description": "A training framework that incorporates past model outputs paired with feedback into sequence modeling, using masking to avoid training on feedback tokens directly; reported to align LLMs with human feedback more effectively than SFT or RLHF on tasks like summarization and dialogue.",
            "citation_title": "Chain of hindsight aligns language models with feedback",
            "mention_or_use": "mention",
            "system_name": "Chain of Hindsight (CoH)",
            "system_type": "LLM training/alignment method (sequence modeling with feedback masking)",
            "domain": "language tasks (summarization, dialogue) and LLM alignment",
            "generation_capability": "produces model outputs aligned with human feedback, improved summaries and dialog responses",
            "validation_method": "benchmark comparisons to RLHF and SFT on summarization and dialogue datasets, human preference evaluations",
            "novelty_measure": "measured by improvement over baseline alignment (human preference/metric gains); not framed as scientific novelty",
            "generation_performance": "Reported in the review as significantly surpassing RLHF and baseline methods on summarization and dialogue datasets (no numeric values provided in review)",
            "validation_performance": "Validated via dataset-based metrics and human evaluations demonstrating better alignment; the review does not report detailed numeric validation rates",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Not applicable in the scientific-discovery sense within the review; CoH improves alignment for in-domain tasks but OOD behavior not quantified",
            "generation_validation_asymmetry": "CoH focuses on improving generation alignment rather than independent validation mechanisms; thus it narrows generation-validation mismatch for language outputs but does not address empirical experimental validation",
            "out_of_distribution_performance": "Not detailed in the review; generalization beyond datasets is unreported",
            "calibration_quality": "Not reported in the review",
            "validation_computational_cost": "Training with feedback sequences has additional data-processing complexity, but review does not quantify cost",
            "human_validation_required": null,
            "gap_closing_mechanisms": "training on historical outputs with feedback and masking to prevent learning feedback tokens directly; aligns generation more closely with human preferences",
            "evidence_type": "mixed",
            "key_findings": "CoH is an effective alignment technique for LLM outputs in language tasks, outperforming RLHF in cited experiments, but its role is limited to improving generation alignment rather than providing independent empirical validation for scientific discoveries.",
            "uuid": "e2150.3"
        },
        {
            "name_short": "MLR-Copilot",
            "name_full": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
            "brief_description": "A referenced system that uses LLM-based agents to autonomously conduct aspects of machine learning research (e.g., experiment setup, code generation, analysis), demonstrating automated support for research workflows in ML.",
            "citation_title": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
            "mention_or_use": "mention",
            "system_name": "MLR-Copilot",
            "system_type": "LLM-based agentic research assistant (code+experiment orchestration)",
            "domain": "machine learning research and experiment automation",
            "generation_capability": "research scaffolding: experiment design, code generation, hyperparameter suggestions, result summaries and draft writeups",
            "validation_method": "benchmarking experiments, unit tests, automated evaluation metrics (e.g., held-out performance), and developer/human review; the review notes such systems can maintain codebases and run tests",
            "novelty_measure": "measured by ability to propose novel experiments or configurations not in training data and by improvements in automated ML workflow efficiency; not standardized in review",
            "generation_performance": "Qualitative: capable of automating many routine ML-research tasks and producing working code/experiments, though the review warns about hallucinations and reproducibility issues",
            "validation_performance": "Validation primarily via automated tests and ML evaluation metrics; review implies this is effective for routine tasks but insufficient for high-novelty research claims",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Automated validation is adequate for familiar/routine research tasks but degrades for novel experiments that require interpretive judgement or new evaluation protocols",
            "generation_validation_asymmetry": "Present: MLR-Copilot can generate runnable experiments readily, but validating whether novel experiments constitute genuine scientific advancement requires human oversight",
            "out_of_distribution_performance": "Degrades on novel research directions not represented in its training or tested pipelines",
            "calibration_quality": "Not reported; review cautions about overconfidence/hallucination risks",
            "validation_computational_cost": "Moderate computational cost for running ML experiments; validation cost scales with experiment complexity but is generally lower than wet-lab experimental validation",
            "human_validation_required": true,
            "gap_closing_mechanisms": "automated testing, unit tests, CI pipelines, human-in-the-loop code review, and ensemble/reproducibility checks",
            "evidence_type": "mixed",
            "key_findings": "MLR-Copilot-like agents can automate many ML-research tasks and produce executable experiments, but automated validation is reliable mainly for familiar tasks and insufficient for judging novel scientific contributions without human review.",
            "uuid": "e2150.4"
        },
        {
            "name_short": "LAB-Bench",
            "name_full": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
            "brief_description": "A benchmark and evaluation suite (referenced in the review) that measures LLM capabilities applied to biology research tasks; intended to quantify what LLMs can and cannot do in practical biology research contexts.",
            "citation_title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
            "mention_or_use": "mention",
            "system_name": "LAB-Bench",
            "system_type": "benchmark / evaluation framework for LLMs in biology",
            "domain": "biology research (biological data interpretation, experiment design assistance, literature synthesis)",
            "generation_capability": "N/A (benchmark evaluates LLM generation of biology research artifacts such as experimental plans, literature summaries, and analysis)",
            "validation_method": "benchmark tasks with ground-truth answers or expert-annotated evaluations, comparison to known results, and human expert scoring",
            "novelty_measure": "benchmarks typically measure in-distribution task accuracy and some OOD probes; review notes need for metrics that capture novelty and scientific usefulness",
            "generation_performance": "Benchmark-based: LLMs show strengths on literature synthesis and routine tasks but struggle on tasks requiring domain-specific reasoning or experimental design that is novel; paper does not include numeric metrics in review",
            "validation_performance": "Benchmark validations use expert scoring and comparison to curated ground truth; review states these reveal gaps especially for novel, high-impact tasks",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Benchmarks expose reduced validation/accuracy for novel or OOD tasks; review emphasizes need for better OOD evaluation",
            "generation_validation_asymmetry": "Benchmarks reveal that generation quality can appear high on in-distribution tasks while validation/expert acceptance for novel outputs is lower",
            "out_of_distribution_performance": "Typically degrades on OOD biology tasks according to reported benchmark analyses referenced in the review",
            "calibration_quality": "Benchmarks highlight calibration issues but review provides no numeric calibration metrics",
            "validation_computational_cost": "Benchmark evaluation is computationally modest but human expert scoring increases cost and is required for nuanced assessment",
            "human_validation_required": true,
            "gap_closing_mechanisms": "benchmark-driven evaluation, task-specific human annotation, creation of OOD testbeds and standardized biological evaluation protocols",
            "evidence_type": "supports",
            "key_findings": "LAB-Bench-style evaluations show LLMs can help with routine biology tasks but are unreliable for novel experimental design; benchmarks reveal a generation-validation gap that widens for OOD tasks and novel research questions.",
            "uuid": "e2150.5"
        },
        {
            "name_short": "Scalable Multi-Agent Lab Framework",
            "name_full": "Scalable multi-agent lab framework for lab optimization",
            "brief_description": "A referenced framework that uses multiple coordinating agents to optimize laboratory experiments and workflows, leveraging multi-agent coordination to increase throughput and explore parameter spaces more effectively.",
            "citation_title": "Scalable multi-agent lab framework for lab optimization",
            "mention_or_use": "mention",
            "system_name": "Scalable multi-agent lab framework",
            "system_type": "multi-agent coordination system integrating planning, experiment scheduling, and robotic execution",
            "domain": "laboratory automation, materials/chemistry/biology experiments",
            "generation_capability": "generates experiment schedules, parameter sweeps, and coordinated experimental campaigns to optimize objectives",
            "validation_method": "iterative experimental evaluation (closed-loop lab runs), simulation-based pre-screening, and comparison of optimization outcomes to baseline lab protocols",
            "novelty_measure": "measured by improvement in optimization metrics (throughput, objective function values) and capacity to discover previously unexplored parameter regions; explicit novelty-distance measures not described in review",
            "generation_performance": "Qualitatively reported to improve lab optimization and throughput; review does not provide numeric success rates but notes enhanced exploration efficiency relative to single-agent or manual workflows",
            "validation_performance": "Validated via closed-loop experimental runs showing improved optimization results; robustness on novel target spaces is limited and depends on surrogate model quality",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_effect_on_validation": "Performance and validation reliability depend on whether surrogate models and prior data cover the target space; more novel regions yield less reliable automated validation",
            "generation_validation_asymmetry": "Present: coordination enables aggressive generation/exploration but experimental validation remains the bottleneck, especially in novel parameter regimes",
            "out_of_distribution_performance": "Degrades when optimization targets fall outside prior data distributions or the surrogate model's domain",
            "calibration_quality": "Not characterized in review; surrogate model uncertainty estimation is implied to be important but not standardized",
            "validation_computational_cost": "Generation and planning costs are modest; experimental validation cost remains high and increases with exploratory novelty",
            "human_validation_required": true,
            "gap_closing_mechanisms": "multi-agent orchestration to triage experiments, surrogate-model pre-screening, uncertainty-aware acquisition functions, human oversight for high-risk or novel experiments",
            "evidence_type": "mixed",
            "key_findings": "Multi-agent lab frameworks accelerate exploration and optimization but still face validation bottlenecks when moving into novel experimental regions; surrogate models and coordination help but do not remove need for experimental confirmation.",
            "uuid": "e2150.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
            "rating": 2
        },
        {
            "paper_title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
            "rating": 2
        },
        {
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Chain of hindsight aligns language models with feedback",
            "rating": 2
        },
        {
            "paper_title": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
            "rating": 2
        },
        {
            "paper_title": "Scalable multi-agent lab framework for lab optimization",
            "rating": 2
        },
        {
            "paper_title": "Empowering biomedical discovery with AI agents",
            "rating": 1
        },
        {
            "paper_title": "A multi-agent-driven robotic AI chemist enabling autonomous chemical research on demand",
            "rating": 1
        }
    ],
    "cost": 0.01827725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond
16 Aug 2025</p>
<p>Xiaodong Qu 
Andrews Damoah 
University of Maryland
College Park</p>
<p>Joshua Sherwood 
Peiyan Liu 
Christian Shun 
Independent Researcher 6
Brown University 13 University of Illinois Urbana-Champaign 14 San Francisco State University 15 Stanford University
7,9 Virginia Tech 12</p>
<p>Lulu Chen 
Minjie Shen 
Nawwaf Aleisa 
Zeyuan Hou 
Chenyu Zhang 
Lifu Gao 
Yanshu Li 
Qikai Yang 
Qun Wang 
Cristabelle De Souza 
George Washington University 
A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond
16 Aug 2025ACCBA578E047416CE108ED167FD2E6CCarXiv:2508.11957v1[cs.MA]
Artificial Intelligence (AI) agents have rapidly evolved from specialized, rule-based programs to versatile, learning-driven autonomous systems capable of perception, reasoning, and action in complex environments.The explosion of data, advances in deep learning, reinforcement learning, and multi-agent coordination have accelerated this transformation.Yet, designing and deploying unified AI agents that seamlessly integrate cognition, planning, and interaction remains a grand challenge.In this review, we systematically examine the architectural principles, foundational components, and emergent paradigms that define the landscape of contemporary AI agents.We synthesize insights from cognitive science-inspired models, hierarchical reinforcement learning frameworks, and large language model-based reasoning.Moreover, we discuss the pressing ethical, safety, and interpretability concerns associated with deploying these agents in real-world scenarios.By highlighting major breakthroughs, persistent challenges, and promising research directions, this review aims to guide the next generation of AI agent systems toward more robust, adaptable, and trustworthy autonomous intelligence.</p>
<p>Introduction</p>
<p>The development of artificial intelligence (AI) agents-autonomous systems capable of perceiving their surroundings, reasoning about possible courses of action, and executing decisions-has evolved significantly in recent decades.Early AI agents, rooted in the symbolic reasoning systems of the 1950s and 1960s, relied on hand-crafted rules and logic-based methods, excelling in constrained domains but struggling with adaptability and uncertainty [1,2].The introduction of statistical learning and probabilistic reasoning in the 1980s and 1990s enhanced reliability, while the rise of reinforcement learning (RL) allowed agents to learn policies through trial-and-error interactions [3,4,5,6].The integration of deep neural networks with RL (DeepRL) led to breakthroughs such as superhuman performance in Atari games and Go [7,8].With growing computational power, recent advancements in statistical methods and machine learning, AI agents have incorporated advanced perception, natural language sequence modeling, and cognitive-inspired principles, enabling them to adapt, collaborate, and mirror aspects of human reasoning in dynamic environments [2,9,10,11,12,13,14].</p>
<p>Contemporary AI agents are increasingly deployed in high-stakes, real-world contexts: self-driving cars navigating congested urban environments [15,16], autonomous laboratories accelerating scientific discovery [17,18], virtual assistants managing complex user queries [19], and automated trading agents operating in financial markets [20].Underpinning these successes are developments in deep learning for perception [10,11,2], reinforcement learning (RL) for decision-making [21,22], large language models (LLMs) for communication and reasoning [9,12], and multi-agent frameworks that orchestrate coordination and competition among numerous entities [8,23].</p>
<p>However, forging truly unified AI agents presents an array of open problems.Such agents must integrate perception, abstract reasoning, hierarchical planning, and flexible communication while ensuring safety, interpretability, and adherence to ethical standards.In this systematic review, we synthesize a broad literature on AI agents, examining foundational methods, current paradigms, and emerging architectures [24].We highlight key breakthroughs from cognitive-inspired models to LLM-driven reasoning engines, from hierarchical RL to multimodal sensor fusion, and from single-agent solutions to scalable multi-agent frameworks [25].</p>
<p>We also identify critical gaps and challenges.Robustness under domain shift, explainability of complex decision-making, and value alignment with human norms remain unsolved.Achieving human-level adaptability, transparency, resource efficiency, and trustworthy autonomy calls for deeper interdisciplinary research, from cognitive science to ethics, neuroscience, and economics.</p>
<p>Related Work</p>
<p>With the recent popularity of AI agents in both research and industry, alongside rapid advancements within this domain, we have begun to see an emergence of literature reviews attempting to consolidate and analyze the history and progress made within this evolving field.</p>
<p>Past Reviews on AI Agents</p>
<p>The review by Wang et al. takes a holistic approach when discussing the evolution of LLM-based agents [26].The authors focus on analyzing three main aspects including the foundations of AI agent construction, applications within various fields, and common evaluation strategies for benchmarking performance.They cover many of the core components and technology fueling AI agents, proposing a unified framework encompassing early development strategies, as well as the diverse applications of these agents in fields such as social science, natural science, and engineering.They also look at various strategies for evaluating AI agent performance, ranging from subjective evaluation, such as human annotations and Turing tests, to more objective metrics such as success rate and accuracy.Their review provides a comprehensive look into the development of AI agents and their domain applications within the current day.</p>
<p>The paper by Guo et al. conducts a similar review, focusing more on multi-agent systems, specifically for simulation research [27].The study takes an in-depth look at the fundamental aspects of multiagent systems, common domains that utilize multi-agent systems for simulations, and the challenges within this field.The authors compare differences in functionality between single-agent and multi-agent systems, specifically in the context of profiling, communications, and decision-making.They highlight the two main applications of multi-agent systems: problem-solving, which leverages collaboration to address complex tasks, and world simulation, where agents are used to replicate social environments to reproduce real-world interactions.The authors also address many of the common challenges within the field such as hallucinations, scaling, and lack of multi-modal support [28].</p>
<p>The study conducted by Xi et al. investigates the role LLMs play as foundational models for AI agents [29].Through this lens, the authors detail the origins of LLM-based agents, applications in agent-to-agent (both human and artificial) interactions, and open questions in the field.They highlight key properties that validate LLMs as suitable foundations for agentic systems, such as autonomy and adaptability.They also highlight the importance of natural language processing, a key aspect of LLMs, in an agent's ability to reason and communicate.The authors discuss the deployment of AI agents in various scenarios including single-agent, multi-agent, and human-agent settings, as well as practical applications of each.They extend this methodology to agentic societies, where multiple agents interact to create an artificial society.This framework builds upon individual agent behaviors and environments to construct fully realistic, artificial societies.</p>
<p>The work detailed in the paper by Xie et al. focuses on a review of LLM-based agents specifically in the multimodal domain [30].They highlight the impact and challenges of multimodality on design frameworks, evaluation methods, and applications.The authors discuss how the core components of an AI agent, such as the planning and memory modules, require integration of textual, image, and audio capabilities into their architectures in multimodal settings.They also discuss the need for robust evaluation methods, especially for multimodal agents, that are capable of assessing the agent's capabilities across multiple domains and how they interact to allow for complex reasons and problem-solving.The authors also discuss the extensive and diverse applications of multimodal agents in fields like autonomous driving, game development, and robotics.They emphasize the importance of multimodality in driving human-computer interaction between humans and autonomous agents by enabling their use in more complex, nuanced settings.</p>
<p>As a collective, past reviews on AI agents develop a comprehensive assessment of the technology and provide an in-depth analysis of foundational elements, diverse applications, current evaluation paradigms, and future prospects of autonomous agents.Although many of these studies are suitable for people with prior knowledge in the field, few provide a simplified framework to understand these concepts, specifically targeting new researchers.</p>
<p>Methodology</p>
<p>We conducted a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines to ensure a thorough and transparent approach.This method helped identify, screen, and select relevant studies focused on AI agents.</p>
<p>Figure 1: The PRISMA review was conducted independently by authors on each topic relating to core components, applications, and paradigm-shifting designs within the AI agent space, and combined into one diagram.</p>
<p>Search Strategy</p>
<p>Following the PRISMA guidelines, we conducted our literature review process to identify relevant papers on foundational frameworks, current trends, and breakthrough advancements in AI agent research.Employing this strategy allowed us to conduct a rigorous analysis of relevant research, aligning with methodologies utilized in previous works.We used Google Scholar to conduct our review of emergent technologies in the AI agent space and 4 application domains: business, education, science, and entertainment.All queries were conducted using search terms related to AI agents and the individual topics.Common search terms included: "Autonomous Agent", "Reinforcement Learning Agent", and "Multi-Agent System", with "AI Agent" being the prime term used across all contributors' searches.The full list of queries by topic can be found in Appendix A.</p>
<p>The review process included three stages:</p>
<ol>
<li>
<p>Google Scholar Search: The records resulting from the query were examined by page, and full pages were included in order of relevancy (by Google Scholar's algorithm) until no results on the given page were relevant, based on titles.</p>
</li>
<li>
<p>Initial Screening: Titles and abstracts were reviewed to exclude irrelevant papers.</p>
</li>
<li>
<p>Full-Text Review: Full papers were reviewed to exclude irrelevant papers.</p>
</li>
</ol>
<p>Exclusion Criteria</p>
<p>To ensure the relevance and accessibility of our selected studies, we applied a rigorous set of exclusion criteria.One of the primary considerations was the availability of the full text.Studies that were only accessible as abstracts, summaries, or paywalled content without institutional or open-access availability were excluded.This step was necessary to ensure that all reviewed studies could be thoroughly analyzed, preventing misinterpretations or incomplete evaluations based on limited information [31].Additionally, we filtered out publications that were not directly focused on AI agents or fell outside the intended scope of our review.Given the broad application of artificial intelligence across various domains, many papers may reference AI agents tangentially without providing substantial insights into their architectures, methodologies, or applications.To maintain a focused and cohesive analysis, we prioritized studies that directly contributed to AI agent research, whether in foundational theory, implementation strategies, or domain-specific applications.</p>
<p>Language accessibility was another key factor in our selection process.Since our review was conducted in English, we excluded papers published in other languages due to the potential for misinterpretation and difficulty in verifying content accuracy.While we acknowledge that valuable research exists in multiple languages, our methodology required consistency in analysis and comprehension, which was best achieved by limiting our review to English-language publications.</p>
<p>By implementing these exclusion criteria, we refined our dataset to ensure a high-quality and relevant selection of literature.Each filtered study contributed meaningfully to our analysis, helping to create a structured and comprehensive review of AI agents while avoiding redundancy and extraneous content [32].</p>
<p>Data Extraction</p>
<p>To systematically analyze the selected studies, we conducted a structured data extraction process, ensuring that each paper contributed valuable insights into AI agent research.The primary focus of this extraction was identifying the core methodologies used in AI agent development.This included examining the underlying frameworks and architectures employed in various studies, as well as the algorithms and techniques utilized for reasoning, decision-making, and adaptation.Understanding these methodological foundations allowed us to categorize and compare different approaches in AI agent design.</p>
<p>In addition to methodologies, we documented each study's key findings and contributions to the field.This involved assessing the significance of their results, novel approaches, and the broader implications for AI agent research.Whether a study introduced a new decision-making framework, improved reinforcement learning strategies, or proposed a novel integration of multi-agent coordination, we aimed to capture its unique contribution to advancing AI intelligence and autonomy [33].</p>
<p>Furthermore, we evaluated the relevance of each study to the progression of AI agent research.Studies that addressed pressing challenges, introduced paradigm-shifting ideas, or explored new application areas were given particular attention.By focusing on research that actively pushed the boundaries of AI agent capabilities, we ensured that our review highlighted the most impactful and forward-thinking work in the field.</p>
<p>Results</p>
<p>Architectures and Learning Paradigms</p>
<p>Modern AI agent architectures integrate diverse components, from memory systems to decision-making frameworks.For instance, Lilian Weng's blog provides a detailed exploration of agent architectures, emphasizing the interplay between memory, planning, and tool use.The Stanford HAI overview highlights how computational agents are beginning to exhibit human-like behaviors, underscoring their potential for real-world applications.These studies collectively illustrate the shift toward more holistic and adaptive agent designs.</p>
<p>Core Components of Modern AI Agent Architectures</p>
<p>AI agent architectures include components designed to enable perception, reasoning, decision-making, and interaction.Our review provides a deep dive of these core components, highlighting key breakthroughs and future opportunities [34].</p>
<p>The system contains four major components -memory, tools, actions and planning.Memory is divided into short-term and long-term memories, offering both contextual and enduring information.The Agent is also capable of employing a wide range of tools, such as calendars, calculators, code interpreters, and search functions to execute specialized tasks [35].Planning encompasses sophisticated techniques such as reflection, self-evaluation, chain of thought reasoning, and sub-goal breakdown, enabling the Agent to enhance its decision-making and tackle intricate challenges effectively.(see Fig. 2): Figure 2: An overview of an AI Agent's core components [36]</p>
<p>Planning</p>
<p>Inspired by classical AI planning [4], modern agents integrate symbolic and subsymbolic methods to reason about future states, causal dependencies, and long-term goals.Hierarchical RL structures decisionmaking at multiple levels of abstraction, improving sample efficiency and interpretability [37,38].Additionally, model-based RL, graph-based planning, and hybrid neural-symbolic reasoning approaches allow agents to perform sophisticated problem-solving.</p>
<p>Chain-of-thought .[39] is a milestone technique to significantly improve the ability of large language models (LLMs) to perform complex reasoning tasks.The framework provides the models with examples of step-by-step reasoning (a "chain of thought") in the prompt, guiding them to break down complex problems into intermediate steps before arriving at the final answer.This helps the model perform better on tasks requiring multi-step reasoning.</p>
<p>Agents must adapt policies over time.Reinforcement learning algorithms, from value-based methods [21] to policy gradient techniques [40,41], enable agents to learn through interaction.</p>
<p>Reflexion [42] is a framework designed to enhance AI Agents through reinforcement learning.It has a self-reflection architecture that leverages the heuristic function and linguistic feedback to improve reasoning skills.Reflexion represents a significant step forward in enabling LLM-based agents to learn from trial and error through verbal self-reflection.The framework's ability to improve performance across diverse tasks without requiring extensive fine-tuning makes it a promising approach for future research in autonomous agents.</p>
<p>Chain of Hindsight(CoH) [43] is another framework that helps LLM agents improve their outputs by training with historical datasets that contain past sequential outputs with feedback.The framework aligns large language models with human feedback more effectively than traditional methods such as supervised fine-tuning (SFT) or reinforcement learning with human feedback (RLHF).The CoH algorithm trains the model to maximize the likelihood of predicting tokens in sequences x = [x 1 , x 2 , . . ., x n ], using Figure 3: An overview of the Reflexion framework [42] a causal Transformer architecture:
logp(x) = n i=1 log p(x i | x &lt;i )
The training sequence contains model outputs combined with feedback.To make sure the model will only be trained to predict non-feedback tokens, a masking technique is adopted such that:
logp(x) = n i=1 ⊮ O(x) (x i ) log p(x i | x &lt;i )
where ⊮ O(x) (x i ) is 1 if x i is not part of the feedback and 0 otherwise.Comprehensive experiments on summarization and dialogue datasets demonstrate that CoH significantly surpasses RLHF and other baseline methods.</p>
<p>Meta-learning [44] and continual learning [45] approaches allow agents to generalize across tasks and accumulate knowledge without catastrophic forgetting.</p>
<p>Memory</p>
<p>Memory processing in AI agents is crucial for enhancing their effectiveness.Much like human memory, it enables the acquisition, storage, retention, and retrieval of information for future use [36].Memory is categorized into short-term or textual, constrained by the context window of the underlying transformer models, and long-term or parametric, encompassing declarative (facts and events) and procedural (unconscious skills) memory [46].</p>
<p>Memory-enhanced agents have demonstrated significant capabilities in maintaining context, emulating human-like behavior, and tackling complex tasks by effectively utilizing both short-term and longterm memory.However, despite these advancements, challenges remain in scalability, efficiency, and the seamless integration of external knowledge for LLM-based AI agents [48].Addressing these limitations is crucial for advancing LLM-based agents toward artificial general intelligence (AGI), enhancing their robustness and efficiency in real-world applications [49,47].</p>
<p>Tools</p>
<p>One of the hallmarks of human intelligence is the ability to use tools that reflect advanced cognitive functions such as problem-solving, adaptability, and foresight.Equipping LLMs with external tools can significantly extend model capabilities [36].In fact, LLM-based AI agents can be defined as systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they Figure 4: An overview of the sources, forms, and operations of the memory in LLM-based agents.[47] perform tasks [50].Tools are external modules that LLMs can call to gather information or perform actions.Examples include information retrieval systems, search engines, code interpreters, and robotic arms [51].The key challenges for tool-augmented LLMs, as highlighted in the paper, revolve around hallucinations, planning complexity, and input errors, which greatly impact their viability in practical settings.These challenges underscore the necessity for more rigorous adherence to API documentation, enhanced planning algorithms, and broader, more inclusive training datasets to improve the robustness and reliability of AI agents in practical, real-world applications involving tool use [52,53].</p>
<p>Perception Modules</p>
<p>Perception converts raw sensory data (e.g., images, audio, text, LiDAR scans) into structured representations.Vision backbones rely on convolutional neural networks [10,11] and vision transformers [2], while speech recognition and language processing leverage transformer-based LLMs [54,9,12].Sensor fusion merges multiple modalities to form a holistic, environmental understanding.</p>
<p>Representation and Abstraction Layers</p>
<p>Agents require compact, meaningful representations.Self-supervised and contrastive learning approaches [55,56] extract latent features from high-dimensional data.LLMs construct rich language embeddings that capture semantic and syntactic nuances, enabling agents to interpret instructions, query knowledge, and generate natural language outputs [57].</p>
<p>Planning and Reasoning Engines</p>
<p>Inspired by classical AI planning [4,58], modern agents integrate symbolic and subsymbolic methods to reason about future states, causal dependencies, and long-term goals.Hierarchical RL structures decision-making at multiple levels of abstraction, improving sample efficiency and interpretability [37,38].Additionally, model-based RL, graph-based planning, and hybrid neural-symbolic reasoning approaches allow agents to perform sophisticated problem-solving.</p>
<p>Interaction and Communication Interfaces</p>
<p>For agents to collaborate effectively, they must communicate.Natural language interfaces [9,12], emergent communication protocols in MAS [59], grounded language acquisition [60], and embodiment enable richer, more flexible multi-agent interactions and human-agent cooperation.</p>
<p>Applications of AI Agents</p>
<p>AI agents have begun to influence a broad spectrum of real-world applications, serving as critical components in complex decision-making processes and enhancing human capabilities.They integrate advances in perception, reasoning, communication, and control to provide adaptive and context-sensitive solutions that were once out of reach for traditional software systems [61,62].</p>
<p>Healthcare</p>
<p>AI agents-digital systems capable of perceiving their environment, reasoning about what they perceive, and taking actions -have begun to make a remarkable impact in healthcare [63].As medical practices face growing patient demands, clinician burnout, and data complexity, these agents promise to lighten workloads, improve care quality, and augment the clinical decision-making process.While the concept of AI in medicine has existed for decades, recent advancements in computational power, machine learning algorithms, and the availability of large, high-quality datasets have accelerated progress, transforming what was once science fiction into everyday reality.The development of AI agents in healthcare did not happen overnight.The rise of machine learning-particularly deep learning-over the past decade has dramatically changed the landscape.With the proliferation of electronic health records (EHRs), medical imaging databases [64], and wearable sensors, healthcare organizations today have unprecedented access to vast and varied datasets.This data revolution, combined with cheaper and more powerful cloud computing services, has allowed modern AI agents to become more accurate, context-aware, and integrated into existing healthcare workflows [65,66].By the late 2010s, AI agents began to show promise in detecting diseases from imaging scans, triaging patient queries, and even assisting in surgical interventions.</p>
<p>Diagnostic and Decision-Support Agents</p>
<p>Diagnostic and Decision-Support Agents AI-driven clinical decision support systems (CDSS) harness large repositories of medical knowledge and patient data to guide clinicians [67].For example, agents trained on vast numbers of radiology images can highlight suspicious regions in a chest X-ray or mammogram, alerting a physician to potential conditions [68].In dermatology, AI agents analyzing skin lesion images can help detect melanoma, while in ophthalmology, they can identify signs of diabetic retinopathy.These agents reduce the cognitive load on physicians, enhance diagnostic accuracy [69], and potentially catch conditions earlier, leading to better patient outcomes.</p>
<p>Patient-Facing Virtual Assistants and Chatbots</p>
<p>On the patient side, AI-based virtual assistants and chatbots are becoming increasingly common.These conversational agents help patients book appointments, remind them to take medication, provide educational information, and even guide them through symptom checking [70].By offering round-the-clock support, such agents improve access to care and empower patients to take more control of their health.They are especially helpful in primary care settings, where they can quickly triage simple queries and refer complex questions to healthcare professionals.</p>
<p>Robotic and Surgical AI Agents</p>
<p>Autonomous surgical robots and AI-assisted robotic surgery tools help enhance the precision and dexterity of surgeons.While these technologies still rely on human oversight, AI agents can predict tissue responses, reduce tremors in tool manipulation, and adjust strategies mid-operation for the best possible outcomes.Outside the operating room, robots equipped with AI-powered navigation systems can assist in rehabilitation centers, aiding patients with mobility issues and helping clinicians monitor progress more efficiently [71].</p>
<p>Artificial intelligencetificial intelligence agents are poised to become indispensable partners in healthcare, offering diagnostic support, patient education, and assistance with complex surgical procedures.While the road to fully realizing their potential is paved with challenges such as bias, data privacy, regulatory hurdles, and integration complexities, ongoing research and responsible innovation are making rapid progress [72].</p>
<p>Business and Industry</p>
<p>Enterprise applications of AI agents span customer service chatbots, supply chain optimization, and strategic decision support.Conversational agents handle routine inquiries, freeing human operators to address more complex tasks [19,12].AI-driven agents in operations management can forecast demand, manage inventory, and optimize logistics.Financial institutions employ agents for fraud detection, risk assessment, and algorithmic trading [20], reducing costs, improving efficiency, and enhancing overall competitiveness.</p>
<p>Customer Service and Engagement</p>
<p>AI-powered conversational agents, such as chatbots and virtual assistants are streamlining the customer experience by handling routine inquiries, resolving issues and personalizing customers.These agents enable businesses to operate 24/7, providing instant responses and freeing human agents to focus on other complex or sensitive issues.For example, having companies use AI chatbots to guide users through product selection, technical issues and managing post-purchase support [73].</p>
<p>In addition to traditional customer service roles, AI agents are now essential to marketing campaigns.They analyze customer behavior to create targeted advertisements and personalized content.By dynamically adapting to user preferences, these agents help businesses improve conversion rates and create long-term customer loyalty, overall; this empowers businesses to scale operations without compromising quality.</p>
<p>Supply Chain Optimization and Operation Management</p>
<p>AI agents are revolutionizing supply chain management by enabling efficient forecasting, inventory control, and logistics optimization.The complex and dynamic nature of modern supply chains make them an ideal application area for AI as these systems can process vast amounts of data to identify patterns, predict disruptions, and suggest corrective actions [74].</p>
<p>Predictive analytics allow businesses to forecast demand with significant accuracy.This capability helps to minimize overproduction and stockouts, leading to significant cost savings.For instance, multinational corporations like Amazon rely on AI agents to manage their inventory globally across warehouses, dynamically adjusting stock levels based on real-time sales.[75] [76] When it comes to logistics, route optimization algorithms consider variables such as traffic, weather conditions and delivery deadline to find the most efficient paths for transportation.This not only reduces fuel consumption and delivery times but also contributes to sustainability goals.[75] [76] Warehouse automation further highlights the role of AI agents.With autonomous robots powered by machine learning and computer vision technologies while managing tasks like sorting, packing and inventory auditing.These innovations reduce human error, improve throughput and enhance overall operational efficiency, making AI agents indispensable in modern supply chain ecosystems.[77].</p>
<p>Financial Decision-Making and Risk Management</p>
<p>The financial sector has embraced AI agents for their ability to analyze large datasets,identify trends and make decisions with precision and speed.AI applications in finance range from fraud detection, and credit scoring to algorithmic trading and portfolio management [78].</p>
<p>Fraud detection is a critical section for AI agents to excel.By analyzing patterns in transaction data, these systems can flag anomalies that might indicate fraudulent activity.For example, credit card companies use AI to detect unusual spending behavior in real time, notifying customers, and freezing accounts to prevent losses.These systems continuously learn and adapt, improving their ability to detect types of fraud as they emerge [79,80].</p>
<p>In credit risk assessment, AI agents evaluate an applicant's creditworthiness by analyzing traditional metrics alongside alternative data sources, such as social media activity and online behavior.This holistic approach provides lenders with deeper insights, enabling them to make more informed decisions while expanding access to credit for under banked populations [81].</p>
<p>AI agents have transformed financial trading by enabling institutions to analyze complex datasets and execute trades with precision and speed.In algorithmic trading AI systems analyze market trends, price movements and macroeconomic indicators to make split-second trading decisions that would be impossible for a human to replicate [82].These agents optimize strategies by backtesting historical data, identifying profitable patterns and adapting to real-time market changes.For example, reinforcement learning models are increasingly used in trading algorithms to improve performance by learning from past successes and failures [83,84].Such systems enhance profitability while reducing the impact of human bias and error.</p>
<p>Risk management is another important area where AI agents are proving to irreplaceable.Advanced risk models powered by machine learning can assess and predict potential market risks by analyzing diverse datasets, including volatility indices, credit spreads, and geopolitical events [85,86].By identifying correlations and anomalies that humans might overlook, these systems enable traders and portfolio managers to mitigate exposure to adverse market conditions.Additionally, AI agents are used to simulate stress-testing scenarios, helping financial institutions to prepare for extreme market events [87].This ability to provide actionable insights ensures that trading strategies remain robust and adaptive, even in highly uncertain environments.</p>
<p>Education</p>
<p>Recent efforts to implement AI agents in education have targeted elementary [88], middle [89], and upper level [90] students.These efforts target diverse areas, including healthcare [90], language learning [91], and computer science [92,93].Across these domains, use cases can be grouped into 2 main categories: elevating student engagement and reducing instructor workload.[91] identifies 3 potential strengths of AI agents in education: team teaching, personalized learning suggestions, and data-driven feedback.In their discussion of team teaching, they argue that human teachers should provide knowledge of pedagogy, subject expertise, and emotional intelligence, while the AI agent is utilized for information processing.A main limitation is that the information provided by AI agents may still not be perfectly accurate, and neurodiverse populations are not fully represented in training data [88].While acknowledging challenges, authors propose architecture guidelines for AI agent integration into education [94,95,46] and are generally optimistic about future progress in the area.</p>
<p>Student engagement</p>
<p>AI agents are commonly implemented in education with a knowledge base containing course materials [96,97].One study [92] implemented AI agents as co-learners for asynchronous learning.While the students watched tutorial videos, the agents had access to their screen and mouse movements, and students interacted with the agents through text and voice message.This resulted in improved social and cognitive presence.Cognitive presence is generally defined as meaning derived through sustained reflection and discourse; social presence is perceiving one's environment to contain others.Another project, Mentigo, [89] adaptively responds to student interactions.The agent tracks 3 parameters: creative-problem-solving stage, student state, and selected strategy; after each dialogue round, the agent determines the state and stage, and from these values chooses the appropriate strategy.</p>
<p>AI agents can also help to simulate real-world scenarios.For example, in [90], students are studying healthcare root cause analysis, and agents representing professional roles-such as pharmacist and prescriber-provides students with the opportunity to participate in more dynamic and representative simulations than they might otherwise have access to.The authors implement a mentor agent which provides feedback to the learner based on every last 5 interactions.This mentor has access to the user's interactions with all other agents, as well as the course and assignment goals, and is thus able to guide students towards the correct answer without revealing it directly: a key educator design goal for AI agents.</p>
<p>Educator workload</p>
<p>Educators often find themselves without the resources to provide personalized attention to every student.And although full AI agent integration has not yet taken place in education, several groups have identified good practices, conducted initial experiments, and created AI agents focused on education.One group [91] created a customized ChatGPT agent.In the system prompt, they provide the model with several steps to use while interacting with the student.For example, this group's focus was teaching order words, so their first step was "Explain what are order words?",part of their fifth step was "Confirm students' understanding by asking them the following multiple-choice question...", and their last step was "Ask students to describe the story of Snow White in a 5-step story and use appropriate order words to tell their story.",which is the assignment evaluated by the educator.This process can be iterative, with the educator providing feedback at chosen steps, and the agent guiding students towards meeting the goals of the provided rubric while only providing educator-approved content [98].</p>
<p>Educators may also seek AI agent assistance in managing group dynamics, such as through socially shared regulation of learning (SSRL).[99] designed an agent with the task of raising group-level metacognitive awareness as part of improving SSRL, and prompted students when their contribution was not identified as group-oriented or when there were communication issues.Although the initial experiment with the group of 52 pre-service teachers was not considered successful in promoting SSRL, this work is illustrative of the future potential AI agents may have in regulating group settings.</p>
<p>AI agents also have the potential to assist with the development of course materials.[100] presents one method, where the educator provides a set of slides, and the AI agents work to provide lecture notes and other resources dynamically based on student need.The study also supports a modified Massive Open Online Course (MOOC) format, termed MAIC (Massive AI Course) and employs teacher, assistant, classmate, analyzer, and manager agents as part of the core interaction infrastructure, with the additional option of custom agents as requested by the user.They also test their concept with 500 university volunteers and 2 courses, and find promising preliminary results [101].</p>
<p>Science and Research</p>
<p>Automated laboratories and scientific discovery agents can aid in optimizing laboratory functions by designing experiments, analyzing results, and proposing new hypotheses [102].Agents can rapidly process large datasets from genomics, proteomics, materials science, and physics, identifying patterns and suggesting novel solutions to catalyze fundamental research breakthroughs in many fields.</p>
<p>AI agents are able to contribute meaningfully to various aspects of the research process by making use of various cognitive and technical skills including, vast knowledge bases, self-management and evaluation, and communication.Research frameworks suggest AI agents can assist heavily in tasks involving data analysis, information retrieval, experimental design, and even the formulation of research questions and hypotheses.Multi-agent systems allow for interactions between individual agents while completing tasks, enabling seamless collaboration between human and AI researchers on all fronts [24,103].</p>
<p>Automated Laboratories in Biology and Chemistry</p>
<p>Research in Biology and Chemistry has seen the benefit of AI agent integration in automating laboratory functions.Leveraging their vast knowledge bases, AI agents can employ domain-specific knowledge when carrying out tasks such as experiment design and analysis of large datasets [104].This can be especially useful in materials sciences where data scarcity and comprehensive knowledge requirements can slow the research process [105].Furthermore, combining intelligent AI agent systems with robotics capabilities and laboratory hardware enables these systems to interact with the real world, automating repetitive lab work and minimizing risk when dealing with hazardous biological and chemical materials [106,107].Multi-agent systems can be utilized to conduct virtual simulations of cellular and molecular environments alongside subsequent analysis [108], accelerating scientific discovery within these fields [109].</p>
<p>AI Researchers</p>
<p>While the utilization of AI and AI agents for completing specific research tasks has been well studied, there has been a recent effort to expand these agents to assist in the research process more holistically.Current AI research agents are prevalent in computer science and machine learning research.With many LLMs already possessing programming knowledge and capabilities, LLM-based agents can be used to maintain codebases, interact with files, conduct testing, and perform more general research tasks (hypothesis formulation, results analysis and discussion, etc.), mostly out-of-the-box [110].Furthermore, Projects like the "AI Scientist" have attempted to create an agent capable of fully automating all aspects of research from generating novel research ideas to conducting experiments to publishing their findings [111].Despite their remarkable potential, many of these agents still struggle with issues present in LLMS such as hallucinations and explainability [111,112].Nevertheless, as these models improve over time and are better able to synthesize their vast amounts of knowledge, the viability of fully autonomous research agents will only grow.</p>
<p>Public Services and Urban Planning</p>
<p>AI agents also enhance public service delivery, from optimizing public transportation schedules to managing energy grids and water distribution systems.Urban planners use AI-driven simulations to forecast the impact of infrastructure projects, assess environmental policies, and develop sustainable city layouts.By integrating data from diverse sources, agents can balance competing objectives such as cost, efficiency, and social equity.</p>
<p>Land Use and Urban Resource Management</p>
<p>Sustainable urban growth requires efficient resource management and land utilization.In parks and gardens, sensors keep an eye on irrigation-related parameters to guarantee effective water use.Energy conservation is aided by smart street lighting systems that have wireless internet relay capabilities, CCTV, and energy-efficient LED lights.Geographic Information Systems (GIS) and geospatial technologies help with resource allocation and urban planning by offering insights into land use trends [113].AI helps create the best land use plans by striking a balance between environmental sustainability and development requirements.AI also facilitates the installation of green infrastructure, which reduces pollution and enhances urban sustainability [114].Examples of this include parks and green roofs.which help mitigate pollution and improve urban sustainability</p>
<p>Collaborative Decision-making AI Agents in Public Administration</p>
<p>In public administration, AI and participative sensing technologies greatly improve decision-making.By enabling people to report events or incidents in the city, participatory sensing enhances public administration's responsiveness and efficacy by sharing the reports with other users [113].AI-driven urban planning offers data-driven insights that assist planners in making well-informed choices to enhance air quality and efficiently control urban growth.Predictive models help public administration improve public safety and allocate resources effectively by forecasting high crime risk locations [115].Data-driven policymaking is supported by AI and GIS technologies, which offer insightful information for public administration and urban planning [116].Policymakers can use these insights to inform policies that minimize pollution and advance sustainable development.</p>
<p>Transport routing optimization AI agents</p>
<p>AI technologies are essential for optimizing traffic flow and minimizing congestion in urban transport routes.Parking sensors save needless travel and pollution by guiding drivers and detecting available parking places.In order to help with effective traffic management, traffic intensity monitoring devices evaluate vehicle speeds, road occupancy, and traffic volumes.AI optimizes effective transportation flows, forecasts traffic, and examines transportation patterns.Through the support of Transit-Oriented Development (TOD), artificial intelligence (AI) contributes to the development of transit networks that provide high-capacity, safe, and effective modes of transportation while lowering emissions and traffic congestion [116].Furthermore, AI applications in transportation safety improve public safety and optimize transportation routes, for example, by forecasting high-crime risk zones [115].</p>
<p>Entertainment and Creativity</p>
<p>In the 21st century, people's entertainment has dramatically shifted from traditional offline mediums to digital platforms, like social media platforms, video/music streaming services, and video games across different platforms and devices.This evolution has further been enhanced by recommendation algorithms specifically designed to personalize user experiences.Nowadays, the integration of AI-agents into the entertainment industry is becoming more popular.It's a new trend that people start using AI-agents to create a better experience for the users.In the entertainment industry, AI-agents not only generate personalized content recommendations, but also drive non-player characters in games.They can even assist in creative processes such as music composition, artwork generation, and scriptwriting as well.These creative agents leverage cutting-edge large language models and multimodal generation, along with traditional neural networks and optical character recognition techniques to support and produce results which are tailored to users' interests and needs [117].Such personalized tools opens new paths for innovative approaches to artwork creation and interactive storytelling and significantly boosts players' engagements and entertainments in games.</p>
<p>Visual Design and Storytelling</p>
<p>Artists and authors have long benefited from artificial intelligence.Tools such as text generation from ChatGPT and image creation from MidJourney and Stable Diffusion have reshaped the production of high-quality artworks and stories by aiding in the visualization of ideas, and reduction of repetitive tasks [118] This evolution of workflow is further enhanced by the integration of AI-agents, which has the ability to integrate with multiple tools simultaneously to deliver design inspirations via both visual and textual mediums [118].Additionally, there is Mimisbrunnur, which employs a mixed-initiative system to assist the writers in crafting compelling, high-quality interactive stories [119].</p>
<p>Video games</p>
<p>Video games stand as a dominating form of entertainment in modern society.Their origin can track back to the 1960s.In order to create a more living environment and interactive experience, the concept of computer-controlled non-player characters (NPCs), inspired by Dungeons and Dragons, was introduced in the late 1970s.In the early years, the decision-making process of NPCs relied heavily on algorithms like Finite State Machines, as seen with Pac-Man's ghosts, and tree-based methods like decision trees and behavior trees [120].Today, people have seen the potential power of AI-agents and therefore shifted focus toward utilizing AI-agents to create more unique and revolutionary gaming experiences for players.Projects like the Scalable, Instructable, Multiworld Agent (SIMA) aim to develop a generalized AIagent that can learn and engage with open-world games using a combination of on-screen visuals, text information as inputs, and potential user language directionss [121].Another study explores AI-agents in the game "Passcode," where the AI-agent plays the role of the "giver", providing clues for the "guesser", which is the player, to guess a randomly chose word at the beginning of the game, demonstrating AIagent's ability to understand and handle interactive tasks [122].</p>
<p>However, while there's huge potential in integrating AI-agents into the games, such a process still faces significant challenges.Currently, the behavior of AI-agent, particularly those driven by Large Language Models and neural networks, still struggles to reach the skill level of experienced human players.These AI-agents can be easily identified due to their unnatural actions and movements [123].In addition, although they can understand simple commands like "move forward" and "stop", they struggle to understand more complicated tasks [121].Nevertheless, ongoing research still promises a rapid evolution in AI-agent performance within the gaming industry.</p>
<p>Societal Impact and Considerations</p>
<p>The applications of AI agents show significant promise and, at the same time, the social aspects cannot be ignored.It is crucial to guarantee the fairness, privacy, and inclusion of individuals in the design and decision making processes of AI technologies [124,125].The public, industry leaders, and policymakers must work together to create and establish ethical principles, rules, and regulations that should be followed in the development and use of AI technologies.</p>
<p>The AI revolution has the potential to surpass the previous industrial and digital revolutions in scale and impact.While the Industrial Revolution mechanized manual tasks and the Digital Revolution automated routine mental tasks, the AI revolution has the potential to replicate and improve nearly all human cognitive functions [126].Apparently, AI agents have the most promising role in accelerating the AI revolution because they can invent new products and processes, increase efficiency, and apply them to various sectors.</p>
<p>However, with these promising opportunities, the AI revolution, driven by the rise of advanced AI agents, would bring significant challenges that governments and societies must address.AI agents, with their ability to automate not just routine but also complex cognitive tasks, can accelerate job displacement across industries.Their integration could disproportionately impact workers whose skills are rendered obsolete, amplifying skill mismatches and economic disruptions, particularly in regions heavily reliant on automation-vulnerable sectors [126].Furthermore, as AI agents become integral in decision-making processes, the economic gains they generate are likely to concentrate among those who develop and control these systems, exacerbating wealth inequality both within and across nations.</p>
<p>Unlike traditional large language models, AI agents operate autonomously and adapt over time, which makes accountability far more complex.Pin down who or what is responsible for an agent's decisions or actions becomes increasingly difficult as its behavior evolves.Because these agents can interact directly with people, other systems, and even their surroundings, their influence tends to be much broader and more systemic.This amplifies both their potential impact and the risk of unintended outcomes.</p>
<p>To address the social impacts brought by AI Agents, it is important to develop standardized evaluation methods that ensure consistency and reliability in assessing potential harms and benefits.Transparency in AI development, data usage, and deployment must be established to build trust.Inclusive policies and equitable resource distribution are crucial to mitigating harms and reducing disparities.Furthermore, promoting ethical AI development requires attention to cultural and contextual differences, ensuring that AI systems respect diverse values [127].</p>
<p>In summary, AI agents are transforming a wide range of domains, improving efficiency, accessibility, and personalization.As these agents mature, they hold the potential to address grand challenges in healthcare, education, sustainability, and beyond, provided that developers and stakeholders maintain a steadfast commitment to ethical and human-centric design.Governments should also play a critical role in establishing clear regulatory frameworks, promoting equitable access to AI technologies, and ensuring accountability to safeguard societal interests while fostering innovation.</p>
<p>AI Agent Design</p>
<p>The development of next-generation AI agents:</p>
<p>Cognitive-Inspired Architectures</p>
<p>Hybrid models that combine symbolic reasoning with neural networks are heavily inspired by human cognitive processes, where both structured reasoning and adaptive learning coexist.By leveraging the compositionality and hierarchical structure inherent in symbolic representations, these architectures not only enhance interpretability but also improve generalization capabilities across diverse tasks [13,128].</p>
<p>These models excel in domains requiring precise reasoning, such as scientific discovery, automated theorem proving, and natural language understanding, where traditional deep learning approaches struggle with ambiguity or long-range dependencies [14].The integration of neural networks enables these hybrid systems to process unstructured data like images, audio, and text, while symbolic components offer a framework for logic, abstraction, and transfer learning.</p>
<p>Recent advances in hybrid architectures have shown promise in areas such as program synthesis, where symbolic reasoning is used for code generation and verification, and robotics, where symbolic planning enhances decision-making in dynamic environments.Future research is expected to focus on scalable implementations of these systems and developing methods to dynamically balance symbolic and neural components for optimal performance in real-world applications [128].</p>
<p>Hierarchical and Modular Approaches</p>
<p>Decomposing complex tasks into manageable subtasks and leveraging modular architectures fosters scalability, reusability, and system stability.Hierarchical frameworks enable AI agents to break down highlevel goals into smaller, more tractable components, streamlining task execution and improving performance.Modular architectures, on the other hand, allow for the development of specialized submodules, each dedicated to a specific functionality, thereby promoting adaptability and efficient resource allocation.</p>
<p>These approaches also enhance interpretability by allowing researchers and practitioners to understand the role and behavior of individual modules, which is particularly critical in safety-critical domains like autonomous vehicles, healthcare, and robotics.Additionally, modular systems simplify failure diagnosis, as issues can often be traced back to specific components rather than requiring analysis of the entire system.</p>
<p>Recent advances have demonstrated the utility of hierarchical and modular designs in reinforcement learning, natural language processing, and robotics.For instance, hierarchical reinforcement learning algorithms decompose decision-making processes into macro-actions, enabling agents to solve long-horizon tasks more effectively.Similarly, modular neural networks in natural language processing have been employed to handle tasks like machine translation, sentiment analysis, and summarization within a unified framework.</p>
<p>Moving forward, future research should focus on enhancing the dynamic interplay between hierarchical control layers and modular subsystems, enabling AI agents to seamlessly adapt to new and unforeseen challenges.Efforts to integrate these approaches with techniques such as meta-learning and transfer learning hold promise for creating robust, scalable, and generalizable AI agents capable of operating in complex, real-world environments [129,130].</p>
<p>Discussion</p>
<p>Discussion and a Step-by-Step Guide</p>
<p>For newcomers, AI agent research can seem overwhelming due to its interdisciplinary nature.This section provides a structured path to help researchers gain foundational knowledge and practical experience.Given its breadth and interdisciplinary nature, newcomers often struggle to find a structured learning path.This guide provides an approach to help researchers navigate challenges, build foundational knowledge, and develop impactful projects.</p>
<p>Step 1: Build a Strong Theoretical Foundation Developing a solid theoretical foundation is the first step.Understanding how AI agents perceive, make decisions, and act is essential before implementation.Topics such as reinforcement learning, multiagent coordination, planning, and decision theory provide a necessary framework.</p>
<p>Foundational works such as Multi-Agent Systems: A Survey and Reinforcement Learning: An Introduction [6] help researchers grasp core AI agent architectures and methodologies.Online courses and research blogs, such as Lilian Weng's Blog [36], provide accessible explanations of advanced topics like memory-augmented neural networks and tool-augmented learning.</p>
<p>Beyond theory, implementing simple reinforcement learning algorithms in controlled environments is crucial.OpenAI Gym and similar frameworks allow hands-on experimentation, helping researchers develop an intuitive understanding of AI agent behavior.Starting with basic agents for navigation, decision-making, and task automation reinforces theoretical knowledge through direct application [131].</p>
<p>Step 2: Focus on Measurable Projects AI agent research requires clear success metrics.Unlike traditional supervised learning, AI agents operate in dynamic environments where evaluation methods differ.Researchers should begin with structured projects that allow controlled experimentation and measurable outcomes.</p>
<p>Single-agent reinforcement learning tasks, such as autonomous navigation and game-playing, provide an excellent starting point.Evaluating performance through reward signals, convergence rates, and task completion times ensures systematic progress tracking.For those interested in multi-agent research, simulation platforms such as CARLA [132] and PettingZoo [133] offer controlled settings to study collaborative and competitive agent behaviors.</p>
<p>Defining evaluation metrics early ensures research remains focused and reproducible.Whether optimizing decision policies, improving sample efficiency, or enhancing interpretability, measurable goals help refine research directions and improve experimental reproducibility.</p>
<p>Step 3: Gain Practical Experience with Tools and Iterative Learning Hands-on experience with AI agent frameworks is essential for moving beyond theoretical learning.Simulation environments such as RoboCup Soccer Simulation [134] and CARLA [132] allow structured experimentation without extensive development, enabling researchers to focus on agent decision-making, coordination, and adaptability [135].</p>
<p>AI agents learn through repeated interactions rather than fixed datasets.Iterative learning techniques, such as reinforcement learning with self-reflection and hierarchical RL [36], help refine agent behavior.Adjusting hyperparameters, modifying architectures, and fine-tuning reward functions improve learning efficiency and stability.</p>
<p>Engagement with open-source AI communities accelerates learning.Platforms like GitHub host repositories with baseline models and experimental frameworks, allowing new researchers to explore existing implementations and contribute to ongoing projects.Reproducing research paper results is another valuable exercise, helping researchers understand the nuances of implementation and evaluation [136].</p>
<p>Step 4. Leverage Open-Source Communities and Reproducibility.</p>
<p>Engagement with open-source projects accelerates learning and fosters collaboration.Sharing project code and insights within the community not only enhances reproducibility but also allows researchers to build on each other's work.Platforms like GitHub host numerous repositories for AI agent research, providing access to baseline models and implementations that can serve as starting points for new projects.Projects like CARLA and PettingZoo provide a variety of tools including access to simulation environments, assets, models, and step-by-step instructions, enabling a straightforward process for replicating experiments and streamlining iteration upon existing work [132,133].Projects like RoboCup Soccer Simulation leverage open-source competitions to drive community engagement and accelerate development of cutting-edge AI agent systems.By actively contributing to these communities, researchers can stay informed about emerging trends and gain feedback on their work [137].</p>
<p>Step 5. Address Broader Research Gaps.</p>
<p>The novelty of AI agents means that many areas remain underexplored.Researchers should identify gaps in the literature, such as the integration of advanced planning algorithms with tool-augmented LLMs or the use of hybrid symbolic-subsymbolic approaches for better interpretability [138,13].Exploring these areas can lead to groundbreaking contributions and help establish best practices for the field.</p>
<p>Challenges and Limitations</p>
<p>Despite substantial progress, significant hurdles remain that limit their potential [139].This section examines critical areas of concern, including safety, interpretability, ethics, generalization and acability, and highlights the need for interdisciplinary efforts to address these issues:</p>
<p>Safety and Robustness</p>
<p>Among these, ensuring safety and robustness in dynamic environments is a persistent hurdle.AI agents often struggle with adapting changes in the environment, particularly when exposed to scenarios or data that differ significantly from their training.These vulnerabilities are further compounded by the potential for adversarial attacks, where minor input perturbations can drastically alter agent behavior.resilience to variability and ensure reliable performance even under extreme conditions Agents often exhibit sensitivity to distributional shifts, adversarial perturbations, and environment changes [140].Ensuring safe operation in open-ended and uncertain settings requires improved robustness techniques, formal verification, and worst-case guarantees under extreme conditions.</p>
<p>Explainability and Interpretability</p>
<p>As agents grow more complex, their decision-making processes become opaque [141].This lack of interpretability poses significant challenges in fostering user trust, debugging errors, and complying with regulatory requirements, especially in domains such as finance and medicine.Tools for model introspection, attention visualization, causal attribution, and symbolic distillation have been proposed as potential solutions [142].These approaches aim to provide clear insight into agent decision-making, enabling stakeholders to better assess and trust system's outputs.However, current methods remain limited and require further refinement to align with practical needs of end-users and regulatory frameworks.</p>
<p>Ethical and Social Considerations</p>
<p>The deployment of AI agents in sensitive domains introduces ethical and social challenges.Issues such as bias, fairness, privacy, and accountability are pressing concerns as agents often inherit biases present from their training data, perpetuating social inequalities [125,124].For example, the MDPI review on AI agent challenges discusses these concerns in detail, emphasizing the need for transparent evaluation methods and robust regulatory frameworks.Aligning agents with human values, establishing standards for responsible AI, and developing frameworks for ethical oversight will be crucial as agents increasingly connect and interact with social systems.Without these safeguards, the widespread deployment of AI agents could exacerbate existing disparities and raise concerns about their impact on human autonomy and rights [143,144].</p>
<p>Generalization and Transfer</p>
<p>Many agents struggle with out-of-distribution generalization, requiring extensive retraining for new tasks or domains, often requiring extensive training to operate effectively in different environments.This lack of transferability undermines their utility in real-world applications, where agents must adapt quickly to novel scenarios [145].For example, an agent trained in a simulated environment may fail to perform effectively in a real-deployment due to subtle but critical differences between two contexts.Advancing methods for domain adaptation, transfer learning, and task-agnostic representations will be essential for creating versatile and agile agents capable of functioning in diverse and unpredictable conditions [146,147].</p>
<p>Scalability and Resource Efficiency</p>
<p>Training and deploying state-of-the-art models can be computationally and energy-intensive which represents a barrier to scalability and accessibility.Modern AI agents often require extensive resources, limiting their deployment to organizations with substantial computational infrastructure [148].Additionally, the environmental impact of these systems raises concerns about sustainability.Research on model compression, efficient architectures, and distributed learning paradigms aims to reduce resource footprints without sacrificing performance.These advancements are necessary to make AI agents more accessible to smaller organizations and environmentally sustainable for widespread adoption [149,150,151].</p>
<p>Future Directions and Emerging Opportunities</p>
<p>Despite current challenges in the field of AI agents, several promising frontiers offer opportunities for future advancements in this area.Therefore, this section explores some of these potential applications where AI agents could support and enhance research and production [152]:</p>
<p>Neuroscience-Inspired Mechanisms</p>
<p>Recent studies have applied principles from neuroscience into deep learning, particularly focusing on how neurons in the brain utilize cost functions to adapt to diverse contexts by changing their properties.This integration has demonstrated utility in enhancing the performance of deep learning models [138].Consequently, this direction worth future attention to dive deeper into the adoption of additional neuroscience paradigms, including predictive coding, dendritic computations, and synaptic plasticity, into AI agents.Such integration could potentially yield more stable, interpretable, and efficient learning mechanisms [153].</p>
<p>Interactive and Continual Learning</p>
<p>Traditional machine learning approaches are mainly designed for static environments, such as training models to classify predefined categories or to play specific games.A significant drawback of these methods is catastrophic forgetting, where models lose previously learned concepts when exposed to new data or features [154].In response, research has examined the concept of continual learning, an architecture that involves learning from an endless stream of data while retaining previous knowledge [44,155].This approach has proven useful for machine learning models for keeping a long-term memory on learned features, suggesting that it could enable AI agents to refine their knowledge base through iterative feedback, human demonstrations, and structured curricula, and consequentially making them more robust and versatile [156,45,157].</p>
<p>Hybrid Symbolic-Subsymbolic Models</p>
<p>Symbolic and subsymbolic models represent the two primary types of AI models, categorized by their background features like reasoning and knowledge storage mechanisms.Both types has demonstrated significant success in performing specific tasks [158,159,160].Given these strengths, it is worthwhile to explore the integration of these methodologies and leveraging the advantages of both.We believe such an approach of blending the transparency and structure of symbolic reasoning with the pattern recognition capabilities of deep neural networks holds the potential for robust generalization, interpretability, and efficiency [13,14].</p>
<p>Multi-Agent Governance and Coordination</p>
<p>The architecture of AI agents inherently involves the collaboration of multiple agents, each possessing unique features and advantages.As the scale of an AI agent system grows, the number of participants would increase [161].Thus, the governance and coordination of these agents -which includes task allocation, negotiation protocols, and data race management -are crucial to the system's performance.Studies have indicated that by implementing suitable protocols within multi-agent deep learning models, system performance can be enhanced [23,162,163].Therefore, it is essential to conduct future research focused on these coordination mechanisms to advance the performance of AI agents [164,165].</p>
<p>Conclusion</p>
<p>AI agents have transformed from specialized, rule-bound systems to increasingly integrated, autonomous entities that perceive, reason, act, and collaborate.This review surveyed the historical evolution, core architectural components, and emerging paradigms that define contemporary AI agents.We discussed breakthroughs in reinforcement learning, large language models, hierarchical planning, and embodied intelligence.Yet, critical challenges persist: improving safety, interpretability, and ethical stewardship, as well as achieving robust generalization and resource efficiency [166,167,153].</p>
<p>The path forward demands interdisciplinary engagement.Insights from cognitive science, neuroscience, sociology, economics, and ethics will inform next-generation agents.By prioritizing human values, transparency, and long-term adaptability, we can usher in an era where AI agents serve as trustworthy partners in scientific research, industrial automation, healthcare, education, and beyond.With sustained collaboration and careful innovation, the future of AI agents holds the promise of more capable, responsible, and beneficial autonomous intelligence [168,169].</p>
<p>Competing InterestsThe author declares no competing interests.A AppendixThe first 4 queries were used to query Google Scholar and the last query was used to query Papers with Code:Business: ("AI Agent" OR "ML Agent" OR "Deep Learning Agent" OR "Autonomous Agent" OR "Automated AI" OR "Generative AI Agent" OR "Reinforcement Learning Agent" OR "Intelligent Agent" OR "Multi-Agent System") AND ("Business" OR "Industry" OR "Industrial Applications" OR "Manufacturing" OR "Production" OR "Supply Chain" OR "Logistics" OR "Automation" OR "Process Optimization" OR "Predictive Maintenance" OR "Operations Management" OR "Enterprise AI" OR "Decision-Making in Industry" OR "Industrial AI")" Education: ('AI Agent') AND ('Education') AND ('Learning' OR 'Teaching') AND ('Classroom' OR 'Critical Thinking' OR 'Curriculum' OR 'Synchronous') AND ('Resource') Science: ("AI Agent" OR "Agent" OR "Autonomous Agent" OR "ML Agent" OR "Multi-Agent System" OR "Reinforcement Learning Agent" OR "LLM-Based Agent") AND ("AI Scientist" OR "AI Researcher" OR "Autonomous Researcher" OR "Autonomous Laboratory" OR "Scientific Discovery Agent") Entertainment: ("AI Agent" OR "AI-Assisted") AND ("Entertainment" OR "Design" OR "Game" OR "Storytelling") Social Impact: ("AI Agent" OR "Generative AI") AND ("Social Impact" OR "Society" OR "Social Implications") Papers with Code: "AI Agent"
Multiagent systems: A survey from a machine learning perspective. Peter Stone, Manuela Veloso, Autonomous Robots. 832000</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. Alexey , ICLR2021</p>
<p>The Fifth Generation: Artificial Intelligence and Japan's Computer Challenge to the World. Edward A Feigenbaum, Pamela Mccorduck, 1983Addison-Wesley</p>
<p>Automated Planning: Theory and Practice. Malik Ghallab, Dana Nau, Paolo Traverso, Elsevier. 2004</p>
<p>Reinforcement learning: A survey. Leslie Pack, Kaelbling Michael L Littman, Andrew W Moore, Journal of artificial intelligence research. 41996</p>
<p>Reinforcement Learning: An Introduction. S Richard, Andrew G Sutton, Barto, 2018MIT press</p>
<p>Mastering the game of go with deep neural networks and tree search. David , Nature. 5292016</p>
<p>Mastering the game of go without human knowledge. David , Nature. 5502017</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob , NAACL-HLT. 2019</p>
<p>Imagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Communications of the ACM. 6062017</p>
<p>Deep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. 2016</p>
<p>Language models are few-shot learners. B Tom, NeurIPS. 332020</p>
<p>Building machines that learn and think like people. Brenden M Lake, Joshua B Tomer D Ullman, Samuel J Tenenbaum, Gershman, Behavioral and Brain Sciences. 40e2532017</p>
<p>The next decade in ai: Four steps towards robust artificial intelligence. Medium. Gary Marcus, 2020</p>
<p>Textsquare: Scaling up text-centric visual instruction tuning. Jingqun Tang, Chunhui Lin, Zhen Zhao, Shu Wei, Binghong Wu, Qi Liu, Hao Feng, Yang Li, Siqi Wang, Lei Liao, arXiv:2404.128032024arXiv preprint</p>
<p>A survey of motion planning and control techniques for self-driving urban vehicles. Brian Paden, Michal Čáp, Zheng Sze, Denis Yong, Emilio Yershov, Frazzoli, IEEE Transactions on Intelligent Vehicles. 112016</p>
<p>Configurable robotic platform for automated synthesis. Guillaume Philip J Kitson, John S Marie, Paulo Fossey, Leroy Jesus, Cronin, Nature. 5492017</p>
<p>Harmonizing visual text comprehension and generation. Zhen Zhao, Jingqun Tang, Binghong Wu, Chunhui Lin, Shu Wei, Hao Liu, Xin Tan, Zhizhong Zhang, Can Huang, Yuan Xie, arXiv:2407.163642024arXiv preprint</p>
<p>Gokhan Tür, Renato De Mori, Spoken Language Understanding: Systems for Extracting Semantic Information from Speech. Wiley2011</p>
<p>Deep direct reinforcement learning for financial signal representation and trading. Yue Deng, Feng Bao, Youyong Kong, Zhiquan Ren, Qionghai Dai, IEEE transactions on neural networks and learning systems. 201728</p>
<p>Human-level control through deep reinforcement learning. Volodymyr, Nature. 5182015</p>
<p>Playing atari with deep reinforcement learning. Volodymyr Mnih, Koray Kavukcuoglu, David Silver, NIPS Deep Learning Workshop. 2013</p>
<p>Mean field multi-agent reinforcement learning. Yaodong, International Conference on Machine Learning. 2018</p>
<p>Acellular fish skin grafts in the treatment of diabetic wounds: Advantages and clinical translation. Chenyu Zhao, Mengyi Feng, Martin Gluchman, Xianghe Ma, Jinhao Li, Hui Wang, Journal of Diabetes. 165e135542024</p>
<p>Cosbin: cosine score-based iterative normalization of biologically diverse samples. Chiung-Ting Wu, Minjie Shen, Dongping Du, Zuolin Cheng, Sarah J Parker, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, Bioinformatics Advances. 21762022</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Jirong Wen, Frontiers of Computer Science. 186186345March 2024</p>
<p>Large Language Model based Multi-Agents: A Survey of Progress and Challenges. Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, arXiv:2402.01680April 2024</p>
<p>Fdnet: Fourier transform guided dual-channel underwater image enhancement diffusion network. Zhen Zhu, Xiaobo Li, Qianwen Ma, Jingsheng Zhai, Haofeng Hu, Science China Technological Sciences. 68111004032025</p>
<p>Xipeng Qiu, Xuanjing Huang, and Tao Gui. The Rise and Potential of Large Language Model Based Agents: A Survey. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang ; Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, arXiv:2309.07864Junzhe Wang,. September 2023</p>
<p>Large Multimodal Agents: A Survey. Junlin Xie, Zhihong Chen, Ruifei Zhang, Xiang Wan, Guanbin Li, arXiv:2402.15116February 2024</p>
<p>Cot: an efficient python tool for detecting marker genes among many subtypes. Yingzhou Lu, Chiung-Ting Wu, Sarah J Parker, Lulu Chen, Georgia Saylor, Jennifer E Van Eyk, David M Herrington, Yue Wang, bioRxiv. 2021</p>
<p>Is llama 3 good at identifying emotion? a comprehensive study. Jinran Zhang, Zhelu Mai, Zhuoer Xu, Zhaomin Xiao, Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI), MLMI '24. the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI), MLMI '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>The application of deep learning in the whole potato production chain: A comprehensive review. Rui-Feng Wang, Wen-Hao Su, Agriculture. 14812252024</p>
<p>Self-supervised transformer-based pre-training method with general plant infection dataset. Zhengle Wang, Ruifeng Wang, Minjuan Wang, Tianyun Lai, Man Zhang, Chinese Conference on Pattern Recognition and Computer Vision (PRCV). Springer2024</p>
<p>Fine-grained control of generative data augmentation in iot sensing. Tianshi Wang, Qikai Yang, Ruijie Wang, Dachun Sun, Jinyang Li, Yizhuo Chen, Yigong Hu, Chaoqi Yang, Tomoyoshi Kimura, Denizhan Kara, Advances in Neural Information Processing Systems. 202537</p>
<p>Llm-powered autonomous agents. lilianweng.github.io. Lilian Weng, Jun 2023</p>
<p>Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic NeurIPS. D Tejas, 2016</p>
<p>Learning quickly to plan quickly using modular meta-learning. Rohan Chitnis, Tom Silver, Tomas Lozano-Pérez, ICRA. 2021</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason , NeurIPS. 2022</p>
<p>John , arXiv:1707.06347Proximal policy optimization algorithms. 2017</p>
<p>Tuomas, arXiv:1812.05905Soft actor-critic algorithms and applications. 2018</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202436</p>
<p>Chain of hindsight aligns language models with feedback. Hao Liu, Carmelo Sferrazza, Pieter Abbeel, arXiv:2302.026762023arXiv preprint</p>
<p>Model-agnostic meta-learning for fast adaptation of deep networks. Chelsea Finn, Pieter Abbeel, Sergey Levine, ICML. 2017</p>
<p>A continual learning survey: Defying forgetting in classification tasks. Matthias , IEEE TPAMI. 4472022</p>
<p>Ai agent for education: Von neumann multi-agent system framework. Yuan-Hao Jiang, Ruijia Li, Yizhou Zhou, Changyong Qi, Hanglei Hu, Yuang Wei, Bo Jiang, Yonghe Wu, Proceedings of the 28th Global Chinese Conference on Computers in Education (GCCCE 2024). the 28th Global Chinese Conference on Computers in Education (GCCCE 2024)2024</p>
<p>Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, Ji-Rong Wen, arXiv:2404.13501A survey on the memory mechanism of large language model based agents. 2024arXiv preprint</p>
<p>Conflictbank: A benchmark for evaluating the influence of knowledge conflicts in llm. Zhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, Yu Cheng, 2024</p>
<p>From theory to play: A review of eeg-controlled directional games and evaluation of custom-developed bci games. Wensi Xie, Jingwen Dou, Yiran Wang, Xiaodong Qu, 2025</p>
<p>Building effective agents. Anthropic, 2024-12-20</p>
<p>Augmented language models: a survey. Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Timo Baptiste Rozière, Jane Schick, Asli Dwivedi-Yu, Celikyilmaz, arXiv:2302.078422023arXiv preprint</p>
<p>Short interest trend prediction with large language models. Zhaomin Xiao, Zhelu Mai, Yachen Cui, Zhuoer Xu, Jiancheng Li, Proceedings of the 2024 International Conference on Innovation in Artificial Intelligence, ICIAI '24. the 2024 International Conference on Innovation in Artificial Intelligence, ICIAI '24New York, NY, USAAssociation for Computing Machinery20241</p>
<p>Api-bank: A comprehensive benchmark for tool-augmented llms. Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, Yongbin Li, arXiv:2304.082442023arXiv preprint</p>
<p>Few could be better than all: Feature sampling and grouping for scene text detection. Jingqun Tang, Wenqing Zhang, Hongye Liu, Mingkun Yang, Bo Jiang, Guanglong Hu, Xiang Bai, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>A simple framework for contrastive learning of visual representations. Ting, ICML. 2020</p>
<p>Optimal boxes: boosting end-to-end scene text recognition by adjusting annotated bounding boxes via reinforcement learning. Jingqun Tang, Wenming Qian, Luchuan Song, Xiena Dong, Lan Li, Xiang Bai, European Conference on Computer Vision. Springer2022</p>
<p>Short interest trend prediction. Zhaomin Xiao, Zhelu Mai, Zhuoer Xu, Youngkwang Kwon, Jiancheng Li, 2024 6th International Conference on Natural Language Processing (ICNLP). 2024</p>
<p>Active disturbance rejection control-new trends in agricultural cybernetics in the future: A comprehensive review. Yu-Hao Tu, Rui-Feng Wang, Wen-Hao Su, Machines. 1321112025</p>
<p>Emergent multi-agent communication in the deep learning era. Angeliki Lazaridou, Marco Baroni, Neural Computation. 3152019</p>
<p>Experience grounds language. Yonatan, EMNLP. 2020</p>
<p>Zilinghan Li, Shilan He, Ze Yang, Minseok Ryu, Kibaek Kim, Ravi Madduri, arXiv:2409.11585Advances in appfl: A comprehensive and extensible federated learning framework. 2024arXiv preprint</p>
<p>Individual variations in glycemic responses to carbohydrates and underlying metabolic physiology. Yue Wu, Ben Ehlert, Ahmed A Metwally, Dalia Perelman, Heyjun Park, Andrew Wallace Brooks, Fahim Abbasi, Basil Michael, Alessandra Celli, Caroline Bejikian, Nature Medicine. 2025</p>
<p>iddn: determining trans-omics network structure and rewiring with integrative differential dependency networks. Yizhi Wang, Yi Fu, Zhen Zhang, Robert Clarke, Sarah J Parker, David M Herrington, Guoqiang Yu, Yue Wang, Bioinformatics Advances. 51862025</p>
<p>A two-step bayesian mendelian randomization study on cholecystitis and dermatitis. medRxiv. Chenyu Zhao, Changqian Cen, Ruihan Zhang, Wenjin He, Yiyang Jiao, Zhuoya Chen, Zhaoqi Wu, Ting Luan, 2024</p>
<p>Advancing eeg-based gaze prediction using depthwise separable convolution and enhanced pre-processing. Tural Matthew L Key, Xiaodong Mehtiyev, Qu, International Conference on Human-Computer Interaction. Springer2024</p>
<p>Data-driven detection of subtype-specific differentially expressed genes. Lulu Chen, Yingzhou Lu, Chiung-Ting Wu, Robert Clarke, Guoqiang Yu, Jennifer E Van Eyk, David M Herrington, Yue Wang, Scientific reports. 1113322021</p>
<p>The multi-omic, multi-tissue response to acute endurance and resistance exercise: Results from the molecular transducers of physical activity consortium. Daniel Katz, Christopher Jin, Gregory Smith, Natalie Clark, Gayatri Iyer, Hasmik Keshishian, Patrick Hart, James Sanford, Zidong Zhang, Yongchao Ge, Circulation. 15012024Suppl</p>
<p>Enhancing eye-tracking performance through multitask learning transformer. Weigeng Li, Neng Zhou, Xiaodong Qu, International Conference on Human-Computer Interaction. Springer2024</p>
<p>Predicting 30-day hospital readmission in medicare patients insights from an lstm deep learning model. Xintao Li, Sibei Liu, Dezhi Yu, Yang Zhang, Xiaoyu Liu, 2024 3rd International Conference on Cloud Computing, Big Data Application and Software Engineering (CBASE). 2024</p>
<p>Abds: tool suite for analyzing biologically diverse samples. Dongping Du, Saurabh Bhardwaj, Sarah J Parker, Zuolin Cheng, Zhen Zhang, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, bioRxiv. 2023</p>
<p>Yi Fu, Yingzhou Lu, Yizhi Wang, Bai Zhang, Zhen Zhang, Guoqiang Yu, Chunyu Liu, Robert Clarke, David M Herrington, Yue Wang, Ddn3. 0: Determining significant rewiring of biological network structure with differential dependency networks. 2024e376</p>
<p>Can speculative sampling accelerate react without compromising reasoning quality?. Han Xu, Jingyang Ye, Yutong Li, Haipeng Chen, 2024In The Second Tiny Papers Track at ICLR 2024</p>
<p>Applications of artificial intelligence on customer experience and service quality of the banking sector. M Satheesh, Samala Nagaraj, International Management Review. 1712021</p>
<p>Embracing the informative missingness and silent gene in analyzing biologically diverse samples. Dongping Du, Saurabh Bhardwaj, Yizhi Wang, Sarah J Parker, Zhen Zhang, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, Scientific Reports. 141282652024</p>
<p>Logistics and supply chain management. Martin Christopher, 2022PearsonUk</p>
<p>Application of artificial intelligence in automation of supply chain management. Rupa Dash, Mark Mcmurtrey, Carl Rebman, Upendra K Kar, Journal of Strategic Innovation and Sustainability. 1432019</p>
<p>The AI advantage: How to put the artificial intelligence revolution to work. H Thomas, Davenport, 2018mit Press</p>
<p>Application of an ann and lstm-based ensemble model for stock market prediction. Fang Liu, Shaobo Guo, Qianwen Xing, Xinye Sha, Ying Chen, Yuhui Jin, Qi Zheng, Chang Yu, 2024 IEEE 7th International Conference on Information Systems and Computer Aided Education (ICISCAE). IEEE2024</p>
<p>Artificial intelligence and fraud detection. Innovative Technology at the Interface of Finance and Operations: Volume I. Yang Bao, Gilles Hilary, Bin Ke, 2022</p>
<p>Application of ai in real-time credit risk detection. Zhuqi Wang, Qinghe Zhang, Zhuopei Cheng, 2025</p>
<p>Regression and forecasting of us stock returns based on lstm. Shicheng Zhou, Zizhou Zhang, Rong Zhang, Yuchen Yin, Chia Hong, Chang , Qinyan Shen, arXiv:2502.052102025arXiv preprint</p>
<p>Algorithmic trading. Giuseppe Nuti, Mahnoosh Mirghaemi, Philip Treleaven, Chaiyakorn Yingsaeree, Computer. 44112011</p>
<p>Optimized credit score prediction via an ensemble model and smoteenn integration. Yu Cheng, Liyang Wang, Xinye Sha, Qiyuan Tian, Fang Liu, Qianwen Xing, Hao Wang, Chang Yu, 2024 IEEE 7th International Conference on Information Systems and Computer Aided Education (ICISCAE). 2024</p>
<p>Ad placement optimization algorithm combined with machine learning in internet e-commerce. Haoyang Feng, Yuan Gao, 2025</p>
<p>A survey of multi-agent system approach in risk assessment. Mustafa Hamid Hassan, Salama A Mostafa, Aida Mustapha, Mohd Helmy Abd, Danial Md Wahab, Nor, 2018 International Symposium on Agent, Multi-Agent Systems and Robotics (ISAMSR). IEEE2018</p>
<p>Detection of ai deepfake and fraud in online payments using gan-based models. Zong Ke, Shicheng Zhou, Yining Zhou, Chia Hong, Chang , Rong Zhang, arXiv:2501.070332025arXiv preprint</p>
<p>Deep learning in the stock market-a systematic survey of practice, backtesting, and applications. Kenniy Olorunnimbe, Herna Viktor, Artificial Intelligence Review. 5632023</p>
<p>Using an artificial intelligence (ai) agent to support teacher instruction and student learning. Lisa A Dieker, Rebecca Hines, Ilene Wilkins, Charles Hughes, Karyn Hawkins Scott, Shaunn Smith, Kathleen Ingraham, Kamran Ali, Tiffanie Zaugg, Sachin Shah, Journal of Special Education Preparation. 422024</p>
<p>An intelligent agent for mentoring students in the creative problem solving process. Siyu Zha, Yujia Liu, Chengbo Zheng, X U Jiaqi, Fuze Yu, Jiangtao Gong, Yingqing Xu Mentigo, arXiv:2409.142282024arXiv preprint</p>
<p>Mohammed As' ad. Intelligent tutoring systems, generative artificial intelligence (ai), and healthcare agents: A proof of concept and dual-layer approach. Cureus. 169e697102024</p>
<p>Teachers' agency in the era of llm and generative ai. Yu-Ju Lan, Nian-Shing Chen, Educational Technology &amp; Society. 2712024I-XVIII</p>
<p>Generative co-learners: Enhancing cognitive and social presence of students in asynchronous learning with generative ai. Tianjia Wang, Tong Wu, Huayi Liu, Chris Brown, Yan Chen, arXiv:2410.043652024arXiv preprint</p>
<p>Exploring ai music generation: A review of deep learning algorithms and datasets for undergraduate researchers. Isshin Yunoki, Guy Berreby, D' Nicholas, Yuhua Andrea, Xiaodong Lu, Qu, International Conference on Human-Computer Interaction. Springer2023</p>
<p>Foundation models for education: Promises and prospects. Tianlong Xu, Richard Tong, Jing Liang, Xing Fan, Haoyang Li, Qingsong Wen, arXiv:2405.109592024arXiv preprint</p>
<p>Ai agents in education: An early systematic review of emerging roles, potential, and limitations. Olimpius Istrate, Revista de Pedagogie Digitala. 312024</p>
<p>Design and implementation of an ethical ai-based teaching assistant for iot security education. Matilda Isaacs, Anwar Majeed, Karim Moussa, Dolapo Shodipo, African Journal of Inter/Multidisciplinary Studies. 612024</p>
<p>Transforming education: A modern ai-driven approach for enhancing student engagement in higher education. Malni Kumarathunga, 2024</p>
<p>Generative ai tools in higher education: A meta-analysis of cognitive impact. Xiaodong Qu, Joshua Sherwood, Peiyan Liu, Nawwaf Aleisa, Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems2025</p>
<p>Human-ai collaboration: Designing artificial agents to facilitate socially shared regulation among learners. Justin Edwards, Andy Nguyen, Joni Lämsä, Marta Sobocinski, Ridwan Whitehead, Belle Dang, Anni-Sofia Roberts, Sanna Järvelä, British Journal of Educational Technology. 2024</p>
<p>From mooc to maic: Reshaping online teaching and learning through llm-driven agents. Jifan Yu, Zheyuan Zhang, Daniel Zhang-Li, Shangqing Tu, Zhanxin Hao, Rui Miao Li, Haoxuan Li, Yuanchun Wang, Hanming Li, Linlu Gong, arXiv:2409.035122024arXiv preprint</p>
<p>A systematic review of machine learning approaches for detecting deceptive activities on social media: Methods, challenges, and biases. Yunchong Liu, Xiaorui Shen, Yeyubei Zhang, Zhongyan Wang, Yexin Tian, Jianglai Dai, Yuchen Cao, 2024</p>
<p>Scalable multi-agent lab framework for lab optimization. A , Gilad Kusne, Austin Mcdannald, Matter. 66June 2023</p>
<p>Towards a science exocortex. Kevin G Yager, Digital Discovery. 3102024Royal Society of Chemistry</p>
<p>Towards AI Research Agents in the Chemical Sciences. Ofer Shir, January 2024</p>
<p>Large-language models: The game-changers for materials science research. Songlin Yu, Nian Ran, Jianjun Liu, Artificial Intelligence Chemistry. 22100076December 2024</p>
<p>A multi-agent-driven robotic AI chemist enabling autonomous chemical research on demand. Tao Song, Man Luo, Linjiang Chen, Yan Huang, Qing Zhu, Daobin Liu, Baicheng Zhang, Gang Zou, Fei Zhang, Weiwei Shang, Jun Jiang, Yi Luo, July 2024</p>
<p>The Digital Lab Facility Manager: Automating operations of research laboratories through. Simon D Rihm, Wilson Yong Ren Tan, Ang, Yee Hou, Xinhong Quek, Michael Deng, Jiaru Teguh Laksana, Sebastian Bai, Jethro Mosbach, Markus Akroyd, Kraft, The World Avatar". Nexus. 13September 2024Publisher</p>
<p>Cot: an efficient and accurate method for detecting marker genes among many subtypes. Yingzhou Lu, Chiung-Ting Wu, Sarah J Parker, Zuolin Cheng, Georgia Saylor, Jennifer E Van Eyk, Guoqiang Yu, Robert Clarke, David M Herrington, Yue Wang, Bioinformatics Advances. 21372022</p>
<p>Empowering biomedical discovery with AI agents. Shanghua Gao, Ada Fang, Yepeng Huang, Valentina Giunchiglia, Ayush Noori, Jonathan Richard Schwarz, Yasha Ektefaie, Jovana Kondic, Marinka Zitnik, Cell. 18722October 2024Elsevier</p>
<p>MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents. Ruochen Li, Teerth Patel, Qingyun Wang, Xinya Du, arXiv:2408.14033September 2024</p>
<p>Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha, arXiv:2408.06292The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery. September 2024</p>
<p>Rodriques. LAB-Bench: Measuring Capabilities of Language Models for Biology Research. Jon M Laurent, Joseph D Janizek, Michael Ruzo, Michaela M Hinks, Michael J Hammerling, Siddharth Narayanan, Manvitha Ponnapati, Andrew D White, G Samuel, arXiv:2407.10362July 2024</p>
<p>Iot-enabled smart cities: Evolution and outlook. Martin Bauer, Luis Sanchez, Jaeseung Song, Sensors. 211345112021</p>
<p>Exploring diverse methods in visual question answering. Panfeng Li, Qikai Yang, Xieming Geng, Wenjing Zhou, Zhicheng Ding, Yi Nian, 2024 5th International Conference on Electronic Communication and Artificial Intelligence (ICECAI). IEEE2024</p>
<p>The application of artificial intelligence in public administration for forecasting high crime risk transportation areas in urban environment. N Georgios, Kouziokas, Transportation research procedia. 242017</p>
<p>Urban design and pollution using ai: Implications for urban development in china. Xinyue Zheng, Zhenya Ma, Zhao Yuang, Heliyon. 10182024</p>
<p>AI and the future of entertainment technology. Markus Schatten, </p>
<p>DesignGPT: Multi-agent collaboration in design. Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, Chunlei Chai, 2023 16th International Symposium on Computational Intelligence and Design (ISCID). </p>
<p>Mimisbrunnur: AI-assisted authoring for interactive storytelling. Ingibergur Stefnisson, David Thue, 14</p>
<p>Non-player character decision-making in computer games. Kaya Muhtar C ¸agkan Uludaglı, Oguz, 56</p>
<p>. Maria Sima Team, Arun Abi Raad, Catarina Ahuja, Frederic Barros, Andrew Besse, Adrian Bolt, Bethanie Bolton, Brownfield, Buttimore, Scaling instructable agents across many simulated worlds</p>
<p>Mental models of AI agents in a cooperative game setting. Katy Ilonka Gero, Zahra Ashktorab, Casey Dugan, Qian Pan, James Johnson, Werner Geyer, Maria Ruiz, Sarah Miller, David R Millen, Murray Campbell, Sadhana Kumaravel, Wei Zhang, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, CHI '20. the 2020 CHI Conference on Human Factors in Computing Systems, CHI '20Association for Computing Machinery</p>
<p>Agent-based players for a first-person entertainmentbased real-time artificial environment. Lawrence B Holder, G Michael Youngblood, </p>
<p>The ethics of ai ethics: An evaluation of guidelines. Minds and Machines. Thilo Hagendorff, 202030</p>
<p>The global landscape of ai ethics guidelines. Anna Jobin, Marcello Ienca, Effy Vayena, Nature Machine Intelligence. 12019</p>
<p>The forthcoming artificial intelligence (ai) revolution: Its impact on society and firms. Spyros Makridakis, Futures. 902017</p>
<p>Evaluating the social impact of generative ai systems in systems and society. Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal Daumé, Iii , Jesse Dodge, Isabella Duan, arXiv:2306.059492023arXiv preprint</p>
<p>Mapping the molecular progression of human coronary atherosclerosis confirms key role of smooth muscle cell phenotype and highlights novel regulators of phenotypic fate. Sarah Parker, Chunhong Mao, Yizhi Wang, Austin Seals, Do-Kyun Kim, Yingzhou Lu, Dongping Du, Genesio Karere, David Caudell, Circulation. 15012024Suppl</p>
<p>Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Ting, ICLR2023</p>
<p>Learning knowledge graphs with language models: A survey. Yu Li, Tengfei Ma, Shengyu Zhu, arXiv:2301.010372023</p>
<p>Enhance image-to-image generation with llava-generated prompts. Zhicheng Ding, Panfeng Li, Qikai Yang, Siyang Li, 2024 5th International Conference on Information Science, Parallel and Distributed Systems (ISPDS). IEEE2024</p>
<p>. Carla Carla, 2025autonomous driving simulator</p>
<p>Pettingzoo (multi-agent reinforcement learning environments. Farama Foundation. 2024</p>
<p>Robocup soccer simulator. The RoboCup Soccer Simulator2025</p>
<p>Amazon-m2 product recommendation in underrepresented locales using chatgpt4o-mini and gemini models. Qicheng Chen, Xiaodong Qu, International Conference on Human-Computer Interaction. Springer2025</p>
<p>Artificial intelligence-aided digital twin design: A systematic review. Nan Hao, Yuangang Li, Kecheng Liu, Songtao Liu, Bohao Xu, Chenhao Li, Jintai Chen, Ling Yue, Tianfan Fu, 2024Preprints</p>
<p>Hades: Hardware accelerated decoding for efficient speculation in large language models. Ze Yang, Yihong Jin, Xinhe Xu, arXiv:2412.199252024arXiv preprint</p>
<p>Toward an integration of deep learning and neuroscience. Greg Adam H Marblestone, Konrad P Wayne, Kording, Frontiers in Computational Neuroscience. 10942016</p>
<p>Optimization and application of cloud-based deep learning architecture for multi-source data prediction. Yang Zhang, Fa Wang, Xin Huang, Xintao Li, Sibei Liu, Hansong Zhang, 2024</p>
<p>Dario , arXiv:1606.06565Concrete problems in ai safety. 2016</p>
<p>Towards a rigorous science of interpretable machine learning. Finale Doshi, - Velez, Been Kim, arXiv:1702.086082017</p>
<p>Enhance wound healing monitoring through a thermal imaging based smartphone app. Steven Yi, Adam Yee, John Harmon, Frank Meng, Saurabh Hinduja, Medical imaging 2018: Imaging informatics for healthcare, research, and applications. SPIE201810579</p>
<p>Large language models for forecasting and anomaly detection: A systematic literature review. Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, Junhong Lin, arXiv:2402.103502024arXiv preprint</p>
<p>Scam detection for ethereum smart contracts: Leveraging graph representation learning for secure blockchain. Yihong Jin, Ze Yang, arXiv:2412.123702024arXiv preprint</p>
<p>Towards domain-agnostic and open-domain generalization of vision and language agents. Yanli, NeurIPS. 2021</p>
<p>Seamcarver: Llm-enhanced content-aware image resizing. Dong Liu, Yanxuan Yu, Lianghao Tan, Wenjun Wu, Bide Zhao, Zichao Li, Bingjie Lu, Yijie Wen, 2024</p>
<p>Relax: Reinforcement learning agent explainer for arbitrary predictive models. Ziheng Chen, Fabrizio Silvestri, Jia Wang, He Zhu, Hongshik Ahn, Gabriele Tolomei, Proceedings of the 31st ACM international conference on information &amp; knowledge management. the 31st ACM international conference on information &amp; knowledge management2022</p>
<p>Energy and policy considerations for deep learning in nlp. Emma Strubell, Ananya Ganesh, Andrew Mccallum, ACL. 2019</p>
<p>Tkil: Tangent kernel optimization for class balanced incremental learning. Jinlin Xiang, Eli Shlizerman, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Zikai Zhang, Suman Rath, Jiaohao Xu, Tingsong Xiao, arXiv:2409.10764Federated learning for smart grid: A survey on applications and potential vulnerabilities. 2024arXiv preprint</p>
<p>Measuring digitalization capabilities using machine learning. Jinglan Yang, Jianghuai Liu, Zheng Yao, Chaoqun Ma, Research in International Business and Finance. 701023802024</p>
<p>Blockchain governance: a bibliometric study and content analysis. Jinglan Yang, Chaoqun Ma, Shisong Hsiao, Jianghuai Liu, Technology Analysis &amp; Strategic Management. 002024</p>
<p>Towards foundation-modelbased multiagent system to accelerate ai for social impact. Yunfan Zhao, Niclas Boehmer, Aparna Taneja, Milind Tambe, arXiv:2412.078802024arXiv preprint</p>
<p>Association of composite dietary antioxidant index with circadian syndrome: evidence from nhanes. Chen Chen, Chenyu Zhao, Hongyu Jin, Zhiping Jiang, Wei Wang, Wen-Yang Li, Frontiers in Nutrition. 1115013522025</p>
<p>Incremental learning meets transfer learning: Application to multi-site prostate mri segmentation. Chenyu You, Jinlin Xiang, Kun Su, Xiaoran Zhang, Siyuan Dong, John Onofrey, Lawrence Staib, James S Duncan, International Workshop on Distributed, Collaborative, and Federated Learning. Springer2022</p>
<p>Zhihao Lin, Qi Zhang, Zhen Tian, Peizhuo Yu, Ziyang Ye, Hanyang Zhuang, Jianglin Lan, Slam2: Simultaneous localization and multimode mapping for indoor dynamic environments. Pattern Recognition. 2025158111054</p>
<p>Sparsebf: Enhancing scalability and efficiency for sparsely filled privacy-preserving record linkage. Han Xu, Yuhong Shao, Kareem Benaissa, Yutong Li, Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge Management2024</p>
<p>Multiple distresses detection for asphalt pavement using improved you only look once algorithm based on convolutional neural network. Han-Cheng Dan, Peng Yan, Jiawei Tan, Yinchao Zhou, Bingjie Lu, International Journal of Pavement Engineering. 25123081692024</p>
<p>Dpl-slam: enhancing dynamic point-line slam through dense semantic methods. Zhihao Lin, Qi Zhang, Zhen Tian, Peizhuo Yu, Jianglin Lan, IEEE Sensors Journal. 2024</p>
<p>Gradient ga: Gradient genetic algorithm for drug molecular design. Chris Zhuang, Debadyuti Mukherjee, Tianfan Fu, Ruqi Zhang, arXiv:2502.098602025arXiv preprint</p>
<p>Political-llm: Large language models in political science. Lincan Li, Jiaqi Li, Catherine Chen, Fred Gui, Hongjia Yang, Chenxiao Yu, Zhengguang Wang, Jianing Cai, Junlong , Aaron Zhou, Bolin Shen, arXiv:2412.068642024arXiv preprint</p>
<p>Enhancing thyroid disease prediction using machine learning: A comparative study of ensemble models and class balancing 2025. Jiachen Zhong, Yiting Wang, </p>
<p>An-Lan Wang, Bin Shan, Wei Shi, Kun-Yu Lin, Xiang Fei, Guozhi Tang, Lei Liao, Jingqun Tang, Can Huang, Wei-Shi Zheng, arXiv:2408.12928Pargo: Bridging vision-language with partial and global views. 2024arXiv preprint</p>
<p>Ct-patchtst: Channel-time patch time-series transformer for long-term renewable energy forecasting. Menghao Huo, Kuan Lu, Yuxiao Li, Qiang Zhu, 2025</p>
<p>Flockjs: A browsernative game engine integrating webgpu and peer-to-peer networking for scalable multiplayer experiences. Faris Jiwad, Owen Wolff, Omar Barabandi, Laith Najjab, Xiaodong Qu, </p>
<p>Podb: A learning-based polarimetric object detection benchmark for road scenes in adverse weather conditions. Zhen Zhu, Xiaobo Li, Jingsheng Zhai, Haofeng Hu, Information Fusion. 1081023852024</p>
<p>Explain the explainer: Interpreting model-agnostic counterfactual explanations of a deep reinforcement learning agent. Ziheng Chen, Fabrizio Silvestri, Gabriele Tolomei, Jia Wang, He Zhu, Hongshik Ahn, IEEE Transactions on Artificial Intelligence. 542022</p>
<p>Estimate-then-optimize versus integrated-estimation-optimization versus sample average approximation: a stochastic dominance perspective. Henry Adam N Elmachtoub, Haofeng Lam, Yunfan Zhang, Zhao, arXiv:2304.068332023arXiv preprint</p>
<p>Towards real-time and personalized code generation. Han Xu, Xingyuan Wang, Haipeng Chen, Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge Management2024</p>            </div>
        </div>

    </div>
</body>
</html>