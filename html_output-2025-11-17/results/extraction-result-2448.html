<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2448 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2448</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2448</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-64.html">extraction-schema-64</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <p><strong>Paper ID:</strong> paper-82e29e97049170c7ebbe11dd30cddd641835b970</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/82e29e97049170c7ebbe11dd30cddd641835b970" target="_blank">Augmenting Scientific Creativity with Retrieval across Knowledge Domains</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> An exploratory search system in which end-users can select a portion of text core to their interest from a paper abstract and retrieve papers that have a high similarity to the user-selected core aspect but differ in terms of domains.</p>
                <p><strong>Paper Abstract:</strong> Exposure to ideas in domains outside a scientist's own may benefit her in reformulating existing research problems in novel ways and discovering new application domains for existing solution ideas. While improved performance in scholarly search engines can help scientists efficiently identify relevant advances in domains they may already be familiar with, it may fall short of helping them explore diverse ideas \textit{outside} such domains. In this paper we explore the design of systems aimed at augmenting the end-user ability in cross-domain exploration with flexible query specification. To this end, we develop an exploratory search system in which end-users can select a portion of text core to their interest from a paper abstract and retrieve papers that have a high similarity to the user-selected core aspect but differ in terms of domains. Furthermore, end-users can `zoom in' to specific domain clusters to retrieve more papers from them and understand nuanced differences within the clusters. Our case studies with scientists uncover opportunities and design implications for systems aimed at facilitating cross-domain exploration and inspiration.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2448.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2448.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cross-domain Faceted QbE Prototype</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cross-domain exploratory search prototype using faceted Query-by-Example with global and local clustering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interactive retrieval system that indexes sentences of papers and returns sentences similar to a user-selected query sentence while controlling for domain distance via automatically built global clusters (SPECTER+KMeans) and query-specific local clustering; intended to augment scientific creativity by surfacing cross-domain analogs and enabling zoom-in exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Cross-domain exploratory search prototype (sentence-level faceted QbE with global + local clusters)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The system represents documents at the sentence level using a pre-trained sentence encoder (sentence-transformers all-mpnet-base-v2) and builds global domain clusters by KMeans on SPECTER document embeddings (|G| = 20). For a query abstract and a user-selected sentence sg, the sentence is embedded and the T nearest sentences are retrieved from each per-cluster approximate nearest-neighbor index (HNSW/FAISS). Users may select subsets of global clusters Gs and 'zoom in' by retrieving L > T nearest sentences from those clusters and re-clustering into M local clusters to reveal nuanced variations. Cluster descriptors are derived from TF-IDF unigrams. The system is a retrieval-based inspiration tool (not a generative LLM) designed to surface potentially novel analogs across domain boundaries while letting the user control distance and scope.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>materials science / general scientific research (exploratory cross-domain retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>interdisciplinary synthesis / open-ended exploration</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Human novelty annotation collected during case studies using a 3-level scale (1: 'I have seen this exact paper before'; 2: 'I have not seen this exact paper but similar ideas before'; 3: 'I have not seen anything like this before'); conceptual control of novelty via 'domain distance' implemented as selection of global clusters (clusters intended to represent domains) and by promoting diversity across clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Binary relevance label (participants marked retrieved papers as relevant or not) collected alongside novelty; no explicit quantitative feasibility/likelihood metric reported.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Qualitative evidence only: authors and participants describe a 'sweet spot' of distance (not too near, not too far) where results are useful and inspiring; participants sometimes initially rejected very-different results but found value after zooming in; no quantitative trade-off measurements reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>User-driven control: selection of a query sentence (faceted QbE), selection of global clusters to control domain distance, and zoom-in local clustering to inspect nuanced subtopics; no explicit automated multi-objective optimization or weighted balancing of novelty vs feasibility is implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Case studies with three materials-science researchers (think-aloud interviews). Results were qualitative: participants reported more diverse results compared to their chosen baselines and that the system helped surface novel application domains and hidden assumptions; participants used the ternary novelty scale and binary relevance to rate examples, but no aggregated numeric novelty/relevance statistics were reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Participant-selected baselines used for comparison in case studies (ConnectedPapers, SciFinder, Google Scholar).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Qualitative comparisons: participants said baseline systems were better for narrowly focused, domain-specific retrieval, while the prototype provided complementary value by surfacing diverse, cross-domain inspirations. No quantitative comparison of novelty/feasibility was reported (only qualitative user feedback).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Materials-science case studies: examples include surfacing papers from domains like electrochromic mirrors (optics) and orthopedic implants that share mechanisms with battery materials; zooming-in revealed nuanced mechanistic trade-offs (e.g., doping vs sintering temperature impacts), helping participants discover cross-domain solutions and hidden assumptions in their fields.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2448.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Faceted QbE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Faceted Query-by-Example</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A query paradigm where a user provides an example document and selects a textual facet (e.g., a sentence) that defines the aspect to be matched; retrieval is conditioned on that selected aspect.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CSFCube - a test collection of computer science research articles for faceted query by example.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Faceted Query-by-Example (sentence-level)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Faceted QbE embeds the user-selected sentence (the facet) and retrieves sentences/documents that are similar with respect to that facet. In this paper the faceted QbE is implemented with a sentence-transformer encoder and per-global-cluster ANN indices, enabling aspect-aligned cross-domain retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>general scientific exploratory search / information retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended exploration / aspect-conditioned retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2448.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPECTER Clustering</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SPECTER-based global domain clustering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of SPECTER document embeddings (citation-informed transformer representations) with KMeans to partition a corpus into global domain clusters that control domain distance for retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SPECTER: Document-level representation learning using citation-informed transformers.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SPECTER KMeans domain clustering</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Compute SPECTER embeddings from Title+Abstract, then apply KMeans (authors used K=20 for global clusters) to induce domain clusters that serve as the interface-level notion of 'domain/distance'. Per-cluster sentence indices are then built to support retrieval constrained to specific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>materials science corpus (applied to 3.2M abstracts in S2ORC) / general scientific corpora</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>domain partitioning to support cross-domain retrieval and control distance</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Cluster purity measured against author-provided keywords (treated as gold labels) to evaluate cluster coherence as a proxy for meaningful domain separation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Reported cluster purity averaged over three runs: SPECTER = 47.93% (keywords present) and 43.90% (keywords removed).</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Automated evaluation using an expert-curated keyword-labeled subset (39,699 documents) showed SPECTER maintained higher purity than term-based methods after removal of category keywords, indicating SPECTER captures domain structure beyond explicit term overlap.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>TFIDF and SCIBERT document representations evaluated under the same clustering protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>TFIDF purity: 48.08% (present) / 39.75% (removed). SCIBERT purity: 31.80% / 31.32%. SPECTER comparable to TFIDF when keywords present and outperforms TFIDF when keywords are removed (indicating robustness).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>SPECTER embeddings are effective at inducing subdomain clusters in materials science and are more robust than TFIDF to removal of domain-defining keywords.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2448.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Solvent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Solvent: A mixed-initiative system for finding analogies between research papers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior mixed-initiative analogy-finding system that uses metadata-informed domain structures and supported a crowdsourced labeling pipeline for aspect labels to enable analogical retrieval between scientific papers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solvent: A mixed initiative system for finding analogies between research papers.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Solvent (mixed-initiative analogy search)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Solvent uses document metadata and a domain-structure informed pipeline to surface analogical connections between papers and demonstrated a crowdsourcing approach to label aspects of papers (rhetorical/schema labels) for training downstream models.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>general scientific research / analogical search</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>interdisciplinary synthesis / creative ideation via analogies</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Not specified in this paper; Chan et al. (2018) used crowdsourced aspect labels as an intermediate supervisory signal for analogical retrieval but did not provide a standardized numeric novelty metric in this paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>The paper notes Chan et al. (2018) demonstrated crowdsourcing labels with non-expert crowdworkers; subsequent supervised models trained on those crowd labels showed limitations in accuracy and downstream retrieval usefulness (as discussed in Kang et al. 2022a).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2448.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Analogical Search (Kang et al. 2022a)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Augmenting scientific creativity with an analogical search engine</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work by the authors that retrieves analogs similar in one aspect and different in another to break fixation and support creative ideation; introduced supervised models trained on crowdsourced aspect labels and evaluated usefulness for ideation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting scientific creativity with an analogical search engine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Analogical Search Engine (aspect-conditioned retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Retrieves papers that match a target aspect (e.g., problem solved) while differing along another aspect (e.g., method used) to promote analogical transfer; prior pipeline involved crowd-labeled aspect data and supervised models to learn aspect-conditioned similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>design and scientific ideation / interdisciplinary creativity</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>interdisciplinary synthesis / creative ideation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Earlier work used human judgments and aspect-conditioned retrieval to characterize novelty; this paper references that prior study's evaluation design but does not re-report numeric novelty metrics here.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Prior work showed exposure to aspect-aligned analogs can help break fixation; however, supervised models trained on crowd-labeled aspect data had limitations in model accuracy and downstream retrieval usefulness (as noted in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2448.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Search Diversification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Search result diversification (novelty and coverage optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A body of IR methods that explicitly optimize retrieved result sets for novelty and coverage across possible query intents, used primarily for ambiguous queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Search result diversification.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Search result diversification algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Algorithms and objective formulations that select or re-rank documents to maximize coverage of subtopics or novelty relative to a query (e.g., diversification objectives, subtopic recall, intent coverage). The paper cites this literature as conceptually related but notes such methods often lack fine-grained user controllability for specifying types of novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>information retrieval / recommender systems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>ambiguous queries / exploratory search requiring diversity</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>General IR metrics for diversification (e.g., subtopic recall, Î±-nDCG, coverage); the paper references the literature broadly but does not report specific formulas or scores in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Discussed conceptually: diversification methods aim to increase novelty/coverage but may not provide user-level controllability needed for particular kinds of novelty; no empirical trade-off data in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Optimization of diversity/coverage objectives (literature-level), not implemented as an automated novelty-feasibility balancing method in the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2448.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2448.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ternary Novelty Rating</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Three-level human novelty annotation (1 exact seen, 2 similar seen, 3 novel)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A straightforward human annotation method used in the case studies where participants labeled retrieved papers on a 3-point novelty scale to assess whether results were previously known, similar-to-known, or novel.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting scientific creativity with an analogical search engine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Human ternary novelty annotation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Participants rated each paper they found interesting during the session along a 3-point scale (1: seen exact paper before; 2: not seen exact paper but similar ideas before; 3: not seen anything like this before). The scale is noted to be similar to the scale used in Kang et al. (2022a). Ratings were collected alongside a binary relevance label and used to ground debrief discussions; no aggregate statistics were reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>human evaluation in IR / human-computer interaction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>evaluation of novelty in idea-generation support tools</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>The 3-point categorical novelty label described above.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Binary relevance label collected in parallel (useful / not useful) used as a proxy for feasibility/applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>No quantitative tradeoff; method provided qualitative paired novelty vs relevance judgments from participants that the authors used during debriefs.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Used in three think-aloud interviews; participants provided novelty and relevance judgments and qualitative commentary. No numerical aggregates or statistical analyses reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Applied in materials science case studies; facilitated discussion of how retrieved cross-domain items related to participants' prior knowledge and assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Scientific Creativity with Retrieval across Knowledge Domains', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Augmenting scientific creativity with an analogical search engine <em>(Rating: 2)</em></li>
                <li>Solvent: A mixed initiative system for finding analogies between research papers <em>(Rating: 2)</em></li>
                <li>CSFCube - a test collection of computer science research articles for faceted query by example. <em>(Rating: 2)</em></li>
                <li>SPECTER: Document-level representation learning using citation-informed transformers. <em>(Rating: 2)</em></li>
                <li>Search result diversification. <em>(Rating: 2)</em></li>
                <li>Accelerating innovation through analogy mining <em>(Rating: 2)</em></li>
                <li>Scaling creative inspiration with fine-grained functional facets of product ideas. <em>(Rating: 1)</em></li>
                <li>Neighborhood contrastive learning for scientific document representations with citation embeddings <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2448",
    "paper_id": "paper-82e29e97049170c7ebbe11dd30cddd641835b970",
    "extraction_schema_id": "extraction-schema-64",
    "extracted_data": [
        {
            "name_short": "Cross-domain Faceted QbE Prototype",
            "name_full": "Cross-domain exploratory search prototype using faceted Query-by-Example with global and local clustering",
            "brief_description": "An interactive retrieval system that indexes sentences of papers and returns sentences similar to a user-selected query sentence while controlling for domain distance via automatically built global clusters (SPECTER+KMeans) and query-specific local clustering; intended to augment scientific creativity by surfacing cross-domain analogs and enabling zoom-in exploration.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Cross-domain exploratory search prototype (sentence-level faceted QbE with global + local clusters)",
            "system_description": "The system represents documents at the sentence level using a pre-trained sentence encoder (sentence-transformers all-mpnet-base-v2) and builds global domain clusters by KMeans on SPECTER document embeddings (|G| = 20). For a query abstract and a user-selected sentence sg, the sentence is embedded and the T nearest sentences are retrieved from each per-cluster approximate nearest-neighbor index (HNSW/FAISS). Users may select subsets of global clusters Gs and 'zoom in' by retrieving L &gt; T nearest sentences from those clusters and re-clustering into M local clusters to reveal nuanced variations. Cluster descriptors are derived from TF-IDF unigrams. The system is a retrieval-based inspiration tool (not a generative LLM) designed to surface potentially novel analogs across domain boundaries while letting the user control distance and scope.",
            "research_domain": "materials science / general scientific research (exploratory cross-domain retrieval)",
            "problem_type": "interdisciplinary synthesis / open-ended exploration",
            "novelty_metric": "Human novelty annotation collected during case studies using a 3-level scale (1: 'I have seen this exact paper before'; 2: 'I have not seen this exact paper but similar ideas before'; 3: 'I have not seen anything like this before'); conceptual control of novelty via 'domain distance' implemented as selection of global clusters (clusters intended to represent domains) and by promoting diversity across clusters.",
            "novelty_score": null,
            "feasibility_metric": "Binary relevance label (participants marked retrieved papers as relevant or not) collected alongside novelty; no explicit quantitative feasibility/likelihood metric reported.",
            "feasibility_score": null,
            "tradeoff_evidence": "Qualitative evidence only: authors and participants describe a 'sweet spot' of distance (not too near, not too far) where results are useful and inspiring; participants sometimes initially rejected very-different results but found value after zooming in; no quantitative trade-off measurements reported.",
            "optimization_strategy": "User-driven control: selection of a query sentence (faceted QbE), selection of global clusters to control domain distance, and zoom-in local clustering to inspect nuanced subtopics; no explicit automated multi-objective optimization or weighted balancing of novelty vs feasibility is implemented.",
            "human_evaluation": true,
            "human_evaluation_results": "Case studies with three materials-science researchers (think-aloud interviews). Results were qualitative: participants reported more diverse results compared to their chosen baselines and that the system helped surface novel application domains and hidden assumptions; participants used the ternary novelty scale and binary relevance to rate examples, but no aggregated numeric novelty/relevance statistics were reported in the paper.",
            "comparative_baseline": "Participant-selected baselines used for comparison in case studies (ConnectedPapers, SciFinder, Google Scholar).",
            "comparative_results": "Qualitative comparisons: participants said baseline systems were better for narrowly focused, domain-specific retrieval, while the prototype provided complementary value by surfacing diverse, cross-domain inspirations. No quantitative comparison of novelty/feasibility was reported (only qualitative user feedback).",
            "domain_specific_findings": "Materials-science case studies: examples include surfacing papers from domains like electrochromic mirrors (optics) and orthopedic implants that share mechanisms with battery materials; zooming-in revealed nuanced mechanistic trade-offs (e.g., doping vs sintering temperature impacts), helping participants discover cross-domain solutions and hidden assumptions in their fields.",
            "uuid": "e2448.0",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Faceted QbE",
            "name_full": "Faceted Query-by-Example",
            "brief_description": "A query paradigm where a user provides an example document and selects a textual facet (e.g., a sentence) that defines the aspect to be matched; retrieval is conditioned on that selected aspect.",
            "citation_title": "CSFCube - a test collection of computer science research articles for faceted query by example.",
            "mention_or_use": "use",
            "system_name": "Faceted Query-by-Example (sentence-level)",
            "system_description": "Faceted QbE embeds the user-selected sentence (the facet) and retrieves sentences/documents that are similar with respect to that facet. In this paper the faceted QbE is implemented with a sentence-transformer encoder and per-global-cluster ANN indices, enabling aspect-aligned cross-domain retrieval.",
            "research_domain": "general scientific exploratory search / information retrieval",
            "problem_type": "open-ended exploration / aspect-conditioned retrieval",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2448.1",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "SPECTER Clustering",
            "name_full": "SPECTER-based global domain clustering",
            "brief_description": "Use of SPECTER document embeddings (citation-informed transformer representations) with KMeans to partition a corpus into global domain clusters that control domain distance for retrieval.",
            "citation_title": "SPECTER: Document-level representation learning using citation-informed transformers.",
            "mention_or_use": "use",
            "system_name": "SPECTER KMeans domain clustering",
            "system_description": "Compute SPECTER embeddings from Title+Abstract, then apply KMeans (authors used K=20 for global clusters) to induce domain clusters that serve as the interface-level notion of 'domain/distance'. Per-cluster sentence indices are then built to support retrieval constrained to specific domains.",
            "research_domain": "materials science corpus (applied to 3.2M abstracts in S2ORC) / general scientific corpora",
            "problem_type": "domain partitioning to support cross-domain retrieval and control distance",
            "novelty_metric": "Cluster purity measured against author-provided keywords (treated as gold labels) to evaluate cluster coherence as a proxy for meaningful domain separation.",
            "novelty_score": "Reported cluster purity averaged over three runs: SPECTER = 47.93% (keywords present) and 43.90% (keywords removed).",
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": false,
            "human_evaluation_results": "Automated evaluation using an expert-curated keyword-labeled subset (39,699 documents) showed SPECTER maintained higher purity than term-based methods after removal of category keywords, indicating SPECTER captures domain structure beyond explicit term overlap.",
            "comparative_baseline": "TFIDF and SCIBERT document representations evaluated under the same clustering protocol.",
            "comparative_results": "TFIDF purity: 48.08% (present) / 39.75% (removed). SCIBERT purity: 31.80% / 31.32%. SPECTER comparable to TFIDF when keywords present and outperforms TFIDF when keywords are removed (indicating robustness).",
            "domain_specific_findings": "SPECTER embeddings are effective at inducing subdomain clusters in materials science and are more robust than TFIDF to removal of domain-defining keywords.",
            "uuid": "e2448.2",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Solvent",
            "name_full": "Solvent: A mixed-initiative system for finding analogies between research papers",
            "brief_description": "A prior mixed-initiative analogy-finding system that uses metadata-informed domain structures and supported a crowdsourced labeling pipeline for aspect labels to enable analogical retrieval between scientific papers.",
            "citation_title": "Solvent: A mixed initiative system for finding analogies between research papers.",
            "mention_or_use": "mention",
            "system_name": "Solvent (mixed-initiative analogy search)",
            "system_description": "Solvent uses document metadata and a domain-structure informed pipeline to surface analogical connections between papers and demonstrated a crowdsourcing approach to label aspects of papers (rhetorical/schema labels) for training downstream models.",
            "research_domain": "general scientific research / analogical search",
            "problem_type": "interdisciplinary synthesis / creative ideation via analogies",
            "novelty_metric": "Not specified in this paper; Chan et al. (2018) used crowdsourced aspect labels as an intermediate supervisory signal for analogical retrieval but did not provide a standardized numeric novelty metric in this paper's discussion.",
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "The paper notes Chan et al. (2018) demonstrated crowdsourcing labels with non-expert crowdworkers; subsequent supervised models trained on those crowd labels showed limitations in accuracy and downstream retrieval usefulness (as discussed in Kang et al. 2022a).",
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2448.3",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Analogical Search (Kang et al. 2022a)",
            "name_full": "Augmenting scientific creativity with an analogical search engine",
            "brief_description": "Prior work by the authors that retrieves analogs similar in one aspect and different in another to break fixation and support creative ideation; introduced supervised models trained on crowdsourced aspect labels and evaluated usefulness for ideation.",
            "citation_title": "Augmenting scientific creativity with an analogical search engine.",
            "mention_or_use": "mention",
            "system_name": "Analogical Search Engine (aspect-conditioned retrieval)",
            "system_description": "Retrieves papers that match a target aspect (e.g., problem solved) while differing along another aspect (e.g., method used) to promote analogical transfer; prior pipeline involved crowd-labeled aspect data and supervised models to learn aspect-conditioned similarity.",
            "research_domain": "design and scientific ideation / interdisciplinary creativity",
            "problem_type": "interdisciplinary synthesis / creative ideation",
            "novelty_metric": "Earlier work used human judgments and aspect-conditioned retrieval to characterize novelty; this paper references that prior study's evaluation design but does not re-report numeric novelty metrics here.",
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "Prior work showed exposure to aspect-aligned analogs can help break fixation; however, supervised models trained on crowd-labeled aspect data had limitations in model accuracy and downstream retrieval usefulness (as noted in this paper).",
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2448.4",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Search Diversification",
            "name_full": "Search result diversification (novelty and coverage optimization)",
            "brief_description": "A body of IR methods that explicitly optimize retrieved result sets for novelty and coverage across possible query intents, used primarily for ambiguous queries.",
            "citation_title": "Search result diversification.",
            "mention_or_use": "mention",
            "system_name": "Search result diversification algorithms",
            "system_description": "Algorithms and objective formulations that select or re-rank documents to maximize coverage of subtopics or novelty relative to a query (e.g., diversification objectives, subtopic recall, intent coverage). The paper cites this literature as conceptually related but notes such methods often lack fine-grained user controllability for specifying types of novelty.",
            "research_domain": "information retrieval / recommender systems",
            "problem_type": "ambiguous queries / exploratory search requiring diversity",
            "novelty_metric": "General IR metrics for diversification (e.g., subtopic recall, Î±-nDCG, coverage); the paper references the literature broadly but does not report specific formulas or scores in this work.",
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": "Discussed conceptually: diversification methods aim to increase novelty/coverage but may not provide user-level controllability needed for particular kinds of novelty; no empirical trade-off data in this paper.",
            "optimization_strategy": "Optimization of diversity/coverage objectives (literature-level), not implemented as an automated novelty-feasibility balancing method in the prototype.",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2448.5",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Ternary Novelty Rating",
            "name_full": "Three-level human novelty annotation (1 exact seen, 2 similar seen, 3 novel)",
            "brief_description": "A straightforward human annotation method used in the case studies where participants labeled retrieved papers on a 3-point novelty scale to assess whether results were previously known, similar-to-known, or novel.",
            "citation_title": "Augmenting scientific creativity with an analogical search engine.",
            "mention_or_use": "use",
            "system_name": "Human ternary novelty annotation",
            "system_description": "Participants rated each paper they found interesting during the session along a 3-point scale (1: seen exact paper before; 2: not seen exact paper but similar ideas before; 3: not seen anything like this before). The scale is noted to be similar to the scale used in Kang et al. (2022a). Ratings were collected alongside a binary relevance label and used to ground debrief discussions; no aggregate statistics were reported in this paper.",
            "research_domain": "human evaluation in IR / human-computer interaction",
            "problem_type": "evaluation of novelty in idea-generation support tools",
            "novelty_metric": "The 3-point categorical novelty label described above.",
            "novelty_score": null,
            "feasibility_metric": "Binary relevance label collected in parallel (useful / not useful) used as a proxy for feasibility/applicability.",
            "feasibility_score": null,
            "tradeoff_evidence": "No quantitative tradeoff; method provided qualitative paired novelty vs relevance judgments from participants that the authors used during debriefs.",
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "Used in three think-aloud interviews; participants provided novelty and relevance judgments and qualitative commentary. No numerical aggregates or statistical analyses reported.",
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Applied in materials science case studies; facilitated discussion of how retrieved cross-domain items related to participants' prior knowledge and assumptions.",
            "uuid": "e2448.6",
            "source_info": {
                "paper_title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Augmenting scientific creativity with an analogical search engine",
            "rating": 2
        },
        {
            "paper_title": "Solvent: A mixed initiative system for finding analogies between research papers",
            "rating": 2
        },
        {
            "paper_title": "CSFCube - a test collection of computer science research articles for faceted query by example.",
            "rating": 2
        },
        {
            "paper_title": "SPECTER: Document-level representation learning using citation-informed transformers.",
            "rating": 2
        },
        {
            "paper_title": "Search result diversification.",
            "rating": 2
        },
        {
            "paper_title": "Accelerating innovation through analogy mining",
            "rating": 2
        },
        {
            "paper_title": "Scaling creative inspiration with fine-grained functional facets of product ideas.",
            "rating": 1
        },
        {
            "paper_title": "Neighborhood contrastive learning for scientific document representations with citation embeddings",
            "rating": 1
        }
    ],
    "cost": 0.020146749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Augmenting Scientific Creativity with Retrieval across Knowledge Domains
Hyeonsu B. Kang ${ }^{1 <em>}$ Sheshera Mysore ${ }^{2 </em>}$ Kevin Huang ${ }^{3 *}$ Haw-Shiuan Chang ${ }^{2}$ Thorben Prein ${ }^{3}$ Andrew McCallum ${ }^{2}$ Aniket Kittur ${ }^{1}$ Elsa Olivetti ${ }^{3}$ ${ }^{1}$ Human-Computer Interaction Institute, CMU, PA, USA
${ }^{2}$ Manning College of Information and Computer Sciences, uMass Amherst, MA, USA
${ }^{3}$ Department of Materials Science and Engineering, MIT, MA, USA
{hyeonsuk,nkittur}@cs.cmu.edu
{smysore, hschang, mccallum}@cs.umass.edu
{kjhuang, prein, elsao}@mit.edu</p>
<h4>Abstract</h4>
<p>Exposure to ideas in domains outside a scientist's own may benefit her in reformulating existing research problems in novel ways and discovering new application domains for existing solution ideas. While improved performance in scholarly search engines can help scientists efficiently identify relevant advances in domains they may already be familiar with, it may fall short of helping them explore diverse ideas outside such domains. In this paper we explore the design of systems aimed at augmenting the end-user ability in cross-domain exploration with flexible query specification. To this end, we develop an exploratory search system in which end-users can select a portion of text core to their interest from a paper abstract and retrieve papers that have a high similarity to the user-selected core aspect but differ in terms of domains. Furthermore, end-users can 'zoom in' to specific domain clusters to retrieve more papers from them and understand nuanced differences within the clusters. Our case studies with scientists uncover opportunities and design implications for systems aimed at facilitating cross-domain exploration and inspiration.</p>
<h2>1 Introduction</h2>
<p>Analogies have been a central mechanism for crossboundary inspirations and innovation throughout the history of science and technology (Gentner et al., 1997; Oppenheimer, 1956). For example, analogical reasoning helped the Greek philosopher Chrysippus (c. 240 Ð².Ñ.) model sound waves from observations of water waves, two domains that did not interact prior to this insight. However, as knowledge areas deepen in specialization, they interact less with each other (Swanson and Smalheiser, 1996; Chu and Evans, 2021) and analogical reasoning across domains becomes increasingly challenging. Yet, a systematic review of existing literature suggests that enabling connections that</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>jump between scientific domains may bring significant innovations and scientific progress (Rzhetsky et al., 2015). As such, developing a computational means to augmenting human intelligence with analogical creativity remains a holy-grail challenge in both cognitive science and AI research (Mitchell, 1993; Hesse, 1965; Kittur et al., 2019).</p>
<p>To this end, recent approaches for retrieving analogically similar ideas have demonstrated promising results (Kang et al., 2022a; Hope et al., 2017, 2021; Chan et al., 2018). The central idea of these approaches focuses on retrieving analogs similar in one aspect of a pre-determined schema (e.g., 'problem solved') while differing on the other (e.g., 'method used'), exposure to which has shown to unlock scientists' creativity to break out of fixation and mechanistic conventions (Kang et al., 2022a).</p>
<p>While promising, there are remaining technical and design challenges that prohibit realization of systems that support exploration across boundaries of knowledge domains. The first challenge is developing mechanisms that allow end-users to explore diverse domains and find ones they want to jump to find analogous retrievals. Prior work in cognitive psychology research on human creativity (Chan et al., 2015; GonÃ§alves et al., 2013) has noted a sweet spot of distance for retrieval, with effective results being neither too different from the query, which may cause early rejection from searchers, nor too similar, which may be insufficient for breaking out of conventions and fixation (Jansson and Smith, 1991). This notion of effective distance is a departure from the commonly used notions of relevance in the literature of IR and NLP that rely on topical overlap (Borlund, 2003) and development of methods often optimized for maximal contentsimilarity (Carterette, 2011). A notable exception is the prior research in search diversification (see Santos et al. (2015)), which contributes mechanisms for optimizing the novelty and coverage of search results given ambiguous queries. However,</p>
<p>they often lack the controllability for end-users who want to specify the kinds of novelty they are interested in and the scope of coverage.</p>
<p>The second challenge is the lack of labeled data for scaling a schematic representation of documents. Barriers to domain knowledge make accurate labeling of research papers using a predetermined schema across diverse domains prohibitively costly. While Chan et al. (2018) demonstrated a potential pipeline for crowdsourcing the labels with non-expert crowdworkers, a subsequent paper in which a supervised model was trained based on the crowd-labeled data showed limitations on the model accuracy and downstream retrieval usefulness (Kang et al., 2022a). Furthermore, emerging scientific domains present an additional challenge with updating data.</p>
<p>Finally, studying how cross-domain explorations occur in authentic use scenarios requires a) development of an interactive search system with a usable performance and b) evaluating it with scientists seeking inspirations on real-world research problems. Insights from the study also contribute to the growing literature that studies open questions around how informational and exploration needs in creative work change over time and during the exploration (Li et al., 2022).</p>
<p>In this work we develop an interactive prototype system which we use to probe these challenges and uncover design implications for future analogical search systems aimed at supporting retrieval across knowledge domains. Our system leverages the recently introduced <em>faceted Query-by-Example (QbE)</em> paradigm to increase the controllability of search novelty and scope, by allowing searchers to query using a paper abstract and a sentence in the abstract that indicates personally interesting core aspects of the paper (Mysore et al., 2021). To find matching abstracts based on the query aspect, our system first indexes documents using each of its sentences and retrieves similar sentences using a strong sentence encoding model (sbert.net, 2021) at runtime. To go beyond the high-demand for labeled data in a challenging domain, our approach relaxes the mechanism for retrieval from relying on a predetermined schematic representation of abstracts to using a readily available, intuitive sentence-level representation. To support an increased diversity</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: We leverage free-form sentence level querying 1 to retrieve documents across automatically built domain clusters 2. These are expanded based on searcher selection and re-clustered to allow navigation of nuanced differences within selected global clusters 3. Searchers can move between global clusters, 'zoom in' to examine global clusters, and reformulate their queries for additional alternative exploration.</p>
<p>of matching over prior work that mapped each abstract into a single 'best' schematic representation, we enable users to select any sentence in an abstract as interesting for querying. The system then retrieves papers similar to the selected aspect but different in terms of their domains. Domain clusters in our system were constructed using a pre-trained scientific document representation model trained on citation data (Cohan et al., 2020) capturing a global domain knowledge structure, and also do not require explicit labeled data in the process.</p>
<p>In order to center authentic user needs in the development of our prototype system, we adopted an iterative design process and sought feedback from a group of materials science researchers studying climate change mitigation strategies. Due to the complex systems nature of climate change, development of mitigation strategies such as clean energy technologies and more sustainable building materials requires a cross-disciplinary approach (Xu et al., 2016) and related closely to the needs we set out to support in this research. We conducted case studies with our system to gain deeper insights into whether the system retrieves results that represent meaningful 'jumps' between knowledge domains, whether scientists can make sense of them, and the design challenges for future exploratory search systems that facilitate cross-boundary inspirations.</p>
<h2>2 System Description</h2>
<p>Our system allows searchers to explore retrievals from global clusters and select interesting ones. The user may zoom into the clusters by retrieving additional results from them, which may reveal nuanced differences via local clustering. This interaction is supported by the 'Zoom in' button in</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Front-end interface. â  In the input panel, searchers enter the query paper abstract and a specific sentence aspect they want to align the retrieval results on. â¡ Once searchers click on 'Search' at the bottom left, the system retrieves papers along with global domain clusters and displays them at the top of the navigation panel. Searchers can switch between different clusters to examine the results. Clicking on a cluster label highlights it and filters the papers that belong to the cluster in the table (clicking again on a selected cluster label de-selects it and refreshes the filtered table view). â¢ The papers are displayed in the table on the right, with a green sentence highlight showing the closest aspect to the query. Searchers can type keywords in the filter at the top to find papers that contain them (matching keywords in the abstract are highlighted). Optional control buttons for our case studies for collecting feedback data are also shown in the table. â£ Clicking the 'Zoom in' button retrieves more papers from the selected clusters, allowing searchers to examine nuanced differences within the selected domain clusters.</p>
<p>The interface (Fig. 2). There are three main components of the system (Fig. 1): <em>Global clusters</em>. A set of clusters partitioning the entire corpus of papers into domains, built from paper embeddings computed with [cohan2020]âs transformer-based model; <em>Sentential representations</em>. Each sentence in an abstract is encoded using a state-of-the-art sentence encoder [sbert.net, 2021] to enable faceted retrieval at that level; <em>Local clusters</em>. A set of nested clusters built from query-specific retrievals within user-specified global clusters to reveal variations within the clusters. For the text corpus of our system, we used 3.2M Materials Science abstracts in the S2ORC corpus [lo2020s2orc].</p>
<p>Global domain clusters. We represent broad subdisciplines of materials science with a set of global clusters, G â G. These serve as the primary means for searchers to control the distance of retrievals to a query. The clusters were obtained via citation-based similarity clustering using SPECTER embeddings of abstracts d's in the corpus [cohan2020]. We employ a K-Means clustering of the embeddings with |G| = 20. This use follows from results indicating that pre-trained representations often capture domain structures well [aharoni2020] [peng2021]. We further validate these clusters in Appendix A.</p>
<p>Following the creation of G, we index the sentences s, of documents in each cluster, dg â G, with a cluster specific approximate nearest neighbour search index, Ig, in preparation for search. We use the HNSW index of [faiss2019] and a pre-trained sentence encoder, BERT<sup>s</sup> to encode the sentences [sbert.net, 2021].</p>
<p>Sentence-level retrieval. We leverage the recently proposed faceted QbE search paradigm [mysore2021] for querying, shown to support exploratory search tasks well [lissandrini2019]. Here, searchers query the system with an abstract q and a sentence in the abstract sg â q indicative of the aspect of their interest.</p>
<p>We embed sg with BERT<sup>s</sup>, and retrieve the T nearest sentences from each global cluster index Ig. Users can then browse the results by switching between domains in the front-end interface, and additionally indicate specific global clusters Gs â G they want to explore further. These serve as input to constructing query-specific local clusters.</p>
<p>Zooming in on global clusters with local clustering. Given a set of global clusters Gs, and the query sg, we retrieve the L nearest sentences to sg from selected indices Ig â G. To support retrieval of more results from the same domain(s), we set L &gt; T. We then re-cluster the similar document</p>
<p>sentences into a set of $M$ clusters to show variations within the selected global clusters.</p>
<p>Finally, our prototype used a preliminary TFIDF scoring of unigrams in a cluster to extract descriptors for global and local clusters - the informativeness of the descriptors was however limited.
Interface used in the case studies. The main components of the front-end interface of our system are (See Fig. 2) A): Query input panel, B): Cluster navigation panel, (C): Retrieval table view with filtering, and (D): An optional 'Zoom in' button. Clicking this button retrieves more papers from the domain clusters searchers selected which allows them to explore and make sense of nuanced details among the results within the selected clusters.</p>
<h2>3 Case Studies</h2>
<p>We conducted think-aloud interviews (Fonteyn et al., 1993) with three participants who engage in Materials Science and Engineering research to probe 1) what potentially distinct values our system may bring to scientists exploring their own research questions compared to baseline systems, and 2) design challenges for realizing the full potential of search systems aimed at cross-domain exploration. We detail the study procedure in Appendix B.</p>
<h2>4 Findings</h2>
<p>Diverse results \&amp; complementary value. All participants commented on seeing more diverse results using our system over the baselines (Table 3). P1 compared his experiences as follows:
"On ConnectedPapers (P1's baseline system), I can see the overall relations between works such as who's citing who, and identifying what's well-cited...but focused in the closely related fields like geochemistry and dissolution of cement...In [our system], you can see that it's picking up things that I quite frankly had no idea why it picked up at first." - P1
This quote demonstrates that while the prototype system did seem to retrieve more diverse results compared to the baseline system, the difference in results may require a closer look for apt engagement. Participants thought the value of retrieving such diverse results in the prototype system was complementary to that of the baseline systems. Both P2 and P3, who chose keyword query-based search engines as baselines, felt the baseline systems were useful for finding things in the domain they already knew: "In regular search engines like ScIFinder I can put in the exact query to find
precisely that kind of papers" (P2). In comparison, "[our system] is fantastic for learning more about a topic and kind of exploring...there are a lot of things that I found that I hadn't seen anywhere before." (P2). However, this value also seemed to depend on how focused the search goal was: "It depends on what I'm trying to do...If I had a specific experiment in mind, for example tracking the activity of magnesium...I probably wouldn't be interested in looking at even iron or non-manganese materials...but in other times, I'll be open to seeing even non-battery domains so long as similar challenges are addressed." (P3).</p>
<p>Sourcing diversity from global domain clusters. This diversity seemed to originate from the differences in domains that participants perceived while interacting with the system. Specifically, participants thought the global clusters mapped to different application domains of similar mechanisms captured in their query sentences. For P1, this included clusters of papers focused on 'mixture strategies to create cement with radiation shielding to use in military bases' (as opposed to recapturing materials from industrial wastes to create mixtures for buildings for non-military use) or 'mixtures for bone-like scaffolds and implants in mice' (as opposed to buildings). In addition, P1 perceived the application domain of military bases as closer than Orthopedics in mice. An example P2 found interesting was a paper describing solid-state electrolytes for use in electrochromic mirrors, as opposed to the domain of battery technologies he was familiar with. This and other papers in the cluster showed P2 a whole new set of application domains related to optical properties of electrolytes that P2 did not know of. P3 found the results describing 'discharging' mechanisms interesting and useful for learning new contexts of research that explore similar mechanisms, e.g., papers on electrostatic discharging observed in clouds or the effects of mechanical properties in anode coatings on discharging.
Zooming in \&amp; realizing hidden assumptions. While reviewing the variations among the results, participants realized hidden assumptions that guided them to seek inspirations in 'typical' domains. For example, in seeing varying uses of a similar mechanism (e.g., discharging) in different contexts (e.g., electrostatic vs. electrochemical), P3 learned about other domains which she did not tap into for inspirations before: "Now I can see that discharging happens everywhere, even outside the bat-</p>
<p>tery domains. What I assumed was that discharging is only related to rate-related challenges in (an) electrochemical (context)." - P3. Unlike similaritymaximizing search, learning about various domains helped P3 realize her own pre-conceived notion of typicality of a search domain, broaden potential domains of inspiration, and connect previously disjoint clusters (e.g., [mechanical strategies], such as nanoindentations in anode coating materials, to [electrochemical] discharging efficiency).</p>
<p>Retrieving more results in selected domain clusters and surfacing local clusters not only assisted participants in making sense of the high-level similarity within the clusters but also helped them see nuanced differences. For P2, seeing results on [doping] and [sintering temperature] were on-point with regards to the core mechanistic relevance for his experiments (high-level similarity), while zooming in the clusters revealed more nuanced trade-off relationships such as how doping has been used as a mitigation strategy against loss of lithium at high temperatures. Examining the additional retrievals also led P2 to notice diverse sub-fields such as [powder metallurgy] and [laser deposition] that the nuanced mechanistic differences occurred.</p>
<p>Sometimes recognizing such nuanced differences helped participants make sense of how the search system worked: "So these papers lack (connection to) dissolution and are mostly about production of cement which makes sense because my query sentence only mentions producing aggregates. But I thought because the rest of the abstract talks about dissolution of aggregates, the system would know that's the context I'm focusing on." P1. Interpreting how the system worked guided participants' query reformulation to counter their hidden assumptions or broaden the scope of search.</p>
<h2>5 Implications for Design</h2>
<p>These results confirm earlier findings that emphasize support for an iterative discovery of important and generative mis-alignments during analogical search (Kang et al., 2022a), while also contributing new challenges specific to cross-domain exploration. Compared to similarity-maximizing search that optimizes for alignment of search results, cross-domain inspiration requires identification of aspects in analogs that may be diversified for end-user inspiration versus those that need to be preserved for retaining relevance.</p>
<p>Specifically, how to identify clusters that lack important connections to query problems is challeng-
ing because a cluster can be centered around a specific mechanism relevant to the query while lacking connections to other contextual mechanisms (e.g., a cluster of papers that focuses on production mechanisms of aggregate mixture but does not study the dissolution process of waste materials, which is a related mechanism for providing the ingredients to the production pipeline), or may not preserve important directionality of the cause-andeffect relationships (e.g., papers that demonstrate techniques to make electrolytes more inflammable may be useful in certain application domains but not for making battery technologies safer).</p>
<p>Given the importance of participants' reflection on their own assumptions and how the system performed search, future designs may focus on supporting stateful explorations and aim to help searchers keep track of which clusters they have visited, what they found as useful (and not useful) in them, and how they might reformulate subsequent search queries based on the previously hidden but salient aspects of their search intent. This information may provide valuable feedback to the system for tuning its behavior over time.</p>
<p>Lastly, unfamiliar domains may require explanations of relevance for searchers to scaffold engagement at a deeper level and to prevent early rejection based on snap judgment. We observed that organizing papers in domain clusters based on their high-level similarity to the query aspect serves as an important anchor for sensemaking. Furthermore, encouraging end-users to zoom into local clusters that exhibit nuanced differences may have led our expert users to slow down their judgment (Carolanne et al., 2007), allowing a deeper processing of results. However, open questions remain for future work to effectively communicate papers' relevance to scientists (e.g., Kang et al. (2022b)).</p>
<h2>6 Conclusion</h2>
<p>Our work presents an novel approach for exploring domain clusters to broaden sources of scientific inspiration and probe design implications for future interactive systems. Our case studies suggest that systems leveraging the global structure of knowledge domains and enabling flexible aspect-based retrieval help scientists find meaningful inspirations outside the domains they are familiar with. Additional work is needed to realize the full potential of interactive systems that augment scientific creativity via cross-domain inspirations.</p>
<h2>7 Acknowledgments</h2>
<p>We thank our study participants for their valuable insights and feedback. We would like to acknowledge partial funding from Shell, the Center for Knowledge Acceleration, the Allen Institute for Artificial Intelligence (AI2), National Science Foundation under Grant Number IIS-1763618, FW-HTF-RL-1928631, and IIS-1816242, DMREF Awards 1922311, 1922372, and 1922090, the Office of Naval Research (ONR) under contracts: N00014-20-1-2280 and N00014-19-1-2114, the IBM Research AI through the AI Horizons Network, and the Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction. This work is also supported by the Google Cloud Research Credits program with the award GCP19980904.</p>
<h2>References</h2>
<p>KP Abhilash, P Christopher Selvin, B Nalini, P Nithyadharseni, and BC Pillai. 2013. Investigations on pure and Ag doped lithium lanthanum titanate (LLTO) nanocrystalline ceramic electrolytes for rechargeable lithium-ion batteries. Ceramics International, 39(2):947-952.</p>
<p>Roee Aharoni and Yoav Goldberg. 2020. Unsupervised domain clusters in pretrained language models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 77477763.</p>
<p>Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 36153620, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Pia Borlund. 2003. The concept of relevance in IR. Journal of the American Society for information Science and Technology, 54(10):913-925.</p>
<p>E Moulton Carol-anne, Glenn Regehr, Maria Mylopoulos, and Helen M MacRae. 2007. Slowing down when you should: a new model of expert judgment. Academic Medicine, 82(10):S109-S116.</p>
<p>Ben Carterette. 2011. System effectiveness, user models, and user utility: a conceptual framework for investigation. In Proceedings of the 34th international ACM SIGIR conference on Research and development in information retrieval, pages 903-912.</p>
<p>Tanmoy Chakraborty, Amrith Krishna, Mayank Singh, Niloy Ganguly, Pawan Goyal, and Animesh Mukher-
jee. 2016. Ferosa: A faceted recommendation system for scientific articles. In Proceedings, Part II, of the 20th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining - Volume 9652, PAKDD 2016, page 528-541, Berlin, Heidelberg. Springer-Verlag.</p>
<p>Joel Chan, Joseph Chee Chang, Tom Hope, Dafna Shahaf, and Aniket Kittur. 2018. Solvent: A mixed initiative system for finding analogies between research papers. Proc. ACM Hum.-Comput. Interact., 2(CSCW).</p>
<p>Joel Chan, Steven P. Dow, and Christian D. Schunn. 2015. Do The Best Design Ideas (Really) Come From Conceptually Distant Sources Of Inspiration? Design Studies, 36:31-58.</p>
<p>Johan SG Chu and James A Evans. 2021. Slowed canonical progress in large fields of science. Proceedings of the National Academy of Sciences, 118(41).</p>
<p>Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel Weld. 2020. SPECTER: Document-level representation learning using citation-informed transformers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2270-2282, Online. Association for Computational Linguistics.</p>
<p>Daniel Cohen, Bhaskar Mitra, Katja Hofmann, and W Bruce Croft. 2018. Cross domain regularization for neural ranking models using adversarial learning. In The 41st International ACM SIGIR Conference on Research \&amp; Development in Information Retrieval, pages 1025-1028.</p>
<p>Khalid El-Arini and Carlos Guestrin. 2011. Beyond keyword search: Discovering relevant scientific literature. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '11, page 439-447, New York, NY, USA. Association for Computing Machinery.</p>
<p>Michael FÃ¤rber and Adam Jatowt. 2020. Citation recommendation: approaches and datasets. International Journal on Digital Libraries, 21(4):375-405.</p>
<p>Marsha E Fonteyn, Benjamin Kuipers, and Susan J Grobe. 1993. A description of think aloud method and protocol analysis. Qualitative health research, 3(4):430-441.
D. Gentner, S. Brem, R. W. Ferguson, P. Wolff, A. B. Markman, and K. D. Forbus. 1997. Analogy and Creativity in the Works of Johannes Kepler. In T. B. Ward, J. Vaid, and S. M. Smith, editors, Creative thought: An investigation of conceptual structures and processes, pages 403-459. American Psychological Association, Washington D.C.</p>
<p>Milene GonÃ§alves, Carlos Cardoso, and Petra BadkeSchaub. 2013. Inspiration peak: exploring the semantic distance between design problem and textual</p>
<p>inspirational stimuli. International Journal of Design Creativity and Innovation, 1(4):215-232.</p>
<p>Kevin Heffernan and Simone Teufel. 2018. Identifying problems and solutions in scientific text. Scientometrics, 116(2):1367-1382.</p>
<p>Mary Hesse. 1965. Models and analogies in science. British Journal for the Philosophy of Science, 16(62).</p>
<p>Tom Hope, Joel Chan, Aniket Kittur, and Dafna Shahaf. 2017. Accelerating innovation through analogy mining. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '17, pages 235-243, New York, NY, USA. ACM.</p>
<p>Tom Hope, Jason Portenoy, Kishore Vasan, Jonathan Borchardt, Eric Horvitz, Daniel Weld, Marti Hearst, and Jevin West. 2020. SciSight: Combining faceted navigation and research group detection for COVID19 exploratory scientific search. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 135-143, Online. Association for Computational Linguistics.</p>
<p>Tom Hope, Ronen Tamari, Hyeonsu Kang, Daniel Hershcovich, Joel Chan, Aniket Kittur, and Dafna Shahaf. 2021. Scaling creative inspiration with finegrained functional facets of product ideas.</p>
<p>Sarthak Jain, Edward Banner, Jan-Willem van de Meent, Iain J Marshall, and Byron C Wallace. 2018. Learning disentangled representations of texts with application to biomedical abstracts. In EMNLP, volume 2018, page 4683.</p>
<p>David G Jansson and Steven M Smith. 1991. Design fixation. Design studies, 12(1):3-11.</p>
<p>Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3):535-547.</p>
<p>Marius Kaminskas and Derek Bridge. 2016. Diversity, serendipity, novelty, and coverage: a survey and empirical analysis of beyond-accuracy objectives in recommender systems. ACM Transactions on Interactive Intelligent Systems (TiiS), 7(1):1-42.</p>
<p>Hyeonsu Kang, Xin Qian, Tom Hope, Dafna Shahaf, Joel Chan, and Aniket Kittur. 2022a. Augmenting scientific creativity with an analogical search engine. Transactions on Computer-Human Interaction.</p>
<p>Hyeonsu B Kang, Rafal Kocielnik, Andrew Head, Jiangjiang Yang, Matt Latzke, Aniket Kittur, Daniel S Weld, Doug Downey, and Jonathan Bragg. 2022b. From Who You Know to What You Read: Augmenting Scientific Recommendations with Implicit Social Networks. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '22, New York, NY, USA. Association for Computing Machinery.</p>
<p>Aniket Kittur, Lixiu Yu, Tom Hope, Joel Chan, Hila Lifshitz-Assaf, Karni Gilon, Felicia Ng, Robert E Kraut, and Dafna Shahaf. 2019. Scaling up analogical innovation with crowds and ai. Proceedings of the National Academy of Sciences, 116(6):18701877.</p>
<p>Alex Ksikes. 2014. Towards exploratory faceted search systems. Ph.D. thesis, University of Cambridge.</p>
<p>Or Levi, Ido Guy, Fiana Raiber, and Oren Kurland. 2018. Selective cluster presentation on the search results page. ACM Trans. Inf. Syst., 36(3).</p>
<p>Yuan Li, Yinglong Zhang, and Robert Capra. 2022. Analyzing information resources that support the creative process. In ACM SIGIR Conference on Human Information Interaction and Retrieval, pages 180190.</p>
<p>Matteo Lissandrini, Davide Mottin, Themis Palpanas, and Yannis Velegrakis. 2019. Example-based search: a new frontier for exploratory search. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1411-1412.</p>
<p>Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.</p>
<p>Christopher D. Manning, Prabhakar Raghavan, and Hinrich SchÃ¼tze. 2008. Introduction to Information Retrieval. Cambridge University Press.</p>
<p>Melanie Mitchell. 1993. Analogy-making as perception: A computer model. Mit Press.</p>
<p>Sheshera Mysore, Arman Cohan, and Tom Hope. 2022. Multi-vector models with textual guidance for finegrained scientific document similarity. NAACL.</p>
<p>Sheshera Mysore, Tim OâGorman, Andrew McCallum, and Hamed Zamani. 2021. CSFCube - a test collection of computer science research articles for faceted query by example. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).</p>
<p>Mariana Neves, Daniel Butzke, and Barbara Grune. 2019. Evaluation of scientific elements for text similarity in biomedical publications. In Proceedings of the 6th Workshop on Argument Mining, Florence, Italy. Association for Computational Linguistics.
R. Oppenheimer. 1956. Analogy in science. American Psychologist, 11(3):127-135.</p>
<p>Malte Ostendorff, Nils Rethmeier, Isabelle Augenstein, Bela Gipp, and Georg Rehm. 2022. Neighborhood contrastive learning for scientific document representations with citation embeddings.</p>
<p>Malte Ostendorff, Terry Ruas, Till Blume, Bela Gipp, and Georg Rehm. 2020. Aspect-based document similarity for research papers. In Proceedings of the 28th International Conference on Computational Linguistics, pages 6194-6206, Barcelona, Spain (Online). International Committee on Computational Linguistics.</p>
<p>Liang Pang, Qingyao Ai, and Jun Xu. 2021. Beyond probability ranking principle: Modeling the dependencies among documents. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining, WSDM '21, page 1137-1140, New York, NY, USA. Association for Computing Machinery.</p>
<p>Hao Peng, Qing Ke, Ceren Budak, Daniel M Romero, and Yong-Yeol Ahn. 2021. Neural embeddings of scholarly periodicals reveal complex disciplinary organizations. Science Advances, 7(17):eabb9004.</p>
<p>Jason Portenoy, Marissa Radensky, Jevin D West, Eric Horvitz, Daniel S Weld, and Tom Hope. 2022. Bursting scientific filter bubbles: Boosting innovation via novel author discovery. In CHI Conference on Human Factors in Computing Systems, CHI '22, New York, NY, USA. Association for Computing Machinery.</p>
<p>Andrey Rzhetsky, Jacob G Foster, Ian T Foster, and James A Evans. 2015. Choosing experiments to accelerate collective discovery. Proceedings of the National Academy of Sciences, 112(47):14569-14574.</p>
<p>Rodrygo L. T. Santos, Craig Macdonald, and Iadh Ounis. 2015. Search result diversification. Found. Trends Inf. Retr., 9(1):1-90.
sbert.net. 2021. sentence-transformers all-mpnet-base-v2.</p>
<p>Soumya Shukla and Orland Hoeber. 2021. Visually linked keywords to support exploratory browsing. In Proceedings of the 2021 Conference on Human Information Interaction and Retrieval, pages 273277.</p>
<p>Amin Sorkhei, Kalle Ilves, and Dorota Glowacka. 2017. Exploring scientific literature search through topic models. In Proceedings of the 2017 ACM Workshop on Exploratory Search and Interactive Data Analytics, pages 65-68.</p>
<p>Nicole Sultanum, Christine Murad, and Daniel Wigdor. 2020. Understanding and supporting academic literature review workflows with litsense. In Proceedings of the International Conference on Advanced Visual Interfaces, pages 1-5.</p>
<p>Don R Swanson and Neil R Smalheiser. 1996. Undiscovered public knowledge: A ten-year update. In $K D D$, pages 295-298.</p>
<p>Brandon Tran, Maryam Karimzadehgan, Rama Kumar Pasumarthi, Michael Bendersky, and Donald Metzler. 2019. Domain adaptation for enterprise email
search. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 25-34.</p>
<p>Brian Traynor, Ciara Mulcahy, Hugo Uvegi, Tunahan Aytas, Nicolas Chanut, and Elsa A Olivetti. 2020. Dissolution of olivines from steel and copper slags in basic solution. Cement and Concrete Research, 133:106065.</p>
<p>Ryen W. White and Resa A. Roth. 2009. Exploratory search: Beyond the query-response paradigm. Synthesis Lectures on Information Concepts, Retrieval, and Services, 1:98.</p>
<p>Yi Xie, Yuqing Sun, and Elisa Bertino. 2021. Learning Domain Semantics and Cross-Domain Correlations for Paper Recommendation, page 706-715. Association for Computing Machinery, New York, NY, USA.</p>
<p>Xiaofeng Xu, Santonu Goswami, Jay Gulledge, Stan D Wullschleger, and Peter E Thornton. 2016. Interdisciplinary research in climate and energy sciences. Wiley Interdisciplinary Reviews: Energy and Environment, 5(1):49-56.</p>
<p>Dengmei Zhou, Chong Zeng, Jing Xiang, Tao Wang, Zitian Gao, Chunlian An, and Wanxia Huang. 2022. Review on Mn-based and Fe-based layered cathode materials for sodium-ion batteries. Ionics, pages 112 .</p>
<h2>A Evaluation of Global Clusters</h2>
<p>To investigate the ability of clustering methods for separation of materials science corpora into coherent subdomains, we compare model generated clusters with author-provided keywords treated as gold standard labels.
Dataset. To generate our evaluation dataset domain experts first screened most frequent keywords in a multi-domain dataset of 700k English materials science publications and selected 18 keywords indicative of sub-domains (see Table 2). Next, only a subset of the corpus with documents assigned a single keyword of the 18 sub-domain keywords was retained for evaluation. This yields a corpus of 39,699 documents. A sample of these documents were checked manually to ensure that they represented reasonable paper-keyword assignments. This corpus is available. ${ }^{3}$
Experimental Protocol. We compare the method used in our system, SPECTER (Cohan et al., 2020) to TFIDF and SCIBERT baselines (Beltagy et al.,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th></th>
<th>Keywords</th>
<th>Keywords</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Present</td>
<td>Removed</td>
</tr>
<tr>
<td>RANDOM</td>
<td>27.37</td>
<td>27.37</td>
</tr>
<tr>
<td>TFIDF</td>
<td>$\mathbf{4 8 . 0 8}$</td>
<td>39.75</td>
</tr>
<tr>
<td>SCIBERT</td>
<td>31.80</td>
<td>31.32</td>
</tr>
<tr>
<td>SPECTER</td>
<td>47.93</td>
<td>$\mathbf{4 3 . 9 0}$</td>
</tr>
</tbody>
</table>
<p>Table 1: Domain cluster purity for SPECTER, compared to baseline approaches on a corpus of materials science papers and author-provided keywords. Number of clusters = 18. Reported metrics represent cluster purity in percent, averaged over three runs. "Keywords Removed" represents the performance after removal of all category defining keywords (of Table 2) from the text of the title and abstract based on which paper representations are computed.
2019). For evaluation of document clusters, embeddings are computed using publications titles and abstracts. SCIBERT and SPECTER input the papers as "Title [SEP] Abstract". To generate clusters we employ K-Means with $K=18$. We report average cluster purity over three separate runs of clustering (Manning et al., 2008, C16.3).
Results. Results (Table 1) show SPECTERs' ability to induce subdomains clusters. Surprisingly high dimensional TFIDF embeddings perform similarly to transformer generated SPECTER embeddings (column: "Keywords Present"). An explanation for this might be found in the evaluation dataset we created - clusters based on author provided keywords, which are also likely to appear in the title and abstract of a paper are likely to see term-based methods (i.e. TFIDF) seeing strong performance. To investigate this further, we repeat the evaluation after removing the 18 category defining keywords (Table 2) from abstracts and title text before encoding papers. This experiment (column: "Keywords Removed") strengthens our hypothesis, showing a larger drop in the measured cluster purity values for the TFIDF approach compared to SPECTER. SPECTER's ability to induce clusters in the absence of explicit term overlap provides the value needed in our search setup.</p>
<h2>B Procedure and Interface Design Used in the Case Studies</h2>
<p>Participants. Three participants (1 female) whose research areas are in the broader space of material science and engineering were recruited for interviews. The mean age of participants was 24 $(\mathrm{SD}=4.04)$. They all reported conducting a review</p>
<table>
<thead>
<tr>
<th style="text-align: center;">magnetic materials</th>
<th style="text-align: center;">carbon materials</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ceramics</td>
<td style="text-align: center;">optical properties</td>
</tr>
<tr>
<td style="text-align: center;">electrochemistry</td>
<td style="text-align: center;">nanomaterials</td>
</tr>
<tr>
<td style="text-align: center;">alloys</td>
<td style="text-align: center;">photocatalysis</td>
</tr>
<tr>
<td style="text-align: center;">semiconductors</td>
<td style="text-align: center;">solar cells</td>
</tr>
<tr>
<td style="text-align: center;">fuel cells</td>
<td style="text-align: center;">polymers</td>
</tr>
<tr>
<td style="text-align: center;">composite materials</td>
<td style="text-align: center;">biomaterials</td>
</tr>
<tr>
<td style="text-align: center;">thermodynamics</td>
<td style="text-align: center;">lithium-ion batteries</td>
</tr>
<tr>
<td style="text-align: center;">thin films</td>
<td style="text-align: center;">microstructure</td>
</tr>
</tbody>
</table>
<p>Table 2: Keywords representative of clusters in our cluster evaluation dataset.
of related work using scholarly search engines as a research facilitator and vehicle for learning.
Procedure. Participants prepared a query paper and a description of their research problem (Table 3) and chose search engines they personally use the most and are familiar with for the first stage ( 20 min ) of the interview. Using the search engines of their choice, participants in the first stage looked for as many related work as possible for the query domain. The goal of this stage was to gain a sense of 'what is out there' which served as context for their judgement on retrieval results in the subsequent stage using our system. In the next stage, participants interacted with our system with the focus of finding different ideas than what they have found in the first stage ( 20 min ). For the papers they found interesting, they provided feedback on two dimensions, 1) Novelty with the following ternary response options (1: "I have seen this exact paper before"; 2: "I have not seen this exact paper but similar ideas before"; 3: "I have not seen anything like this before," similar to the scale used in (Kang et al., 2022a)) and 2) Relevance with binary response options. The collected feedback was used in the end-of-session debriefs to aid both the interviewer's and participants' memory and discussion grounded on specific examples.</p>
<h2>C Related Work</h2>
<p>Our work bears resemblance to a number of prior lines of work. We group these broadly into methods for exploratory search of text corpora, and methodological NLP and information retrieval work which bears resemblance to parts of our system.</p>
<h2>C. 1 Exploratory Search for Text Corpora</h2>
<p>A large body of work has explored the problem of exploratory search for text corpora, with searchers</p>
<table>
<thead>
<tr>
<th style="text-align: center;">PID</th>
<th style="text-align: center;">Research Domains</th>
<th style="text-align: center;">Seed Paper \&amp; Query sentence</th>
<th style="text-align: center;">Baseline Search System</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">New ways of producing cement using industrial wastes to lower the carbon footprint and maintain sustainability in commercial bldgs</td>
<td style="text-align: center;">Query sentence was the 2nd sentence in the abstract of Traynor et al. (2020)</td>
<td style="text-align: center;">CONNECTEDPAPERS ${ }^{4}$</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">New electrolyte materials for simultaneously increasing the capacity and stability of batteries</td>
<td style="text-align: center;">Query sentence: 8th abstract sentence in Abhilash et al. (2013)</td>
<td style="text-align: center;">SCIFINDER $^{5}$</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Understanding the barriers to scaling up the manufacturing of effective cathode materials</td>
<td style="text-align: center;">Query sentence: 2nd abstrct sentence in Zhou et al. (2022)</td>
<td style="text-align: center;">Google Scholar</td>
</tr>
</tbody>
</table>
<p>Table 3: Participants' research domains, seed papers used in the study, and baseline search engines they chose.
often interested in learning and discovery of new content. These search tasks are often characterized by an open-ended and multifaceted information need and involve a sizable browsing component (White and Roth, 2009, Sec 2.4). Given the importance of these aspects, we group the ways in which prior work represents documents in a system, this in turn, affect the ways that users query a search system. In describing past work we also highlight the ways in which they facilitate browsing.</p>
<p>Exploration via rhetorical structure. This line of work primarily consists of designing a schema of labels to describe the rhetorical structure elements of documents, automatically or manually extracting these elements from documents, and indexing and retrieving documents along these aspects in response to a query. Document representation with rhetorical structure elements follows from a large body of work demonstrating that problem solving is often characterized by descriptions of the Situation, Problem, Solution, and Evaluation (Heffernan and Teufel, 2018, Sec 1). In practice, a primary bottleneck of this line of work is its reliance on a schema of labels - making transitions to new corpora challenging. The closest prior work of this type is that of analogical search for creative ideation applied to science and design (Hope et al., 2017, 2021; Kang et al., 2022a). The method of query specification in this body of work is primarily via short text queries. In contrast, our system adopts a faceted query-byexample approach where searchers query with an example document and indicate an aspect of the document they would to focus on via selecting text spans, with documents indexed at the sentence level (Mysore et al., 2021). In this respect, work of Chan et al. (2018) and Neves et al. (2019) bear the closest resemblance to ours in supporting querying with documents in combination with a fixed schema of
aspect labels.
While most work highlighted above retrieve a list of documents, Chan et al. (2018) and Hope et al. (2021) present exceptions in allowing browsing via domain-like structures - bearing resemblance to our approach. While Chan et al. (2018) search across domain structures informed by document metadata, our system relies on a set of automatically built global domain clusters and a set of query specific local clusters. Similarly, Hope et al. (2021), allow exploration of purpose and mechanism aspects via a hierarchical organization of these aspects constructed with a rule-mining approach. This approach, while well suited to use cases where aspects can be pre-extracted proves challenging to operationalize in the absence of these extractions. Our work complementarily prioritizes flexibility in query specification without a schema based document representation.</p>
<p>Other work also bear resemblance to the ones presented above. Jain et al. (2018) learn aspect disentangled paper representations with aspect specific encoders trained with similarity data aligned to aspects in biomedical abstracts. Chakraborty et al. (2016) present a system for retrieval of similar papers grouped along a schema of aspects based on citation and content similarities to a query. Ostendorff et al. (2020), present an approach to classify the aspect of similarity between a pair of papers rather than producing a ranking over documents. Portenoy et al. (2022) present a system for exploring authors across knowledge domains.
Exploration via topical structures. A separate line of work has also leveraged topical structures such as knowledge base entities (concepts), keywords, or other model inferred topic structures. Hope et al. (2020) present a system for exploration of biomedical concepts (e.g. proteins, diseases,</p>
<p>drugs) and research groups. Similarly, Shukla and Hoeber (2021) enhance academic search engine result pages with keywords available in document metadata, and Sorkhei et al. (2017) allow exploration of a corpus of papers via topics inferred with a LDA model. Besides the bottleneck of concept extraction in some of these methods, a key challenge of concept based exploration, as noted in Hope et al. (2020) and Sultanum et al. (2020), stems from users desire to continually explore additional concepts unavailable in a system or add concepts of their own. We alleviate this drawback in part by allowing users to directly query with text spans in a document context. That said, the two methods provide complementary value - while topical structures provide value in gaining an overview of a corpus our approach is likely to allow expression of more complex queries.</p>
<h2>C. 2 Search and Recommendation</h2>
<p>A body of work in NLP, information retrieval, and recommendation bear resemblance to parts of our system. We group these into query-by-example methods and methods for cluster ranking and result diversification. While the former contextualizes our document representation and querying mechanism the latter contextualizes our result presentation.</p>
<p>Query-by-Example. This body of work primarily intends to retrieve documents given a query document and is well suited to exploratory search given its ability to express more context for underspecified queries (Ksikes, 2014; Lissandrini et al., 2019). This is best represented in El-Arini and Guestrin (2011), who present a system for personalized recommendation of papers given a set of user trusted papers - with documents presented as a diversified ranking of candidate documents based on citation network similarities. A large body of work under citation recommendation also recommends documents similar to a query document FÃ¤rber and Jatowt (2020). Recent work has also seen strong performance for a variety of scientific paper recommendation tasks by training transformer biencoder models on citation network data (Cohan et al., 2020; Ostendorff et al., 2022). In contrast with this work, our work intends to model aspect conditional similarities. Closest work to ours is presented by Mysore et al. (2022) who extend these transformer bi-encoder models to a sentence level multi-vector model intended for finer-grained aspect conditional document similarities trained with co-citation data and textual supervision.
Cluster retrieval and diversification. In our generation of results based on a set of global clusters and a set of local clusters, our work departs from the standard IR assumption of treating candidate documents as independent from each other - Pang et al. (2021) overview this line of work. In doing so, our work relates to lines of work on search result diversification and cluster retrieval. Work in search result diversification most often intends to improve retrieval performance for ambiguous queries by optimizing the novelty of retrieved results or optimizing for coverage of all possible interpretations of a query, Santos et al. (2015) surveys this body of work in the context of search, while Kaminskas and Bridge (2016) survey similar work in the context of recommendations. Close work in cluster retrieval comes from Levi et al. (2018), who investigate the appropriate queries for which results should be grouped on a search result page. These lines of work differ from ours in intending to improve performance for ad-hoc search, our work on the other hand intends to use clusters of documents as a means of controlling "distance" to a query in an exploratory search setup. In this respect, Xie et al. (2021) represents closely related recent work in training a model for citation recommendation across-domain boundaries while leveraging an existing ontology of domain concepts to learn the domain specific semantics - training similar models for our setup represent exciting future steps.</p>
<p>Finally, cross-domain retrieval (Cohen et al., 2018; Tran et al., 2019) aims to improve in-domain performance of retrieval models in a transfer learning setup while our work focuses on retrieval across domain boundaries.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://github.com/olivettigroup/ cross-domain-exploration&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>