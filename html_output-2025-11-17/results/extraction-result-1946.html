<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1946 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1946</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1946</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-41.html">extraction-schema-41</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <p><strong>Paper ID:</strong> paper-278310700</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.00991v1.pdf" target="_blank">DexCtrl: Towards Sim-to-Real Dexterity with Adaptive Controller Learning</a></p>
                <p><strong>Paper Abstract:</strong> Dexterous manipulation has seen remarkable progress in recent years, with policies capable of executing many complex and contact-rich tasks in simulation. However, transferring these policies from simulation to real world remains a significant challenge. One important issue is the mismatch in low-level controller dynamics, where identical trajectories can lead to vastly different contact forces and behaviors when control parameters vary. Existing approaches often rely on manual tuning or controller randomization, which can be labor-intensive, task-specific, and introduce significant training difficulty. In this work, we propose a framework that jointly learns actions and controller parameters based on the historical information of both trajectory and controller. This adaptive controller adjustment mechanism allows the policy to automatically tune control parameters during execution, thereby mitigating the sim-to-real gap without extensive manual tuning or excessive randomization. Moreover, by explicitly providing controller parameters as part of the observation, our approach facilitates better reasoning over force interactions and improves robustness in real-world scenarios. Experimental results demonstrate that our method achieves improved transfer performance across a variety of dexterous tasks involving variable force conditions.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1946.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1946.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DexCtrl (rotation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DexCtrl — adaptive action and controller-parameter prediction framework (in-hand rotation experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that jointly predicts desired joint actions and per-step joint-level PD controller parameters (stiffness K_P and damping K_D) from historical proprioceptive information to reduce sim-to-real gap for contact-rich dexterous in-hand rotation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>in-hand object rotation</td>
                        </tr>
                        <tr>
                            <td><strong>task_timescale</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_contact_ratio</strong></td>
                            <td>contact-rich</td>
                        </tr>
                        <tr>
                            <td><strong>task_precision_requirement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_modeled</strong></td>
                            <td>Joint-level PD gains: K_P (stiffness) and K_D (damping) per joint (diagonal matrices). Torque control law modeled as τ = K_P (q_d - q_c) + K_D (qd - qc).</td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_simplified</strong></td>
                            <td>Assumed diagonal (decoupled) K_P and K_D (no cross-coupling), desired joint velocities set to zero; did not model actuator bandwidth, motor transmission dynamics, backlash, or explicit joint friction models at high fidelity; no force/torque/tactile sensors modeled in real robot simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level_description</strong></td>
                            <td>Moderate-fidelity controller-level modeling: simulation includes a parametric joint-torque PD controller (per-joint gains) but omits detailed actuator dynamics such as bandwidth limits, transmission compliance, and high-fidelity friction/backlash.</td>
                        </tr>
                        <tr>
                            <td><strong>parameter_specific_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Rotation Reward (RotR — in sim: average rotation reward; in real: net rotation in radians), Time To Fail (TTF — average trajectory length before failure), ObjVel (avg object linear velocity, sim only), Torque penalty (sim only). The paper reports these metrics in Tables 1–4 and shows DexCtrl outperforms baselines on RotR and TTF for rotation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>sim_vs_real_performance</strong></td>
                            <td>Qualitative: real-world performance gap is larger than simulation; DexCtrl achieves significantly better zero-shot sim-to-real transfer than manual-tuning and fixed-PD baselines, but the paper does not present a single scalar percentage gap between sim and real.</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_performed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_results</strong></td>
                            <td>Analyzed learned stiffness (K_P): stiffness increases monotonically with object mass; relationship with surface friction is task- and joint-dependent (sometimes increases, sometimes decreases). Heavier objects elicit higher stiffness at specific joints or for longer durations — indicating K_P is a primary factor modulating contact forces.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>The paper compares methods (DexCtrl vs manual tuning vs 'Ours w/o PD' which uses fixed controller parameters) but does not present an explicit experimental comparison across multiple actuator-model fidelity levels.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td>Oracle policies in simulation were trained with diverse object physical parameters (object scale, mass, friction). The student policy training used Gaussian noise added to current trajectory observations; controller parameters were mapped linearly from sim to real with approximate bounds instead of exhaustive controller randomization. No numeric ranges or percent variations for randomized parameters are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>robot_type</strong></td>
                            <td>LEAP hand (dexterous hand), 16-DOF, joint-torque control</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_analysis</strong></td>
                            <td>Identifies mismatch in low-level controller dynamics (PD gains) between sim and real as a key cause of transfer failure; manual tuning of controller gains is laborious and often insufficient, while naive controller randomization increases training difficulty and can cause task failure.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_for_theory</strong></td>
                            <td>Controller-level dynamics (per-joint stiffness and damping) critically determine contact forces and therefore the sim-to-real gap in contact-rich dexterous tasks; adaptively predicting/adjusting PD gains per time step (and including controller parameters in observations) substantially improves zero-shot transfer by better matching force profiles to object properties.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1946.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1946.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DexCtrl (flipping)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DexCtrl — adaptive action and controller-parameter prediction framework (object flipping experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Same adaptive framework applied to object flipping on a table, jointly predicting actions and per-step PD gains to improve sim-to-real transfer in a task with richer environment contact.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>object flipping on a table</td>
                        </tr>
                        <tr>
                            <td><strong>task_timescale</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_contact_ratio</strong></td>
                            <td>contact-rich (contacts with both hand and environment/table)</td>
                        </tr>
                        <tr>
                            <td><strong>task_precision_requirement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_modeled</strong></td>
                            <td>Per-joint PD gains (K_P and K_D) used in joint-torque controller; torque computed as τ = K_P (q_d - q_c) + K_D (qd - qc).</td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_simplified</strong></td>
                            <td>Diagonal (per-joint) PD gains assumed; no explicit modeling of actuator bandwidth, transmission dynamics, backlash, or detailed friction in actuators; no tactile/force sensing used in real-world experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level_description</strong></td>
                            <td>Moderate-fidelity: simulation models PD control influence on torque but omits detailed actuator dynamics and direct force sensing; focuses on controller-parameter effects rather than full actuator dynamics fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>parameter_specific_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Rotation Reward (RotR), Time To Fail (TTF), Torque penalty (sim); the paper reports these metrics (Table 2) showing mixed results: DexCtrl improves oracle performance in some cases but 'Ours w/o PD' did not outperform the manual baseline for flipping, indicating environment contacts increase sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>sim_vs_real_performance</strong></td>
                            <td>Qualitative: DexCtrl demonstrates generalizability to flipping in real world (visualizations provided). The performance gap and numeric sim-vs-real degradation are not summarized as a single scalar in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_performed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_results</strong></td>
                            <td>Controller stiffness patterns varied with object mass and friction; flipping (which involves more environment contact) was more sensitive to contact modeling, and fixed-PD trajectories ('Ours w/o PD') did not consistently outperform manual tuning—indicating that adaptive controller prediction is more critical when environmental contacts are rich.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>Compared algorithmic variants (DexCtrl vs fixed-PD student vs manual tuning) but no explicit comparison between high- and low-fidelity actuator dynamic models.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td>Oracle trained on diverse object physical parameters (mass/friction/scale); student training used Gaussian observation noise; controller mapping to real used approximate bounds rather than extensive controller randomization. Exact ranges not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>robot_type</strong></td>
                            <td>LEAP hand (dexterous hand), 16-DOF, joint-torque control</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_analysis</strong></td>
                            <td>Flipping is more sensitive to contact-rich interactions; the paper attributes poorer relative performance of the fixed-PD baseline to richer contacts with environment and the resulting higher sensitivity to controller-parameter mismatches.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_for_theory</strong></td>
                            <td>Adaptive per-step controller-parameter prediction is especially important for tasks with significant environment contact (e.g., flipping), because fixed controller parameters or trajectory-only transfer fail to account for environment-induced variations in required contact forces.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>In-hand object rotation via rapid motor adaptation <em>(Rating: 2)</em></li>
                <li>Anyrotate: Gravity-invariant in-hand object rotation with sim-to-real touch <em>(Rating: 2)</em></li>
                <li>Efficient sim-to-real transfer of contact-rich manipulation skills with online admittance residual learning <em>(Rating: 2)</em></li>
                <li>Bridging the sim-to-real gap with dynamic compliance tuning for industrial insertion <em>(Rating: 2)</em></li>
                <li>Learning variable impedance control <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1946",
    "paper_id": "paper-278310700",
    "extraction_schema_id": "extraction-schema-41",
    "extracted_data": [
        {
            "name_short": "DexCtrl (rotation)",
            "name_full": "DexCtrl — adaptive action and controller-parameter prediction framework (in-hand rotation experiments)",
            "brief_description": "A framework that jointly predicts desired joint actions and per-step joint-level PD controller parameters (stiffness K_P and damping K_D) from historical proprioceptive information to reduce sim-to-real gap for contact-rich dexterous in-hand rotation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "task_name": "in-hand object rotation",
            "task_timescale": null,
            "task_contact_ratio": "contact-rich",
            "task_precision_requirement": null,
            "actuator_parameters_modeled": "Joint-level PD gains: K_P (stiffness) and K_D (damping) per joint (diagonal matrices). Torque control law modeled as τ = K_P (q_d - q_c) + K_D (qd - qc).",
            "actuator_parameters_simplified": "Assumed diagonal (decoupled) K_P and K_D (no cross-coupling), desired joint velocities set to zero; did not model actuator bandwidth, motor transmission dynamics, backlash, or explicit joint friction models at high fidelity; no force/torque/tactile sensors modeled in real robot simulation.",
            "fidelity_level_description": "Moderate-fidelity controller-level modeling: simulation includes a parametric joint-torque PD controller (per-joint gains) but omits detailed actuator dynamics such as bandwidth limits, transmission compliance, and high-fidelity friction/backlash.",
            "parameter_specific_fidelity": null,
            "transfer_success_metric": "Rotation Reward (RotR — in sim: average rotation reward; in real: net rotation in radians), Time To Fail (TTF — average trajectory length before failure), ObjVel (avg object linear velocity, sim only), Torque penalty (sim only). The paper reports these metrics in Tables 1–4 and shows DexCtrl outperforms baselines on RotR and TTF for rotation tasks.",
            "sim_vs_real_performance": "Qualitative: real-world performance gap is larger than simulation; DexCtrl achieves significantly better zero-shot sim-to-real transfer than manual-tuning and fixed-PD baselines, but the paper does not present a single scalar percentage gap between sim and real.",
            "sensitivity_analysis_performed": true,
            "sensitivity_analysis_results": "Analyzed learned stiffness (K_P): stiffness increases monotonically with object mass; relationship with surface friction is task- and joint-dependent (sometimes increases, sometimes decreases). Heavier objects elicit higher stiffness at specific joints or for longer durations — indicating K_P is a primary factor modulating contact forces.",
            "computational_cost_reported": false,
            "computational_cost_details": null,
            "fidelity_comparison": "The paper compares methods (DexCtrl vs manual tuning vs 'Ours w/o PD' which uses fixed controller parameters) but does not present an explicit experimental comparison across multiple actuator-model fidelity levels.",
            "domain_randomization_used": true,
            "domain_randomization_details": "Oracle policies in simulation were trained with diverse object physical parameters (object scale, mass, friction). The student policy training used Gaussian noise added to current trajectory observations; controller parameters were mapped linearly from sim to real with approximate bounds instead of exhaustive controller randomization. No numeric ranges or percent variations for randomized parameters are reported.",
            "robot_type": "LEAP hand (dexterous hand), 16-DOF, joint-torque control",
            "transfer_failure_analysis": "Identifies mismatch in low-level controller dynamics (PD gains) between sim and real as a key cause of transfer failure; manual tuning of controller gains is laborious and often insufficient, while naive controller randomization increases training difficulty and can cause task failure.",
            "key_finding_for_theory": "Controller-level dynamics (per-joint stiffness and damping) critically determine contact forces and therefore the sim-to-real gap in contact-rich dexterous tasks; adaptively predicting/adjusting PD gains per time step (and including controller parameters in observations) substantially improves zero-shot transfer by better matching force profiles to object properties.",
            "uuid": "e1946.0"
        },
        {
            "name_short": "DexCtrl (flipping)",
            "name_full": "DexCtrl — adaptive action and controller-parameter prediction framework (object flipping experiments)",
            "brief_description": "Same adaptive framework applied to object flipping on a table, jointly predicting actions and per-step PD gains to improve sim-to-real transfer in a task with richer environment contact.",
            "citation_title": "here",
            "mention_or_use": "use",
            "task_name": "object flipping on a table",
            "task_timescale": null,
            "task_contact_ratio": "contact-rich (contacts with both hand and environment/table)",
            "task_precision_requirement": null,
            "actuator_parameters_modeled": "Per-joint PD gains (K_P and K_D) used in joint-torque controller; torque computed as τ = K_P (q_d - q_c) + K_D (qd - qc).",
            "actuator_parameters_simplified": "Diagonal (per-joint) PD gains assumed; no explicit modeling of actuator bandwidth, transmission dynamics, backlash, or detailed friction in actuators; no tactile/force sensing used in real-world experiments.",
            "fidelity_level_description": "Moderate-fidelity: simulation models PD control influence on torque but omits detailed actuator dynamics and direct force sensing; focuses on controller-parameter effects rather than full actuator dynamics fidelity.",
            "parameter_specific_fidelity": null,
            "transfer_success_metric": "Rotation Reward (RotR), Time To Fail (TTF), Torque penalty (sim); the paper reports these metrics (Table 2) showing mixed results: DexCtrl improves oracle performance in some cases but 'Ours w/o PD' did not outperform the manual baseline for flipping, indicating environment contacts increase sensitivity.",
            "sim_vs_real_performance": "Qualitative: DexCtrl demonstrates generalizability to flipping in real world (visualizations provided). The performance gap and numeric sim-vs-real degradation are not summarized as a single scalar in the paper.",
            "sensitivity_analysis_performed": true,
            "sensitivity_analysis_results": "Controller stiffness patterns varied with object mass and friction; flipping (which involves more environment contact) was more sensitive to contact modeling, and fixed-PD trajectories ('Ours w/o PD') did not consistently outperform manual tuning—indicating that adaptive controller prediction is more critical when environmental contacts are rich.",
            "computational_cost_reported": false,
            "computational_cost_details": null,
            "fidelity_comparison": "Compared algorithmic variants (DexCtrl vs fixed-PD student vs manual tuning) but no explicit comparison between high- and low-fidelity actuator dynamic models.",
            "domain_randomization_used": true,
            "domain_randomization_details": "Oracle trained on diverse object physical parameters (mass/friction/scale); student training used Gaussian observation noise; controller mapping to real used approximate bounds rather than extensive controller randomization. Exact ranges not reported.",
            "robot_type": "LEAP hand (dexterous hand), 16-DOF, joint-torque control",
            "transfer_failure_analysis": "Flipping is more sensitive to contact-rich interactions; the paper attributes poorer relative performance of the fixed-PD baseline to richer contacts with environment and the resulting higher sensitivity to controller-parameter mismatches.",
            "key_finding_for_theory": "Adaptive per-step controller-parameter prediction is especially important for tasks with significant environment contact (e.g., flipping), because fixed controller parameters or trajectory-only transfer fail to account for environment-induced variations in required contact forces.",
            "uuid": "e1946.1"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "In-hand object rotation via rapid motor adaptation",
            "rating": 2
        },
        {
            "paper_title": "Anyrotate: Gravity-invariant in-hand object rotation with sim-to-real touch",
            "rating": 2
        },
        {
            "paper_title": "Efficient sim-to-real transfer of contact-rich manipulation skills with online admittance residual learning",
            "rating": 2
        },
        {
            "paper_title": "Bridging the sim-to-real gap with dynamic compliance tuning for industrial insertion",
            "rating": 2
        },
        {
            "paper_title": "Learning variable impedance control",
            "rating": 1
        }
    ],
    "cost": 0.011574999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>2 May 2025
2 May 2025CC4C59FD7140975031133E957F3EFC56arXiv:2505.00991v1[cs.RO]Dexterous ManipulationSim-to-real TransferAdaptive ControlReinforcement Learning
historical information of both trajectory and controller.This adaptive controller adjustment mechanism allows the policy to automatically tune control parameters during execution, thereby mitigating the sim-to-real gap without extensive manual tuning or excessive randomization.Moreover, by explicitly providing controller parameters as part of the observation, our approach facilitates better reasoning over force interactions and improves robustness in real-world scenarios.Experimental results demonstrate that our method achieves improved transfer performance across a variety of dexterous tasks involving variable force conditions.</p>
<p>Abstract: Dexterous manipulation has seen remarkable progress in recent years, with policies capable of executing many complex and contact-rich tasks in simulation.However, transferring these policies from simulation to real world remains a significant challenge.One important issue is the mismatch in low-level controller dynamics, where identical trajectories can lead to vastly different contact forces and behaviors when control parameters vary.Existing approaches often rely on manual tuning or controller randomization, which can be labor-intensive, taskspecific, and introduce significant training difficulty.In this work, we propose a framework that jointly learns actions and controller parameters based on the</p>
<p>Introduction</p>
<p>Dexterity is a core component of human manipulation and has long posed a significant challenge in robotics research.Beyond their strong performance in grasping [1,2,3,4], dexterous manipulation policies has shown capabilities in handling various contact-rich manipulation tasks such as rotating objects [5,6,7,8,9], playing the piano [10,11], and using various tools [12,13].Despite these progress, transferring dexterous policies from simulation to the real world still remains a critical challenge.Currently, many manipulation policies have addressed the sim-to-real gap from various aspects, such as introducing random noise to the observed proprioceptive information or applying random forces to objects to enhance output trajectory robustness.However, we here identify that one important issue has received relatively little attention in previous work: the discrepancies between robot controllers in simulation and the real world.Since the final command sent to the robot is the motor torque computed from both the trajectory and control parameters, failing to explicitly consider robot controller gap still results in a discrepancy between simulated and real-world performance.Nowadays, people try to bridge this gap by manually tuning controller parameters, which compares the robot's trajectory outputs between simulation and the real world to match the final performance [5,14].Additionally, mild randomization of controller parameters during training has also been widely used to enhance policy robustness against sim-to-real discrepancies [7,12].However, manual tuning and randomization can both ultimately lead to task failure in real-world deployments: randomization leads to a substantial increase in training difficulty, and manually tuning control parameters often fails to achieve the necessary precision for successful task execution.Moreover, both of them require extensive effort in adjusting controller parameters and tuning randomization hyperparameters, significantly increasing human labor.Fundamentally, current solutions to this problem have relied merely on extensive attempts based on prior human experiences, rather than a truly principled and automatic approach.</p>
<p>In our work, as shown in Figure 1, we propose a novel method, DexCtrl, that adaptively adjusts the controller parameters based on historical information, thus narrowing the sim-to-real gap.Concretely, DexCtrl model learns to output both actions and controller parameters for each time step based on previous desired and actual joint trajectories as well as the corresponding controller parameters within a time window.By doing so, DexCtrl can automatically adjust the controller behavior in a close-loop manner, bypassing the complicated procedure of manually tuning parameters, with the assurance of strong adaptability to real-world scenarios.Besides, it alleviates the policy exploration difficulty introduced by randomization because DexCtrl directly obtains controller information in observation, leading to better capture of force information.Overall, the contributions of our work are as follows:</p>
<p>• We identify the mismatch of robot controllers as a critical factor in the sim-to-real gap and propose a novel method to adjust the control parameters adaptively.</p>
<p>• We design a simple and elegant framework to jointly obtain actions and controller parameters based on historical information, which can offer better adaptivity to force variation.</p>
<p>• Extensive experiments on two different tasks show our method can significantly outperform baselines in both simulation and the real world, along with thorough analysis.</p>
<p>Problem Statements</p>
<p>Manipulation Tasks Our method primarily focuses on enhancing the sim-to-real performance of dexterous manipulation tasks by bridging the control gap.To validate our approach, we implement two challenging dexterous manipulation tasks that involve contact between objects, hands, and environments: in-hand object rotation and flipping.The goal of the in-hand rotation task is to rotate an object using the fingertips along a specific axis without dropping it, while the goal of the flipping task is to flip an object on a table along a designated axis.Both tasks exemplify the contact-rich behaviors characteristic of dexterous manipulation, where the sim-to-real gap significantly impacts real-world performance.</p>
<p>Robot Controller Our method is primarily designed for policies operating under joint torque control.We use the LEAP hand as an example, which has 16 degrees of freedom (DOF).The torque controller takes in the robot hand desired joint trajectories [q d , qd ] ∈ R 32 , and robot current trajectories [q c , qc ] ∈ R 32 , and computes the corresponding joint torque τ ∈ R 16 as follows:
τ = K P (q d − q c ) + K D ( qd − qc )(1)
We assume K P , K D are diagonal for simplicity, and define K = {K P , K D } ∈ R 32 as the collection of controller parameters, representing the robot stiffness and damping matrices, respectively.As shown in Eq. 1, the torque output is directly modulated by the choice of K, which necessitates careful tuning of these parameters.In particular, besides control parameters K that directly determine the actual torque values, increasing stiffness K P reduces steady-state error but may induce oscillations, while increasing damping K D suppresses overshoot but can amplify high-frequency noise from a dynamic perspective.In policies without adaptive control mechanisms, the controller parameters are fixed, and only the desired trajectory q d t is predicted by the policy.Different from previous work, DexCtrl also predicts controller parameters K t along with q d t at each time step, enabling simultaneous controller adjustment at each time step to meet force requirements and ensure smooth trajectories.Desired velocities qd are set as zero in both our method and previous work.</p>
<p>Methods</p>
<p>Overall framework of our method is shown in Figure 2.During training (Figure 2 a)), we first collect sufficient data using an oracle policy trained in simulation with diverse object physical parameters.Then we distill two separate models to predict desired action and control parameters, respectively, based on historical information extracted from the collected dataset.During inference (Figure 2 b)), we recursively predict desired actions for the next step given current and historical observations, and then predict control parameters for the next step based on the generated desired action.By doing so, our method provides two main advantages.First, we include control parameters and actions as part of the observation, which better handles force information and narrows the sim-to-real gap.Second, our method explicitly predicts control parameters with a separate module, which not only adaptively adjusts parameters to improve task performance but also reduces overall training difficulty.</p>
<p>Oracle Policy for Data Collection</p>
<p>We utilize model-free Proximal Policy Optimization (PPO) reinforcement learning to obtain oracle policies in simulation.Specifically, for each time step t, oracle policy π(a t , K t | s t ) takes in state s t , outputs joint action a t and K t simultaneously.The action a t is executed using a controller with parameters K t .The desired joint trajectories at t time step are obtained from q d t = q d t−1 + a t .The detailed task designs for two contact-rich manipulation tasks are described as follows:</p>
<p>State: States of two tasks s t ∈ R 219 contain observation of object and robot over the last three time steps.Robot information s r t ∈ R 64 for each step includes current joint positions q c t , desired joint positions q d t and controller parameters K t .Object information s obj t ∈ R 9 contains object pose p obj t ∈ R 6 and object property vector µ ∈ R 3 , including scale, mass and friction.In short, the state can be presented as: s t ≜ (s r t−2:t , s obj t−2:t ), s r t ≜ (q c t , q d t , K t ), s obj t ≜ (p obj t , µ) Reward Reward of two tasks r t mainly contains four parts:
r t = r rotation + r contact + r smoothness + r terminate(2)
The rotation speed reward r rotation encourages the object to rotate faster along a certain axis until it reaches the targeted maximum speed.The contact reward r contact encourages binary contacts between the object and the fingertips.The smoothness reward r smoothness penalizes sudden changes of robot joint positions and torques.The terminal reward r terminate penalizes objects when falling off the fingertips (Rotation) and moving too far from the initial positions (Flipping).Details of reward parameters can be found in the appendix.</p>
<p>Action Prediction and Control Parameters Prediction</p>
<p>We separately train our student policy into two modules, i.e. an action prediction module for trajectory generation and a control parameter prediction module for adapting control parameters, as not only do they encode fundamentally different aspects of the task, but also we want to prevent control parameters prediction from affecting action prediction.</p>
<p>Historical Information for Distillation Though feasible for task completion, oracle policies cannot be directly transferred to the real world because some primitive information such as object information is not directly accessible in real-world settings.To solve this problem, our method utilizes historical states of robot proprioception to distill primitive information used in oracle policy, enabling the estimation of rotated object properties [6].Concretely, we use the last ten steps of the current and desired joint trajectories, along with corresponding controller parameters as historical information for policy input.</p>
<p>Module Design To better leverage historical information, we use self-attention to model temporal historical input for action prediction.For control parameter prediction, we use cross-attention where current action serves as query and historical input serves as key and value, modeling the relationship between the current action and historical input.Although the historical input formulations of the two modules remain the same, their meaning is completely different.In action prediction, the input mainly indicates the trend of joint trajectory variation, similar to the previous work [7,8].In control parameter prediction, it mainly indicates an approximate relation between joint actions and control parameters, which can be analogized to how humans infer current control parameters decisions based on historical trajectories and previous parameters.</p>
<p>Training and Inference</p>
<p>Training processes of the two modules are performed in an open-loop manner, meaning all input data is directly retrieved from the collected simulation dataset.However, during both simulation and real-world inference, our method performs closed-loop behaviors, meaning values of current trajectories are obtained from actual robot sensors.We linearly map the control parameters from simulation to their corresponding values on the real-world system, with only an approximate estimate of upper and lower bounds instead of careful calculation and tuning.Furthermore, we find that adding Gaussian noise to the current trajectory values during student policy training is enough for sim-to-real transfer, even though the training dataset is not collected by a teacher policy with input noise randomization.This finding indicates that certain randomization on observation can be reduced to ease the teacher policy training procedure.</p>
<p>Experiments</p>
<p>We conducted experiments in both simulated and real-robot environments to evaluate our proposed method.Specifically, we present results on contact-rich dexterous manipulation tasks, examining two key aspects: in-hand rotation, which emphasizes object-hand interaction, and object flipping, which highlights environment contact.Our investigation primarily addresses key questions through in-hand rotation experiments, with in-hand flipping serving as a supporting task to provide additional insights: Q1: Does our method improve the original oracle performance?Q2: Does our method narrow the sim-to-real gap?Q3: How does our method perform across objects with varying physical parameters?Q4: How do changes in controller parameters impact the results?</p>
<p>Experimental Setup</p>
<p>Baselines We compare our method with two main baselines:</p>
<p>• Manual Tuning Similar to [5,7], this baseline trains a new oracle policy with (1) carefully tuned control parameters based on trajectory output comparison between simulation and real world (2) a small range of randomization added on the controller, and then use this new oracle policy for student policy training.Both the new oracle policy and student policy would not output adaptive controller parameters.</p>
<p>• Ours w/o PD This baseline replaces the adaptive controller parameter prediction module in the student policy with fixed controller parameters same as manual tuning, and only trains the action prediction module using the dataset collected by our oracle policy.</p>
<p>Metrics We quantitatively evaluate the performance of all methods with four metrics [6,7]:</p>
<p>• Rotation Reward/Radians (RotR) This metric represents the rotation speed of the targeted object around the desired axis.In simulation, it is calculated as the average rotation reward over a trajectory.In the real world, it is calculated by the net rotation of object in radians over a trajectory.</p>
<p>• Time To Fail (TTF) This metric represents the average trajectory length before the object falls off the hand or moves too far from its initial positions in rotation and flipping tasks, respectively.</p>
<p>• Object linear Velocity (ObjVel) This metric represents the average magnitude of object linear velocity per action step.It reflects the stability of the targeted object.This metric is only calculated in the simulation because real-world object velocity can not be easily measured in rotation.It is only evaluated in rotation because such behavior is inevitable in flipping.</p>
<p>• Torque Penalty (Torque) This metric computes the torque penalty reward per time step to measure the energy cost and it is only measured in simulation.</p>
<p>Does our Method Improve the Original Oracle Performance?</p>
<p>We first test DexCtrl in a simulation environment with and without randomly applying force disturbances on objects.During validation, we randomize 1024 different initial robot poses and set the simulation controllers exactly the same as those used during training, meaning no controller gap is involved.This experiment aims to show whether performance can be improved by simultaneously adjusting action and control parameters even under the same controllers.to controller parameters' variance.In conclusion, our method outperforms the baseline in both task performance and training speed, even in the absence of the controller gap.</p>
<p>Does our Method Narrow the Sim-to-real Gap?</p>
<p>We directly deploy DexCtrl in real-world scenarios.For the in-hand rotation task, we use twelve different real-world unseen objects with varying masses and frictions, and validate rotation performance based on the average metrics over ten randomly sampled initial robot poses per object.Table 3 and Figure 4 present quantitative results and visualizations of DexCtrl along with baselines across different objects, respectively.Compared to the simulation results, the performance gap among different methods is more pronounced in the real world, where DexCtrl significantly outperforms the baseline under zero-shot sim-to-real transfer.Also, Ours w/o PD achieves relatively strong performance, demonstrating that trajectories generated by DexCtrl can be more robust when transferred to real-world scenarios.It's worth noticing that the performance gap between DexCtrl and Ours w/o PD is much larger in the real world than in simulation.This finding highlights the necessity of adaptively adjusting control parameters at every step in real-world robots, which further emphasizes the importance of adaptive controller prediction in tackling sim-to-real issues.We also conduct real-world experiments on the flipping task with visualizations shown in Figure 3, demonstrating the real-world task generalizability of our method.</p>
<p>How does our Method Perform across Objects with Varying Physical Parameters?</p>
<p>To further evaluate our policy, we perform additional tests on objects with different masses and friction coefficients.To ensure better control over confounding factors, we use a hollow cube for mass experiments and vary its mass by inserting different internal objects, and use cubes of different textures with the same mass for friction experiments.As shown in Table 4 and Figure 5, our method significantly outperforms both baselines, especially on heavy objects, indicating that it can better adapt to objects with different physical parameters.Also, the pattern of our method broadly aligns with our force-based predictions, namely, the lightest and smoothest objects exhibit the highest speed and lowest stability, respectively.</p>
<p>How do Changes in Controller Parameters Impact the Results?</p>
<p>In this section, we investigate the fundamental question: how do the learned controller parameters affect dexterous manipulation performance?To simplify the analysis, we focus solely on the pattern of learned stiffness, as it contributes more than damping to the task performance.Theoretically, changes in stiffness directly influence the resulting joint torques, thereby modulating the contact forces between the robot and the manipulated object.Given that objects with different physical properties (e.g., mass and friction) require distinct contact force profiles, we hypothesize that variations in stiffness are closely related to object-specific configurations, aiming to provide better adaptation to varying force requirements.</p>
<p>To validate this hypothesis, we first analyze data collected in the simulation.Figure 6 illustrates the relationship between the average stiffness observed across trajectories and object mass as well as surface friction.The results reveal that stiffness increases monotonically with mass (left of Figure 6), consistent with the intuitive physical principle that heavier objects require greater force for manipulation.However, the relationship between stiffness and friction is more nuanced: in some cases, stiffness increases with friction (middle of Figure 6), while in others it decreases (right of Figure 6).We attribute this inconsistency to task-dependent dynamics.For instance, in rotation tasks, friction may primarily resist angular motion at certain joints, while at others it may act more like a supporting or pushing force.This suggests that the role of friction-and consequently the required stiffness-depends on both the object's properties and the specific joint-task interaction.</p>
<p>To further investigate this relationship in real-world settings, we isolate the controller parameters prediction module and provide ground-truth actions to only predict controller parameters.This allows us to observe the influence of object properties without the confounding effects of policy action noise.Figure 7 presents the trends across objects with varying mass and friction.Two consistent patterns emerge: (1) for heavier objects, stiffness tends to increase at specific time steps or remain at its maximum value for longer durations; (2) for smoother objects, stiffness exhibits similar patterns at some joints but opposite trends at others, again indicating task-and joint-specific behavior.</p>
<p>In summary, our results show that the learned stiffness adapts systematically to object mass and friction, validating our hypothesis that controller parameters encode variations in required contact forces and thereby enhance manipulation performance through better adjustment to force requirements.</p>
<p>Related Work</p>
<p>Sim-to-real Transfer in Dexterous Manipulation Dexterous manipulation tasks typically involve complex interactions between robots and objects through contact [15,16,17,18,19].Simulation has proven to be an effective way to learn these behaviors [20,21,4,22], as teleoperation [23,24,25,26,27,28] is often not feasible due to the embodiment gap and the delicate nature of the tasks.However, the sim-to-real gap remains a significant challenge [20,29].To bridge this gap, various approaches have been explored, including system identification, policy fine-tuning, and domain randomization [8,30].However, previous methods have largely overlooked the sim-toreal controller gap, while our work focuses on narrowing this sim-to-real controller-level gap and significantly improves task performance.</p>
<p>Learning Adaptive Force Control Learning adaptive force control has been shown to be beneficial for contact-rich manipulation tasks, as varying control parameters can regulate the robot's behavior during interaction.Several works in the literature demonstrate its effectiveness for various contactrich tasks, such as robotic table wiping [31,32], object pivoting [33,34], and assembly [35,34,36].However, this approach has received relatively little attention in the context of dexterous manipulation, and the question of whether and how such a method influences dexterous hand manipulation has not been specifically answered.In our work, we apply the idea of adaptive control to contact-rich dexterous manipulation and prove its efficiency in performance improvement with ample quantitative results, visualization, and discussions.</p>
<p>Conclusion</p>
<p>In this work, we address the challenge of narrowing the sim-to-real gap in dexterous manipulation by applying adaptive control parameters, and propose a novel method that jointly outputs actions and control parameters based on historical information.To validate our approach, we conduct comprehensive experiments in both simulation and real-world scenarios, and analyze how control parameters contribute to performance improvements through in-hand rotation tasks.We also apply our method to the flipping task, demonstrating its generalizability across dexterous manipulation settings.In the future, we plan to expand the applicability of our policy so that multiple dexterous tasks can share a single control parameters prediction module.Additionally, if supported by hardware, another promising direction is to perform online fine-tuning based on real-time force feedback.</p>
<p>Limitations</p>
<p>Limitations of our method arise primarily in two aspects.First, our approach currently does not incorporate real-world force or tactile sensing due to hardware limitations.As a result, it relies solely on proprioceptive information, which may not be sufficient to fully recover the system state, particularly in contact-rich scenarios.Future work could explore integrating our method with highfidelity force feedback to further improve real-world performance.Second, the real-world evaluation is limited to the LeapHand platform, constrained by the available hardware.In future work, we aim to extend our method to other dexterous hand platforms to assess its generalizability across different robotic embodiments.</p>
<p>Figure 1 :
1
Figure 1: Compared to previous work with only action prediction (upper left), DexCtrl (lower left) jointly predicts both action and control parameters, significantly reducing human labor for tuning and achieving better performance on two contact-rich manipulation tasks: rotation and flipping.</p>
<p>Figure 2 :
2
Figure 2: Overview framework of DexCtrl, where ât and Kt mean predicted joint position actions and predicted control parameters, respectively.</p>
<p>Figure 3 :
3
Figure 3: Flipping task performance in simulation and real world.</p>
<p>Figure 4 :
4
Figure 4: Real-world results of object rotation with different physical parameters.</p>
<p>Figure 5 :
5
Figure 5: Visualization for same-shape objects rotation with different masses and frictions.</p>
<p>Figure 6 :
6
Figure 6: Average stiffness curve under mass (left) and friction change (middle and right).</p>
<p>Figure 7 :
7
Figure 7: Stiffness over time under varying mass and friction.</p>
<p>Table 1 and
1
Table 2present the quantitative results of baselines and DexCtrl in simulation validation.Compared to the manual tuning baseline, DexCtrl improves performance significantly, especially in RotR and TTF.This demonstrates that our method can effectively stabilize and accelerate the task process with or without disturbance.It's worth noticing that Ours w/o PD also reaches relatively good performance, indicating the robustness of trajectories generated by our method.However, in the flipping tasks with results in Table2, Ours w/o PD does not outperform the baseline.We believe it is because flipping involves rich contact between both the floor and the dexterous hands, making it more sensitive</p>
<p>Table 1 :
1
Rotation oracle policy in simulation.
MethodRotR ↑TTF ↑Torque ↓ObjVel ↓With DisturbanceManual Tuning Ours w/o PD Ours35.05 41.60 43.51239.4 252.3 255.90.398 0.152 0.0990.154 0.140 0.144Without DisturbanceManual Tuning Ours w/o PD Ours37.64 47.87 52.33247.5 275.8 287.70.264 0.144 0.0920.148 0.131 0.132</p>
<p>Table 2 :
2
Flipping oracle policy in simulation.
MethodRotR ↑TTF ↑Torque ↓With DisturbanceManual Tuning Ours w/o PD Ours91.07 82.23 172.50295.2 295.6 296.90.376 0.299 0.140Without DisturbanceManual Tuning Ours w/o PD Ours92.24 82.90 184.00295.0 295.4 296.90.446 0.328 0.127</p>
<p>Table 3 :
3
Quantitative results of rotation performance for objects with different masses and frictions.
Cube(94g)Bottle(150g)Apple(221g)Yogurt(164g)Baseball(144g)AverageManualRotR ↑1.9632.8751.9142.9432.7452.431TuningTTF ↑286.5266.9242.7300239.6272.4OursRotR ↑5.4984.2854.4925.4244.6814.986w/o PDTTF ↑297.7281.7291.6300271.6287.2OursRotR ↑ TTF ↑9.386 289.314.006 3009.676 30015.017 30011.342 292.211.041 292.6</p>
<p>Table 4 :
4
Quantitative results for same-shape objects rotation with different masses and frictions.
MethodsMetricsLightMass MediumHeavySmallFriction MediumLargeManualRotR ↑2.0421.9630.6281.9631.3742.231TuningTTF ↑286.5286.5243286.5239.9288OursRotR ↑4.9985.4982.3565.4984.3554.855w/o PDTTF ↑298.8297.7264.9297.7278.6286.6OursRotR ↑ TTF ↑10.414 258.29.386 289.35.998 3009.386 289.310.211 30010.681 290.4</p>
<p>Dexgraspnet 2.0: Learning generative dexterous grasping in large-scale synthetic cluttered scenes. J Zhang, H Liu, D Li, X Yu, H Geng, Y Ding, J Chen, H Wang, 8th Annual Conference on Robot Learning. 2024</p>
<p>Z.-H Yin, C Wang, L Pineda, K Bodduluri, T Wu, P Abbeel, M Mukadam, arXiv:2503.07541Geometric retargeting: A principled, ultrafast neural hand retargeting algorithm. 2025arXiv preprint</p>
<p>Learning continuous grasping function with a dexterous hand from human demonstrations. J Ye, J Wang, B Huang, Y Qin, X Wang, IEEE Robotics and Automation Letters. 852023</p>
<p>M Yang, C Lu, A Church, Y Lin, C Ford, H Li, E Psomopoulou, D A Barton, N F Lepora, arXiv:2405.07391Anyrotate: Gravity-invariant in-hand object rotation with sim-to-real touch. 2024arXiv preprint</p>
<p>Visual dexterity: Inhand reorientation of novel and complex object shapes. T Chen, M Tippur, S Wu, V Kumar, E Adelson, P , 10.1126/scirobotics.adc9244Science Robotics. 8842023</p>
<p>In-hand object rotation via rapid motor adaptation. H Qi, A Kumar, R Calandra, Y Ma, J Malik, Conference on Robot Learning. PMLR2023</p>
<p>General in-hand object rotation with vision and touch. H Qi, B Yi, S Suresh, M Lambeta, Y Ma, R Calandra, J Malik, Conference on Robot Learning. PMLR2023</p>
<p>Lessons from learning to spin" pens. J Wang, Y Yuan, H Che, H Qi, Y Ma, J Malik, X Wang, arXiv:2407.189022024arXiv preprint</p>
<p>From simple to complex skills: The case of in-hand object reorientation. H Qi, B Yi, M Lambeta, Y Ma, R Calandra, J Malik, arXiv:2501.054392025arXiv preprint</p>
<p>K Zakka, P Wu, L Smith, N Gileadi, T Howell, X B Peng, S Singh, Y Tassa, P Florence, A Zeng, arXiv:2304.04150Dexterous piano playing with deep reinforcement learning. 2023arXiv preprint</p>
<p>Pianomime: Learning a generalist, dexterous piano player from internet demonstrations. C Qian, J Urain, K Zakka, J Peters, arXiv:2407.181782024arXiv preprint</p>
<p>Z.-H Yin, C Wang, L Pineda, F Hogan, K Bodduluri, A Sharma, P Lancaster, I Prasad, M Kalakrishnan, J Malik, arXiv:2502.04307Foundation controller for unprecedented dexterity. 2025arXiv preprint</p>
<p>X Liu, J Adalibieke, Q Han, Y Qin, L Yi, Dextrack, arXiv:2502.09614Towards generalizable neural tracking control for dexterous manipulation from human references. 2025arXiv preprint</p>
<p>In-hand following of deformable linear objects using dexterous fingers with tactile sensing. M Yu, B Liang, X Zhang, X Zhu, L Sun, C Wang, S Song, X Li, M Tomizuka, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2024</p>
<p>T Lin, Z.-H Yin, H Qi, P Abbeel, J Malik, arXiv:2403.02338Twisting lids off with two hands. 2024arXiv preprint</p>
<p>Solving rubik's cube with a robot hand. I Akkaya, M Andrychowicz, M Chociej, M Litwin, B Mcgrew, A Petron, A Paino, M Plappert, G Powell, R Ribas, arXiv:1910.071132019arXiv preprint</p>
<p>Learning dexterous in-hand manipulation. O M Andrychowicz, B Baker, M Chociej, R Jozefowicz, B Mcgrew, J Pachocki, A Petron, M Plappert, G Powell, A Ray, The International Journal of Robotics Research. 3912020</p>
<p>Controlling palm-object interactions via friction for enhanced in-hand manipulation. C B Teeple, B Aktas, ¸ , M C Yuen, G R Kim, R D Howe, R J Wood, IEEE Robotics and Automation Letters. 722022</p>
<p>Z.-H Yin, B Huang, Y Qin, Q Chen, X Wang, arXiv:2303.10880Rotating without seeing: Towards in-hand dexterity through touch. 2023arXiv preprint</p>
<p>D Guo, Y Xiang, S Zhao, X Zhu, M Tomizuka, M Ding, W Zhan, arXiv:2402.16836Phygrasp: generalizing robotic grasping with physics-informed large multimodal models. 2024arXiv preprint</p>
<p>S Zhao, X Zhu, Y Chen, C Li, X Zhang, M Ding, M Tomizuka, arXiv:2411.04428Dexh2r: Task-oriented dexterous manipulation from human to robots. 2024arXiv preprint</p>
<p>F Lan, S Wang, Y Zhang, H Xu, O Oseni, Z Zhang, Y Gao, T Zhang, Dexcatch, arXiv:2310.08809Learning to catch arbitrary objects with dexterous hands. 2023arXiv preprint</p>
<p>C Wang, H Shi, W Wang, R Zhang, L Fei-Fei, C K Liu, arXiv:2403.07788Dexcap: Scalable and portable mocap data collection system for dexterous manipulation. 2024arXiv preprint</p>
<p>K Shaw, Y Li, J Yang, M K Srirama, R Liu, H Xiong, R Mendonca, D Pathak, arXiv:2411.13677Bimanual dexterity for complex tasks. 2024arXiv preprint</p>
<p>Z Fu, T Z Zhao, C Finn, arXiv:2401.02117Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation. 2024arXiv preprint</p>
<p>Dexterous imitation made easy: A learning-based framework for efficient dexterous manipulation. S P Arunachalam, S Silwal, B Evans, L Pinto, 2023 ieee international conference on robotics and automation (icra). IEEE2023</p>
<p>Dexmv: Imitation learning for dexterous manipulation from human videos. Y Qin, Y.-H Wu, S Liu, H Jiang, R Yang, Y Fu, X Wang, European Conference on Computer Vision. Springer2022</p>
<p>T Z Zhao, J Tompson, D Driess, P Florence, K Ghasemipour, C Finn, A Wahid, arXiv:2410.13126Aloha unleashed: A simple recipe for robot dexterity. 2024arXiv preprint</p>
<p>A joint modeling of vision-language-action for target-oriented grasping in clutter. K Xu, S Zhao, Z Zhou, Z Li, H Pi, Y Zhu, Y Wang, R Xiong, 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE2023</p>
<p>Understanding domain randomization for sim-toreal transfer. X Chen, J Hu, C Jin, L Li, L Wang, arXiv:2110.032392021arXiv preprint</p>
<p>Variable impedance control in end-effector space: An action space for reinforcement learning in contact-rich tasks. R Martín-Martín, M A Lee, R Gardner, S Savarese, J Bohg, A Garg, 2019 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE2019</p>
<p>Safe online gain optimization for cartesian space variable impedance control. C Wang, X Zhang, Z Kuang, M Tomizuka, 2022 IEEE 18th International Conference on Automation Science and Engineering (CASE). IEEE2022</p>
<p>Learning variable impedance control. J Buchli, F Stulp, E Theodorou, S Schaal, The International Journal of Robotics Research. 3072011</p>
<p>Efficient sim-to-real transfer of contact-rich manipulation skills with online admittance residual learning. X Zhang, C Wang, L Sun, Z Wu, X Zhu, M Tomizuka, Conference on Robot Learning. PMLR2023</p>
<p>Variable compliance control for robotic peg-in-hole assembly: A deep-reinforcement-learning approach. C C Beltran-Hernandez, D Petit, I G Ramirez-Alpizar, K Harada, Applied Sciences. 101969232020</p>
<p>Bridging the sim-to-real gap with dynamic compliance tuning for industrial insertion. X Zhang, M Tomizuka, H Li, 2024 IEEE International Conference on Robotics and Automation (ICRA). IEEE2024</p>            </div>
        </div>

    </div>
</body>
</html>