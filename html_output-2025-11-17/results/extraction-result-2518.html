<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2518 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2518</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2518</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-235476723</p>
                <p><strong>Paper Title:</strong> Nobel Turing Challenge: creating the engine for scientific discovery</p>
                <p><strong>Paper Abstract:</strong> Scientific discovery has long been one of the central driving forces in our civilization. It uncovered the principles of the world we live in, and enabled us to invent new technologies reshaping our society, cure diseases, explore unknown new frontiers, and hopefully lead us to build a sustainable society. Accelerating the speed of scientific discovery is therefore one of the most important endeavors. This requires an in-depth understanding of not only the subject areas but also the nature of scientific discoveries themselves. In other words, the “science of science” needs to be established, and has to be implemented using artificial intelligence (AI) systems to be practically executable. At the same time, what may be implemented by “AI Scientists” may not resemble the scientific process conducted by human scientist. It may be an alternative form of science that will break the limitation of current scientific practice largely hampered by human cognitive limitation and sociological constraints. It could give rise to a human-AI hybrid form of science that shall bring systems biology and other sciences into the next stage. The Nobel Turing Challenge aims to develop a highly autonomous AI system that can perform top-level science, indistinguishable from the quality of that performed by the best human scientists, where some of the discoveries may be worthy of Nobel Prize level recognition and beyond.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2518.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2518.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist Adam</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-loop robot scientist that automatically generated functional genomic hypotheses and executed experiments to test them in budding yeast; an early instantiation of automated hypothesis generation plus experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adam (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A closed-loop system that (1) generates hypotheses about gene function from genomic data, (2) designs experimental protocols, (3) executes experiments using laboratory automation, and (4) analyses results to accept/reject hypotheses; described as an end-to-end automation of hypothesis generation and wet-lab validation in yeast.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>closed-loop automated hypothesis-generation + lab automation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology / functional genomics</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Data-driven generation from genomic datasets using symbolic/algorithmic hypothesis-formers that propose gene-function hypotheses (inferred from the cited King et al. work); hypothesis sets are enumerated and prioritized for experimental testing.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Consistency checking against available genomic/experimental data and prioritization for experimental testing (as described generally; implementation details not given in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Experimental wet-lab validation executed by robotic lab instruments in a closed-loop workflow; results analysed to accept/reject hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Automated execution of protocols for traceability and reproducibility; provenance recording of experiments (paper emphasizes automation and traceability as reproducibility enablers).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Implicit via recording of experimental evidence and survival against falsifiability; probabilistic knowledge representation discussed in the broader text but not specific to Adam.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Used to discover/verify orphan enzyme functions in yeast (cited as an example of automated scientific discovery).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Special-purpose, highly engineered for particular tasks and not fully autonomous in strategic topic selection; scalability and domain-generalization remain challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2518.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist Eve</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated system designed for drug repositioning and high-throughput hypothesis testing that combined in silico hypothesis generation with automated assays to find candidate therapeutics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eve (Automated drug-repositioning system)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A closed-loop platform that generates drug-repositioning hypotheses, automates low-throughput assays for validation, and analyses results; optimized for screening and repositioning tasks with robotic execution of protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>closed-loop automated hypothesis-generation + lab automation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>drug discovery / neglected tropical diseases / biology</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>In-silico generation of repositioning hypotheses (drug-target-disease links) guided by data and literature, then prioritization for automated experimental screening.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Prioritization based on computational predictions and known biological relationships before experimental assays.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Automated biochemical/phenotypic assays executed by robotic instrumentation to validate repositioning hypotheses; example: identification of TP-470 activity as DHFR inhibitor for malaria.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Automation, standardized protocols, and traceable experiment execution to improve reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Implicit via experimental results and survival against falsification; no detailed uncertainty quantification method specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Cited example: repositioning identification (TP-470 repurposed) validated experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Highly automated but task-specialized; not fully autonomous in problem selection; scalability beyond designed tasks is a challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2518.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ramanujan Machine (automated conjecture generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated system that generates mathematical conjectures (formulas for fundamental constants) by searching structured hypothesis spaces of expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generating conjectures on fundamental constants with the Ramanujan Machine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that algorithmically enumerates candidate mathematical expressions/conjectures for constants and filters them by fitting to high-precision numerical values, thereby proposing novel conjectures for further analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic/conjecture-generation (search + pattern-fitting)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mathematics (conjecture generation)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Combinatorial enumeration of formula templates and numerical fitting against high-precision constants to propose conjectures.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty is implicit by generating formulas not previously known; assessed by whether formula matches constants and whether it is previously published (not detailed in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Numerical consistency with high-precision values provides plausibility; symbolic/analytic proof remains required.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Numerical fit to high-precision constants (residual error) used as selection criterion (paper mentions approach conceptually).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational numerical consistency checks; final validation requires mathematical proof or further analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Numerical residuals and fit errors provide implicit uncertainty indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Generated novel conjectures about fundamental constants (presented as conjectures requiring proof).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Generates conjectures based on numerical fit; does not provide formal proofs; domain limited to expressible formula templates and numerical checks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2518.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous Debating System</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous debating system (AI debate / Project Debater-like)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI system that constructs and evaluates argumentation for and against claims via structured debate to surface evidence and counterarguments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An autonomous debating system.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autonomous Debating System</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that generates structured argumentation, supporting and rebutting arguments, using retrieved evidence and natural-language generation to debate claims; proposed as a component to generate and test argumentation for scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>argumentation-based / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general / argumentative evaluation of claims (applicable to science communication and claim vetting)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not primarily a hypothesis generator, but can produce counter-claims and structured rebuttals that help test and refine hypotheses via adversarial argument generation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Argues for/against claims using retrieved evidence; plausibility judged by strength and provenance of supporting evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human or automated adjudication of debate outcomes and use of evidence-based scoring to rank arguments; suggested as a way to generate argumentation that strengthens or falsifies hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Use of evidence retrieval and provenance to ground arguments (paper points to computational debate as a first step to generate argumentations).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Adversarial rebuttal generation to surface contradictions and weakly supported claims; explicit tracing of evidence provenance.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Argument strength and provenance used as proxy for confidence; no explicit probabilistic model described.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Argumentation alone does not replace experimental validation; effectiveness relies on quality and completeness of retrieved evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2518.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Truth Maintenance System</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Truth maintenance system (TMS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical AI infrastructure for tracking dependencies among beliefs (knowledge items) and updating or retracting beliefs when supporting evidence changes; proposed for managing multiple, probabilistic scientific knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A truth maintenance system.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Truth Maintenance System (TMS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A symbolic system that records assumptions and justifications for beliefs, supports incremental addition/removal of evidence, and maintains consistent sets of beliefs by propagating changes; proposed to maintain multiple contextualized knowledge graphs and track survival/falsification of hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph / symbolic truth-maintenance</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific knowledge management</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Belief support is judged by explicit supporting data and arguments stored in the TMS; hypotheses survive while their supporting justifications remain valid.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Automated re-evaluation of dependent hypotheses when underlying data/arguments change; supports falsifiability by tracing failed justifications.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Provenance and justification recording to enable traceable reasoning chains and reproducibility of knowledge state transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Maintaining explicit evidence-justification links to avoid unsupported assertions (implied).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Detects inconsistent or unsupported beliefs when justifications are removed or contradicted; triggers retraction or forked knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Supports multiple coexisting knowledge sets with dynamic likelihoods; paper suggests tracking probability/likelihood of each knowledge set to represent uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Classical TMS are symbolic and may struggle with the scale and uncertain/noisy nature of large scientific literature unless extended with probabilistic mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2518.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Assumption-based TMS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Assumption-based Truth Maintenance System (ATMS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of TMS that represents multiple contexts (assumption sets) and computes which conclusions hold under which assumptions, enabling parallel maintenance of alternative knowledge graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An assumption-based TMS.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Assumption-based TMS</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Maintains mappings from assumptions to derived beliefs, enabling representation of many alternative, context-specific knowledge states (useful for keeping forks of inconsistent scientific claims with their contexts).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic / context-aware truth maintenance</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general knowledge management for science</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is represented by which assumption sets support a hypothesis; hypotheses tied to strong assumption sets considered more plausible.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Re-evaluation when assumptions are revised or when new data arrive; supports conditional acceptance.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Explicit representation of assumptions and dependencies aids reproducibility and re-analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>By tying beliefs to explicit assumptions and evidence, spurious claims lacking assumptions/evidence can be identified.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Contradictions among assumption-supported belief sets trigger detection of conflicting claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Allows multiple coexisting belief sets with varying plausibility; can be extended to probabilistic weights though not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Scalability and integration with noisy probabilistic text-mined data not specified; requires extensions for large-scale literature-driven science.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2518.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Non-monotonic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Non-monotonic reasoning frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Inference frameworks that allow withdrawal of conclusions when new evidence contradicts them, recommended for managing the probabilistic and revisable nature of scientific knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NMR-2020: Workshop Notes of the 18th International Workshop on Non-Monotonic Reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Non-monotonic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A class of logical systems (e.g., defeasible reasoning) that models belief revision, defaults, and context-dependent truth — enabling AI Scientists to maintain multiple, revisable knowledge sets and to retract hypotheses when contradicted.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic reasoning / belief revision</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific reasoning and knowledge maintenance</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility judged relative to current evidence and defaults; conclusions can be retracted when stronger evidence arises.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Logical re-evaluation of hypotheses as evidence is added; supports falsifiability and iterative verification.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Explicit recording of contexts/defaults supporting claims enhances reproducibility of reasoning paths.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>By requiring explicit justifications and allowing retraction when unjustified, reduces persistence of unsupported claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Inconsistency detection when new data conflict with derived conclusions; triggers belief revision.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Represents uncertainty via defeasible conclusions and ranked justifications; probabilistic extensions possible though not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Classical frameworks are symbolic and may require coupling to statistical/probabilistic systems to handle noisy literature-scale data effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2518.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Epistemic Graphs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Epistemic graphs for representing and reasoning with arguments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formalism to represent arguments, their positive/negative influences, and degrees of belief (epistemic weights) used to reason about and rank competing claims.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Epistemic graphs for representing and reasoning with positive and negative influences of arguments.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Epistemic graphs</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Graphical argumentation models where nodes are claims/arguments and edges represent influences (support/attack); epistemic weights quantify belief strength and enable probabilistic-style reasoning about competing hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>argumentation-based / graph-based probabilistic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific argument evaluation and knowledge representation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Belief strengths (epistemic weights) and structure of supportive/attacking arguments used to assess plausibility of claims.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Argument strength scores / epistemic weights as proxies for hypothesis credibility (paper references epistemic graphs as relevant).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Argument-based evaluation using collected evidence and counterarguments; conflicts resolved by comparing epistemic weights and supporting data.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Explicit graphed arguments with provenance allow reproducible re-evaluation of claim strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Require supporting arguments and provenance; weakly supported claims will have low epistemic weight.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Identification of claims with no/weak supporting edges or strong attacking arguments exposes potential hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Epistemic weights provide quantified degrees of belief; can be updated when evidence changes.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Mapping noisy literature claims into structured argumentation graphs at scale is nontrivial; integration with experimental evidence pipelines needed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2518.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T-PAIR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T-PAIR (Temporal node-pair embedding for automatic biomedical hypothesis generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A machine-learning method that uses temporal embeddings of node pairs in biomedical networks to generate hypotheses about biomedical relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Temporal node-pair embedding for automatic biomedical hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>T-PAIR (Temporal node-pair embedding)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Learns temporal embeddings for node pairs in biomedical knowledge graphs (e.g., genes, diseases, drugs) to predict and generate candidate novel relations/hypotheses over time.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>graph-embedding / temporal representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Learning temporal node-pair embeddings from longitudinal literature/graph snapshots and scoring candidate associations to propose hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility via learned embedding similarity and temporal predictive power; higher-scoring candidate pairs prioritized for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Embedding-based prediction scores (rankings); specific metrics not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational ranking and (optionally) subsequent experimental follow-up; the paper cites T-PAIR as an example of automatic hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Implicit via prediction scores and temporal validation performance; explicit uncertainty models not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on quality and temporal coverage of input literature/graphs; experimental validation required for generated hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2518.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deep literature LMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep learning networks trained on large corpora for hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large neural networks trained on millions of scientific articles that can infer molecular interactions and candidate molecule-disease relationships from text, thereby producing hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep literature-trained neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Deep neural language models and representation learners trained on large scientific corpora to extract relationships (molecule–molecule, molecule–disease) and to propose hypotheses; cited as evidence that deep learning can generate extensive molecular-interaction hypotheses from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-style / deep learning / information extraction</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology / biomedical literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Unsupervised or supervised extraction of entity relations from large corpora, followed by link prediction to propose novel interactions and associations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Consistency with co-occurrence, learned relation patterns, and prior literature; prioritization by model confidence/scores.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Model confidence scores / likelihoods for predicted relations (paper mentions predictive capability but not specific metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational consistency checks against held-out literature and retrospective tests (some studies cited show predictions preceding later discoveries), plus eventual experimental testing.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Grounding predictions in evidence from literature and requiring provenance for claims (paper suggests provenance is necessary but does not detail methods).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Retrospective validation against later-published findings; argumentation and TMS could flag unsupported claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Model confidence/score provides uncertainty proxies; explicit Bayesian calibration not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Paper cites studies where deep models recovered molecular interactions and predicted relationships that predated later discoveries (references 31,32 in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Risk of propagating erroneous literature claims; requires provenance and integration with experimental validation to avoid false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2518.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGo family</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaGo / AlphaGo Zero / AlphaZero / MuZero</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A series of deep learning + search / reinforcement learning systems that demonstrated the power of massive, unbiased exploration and self-play in complex domains; used as conceptual models for exploration of hypothesis spaces in science.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mastering the game of Go with deep neural networks and tree search.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaGo family (AlphaGo, AlphaGo Zero, AlphaZero, MuZero)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Systems that combine deep neural networks (policy/value) with Monte Carlo Tree Search (AlphaGo), self-play reinforcement learning (AlphaGo Zero/AlphaZero), and learned model-based planning (MuZero) to explore very large state/hypothesis spaces and discover strategies without human priors; presented as an analogy for exploring scientific hypothesis spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>deep RL + search / model-based RL</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general (conceptual analogy for scientific discovery processes)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Randomized/unbiased generation (self-play) and search-guided sampling of state space informed by learned policy/value models; in the paper this approach is proposed as analogous to randomly generating hypotheses and using search to expand promising regions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Value networks estimate state value (analogy: plausibility/value of hypothesis) to guide search; in scientific context the paper suggests training networks to evaluate hypotheses against existing knowledge and experimental outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>In analogy: computational consistency checks, value estimation, and selective experimental verification of high-value candidates; paper does not report a concrete scientific implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Value estimates and policy probabilities provide internal confidence signals; explicit uncertainty quantification methods for scientific hypotheses are not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Hypothesis space in science is open-ended and continuous, making direct application nontrivial; evaluation costs and ill-defined state descriptions pose challenges compared to games.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2518.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian optimization (robotic search example)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian optimization used in robotic search for cell culture optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An optimization method (Bayesian optimization) applied to robotics-driven parameter search in cell culture to find optimal conditions by efficiently exploring large parameter spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robotic search for optimal cell culture in regenerative medicine.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian optimization (for automated experimental search)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses surrogate probabilistic models (e.g., Gaussian processes) to model objective landscapes and select next experiments to maximally improve objective (e.g., cell culture quality), enabling search through tens to hundreds of millions of parameter combinations efficiently when coupled to robotic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Bayesian optimization / probabilistic surrogate modeling</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>experimental biology / regenerative medicine / lab automation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not a hypothesis generator per se, but explores parameter/hypothesis space by proposing next experimental conditions based on acquisition functions balancing exploration and exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Surrogate model posterior mean and variance used to estimate expected improvement and thus plausibility of candidate conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Acquisition function scores (e.g., expected improvement) and surrogate-predicted performance; specific acquisition functions not spelled out in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Experimental execution by robotic lab followed by measurement of objective (e.g., cell quality); iterative model updating.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Automation and precise control of experimental parameters improve reproducibility; provenance recording implied.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Surrogate posterior predictive variance provides principled uncertainty estimates used by acquisition functions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper cites example searching 200 million parameter combinations by Bayesian optimization in robotic cell-culture optimization (no numeric success rate provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Example: robotic identification of optimal conditions for medical-grade iPS-derived RPE cell culture via Bayesian-optimized search.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Scalability when objective evaluations are extremely costly; requires reasonable surrogate models and constrained input spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2518.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-driving laboratories</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-driving laboratories / closed-loop autonomous labs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Integrated systems combining automated experiment execution, data analysis, and machine-learning-guided experimental design (closed-loop) to accelerate materials/chemical/biological discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-driving laboratory for accelerated discovery of thin-film materials.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Self-driving laboratory (closed-loop automated discovery platform)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Platforms that integrate robotic experiment execution, online analysis, and ML-guided decision-making (e.g., Bayesian optimization or model-based planners) to autonomously select and run experiments and update models iteratively.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>closed-loop lab automation + ML-guided experimental design</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science, chemistry, experimental biology</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate experimental conditions or parameterized hypotheses via acquisition functions or learned policies; can be framed as hypothesis generation in parametric spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Model uncertainty and predicted improvement guide plausibility/prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Direct experimental execution by integrated robotics; model-updates based on measured outcomes provide iterative validation.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Standardized automated protocols, minimized reagent volumes, and provenance tracking to improve reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Surrogate models and predictive uncertainties used to guide experiment selection.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Cited examples in materials and chemistry where self-driving labs accelerated discovery (e.g., thin-film materials).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Integration complexity across diverse experimental modalities and scaling to open-ended hypothesis spaces beyond parametric optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e2518.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Argumentation Module</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Argumentation / computational debate modules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Software modules that automatically generate arguments supporting or refuting scientific claims, intended to strengthen justification or produce rebuttals to test claims.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward artificial argumentation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Argumentation Module</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Generates structured argumentation (claims, evidence, rebuttals) using retrieved data and reasoning templates; intended to produce justifications for hypotheses and to generate counterarguments that can trigger additional experiments or re-evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>argumentation-based / symbolic + retrieval-augmented</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific reasoning and claim evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Not primarily generative of novel hypotheses but produces sub-hypotheses, supporting evidence chains, and rebuttals that refine and stress-test hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Quality and provenance of evidence used in arguments determine plausibility; argument strength metrics can be used to rank claims.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Generates additional experiments or data-collection plans to strengthen or refute arguments; integrates with TMS/knowledge graphs for re-evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Explicit argument and evidence provenance facilitates reproducible assessment of claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Demanding explicit evidence and counterargument generation to reveal unsupported claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Automated generation of rebuttals and cross-checks against evidence to detect weak or hallucinated claims.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Argument strength and conflicting evidence counts provide proxies for uncertainty; probabilistic extensions discussed but not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Effectiveness depends on quality of retrieved evidence and ability to formalize domain arguments; scaling to literature-scale remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2518.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e2518.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qualitative physics / qualitative simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qualitative physics / qualitative simulation methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Symbolic simulation approaches for generating and matching qualitative system behaviors (e.g., bifurcations, phase transitions) to explain observed biological dynamics and generate conceptual-level hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Qualitative modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Qualitative physics / qualitative simulation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Techniques that represent system dynamics qualitatively (signs of change, causal influences, qualitative states) and simulate possible behaviors to generate mechanistic hypotheses about system-level phenomena where precise quantitative models are unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic simulation / qualitative reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>systems biology / dynamical systems modeling</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generate candidate conceptual/dynamical hypotheses by matching qualitative simulation outputs (e.g., possible bifurcations) to observed system behaviors and proposing underlying network structures/mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Consistency of qualitative predictions with observed phenomena and with known mechanistic constraints (e.g., biochemistry and physics).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Propose focused quantitative experiments to test qualitative predictions; used as a human-understandable explanatory layer.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Generates explanations constrained by qualitative laws and known principles to avoid unconstrained speculation.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Qualitative distinctions rather than numeric uncertainties; can be combined with probabilistic methods for quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Qualitative results are coarse-grained and need quantitative follow-up; mapping complex biological detail to qualitative models is nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Nobel Turing Challenge: creating the engine for scientific discovery', 'publication_date_yy_mm': '2021-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist. <em>(Rating: 2)</em></li>
                <li>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. <em>(Rating: 2)</em></li>
                <li>Generating conjectures on fundamental constants with the Ramanujan Machine. <em>(Rating: 2)</em></li>
                <li>An autonomous debating system. <em>(Rating: 2)</em></li>
                <li>Temporal node-pair embedding for automatic biomedical hypothesis generation. <em>(Rating: 2)</em></li>
                <li>Representation of probabilistic scientific knowledge. <em>(Rating: 2)</em></li>
                <li>Mastering the game of Go with deep neural networks and tree search. <em>(Rating: 1)</em></li>
                <li>Mastering the game of Go without human knowledge. <em>(Rating: 1)</em></li>
                <li>Mastering Atari, Go, chess and shogi by planning with a learned model. <em>(Rating: 1)</em></li>
                <li>A truth maintenance system. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2518",
    "paper_id": "paper-235476723",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "Adam",
            "name_full": "Robot Scientist Adam",
            "brief_description": "A closed-loop robot scientist that automatically generated functional genomic hypotheses and executed experiments to test them in budding yeast; an early instantiation of automated hypothesis generation plus experimental validation.",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "mention_or_use": "mention",
            "system_name": "Adam (Robot Scientist)",
            "system_description": "A closed-loop system that (1) generates hypotheses about gene function from genomic data, (2) designs experimental protocols, (3) executes experiments using laboratory automation, and (4) analyses results to accept/reject hypotheses; described as an end-to-end automation of hypothesis generation and wet-lab validation in yeast.",
            "system_type": "closed-loop automated hypothesis-generation + lab automation",
            "scientific_domain": "biology / functional genomics",
            "hypothesis_generation_method": "Data-driven generation from genomic datasets using symbolic/algorithmic hypothesis-formers that propose gene-function hypotheses (inferred from the cited King et al. work); hypothesis sets are enumerated and prioritized for experimental testing.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Consistency checking against available genomic/experimental data and prioritization for experimental testing (as described generally; implementation details not given in this paper).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Experimental wet-lab validation executed by robotic lab instruments in a closed-loop workflow; results analysed to accept/reject hypotheses.",
            "reproducibility_measures": "Automated execution of protocols for traceability and reproducibility; provenance recording of experiments (paper emphasizes automation and traceability as reproducibility enablers).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Implicit via recording of experimental evidence and survival against falsifiability; probabilistic knowledge representation discussed in the broader text but not specific to Adam.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Used to discover/verify orphan enzyme functions in yeast (cited as an example of automated scientific discovery).",
            "limitations": "Special-purpose, highly engineered for particular tasks and not fully autonomous in strategic topic selection; scalability and domain-generalization remain challenges.",
            "uuid": "e2518.0",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Eve",
            "name_full": "Robot Scientist Eve",
            "brief_description": "An automated system designed for drug repositioning and high-throughput hypothesis testing that combined in silico hypothesis generation with automated assays to find candidate therapeutics.",
            "citation_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "mention_or_use": "mention",
            "system_name": "Eve (Automated drug-repositioning system)",
            "system_description": "A closed-loop platform that generates drug-repositioning hypotheses, automates low-throughput assays for validation, and analyses results; optimized for screening and repositioning tasks with robotic execution of protocols.",
            "system_type": "closed-loop automated hypothesis-generation + lab automation",
            "scientific_domain": "drug discovery / neglected tropical diseases / biology",
            "hypothesis_generation_method": "In-silico generation of repositioning hypotheses (drug-target-disease links) guided by data and literature, then prioritization for automated experimental screening.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Prioritization based on computational predictions and known biological relationships before experimental assays.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Automated biochemical/phenotypic assays executed by robotic instrumentation to validate repositioning hypotheses; example: identification of TP-470 activity as DHFR inhibitor for malaria.",
            "reproducibility_measures": "Automation, standardized protocols, and traceable experiment execution to improve reproducibility.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Implicit via experimental results and survival against falsification; no detailed uncertainty quantification method specified in this paper.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Cited example: repositioning identification (TP-470 repurposed) validated experimentally.",
            "limitations": "Highly automated but task-specialized; not fully autonomous in problem selection; scalability beyond designed tasks is a challenge.",
            "uuid": "e2518.1",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Ramanujan Machine",
            "name_full": "Ramanujan Machine (automated conjecture generator)",
            "brief_description": "An automated system that generates mathematical conjectures (formulas for fundamental constants) by searching structured hypothesis spaces of expressions.",
            "citation_title": "Generating conjectures on fundamental constants with the Ramanujan Machine.",
            "mention_or_use": "mention",
            "system_name": "Ramanujan Machine",
            "system_description": "A system that algorithmically enumerates candidate mathematical expressions/conjectures for constants and filters them by fitting to high-precision numerical values, thereby proposing novel conjectures for further analysis.",
            "system_type": "symbolic/conjecture-generation (search + pattern-fitting)",
            "scientific_domain": "mathematics (conjecture generation)",
            "hypothesis_generation_method": "Combinatorial enumeration of formula templates and numerical fitting against high-precision constants to propose conjectures.",
            "novelty_assessment_method": "Novelty is implicit by generating formulas not previously known; assessed by whether formula matches constants and whether it is previously published (not detailed in paper).",
            "plausibility_assessment_method": "Numerical consistency with high-precision values provides plausibility; symbolic/analytic proof remains required.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Numerical fit to high-precision constants (residual error) used as selection criterion (paper mentions approach conceptually).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational numerical consistency checks; final validation requires mathematical proof or further analysis.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Numerical residuals and fit errors provide implicit uncertainty indicators.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": "Generated novel conjectures about fundamental constants (presented as conjectures requiring proof).",
            "limitations": "Generates conjectures based on numerical fit; does not provide formal proofs; domain limited to expressible formula templates and numerical checks.",
            "uuid": "e2518.2",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Autonomous Debating System",
            "name_full": "Autonomous debating system (AI debate / Project Debater-like)",
            "brief_description": "An AI system that constructs and evaluates argumentation for and against claims via structured debate to surface evidence and counterarguments.",
            "citation_title": "An autonomous debating system.",
            "mention_or_use": "mention",
            "system_name": "Autonomous Debating System",
            "system_description": "A system that generates structured argumentation, supporting and rebutting arguments, using retrieved evidence and natural-language generation to debate claims; proposed as a component to generate and test argumentation for scientific claims.",
            "system_type": "argumentation-based / retrieval-augmented generation",
            "scientific_domain": "general / argumentative evaluation of claims (applicable to science communication and claim vetting)",
            "hypothesis_generation_method": "Not primarily a hypothesis generator, but can produce counter-claims and structured rebuttals that help test and refine hypotheses via adversarial argument generation.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Argues for/against claims using retrieved evidence; plausibility judged by strength and provenance of supporting evidence.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Human or automated adjudication of debate outcomes and use of evidence-based scoring to rank arguments; suggested as a way to generate argumentation that strengthens or falsifies hypotheses.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Use of evidence retrieval and provenance to ground arguments (paper points to computational debate as a first step to generate argumentations).",
            "hallucination_detection_method": "Adversarial rebuttal generation to surface contradictions and weakly supported claims; explicit tracing of evidence provenance.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Argument strength and provenance used as proxy for confidence; no explicit probabilistic model described.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Argumentation alone does not replace experimental validation; effectiveness relies on quality and completeness of retrieved evidence.",
            "uuid": "e2518.3",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Truth Maintenance System",
            "name_full": "Truth maintenance system (TMS)",
            "brief_description": "Classical AI infrastructure for tracking dependencies among beliefs (knowledge items) and updating or retracting beliefs when supporting evidence changes; proposed for managing multiple, probabilistic scientific knowledge graphs.",
            "citation_title": "A truth maintenance system.",
            "mention_or_use": "mention",
            "system_name": "Truth Maintenance System (TMS)",
            "system_description": "A symbolic system that records assumptions and justifications for beliefs, supports incremental addition/removal of evidence, and maintains consistent sets of beliefs by propagating changes; proposed to maintain multiple contextualized knowledge graphs and track survival/falsification of hypotheses.",
            "system_type": "knowledge graph / symbolic truth-maintenance",
            "scientific_domain": "general scientific knowledge management",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Belief support is judged by explicit supporting data and arguments stored in the TMS; hypotheses survive while their supporting justifications remain valid.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Automated re-evaluation of dependent hypotheses when underlying data/arguments change; supports falsifiability by tracing failed justifications.",
            "reproducibility_measures": "Provenance and justification recording to enable traceable reasoning chains and reproducibility of knowledge state transitions.",
            "hallucination_prevention_method": "Maintaining explicit evidence-justification links to avoid unsupported assertions (implied).",
            "hallucination_detection_method": "Detects inconsistent or unsupported beliefs when justifications are removed or contradicted; triggers retraction or forked knowledge graphs.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Supports multiple coexisting knowledge sets with dynamic likelihoods; paper suggests tracking probability/likelihood of each knowledge set to represent uncertainty.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Classical TMS are symbolic and may struggle with the scale and uncertain/noisy nature of large scientific literature unless extended with probabilistic mechanisms.",
            "uuid": "e2518.4",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Assumption-based TMS",
            "name_full": "Assumption-based Truth Maintenance System (ATMS)",
            "brief_description": "An extension of TMS that represents multiple contexts (assumption sets) and computes which conclusions hold under which assumptions, enabling parallel maintenance of alternative knowledge graphs.",
            "citation_title": "An assumption-based TMS.",
            "mention_or_use": "mention",
            "system_name": "Assumption-based TMS",
            "system_description": "Maintains mappings from assumptions to derived beliefs, enabling representation of many alternative, context-specific knowledge states (useful for keeping forks of inconsistent scientific claims with their contexts).",
            "system_type": "symbolic / context-aware truth maintenance",
            "scientific_domain": "general knowledge management for science",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is represented by which assumption sets support a hypothesis; hypotheses tied to strong assumption sets considered more plausible.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Re-evaluation when assumptions are revised or when new data arrive; supports conditional acceptance.",
            "reproducibility_measures": "Explicit representation of assumptions and dependencies aids reproducibility and re-analysis.",
            "hallucination_prevention_method": "By tying beliefs to explicit assumptions and evidence, spurious claims lacking assumptions/evidence can be identified.",
            "hallucination_detection_method": "Contradictions among assumption-supported belief sets trigger detection of conflicting claims.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Allows multiple coexisting belief sets with varying plausibility; can be extended to probabilistic weights though not specified here.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Scalability and integration with noisy probabilistic text-mined data not specified; requires extensions for large-scale literature-driven science.",
            "uuid": "e2518.5",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Non-monotonic reasoning",
            "name_full": "Non-monotonic reasoning frameworks",
            "brief_description": "Inference frameworks that allow withdrawal of conclusions when new evidence contradicts them, recommended for managing the probabilistic and revisable nature of scientific knowledge.",
            "citation_title": "NMR-2020: Workshop Notes of the 18th International Workshop on Non-Monotonic Reasoning.",
            "mention_or_use": "mention",
            "system_name": "Non-monotonic reasoning",
            "system_description": "A class of logical systems (e.g., defeasible reasoning) that models belief revision, defaults, and context-dependent truth — enabling AI Scientists to maintain multiple, revisable knowledge sets and to retract hypotheses when contradicted.",
            "system_type": "symbolic reasoning / belief revision",
            "scientific_domain": "general scientific reasoning and knowledge maintenance",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility judged relative to current evidence and defaults; conclusions can be retracted when stronger evidence arises.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Logical re-evaluation of hypotheses as evidence is added; supports falsifiability and iterative verification.",
            "reproducibility_measures": "Explicit recording of contexts/defaults supporting claims enhances reproducibility of reasoning paths.",
            "hallucination_prevention_method": "By requiring explicit justifications and allowing retraction when unjustified, reduces persistence of unsupported claims.",
            "hallucination_detection_method": "Inconsistency detection when new data conflict with derived conclusions; triggers belief revision.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Represents uncertainty via defeasible conclusions and ranked justifications; probabilistic extensions possible though not specified.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Classical frameworks are symbolic and may require coupling to statistical/probabilistic systems to handle noisy literature-scale data effectively.",
            "uuid": "e2518.6",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Epistemic Graphs",
            "name_full": "Epistemic graphs for representing and reasoning with arguments",
            "brief_description": "A formalism to represent arguments, their positive/negative influences, and degrees of belief (epistemic weights) used to reason about and rank competing claims.",
            "citation_title": "Epistemic graphs for representing and reasoning with positive and negative influences of arguments.",
            "mention_or_use": "mention",
            "system_name": "Epistemic graphs",
            "system_description": "Graphical argumentation models where nodes are claims/arguments and edges represent influences (support/attack); epistemic weights quantify belief strength and enable probabilistic-style reasoning about competing hypotheses.",
            "system_type": "argumentation-based / graph-based probabilistic reasoning",
            "scientific_domain": "general scientific argument evaluation and knowledge representation",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Belief strengths (epistemic weights) and structure of supportive/attacking arguments used to assess plausibility of claims.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Argument strength scores / epistemic weights as proxies for hypothesis credibility (paper references epistemic graphs as relevant).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Argument-based evaluation using collected evidence and counterarguments; conflicts resolved by comparing epistemic weights and supporting data.",
            "reproducibility_measures": "Explicit graphed arguments with provenance allow reproducible re-evaluation of claim strengths.",
            "hallucination_prevention_method": "Require supporting arguments and provenance; weakly supported claims will have low epistemic weight.",
            "hallucination_detection_method": "Identification of claims with no/weak supporting edges or strong attacking arguments exposes potential hallucinations.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Epistemic weights provide quantified degrees of belief; can be updated when evidence changes.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Mapping noisy literature claims into structured argumentation graphs at scale is nontrivial; integration with experimental evidence pipelines needed.",
            "uuid": "e2518.7",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "T-PAIR",
            "name_full": "T-PAIR (Temporal node-pair embedding for automatic biomedical hypothesis generation)",
            "brief_description": "A machine-learning method that uses temporal embeddings of node pairs in biomedical networks to generate hypotheses about biomedical relationships.",
            "citation_title": "Temporal node-pair embedding for automatic biomedical hypothesis generation.",
            "mention_or_use": "mention",
            "system_name": "T-PAIR (Temporal node-pair embedding)",
            "system_description": "Learns temporal embeddings for node pairs in biomedical knowledge graphs (e.g., genes, diseases, drugs) to predict and generate candidate novel relations/hypotheses over time.",
            "system_type": "graph-embedding / temporal representation learning",
            "scientific_domain": "biomedical hypothesis generation",
            "hypothesis_generation_method": "Learning temporal node-pair embeddings from longitudinal literature/graph snapshots and scoring candidate associations to propose hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility via learned embedding similarity and temporal predictive power; higher-scoring candidate pairs prioritized for validation.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Embedding-based prediction scores (rankings); specific metrics not detailed in this paper.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational ranking and (optionally) subsequent experimental follow-up; the paper cites T-PAIR as an example of automatic hypothesis generation.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Implicit via prediction scores and temporal validation performance; explicit uncertainty models not detailed here.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Relies on quality and temporal coverage of input literature/graphs; experimental validation required for generated hypotheses.",
            "uuid": "e2518.8",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Deep literature LMs",
            "name_full": "Deep learning networks trained on large corpora for hypothesis generation",
            "brief_description": "Large neural networks trained on millions of scientific articles that can infer molecular interactions and candidate molecule-disease relationships from text, thereby producing hypotheses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Deep literature-trained neural networks",
            "system_description": "Deep neural language models and representation learners trained on large scientific corpora to extract relationships (molecule–molecule, molecule–disease) and to propose hypotheses; cited as evidence that deep learning can generate extensive molecular-interaction hypotheses from literature.",
            "system_type": "LLM-style / deep learning / information extraction",
            "scientific_domain": "biology / biomedical literature mining",
            "hypothesis_generation_method": "Unsupervised or supervised extraction of entity relations from large corpora, followed by link prediction to propose novel interactions and associations.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Consistency with co-occurrence, learned relation patterns, and prior literature; prioritization by model confidence/scores.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Model confidence scores / likelihoods for predicted relations (paper mentions predictive capability but not specific metrics).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational consistency checks against held-out literature and retrospective tests (some studies cited show predictions preceding later discoveries), plus eventual experimental testing.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Grounding predictions in evidence from literature and requiring provenance for claims (paper suggests provenance is necessary but does not detail methods).",
            "hallucination_detection_method": "Retrospective validation against later-published findings; argumentation and TMS could flag unsupported claims.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Model confidence/score provides uncertainty proxies; explicit Bayesian calibration not specified.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Paper cites studies where deep models recovered molecular interactions and predicted relationships that predated later discoveries (references 31,32 in the paper).",
            "limitations": "Risk of propagating erroneous literature claims; requires provenance and integration with experimental validation to avoid false positives.",
            "uuid": "e2518.9",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "AlphaGo family",
            "name_full": "AlphaGo / AlphaGo Zero / AlphaZero / MuZero",
            "brief_description": "A series of deep learning + search / reinforcement learning systems that demonstrated the power of massive, unbiased exploration and self-play in complex domains; used as conceptual models for exploration of hypothesis spaces in science.",
            "citation_title": "Mastering the game of Go with deep neural networks and tree search.",
            "mention_or_use": "mention",
            "system_name": "AlphaGo family (AlphaGo, AlphaGo Zero, AlphaZero, MuZero)",
            "system_description": "Systems that combine deep neural networks (policy/value) with Monte Carlo Tree Search (AlphaGo), self-play reinforcement learning (AlphaGo Zero/AlphaZero), and learned model-based planning (MuZero) to explore very large state/hypothesis spaces and discover strategies without human priors; presented as an analogy for exploring scientific hypothesis spaces.",
            "system_type": "deep RL + search / model-based RL",
            "scientific_domain": "general (conceptual analogy for scientific discovery processes)",
            "hypothesis_generation_method": "Randomized/unbiased generation (self-play) and search-guided sampling of state space informed by learned policy/value models; in the paper this approach is proposed as analogous to randomly generating hypotheses and using search to expand promising regions.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Value networks estimate state value (analogy: plausibility/value of hypothesis) to guide search; in scientific context the paper suggests training networks to evaluate hypotheses against existing knowledge and experimental outcomes.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "In analogy: computational consistency checks, value estimation, and selective experimental verification of high-value candidates; paper does not report a concrete scientific implementation.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Value estimates and policy probabilities provide internal confidence signals; explicit uncertainty quantification methods for scientific hypotheses are not detailed.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Hypothesis space in science is open-ended and continuous, making direct application nontrivial; evaluation costs and ill-defined state descriptions pose challenges compared to games.",
            "uuid": "e2518.10",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Bayesian optimization (robotic search example)",
            "name_full": "Bayesian optimization used in robotic search for cell culture optimization",
            "brief_description": "An optimization method (Bayesian optimization) applied to robotics-driven parameter search in cell culture to find optimal conditions by efficiently exploring large parameter spaces.",
            "citation_title": "Robotic search for optimal cell culture in regenerative medicine.",
            "mention_or_use": "mention",
            "system_name": "Bayesian optimization (for automated experimental search)",
            "system_description": "Uses surrogate probabilistic models (e.g., Gaussian processes) to model objective landscapes and select next experiments to maximally improve objective (e.g., cell culture quality), enabling search through tens to hundreds of millions of parameter combinations efficiently when coupled to robotic execution.",
            "system_type": "Bayesian optimization / probabilistic surrogate modeling",
            "scientific_domain": "experimental biology / regenerative medicine / lab automation",
            "hypothesis_generation_method": "Not a hypothesis generator per se, but explores parameter/hypothesis space by proposing next experimental conditions based on acquisition functions balancing exploration and exploitation.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Surrogate model posterior mean and variance used to estimate expected improvement and thus plausibility of candidate conditions.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Acquisition function scores (e.g., expected improvement) and surrogate-predicted performance; specific acquisition functions not spelled out in the text.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Experimental execution by robotic lab followed by measurement of objective (e.g., cell quality); iterative model updating.",
            "reproducibility_measures": "Automation and precise control of experimental parameters improve reproducibility; provenance recording implied.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Surrogate posterior predictive variance provides principled uncertainty estimates used by acquisition functions.",
            "benchmark_dataset": null,
            "performance_metrics": "Paper cites example searching 200 million parameter combinations by Bayesian optimization in robotic cell-culture optimization (no numeric success rate provided in this paper).",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Example: robotic identification of optimal conditions for medical-grade iPS-derived RPE cell culture via Bayesian-optimized search.",
            "limitations": "Scalability when objective evaluations are extremely costly; requires reasonable surrogate models and constrained input spaces.",
            "uuid": "e2518.11",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Self-driving laboratories",
            "name_full": "Self-driving laboratories / closed-loop autonomous labs",
            "brief_description": "Integrated systems combining automated experiment execution, data analysis, and machine-learning-guided experimental design (closed-loop) to accelerate materials/chemical/biological discovery.",
            "citation_title": "Self-driving laboratory for accelerated discovery of thin-film materials.",
            "mention_or_use": "mention",
            "system_name": "Self-driving laboratory (closed-loop automated discovery platform)",
            "system_description": "Platforms that integrate robotic experiment execution, online analysis, and ML-guided decision-making (e.g., Bayesian optimization or model-based planners) to autonomously select and run experiments and update models iteratively.",
            "system_type": "closed-loop lab automation + ML-guided experimental design",
            "scientific_domain": "materials science, chemistry, experimental biology",
            "hypothesis_generation_method": "Generates candidate experimental conditions or parameterized hypotheses via acquisition functions or learned policies; can be framed as hypothesis generation in parametric spaces.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Model uncertainty and predicted improvement guide plausibility/prioritization.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Direct experimental execution by integrated robotics; model-updates based on measured outcomes provide iterative validation.",
            "reproducibility_measures": "Standardized automated protocols, minimized reagent volumes, and provenance tracking to improve reproducibility.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Surrogate models and predictive uncertainties used to guide experiment selection.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": "Cited examples in materials and chemistry where self-driving labs accelerated discovery (e.g., thin-film materials).",
            "limitations": "Integration complexity across diverse experimental modalities and scaling to open-ended hypothesis spaces beyond parametric optimization.",
            "uuid": "e2518.12",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Argumentation Module",
            "name_full": "Argumentation / computational debate modules",
            "brief_description": "Software modules that automatically generate arguments supporting or refuting scientific claims, intended to strengthen justification or produce rebuttals to test claims.",
            "citation_title": "Toward artificial argumentation.",
            "mention_or_use": "mention",
            "system_name": "Argumentation Module",
            "system_description": "Generates structured argumentation (claims, evidence, rebuttals) using retrieved data and reasoning templates; intended to produce justifications for hypotheses and to generate counterarguments that can trigger additional experiments or re-evaluation.",
            "system_type": "argumentation-based / symbolic + retrieval-augmented",
            "scientific_domain": "general scientific reasoning and claim evaluation",
            "hypothesis_generation_method": "Not primarily generative of novel hypotheses but produces sub-hypotheses, supporting evidence chains, and rebuttals that refine and stress-test hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Quality and provenance of evidence used in arguments determine plausibility; argument strength metrics can be used to rank claims.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Generates additional experiments or data-collection plans to strengthen or refute arguments; integrates with TMS/knowledge graphs for re-evaluation.",
            "reproducibility_measures": "Explicit argument and evidence provenance facilitates reproducible assessment of claims.",
            "hallucination_prevention_method": "Demanding explicit evidence and counterargument generation to reveal unsupported claims.",
            "hallucination_detection_method": "Automated generation of rebuttals and cross-checks against evidence to detect weak or hallucinated claims.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Argument strength and conflicting evidence counts provide proxies for uncertainty; probabilistic extensions discussed but not specified.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Effectiveness depends on quality of retrieved evidence and ability to formalize domain arguments; scaling to literature-scale remains challenging.",
            "uuid": "e2518.13",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        },
        {
            "name_short": "Qualitative physics / qualitative simulation",
            "name_full": "Qualitative physics / qualitative simulation methods",
            "brief_description": "Symbolic simulation approaches for generating and matching qualitative system behaviors (e.g., bifurcations, phase transitions) to explain observed biological dynamics and generate conceptual-level hypotheses.",
            "citation_title": "Qualitative modeling.",
            "mention_or_use": "mention",
            "system_name": "Qualitative physics / qualitative simulation",
            "system_description": "Techniques that represent system dynamics qualitatively (signs of change, causal influences, qualitative states) and simulate possible behaviors to generate mechanistic hypotheses about system-level phenomena where precise quantitative models are unavailable.",
            "system_type": "symbolic simulation / qualitative reasoning",
            "scientific_domain": "systems biology / dynamical systems modeling",
            "hypothesis_generation_method": "Generate candidate conceptual/dynamical hypotheses by matching qualitative simulation outputs (e.g., possible bifurcations) to observed system behaviors and proposing underlying network structures/mechanisms.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Consistency of qualitative predictions with observed phenomena and with known mechanistic constraints (e.g., biochemistry and physics).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Propose focused quantitative experiments to test qualitative predictions; used as a human-understandable explanatory layer.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Generates explanations constrained by qualitative laws and known principles to avoid unconstrained speculation.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Qualitative distinctions rather than numeric uncertainties; can be combined with probabilistic methods for quantification.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Qualitative results are coarse-grained and need quantitative follow-up; mapping complex biological detail to qualitative models is nontrivial.",
            "uuid": "e2518.14",
            "source_info": {
                "paper_title": "Nobel Turing Challenge: creating the engine for scientific discovery",
                "publication_date_yy_mm": "2021-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist.",
            "rating": 2,
            "sanitized_title": "functional_genomic_hypothesis_generation_and_experimentation_by_a_robot_scientist"
        },
        {
            "paper_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "rating": 2,
            "sanitized_title": "cheaper_faster_drug_development_validated_by_the_repositioning_of_drugs_against_neglected_tropical_diseases"
        },
        {
            "paper_title": "Generating conjectures on fundamental constants with the Ramanujan Machine.",
            "rating": 2,
            "sanitized_title": "generating_conjectures_on_fundamental_constants_with_the_ramanujan_machine"
        },
        {
            "paper_title": "An autonomous debating system.",
            "rating": 2,
            "sanitized_title": "an_autonomous_debating_system"
        },
        {
            "paper_title": "Temporal node-pair embedding for automatic biomedical hypothesis generation.",
            "rating": 2,
            "sanitized_title": "temporal_nodepair_embedding_for_automatic_biomedical_hypothesis_generation"
        },
        {
            "paper_title": "Representation of probabilistic scientific knowledge.",
            "rating": 2,
            "sanitized_title": "representation_of_probabilistic_scientific_knowledge"
        },
        {
            "paper_title": "Mastering the game of Go with deep neural networks and tree search.",
            "rating": 1,
            "sanitized_title": "mastering_the_game_of_go_with_deep_neural_networks_and_tree_search"
        },
        {
            "paper_title": "Mastering the game of Go without human knowledge.",
            "rating": 1,
            "sanitized_title": "mastering_the_game_of_go_without_human_knowledge"
        },
        {
            "paper_title": "Mastering Atari, Go, chess and shogi by planning with a learned model.",
            "rating": 1,
            "sanitized_title": "mastering_atari_go_chess_and_shogi_by_planning_with_a_learned_model"
        },
        {
            "paper_title": "A truth maintenance system.",
            "rating": 1,
            "sanitized_title": "a_truth_maintenance_system"
        }
    ],
    "cost": 0.02496375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PERSPECTIVE Nobel Turing Challenge: creating the engine for scientific discovery</p>
<p>Hiroaki Kitano 
The Systems Biology Institute
Okinawa Institute of Science and Technology Graduate School
Tokyo, OkinawaJapan, Japan</p>
<p>Sony Computer Science Laboratories, Inc
TokyoSonyJapan</p>
<p>AI, Inc
TokyoJapan</p>
<p>The Alan Turing Institute
LondonUK. ✉</p>
<p>PERSPECTIVE Nobel Turing Challenge: creating the engine for scientific discovery
10.1038/s41540-021-00189-3OPEN
Scientific discovery has long been one of the central driving forces in our civilization. It uncovered the principles of the world we live in, and enabled us to invent new technologies reshaping our society, cure diseases, explore unknown new frontiers, and hopefully lead us to build a sustainable society. Accelerating the speed of scientific discovery is therefore one of the most important endeavors. This requires an in-depth understanding of not only the subject areas but also the nature of scientific discoveries themselves. In other words, the "science of science" needs to be established, and has to be implemented using artificial intelligence (AI) systems to be practically executable. At the same time, what may be implemented by "AI Scientists" may not resemble the scientific process conducted by human scientist. It may be an alternative form of science that will break the limitation of current scientific practice largely hampered by human cognitive limitation and sociological constraints. It could give rise to a human-AI hybrid form of science that shall bring systems biology and other sciences into the next stage. The Nobel Turing Challenge aims to develop a highly autonomous AI system that can perform top-level science, indistinguishable from the quality of that performed by the best human scientists, where some of the discoveries may be worthy of Nobel Prize level recognition and beyond.npj Systems Biology and Applications (2021) 7:29 ; https://doi.</p>
<p>npj Systems Biology and Applications (2021) 7:29 ; https://doi.org/10.1038/s41540-021-00189-3 NOBEL TURING CHALLENGE AS AN ULTIMATE GRAND CHALLENGE Understanding, reformulating, and accelerating the process of scientific discovery is critical in solving problems we are facing and exploring the future. Building the machine to make it happen could be one of the most important contribution to society, and it will transform many areas of science and technology including systems biology. Since scientific research has been one of the most important activities that drove our civilization forward, the implications of such development will be profound.</p>
<p>Attempts to understand the process of scientific discoveries have a long tradition in the philosophy of science as well as artificial intelligence. Karl Popper introduced a concept of falsifiability as a criterion and process of solid scientific process but the process of hypothesis and concept generation do not have particular logic behind it 1 . Thomas Kuhn proposed a concept of a Paradigm shift where two competing paradigms are incommensurable and a set of knowledge, rather than a single knowledge, has to be switched with the transition of paradigm 2 . Imre Lakatos reconciles them by proposing actual science makes progress based on a "research program" composed of a hardcore that is immune to revision and flexible peripheral theories 3 . Contrary to these positions, Paul Feyerabend argued that there are no methodological rules in the scientific process 4 . Although these arguments are important thoughts in the philosophy of science, ideas are philosophical and not concrete to be implemented computationally. In addition, these studies are focused on how science is carried out as a part of human social activities. A rare example of implementing such concepts can be seen in the model inference system implemented by Ehud Shapiro that reflects Popper's falsifiability 5 .</p>
<p>Not surprisingly, scientific discovery has been a major topic in artificial intelligence research that dates back to DENDRAL 6 and META-DENDRAL, followed by MYCIN, BEACON 7 , AM, and EURISKO 6,8 . It continues to be one of the main topics of AI 9,10 . Recently, an automated experimental system that closed-the-loop of hypothesis generation, experimental planning, and execution has developed for budding yeast genetics that clearly marks the next step towards an AI Scientist [11][12][13] . While these pioneering works have focused on a single data set or a specific task using limited resources, it signifies the state-of-the-art of technology today that can be the basis of more ambitious challenges.</p>
<p>The obvious next step is to develop a system that makes scientific discoveries that shall truly impact the way we do science and aim for major discoveries. Therefore, I propose the launch of a grand challenge to develop AI systems that can make significant scientific discoveries that can outperform the best human scientist, with the ultimate purpose of creating the alternative form of scientific discovery 14 . Such a system, or systems, may be called "AI Scientist" that is most likely a constellation of software and hardware modules dynamically interacting to accomplish tasks. Since the critical feature that distinguishes it from conventional laboratory automation is its capability to generate hypotheses, learn from data and interactions with humans and other parts of the system, reasoning, and a high level of autonomous decision-making, the term "AI Scientist" best represents the characteristics of the system to be developed. The best way to accelerate the grand challenge of this nature is to define a clear mission statement with an audacious yet provocative goal such as winning the Nobel Prize 14 . Therefore, I propose the Nobel Turing Challenge as a grand challenge for artificial intelligence that aims at "developing AI Scientists capable of autonomously carrying out research to make major scientific discoveries and win a Nobel Prize by 2050". While the previous article 14 focused on rationales for such a challenge with emphasis on human cognitive limitations and needs for exhaustive search of hypothesis space, this article formulates the vision as the Nobel Turing Challenge and implications of massive and unbiased search 1 of hypothesis space and verification, architectural issues, and interaction with human scientists are discussed as a transformative paradigm in science. The distinct characteristic of this challenge is to field the system into an open-ended domain to explore significant discoveries rather than rediscovering what we already know or trying to mimic speculated human thought processes. The vision is to reformulate scientific discovery itself and to create an alternative form of scientific discovery.</p>
<p>The accomplishment of this challenge requires two goals to be achieved that are: (1) to develop an AI Scientist that performs scientific research highly autonomously enabling scientific discoveries at scale, and (2) to develop an AI Scientist capable of making strategic choices on the topic of research, that can communicate in the form of publications and other means to explain the value, methods, reasoning behind the discovery, and their applications and social implications. When both goals are met, the machine will be (almost) comparable to the top-level human scientist as well as being scientific collaborators. The question and challenge is whether the machine will be indistinguishable from the top-level human scientists and most likely pass the Feigenbaum Test which is a variation of the Turing Test 15 , or whether it will exhibit patterns of scientific discovery that are different from human scientists.</p>
<p>It should be noted "winning the Nobel Prize" is used as a symbolic target illustrating the level of discoveries the challenge is aiming at. The value lies in the development of machines that can make discoveries continuously and autonomously, rather than winning any award including the Nobel Prize. It is used as a symbolism that triggers inspiration and controversy.</p>
<p>At the same time, the implication of the statement that explicitly aims to win the Nobel Prize poses a series of interesting questions whether such AI systems making a decisive discovery may also evolve to be indistinguishable from the top human scientist (passing the Feigenbaum Test 16 ). As witness in case of Satoshi Nakamoto's blockchain and bitcoin, there is a case where a decisive contribution was simply published as a blogpost 17 and taken seriously, yet no one ever met him and his identity (at the time of writing) is a complete mystery. Given the possibility of creating a highly sophisticated virtual agent to interact with a human, with natural language capability to generate professional article, it will be non-trivial to distinguish whether such a scientist is human or AI. If a developer of an AI Scientist determined to create a virtual persona of a scientist with an ORCID iD, for demonstration of technological achievement, product promotion, or for another motivation, it would be almost impossible to distinguish between the AI and human scientist. The challenge shall be considered practically achieved when the Nobel Prize committee is alerted for any confusion on potential recipients. We might expect an AI Scientist detection system to be developed to identify who is an AI Scientist or not, that may resemble Deckard's interrogation of Rachael in Blade Runner.</p>
<p>It shall be made clear that this goal does not state or imply that "all major discoveries will be made by AI Scientists", nor that completeness of hypotheses or discoveries made by AI Scientist will be achieved. The challenge is fundamentally different from any attempts to prove the completeness of the system, including the Hilbert Program intended to prove axiomatic completeness of mathematic where feasibility is debunked by Incompleteness theorems by Kurt Gödel. It simply implies: "among discoveries made by AI Scientists, there should be discoveries that are considered very significant at the level worthy of the Nobel Prize or beyond". The challenge is initiated based on the belief any significant acceleration of scientific discovery would benefits our civilization. This will be achieved by creating an alternative form of scientific discovery, and will change the form of science as we know as well as uncovering the essence of scientific discovery. The utility of such technology shall benefit broader areas of science, industry, and society.</p>
<p>The core of the research program shall be about "Science of Science" rather than "Science of the process of science by human scientists". As in the case of past AI grand challenges, the best and perhaps the only way to demonstrate that scientific discovery can be reformulated computationally is to develop an AI system that outperforms the best human scientists. Furthermore, it is not sufficient to have AI Scientist make one discovery, it shall generate a continuous flow of discoveries at scale. The fundamental purpose behind this challenge is to uncover and reformulate the process of scientific discovery and develop a scalable system to perform it that may result in an alternative form of scientific discovery that we have not seen before.</p>
<p>Case studies: scientific discovery as a problem-solving Herbert Simon argued that science is problem-solving in his article "The Scientist as Problem Solver" 18 . Scientists set themselves tasks of solving significant scientific problems. If this postulation holds, defining the problem and strategy and tactics to solve these problems is the essence of scientific discoveries.</p>
<p>An example of the discovery of cellular reprogramming leading to iPS cell and regenerative medicine by Shinya Yamanaka is consistent with this framework 19,20 . It has a well-defined goal with obvious scientific and medical implications, and search and optimization has been performed beautifully to discover cellular reprogramming capability using four transcription factors, now known to be Yamanaka factors 21 .</p>
<p>Another example is the discovery of conducting polymer by Hideki Shirakawa, Alan MacDiarmid, and Alan Heeger. It started with an accident that an intern researcher at Shirakawa's Lab mistakenly used an abnormally high concentration of chemicals that formed thin film. Shikawaka noticed this accidental discovery and optimized the condition of thin-film formation. Then, with MacDiarmiad and Heeger, they identified a condition for conducting polymer formation. The initial experiments with an accidentally high dose of the chemical can be view as a stochastic search process where search space was extended beyond normal scope followed by extensive search and optimization for stable thin-film formation 22 .</p>
<p>The very simplified processes of these discoveries are shown in Fig. 1. These examples, among many other cases, exemplify the process of scientific discovery as problems solving and typical tactics are search and optimization.</p>
<p>Deep and unbiased exploration of hypothesis space as an alternative form of science Discovery with an exhaustive search of hypothesis space is what characterizes AI Scientist. In the traditional approach, scientists wish to maximize the probability that the discovery they make will be significant under certain criteria. In other words, scientists are focusing on making significant discoveries and are not interested in the number of discoveries made. This is the value-driven approach. In the alternative approach, the system will learn to maximize the probability that discovery at any level of significance can be made without imposing any value-driven criteria. This is an exploration-driven approach that is an unbiased exploration of hypotheses and makes sharp contrast against the current practice of science. This approach subsumes the problem-solving approach because specific problems will be included in hypotheses generated by an unbiased search of hypothesis space and their verification. This means AI Scientist will generate-and-verify as many hypotheses as possible, expecting some of them may lead to major discoveries by themselves or be a basis of major discoveries. A capability to generate hypotheses exhaustively and efficiently verify them is the core of the system and it can be the engine that gives horsepower to the system. This transition of a value-based approach to exploration-based approach driven by the unbiased search of hypotheses space may resemble a transition from the intuition-driven design of experiments to unbiased exhaustive measurements represented by omics-approach made possible with microarray and highthroughput genome sequencers, combined with bioinformatics supported by powerful computing resources. Unbiased hypotheses generation and verification will be built on the unbiased measurement of the well-established omics-approach, hypothesis generation system, a series of machine learning and reasoning systems, and robotics-based experimental systems. This is a logical evolution of the modality of science where a vast hypothesis space is searched in an unbiased manner rather than depending on human intuition.</p>
<p>A potential argument against this approach is that such a brute force approach is too inefficient and may not lead to any significant discoveries. Furthermore, one may argue that asking the right question is most important in science rather than brute force exploration. It is interesting to note that in the early days of AI research, it was widely accepted that a brute force approach would not work for complex problems such as chess, and that heuristic programming was essential for very large and complex problems 23 . The actual history of AI clearly demonstrated massive computing and machine learning is the key to success as seen in DeepBlue 24 and AlphaGo 25 .</p>
<p>Does that lessen apply to scientific discovery? There are three notable differences that are: (1) hypothesis space in scientific discovery is vast, open-ended, and possibly infinite as opposed to huge but finite space as in most games, (2) description in science, either knowledge or data, is not well-defined and often inaccurate whereas the well-defined description of game states and records exist in most games, and (3) evaluating hypothesis is likely to be more costly and time-consuming in science due to involvement of experiments. However, these issues can be made manageable and series of technologies to make them manageable will transform science and bring it to the next stage.</p>
<p>The exploration of hypothesis space in scientific discovery The hypothesis space for scientific discovery is huge and complex as opposed to very big but finite, well-defined, and monolithic state-space in games. State-space for games such as Chess, Shogi, and Go are finite, quantized, completely observable, and monolithic. For example, the game of Go is known to have a state-space complexity in order of 10 170 and a game tree complexity in order of 10 360 . Every state of the game can be fully and unambiguously describable with a set of coordinates. There is no hierarchical structure in the state space. This is not the case in scientific discovery. The size of an entire hypothesis space is infinite or undefinable. States of objects involve substantial continuous values of higher-order dimensions. Nested hierarchical structures are prevalent. While it appears to be fundamentally different, much can be learned and adapted from experiences in building AI systems for gaming.</p>
<p>The most recent and significant success of building AI system for a board game is AlphaGo series that beat the best human players. AlphaGo combined deep learning, reinforcement learning, and Monte-Carlo Tree Search (MCTS) to explore possible state space and game tree to learn best possible play within an explored state space 25 . State spaces are explored based on predictions of possible next moves generated by networks trained through supervised learning of past records of Game of Go (SL policy network) and MCTS expanded a search space. Reinforcement learning using self-play improves policy network and a value network is trained to properly evaluate game status. This approach enabled AlphaGo to learn how humans played, and how humans may play in the possible game state that has proximity to the past game ( Fig. 2a, orange circle). AlphaGo Zero starts from a random move and learns to play purely using reinforcement learning without human knowledge 26 . Interestingly, AlphaGo Zero not only outperforms the best human players, it outperforms AlphaGo as well. This demonstrates the strength of unbiased exploration of state space as AlphaGo Zero explores an entire state space of Go where AlphaGo incrementally searches the vicinity of human play styles (Fig. 2a, green space). AlphaZero 27 and MuZero 28 further extend such approaches to be able to learn and exhibit superhuman capability in multiple different games by learning game dynamics with model-free and mode-based reinforcement learning, respectively.</p>
<p>A part of such an approach can be applied to scientific discovery. With AlphaGo levels of approach, a set of hypotheses can be generated using a body of knowledge accumulated to date, and it can be tested against a body of knowledge for their consistency and verified experimentally (Fig. 2b, orange circle). Enhancing the level of complexity of hypothesis and automation of experimental verification, exploration can be extended to hypothesis space where it was not practical with an incremental extension of current scientific practice (Fig. 2b, blue circle). The challenge would be to implement AlphaGo Zero strategy to randomly generate hypotheses for an entire hypothesis space because the hypothesis space can be infinite and undefinable (Fig.  2b, green zone). However, practical approaches may exist to solve this issue by leveraging the intrinsic structure of problem domains.  Fig. 1 Very simplified process of scientific discoveries of iPS and conducting polymer. Search and optimization plays a critical role in the process of discovery. Yamanaka's case is interesting because a search was conducted in bioinformatics followed by experiment-driven optimization that may be well suited for AI Scientist in the future.</p>
<p>In biomedical sciences, any biological phenomena are the result of molecular interactions. It can be a simple interaction or involve a very complex network composed of very large numbers of molecules. Interactions among cells or even individuals can be attributed to molecular interactions. Information of any kind will be received by receptors to be meaningful for a biological system, therefore converted into molecular interactions. The explorationdriven approach in biomedical science leverages such intrinsic characteristics of application domains and may start from generating and testing hypotheses for basic biological mechanisms such as molecular interactions, genetic functions, metabolic reactions, material properties, and so forth and explore them at an unprecedented scale. Since most discoveries in biomedical science are on mechanisms behind diseases or specific biological phenomena exhaustive and unbiased exploration of molecular mechanisms shall be a building block for uncovering complex mechanisms for more complex biological phenomena (Fig. 3).</p>
<p>Therefore, it is reasonable to assume that the first stage of the project focuses on the hypothesis of a particular form, rather than unlimited and complex forms, specifically to identify molecular mechanisms behind biological processes. By focusing on the specific type of canonical form of knowledge, the problem is now relatively well-defined which is important as an opening game of the challenge. While the omics-approach uncovered massive data on genomes, transcriptomes, metabolomes, and interactomes, detailed and exhaustive characterization and precision measurements using low-throughput methods are required to verify specific molecular characteristics and nature interactions. Such processes are generally time-consuming and often not automated thus experiments are performed only for high priority targets. Automating such processes to match omics-scale enables exhaustive search and verification of a broader range of hypotheses, which shall lead to discoveries with high-impact biomedical and biotechnology applications.</p>
<p>There are pioneering works to turn this idea into reality. Adam, the first closed-loop system for scientific discovery, is designed to execute the discovery of orphan enzymes in budding yeast 11,13 . Eve was designed to perform an automated drug repositioning screen for neglected diseases and identified TP-470, originally developed as an angiogenesis inhibiting anti-cancer drug for its irreversible binding to methionine aminopeptidase-2, to be as effective as an anti-Malaria drug as a DHFR inhibitor 29 . These systems automated low-throughput assay processes and enabled exhaustive verification based on the hypothesis generated. These systems are highly automated, but not autonomous, as the problem to be solved and the process are fully designed by humans to the detail. These are special-purpose machines optimized for specific types of problems.</p>
<p>This process can be applied iteratively (Fig. 4a). A biological process in questions (h 1 ) may be explained by hypothesis h 2 or a combination of h 3 and h 4 , where h 2 , h 3 , and h 4 may have possible underlying molecular mechanisms of h 5 and h 6 , h 6 and h 7 , and h 8 , respectively. In such a case, a process of hypothesis generation and verification will be performed iteratively to verify or reject h 1 with a verified supporting mechanism either h 2 , h 3 , and h 4 . Generating experimental protocols and executing them is rather straightforward.</p>
<p>There are cases where a biological process can be only understood from a system dynamics perspective such as bifurcation and phase transition. A simple application of the iterative procedure to identify molecular mechanism is not sufficient. It requires reconstruction of molecular interaction network and analysis of their dynamical behaviors possibly underlying the process in question (Fig. 4b). This is more challenging as it requires the generation of hypothesis that link biological process with mathematical concepts and verifying them through experimental verification of network behaviors and molecular mechanisms composing the network.</p>
<p>Exhaustive exploration of hypothesis means a set of hypotheses is generated and verified rather than a single hypothesis. Thus, nodes of a hypothesis dependency tree in Fig. 4 shall be sets, rather than an element (Fig. 4c). Experiments shall be executed to verify an entire set of hypotheses, and protocols enabling such a  Fig. 2 A possible space of exploration by AI Scientists. Search space structures for a perfect information games as represented by the Game of GO and b scientific discovery are illustrated with commonalities and differences. While the search space for the Game of GO is well-defined, the search space for scientific discovery is open-ended. A practical initial strategy is to augment search space based on current scientific knowledge with human-centric AI-Human Hybrid system. An extreme option is to set search space broadly into distant hypothesis spaces where AI Scientist may discover knowledge that was unlikely to be discovered by the human scientist.</p>
<p>Explaining mechanisms of biological phenomena</p>
<p>Combinations of molecular mechanisms</p>
<p>Molecules involved</p>
<p>System dynamics context Experimental context Fig. 3 A basic structure of discovery in biology. Most discoveries in biology and medicine are concerned with the identification of mechanisms behind important biological processes. It can be fundamental processes such as cell cycle and cellular reprogramming or clinically relevant processes such as mechanisms of disease outbreak and progression. In many cases, this basic structure will be nested into multiple levels. It should be noted that "Molecular mechanisms" are biological processes by themselves, thus multilayer construction of this basic structure of discovery are inevitable.</p>
<p>H. Kitano process shall be generated. This may also include the generation of sub-hypothesis to be verified (Fig. 5).</p>
<p>The value of exhaustive generation of hypothesis and verification is in its potential capability to overcome the horizon problem. Assume that hypotheses are generated to maximize the expected significance of the discovery and tuned to focus highly expected value, such a strategy would work when the landscape is monotonically increasing (Fig. 6a). However, it may avert exploring paths to significant discovery, when a series of discoveries precondition to the significant one was low in expected significance (Fig. 6b). Searches may be terminated before reaching a significant discovery that may be located over-the-horizon. The landscape of discovery significance may be complex and nonmonotonic. By enabling exhaustive exploration of hypothesis space, AI Scientist can go beyond the area that is over-the-horizon without it. At the same time, AI Scientist is not free from resource limitation. One of the most important areas of research would be to find out how to sample hypothesis space to effectively identify its landscape. Machine learning-guided experimental design was shown to be effective in chemistry 30 and some of the principles can be applied here.</p>
<p>Knowledge of the world that science deals with is composed of multiple layers of abstraction, generally corresponding to the layers of systems in the domain. Discussions so far are centered around exploring and verifying hypothesis at molecular mechanisms, although it can be complex and nested. The next step shall be to uncover more complex phenomena and their dynamics that are interlinked with multiple layers of interaction, cells, organs, and individuals. This level further requires the identification of design principles and concepts behind complex systems (Fig. 7a). As discussed already, system dynamics play a central role in discoveries of this level, hence mathematical concept shall be  Fig. 4 Hypothesis dependency tree. a Each hypothesis is dependent upon other hypotheses that are related to molecular mechanisms. b A hypothesis in question can be verified only at the system-level analysis of molecular interaction network behaviors, c a set of hypotheses and their dependency tree where each element is also a set (e.g.,
H 1 ¼ h 0 1 ; h 1 1 ; h 2 1 ; Á Á Á ; h n 1 È É )
. In massive and exhaustive search of hypothesis space, a set of hypotheses, rather than a single hypothesis, is generated to cover specific hypothesis space and verified.  Fig. 5 Hypothesis tree. A hierarchical generation of hypothesis sets and data to verify them will be automatically generated and executed. Verification of Hypothesis set C requires both Hypothesis sets A and B to be verified. Verification data for Hypothesis sets A and B shall be obtained from experiments in general. In general, multiple data sets are required to fill various parameters of elements in Hypothesis set before finally tested in the verification process. This requires Data Set 1 for Hypothesis set A, and Data Sets 2 and 3 for Hypothesis set B need to be collected. Data sets 1, 2, and 3 can be obtained from databases, or through automated experiments. Verified Hypothesis sets A and B mean a set of elements of Hypothesis sets A and B that are verified to be true or entire sets with a score for each element. Given the hypothesis set to be verified, this process automatically generates hypothesis sets that need to be verified first and specifies the data sets required.</p>
<p>linked to biological processes (Fig. 4b). At the same time, actual biological systems are constrained by fundamental principles such as biochemistry and physics, systems principles such as feedback theory and information theory, selected through evolution and manifested in the context of the environment it lives (Fig. 7b). AI Scientist need to learn what are possible and impossible and what possible biology exist at present, and this could be potentially similar to learning models of game dynamics 28 , but in open-ended and a highly complex environment. The challenge is to find a way for the system to generate and test conceptual level hypotheses and test them. This shall be done in an unbiased manner. Methods such as model-based reinforcement learning and generative adversarial learning can be applied initially to investigate how to develop system that learn laws of nature at scale. Some recent studies demonstrate deep learning networks trained over millions of articles generate extensive molecular interactions 31 and the potential relationship between molecules and disease only using articles a year (or years) before such a relationship was discovered 32 . Deep learning was also used to uncover hierarchical structure and functions of cells 33 , deep generative models for discovering hidden structures 34 , precision phenotyping to predict genetic anomalies 35 , and many more. The outcome of such approaches is a set of hypotheses generated by deep learning and other AI methods from unbiased data, and hypotheses are generated in an unbiased manner. Such predictions can be a basis for the search for in-depth molecular relationships and functions. Furthermore, recent success in the Ramanujan Machine 36 in mathematics and the project Debater 37 in adversarial reasoning augmented possible approach that can be incorporated in the hypothesis generation process. Qualitative physics offers the opportunity to generate, match, and explain physical and mathematical concepts such as bifurcation and phase transition 38,39 . Combined with the capability of deep learning neural network to learn, classify, and generate nonlinear dynamics 40,41 , qualitative physics approach can be a powerful method for hypothesis generation and verification at the level of dynamical system concept. There are studies to use qualitative physics for biological processes 42,43 . This illustrates the potential of AI to be able to generate conceptual model exhaustively, assemble basic knowledge to be consistent with the conceptual model, and experimentally verify them. This approach essentially forces us to create a set of possible substructures of systems and search for structural matching with reality. With unbiased exploration at this level, AI Scientist shall be capable of exploring the complex dynamical system and may be able to discover new knowledge that is less likely to be discovered by human scientists.</p>
<p>The multiverse of knowledge in scientific discovery Generating hypotheses and maintaining a set of consistent body of knowledge in science is a formidable task due to the vast number of hypothesis generated and maintained, complexity and non-monotonicity, and unreliability of knowledge and data published. While publications and data already available today will be the initial foundation of hypothesis generation, the problem is that this initial foundation is not necessarily a solid ground; they contain substantial errors, missing information, and even fabrications. Manually checking statements with misinterpretation and biased interpretation of data individually and Temporal order of discoveries Temporal order of discoveries Estimated significance of discoveries Estimated significance of discoveries a b Fig. 6 The landscape of estimated significance of the discovery. a The landscape is monotonic, and b the landscape is non-monotonic. A simplified illustration on why there are cases that research outcomes not immediately recognized to be significant lead to a major discovery. "Estimated significance of discoveries" is used only as a conceptual index. There is no rigid method to estimate the significance of the discovery. The numbers of citations and their temporal changes can be an interesting index, but it may be biased toward short-term popularity unless the time horizon is set appropriately.  Fig. 7 Layers of knowledge for unbiased exploration. a In scientific discovery, knowledge is layered from tangible knowledge to conceptual knowledge. Properties of molecules and their interactions are tangible and knowledge of systems dynamics and design principles are conceptual as they are not directly associated with tangible objects such as molecules and cells. Conceptual knowledge is often backed by mathematical and system-oriented theories. b Biology that we observe ("existing biology") is constrained by multiple factors such as fundamental principles, systems principles, environmental constraints, and evolutionary selection. "Possible biology" meets all constraints but has not been observed or realized yet.</p>
<p>exhaustively is not practical given the volume of publications that shall be processed by AI Scientist. Currently, certain types of experimental results are known to be difficult to reproduce 44 , where some aspects of reproducibility issues shall be reduced by automated, transparent, and traceable experimental systems [45][46][47] . Intrinsic variability of biological systems due to noise and individual variations are treated as intrinsic features 48,49 and shall be treated separately from ambiguities and inaccuracy caused by the process of research itself. Aside from the immediate reproducibility problem, some observations may hold true in some contexts but may not be applicable in the other context as an intrinsic nature of the complex system. Scientific knowledge is probabilistic and non-monotonic and a representation system shall be able to reflect this reality 50 . Knowledge shall be contextualized, and a new context can be added incrementally. While this is a nature of scientific research, this poses a serious issue in the computational process as hypothesis will be generated using a body of knowledge that is sure to be revised constantly. It is like making reasoning in the twilight zone where what is correct or not is always ambiguous. In this regard, hypothesis and knowledge cannot be clearly distinguished. It is a matter of degree of confidence. Verification in the context of inductive reasoning means that "a certain hypothesis is still surviving against all falsifiability challenges, thus considered most likely so far". This implies for all hypotheses, survived or not, the trace of tests and their outcome need to be recorded. Unless errors are obvious, every statement in publications shall be converted into knowledge graph and the knowledge graph shall be constantly updated (Fig. 8). Obviously, inconsistencies will emerge which will trigger forks of knowledge graph, each of them consistent internally. Whenever some of the assumptions are altered, the relevant hypothesis shall be automatically reevaluated. This can be accomplished by maintaining a very large number of multiple consistent set of knowledge and data with explicit breaking point which set to be considered more probable.</p>
<p>Truth maintenance system, brief revision system, and nonmonotonic reasoning can be applied to maintain consistency with multiple contexts [51][52][53] . Given the nature of scientific knowledge that is essentially probabilistic, multiple sets of knowledge graph shall be maintained persistently, unless sets are proven to be inconsistent, and likelihood of each knowledge set to be most probable change dynamically. To evaluate the probability and possibly eliminate inconsistent knowledge sets, mechanisms to resolve ambiguities and falsify hypothesis need to be implemented. When a hypothesis is generated and verified, it always associated with data and justification why data support or reject the hypothesis. Theory of argumentation 54 and non-monotonic reasoning shall be the basis of argumentation structure generation and processing 55,56 . Hypothesis, or claim, can be rejected or needs further delineation with multiple cases such as (a) data is fabricated, inaccurate, or incomplete, or (b) interpretation of data/assumption is not sufficient to justify the hypothesis, (c) scope of the hypothesis shall be limited, and (d) effective rebuttle exists that denies reasoning connecting data/assumptions and the claim. It is possible that reasoning presented in publications are insufficient to justify hypothesis, and detailed justification may need to be regenerated or argument against the claim to be created to make knowledge set complete. Recent progress in computational debate may be a first step to implement mechanisms to generate such argumentations 37,56,57 . The argumentation module shall generate argumentation to support or falsify existing hypothesis thereby justification can be strengthened through additional experiments and reasoning. At the same time, argumentation generated need to be understood by the human scientist. Qualitative simulation 38,58-60 should be able to generate qualitative explanations consistent with human reasoning 39 . A closedloop system involving such a process shall be developed that can incrementally improve confidence and consistency of knowledge and data thereby incrementally building up rigidly fortified data, argumentations, and hypotheses.</p>
<p>Challenges in technology platform: automation, precision, and efficiency Development of high precision, fast, and low operation cost experimental system and data analysis system is mandatory for this challenge. Unbiased search of hypothesis space means an unprecedented number of hypotheses will be generated and tested. The test requires both computational and experimental tests. The volume of experiments required to execute unbiased exploration would be a magnitude larger than current scientific practices. The revolutionary precise, cost-effective, and fast experimental systems need to be developed and deployed. Since the cycle of hypothesis generation and verification is the ratelimiting factor of the entire process, how fast and accurately perform experiments will determine the chance of success of the challenge. Some experiments will involve hypothesis exploring unusual conditions such as 1000 times off from the conventional parameters such as the concentration of chemicals. The first step would be to make laboratories fully connected and automated. Then, equipment will be replaced over time for high precision and efficient devices including microfluidics, followed by the use AI modules for each process before reaching the high level of autonomy expected in the AI Scientist.</p>
<p>Therefore, experimental systems shall be less resourcedemanding and accurate yet reliable, reproducible, and integrated. While automation of various experimental processes has been commercialized already these are fragments of an entire process. The challenge requires an entire process of various types of experiments to be automated and part of such system may be installed as robotics cloud laboratory 46   ) with the addition of a new data "d1" and associated arguments. Further addition of data "d2" resulted in the additional split of KGs. Data d3 and associated argumentation contextualized conflicting interpretations separating two KGs (KG 1 4 and KG 1 5 ) that resulted in the merger of them. Such a merge happens when KG 1 4 and KG 1 5 are not compatible due to conflicting interpretation of data d2, but data d3 and associated argumentation clarified conflict can be resolved that two interpretation of data d2 is contextdependent thus both interpretations hold in a different context. For two competing KGs (KG 1 6 and KG 1   7 ), d4 and associated argumentation eliminated KG 1 7 , and KG 1 6 survived and augmented to be KG 1 10 . H. Kitano penalization 47 . Optimization of lycopene biosynthesis pathway and biofuels for synthetic biology-based bio-manufacturing are other examples automated search of design space was shown to be effective 61,62 . Such success demonstrates the introduction of robotics-AI systems for each process shall improve the quality and efficiency of experiments. Automated closed-loop system impacts synthetic biology as well due to its quality and reproducibility 63 . Currently, only a system closed-the-loop of hypothesis generation and experimental verification is on budding yeast genetics 13 .</p>
<p>Variety of experiments and their complexity shall be significantly augmented to cope with an extensive set of hypotheses to be verified. A literature analysis of over 1628 papers indicates 86-89% of experimental protocols in these papers can be automated by readily available commercial robotics systems 64 . This implies the progress can be quick initially, and what matters will be how to integrate different processes, data management, and how to automate processes that are not automated at this moment as well as novel protocols in future.</p>
<p>To achieve this, precise process management shall be imposed for the flows of control, materials, data, and physical agents. Due to vast numbers of experiments required for verification, experimental systems shall be compact and requirements for experimental samples and reagents shall be minimized. Organson-Chips is a recent addition to technologies that can reproduce experimental context closer to in vivo condition while maintaining controllability, traceability, and requires smaller amounts of experimental materials 65,66 . A novel origami-inspired surgical robot has interesting characteristics of being compact and high precision that can be applied for a range of experiments 67 . In future, the combination of microfluidics and robotics system will be used extensively in biological experiments to meet the demands of large numbers of experiments and requirements for controllability, accuracy, and traceability 68 .</p>
<p>Experimental devices shall be controlled by a platform that combines software tools, data access, and experimental systems embedded in the closed loop. Machine learning-guided experimental design was shown to be effective in chemistry 30 and some of the principles can be applied to broader domains. Some of the technological platforms are readily available today, as seen in Garuda Connectivity and Automation Platform 69 , Wings workflow management tool 70,71 , and DISK Data Analysis and Hypothesis Evolution framework 72 , but many have to be developed as a part of the technology challenge. Extensive efforts are made to develop bioinformatics and systems biology analysis and modeling software and data standard that are fundamental to obtain data, analyze them properly, make accurate curation, and enabling dynamical simulations. Annual workshops such as COMBINE and HARMONY drive the development and adaptation of standards (http://co.mbine.org/home). Interoperability of software and data is mandatory to ensure connectivity of laboratory that is essential to automation of not only experimental processes but also analysis and modeling processes. More effort shall be made on the representation of hypothesis and knowledge reflecting the reality of scientific knowledge.</p>
<p>Evolving relationship between AI Scientists, human scientists, and society How does AI Scientist evolve and transform scientific activities? It is clear superhuman-AI Scientist would not emerge out of blue. It will co-evolve with the scientific community over time. A possible, and logical, evolutional path of AI Scientist is to increase the level of automation first, followed by the increase of autonomy level (Fig. 9). Most current use of AI for research is a tool for specific tasks such as image classification, text-mining, and other tasks that are isolated and fully instructed by the human scientist. This is an AI tool stage. An early stage of AI scientist will take a form of a group of useful and highly competent software, including hypothesis generation module, and robotics to execute complex but pre-define tasks as instructed. Robot Scientist Adam and Eve are pioneering examples of this stage. Increasing repertoire of experiments and complexity of hypothesis are the next step. Substantial investment and user feedback are essential to make such systems useful and widely adapted.</p>
<p>Evolutionary pressure imposed on AI Scientist is whether it will be used by human scientists and widely adopted. Investment to develop AI Scientist, either by public funding or private sources, will be driven by the utility of such systems for human scientists. Therefore, AI Scientist will be inevitably interlocked with the research ecosystem of human scientists, and highly competent and user-friendly systems will survive for further development. This path inevitably make AI Scientist designed to be highly interactive with human scientists. Researchers will quickly understand the value and the power of AI Scientist, and will soon start asking questions that require the exhaustive generation of hypotheses and verification that exploits the full potential of AI Scientist at each stage of evolution. This will trigger the transformative change in biology as we witness in genomics when the unbiased measurement of genome sequence and transcriptome uncovered new realities in biology such as noncoding RNA 73,74 . Even without large-scale experiments, hypothesis generation capability of AI Scientist shall help researchers to explore hypotheses that may not be considered without such AI Scientist as well as being an extremely effective dialog-based creativity and discovery support system. Institutions without AI Scientist will no longer be competitive in science and technology.</p>
<p>With an increasing level of autonomy, AI Scientists are expected to make an autonomous decision on what to investigate next. While mechanisms to make it possible is yet to be seen, multiple strategies can be considered such as (1) goal-oriented approach of defining very high-level goals and find multiples paths to best achieve such goals or (2) bottom-up approach of exploring hypothesis search space based on discoveries already made by a specific AI Scientist. In either case, questions to be asked can be automatically extracted from publication, defined by human researchers, or randomly generating questions to be answered.</p>
<p>With an increased level of connectivity and flexibility to generate hypotheses and their verification process, instruction from human scientist will be more abstract, and AI Scientist will  Fig. 9 A possible path towards the Nobel Turing Challenge. AI Scientist requires a highly automated and connected laboratory to be able to design and execute experiments, as well as extensive access to databases and publication archives to process, extract, and evaluate current knowledge. Sophisticated laboratory automation is mandatory. Robot Scientist, Adam &amp; Eve, is highly specialized automation with a certain level of intelligence for hypothesis generation and experimental protocol generation. The next step is to fully automate and connect laboratory equipment with layers of control for data flow, material flow, and physical control flow.</p>
<p>Numbers of AI assistants shall be installed for each task initially, but need to be integrated as an integrated and highly autonomous system. The transition of automated system to autonomous system will be one of the most challenging part of the initiative.</p>
<p>have an increased autonomous process to make decision of priorities of hypotheses to be tested and experimental protocols to be performed. This is a semi-autonomous stage because instruction on what to investigate is provided from outside although how to investigate them may be generated internally by AI Scientist. The level of abstraction of instruction by Human scientists need to be carefully chosen so that AI Scientist can execute the task with success. Instruction such as "find a set of protocols (transcription factors, chemicals, procedures) that can transform types of somatic cell (X) into defined cell types (Y)" is a difficult but tangible one. For such an instruction, multiple experimental protocol shall be generated, and prioritize choice of source and target cell types, interventions to use tested, and analysis procedures. However, much higher goals, such as "cure cancer", "increase human life span to 150 years", or "minimize climate change" would be problematic as some of these goals are too abstract, at least at the initial phase of AI Scientist. With the evolution of AI Scientist over years, some these questions may be addressed in future, still it requires user understanding on capability of AI Scientist to utilize its power. With potentially expensive running cost of AI Scientists, especially when large-scale experiments are required, a certain level of monitoring will be enforced in most institutions. AI Scientist may include a function to generate questions more relevant to its owner or to the society. At least, it is highly plausible larger investment will be made to deliver high return on investment outcome. In this case, the choice of problem and evaluation of the significance of discoveries will reflect humancentric value system, most specifically the value of the stakeholders.</p>
<p>However, AI Scientists under this circumstance are less likely to make unexpected discoveries since the problems to be solved are pre-defined. Researchers with a priori expectations may sometime miss the big picture when one without such expectation may notice 75 . There are many cases discoveries initially received minor attention led to major discoveries later. It is extremely difficult, if not impossible, to evaluate the significance of the discovery when a few more discoveries may be needed to translate the discovery into high-impact outcome due to the over-the-horizon problem. The real value of AI Scientist is its capability to explore hypothesis space magnitude more efficiently into seemingly low-value domains with expectation that may eventually leads to major outcomes. Such systematic explorations into seemingly low-value hypothesis space are infeasible to be performed by human scientists. Both aspects of discovery are important that implies two roles for AI Scientist can be assumed that are "AI Scientist as a Problem Solver" aligned with the value of the stakeholders and "AI Scientist as an Explorer" that boldly explore hypothesis space nobody have gone before. However, in either cases, exhaustive hypothesis generation and verification will be the core of the AI Scientist that distinguishes it from the traditional approach. AI Scientist will be a multiplexed multi-agent system generating multiple instances of AI Scientist (Fig. 10). It is comprised of many software and hardware agents (highly functional modules with a certain level of autonomy) with a high level of interactions, interoperability, and scalability in problem size and complexity. There may be two characteristics for an architecture of AI Scientist.</p>
<p>First, it may be a multiplexing multi-agent system. It is possible multiple instances of AI Scientist are created each specialized in a certain area extensively exploring hypothesis space organically. They are almost identical in components but differ in hypothesis space exploring. Communication among AI Scientists may enable them to merge discoveries for further exploration. This may take a form of communication between AI Scientists through a series of inquiries or the creation of a new synthetic new AI Scientist. Therefore, AI Scientist as a whole entails multiple instances of AI Scientist with focused areas. In this case, discoveries may be made systematically centered around initial core domains and eventually as a combination of multiple domains forming specific pathdependencies in discoveries. In the community of AI Scientist, a series of discoveries and publications made by AI Scientist may resemble that of the successful scientist. Interaction between AI Scientists is equivalent to the search and exchange of new knowledge and style of discovery specialized by each AI Scientist. When the critical mass of knowledge and data is required to generate significant hypothesis combining multiple domains, forming the community of AI Scientist would make sense. The discovery of CRISPR-Cas9 may be one of the examples of revolutionary discoveries coming from the combination of basic research seemingly distant areas of research 76 . It is well recognized that many discoveries considered groundbreaking was triggered by connecting two or more seemingly unrelated ideas. If AI Scientist shall be able to make discoveries of this nature, it must be able to access and connect very broad and less related domains where there is already a sufficient accumulation of knowledge and data by each AI Scientist.</p>
<p>Second, it may be a human-in-the-loop system. From AI Scientist perspective, agents composing them do not have to be exclusively software or hardware, it can be human expert as far as it can interface with the rest of the system. Human experts can be in the role of domain experts or in the commanding and monitoring role. The commanding and monitoring role is important to avoid misuse of the system. Potentially, AI Scientist can make discoveries that are harmful to human and our planet. What to discover fully depends on how the owner uses such capability. A strict ethical guideline and enforcement may be required with increased level of autonomy of AI Scientist. Ultimately, it will impact national security of the highest level.</p>
<p>There will be multiple AI Scientists either by institutions, academic community, country, or other societal boundaries. Some of them may communicate each other, some may be configured in isolation, and some would form local networks. Such   Fig. 10 A possible configuration of AI Scientists: AI Scientist is a multiplexed multi-agent system where multiple instances of AI Scientist will be created. They evolve, merge, and interact with humans. Human experts can be a part of the system as human-in-the-loop system. Scientists who wish to work with AI Scientist are most likely to work with instances of AI Scientist.</p>
<p>configuration may be decided based on ownership of data and intellectual properties generated. Some modules and databases will be publicly maintained, and some would be proprietary. Although the level of autonomy can be very high, intellectual property is still retained with human researchers who run this system because human researchers make the decision to run AI Scientist and monitor their progress, and are responsible for the outcome. Some institutions may run AI Scientist at free-run modes with very high levels of autonomy, to let it explore hypothesis space that human researchers may not think of. Even in such a case, completely autonomous may not be achievable, as the intention of the owner will influence the running of the system. AI Scientist to transform systems biology and broader area of sciences Automating the process of hypothesis generation and verification shall transform broad areas of sciences. Systems biology is one of the representative areas most affected by such technology, not only because it enables researchers to cope with massive data and publications otherwise under-utilized, but also it enables researchers to develop large-scale high-precision models as well as performing investigation significantly broader in scope and more extensively in parameter space than current approaches.</p>
<p>One of the initial expectations of systems biology was to develop a high-precision large-scale model of biological systems such as virtual humans that can be used as digital-twin of patients with in-depth molecular mechanisms behind 77,78 . While it is a holy grail of systems biology, it was proven to be extremely challenging as anticipated. There are fundamental difficulties for such a task partly due to the limitation of our cognitive capabilities and sociological constraints 14 . The research landscape of systems biology is clustered around two modalities that are; (1) a highprecision mechanistic model for the smaller and tractable system and (2) a large-scale network model based on omics data but less on detailed mechanisms. There is an inherent trade-off between these two modalities and attempts to overcome such trade-off have fallen short of expectations. First, there are human cognitive constraints. A vast amount of data and complexity of the system often goes beyond human comprehension and non-linear nature of biological process make things more difficult. Second, there are practical constraints as well. Building a large-scale precision model requires details of almost every interaction and molecular behavior to be investigated both computationally and experimentally which is beyond the capability of most research groups. Investigating each of such interactions and molecular behavior would require major efforts while many of them may not result in immediate major discoveries by itself. While interesting discoveries shall spring out from some of such efforts, tasks are designed to fill in every detail of a large model, rather than speculating the potential importance of interactions and molecules. It is not practical to assume dedicated efforts by members of the research group to be sustainable for many years unless most of such process is automated.</p>
<p>Perhaps, systems biology, particularly studies for large-scale precision models, is not a research field for human alone to investigate as possible causes of difficulties lies in human cognitive and sociological limitations. Once we accept the reality such a trade-off is inherent in human cognitive limitations and sociological constraints, the path to overcoming the trade-off is obvious. It is a field suitable for AI or AI-human hybrid system. Building high-precision large-scale models and efficiently exploit such models and aggregated knowledge to back it up requires powerful AI systems to support our scientific activities.</p>
<p>The AI system is not only useful for building large-scale in-depth models but will exhibit its power to discover new mechanisms and principles we have not imagined as well as discovering novel drug targets efficiently with a significantly extended search of target candidates. Extensive use of AI for drug discovery has been discussed with the implication of dramatically improving its efficiency and the transformation of the process 79 . Early successful cases including rapid identification of kinase inhibitor for DDR1 are encouraging 80 . A recent success of AlphaFold represents how AI technologies impact biomedical studies 81 . Studies on the relationship between drug target proteins and numbers of interactions of proteins demonstrate there is a low but reasonable probability that proteins with small numbers of identified interactions to be drug targets 82 . Although chances each protein can be a drug target may be small because the total numbers of such proteins are huge, exhaustive search of this class of proteins may result in abundant novel drug targets. With the same issues that arose in high-precision large-scale models, automation of the research process is essential to explore such opportunities.</p>
<p>Extending such an approach to synthetic biology to automate design and verification processes 63,83,84 .</p>
<p>Ultimately, a series of new discoveries will be integrated into an integrated model that is large-scale, high-precision, and in-depth. The implication is massive. It does not only mean researchers use AI Scientist as one of the tools, but it implies the practice of scientific discovery will be transformed dramatically with AI Scientist because discoveries will be made at scale and autonomously. At the same time, this will be a golden opportunity for systems biology since it will transform system biology into the next stage.</p>
<p>AI Scientist can be transformative not only in life science but also for broader science and technology domains. This is especially the case that requires hypothesis generation and verification to broader range parameter search of chemical synthesis and material discovery. Already, there are emerging interests in chemistry and material science for automation of experiments coupled with machine learning guide experimental design at various levels 30,46,[85][86][87][88][89][90] . The idea of massive search of hypothesis space and verification applies to these domains as well. However, if such efforts can be applied to the discovery of novel concepts are yet to be seen. Recently, The Ramanujan Machine was announced for automated generation of conjectures in mathematics 36 . The Ramanujan Machine added a new perspective as it is not a parameter search and extensive generation of conjectures. With the rapid advances in robotics, sensors, AI with the increasing availability of computing powers, AI Scientists for broader domains of science will be inevitable. Research institutions without such capability will no longer be competitive in the coming decade.</p>
<p>The Nobel Turing Challenge is the ultimate challenge for AI and systems biology. Any progress toward achieving the goal will generate high utility technologies that shall accelerate science. Due to its breadth of expertise required and possible length of duration to achieve the goal, it may best be organized as a virtual big science 91 . Once the initiative taking off, it will uncover the essence of scientific discovery, and results in the creation of an alternative form of science. AI Scientist and human scientists will work together to solve formidable problems and to explore new intellectual territories where no one have gone before.</p>
<p>. Recently, a robotics experimental system successfully identified proper condition for cell culture of medical-grade iPS-derived retinal pigment epithelial (RPE) cells after searching 200 million possible parameter combinations through Bayesian optimization with local</p>
<p>Fig. 8
8Evolving multiverse of knowledge graphs. The original knowledge graph (KG 1 0 ) is split into two incompatible KGs (</p>
<p>A</p>
<p>new synthetic Instance An instance augmented by knowledge exchange Stakeholders: Scientific Community, Funding Agency, Industry, ELSIAI Scientist 
Development 
Community </p>
<p>A Community 
of Scientists 
(Users) </p>
<p>Instances of 
AI Scientist </p>
<p>AI Scientist as Multiplex 
Multi-Agent System </p>
<p>Published in partnership with the Systems Biology Institute npj Systems Biology and Applications (2021) 29
H. Kitano
© The Author(s) 2021
npj Systems Biology and Applications (2021)29 Published in partnership with the Systems Biology Institute
ACKNOWLEDGEMENTSI would like to thank members of the Systems Biology Institute, Okinawa Institute of Science and Technology Graduate School, Sony CSL, and Sony AI for fruitful discussions. Ross King and Yolanda Gil for working together in starting the challenge in reality. Special thanks to Ed Feigenbaum for insightful discussions and encouragements. This work was supported, in part, through an Office of Naval Research Global (ONRG) grant awarded to the Alan Turing Institute.COMPETING INTERESTSThe author is Editor-in-Chief of npj Systems Biology and Applications. The author was not involved in the review and decision on publication of this article.ADDITIONAL INFORMATIONCorrespondence and requests for materials should be addressed to H.K.Reprints and permission information is available at http://www.nature.com/ reprintsPublisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons. org/licenses/by/4.0/.
The Logic of Scientific Discovery. K Popper, Taylor &amp; FrancisPopper, K. The Logic of Scientific Discovery (Taylor &amp; Francis, 1959).</p>
<p>. T S Kuhn, The Structure of Scientific Revolution. University of Chicago PressKuhn, T. S. The Structure of Scientific Revolution (University of Chicago Press, 1962).</p>
<p>I Lakatos, The Methodology of Scientific Research Programmes. Cambridge University PressLakatos, I. The Methodology of Scientific Research Programmes (Cambridge Uni- versity Press, 1978).</p>
<p>P Feyerabend, Method, Outline of an Anarchistic Theory of Knowledge. Humanities PressFeyerabend, P. Against Method: Outline of an Anarchistic Theory of Knowledge (Humanities Press, 1975).</p>
<p>Inductive Inference of Theories From Facts. E Shapiro, Yale UniversityShapiro, E. Inductive Inference of Theories From Facts (Yale University, 1981).</p>
<p>DENDRAL: a case study of the first expert system for scientific hypothesis formation. R Lindsay, B Buchanan, E Feigenbaum, J Lederberg, Artif. Intell. 61Lindsay, R., Buchanan, B., Feigenbaum, E. &amp; Lederberg, J. DENDRAL: a case study of the first expert system for scientific hypothesis formation. Artif. Intell. 61, 209-261 (1993).</p>
<p>P Langley, H Simon, Scientific, Discovery, Computational Exploration of the Creative Processes. The MIT PressLangley, P. &amp; Simon, H. Scientific Discovery: Computational Exploration of the Creative Processes (The MIT Press, 1987).</p>
<p>Why AM and EURISKO appear to work. D Lenat, J Brown, Artif. Intell. 23Lenat, D. &amp; Brown, J. Why AM and EURISKO appear to work. Artif. Intell. 23, 269-294 (1984).</p>
<p>. Y Gil, H Hirsh, Discovery Informatics: AI Opportunities in Scientific Discovery. AAAIGil, Y. &amp; Hirsh, H. Discovery Informatics: AI Opportunities in Scientific Discovery (AAAI, 2012).</p>
<p>Artificial Intelligence. Amplify scientific discovery with artificial intelligence. Y Gil, M Greaves, J Hendler, H Hirsh, Science. 346Gil, Y., Greaves, M., Hendler, J. &amp; Hirsh, H. Artificial Intelligence. Amplify scientific discovery with artificial intelligence. Science 346, 171-172 (2014).</p>
<p>Functional genomic hypothesis generation and experimentation by a robot scientist. R D King, Nature. 427King, R. D. et al. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature 427, 247-252 (2004).</p>
<p>Make way for robot scientists. R D King, Science. 325945King, R. D. et al. Make way for robot scientists. Science 325, 945 (2009).</p>
<p>The automation of science. R D King, Science. 324King, R. D. et al. The automation of science. Science 324, 85-89 (2009).</p>
<p>Artificial intelligence to win the nobel prize and beyond: creating the engine for scientific discovery. H Kitano, AI Mag. 37Kitano, H. Artificial intelligence to win the nobel prize and beyond: creating the engine for scientific discovery. AI Mag. 37, 39-49 (2016).</p>
<p>Computing machinery and intelligence. A M Turing, Mind. 59Turing, A. M. Computing machinery and intelligence. Mind 59, 433-460 (1950).</p>
<p>Some challenges and grand challenges for computational intelligence. E Feigenbaum, J. ACM. 50Feigenbaum, E. Some challenges and grand challenges for computational intel- ligence. J. ACM 50, 32-40 (2003).</p>
<p>Bitcoin: A Peer-to-Peer Electronic Cash System. S Nakamoto, Nakamoto, S. Bitcoin: A Peer-to-Peer Electronic Cash System, http://www.bitcoin. org/bitcoin.pdf (2008).</p>
<p>Complex Information Processing: The Impact of. H A Simon, Klahr, D. &amp; Kotovsky. K.Lawrence Erlbaum Associates, PublishersSimon, H. A. in Complex Information Processing: The Impact of Herbert A. Simon (eds Klahr, D. &amp; Kotovsky. K.) 375-398 (Lawrence Erlbaum Associates, Publishers, 1989).</p>
<p>Induction of pluripotent stem cells from mouse embryonic and adult fibroblast cultures by defined factors. K Takahashi, S Yamanaka, Cell. 126Takahashi, K. &amp; Yamanaka, S. Induction of pluripotent stem cells from mouse embryonic and adult fibroblast cultures by defined factors. Cell 126, 663-676 (2006).</p>
<p>Induction of pluripotent stem cells from adult human fibroblasts by defined factors. K Takahashi, Cell. 131Takahashi, K. et al. Induction of pluripotent stem cells from adult human fibro- blasts by defined factors. Cell 131, 861-872 (2007).</p>
<p>The Nobel Prize in Physiology or Medicine. S Yamanaka, Shinya Yamanaka -Biographical. Yamanaka, S. The Nobel Prize in Physiology or Medicine 2012 -Shinya Yamanaka - Biographical, https://www.nobelprize.org/prizes/medicine/2012/yamanaka/ biographical/ (2012).</p>
<p>The Nobel Prize in Chemistry. H Shirakawa, Hideki Shirakawa -Biographical. Shirakawa, H. The Nobel Prize in Chemistry 2000 -Hideki Shirakawa -Biographical, https://www.nobelprize.org/prizes/chemistry/2000/shirakawa/biographical/ (2000).</p>
<p>. E Feigenbaum, Feldman, J. Computers and Thought. McGraw-Hill Book CompanyFeigenbaum, E. &amp; Feldman, J. Computers and Thought (McGraw-Hill Book Com- pany, 1963).</p>
<p>. M Campbell, J HoaneJr, F.-H. Deep Hsu, Blue, Artif. Intell. 134Campbell, M., Hoane, J. Jr. &amp; Hsu, F.-H. Deep blue. Artif. Intell. 134, 57-83 (2002).</p>
<p>Mastering the game of Go with deep neural networks and tree search. D Silver, Nature. 529Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484-489 (2016).</p>
<p>Mastering the game of Go without human knowledge. D Silver, Nature. 550Silver, D. et al. Mastering the game of Go without human knowledge. Nature 550, 354-359 (2017).</p>
<p>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. D Silver, Science. 362Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140-1144 (2018).</p>
<p>Mastering Atari, Go, chess and shogi by planning with a learned model. J Schrittwieser, Nature. 588Schrittwieser, J. et al. Mastering Atari, Go, chess and shogi by planning with a learned model. Nature 588, 604-609 (2020).</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. K Williams, J. R. Soc. Interface. 1220141289Williams, K. et al. Cheaper faster drug development validated by the reposi- tioning of drugs against neglected tropical diseases. J. R. Soc. Interface 12, 20141289 (2015).</p>
<p>Machine-learning-assisted materials discovery using failed experiments. P Raccuglia, Nature. 533Raccuglia, P. et al. Machine-learning-assisted materials discovery using failed experiments. Nature 533, 73-76 (2016).</p>
<p>. M Spranger, S Palaniappan, S Ghosh, BioNLP. Association of Computaitonal LinguisticsSpranger, M., Palaniappan, S. &amp; Ghosh, S. in BioNLP 2016 Vol. BioNLP 2016, 119-127 (Association of Computaitonal Linguistics, Germany, 2016).</p>
<p>Temporal node-pair embedding for automatic biomedical hypothesis generation. U Akujuobi, M Spranger, S Palaniappan, X Zhang, T-Pair, 10.1109/TKDE.2020.3017687IEEE Transactions on Knowledge and Data Engineering. Akujuobi, U., Spranger, M., Palaniappan, S., Zhang, X. T-PAIR: Temporal node-pair embedding for automatic biomedical hypothesis generation. In IEEE Transactions on Knowledge and Data Engineering https://doi.org/10.1109/TKDE.2020.3017687 (2020).</p>
<p>Using deep learning to model the hierarchical structure and function of a cell. J Ma, Nat. Methods. 15Ma, J. et al. Using deep learning to model the hierarchical structure and function of a cell. Nat. Methods 15, 290-298 (2018).</p>
<p>Enhancing scientific discoveries in molecular biology with deep generative models. R Lopez, A Gayoso, N Yosef, Mol. Syst. Biol. 169198Lopez, R., Gayoso, A. &amp; Yosef, N. Enhancing scientific discoveries in molecular biology with deep generative models. Mol. Syst. Biol. 16, e9198 (2020).</p>
<p>Deep phenotyping predicts Huntington's genotype. D M Ruderfer, J T Dudley, Nat. Biotechnol. 34Ruderfer, D. M. &amp; Dudley, J. T. Deep phenotyping predicts Huntington's genotype. Nat. Biotechnol. 34, 823-824 (2016).</p>
<p>Generating conjectures on fundamental constants with the Ramanujan Machine. G Raayoni, Nature. 590Raayoni, G. et al. Generating conjectures on fundamental constants with the Ramanujan Machine. Nature 590, 67-73 (2021).</p>
<p>An autonomous debating system. N Slonim, Nature. 591Slonim, N. et al. An autonomous debating system. Nature 591, 379-384 (2021).</p>
<p>Qualitative modeling. K D Forbus, 10.1002/wcs.115Wiley Interdiscip. Rev. 2Forbus, K. D. Qualitative modeling. Wiley Interdiscip. Rev. 2, 374-391, https://doi. org/10.1002/wcs.115 (2011).</p>
<p>Representations: How People Reason and Learn About the Continuous World. K D Forbus, Qualiatative, The MIT PressForbus, K. D. Qualiatative Representations: How People Reason and Learn About the Continuous World (The MIT Press, 2019).</p>
<p>Deep hidden physics models: deep learning of nonlinear partial differential equations. M Raissi, J. Mach. Learn. Res. 19Raissi, M. Deep hidden physics models: deep learning of nonlinear partial dif- ferential equations. J. Mach. Learn. Res. 19, 1-24 (2018).</p>
<p>Data driven nonlinear dynamical systems identification using multi-step CLDNN. Q Teng, L Zhang, AIP Advances. 985311Teng, Q. &amp; Zhang, L. Data driven nonlinear dynamical systems identification using multi-step CLDNN. AIP Advances 9, 085311 (2019).</p>
<p>SBML qualitative models: a model representation format and infrastructure to foster interactions between qualitative modelling formalisms and tools. C Chaouiya, BMC Syst. Biol. 7135Chaouiya, C. et al. SBML qualitative models: a model representation format and infrastructure to foster interactions between qualitative modelling formalisms and tools. BMC Syst. Biol. 7, 135 (2013).</p>
<p>Constructing explanatory process models from biological data and knowledge. P Langley, O Shiran, J Shrager, L Todorovski, A Pohorille, Artif. Intell. Med. 37Langley, P., Shiran, O., Shrager, J., Todorovski, L. &amp; Pohorille, A. Constructing explanatory process models from biological data and knowledge. Artif. Intell. Med. 37, 191-201 (2006).</p>
<p>Believe it or not: how much can we rely on published data on potential drug targets?. F Prinz, T Schlange, K Asadullah, Nat. Rev. Drug Discov. 10712Prinz, F., Schlange, T. &amp; Asadullah, K. Believe it or not: how much can we rely on published data on potential drug targets? Nat. Rev. Drug Discov. 10, 712 (2011).</p>
<p>Achieving reproducibility and closed-loop automation in biological experimentation with an IoT-enabled lab of the future. B Miles, P L Lee, SLAS Technol. 23Miles, B. &amp; Lee, P. L. Achieving reproducibility and closed-loop automation in biological experimentation with an IoT-enabled lab of the future. SLAS Technol. 23, 432-439 (2018).</p>
<p>Robotic crowd biology with Maholo LabDroids. N Yachie, C Robotic Biology, T Natsume, Nat. Biotechnol. 35Yachie, N., Robotic Biology, C. &amp; Natsume, T. Robotic crowd biology with Maholo LabDroids. Nat. Biotechnol. 35, 310-312 (2017).</p>
<p>Robotic search for optimal cell culture in regenerative medicine. G N Kanda, 10.1101/2020.11.25.392936Preprint at bioRxivKanda, G. N. et al. Robotic search for optimal cell culture in regenerative medi- cine. Preprint at bioRxiv https://doi.org/10.1101/2020.11.25.392936 (2020).</p>
<p>Identifying noise sources governing cell-to-cell variability. S Mitchell, A Hoffmann, Curr. Opin. Syst. Biol. 8Mitchell, S. &amp; Hoffmann, A. Identifying noise sources governing cell-to-cell variability. Curr. Opin. Syst. Biol. 8, 39-45 (2018).</p>
<p>Cell-to-cell variability in the propensity to transcribe explains correlated fluctuations in gene expression. M S Sherman, K Lorenz, M H Lanier, B A Cohen, Cell Syst. 1Sherman, M. S., Lorenz, K., Lanier, M. H. &amp; Cohen, B. A. Cell-to-cell variability in the propensity to transcribe explains correlated fluctuations in gene expression. Cell Syst. 1, 315-325 (2015).</p>
<p>Representation of probabilistic scientific knowledge. L N Soldatova, A Rzhetsky, K De Grave, R D King, J. Biomed. Semant. 47Soldatova, L. N., Rzhetsky, A., De Grave, K. &amp; King, R. D. Representation of prob- abilistic scientific knowledge. J. Biomed. Semant. 4, S7 (2013).</p>
<p>A truth maintenance system. J Doyle, Artif. Intell. 12Doyle, J. A truth maintenance system. Artif. Intell. 12, 251-272 (1979).</p>
<p>An assumption-based TMS. J De Kleer, Artif. Intell. 28de Kleer, J. An assumption-based TMS. Artif. Intell. 28, 127-162 (1986).</p>
<p>M V Martinez, I Varzinczak, NMR-2020: Workshop Notes of the 18th International Workshop on Non-Monotonic Reasoning. Buenos Aires and LensMartinez, M. V. &amp; Varzinczak, I., NMR-2020: Workshop Notes of the 18th Inter- national Workshop on Non-Monotonic Reasoning, (Buenos Aires and Lens, 2020).</p>
<p>S Toulmin, The Uses of Argument. Cambridge University PressToulmin, S. The Uses of Argument (Cambridge University Press, 1958).</p>
<p>Epistemic graphs for representing and reasoning with positive and negative influences of arguments. A Hunter, S Polberg, M Thimm, Artif. Intell. 281103236Hunter, A., Polberg, S. &amp; Thimm, M. Epistemic graphs for representing and rea- soning with positive and negative influences of arguments. Artif. Intell. 281, 103236 (2020).</p>
<p>Toward artificial argumentation. AI Magazine. K Atkinson, Atkinson, K. et al. Toward artificial argumentation. AI Magazine 25-36 (Fall, 2017).</p>
<p>Argumentation in artificial intelligence. T J M Bench-Capon, P Dunne, Artif. Intell. 171Bench-Capon, T. J. M. &amp; Dunne, P. Argumentation in artificial intelligence. Artif. Intell. 171, 619-641 (2007).</p>
<p>Qualitative simulation. B Kuipers, Artif. Intell. 29Kuipers, B. Qualitative simulation. Artif. Intell. 29, 289-338 (1986).</p>
<p>Qualitative simulation: then and now. B Kuipers, Artif. Intell. 59Kuipers, B. Qualitative simulation: then and now. Artif. Intell. 59, 133-140 (1993).</p>
<p>The scope and limits of simulation in automated reasoning. E Davis, G Marcus, Artif. Intell. 233Davis, E. &amp; Marcus, G. The scope and limits of simulation in automated reasoning. Artif. Intell. 233, 60-72 (2016).</p>
<p>Accelerating strain engineering in biofuel research via build and test automation of synthetic biology. J Zhang, Curr. Opin. Biotechnol. 67Zhang, J. et al. Accelerating strain engineering in biofuel research via build and test automation of synthetic biology. Curr. Opin. Biotechnol. 67, 88-98 (2021).</p>
<p>Towards a fully automated algorithm driven platform for biosystems design. M Hamedirad, Nat. Commun. 105150HamediRad, M. et al. Towards a fully automated algorithm driven platform for biosystems design. Nat. Commun. 10, 5150 (2019).</p>
<p>Improving reproducibility in synthetic biology. M M Jessop-Fabre, N Sonnenschein, Front. Bioeng. Biotechnol. 718Jessop-Fabre, M. M. &amp; Sonnenschein, N. Improving reproducibility in synthetic biology. Front. Bioeng. Biotechnol. 7, 18 (2019).</p>
<p>Indicators for the use of robotic labs in basic biomedical research: a literature analysis. P Groth, J Cox, PeerJ. 53997Groth, P. &amp; Cox, J. Indicators for the use of robotic labs in basic biomedical research: a literature analysis. PeerJ 5, e3997 (2017).</p>
<p>Organs-onchips: into the next decade. L A Low, C Mummery, B R Berridge, C P Austin, D A Tagle, Nat. Rev. Drug Discov. 20Low, L. A., Mummery, C., Berridge, B. R., Austin, C. P. &amp; Tagle, D. A. Organs-on- chips: into the next decade. Nat. Rev. Drug Discov. 20, 345-361 (2020).</p>
<p>Scaling and systems biology for integrating multiple organson-a-chip. J P Wikswo, Lab Chip. 13Wikswo, J. P. et al. Scaling and systems biology for integrating multiple organs- on-a-chip. Lab Chip 13, 3496-3511 (2013).</p>
<p>Origami-inspired miniature manipulator for teleoperated microsurgery. H Suzuki, R J Wood, Nat. Mach. Intell. 2Suzuki, H. &amp; Wood, R. J. Origami-inspired miniature manipulator for teleoperated microsurgery. Nat. Mach. Intell. 2, 437-446 (2020).</p>
<p>When robotics met fluidics. J Zhong, Lab Chip. 20Zhong, J. et al. When robotics met fluidics. Lab Chip 20, 709-716 (2020).</p>
<p>Software for systems biology: from tools to integrated platforms. S Ghosh, Y Matsuoka, Y Asai, K Y Hsin, H Kitano, Nat. Rev. Genet. 12Ghosh, S., Matsuoka, Y., Asai, Y., Hsin, K. Y. &amp; Kitano, H. Software for systems biology: from tools to integrated platforms. Nat. Rev. Genet. 12, 821-832 (2011).</p>
<p>Y Gil, V Ratnakar, E Deelman, G Mehta, J Kim, Innovative Applications of Artificial Intelligence (IAAI-07). Vancouver, British Columbia, CanadaGil, Y., Ratnakar, V., Deelman, E., Mehta, G. &amp; Kim, J. In Innovative Applications of Artificial Intelligence (IAAI-07) (Vancouver, British Columbia, Canada, 2007).</p>
<p>Wings: intelligent workflow-based design of computational experiments. Y Gil, IEEE Intell. Syst. 26Gil, Y. et al. Wings: intelligent workflow-based design of computational experi- ments. IEEE Intell. Syst. 26, 62-72 (2011).</p>
<p>Y Gil, The Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17) (The Association for the Advancement of Artificial Intelligence. Gil, Y. et al. in The Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17) (The Association for the Advancement of Artificial Intelligence, 2017).</p>
<p>Paradigm shifts in genomics through the FANTOM projects. M De Hoon, J W Shin, P Carninci, Mamm. Genome. 26de Hoon, M., Shin, J. W. &amp; Carninci, P. Paradigm shifts in genomics through the FANTOM projects. Mamm. Genome 26, 391-402 (2015).</p>
<p>FANTOM enters 20th year: expansion of transcriptomic atlases and functional annotation of non-coding RNAs. I Abugessaisa, Nucleic Acids Res. 49Abugessaisa, I. et al. FANTOM enters 20th year: expansion of transcriptomic atlases and functional annotation of non-coding RNAs. Nucleic Acids Res. 49, D892-D898 (2021).</p>
<p>A hypothesis is a liability. I Yanai, M Lercher, Genome Biol. 21231Yanai, I. &amp; Lercher, M. A hypothesis is a liability. Genome Biol. 21, 231 (2020).</p>
<p>A Crack in Creation: Gene Editing and the Unthinkable Power to Control Evolution. J Doudna, S Sternberg, Houghton Mifflin HarcourtDoudna, J. &amp; Sternberg, S. A Crack in Creation: Gene Editing and the Unthinkable Power to Control Evolution (Houghton Mifflin Harcourt, 2017).</p>
<p>All systems go. D Jones, Nat. Rev. Drug Discov. 7Jones, D. All systems go. Nat. Rev. Drug Discov. 7, 128-129 (2008).</p>
<p>Pharma 2020: Virtual R&amp;D ---Which Path Will You Take?. Pricewaterhousecoopers, PricewaterhouseCoopers. Pharma 2020: Virtual R&amp;D ---Which Path Will You Take? (2007).</p>
<p>Rethinking drug design in the artificial intelligence era. P Schneider, Nat. Rev. Drug Discov. 19Schneider, P. et al. Rethinking drug design in the artificial intelligence era. Nat. Rev. Drug Discov. 19, 353-364 (2020).</p>
<p>Deep learning enables rapid identification of potent DDR1 kinase inhibitors. A Zhavoronkov, Nat. Biotechnol. 37Zhavoronkov, A. et al. Deep learning enables rapid identification of potent DDR1 kinase inhibitors. Nat. Biotechnol. 37, 1038-1040 (2019).</p>
<p>Improved protein structure prediction using potentials from deep learning. A W Senior, Nature. 577Senior, A. W. et al. Improved protein structure prediction using potentials from deep learning. Nature 577, 706-710 (2020).</p>
<p>Structure of protein interaction networks and their implications on drug design. T Hase, H Tanaka, Y Suzuki, S Nakagawa, H Kitano, PLoS Comput. Biol. 51000550Hase, T., Tanaka, H., Suzuki, Y., Nakagawa, S. &amp; Kitano, H. Structure of protein interaction networks and their implications on drug design. PLoS Comput. Biol. 5, e1000550 (2009).</p>
<p>Design automation in synthetic biology. E Appleton, C Madsen, N Roehner, D Densmore, 10.1101/cshperspect.a023978Cold Spring Harb. Perspect. Biol. 9Appleton, E., Madsen, C., Roehner, N. &amp; Densmore, D. Design automation in synthetic biology. Cold Spring Harb. Perspect. Biol. 9, https://doi.org/10.1101/ cshperspect.a023978 (2017).</p>
<p>Needs and opportunities in bio-design automation: four areas for focus. E Appleton, D Densmore, C Madsen, N Roehner, Curr. Opin. Chem. Biol. 40Appleton, E., Densmore, D., Madsen, C. &amp; Roehner, N. Needs and opportunities in bio-design automation: four areas for focus. Curr. Opin. Chem. Biol. 40, 111-118 (2017).</p>
<p>Self-driving laboratory for accelerated discovery of thin-film materials. B P Macleod, Science Adv. 68867MacLeod, B. P. et al. Self-driving laboratory for accelerated discovery of thin-film materials. Science Adv. 6, eaaz8867 (2020).</p>
<p>Next-generation experimentation with self-driving laboratories. F Häse, L M Roch, A Aspuru-Guzik, Trends Chem. 1Häse, F., Roch, L. M. &amp; Aspuru-Guzik, A. Next-generation experimentation with self-driving laboratories. Trends Chem. 1, 282-291 (2019).</p>
<p>Progress and prospects for accelerating materials science with automated and autonomous workflows. H S Stein, J M Gregoire, Chem. Sci. 10Stein, H. S. &amp; Gregoire, J. M. Progress and prospects for accelerating materials science with automated and autonomous workflows. Chem. Sci. 10, 9640-9649 (2019).</p>
<p>Accelerating the discovery of materials for clean energy in the era of smart automation. D P Tabor, Nat. Rev. Mater. 3Tabor, D. P. et al. Accelerating the discovery of materials for clean energy in the era of smart automation. Nat. Rev. Mater. 3, 5-20 (2018).</p>
<p>Autonomy in materials research: a case study in carbon nanotube growth. P Nikolaev, Comput. Mater. 216031Nikolaev, P. et al. Autonomy in materials research: a case study in carbon nanotube growth. npj Comput. Mater. 2, 16031 (2016).</p>
<p>Scientific AI in materials science: a path to a sustainable and scalable paradigm. B L Decost, 10.1088/2632-2153/ab9a20Mach. Learn Sci. Technol. 1DeCost, B. L. et al. Scientific AI in materials science: a path to a sustainable and scalable paradigm. Mach. Learn Sci. Technol. 1, https://doi.org/10.1088/2632- 2153/ab9a20 (2020).</p>
<p>Social engineering for virtual 'big science' in systems biology. H Kitano, S Ghosh, Y Matsuoka, Nat. Chem. Biol. 7Kitano, H., Ghosh, S. &amp; Matsuoka, Y. Social engineering for virtual 'big science' in systems biology. Nat. Chem. Biol. 7, 323-326 (2011).</p>            </div>
        </div>

    </div>
</body>
</html>